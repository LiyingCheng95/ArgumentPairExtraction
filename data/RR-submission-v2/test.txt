This paper studies the problem of learning both the distance metric and a linkage rule from clustering examples.	O	O	Review	20484
Suppose we have L metrics d_1, ‚Ä¶, d_L and L‚Äô linkage rules for hierarchical agglomerative clustering, D_1, ‚Ä¶, D_L‚Äô where each rule is a 2-point-based merge function (i.e. computes the distance between some two points in the clusters, examples of such functions are single-linkage and complete-linkage).	O	O	Review	20484
The paper considers the problem of finding the convex combination of the distance functions and linkage rules which best fits the data.	O	O	Review	20484
The main result (Theorem 1) is an \tildeO((L‚Äô + L)^2 L‚Äô /eps^2) uniform convergence bound on the number of clustering instances which are required to learn up to expected loss \eps the best possible convex combination.	O	O	Review	20484
The key technical part of the proof is showing that for any fixed clustering the loss function is piecewise-constant with a small number of simple pieces.	O	O	Review	20484
The overall approach is based on Balcan et al‚Äô17 who solve the case when the distance metric is known but the linkage rule is to be learned and Balcan et al ‚Äò19 who give techniques for the piecewise constant case.	O	O	Review	20484
Some further results are given which are specific to learning a mix of two merge functions under a single distance metric and the best combination of two metrics when using the complete linkage merge function.	O	O	Review	20484
Experimental results are given on MNIST, CIFAR-10 and some other fairly small datasets.	O	O	Review	20484
<sep> <sep> The paper makes a somewhat interesting contribution to the area, but I think can only be seen as a basic step in the general direction.	B-Review	B-1	Review	20484
Most of the interesting merge functions used for HAC don‚Äôt boil down to simple 2-point-merge rules (average-linkage, Ward‚Äôs method, etc.).	I-Review	I-1	Review	20484
The sample complexity of the problem is rather prohibitive.	B-Review	B-2	Review	20484
In particular, it is unclear to me why the experimental setup in the paper is consistent with the theoretical model -- when i.i.d.	I-Review	I-2	Review	20484
clusterings should be sampled from a distribution, why is it ok to just sample 5 random classes from MNIST a bunch of times?	I-Review	I-2	Review	20484
In this case the ground truth clustering is fixed and you sample some subset of classes from it each time.	I-Review	I-2	Review	20484
This seems like a much simpler setup compared to the general setting considered in the paper.	I-Review	I-2	Review	20484
I would expect a real experimental setup to have all n points be fixed, then you have a distribution over different clusterings on the same set of points which you sample from each time.	I-Review	I-2	Review	20484
<sep> <sep> Thank you for your careful review and thoughtful comments.	O	O	Reply	20484
<sep> <sep> - At the end of Section 2 we discuss how our analysis can be extended to include merge functions beyond 2-point-based merges.	B-Reply	B-1	Reply	20484
In the camera ready version of the paper we will include clarifications and additional details.	I-Reply	I-1	Reply	20484
We only use the 2-point-based property in Lemma 2.	I-Reply	I-1	Reply	20484
First, we show that restricted to beta belonging to any region of the partition constructed in Lemma 1, any 2-point-based merge function is a linear function of the metric parameter.	I-Reply	I-1	Reply	20484
Second, we use it to count the total number of quadratic functions that must be included in the set Q. We can extend the result to also hold when one of the merge functions is chosen to be average-linkage using the following insights: first, the average-linkage distance between a pair of clusters is always a linear function of the metric parameter.	I-Reply	I-1	Reply	20484
Second, we can replace the bound of on the size of by since that is a bound on the number of ways to choose two clusters from points.	I-Reply	I-1	Reply	20484
This exponential increase in the size of corresponds to a linear dependence on in our final sample complexity, since we depend only on the log size of.	I-Reply	I-1	Reply	20484
<sep> <sep> - The motivating setting for our experiments is described in the introduction.	B-Reply	B-2	Reply	20484
We are thinking about situations where we encounter a collection of related clustering tasks and where the target clustering is consistent from task to task (e.g., each day we cluster the articles appearing in a newspaper and our goal is always to cluster them by topic).	I-Reply	I-2	Reply	20484
The distributions in our experiments model this type of situation.	I-Reply	I-2	Reply	20484
Each instance includes a random set of points (drawn from a larger classification dataset) and our goal is to find an algorithm that best recovers the target clustering given by the ground-truth labels.	I-Reply	I-2	Reply	20484
If we think of the points as being news articles and the class labels being the unknown topics, then this fits well with our formal problem setup and is consistent with our theoretical results.	I-Reply	I-2	Reply	20484
In contrast, if we were to keep the points fixed but vary the target clustering, no single algorithm will have good performance, since each algorithm can produce only one clustering for the points.	I-Reply	I-2	Reply	20484

Summary:	O	O	Review	20484
<sep> This paper proposed a data-driven method of selecting a linkage-based clustering algorithm from a large space.	O	O	Review	20484
The space of algorithms is parameterized by two sets of parameters which indicate the convex combinations of metrics and merge functions.	O	O	Review	20484
They analyze the sample complexity for small generalization error.	O	O	Review	20484
An efficient algorithm for searching an empirically optimal algorithm is proposed.	O	O	Review	20484
<sep> <sep> Comments:	O	O	Review	20484
<sep> In general, I think this is a good quality paper.	O	O	Review	20484
<sep> - Selecting a clustering algorithm from a large space by a data-driven method is an interesting and sound idea, which makes a lot of sense to me.	O	O	Review	20484
<sep> - The theorem for generalization error is strong.	O	O	Review	20484
<sep> <sep> It can be further improved in the following aspects (mainly the experiments).	O	O	Review	20484
<sep> - The curves in Fig 3 all look smooth, so I wondered whether one can simply apply a grid search on [0.1,0.2,...,1.0], the obtained algorithm should also be very good.	B-Review	B-1	Review	20484
To demonstrate the advantage and necessity of the proposed search algorithm, I think it better to either conduct an experiment with a higher dimensional search space (instead of only searching \alpha) or demonstrate a case when there is a sharp turn near the optimal point, so that grid search won't work well.	I-Review	I-1	Review	20484
<sep> - Although the authors have proved the generalization error, it is still better to empirically validate the theoretical result, by showing the training and testing errors along with varying sample sizes.	B-Review	B-2	Review	20484
<sep> <sep> Overall I like the idea and the theoretical analysis in this paper, but the experimental results could be further improved.	O	O	Review	20484
Therefore I vote for weak acceptance.	O	O	Review	20484
<sep> <sep> <sep> ----- after reading the response --	O	O	Review	20484
<sep> I'd like to thank the authors for giving more explanations.	B-Review	B-1	Review	20484
Theoretically, I understand the advantages of the proposed algorithm, but still, it is more convincing if stronger experiments can be conducted.	I-Review	I-1	Review	20484
<sep> <sep> My score does not change, but overall I advocate to accept this paper.	O	O	Review	20484
<sep> <sep> Thank you for your careful review and thoughtful comments.	O	O	Reply	20484
<sep> <sep> - Yes, for the specific distributions in our experiments section, using grid search with a sufficiently fine grid would find nearly optimal parameters.	B-Reply	B-1	Reply	20484
However, there are clustering distributions for which the expected cost is not smooth and the set of approximately optimal parameters is an arbitrarily small interval (we will include such an example in the camera ready version).	I-Reply	I-1	Reply	20484
Our proposed methods have two significant advantages over grid search.	I-Reply	I-1	Reply	20484
First, they are guaranteed to return empirically optimal parameters even when the performance is not smooth.	I-Reply	I-1	Reply	20484
Second, they are more efficient than running grid search with a very fine grid.	I-Reply	I-1	Reply	20484
To see this, observe that if the grid has points, we must run the clustering algorithm times on every training clustering instance.	I-Reply	I-1	Reply	20484
In contrast, the cost of our proposed methods scales with the number of discontinuities for each instance.	I-Reply	I-1	Reply	20484
If is bigger than the average number of discontinuities, then the grid search is actually more computationally expensive.	I-Reply	I-1	Reply	20484
<sep> <sep> - We agree that it would be interesting to validate our theoretical claims empirically by showing that the performance of parameters are similar across training and testing datasets of various sizes.	B-Reply	B-2	Reply	20484
Our current experimental results support our theory by showing that for several natural distributions over clustering tasks, we can obtain large improvements in performance by combining a pair of merge functions or a pair of metrics.	I-Reply	I-2	Reply	20484
They also show that our proposed optimization algorithms are efficient enough to run on realistically sized clustering instances.	I-Reply	I-2	Reply	20484

In this paper, the authors propose an approach to learning combinations of (instance-wise) distance metrics and (cluster-wise) merge functions to optimally cluster instances from a  particular data distribution.	O	O	Review	20484
In particular, given a set of clustering instances (each of which is a set of instances from the domain and their cluster assignment), a set of distance metrics, and a set of merge functions, the proposed approach aims to learn a convex combination of the distance metrics and merge functions to reconstruct the given clusterings.	O	O	Review	20484
<sep> <sep> The paper has two main contributions.	O	O	Review	20484
First, a PAC learning type of guarantee is given on the quality of the learned clustering approach.	O	O	Review	20484
Second, an efficient data structure for identifying the convex combinations is given.	O	O	Review	20484
A small set of experiments suggests that, in practice, the learned combinations can outperform using single distance metrics and merge functions.	O	O	Review	20484
<sep> <sep> Comments	O	O	Review	20484
<sep> I am not an expert in this area; I had trouble following the details of the theoretical developments.	B-Review	B-6	Review	20484
However, I appreciated that intuition was given on both what the theorems and lemmas were showing as well as the main steps of the proofs.	I-Review	I-6	Review	20484
<sep> <sep> Concerning Theorem 1, it is not exactly clear to me what the contribution is on top of [Balcan et al 2019]. The text mentions that they already give sample complexity guarantees in what seems like the same setting (piecewise-structured cost function).	B-Review	B-3	Review	20484
<sep> <sep> The authors point out that depth-first traversal is a good choice here due to its memory efficiency.	B-Review	B-5	Review	20484
However, in cases where the search space is a graph rather than a tree (i.e., there are multiple paths to some nodes), then DFS can exponentially increase the work compared to breadth-first or other search strategies (e.g., [Edelkamp and Schroedl, 2012]).	I-Review	I-5	Review	20484
While the name suggests that the ‚Äúexecution tree‚Äù is, indeed, a tree, is this guaranteed to be the case?	I-Review	I-5	Review	20484
or could multiple paths lead to the same partition?	I-Review	I-5	Review	20484
<sep> <sep> For the experimental evaluation, it seems as though there is no ‚Äútest‚Äù set of clustering instances.	B-Review	B-7	Review	20484
It would be helpful to also include performance of the learned combinations on some test clustering instances to give an idea of how generalizable to approach is to other instances within the data distribution. (	I-Review	I-7	Review	20484
Of course, the main contributions of this work are the theoretical developments, so just one or two examples would be sufficient.)	I-Review	I-7	Review	20484
<sep> <sep> For motivation, it would be helpful to give some examples where the prerequisites of this work are actually met; that is, cases where sufficiently large number of labeled cluster instances are available, but the generative mechanism of the clusters is not.	B-Review	B-4	Review	20484
<sep> <sep> For context, it could be helpful to briefly mention how, if at all, the current results apply to widely-used clustering algorithms such as k-means or Gaussian mixture models.	B-Review	B-2	Review	20484
<sep> <sep> Typos, etc.	B-Review	B-1	Review	20484
<sep> <sep> The references are somewhat inconsistently formatted.	B-Review	B-8	Review	20484
Also, some proper nouns in titles are not capitalized (e.g., ‚Äúlloyd‚Äôs families‚Äù).	I-Review	I-8	Review	20484
<sep> <sep> ‚Äúleaves correspond to‚Äù -&gt; ‚Äúleaves corresponding to‚Äù	I-Review	I-8	Review	20484
<sep> What does the ‚Äúbig-Oh tilde‚Äù notation in Theorem 1 mean?	I-Review	I-8	Review	20484
<sep> <sep> Thank you for your careful review and thoughtful comments.	O	O	Reply	20484
<sep> <sep> - The key insight behind our sample complexity guarantee is that for the proposed family of algorithms and any clustering instance, we can partition the parameter space into a small number of simple regions where the algorithm output is constant.	B-Reply	B-3	Reply	20484
We rely on the results of Balcan et al (2019) only for the last step in the proof to convert this structural property into a sample complexity guarantee.	I-Reply	I-3	Reply	20484
In the camera ready version we will clarify this and provide a direct proof of our sample complexity bound - the proof for our specific setting does not really need the subtle machinery of  that work.	I-Reply	I-3	Reply	20484
<sep> <sep> - The algorithms we propose in Section 3 completely enumerate the leaves of the execution tree (i.e., they don't stop early once they've found a promising leaf), and therefore the number of nodes visited by DFS and BFS are identical.	B-Reply	B-5	Reply	20484
The key difference is that DFS only keeps one path from root to leaf in memory at a time, and for this algorithm family we are guaranteed that the depth of the tree is.	I-Reply	I-5	Reply	20484
On the other hand, BFS keeps one level of the tree in memory at a time, which can be significantly larger (e.g., for interpolating between single and complete linkage, our best bound on the width of a level is.	I-Reply	I-5	Reply	20484
We will clarify this in the camera ready version of the paper.	I-Reply	I-5	Reply	20484
<sep> <sep> - We briefly describe a few examples of where the prerequisites of our work are met in the introduction.	B-Reply	B-4	Reply	20484
In general, we have in mind any application where we face a sequence of clustering tasks and we can ask a human to provide the target clusterings for those tasks (e.g., clustering the news articles that appear day to day by topic).	I-Reply	I-4	Reply	20484
In these situations, having a low sample complexity is crucial because we do not want to ask for many target clusterings.	I-Reply	I-4	Reply	20484
We will expand and emphasize the examples in the camera ready version of the paper.	I-Reply	I-4	Reply	20484
<sep> <sep> - While our results do not apply to the-means algorithm or Gaussian mixture models, we do not view this as a shortcoming given that hierarchical clustering is widely used and a classic research area.	B-Reply	B-2	Reply	20484
Our related work discusses relationships between our work and a related paper for learning initialization procedures for Lloyd's method for-means clustering.	I-Reply	I-2	Reply	20484
We will include further discussion of these relationships and the applicability of our results.	I-Reply	I-2	Reply	20484
<sep> <sep> - We agree that it would be interesting to validate our sample complexity results empirically.	B-Reply	B-3	Reply	20484
See our response to R3's similar comment.	I-Reply	I-3	Reply	20484
<sep> <sep> - We will correct the typos and ambiguities you found, thanks!	B-Reply	B-1	Reply	20484

Summary:	O	O	Review	304
The paper presents three different methods of training a low precision student network from a teacher network using knowledge distillation.	O	O	Review	304
<sep> Scheme A consists of training a high precision teacher jointly with a low precision student.	O	O	Review	304
Scheme B is the traditional knowledge distillation method and Scheme C uses knowledge distillation for fine-tuning a low precision student which was pretrained in high precision mode.	O	O	Review	304
<sep> <sep> Review:	O	O	Review	304
The paper is well written.	O	O	Review	304
The experiments are clear and the three different schemes provide good analytical insights.	O	O	Review	304
<sep> Using scheme B  and C student model with low precision could achieve accuracy close to teacher while compressing the model.	O	O	Review	304
<sep> <sep> Comments:	O	O	Review	304
Tensorflow citation is missing.	B-Review	B-1	Review	304
<sep> Conclusion is short and a few directions for future research would have been useful.	B-Review	B-2	Review	304
Thank you for the reviews and comments.	O	O	Reply	304
<sep> <sep> Missing citation: this is an oversight.	B-Reply	B-1	Reply	304
We will fix this.	I-Reply	I-1	Reply	304
<sep> <sep> Future directions for research:	O	O	Reply	304
1.	O	O	Reply	304
We are currently pursuing the extension of the ideas in this paper to RNNs.	B-Reply	B-2	Reply	304
Our preliminary studies on a language model for PTB dataset showed promise and based on this we are evaluating a larger data set and model like Deep Speech-2.	I-Reply	I-2	Reply	304
<sep> 2.	O	O	Reply	304
Some works proposing low-precision networks advocate for making the layers wider (or the model larger) to recover accuracy at low-precision.	B-Reply	B-2	Reply	304
These works propose making the layers wider by 2x or 3x.	I-Reply	I-2	Reply	304
While these works show the benefits of low-precision, making the model larger increases the number of raw computations.	I-Reply	I-2	Reply	304
Future work could investigate low-precision and less layer widening factor (say 1.10x or 1.25x or ...).	I-Reply	I-2	Reply	304
This would help inference latency while maintaining accuracy at-par with baseline full-precision.	I-Reply	I-2	Reply	304
<sep> 3.	O	O	Reply	304
Another interesting line of investigation for future work is looking into sparsifying networks at low-precision while maintaining baseline level accuracy and using knowledge distillation scheme during this process.	B-Reply	B-2	Reply	304
As mentioned in Sec 5.5 in our paper, sparsifying a model more than a certain percentage leads to accuracy loss.	I-Reply	I-2	Reply	304
Investigating hyper-sparse network models without accuracy loss using distillation based schemes is an interesting avenue of further research.	I-Reply	I-2	Reply	304

The paper aims at improving the accuracy of a low precision network based on knowledge distillation from a full-precision network.	O	O	Review	304
Instead of distillation from a pre-trained network, the paper proposes to train both teacher and student network jointly.	O	O	Review	304
The paper shows an interesting result that the distilled low precision network actually performs better than high precision network.	O	O	Review	304
<sep> <sep> I found the paper interesting but the contribution seems quite limited.	B-Review	B-1	Review	304
<sep> <sep> Pros:	O	O	Review	304
1.	O	O	Review	304
The paper is well written and easy to read.	O	O	Review	304
<sep> 2.	O	O	Review	304
The paper reported some interesting result such as that the distilled low precision network actually performs better than high precision network, and that training jointly outperforms the traditional distillation method (fixing the teacher network) marginally.	O	O	Review	304
<sep> <sep> Cons:	O	O	Review	304
1.	O	O	Review	304
The name Apprentice seems a bit confusing with apprenticeship learning.	B-Review	B-2	Review	304
<sep> 2.	O	O	Review	304
The experiments might be further improved by providing a systematic study about the effect of precisions in this work (e.g., producing more samples of precisions on activations and weights).	B-Review	B-3	Review	304
<sep> 3.	B-Review	B-4	Review	304
It is unclear how the proposed method outperforms other methods based on fine-tuning.	I-Review	I-4	Review	304
It is also quite possible that after fine-tuning the compressed model usually performs quite similarly to the original model.	I-Review	I-4	Review	304
Thank you for the reviews.	O	O	Reply	304
They are useful.	O	O	Reply	304
<sep> <sep> We defend our contribution aspect below:	O	O	Reply	304
<sep> Contributions: Distillation along with lowering precision has not been studied before.	B-Reply	B-1	Reply	304
We show benefits of this combined approach - both distillation and low precision target model compression aspect - but when combined the benefits are significant.	I-Reply	I-1	Reply	304
We also show how one can use the combined distillation and lowering precision approach to training as well as fine-tuning.	I-Reply	I-1	Reply	304
<sep> <sep> Our approach achieves state-of-the-art in accuracy over prior proposals and using our approach we significantly close the gap between full-precision and low-precision model accuracy.	I-Reply	I-1	Reply	304
We demonstrate the benefits on ImageNet with large networks (ResNet).	I-Reply	I-1	Reply	304
For example, with ResNet-50 on ImageNet, prior work showed 4.7% accuracy degradation with 8-bits activation and 4-bits weight.	I-Reply	I-1	Reply	304
We lower this gap to less than 1.5%.	I-Reply	I-1	Reply	304
<sep> <sep> We believe ours to be the first work that targets both model compression (using knowledge distillation) and low-precision.	I-Reply	I-1	Reply	304
<sep> <sep> <sep> Response to the Cons aspects:	O	O	Reply	304
1.	O	O	Reply	304
We probably did not do a good job describing why we call our approach Apprentice.	B-Reply	B-2	Reply	304
We will fix this and disambiguate from apprenticeship-based learning schemes.	I-Reply	I-2	Reply	304
<sep> <sep> 2.	O	O	Reply	304
The reason we focus on sub 8-bit precision is that model inference with 8-bits is becoming mainstream and we seek to target next-gen hardware architectures.	B-Reply	B-3	Reply	304
Also, from a hardware point-of-view 8-bits, 4-bits and 2-bits simplify design (e.g. alignment across cache line boundaries and memory accesses vs. 3-bits or 5-bits precision for example).	I-Reply	I-3	Reply	304
<sep> <sep> 3.	O	O	Reply	304
We had tried the scheme you mention in (3) but the results were not (as) good compared to the schemes we mention in the paper, hence we omitted this scheme from our paper.	O	O	Reply	304
<sep> <sep> We experimented with ResNet-18 with (a) first, compressing using distillation scheme (used ResNet-34 as the teacher network) and then (b) lowered the precision to ternary mode (fine-tuning for 35 epochs with low learning rate).	B-Reply	B-4	Reply	304
This experiment was done for ImageNet-1K dataset.	I-Reply	I-4	Reply	304
This experiment is a variation of scheme-C in our paper where we start with full-precision networks and jointly fine-tune (use distillation scheme with warm start-up).	I-Reply	I-4	Reply	304
<sep> Activation precision was 8-bits for this experiment.	I-Reply	I-4	Reply	304
The ResNet-18 network converged to 33.13% Top-1 error rate.	I-Reply	I-4	Reply	304
Comparing this with "jointly" compressing and lowering precision while training from scratch, we get 32.0% Top-1 error rate (Table-1, 4th row and 2nd column).	I-Reply	I-4	Reply	304
So, our Apprentice scheme for this network and configuration is 1.13% better.	I-Reply	I-4	Reply	304
<sep> <sep> Your point is well taken and we will include results where first we use knowledge distillation scheme to generate a smaller ResNet model and then lower the precision and fine-tune this small model.	I-Reply	I-4	Reply	304
Currently, we have results of this scheme with ResNet-18 and few precision knobs and will collect results with this scheme for ResNet-34 and ResNet-50 for the final paper version.	I-Reply	I-4	Reply	304
<sep> As mentioned above, the conclusions of our paper would not change and the new results will show the benefits of joint training with distillation (Apprentice scheme).	I-Reply	I-4	Reply	304
Many works proposing low-precision knobs advocate for training from scratch or training with warm-startup (from weights at full-precision numerics) -- our work is in line with these observations.	I-Reply	I-4	Reply	304

The authors investigate knowledge distillation as a way to learn low precision networks.	O	O	Review	304
They propose three training schemes to train a low precision student network from a teacher network.	O	O	Review	304
They conduct experiments on ImageNet-1k with variants of ResNets and multiple low precision regimes and compare performance with previous works	O	O	Review	304
<sep> Pros:	O	O	Review	304
(+) The paper is well written, the schemes are well explained	O	O	Review	304
(+) Ablations are thorough and comparisons are fair	O	O	Review	304
Cons:	O	O	Review	304
(-) The gap with full precision models is still large	B-Review	B-1	Review	304
(-) Transferability of the learned low precision models to other tasks is not discussed	B-Review	B-2	Review	304
<sep> The authors tackle a very important problem, the one of learning low precision models without comprosiming performance.	O	O	Review	304
For scheme-A, the authors show the performance of the student network under many low precision regimes and different depths of teacher networks.	O	O	Review	304
One observation not discussed by the authors is that the performance of the student network under each low precision regime doesn't improve with deeper teacher networks (see Table 1, 2 & 3).	B-Review	B-3	Review	304
As a matter of fact, under some scenarios performance even decreases.	I-Review	I-3	Review	304
<sep> <sep> The authors do not discuss the gains of their best low-precision regime in terms of computation and memory.	B-Review	B-4	Review	304
<sep> <sep> Finally, the true applications for models with a low memory footprint are not necessarily related to image classification models (e.g. ImageNet-1k).	B-Review	B-5	Review	304
How good are the low-precision models trained by the authors at transferring to other tasks?	I-Review	I-5	Review	304
Is it possible to transfer student-teacher training practices to other tasks?	I-Review	I-5	Review	304
Thank you for the thorough reviews.	O	O	Reply	304
<sep> <sep> We defend the "Cons" reviews below:	O	O	Reply	304
<sep> Gap from full precision: Agreed.	B-Reply	B-1	Reply	304
However, compared to prior works the improvement is significant.	I-Reply	I-1	Reply	304
For example, now with 8-bits activations and 4-bits weight, ResNet-34 without any change in network architecture is only 0.5% off from baseline full precision.	I-Reply	I-1	Reply	304
This is currently the best Top-1 figure at this precision knob -- the best figure with prior techniques gave 3.3% degradation (so 2.8% improvement with our scheme).	I-Reply	I-1	Reply	304
We believe that by making the models slightly larger (by 10% or so) we can close the gap between low-precision and full-precision networks -- this is our future work.	I-Reply	I-1	Reply	304
<sep> <sep> Transferability: We believe, this aspect should not change with our scheme for low-precision settings -- we simply better the accuracy of a given network at low-precision (compared to prior proposals).	B-Reply	B-2	Reply	304
However much the network was useful in transfer learning scenarios with low-precision tensors before, the network right now with our scheme would be similarly useful (if at all better when compared to prior works since we achieve a better accuracy with low-precision).	I-Reply	I-2	Reply	304
<sep> <sep> Your question: Is it possible to transfer student-teacher training practices to other tasks?	O	O	Reply	304
<sep> Although we did not focus on this aspect in this paper, we found the following 3 works (not an exhaustive list) that use the student-teacher training procedure for other deep-learning domains:	B-Reply	B-5	Reply	304
<sep> 1.	I-Reply	I-5	Reply	304
Transferring Knowledge from a RNN to a DNN, William Chan et al ArXiv pre-print, 2015.	I-Reply	I-5	Reply	304
<sep> 2.	I-Reply	I-5	Reply	304
Recurrent Neural Network Training With Dark Knowledge Transfer, Zhiyuan Tang et al ArXiv pre-print, 2016.	I-Reply	I-5	Reply	304
<sep> 3.	I-Reply	I-5	Reply	304
Simultaneous Deep Transfer Across Domains and Tasks, Eric Tzeng et al ICCV 2015.	I-Reply	I-5	Reply	304
<sep> <sep> <sep> The observation that accuracy does not improve when using bigger teacher network(s): We allude to this in Discussion part of Section 5.2 (page-8).	B-Reply	B-3	Reply	304
We mention that the accuracy improvement saturates at some point.	I-Reply	I-3	Reply	304
We will elaborate on this aspect in the final version of the paper.	I-Reply	I-3	Reply	304
<sep> <sep> We will also discuss the merits of low precision on savings in compute and memory.	B-Reply	B-4	Reply	304
We briefly discuss these aspects in Section 2 where we mention about simplification in hardware support required for inference.	I-Reply	I-4	Reply	304
We will elaborate on these aspects and provide quantification in compute and memory footprint savings vs. accuracy in our final version of the paper.	I-Reply	I-4	Reply	304

Overall the paper suffers from a lack of clarity in the presentation, especially in algorithm 1, and does not communicate well why the assumption of different dynamical processes should be important in practice.	O	O	Review	359
Experiments show some improvement compared to (Trivedi et al 2017) but are limited to two datasets and it is unclear to what extend end the proposed method would help for a larger variety of datasets.	O	O	Review	359
<sep> <sep> Not allowing for deletion of node, and especially edges, is a potential draw-back of the proposed method, but more importantly, in many graph datasets the type of nodes and edges is very important (e.g. a knowledge base graph without edges loses most relevant information) so not considering different types is a big limitation.	O	O	Review	359
<sep> <sep> Comments on the method (sections 2-4).	O	O	Review	359
<sep> <sep> About equation (1):	O	O	Review	359
\bar{t} is not defined and its meaning is not obvious.	B-Review	B-6	Review	359
The rate of event occurrence does not seem to depend on l (links status) whereas is seems to be dependent of l in algorithm 1.	I-Review	I-6	Review	359
<sep> <sep> I don‚Äôt see how the timings of association and communication processes are related, both \lambda_k seem defined independently.	B-Review	B-5	Review	359
Should we expect some temporal dependence between different types of events here?	I-Review	I-5	Review	359
The authors mention that both point processes are ‚Äúrelated through the mediation process and in the embedding space‚Äù, a more rigorous definition would be helpful here.	I-Review	I-5	Review	359
<sep> <sep> The authors claim to learn functions to compute node representations, however the representations z^u seem to be direct embeddings of the nodes.	B-Review	B-1	Review	359
If the representations are computed as functions it should be clear what is the input and which functional form is assumed.	I-Review	I-1	Review	359
<sep> <sep> I find algorithm 1 unclear and do not understand how it is formally derived, its justification seems rather fuzzy.	B-Review	B-2	Review	359
It is also unclear how algorithm 1 relates to the loss optimisation presented in section 4.	I-Review	I-2	Review	359
<sep> <sep> What is the mechanism for addition of new nodes to the graph?	B-Review	B-3	Review	359
I don‚Äôt see in algorithm 1 a step where nodes can be added but this might be handled in a different part of the training.	I-Review	I-3	Review	359
<sep> <sep> Comments on the experiments section.	O	O	Review	359
<sep> <sep> Since the proposed method is a variation on (Trivedi et al 2017), a strong baseline would include experiments performed on the same datasets (or at least one dataset) from that paper.	O	O	Review	359
<sep> <sep> It is not clear which events are actually observed.	B-Review	B-4	Review	359
I can see how a structural change in the network can be observed but what exactly constitutes a communication event for the datasets presented?	I-Review	I-4	Review	359
<sep> <sep> - Functional form of Computing Representation: Eq 4.	B-Reply	B-1	Reply	359
provides the functional form that computes the representations with inputs being the three terms and parameterized by the W parameters.	I-Reply	I-1	Reply	359
We state this clearly in revised version.	I-Reply	I-1	Reply	359

Overall, the contribution of the paper is somewhat limited [but a little more than my initial assessment, thanks to the rebuttal]. It is essentially an extension of (Trivedi et al 2017), adding attention to provide self-exciting rates, applied to two types of edges (communication edges and ‚Äúfriendship‚Äù edges).	B-Review	B-6	Review	359
Conditioned on past edges, future edges are assumed independent, which makes the math trivial.	I-Review	I-6	Review	359
The work would be better described as modeling a Marked Point Process with marks k \in {0,1}.	I-Review	I-6	Review	359
Other comments:	O	O	Review	359
1.	O	O	Review	359
<tab>[addressed] DyRep-No-SP is as good as the proposed approach, maybe because the graph is assumed undirected and the embedding of u can be described by its neighbors (author rebuttal describes as Localized Propagation), as the neighbors themselves use the embedding of u for their own embedding (which means that self-propagation is never "really off").	B-Review	B-3	Review	359
Highly active nodes have a disproportional effect in the embedding, resulting in the better separated embeddings of Figure 4. [	I-Review	I-3	Review	359
after rebuttal: what is the effect of node activity on the embeddings?]	I-Review	I-3	Review	359
<sep> 2.	O	O	Review	359
<tab>[unresolved, comment still misundertood] The Exogenous Drive W_t(t_p ‚Äì t_{p‚àí1}) should be more personalized.	B-Review	B-1	Review	359
Some nodes are intrinsically more active than others. [	I-Review	I-1	Review	359
after rebuttal: answer  is personalized as is node specific", I meant personalized as in Exogenous Drive of people like Alice or Bob]	I-Review	I-1	Review	359
3.	O	O	Review	359
<tab>[unresolved] Fig 4 embeddings should be compared against (Trivedi et al 2017) [after rebuttal: author revision does not make qualitative comparison against Trivedi et al (2017)]	B-Review	B-2	Review	359
<sep> Besides the limited innovation, the writing needs work.	B-Review	B-4	Review	359
<sep> 4.	I-Review	I-4	Review	359
<tab>[resolved] Equation 1 defines but does not define \bar{t}. Knowing (Trivedi et al 2017), I immediately knew what it was, but this is not standard notation and should be defined.	I-Review	I-4	Review	359
<sep> 5.	I-Review	I-4	Review	359
<tab>[resolved] must be a function of u and v	I-Review	I-4	Review	359
6.	I-Review	I-4	Review	359
<tab>[resolved]  represent the dynamic process‚Äù = >   represent the type of edge‚Äù .	I-Review	I-4	Review	359
The way it is written would need to be a stochastic process (it is just a mark, k \in {0,1})	I-Review	I-4	Review	359
7.	I-Review	I-4	Review	359
<tab>[resolved] Algorithm 1 is impossibly confusing.	I-Review	I-4	Review	359
I read it 8 times and I still cannot tell what it is supposed to do.	I-Review	I-4	Review	359
It contains recursive definitions like, where itself is a function of.	I-Review	I-4	Review	359
Maybe the z_i(t) and z_i are different variables with the same name?	I-Review	I-4	Review	359
<sep> 8.	I-Review	I-4	Review	359
<tab>[resolved] The only hint that the graph under consideration is undirected comes from Algorithm 1, A_{uv}(t) = A_{vu}(t) = 1.	I-Review	I-4	Review	359
It is *very* important information for the reader.	I-Review	I-4	Review	359
<sep> Related work (to be added to literature):	I-Review	I-4	Review	359
Dynamic graph embedding: (Yuan et al 2017) (Ghassen et al 2017)	I-Review	I-4	Review	359
Dynamic sub-graph embedding: (Meng et al 2018)	I-Review	I-4	Review	359
<sep> Minor:	O	O	Review	359
state-of-arts => state-of-the-art methods	B-Review	B-5	Review	359
list enumeration ‚Äú1.)‚Äù , ‚Äú2.)‚Äù is strange.	I-Review	I-5	Review	359
Decide either 1) , 2) or 1. ,	I-Review	I-5	Review	359
2. .	I-Review	I-5	Review	359
I have never seen both.	I-Review	I-5	Review	359
<sep> MAE => mean absolute error (MAE)	I-Review	I-5	Review	359
<sep> Yuan, Y., Liang, X., Wang, X., Yeung, D. Y., & Gupta, A., Temporal Dynamic Graph LSTM for Action-Driven Video Object Detection.	O	O	Review	359
ICCV, 2017.	O	O	Review	359
<sep> Jerfel,  , Mehmet E. Basbug, and Barbara E. Engelhardt. "	O	O	Review	359
Dynamic Collaborative Filtering with Compound Poisson Factorization."	O	O	Review	359
AISTATS 2017.	O	O	Review	359
<sep> Meng, C., Mouli, S.C., Ribeiro, B. and Neville, J., Subgraph Pattern Neural Networks for High-Order Graph Evolution Prediction.	O	O	Review	359
AAAI 2018.	O	O	Review	359
<sep> <sep> --- --- After rebuttal	O	O	Review	359
<sep> Authors addressed most of my concerns.	O	O	Review	359
The paper has merit and would be of interest to the community.	O	O	Review	359
I am increasing my score.	O	O	Review	359
Thank you for updating your review.	O	O	Reply	359
We added a clarification on the point process perspective as a response to your previous comment.	O	O	Reply	359
Here we address your updated review comments and re-emphasize the contributions of our work:	O	O	Reply	359
<sep> Exogenous Drive: Do you mean Alice/Bob is a person inside network?	B-Reply	B-1	Reply	359
The exogenous drive constitutes the changes in features of node caused by external influences.	I-Reply	I-1	Reply	359
However, activities external to network are not observed in the dataset.	I-Reply	I-1	Reply	359
Hence for a node (or Alice which will be a node in social network) , the term allows a smooth latent approximation of change in‚Äôs features over time caused by such an external effect.	I-Reply	I-1	Reply	359
Please note, is not the time of previous event in the global dataset, it is time for previous event of node.	I-Reply	I-1	Reply	359
<sep> <sep> Contributions: While one can augment the event specification in (Trivedi et al 2017) with additional mark information, that itself is not adequate to achieve our proposed method of modeling dynamical process over graphs at multiple time scales.	B-Reply	B-6	Reply	359
A subtle but key difference in our deep point process formulation that allows us to achieve our goal of two time-scale expression,  is the form of conditional intensity function (Eq 3 in our paper).	I-Reply	I-6	Reply	359
We employ a softplus function for which contains a dynamic specific scale parameter to achieve this while (Trivedi et al 2017) uses an exponential (exp) function for with no such parameter.	I-Reply	I-6	Reply	359
The exponential choice of also restricts their model to Rayleigh dynamics while DyRep can capture more general dynamics.	I-Reply	I-6	Reply	359
<sep> <sep> However, we wish to emphasize that our major contributions for learning dynamic graph representation in this work extend well beyond this conditional intensity function.	I-Reply	I-6	Reply	359
To the best of our knowledge, our work is the first to adopt the paradigm of expressing network processes at different time-scales (widely studied in network dynamics literature) to representation learning over dynamic graphs and propose an end-to-end framework for the same.	I-Reply	I-6	Reply	359
Further our novel representation learning module that incorporates *graph structure* - using  Temporal Point Process based Self-Attention (a principled advancement over all existing graph based neural self-attention techniques) and Localized Embedding Propagation - is not a straightforward extension or variant of (Trivedi et al 2017).We will release the code and datasets with the final version of the paper.	I-Reply	I-6	Reply	359
<sep> <sep> We again thank you for your time and discussions.	O	O	Reply	359
Please let us know if there are still unclear points and we would be happy to clarify your further concerns.	O	O	Reply	359

The paper is very well written.	O	O	Review	359
The proposed approach is appropriate on modeling the node representations when the two types of events happen in the dynamic networks.	O	O	Review	359
Authors also clearly discussed the relevance and difference to related work.	O	O	Review	359
Experimental results show that the presented method outperforms the other baselines.	O	O	Review	359
<sep> Overall, it is a high-quality paper.	O	O	Review	359
<sep> There are only some minor comments for improving the paper:	O	O	Review	359
ŒΩ<tab>Page 6, there is a typo. ‚	B-Review	B-1	Review	359
Äúfor node v by employing ‚Ä¶‚Äù  should be ‚Äúfor node u‚Äù	I-Review	I-1	Review	359
ŒΩ<tab>Page 6, ‚ÄúBoth GAT and GaAN has‚Äù   should be  ‚ÄúBoth GAT and GaAN have‚Äù	B-Review	B-2	Review	359
ŒΩ<tab>In section 5.1, it will be great if authors can explain more what are the ‚Äúassociation events‚Äù and ‚Äúcommunication events‚Äù with more details in these two evaluation datasets.	B-Review	B-3	Review	359
<sep> <sep> Thank you for your review!	O	O	Reply	359
We appreciate your time and supportive feedback and we are glad that you find our work interesting.	O	O	Reply	359
Details about the corresponding association and communication events in the two datasets are provided in Appendix E.1.	B-Reply	B-3	Reply	359
We uploaded a revised version that contains your suggested changes.	I-Reply	I-3	Reply	359

This paper proposes a method to train high- and low-level controllers to tackle hierarchical RL.	O	O	Review	437
The novelty is framing hierarchical RL as a problem of training a diverse set of LL controllers such that they can be used by a HL controller to solve high-level tasks.	O	O	Review	437
By dividing state representation into proprioceptive and task-specific, the reward used to train LL and HL controllers are simplified.	O	O	Review	437
Experimental result shows that the method is effective at solving maze environments for both ant and humanoid.	O	O	Review	437
<sep> <sep> The good parts:	O	O	Review	437
- The method of training diversified LL controller and a single high-level controller seems to work unreasonably well.	O	O	Review	437
And one benefit of this approach is that the rewards for both high (sparse) and low (difference) level controllers can be trivially defined.	O	O	Review	437
<sep> <sep> - The separation of proprioceptive and task-specific states seems to be gaining popularity.	O	O	Review	437
For the maze environment (and any task that involves locomotion), this can be done intuitively.	O	O	Review	437
<sep> <sep> Place to improve:	O	O	Review	437
- Terrain-Adaptive Locomotion (Peng et al 2016) used a similar approach of phase-indexed motion, as well as selecting from a mixture of experts to generate action sequence for the next cycle.	B-Review	B-1	Review	437
Perhaps worthwhile to cite.	I-Review	I-1	Review	437
<sep> <sep> - In fact, it seems that phase in this work only benefited training of low-level controller for humanoid.	B-Review	B-2	Review	437
But it should be possible to train humanoid locomotion with using phase information.	I-Review	I-2	Review	437
<sep> <sep> - This hierarchical approach shouldn't depend on the selection of state space.	B-Review	B-3	Review	437
What would happen when LL and HL controllers all receive the same inputs?	I-Review	I-3	Review	437
<sep> <sep> - The paper is difficult to follow at places.	B-Review	B-4	Review	437
Ex.	I-Review	I-4	Review	437
b_phi element of R^d in Section 3.3.	I-Review	I-4	Review	437
I'm still not sure what is b_phi, and what is d here.	I-Review	I-4	Review	437
<sep> <sep> - The choice of K = 10 feels arbitrary.	B-Review	B-5	Review	437
Since K corresponds to the length of a cycle, it should make sense to choose K such that the period is reasonable compared to average human stride period, etc.	I-Review	I-5	Review	437
What is the simulation step length?	I-Review	I-5	Review	437
<sep> <sep> - Since LL policies control the style of the motion and the only reward it gets is to keep moving, presumably the resulting motion would look unnatural or exhibit excessive energy consumption.	B-Review	B-6	Review	437
Does "keep moving" reward work with other common rewards like energy penalty, etc?	I-Review	I-6	Review	437
<sep> <sep> We thank the reviewer for their time.	O	O	Reply	437
We will try to answer your questions and concerns here.	O	O	Reply	437
<sep> <sep> Peng et al is definitely worth citing.	B-Reply	B-1	Reply	437
We will add that citation.	I-Reply	I-1	Reply	437
<sep> <sep> Phase function	O	O	Reply	437
The phase training does also benefit the ant, although not as much perhaps as humanoid.	B-Reply	B-2	Reply	437
For humanoid, there definitely have been works that have trained humanoid without phase information with techniques such as Soft-Actor Critic.	I-Reply	I-2	Reply	437
In practice, this seems to be difficult to tune.	I-Reply	I-2	Reply	437
We chose a widely used PPO implementation in Kostrikov (2018), but default parameters and a grid search over parameters, we were unable to train a humanoid that receives reasonable movement reward.	I-Reply	I-2	Reply	437
<sep> State space selection	O	O	Reply	437
It is possible that you could learn the high-level and low-level policy with the entire state space, although not necessarily as efficiently.	B-Reply	B-3	Reply	437
But the idea of the paper is that we want to abstract away low-level details from the high-level controller so it can focus on the planning and high-level problems.	I-Reply	I-3	Reply	437
Especially as RL starts to tackle more complicated problems, and as it moves to real-world robotics, this abstraction is very useful for efficiently learning difficult high-level policies.	I-Reply	I-3	Reply	437
<sep> <sep> Confusion in notation	O	O	Reply	437
b_phi is a learned parameter in our network, like a bias term, that depends on the phase index.	B-Reply	B-4	Reply	437
These are input to our network and the value is updated by back-propogation.	I-Reply	I-4	Reply	437
d is just the choice for the dimensionality of b_phi, in our case 16.	I-Reply	I-4	Reply	437
<sep> We will clarify this in revision.	I-Reply	I-4	Reply	437
<sep> <sep> Choice of K	O	O	Reply	437
K=10 is approximately the time a trained Mujoco ant model will take to make a complete cycle of action.	B-Reply	B-5	Reply	437
The simulation step length is 0.05sec.	I-Reply	I-5	Reply	437
<sep> <sep> Energy consumption	B-Reply	B-6	Reply	437
As we say in S3.2, we do train with the Mujoco environment rewards including energy penalty.	I-Reply	I-6	Reply	437

Brief summary:	O	O	Review	437
HRL method which uses a 2 level hierarchy for sparse reward tasks.	O	O	Review	437
The low level policies are only provided access to proprioceptive parts of the observation, and are trained to maximize change in the non-proprioceptive part of the state as reward.	O	O	Review	437
The higher level policy is trained as usual by commanding lower level policies.	O	O	Review	437
<sep> <sep> Overall impression:	O	O	Review	437
I think the paper has a major assumption about the separation of internal and external state, thereby setting the form of the low level primitives.	B-Review	B-12	Review	437
This may not be fully general, but is particularly useful for the classes of tasks shown here as seen from the strong results.	B-Review	B-1	Review	437
I would like to see the method applied more generally to other robotic tasks, and a comparison to Florensa et al And perhaps the addition of a video which shows the learned behaviors.	I-Review	I-1	Review	437
<sep> <sep> Introduction:	O	O	Review	437
the difficulty of learning a high-level controller when the low-level policies shifts -> look at ‚Äúdata efficient hierarchical reinforcement learning‚Äù (Nachum et al)	O	O	Review	437
<sep> The basic assumption that we can separate out observations into proprioceptive and not proprioceptive can often be difficult.	O	O	Review	437
For example with visual inputs or entangled state representations, this might be very challenging to extract.	O	O	Review	437
This idea seems to be very heavily based on what is ‚Äúinternal‚Äù and what is ‚Äúexternal‚Äù to the agent, which may be quite challenging to separate.	O	O	Review	437
<sep> <sep> The introduction of phase functions seems to be very specific to locomotion?	B-Review	B-2	Review	437
<sep> ‚Ä®Related work:	O	O	Review	437
The connection of learning diverse policies should be discussed with Florensa et al, since they also perform something similar with their mutual information term.	B-Review	B-3	Review	437
DeepMimic, DeepLoco (Peng et al) also use phase information in the state, worthwhile to cite.	I-Review	I-3	Review	437
<sep> <sep> Section 3.1:	B-Review	B-4	Review	437
The pros and cons of making the assumption that representation is disentangled enough to make this separation, should be discussed.	I-Review	I-4	Review	437
<sep> <sep> Also, the internal and external state should be discussed with a concrete example, for the ant for example.	B-Review	B-5	Review	437
<sep> <sep> Section 3.2:	B-Review	B-6	Review	437
The objective for learning diverse policies is in some sense more general than Florensa et al, but in the same vein of thinking.	I-Review	I-6	Review	437
What are the pros and cons of this approach over that?‚Ä®‚Ä®The objective is greedy in the change of external state.	I-Review	I-6	Review	437
We‚Äôd instead like something that over the whole trajectory maximizes change?	I-Review	I-6	Review	437
<sep> <sep> Section 3.3: ‚Ä®How well would these cyclic objectives work in a non-locomotion setting?	B-Review	B-7	Review	437
For example manipulation	I-Review	I-7	Review	437
<sep> Section 3.4:‚Ä®This formulation is really quite standard in many HRL methods such as options framework.	B-Review	B-8	Review	437
The details can be significantly cut down, and not presented as a novel contribution.	I-Review	I-8	Review	437
<sep> <sep> Experiments:	O	O	Review	437
It is quite cool that Figure 2 shows very significant movement, but in some sense this is already supervised to say ‚Äúmove the CoM a lot‚Äù.	B-Review	B-9	Review	437
This should be compared with explicitly optimizing for such an objective, as in Florensa et al I‚Äôm not sure that this would qualify as ‚Äúunsupervised‚Äù per se.	I-Review	I-9	Review	437
As in it too is using a particular set of pre-training tasks, just decided by the form of choosing internal and external state.	I-Review	I-9	Review	437
<sep> <sep> all of the baselines fail to get close to the goal locations.-> this is a bit surprising?	B-Review	B-10	Review	437
Why are all the methods performing this poorly even when rewarded for moving the agent as much as possible.	I-Review	I-10	Review	437
<sep> <sep> Overall, the results are pretty impressive.	O	O	Review	437
A video would be a great addition to the paper.	O	O	Review	437
<sep> <sep> Comparison to Eysenbach et al isn‚Äôt quite fair since that method receives less information.	B-Review	B-11	Review	437
If given the extra information, the HRL method performs much better (as indicated by the ant waypoint plot in that paper).	I-Review	I-11	Review	437
We thank the reviewer for their time.	O	O	Reply	437
We will try to answer your questions and concerns here.	O	O	Reply	437
<sep> <sep> Internal/External assumption	B-Reply	B-12	Reply	437
While we agree that the separation of inputs is not fully general, we think it is appropriate in many reasonable settings.	I-Reply	I-12	Reply	437
In particular, for any actuated robot, it is only reasonable that the robot be designed to know which are proprioceptive sensors.	I-Reply	I-12	Reply	437
More generally for agents whose action spaces are complex and have sensors to directly measure that action space, there is essentially no cost to provide this information to such agents.	I-Reply	I-12	Reply	437
It is also common for researchers in robotics get this information with localization techniques such as visual odometry, SLAM or particle filters.	I-Reply	I-12	Reply	437
<sep> One may argue that we measure success with HRL in these settings as a proxy task, and what we are really interested in is an HRL algorithm(s) that can learn anywhere; but in our view, clean, cheap, widely applicable assumptions are the best hope for real progress.	I-Reply	I-12	Reply	437
Moreover, even if one is searching for the primal-generic HRL algorithms, our work is useful: (i) because it shows that this simple assumption leads to good results on these tasks and (ii) because in the current literature, these tasks are the standard testbeds, this work allows a researcher to recognize a mechanism that a more general algorithm might be using to achieve success.	I-Reply	I-12	Reply	437
<sep> To answer your specific question about the ant: we use the center of mass position as external, and the body angles, as well as the joint configurations as internal.	I-Reply	I-12	Reply	437
Velocities we consider to be the same as the positions for categorizing as internal/external.	I-Reply	I-12	Reply	437
<sep> <sep> ‚Äúcomparison to Florensa et al‚Äù: the main differences between this work and that one are that we do not try to use stochastic neural networks, we do not try to compress the one-hot representation of the low level networks into a dense vector during low level training (instead, keeping them fully separate, what they call the ‚Äúmulti-policy‚Äù architecture), and we do not attempt to impose any regularization to encourage the low level networks to be diverse.	B-Reply	B-1	Reply	437
These can be considered simplifications;  what we show is that the simple thing works quite well.	I-Reply	I-1	Reply	437
<sep> However, one might argue that one of the main points of Florensa et al was to be able to save sample complexity via compressing the multiple policies at train time into a single network.	I-Reply	I-1	Reply	437
Our empirical results suggest that the situation is not so clear cut.	I-Reply	I-1	Reply	437
First, we are able to do well on the Ant task, whereas they have trouble making the high level policy work well there (see appendix d in that work).	I-Reply	I-1	Reply	437
We also do better on humanoid, which is yet more difficult.	I-Reply	I-1	Reply	437
Moreover, if we correctly understand their measurements of sample complexity, our method, even accounting for the multiple independent models, is using far fewer environmental interactions at both the high and low level.	I-Reply	I-1	Reply	437
Thus while training multiple independent models may seem wasteful on paper, it seems to work well in practice, and has superior sample complexity for the low-level policy.	I-Reply	I-1	Reply	437
<sep> <sep> We briefly discuss Florensa et al in our related work, but we can expand it to go into more detail in the comparison.	I-Reply	I-1	Reply	437

This paper presents an approach for hierarchical RL based on an ensemble of low-level controllers.	O	O	Review	437
<sep> From what I can tell, you train K randomly initialized models to maximize displacement (optionally with a periodic implementation).	O	O	Review	437
<sep> This ensemble of low-level models is then presented to a high-level controller, that can use them for actions.	O	O	Review	437
<sep> When you do this, the resultant algorithm performs well on a selection of deep RL tasks.	O	O	Review	437
<sep> <sep> There are several things to like about this paper:	O	O	Review	437
- Hierarchical RL is an important area of research, and this algorithm appears to make progress beyond the state of the art.	O	O	Review	437
<sep> <sep> - The ideas of using ensemble of low-level policies is intuitive and appealing.	O	O	Review	437
<sep> <sep> - The authors provide a reasonable explanation of their "periodicity" ideas, together with evidence that it can be beneficial, but is not always essential to the algorithm.	O	O	Review	437
<sep> <sep> - Overall the writing is good... but I did find the main statement of the algorithm confusing!	O	O	Review	437
I think this deserves a proper appendix with everything spelled out.	O	O	Review	437
<sep> <sep> <sep> There are several places this paper could be improved:	O	O	Review	437
- First, the statement of the *main* algorithm needs to be brought together so that people can follow it clearly.	B-Review	B-1	Review	437
I understand one of the main reasons this is complicated is because the authors have tried to make this "general" or to be used with DQN/PPO/A3C... but if you present a clear implementation for *one* of them (PPO?)	I-Review	I-1	Review	437
then I think this will be a huge improvement.	I-Review	I-1	Review	437
<sep> <sep> - Something *feels* a little hacky about this... why are there only two timescales?	B-Review	B-2	Review	437
Is this a general procedure that we should always expect to work? *	I-Review	I-2	Review	437
why* are we doing this... and what can its downsides be?	I-Review	I-2	Review	437
The ablation studies are good, but I think a little more thought/discussion on how this fits in with a bigger picture of RL/control would be good.	I-Review	I-2	Review	437
<sep> <sep> Overall, I hope that I understood the main idea correctly... and if so, I generally like it.	O	O	Review	437
<sep> I think it will be possible to make this much clearer even with some simple amendments.	O	O	Review	437
We thank the reviewer for their time.	O	O	Reply	437
We will try to answer your questions and concerns here.	O	O	Reply	437
<sep> <sep> Overall algorithm	B-Reply	B-1	Reply	437
We will put a high-level algorithm in the appendix to make this more clear.	I-Reply	I-1	Reply	437
To summarize:	I-Reply	I-1	Reply	437
<sep> 1.	I-Reply	I-1	Reply	437
Train K low-level policies on our low-level objective using PPO/A2C/DQN	I-Reply	I-1	Reply	437
2.	O	O	Reply	437
Train a high level policy on the task reward using PPO/A2C/DQN where the action space is choosing one of the K low-level policies to run for T timesteps.	B-Reply	B-1	Reply	437
<sep> <sep> We will also add an appendix where we can describe the algorithm in terms of pseudo-code for one of the algorithms.	B-Reply	B-1	Reply	437
<sep> <sep> Timescales	B-Reply	B-2	Reply	437
We have a timescale for the low-level policies and a time-scale for the high-level policy, which operates on a longer timescale since you don‚Äôt need to change skills as often.	I-Reply	I-2	Reply	437
<sep> <sep> Generality	B-Reply	B-2	Reply	437
Please see the discussion with reviewer 1 on when our external/internal assumption holds, and when the periodic assumption holds.	I-Reply	I-2	Reply	437
We believe the idea of abstracting away low-level details from the high-level controller so it can focus on the planning and high-level problems is quite general in nature.	I-Reply	I-2	Reply	437
As RL starts to tackle more complicated problems, and as it moves to real-world robotics, this abstraction is very useful for efficiently learning difficult high-level policies	I-Reply	I-2	Reply	437
<sep> Fits into RL/control:	B-Reply	B-2	Reply	437
Hierarchical RL is important but data-inefficient; our separation into internal and external, our use of a skills framework, and the way we specifically train the low-level policies improves performance on sparse reward tasks in Mujoco.	I-Reply	I-2	Reply	437
See related work where we discuss some prior work in hierarchical RL and how it compares to our method.	I-Reply	I-2	Reply	437

The motivation of the paper is to be able to train low precision networks to a high-accuracy.	O	O	Review	437
Quantization is a useful tool in model compression, and doing it well for very low-precision models (2-3 bit precision specifically), is challenging.	O	O	Review	437
<sep> <sep> The main contribution of the paper comes from:	O	O	Review	437
a) Step Size Gradient: They propose a gradient which is sensitive to the distance between the value and the transition point.	O	O	Review	437
This is different from other methods which have gradients dependent only on the clip point.	O	O	Review	437
<sep> b) Step Size Gradient Scale: This is an interesting contribution, where they try to match the ratio of average update of the step size ‚Äòs‚Äô and average magnitude of ‚Äòs‚Äô, with that of the network weights.	O	O	Review	437
This leads them to scale the gradient according to the precision and number of parameters.	O	O	Review	437
They demonstrate that this scaling actually helps improve the accuracy.	O	O	Review	437
<sep> <sep> The results for 8-bit precision are not new.	O	O	Review	437
Several results (Quantization and Training of Neural Networks for Efficient	O	O	Review	437
Integer-Arithmetic-Only Inference, Jacob et al Quantizing deep convolutional networks for	O	O	Review	437
efficient inference: A whitepaper, Krishnamoorthi et al), show 8-bit quantization results where the accuracy matches floating point accuracy, and in some case exceeds it (low precision quantization acting as a regularizer).	O	O	Review	437
However, the results for lower precision are impressive.	O	O	Review	437
<sep> <sep> There are a few questions:	O	O	Review	437
1.	B-Review	B-1	Review	437
In sec 2.1, you mention that ‚Äòeach layer of weights and activations has a distinct step size, represented as an fp32 value, initialized to ‚Ä¶‚Äô.	I-Review	I-1	Review	437
Can you explain the intuition behind the initial value of the step size, and how is it a function of v?	I-Review	I-1	Review	437
<sep> 2. ‚	O	O	Review	437
ÄòModel Compression via Distillation and Quantization‚Äô (Polino et al) shows distillation actually helps significantly improve accuracy.	B-Review	B-2	Review	437
I wonder if the authors have tried different weight combinations for the distillation loss, and using bigger models as teacher models.	I-Review	I-2	Review	437
<sep> 3.	O	O	Review	437
I would like to get more details of the inference setup, specifically the size and inference latency improvements over full-precision networks.	B-Review	B-3	Review	437
The practical applicability of low-precision networks, specifically 2-bit and 3-bit networks, equally depends on the inference infrastructure, as it does on the training improvements.	I-Review	I-3	Review	437
<sep> 4.	B-Review	B-4	Review	437
Have you evaluated your method for a non-Vision usecase?	I-Review	I-4	Review	437
<sep> <sep> Overall this is a good work, I would tend towards accepting this.	O	O	Review	437
<sep> <sep> Question 1:	O	O	Reply	437
We expect that a step size that provides a reasonable quantization of some data, "v", should scale with the magnitude of that data (captured by "&lt;|v|&gt;"), so that the values are reasonably spread across the bins of the quantizer.	B-Reply	B-1	Reply	437
We also expect that as the number of quantized states increases, the step size itself should decrease, so that the data can be quantized more finely (captured by "1/sqrt(Q)").	I-Reply	I-1	Reply	437
The particular heuristic we chose worked well in practice to give a reasonably good initial quantization that could then be further improved through training.	I-Reply	I-1	Reply	437
<sep> <sep> <sep> Question 2:	O	O	Reply	437
Knowledge distillation for quantized networks is certainly an interesting area for research, but we didn't want to expand the focus of our manuscript too far beyond the quantizer training method proposed, particularly as Polino et al and Mishra and Marr already have provided a good overview of knowledge distillation in this domain.	B-Reply	B-2	Reply	437
Thus, we chose to show only the simplest knowledge distillation setup we are are aware of, distilling from a full precision teacher to a low precision student network with the same architecture.	I-Reply	I-2	Reply	437
This approach offers has the benefit that the same trained high precision network used for weight initialization also serves as our teacher, and thus no additional networks are required, whereas distilling from a larger architecture would require training (or otherwise having access to) an additional network.	I-Reply	I-2	Reply	437
However, we have since run an experiment to look at different weights on the distillation loss, and now note in section 3.7: "we used the distillation loss function of Hinton with temperature of 1 and equal weight given to the standard loss and the distillation loss (we found this gave comparable results to weighting the the distillation loss two times more or less than the standard loss on 2-bit ResNet-18)."	I-Reply	I-2	Reply	437
<sep> <sep> <sep> Question 3:	O	O	Reply	437
To show the reduction in model size offered by lower precision models, we have modified Figure 3 to include full precision model sizes.	B-Reply	B-3	Reply	437
<sep> <sep> We did not measure latency or related performance metrics on actual hardware, as our approach was developed in advance of commercially available inference hardware optimized for low precision operations.	I-Reply	I-3	Reply	437
Since algorithms are much cheaper to develop than new hardware, we believe it is the correct first step to demonstrate the ability of deep networks to achieve high accuracy at these extremely low precisions before hardware is created to optimize for these precisions.	I-Reply	I-3	Reply	437
As new low precision inference chips become available, we look forward to benchmarking these low precision networks against full precision alternatives.	I-Reply	I-3	Reply	437
<sep> <sep> Question 4:	O	O	Reply	437
While we have not done so yet due to time constraints, we anticipate evaluating this approach for domains beyond vision as a next step in our research.	B-Reply	B-4	Reply	437

<sep> This paper trains low-precision network with quantized weights and quantized activation.	O	O	Review	437
The main idea is to split the scale and quantized values.	O	O	Review	437
Both scales and weights are updated with backprop and SGD.	O	O	Review	437
The paper presents excellent experimental results on ImageNet.	O	O	Review	437
<sep> <sep> The paper is generally well written and easy to follow.	O	O	Review	437
However, there does exist quite some grammar errors, especially in abstract, which could be improved.	B-Review	B-1	Review	437
<sep> <sep> Moreover, I would like the authors to clarify some technical details.	B-Review	B-2	Review	437
Are the scales s, so called step size in the paper, for every weight, every convolutional kernel, or very layer?	I-Review	I-2	Review	437
How do you deal with BatchNorm?	I-Review	I-2	Review	437
<sep> <sep> What is the main benefits of the proposed quantization method in general?	B-Review	B-3	Review	437
Is it for fast inference, fast training, or just memory compression?	I-Review	I-3	Review	437
Do the authors see the real benefits in practice besides claiming the accuracy does not drop?	I-Review	I-3	Review	437
<sep> <sep> I would suggest the authors discuss and compare with XNOR network in detail.	B-Review	B-4	Review	437
The proposed method looks similar.	I-Review	I-4	Review	437
<sep> <sep> I am wondering how the baseline methods are tuned.	B-Review	B-5	Review	437
There are quite a few ‚Äútricks‚Äù like learning rate scheduler and weight decay, which I do consider them as contributions of the paper.	I-Review	I-5	Review	437
But would baseline methods also benefit from more hyper-parameter tuning?	I-Review	I-5	Review	437
<sep> <sep> Minor issue, I donot get the explanation of eq (4), and it looks rather unnecessary.	B-Review	B-6	Review	437
It sounds to me starting from a trained network and then train 90 epochs is a rather long time.	I-Review	I-6	Review	437
Could the authors convince me this is a standard setting by providing some reference?	I-Review	I-6	Review	437
<sep> <sep> <sep> ================ after rebuttal=========================	O	O	Review	437
Thank the authors for reply.	O	O	Review	437
My rating does not change.	O	O	Review	437
The proposed does look similar to XNOR, and the only difference seems to be how the scales are updated.	B-Review	B-4	Review	437
Since there is only one scale per layer, I will be quite surprised if the proposed method can be much better than XNOR.	I-Review	I-4	Review	437
Moreover, since BatchNorm is not quantized and it is everywhere in a ResNet-like architecture, it surprises me how much the scale helps.	I-Review	I-4	Review	437
Finally, I am worried about practical benefits towards the authors' claim because the networks are not fully quantized.	I-Review	I-4	Review	437
<sep> <sep> We have carefully read through the manuscript to look for and fix grammatical issues.	B-Reply	B-1	Reply	437
If the reviewer points out any specific issues that remain, we will be happy to fix them to improve the manuscript.	I-Reply	I-1	Reply	437
<sep> <sep> There is one step size for each layer of weights (that is, for each weight tensor) and one step size for each layer of activations.	B-Reply	B-2	Reply	437
This is noted in section 2.1 with the line "each layer of weights and each layer of activations has a distinct step size".	I-Reply	I-2	Reply	437
BatchNorm is handled using full precision operations.	I-Reply	I-2	Reply	437
We have updated the text in section 2.3 to clarify this point.	I-Reply	I-2	Reply	437
<sep> <sep> The proposed method offers 2 main benefits.	B-Reply	B-3	Reply	437
First, it allows for a reduction in model size, facilitating the deployment deep networks operating on the edge (for example, in mobile phones).	I-Reply	I-3	Reply	437
Second, it points to the value of developing next generation inference hardware optimized for low precision operations to improve throughput and energy efficiency, while reducing latency.	I-Reply	I-3	Reply	437
As we also note in our response to Review #2, we believe it is the correct first step to demonstrate the ability of deep networks to achieve high accuracy at these extremely low precisions before inference chips optimized for these precisions is commercially available.	I-Reply	I-3	Reply	437
As such hardware becomes available, we look forward to benchmarking these low precision networks against full precision alternatives.	I-Reply	I-3	Reply	437
<sep> We now highlight the importance of XNOR in the introduction by noting it provided the first demonstration of tuned quantization.	B-Reply	B-4	Reply	437
XNOR differs from our approach in that the former employs a quantizer tuned based on data statistics, in approach later taken by techniques such as TWN, Dorefa, FAQ, and Half-wave gaussian quantization, while the latter learns the quantization through backpropagation, which is noted in the introduction.	I-Reply	I-4	Reply	437
<sep> <sep> Providing a comparison between various quantization methods using exactly the same weight decay or learning rate schedule is difficult, as there is no standardization across prior papers on settings.	B-Reply	B-5	Reply	437
Properly re-implementing and re-running methods from prior papers can be challenging if even trivial details (for example, initial values) are missing from the original publications, and even if done properly, it is possible that different weight decay values or schedulers are optimal for different methods.	I-Reply	I-5	Reply	437
However, we have sought to address this as best we can by showing our results at different weight decay values and showing the simple power of 2 search that was employed to find the weight decays chosen (Table 2).	I-Reply	I-5	Reply	437
Notably, our approach still out performs the next best method even when using a weight decay of 10^-4, which is fairly standard for a full precision ResNet-18.	I-Reply	I-5	Reply	437
We also ran an experiment using a more traditional step-based weight decay (Section 3.5), and found that again our approach still out performs that next best method (with only 90 epochs of fine-tuning, compared to a total of 360 epochs of fine-tuning for the next best method).	I-Reply	I-5	Reply	437
<sep> <sep> If of interest, Table 3 explores the value of the gradient adjustment derived from Equation 4, and shows that it is important for achieving high accuracy.	B-Reply	B-6	Reply	437
<sep> <sep> Relatively long fine-tuning in the quantized space after initializing from a full precision trained network is fairly common when targeting networks with less than 8-bits of precision, and in fact the 90 epochs we employ is on the short side.	I-Reply	I-6	Reply	437
For example  Choi et al ("Learning low precision deep neural networks through regularization") fine-tuned for 100 epochs, McKinstry et al ("Discovering low-precision networks close to full- precision networks for efficient embedded inference") fine-tuned for 110 epochs, Baskin et al ("Nice: Noise injection and clamping estimation for neural network quantization") fine-tuned for 120 epochs, and Jung et al ("Joint training of low-precision neural network with quantization interval parameters") used a progressive quantization approach that amounted to a total of 360 additional epochs of fine-tuning for 2-bit models.	I-Reply	I-6	Reply	437

The paper is concerned with neural networks using low-precision operations.	O	O	Review	437
This is an important research are both for applications (e.g., deploying neural networks on embedded systems or other constrained hardware, or increasing throughput on a production system) and for theoretical reasons (e.g., potentially modelling the behavior of biological neural networks).	O	O	Review	437
<sep> <sep> The paper makes two primary contributions: (1) It proposes a new approximation for the gradient of the quantized data with respect to the step size parameter (equation 3) based on the well-known straight through estimator. (	O	O	Review	437
2) It proposes a heuristic for scaling gradient updates based on the number of weights in a given layer and the quantization levels (clipping thresholds).	O	O	Review	437
Experimental results showing higher accuracy than previously reported approaches in a number of settings and for common metrics, and best-to-date results for other settings.	O	O	Review	437
<sep> <sep> I recommend the paper for publication.	O	O	Review	437
<sep> <sep> In terms of improving the paper further, the authors could expand their experiment section.	B-Review	B-3	Review	437
E.g., how does their method compare to current SOTA knowledge-distillation methods; how does it deal with other architectures (recurrent models, attention, etc).	I-Review	I-3	Review	437
<sep> <sep> Minor notes on the manuscript:	O	O	Review	437
<sep> In section 3.4, both the term ‚Äúpopulation size‚Äù as well as the symbol N_W come without any definition.	B-Review	B-1	Review	437
While closer reading makes it clear what is meant is the number of weights per layer, a definition closer to their first usage would be good.	I-Review	I-1	Review	437
This goes in particular for N_W which comes in several versions (N_W, N, nweights).	I-Review	I-1	Review	437
<sep> <sep> In section 3.7, the sentence starting with ‚ÄúWe found that using this approach to distill‚Äù does not seem to fit within its context for this reader, as it describes ‚Äúfull-to-full‚Äù distillation.	B-Review	B-2	Review	437
Perhaps it is meant to read ‚Äúlow precision student network‚Äù?	I-Review	I-2	Review	437
We are very excited to apply this technique to more architectures and application domains.	O	O	Reply	437
Due to time constraints, we are unable to provide results for the current manuscript, but plan to tackle this area in future work.	O	O	Reply	437
<sep> <sep> We wanted to keep our knowledge distillation approach simple to keep the primary focus of the paper on the quantizer step size training technique.	B-Reply	B-3	Reply	437
Thus, we have focused on same-architecture distillation (which has the advantage that it does not require training an additional network beyond what would be done for standard fine-tuning from a pre-trained initialization).	I-Reply	I-3	Reply	437
The only work we are aware of that takes a similar approach is Mishra and Marr, "Apprentice: Using knowledge distillation techniques to improve low-precision network accuracy" (who provided our inspiration to try this knowledge distillation variation), who report results on different precision levels than we report on here, making a direct comparison difficult (though notably, we show higher accuracy at lower precision when comparing with the closest comparable precision levels from Mishra and Marr).	I-Reply	I-3	Reply	437
<sep> <sep> N_W and N_F are now defined where they first appear in section 2.2, reference to N has been replaced with reference to N_W and N_F (and we verified that "nweights", which refers to a function and is therefore subtly different from N_W, is defined where first used).	B-Reply	B-1	Reply	437
<sep> <sep> We have clarified our use of full precision to full precision distillation, which is intended as a simple control experiment:	B-Reply	B-2	Reply	437
"As a control, we also used this approach to distill from the full precision teacher to a full precision (initially untrained) student with the same architecture, which did not lead to an improvement in the student network accuracy beyond training the student alone."	I-Reply	I-2	Reply	437

The authors address the neural networks compression problem and propose to amend the previously known approximations based on different tensor decompositions (CP, Tucker, or tensor train) with a reshaping step, where a tensor is preliminary reshaped to a higher order tensor.	B-Review	B-1	Review	1590
However, I do not see why would such modification be beneficial compared to the previously known approximations; this is also not clarified by the experiments.	B-Review	B-2	Review	1590
<sep> <sep> The paper contains detailed overview of the related literature.	O	O	Review	1590
However, I think it would be more interesting to see a detailed elaboration of the proposed idea.	B-Review	B-1	Review	1590
Most importantly, the description of the proposed approach -- reshaped tensor decomposition -- looks rather superficial.	I-Review	I-1	Review	1590
In particular, I can not see where the improvement (compared with similar approximations without the reshaping) in memory and/or runtime would come from.	I-Review	I-1	Review	1590
Let me clarify with an example.	I-Review	I-1	Review	1590
Given a matrix A of size N x M and assume that this matrix is actually rank-1, i.e. there exist vectors a and b such that A = a‚Äôb.	I-Review	I-1	Review	1590
Let's reshape this matrix into, say, an order-4 tensor T with dimensions n x m x k x p. Assume that this tensor T is also rank-1 and there exist vectors x1, x2, x3, x4 such that T is equal to their outer product.	I-Review	I-1	Review	1590
Since N+M = n+m+k+p, why would vectors x1, x2, x3, x4 need less memory than vectors a and b?	I-Review	I-1	Review	1590
Moreover, would such reshaping transformation preserve the structure of the original tensor, e.g., its low-rank representation?	I-Review	I-1	Review	1590
That is, if A is a rank-1 matrix, is the tensor T guaranteed to still be rank-1?	I-Review	I-1	Review	1590
Isn't it more difficult to factorize a tensor of higher order?	I-Review	I-1	Review	1590
<sep> <sep> I am also confused by the author's choice of the baseline for their experiments.	B-Review	B-2	Review	1590
First of all, wouldn't it be more informative to compare with the other known compression methods based on tensor decompositions (Lebedev, et al, 2015; Jaderberg, et al, 2014; Kim, et al, 2016)?	I-Review	I-2	Review	1590
Although indeed these approaches can be seen as particular cases of the proposed reshaped decomposition, such comparison would demonstrate whether this newer approach (RTD) is better than already existing methods.	I-Review	I-2	Review	1590
In particular, Kim et al experimentally demonstrate that their approximation, based on Tucker decomposition, leads to nearly lossless compression (they perform their experiments with publicly available pre-trained networks which shouldn't be difficult to compare to).	I-Review	I-2	Review	1590
Why the experimental results presented in this paper are so different?	I-Review	I-2	Review	1590
Does the loss of accuracy result from the compression with the Tucker decomposition or is it due to the reshaping step or are there other reasons?	I-Review	I-2	Review	1590
I am also not sure what does plain tensor decomposition stand for and why is it considered to be state-of-the-art (references?)?	I-Review	I-2	Review	1590
<sep> <sep> Minor comments:	B-Review	B-3	Review	1590
figure 2: b is a particular case of a	I-Review	I-3	Review	1590
figure 2: d - shouldn‚Äôt the outer product of two 3-dimensional tensors result in a 6-dimensional tensor?	I-Review	I-3	Review	1590
<sep> might want to use \citep to add brackets around citations	I-Review	I-3	Review	1590
typo: element-wisely -> element-wise	I-Review	I-3	Review	1590
== Response to the question why reshaping/tensorization is beneficial:	O	O	Reply	1590
<sep> Reshaping (a.k.a.	B-Reply	B-1	Reply	1590
tensorization) allows for representing an array with fewer parameters.	I-Reply	I-1	Reply	1590
<sep> A detailed example is elaborated in the paragraph of ‚ÄúMotivation of Tensorization‚Äù at Pa	I-Reply	I-1	Reply	1590

This paper proposed to use the duality gap sup_f V(f, g*) ‚Äì inf_g V(f*, g) as a metric for GAN training.	O	O	Review	20630
It proves that this metric is an upper bound of F-distance.	O	O	Review	20630
It also proves a generalization bound for this metric.	O	O	Review	20630
Simulation resultson MNIST, CIFAR10, etc.	O	O	Review	20630
are reported.	O	O	Review	20630
<sep> <sep> The contribution of this paper is incremental due to the following reasons.	O	O	Review	20630
<sep> <sep> 1) The duality gap is only an upper bound of the F-distance.	B-Review	B-1	Review	20630
This means that if the duality gap is zero then the learned distribution is the true distribution.	I-Review	I-1	Review	20630
However, the converse is not necessarily true: even if the algorithm starts with the true distribution, the duality gap may not be zero.	I-Review	I-1	Review	20630
Thus the metric is not a proper metric.	I-Review	I-1	Review	20630
<sep> The proof of the upper bound is straightforward.	I-Review	I-1	Review	20630
<sep> <sep> 2) Another issue is the gap between the min-max formulation and the real training algorithm.	B-Review	B-2	Review	20630
As for GAN, due to the inexact update, it is not really solving the min-max problem.	I-Review	I-2	Review	20630
For the proposed metric, it is also impossible to solve sup_f V(f, g*) and inf_g V(f*, g) to reasonable accuracy.	I-Review	I-2	Review	20630
Thus what the algorithm is really doing, perhaps, is to optimizing a new loss which is the sum of the original loss and and an extra term.	I-Review	I-2	Review	20630
Viewing it as a ‚Äúduality gap‚Äù seems to be far from the practical training.	I-Review	I-2	Review	20630
This discrepancy exists for GANs, but it is a bigger issue for the duality gap interpretation.	I-Review	I-2	Review	20630
<sep> <sep> 3) The simulation is not convincing.	B-Review	B-3	Review	20630
The reported FID for CIFAR10 using WGAN-GP is 54.4, which seems to be a bit high.	I-Review	I-3	Review	20630
I‚Äôm not sure whether it is due to parameter choice or due to weak D/G networks used in the simulation.	I-Review	I-3	Review	20630
If the paper cannot compare various architecture, it is more convincing to at least use some standard architecture, like DCGAN.	I-Review	I-3	Review	20630
Or at least report the parameter tuning effort made for getting the results.	I-Review	I-3	Review	20630
Thanks for your attention to our work.	O	O	Reply	20630
<sep> 1) For the first problem that the duality gap is only an upper bound of F-distance.	B-Reply	B-1	Reply	20630
Our logic is that: a) There exists a condition s.t.	I-Reply	I-1	Reply	20630
duality gap = 0.	I-Reply	I-1	Reply	20630
b) If duality gap = 0, then the generator is the best one that can generate the true distribution.	I-Reply	I-1	Reply	20630
May be in the algorithm, we will miss the best generator because we do not get the equilibrium.	I-Reply	I-1	Reply	20630
<sep> <sep> 2) Our method may encounter the same problem as the traditional algorithm.	B-Reply	B-2	Reply	20630
It is a kind of Markov chain to train the Loss.	I-Reply	I-2	Reply	20630
And the essence of the algorithm is in fact to solve and.	I-Reply	I-2	Reply	20630
We should consider some better algorithm to solve it.	I-Reply	I-2	Reply	20630
<sep> <sep> 3) For the experiments, we will do some modification and improve our network.	B-Reply	B-3	Reply	20630

This paper has problems with clarity/polish and experimental design that are sufficiently severe	O	O	Review	20630
to merit rejection by themselves.	O	O	Review	20630
<sep> <sep> Regarding clarity/polish:	O	O	Review	20630
I am generally not super picky about these things, but there does have to be some standard.	O	O	Review	20630
<sep> This paper looks very hastily put together, especially pages 7 and 8.	O	O	Review	20630
<sep> There are many typos and unclear statements.	B-Review	B-1	Review	20630
<sep> Just a few examples:	O	O	Review	20630
<sep> &gt; Generative Adversarial Networks (GANs) are powerful framework for (in the abstract)	B-Review	B-1	Review	20630
&gt; be a good metric to evolution the difference (in the abstract)	I-Review	I-1	Review	20630
&gt; In the past few years, Generative Adversarial Networks (GANs) (Goodfellow et al 2014) are impactful because it has shown lots of great results for many AI tasks, (first sentence)	I-Review	I-1	Review	20630
<sep> &gt; It means that there is no an unanimous metric to represent the difference between the true data distribution and the generated distribution	I-Review	I-1	Review	20630
What does this mean?	I-Review	I-1	Review	20630
People have mostly settled on using FID for this.	I-Review	I-1	Review	20630
<sep> &gt; It is also difficult to know whether the generated distribution is close to the true distribution, and this is often observed by human eyes.	I-Review	I-1	Review	20630
<sep> Isn't this just restating the point made in the first sentence?	I-Review	I-1	Review	20630
<sep> Regardless, nobody really uses human evaluation anymore - so this is just not correct.	I-Review	I-1	Review	20630
<sep> <sep> &gt;  It means that if the original generator and discriminator are random, it is difficult to confirm that the generator and discriminator can converge to the ideal conclusion by training with given data.	I-Review	I-1	Review	20630
<sep> But this paper doesn't propose a way to solve that problem, so it's strange to mention this here in this way.	I-Review	I-1	Review	20630
<sep> <sep> <sep> These issues would maybe be excusable if not for the totally inadequate experimental validation.	O	O	Review	20630
<sep> A non-exhaustive list of methodological problems with the (single) experiment:	O	O	Review	20630
<sep> 1.	O	O	Review	20630
The experiment uses a single run each of the baseline and DG-GAN, when it's well-known that GAN training runs	B-Review	B-2	Review	20630
have inter-run variance larger than the difference in score reported in Fig 1 and 2.	I-Review	I-2	Review	20630
<sep> <sep> 2.	O	O	Review	20630
The models have not been trained for long enough.	B-Review	B-2	Review	20630
<sep> <sep> 3.	O	O	Review	20630
The architecture of the neural networks used for the Generator and Discriminator is very non-standard, which	B-Review	B-2	Review	20630
probably leads to:	I-Review	I-2	Review	20630
<sep> 4.	B-Review	B-2	Review	20630
The scores achieved by the baseline are very far from state of the art, making the comparison mostly useless,	I-Review	I-2	Review	20630
and rendering the third claim from the introduction ("We propose an new algorithm with the new metric which demonstrates better results than state-of-the-art algorithms.")	I-Review	I-2	Review	20630
completely untrue.	I-Review	I-2	Review	20630
<sep> <sep> In light of these other issues, I haven't checked the proofs.	O	O	Review	20630
<sep> <sep> Thanks for your attention to our work.	O	O	Reply	20630
<sep> 1) For the presentation, we apologize for our typos and unclear statement in the paper.	B-Reply	B-1	Reply	20630
And your advice is so helpful.	I-Reply	I-1	Reply	20630
We will modify it.	I-Reply	I-1	Reply	20630
<sep> <sep> 2) For the experiment, we will train our experiments longer and modify our network.	B-Reply	B-2	Reply	20630
Thanks for your advice.	I-Reply	I-2	Reply	20630

The paper aims to provide theoretical justification for a "spectral bias" that is observed in training of neural networks: a phenomenon recorded in literature (Rahaman et al), where lower frequency components of a signal are fit faster than higher frequency ones.	O	O	Review	20165
The contributions of the paper are as follows:	O	O	Review	20165
1.	O	O	Review	20165
Proves an upper bound on the rate of convergence on the residual error projected on top few eigenfunctions (of a certain integral operator).	O	O	Review	20165
The upper bound is in terms of the eigenvalues of the corresponding eigenfunctions and is distribution independent.	O	O	Review	20165
<sep> 2.	O	O	Review	20165
Provides an upper bound on the decay of eigenvalues in the case of depth-2 ReLU networks and also a exact characterization of the eigenfunctions.	O	O	Review	20165
While such upper bounds and the characterization of eigenfunctions existed in literature earlier, it is argued that the new bounds are better.	O	O	Review	20165
<sep> 3.	O	O	Review	20165
Combining the above two results, a justification is obtained for the "spectral bias" phenomenon that is recorded in literature.	O	O	Review	20165
<sep> 4.	O	O	Review	20165
Some toy experiments are provided to exhibit the spectral bias phenomenon.	O	O	Review	20165
<sep> <sep> Recommendation:	O	O	Review	20165
I recommend "weak acceptance".	O	O	Review	20165
The paper takes a step towards explaining the phenomenon of spectral bias in deep learning.	O	O	Review	20165
While concrete progress is made in the context of depth-2 ReLU networks (even though in NTK regime), perhaps the ideas could be extended to deeper networks.	B-Review	B-6	Review	20165
<sep> <sep> Technical comments:	O	O	Review	20165
- It is argued that the new bound of is better than the bound of from the previous work of Bietti and Mairal, in the regime where.	B-Review	B-1	Review	20165
I think there is a typo here.	I-Review	I-1	Review	20165
In the regime of, the bound is the smaller one so both bounds are comparable.	I-Review	I-1	Review	20165
It is argued that is the more relevant regime, but then there isn't any improvement here.	I-Review	I-1	Review	20165
<sep> - The proof of spectral analysis is said to follow a similar outline as compared to the prior work of Bietti-Mairal, but it is not clear to me where this new proof deviates and improves on prior techniques?	B-Review	B-2	Review	20165
Or is it just a more careful analysis of the prior techniques?	I-Review	I-2	Review	20165
<sep> - The proof operates in the "Neural Tangent Kernel" regime, by considering hugely overparameterized networks.	B-Review	B-3	Review	20165
This can be viewed as a negative thing, but then, most results in literature also operate in this regime and it is a major challenge for the field to prove results in the mildly overparameterized / non-NTK regime!	I-Review	I-3	Review	20165
<sep> <sep> Potential suggestions for improvement:	O	O	Review	20165
- In Section 4: the y-axis of the graph is labeled "error's coefficient" which is non-informative.	B-Review	B-4	Review	20165
Is it ?	I-Review	I-4	Review	20165
I also had a question here about the proposed Nystrom method: Why is it okay to use the training points in the Nystrom method.	I-Review	I-4	Review	20165
Ideally, we should use freshly sampled points.	I-Review	I-4	Review	20165
Is there a justification for using the training points?	I-Review	I-4	Review	20165
If not, perhaps it is best to go with freshly sampled points.	I-Review	I-4	Review	20165
<sep> - I felt the proofs in the Appendix are very opaque and it is hard to pinpoint what the new insight is (at least for a reader, like me, who does not have an in-depth familiarity with these convergence proofs).	B-Review	B-5	Review	20165
<sep> <sep> Thank you very much for your helpful and positive comments.	O	O	Reply	20165
We address your questions as follows.	O	O	Reply	20165
<sep> <sep> Q1. ‚	O	O	Reply	20165
ÄúIt is argued that the new bound of... there isn't any improvement here.	O	O	Reply	20165
‚Äù	O	O	Reply	20165
A1.	O	O	Reply	20165
Thank you very much for pointing out this issue.	B-Reply	B-1	Reply	20165
We believe that this is a misunderstanding caused by a typo and a misuse of the big-O notation, which we have fixed in the revision.	I-Reply	I-1	Reply	20165
should be instead of the minimum of the two terms.	I-Reply	I-1	Reply	20165
Since the convergence speed is characterized as, the larger is, the faster gradient descent converges.	I-Reply	I-1	Reply	20165
We can see that our result is better then previous results when, since we provide a larger lower bound for.	I-Reply	I-1	Reply	20165
<sep> <sep> <sep> Q2. ‚	O	O	Reply	20165
ÄúThe proof of spectral analysis is said to follow a similar outline... prior techniques?‚Äù	O	O	Reply	20165
A2.	O	O	Reply	20165
Our proof uses the same technique as the proof of Bietti and Mairal (2019) for the setting.	B-Reply	B-2	Reply	20165
The major difference between our result and Bietti and Mairal (2019)‚Äôs is that we also consider the case, which is a more practical setting.	I-Reply	I-2	Reply	20165
This leads to an improved characterization for the eigenvalue.	I-Reply	I-2	Reply	20165
We have emphasized the difference in Remark 3.6.	I-Reply	I-2	Reply	20165
<sep> <sep> <sep> Q3. ‚	O	O	Reply	20165
ÄúThe proof operates in... the mildly overparameterized / non-NTK regime!‚Äù	O	O	Reply	20165
A3.	O	O	Reply	20165
By far, we only focus on the NTK regime and extend previous results by presenting a more precise characterization of convergence result.	B-Reply	B-3	Reply	20165
However we would also like to emphasize that in Theorem 3.2, the over-parameterization requirement is only related to, the-th distinct eigenvalue of NTK.	I-Reply	I-3	Reply	20165
Therefore our theory indeed works for networks with milder over-parameterization, compared with many prior results (for example, Du et al (2018b)).	I-Reply	I-3	Reply	20165
We have emphasized this in Remark 3.3.	I-Reply	I-3	Reply	20165
Analysis in non-NTK regime is beyond the scope of this paper, and can be an interesting future work direction.	I-Reply	I-3	Reply	20165
<sep> <sep> <sep> Q4. ‚	O	O	Reply	20165
ÄúIn Section 4: the y-axis of the graph... freshly sampled points.	O	O	Reply	20165
‚Äù	O	O	Reply	20165
A4.	O	O	Reply	20165
Thanks for the suggestion.	B-Reply	B-4	Reply	20165
We have changed the ‚Äòerror‚Äôs coefficient‚Äô into ‚Äòprojection length‚Äô and given a clearer definition.	I-Reply	I-4	Reply	20165
Ideally the error coefficient is the Gegenbauer coefficient of the residual function:, which can be seen as the projection length onto the Gegenbauer polynomial.	I-Reply	I-4	Reply	20165
<sep> <sep> The experiments are designed to demonstrate the result of our main theorem, which states that the residual of training data, projected to certain eigenfunctions, will decrease at a certain linear rate depending on the eigenvalues.	I-Reply	I-4	Reply	20165
So what we want to show by the experiments is merely about how the residual of training data behaves.	I-Reply	I-4	Reply	20165
That is actually the projection length onto the vectors defined by Gegenbauer polynomials.	I-Reply	I-4	Reply	20165
We admit that the original y-axis label and the word ‚ÄòNystrom‚Äô is not very appropriate.	I-Reply	I-4	Reply	20165
We have presented a more informative definition in our revised version.	I-Reply	I-4	Reply	20165
<sep> <sep> In the case where freshly sampled points are used, what we can get following the same procedure is the residual function‚Äôs Gegenbauer coefficient, which can be seen as the projection length in function space.	I-Reply	I-4	Reply	20165
We also present these results in Appendix E.1	I-Reply	I-4	Reply	20165
<sep> <sep> Q5. ‚	O	O	Reply	20165
ÄúI felt the proofs in the Appendix are very opaque... these convergence proofs).‚Äù	O	O	Reply	20165
A5.	O	O	Reply	20165
We apologize for the unclear proofs.	B-Reply	B-5	Reply	20165
To improve readability, we have added more comments before each lemma in Section B.1 about the intuition and the role of these lemmas in the main proof.	I-Reply	I-5	Reply	20165
<sep> <sep> <sep> The response above has been reflected in our revised paper.	O	O	Reply	20165
Please let us know if you have any further suggestions.	O	O	Reply	20165

This paper studies the training of overparametrized neural networks by gradient descent.	O	O	Review	20165
More precisely, the authors consider the neural tangent regime (NTK regime).	O	O	Review	20165
That is, the weights are chosen sufficiently large and the neural network is sufficiently overparametrized.	O	O	Review	20165
It has been observed that in this scenario, the neural network behaves approximately like a linear function of its weights.	O	O	Review	20165
<sep> <sep> In this regime, the authors show that, the directions corresponding to larger eigenvalues of the neural tangent kernel are learned first.	O	O	Review	20165
As this corresponds to learning lower-degree polynomials first, the authors claim that this explains the "spectral bias" observed in previous papers.	O	O	Review	20165
<sep> <sep> -I think that from a mathematical point of view, the main result of this paper is what one would expect intuitively:	B-Review	B-1	Review	20165
When performing gradient descent with quadratic loss where the function to be learnt is linear, it is common knowledge that convergence is faster on directions corresponding to larger singular values.	I-Review	I-1	Review	20165
Since in the NTK regime, the neural network can be approximated by a linear function around the initialization one expects the behavior predicted by the main results.	I-Review	I-1	Review	20165
From a theoretical perspective, I see the main contribution of the paper as making this statement precise.	I-Review	I-1	Review	20165
<sep> <sep> -I am skeptical about some of the implications for practitioners, which are given by the authors:	B-Review	B-2	Review	20165
For example, on p.5 the authors write "Therefore, Theorem 3.2 theoretically explains the empirical observations given in Rahaman et al (2018), and demonstrates that the difficulty of a function to be learned by neural network should be studied in the eigenspace of neural tangent kernel."	I-Review	I-2	Review	20165
To the best of my knowledge, it is unclear whether practitioners train neural networks in the NTK regime (see, e.g., [1]).	I-Review	I-2	Review	20165
Moreover, I am wondering whether some of the assumptions of their theorem are really met in practice.	B-Review	B-3	Review	20165
For example, the required sample size for higher order polynomials grows exponentially fast with the order and the required step size goes to zero exponentially fast.	I-Review	I-3	Review	20165
Does this really correspond to what is observed in practice? (	B-Review	B-4	Review	20165
Or is this a mere artifact of training in the NTK regime?)	I-Review	I-4	Review	20165
Is this what one observes in the experiments by Ramahan?	I-Review	I-4	Review	20165
<sep> <sep> I think the paper is not yet ready for being published.	B-Review	B-5	Review	20165
<sep> 1.	I-Review	I-5	Review	20165
There are many typos.	I-Review	I-5	Review	20165
Here is an (very incomplete) list.	I-Review	I-5	Review	20165
<sep> -p.	I-Review	I-5	Review	20165
2: "Su and Yang (2019)" improves the convergence..."	I-Review	I-5	Review	20165
-p.	I-Review	I-5	Review	20165
2: "This theorem gives finer-grained control on error term's"	I-Review	I-5	Review	20165
-p.	I-Review	I-5	Review	20165
2: "We present a more general results"	I-Review	I-5	Review	20165
-p.	I-Review	I-5	Review	20165
4: "The variance follows the principal..."	I-Review	I-5	Review	20165
-p.	I-Review	I-5	Review	20165
4: "...we will present Mercer decomposition in (the) next section."	I-Review	I-5	Review	20165
<sep> 2.	I-Review	I-5	Review	20165
I think that the presentation can be polished and many statements are somewhat unclear.	I-Review	I-5	Review	20165
For example, on p. 7 the authors write "the convergence rates [...] are exactly predicted by our theory in a qualitative sense."	I-Review	I-5	Review	20165
<sep> The meaning of this sentence is unclear to me.	B-Review	B-6	Review	20165
Does that mean in a quantitative sense?	I-Review	I-6	Review	20165
To be honest, only considering Fig.1 I am not able to assess whether the convergence rates of the different components are truly linear.	I-Review	I-6	Review	20165
<sep> <sep> I decided for my rating of the paper because of the following reasons:	O	O	Review	20165
-I think that for a theory paper the results obtained by the authors are not enough, as they are rather direct consequences of the "near-linearity" of the neural network around the initialization.	B-Review	B-7	Review	20165
<sep> -In my view, there is a huge gap between current theoretical results for deep learning and practice.	B-Review	B-8	Review	20165
For this reason, it is not problematic for me that it is unclear, what the results in this paper mean for practitioners. (	I-Review	I-8	Review	20165
Apart from that, results for the NTK regime are interesting in its own right.)	I-Review	I-8	Review	20165
However, in my view, one should explain the limitations of the theory more carefully.	I-Review	I-8	Review	20165
<sep> -The presentation of the paper needs to be improved.	B-Review	B-9	Review	20165
<sep> <sep> References:	O	O	Review	20165
[1] A note on lazy training in supervised differentiable programming.	O	O	Review	20165
L Chizat, F Bach - arXiv preprint arXiv:1812.07956, 2018	O	O	Review	20165
<sep> <sep> <sep> -----------------------------	O	O	Review	20165
<sep> I highly appreciate the authors' detailed response.	O	O	Review	20165
However, I feel that the paper does not contain enough novelty to justify acceptance.	B-Review	B-10	Review	20165
<sep> <sep> ------	O	O	Review	20165
"Equation (8) in Arora et al (2019b) only provides a bound on the whole residual vector, i.e., , and therefore cannot show different convergence rates along different directions."	B-Review	B-11	Review	20165
<sep> <sep> When going through Section 4 , I think that it is implicitly stated that one has different convergence along different directions.	I-Review	I-11	Review	20165
<sep> -----	O	O	Review	20165
For this reason, I am not going to change my score.	O	O	Review	20165
<sep> <sep> Thank you for you detailed and helpful comments.	O	O	Reply	20165
We address your questions as follows.	O	O	Reply	20165
<sep> <sep> Q1. ‚	O	O	Reply	20165
Äúfrom a mathematical point of view‚Ä¶ making this statement precise.	O	O	Reply	20165
‚Äù	O	O	Reply	20165
A1.	O	O	Reply	20165
We agree that our result is intuitive.	B-Reply	B-1	Reply	20165
But we believe this is an advantage of our result, instead of a weak point.	I-Reply	I-1	Reply	20165
We also would like to point out that although the results match intuition, the proof is by no means trivial, especially because it only relies on milder over-parameterization conditions to learn the components of the target function with lower complexity.	I-Reply	I-1	Reply	20165
Given the fact that such a result has not been shown in previous work, closing this gap between mathematical intuition and rigorous theoretical analysis is indeed one of our contributions.	I-Reply	I-1	Reply	20165
<sep> <sep> <sep> Q2. ‚	O	O	Reply	20165
ÄúI am skeptical about some of the implications for practitioners‚Ä¶ the NTK regime‚Äù	O	O	Reply	20165
A2.	O	O	Reply	20165
Thanks for pointing it out.	B-Reply	B-2	Reply	20165
Our analysis is indeed in the NTK regime.	I-Reply	I-2	Reply	20165
However, we would like to emphasize that by focusing on the low complexity components of the target function, we have greatly improved the over-parameterization condition in standard results in the NTK regime (Du et al (2018b)).	I-Reply	I-2	Reply	20165
Therefore, we believe our work helps pushing the study of neural networks in the NTK regime towards a more practical setting.	I-Reply	I-2	Reply	20165
We would also like to point out that the optimization method studied in this paper is standard gradient descent with a practically used initialization method.	I-Reply	I-2	Reply	20165
For these reasons, we believe that our results are also of great practical value.	I-Reply	I-2	Reply	20165
In the revision, we have emphasized that our analysis is in the NTK regime.	I-Reply	I-2	Reply	20165
However, we believe that the spectral bias phenomenon can be rigorously proved in other regimes of neural network training.	I-Reply	I-2	Reply	20165
<sep> <sep> <sep> Q3.(a). ‚	O	O	Reply	20165
Äúwhether some of the assumptions of their theorem are really met in practice.	O	O	Reply	20165
For example, the required sample size for higher order polynomials grows exponentially fast with the order and the required step size goes to zero exponentially fast.	O	O	Reply	20165
‚Äù	O	O	Reply	20165
A3.(a).	O	O	Reply	20165
Thanks for your question.	B-Reply	B-3	Reply	20165
We have added a remark (Remark 3.9) to explain such exponential dependency.	I-Reply	I-3	Reply	20165
Here we would like to emphasize that instead of checking the rate in terms of, a more reasonable measure should probably be the relation between and the number of independent function components being learned, which is.	I-Reply	I-3	Reply	20165
Intuitively speaking, based on samples, it is only reasonable to expect learning less than or equal to independent components of the true function, and the exponential dependency in is a natural consequence of the fact that in the high dimensional space, there are a large number of linearly independent polynomials even for very low degrees.	I-Reply	I-3	Reply	20165
From this we can see that is not an artifact, and is a reasonable and unavoidable assumption.	I-Reply	I-3	Reply	20165
In fact, even if we know that the target function is exactly a polynomial with degree less than or equal to, it still requires exponentially many samples to fit this polynomial, since the number of coefficients in a high-dimensional polynomial is exponential in the degree of the polynomial.	I-Reply	I-3	Reply	20165
<sep> <sep> <sep> Q3.(b). ‚	O	O	Reply	20165
ÄúDoes this really correspond to what is observed in practice? (	O	O	Reply	20165
Or is this a mere artifact of training in the NTK regime?)	O	O	Reply	20165
Is this what one observes in the experiments by Ramahan?‚Äù	O	O	Reply	20165
A3.(b).	O	O	Reply	20165
The effect of different sample sizes are not considered in the experiments in Rahaman et al (2018), and therefore no empirical observation conflicts with our theory.	B-Reply	B-4	Reply	20165
In fact, the discussion in Rahaman et al (2018) below Theorem 1 actually matches our calculation in the setting, which backs up our theory.	I-Reply	I-4	Reply	20165
Moreover, we would also like to emphasize that all our results regarding spherical harmonics and the exponential dependency in their degrees are only a special case of Theorem 3.2 when the data inputs are uniformly sampled from unit sphere.	I-Reply	I-4	Reply	20165
Such exponential dependency does not necessarily exist for other input distributions.	I-Reply	I-4	Reply	20165
<sep> <sep> <sep> Q4.	O	O	Reply	20165
About typos and presentation	O	O	Reply	20165
A4.	B-Reply	B-9	Reply	20165
Thank you for pointing out these typos and presentation issues.	I-Reply	I-9	Reply	20165
We apologize for the typos and unclear statements.	I-Reply	I-9	Reply	20165
We have improved the presentation of our paper and fixed typos in the revision.	I-Reply	I-9	Reply	20165
<sep> <sep> <sep> Q5. ‚	O	O	Reply	20165
Äúonly considering Fig.1‚Ä¶ convergence rates of the different components are truly linear.	O	O	Reply	20165
‚Äù	O	O	Reply	20165
A5.	O	O	Reply	20165
We admit that the figure under linear scale is not enough to show the linear convergence rate, and have added the same curves in log scale in Appendix E.2.	B-Reply	B-6	Reply	20165
In log scale we can now see that the curves indeed demonstrate linear convergence.	I-Reply	I-6	Reply	20165
<sep> <sep> <sep> Q6. ‚	O	O	Reply	20165
Äúin my view, one should explain the limitations of the theory more carefully.	O	O	Reply	20165
‚Äù	O	O	Reply	20165
A6.	O	O	Reply	20165
Thanks for your suggestion.	B-Reply	B-8	Reply	20165
We have rephrased Remark 3.3 and mentioned in Section 1 and Section 5 to make it clear that there is still a gap between theory and practice in terms of the spectral bias of neural networks.	I-Reply	I-8	Reply	20165
<sep> <sep> <sep> We hope you find your concerns satisfactorily addressed by our response, which has also been reflected in the revised paper.	O	O	Reply	20165
Please let us know if you have more comments or any other suggestions.	O	O	Reply	20165

Summary	O	O	Review	849
This paper introduced a parameterized image processing technique to improve a robustness of visual recognition systems against noisy input data.	O	O	Review	849
The proposed method is composed of two components; a denoising network that suppresses the noise signals in an image, and gating network that predicts whether to use the original input image or the one produced by the denoising network.	O	O	Review	849
The proposed idea is evaluated on three tasks of object detection, tracking and action recognition.	O	O	Review	849
<sep> <sep> Originality and significance:	O	O	Review	849
The originality of the paper is very limited since the paper simply combines the existing image denoising technique with the idea of gating.	B-Review	B-1	Review	849
The practical significance of the work is also limited since the model is trained and evaluated with only synthetically generated noise patterns; it is not surprising that the proposed method (both denoising and gating networks) works under this setting, as the noise is created synthetically under the same setting in both training and testing.	I-Review	I-1	Review	849
To demonstrate the practical usefulness, it would be great if the model is evaluated with the actual source of noises (e.g. noises from input sensors, distortion by image compression, etc).	I-Review	I-1	Review	849
<sep> Clarity:	O	O	Review	849
I think the title of the paper is misleading; the proposed model is actually not a mixture of preprocessing units, as it combines *a* denoising unit together with identity mapping.	B-Review	B-2	Review	849
The gating network is also not designed to incorporate a mixture of more than two preprocessing units, as it outputs only ‚Äúon/off switches‚Äù instead of weights for K mixture components (K>2).	I-Review	I-2	Review	849
<sep> <sep> Minor comments:	O	O	Review	849
1) the paper argued the importance of lightweight preprocessing but have not provided analysis on computation costs.	B-Review	B-3	Review	849
From the current results, I don‚Äôt see the clear benefit of the proposed method (denoising network) over the average filtering considering the tradeoff between computation vs. performance.	I-Review	I-3	Review	849
<sep> 2) In Figure 5, I suggest highlighting the differences among the examples for clarity.	B-Review	B-4	Review	849
<sep> <sep> Thank you for the valuable reviews.	O	O	Reply	849
<sep> <sep> Q1 ‚Äì Originality and significance:	O	O	Reply	849
<sep> (Ans) In contrast to many other DL works focused on denoising or image classification on noisy images [1-2], the main contribution of this paper is to enhance the performance of object detection and its related other tasks (multiple object tracking and activity recognition) under ‚Äúboth‚Äù noisy/clean condition with ‚Äúlimited overhead‚Äù in terms of memory/computation (table 5).	B-Reply	B-1	Reply	849
Also, we have discovered that adding average filter and U-net [3] like skip connection are beneficial for denoising.	I-Reply	I-1	Reply	849
<sep> For the practical usefulness, it would be great if we can incorporate those actual noises as a future work.	I-Reply	I-1	Reply	849
Thanks for your feedback.	I-Reply	I-1	Reply	849
<sep> <sep> [1] P. Vincent, H. Larochelle, I. Lajoie, Y. Bengio, P.-A. Manzagol, "Stacked denoising autoencoders: learning useful representations in a deep network with a local denoising criterion", J. Mach.	I-Reply	I-1	Reply	849
Learn.	I-Reply	I-1	Reply	849
Res.,	I-Reply	I-1	Reply	849
vol.11, no.	I-Reply	I-1	Reply	849
11, pp.3371-3408, 2010.	I-Reply	I-1	Reply	849
<sep> [2] S. Diamond, V. Sitzmann, S. Boyd, G. Wetzstein, and F. Heide.	I-Reply	I-1	Reply	849
Dirty pixels: Optimizing image classification architectures for raw sensor data.	I-Reply	I-1	Reply	849
arXiv preprint arXiv:1701.06487, 2017.	I-Reply	I-1	Reply	849
<sep> [3] Olaf Ronneberger, Philipp Fischer, and Thomas Brox.	I-Reply	I-1	Reply	849
U-net: Convolutional networks for biomedical image segmentation.	I-Reply	I-1	Reply	849
In MICCAI (3), volume 9351 of Lecture Notes in Computer Science, pp.234‚Äì241.	I-Reply	I-1	Reply	849
Springer, 2015.	I-Reply	I-1	Reply	849
<sep> <sep> Q2 ‚Äì Clarity:	O	O	Reply	849
(Ans) We think that the title of the paper is valid.	B-Reply	B-2	Reply	849
It is true, in this paper, we have used identity mapping for the clean and low-resolution images as a preprocessing.	I-Reply	I-2	Reply	849
This was the result from our experiments, not necessarily obvious one.	I-Reply	I-2	Reply	849
There could be better preprocessing for low-resolution images that we haven‚Äôt explored.	I-Reply	I-2	Reply	849
<sep> <sep> Q3 - lightweight preprocessing	O	O	Reply	849
(Ans) Please see the table 5.	B-Reply	B-3	Reply	849
Also, it is obvious that average filter requires less computation than the denoise net since denoise net includes average filter as a part (Please see the section 3.2 Pre-processing for the noisy images).	I-Reply	I-3	Reply	849
<sep> <sep> Q4 - Figure 5:	O	O	Reply	849
(Ans) We have changed the figure.	B-Reply	B-4	Reply	849

The paper presents a synthetic naive approach to analyzing distorted, especially noisy, images through deep neural networks.	O	O	Review	849
It uses an existing gating network to discriminate between clean and noisy images, averaging and denoising the latter, so as to somewhat improve the results obtained if no such separation was used.	O	O	Review	849
It deals with a well known problem using the deep neural network formulation.	O	O	Review	849
Results should be compared to other image analysis methodologies, avoiding smoothing when not required, that can be used for the same purpose.	B-Review	B-1	Review	849
This should also be reflected in related work in section 2; the reason of including Table 1 in it seems unclear.	B-Review	B-2	Review	849
<sep> <sep> Thank you for the valuable reviews.	O	O	Reply	849
<sep> <sep> Q1 ‚Äì Results should be compared to other image analysis methodologies	O	O	Reply	849
(Ans) The purpose of the paper is to enhance the performance of object detection and its related other tasks (multiple object tracking and activity recognition) under ‚Äúboth‚Äù noisy/clean condition with ‚Äúlimited overhead‚Äù in terms of memory/computation (table 5).	B-Reply	B-1	Reply	849
Existing denoising techniques like BM3D [1] require significant computation per image, thus, are not practical to be used in real time embedded system.	I-Reply	I-1	Reply	849
And use of gating network for avoiding smoothing when not required is not necessarily obvious.	I-Reply	I-1	Reply	849
Gaussian noise is random, thus, one might think it is hard to learn pattern of gaussian noise using neural network which is considered to be good for the data having pattern.	I-Reply	I-1	Reply	849
And we have showed that we can distinguish the clean and noisy images with gating network.	I-Reply	I-1	Reply	849
<sep> Instead, we have added comparison between data augmentation techniques, with/without gating network and with/without fine-tuning to show the effect of the proposed MoPE in table 2/3/4.	I-Reply	I-1	Reply	849
<sep> [1] K. Dabov, A. Foi, V. Katkovnik, and K. Egiazarian.	I-Reply	I-1	Reply	849
Image denoising by sparse 3-d transform-domain collaborative filtering.	I-Reply	I-1	Reply	849
IEEE Transactions on Image Processing, 16(8):2080‚Äì2095, 2007.	I-Reply	I-1	Reply	849
<sep> <sep> Q2 - reason of including Table 1	O	O	Reply	849
(Ans) We wanted to address that adding additional loss without changing network architecture doesn‚Äôt work for object detection which is not true for the image recognition.	B-Reply	B-2	Reply	849
And this was the motivation of this work.	I-Reply	I-2	Reply	849
We eventually proposed MoPE for object detection under clean/noisy/resolution variant conditions with small overhead (table 5).	I-Reply	I-2	Reply	849

The paper addresses the problem of training an object detection network that can achieve good performance on both clean and noisy images.	O	O	Review	849
The proposed approach is based on a gating network that decides whether	O	O	Review	849
the image is clean or  noisy.	O	O	Review	849
in case of  noisy image a denoising  method is applied.	O	O	Review	849
The network components form a mixture of experts architecture and are  jointly trained after a component-level pretraining.	O	O	Review	849
<sep> How good is the gate performance?	B-Review	B-1	Review	849
what happen if you use only one of the trained experts for all the clean/noisy  test data?	B-Review	B-2	Review	849
It is not clear how you combined the results of the two experts.	B-Review	B-4	Review	849
Are you computing a weighted average of the original and the enhanced images?	I-Review	I-4	Review	849
Did you try to use a hard decision gating at test time?	B-Review	B-5	Review	849
<sep> Thank you for the valuable reviews.	O	O	Reply	849
<sep> <sep> Q1 ‚Äì How good is the gate performance?	O	O	Reply	849
<sep> (Ans) The performance of the gating network was above 99% which haven‚Äôt included in the paper.	B-Reply	B-1	Reply	849
Instead, we have shown sample images in figure 5 to show the effect of MoPE.	I-Reply	I-1	Reply	849
<sep> <sep> Q2 - what happen if you use only one of the trained experts for all the clean/noisy  test data?	O	O	Reply	849
<sep> (Ans) Please check the performance of the model 4 in table 2.	B-Reply	B-2	Reply	849
Model 4 uses denoise network as a preprocessing for all the clean/noisy data without having gating network.	I-Reply	I-2	Reply	849
The denoise net is trained on the noisy images with various noise levels including the clean images.	I-Reply	I-2	Reply	849
When sigma is 0, the input image is actually the clean image (Please see the section 5 for implementation details).	I-Reply	I-2	Reply	849
<sep> <sep> Q3 - It is not clear how you combined the results of the two experts.	O	O	Reply	849
<sep> (Ans) Please see the figure 1.	B-Reply	B-3	Reply	849
The shape of the preprocessing output is the same with that of the input image.	I-Reply	I-3	Reply	849
Once we obtain the pre-processed images, the coefficient of the gating network is multiplied per each pre-processing and summed.	I-Reply	I-3	Reply	849
The sum of the coefficients of the gating network is 1 as the output of the gating network is softmax function (See the section 4.2 for details).	I-Reply	I-3	Reply	849
<sep> <sep> Q4 - Did you try to use a hard decision gating at test time?	O	O	Reply	849
<sep> (Ans) No, we have used the same configuration as for the training time.	B-Reply	B-5	Reply	849

CONTRIBUTIONS:	O	O	Review	10149
Topic: Disentangling syntax from semantics in contextualized word representations	O	O	Review	10149
C1.	O	O	Review	10149
A method for generating ‚Äòstructurally equivalent‚Äô sentences is proposed, based only on the assumption that maintaining function words, and replacing one content word of a source sentence with another to produce a new grammatical sentence, yields a target sentence that is equivalent to the source sentence.	O	O	Review	10149
<sep> C2.	O	O	Review	10149
The ‚Äòstructural relation‚Äô between two words in a sentence is modeled as the difference between their vector embeddings.	O	O	Review	10149
<sep> C3a.	O	O	Review	10149
The structural relation between a pair of content words in one sentence is assumed to be the same as that between the corresponding pair in an equivalent sentence.	O	O	Review	10149
<sep> C3b.	O	O	Review	10149
The structural relation between any pair of content words in one sentence is assumed to be different from the structural relation between any pair of content words in an inequivalent sentence.	O	O	Review	10149
<sep> C4.	O	O	Review	10149
Given a selected word in a source sentence, to generate an alternative ‚Äòcorresponding‚Äô content word for an equivalent target sentence, BERT is used to predict the source word when it is masked, given the remaining words in the source sentence.	O	O	Review	10149
The alternative corresponding word is randomly selected from among the top (30) candidates predicted by BERT.	O	O	Review	10149
Given a source sentence, the set of target sentences formed by cumulatively replacing content words one at a time in randomly selected positions defines an ‚Äòequivalence set‚Äô in which words in different sentences with the same left-to-right index are corresponding words. (	O	O	Review	10149
To promote the formation of grammatical target sentences, a word is only replaced by another word with the same POS.)	O	O	Review	10149
A pre-defined set of equivalence sets is used for training.	O	O	Review	10149
<sep> C5.	O	O	Review	10149
A metric learning paradigm with triplet loss is used to find a function f for mapping ELMo or BERT word embeddings to a new vector space of ‚Äòtransformed word representations‚Äô.	O	O	Review	10149
Implementing C2 and C3a, given the indices i and i‚Äô of two content words, the triplet loss rewards closeness of the difference D between the transformed embeddings of the pair of words with these indices in sentence S and the corresponding difference D‚Äô for an equivalent sentence S‚Äô.	O	O	Review	10149
Implementing C3b, the triplet loss penalizes closeness between D and D‚Äù, where D‚Äù is the difference between transformed word embeddings of a pair of content words in a sentence S‚Äù that is inequivalent to S. (Eq.4).	O	O	Review	10149
<sep> C6. (	O	O	Review	10149
Implementing C5.)	O	O	Review	10149
To form a mini-batch for minimizing the triplet loss, a set of (500) sentences S is selected, and for each a pair of indices of content words is chosen.	O	O	Review	10149
Training will use the difference in the transformed embeddings of the words in S with these indices: call this D, and call the set of these (500) D vectors B. For each sentence S in B, a ‚Äòpositive pair‚Äô (D, D‚Äô) is generated, where D‚Äô is the corresponding difference for S‚Äô, a selected sentence in the equivalence set of S. Closeness of D and D‚Äô is rewarded by the triplet loss, implementing C3a.	O	O	Review	10149
To implement C3b, a ‚Äònegative pair‚Äô (D, D‚Äù), for which closeness is penalized by the loss, is formed as follows.	O	O	Review	10149
D‚Äù is the closest vector in B to D that is derived from a sentence S‚Äù that is not equivalent to S.	O	O	Review	10149
C7.	O	O	Review	10149
2-D t-SNE plots (seem to) show that relative to the original ELMo embeddings, the transformed embeddings cluster better by POS (Fig.3). (	O	O	Review	10149
No quantitative measure of this is provided, and the two plots are not easy to distinguish.)	O	O	Review	10149
<sep> C8.	O	O	Review	10149
Pairs of closest ELMo vectors share syntactic (dependency parse) properties to a greater degree after transformation than before (Table 1).	O	O	Review	10149
To check that this goes beyond merely POS-based closeness, the syntactic relations that least determine POS are examined separately, and the result remains.	O	O	Review	10149
Furthermore, the proportion of pairs of closest vectors that are embeddings of the same word (in different contexts) drops from 77.6% to 27.4%, showing that the transformation reduces the influence of lexical-semantic similarity.	O	O	Review	10149
Similar results hold for BERT embeddings, but to a lesser degree, so the paper focusses on ELMo.	O	O	Review	10149
<sep> C9.	O	O	Review	10149
Few-shot parsing.	O	O	Review	10149
Two dependency parsers are trained, one on ELMo embeddings, the other on their transformations (under the proposed method).	O	O	Review	10149
In the small-data regime (less than 200 training examples), the transformed embeddings yield higher parser performance, even when the encoding size of the ELMo embeddings is reduced (from 2048 to 75) to match that of the transformed embeddings by either PCA or a learned linear mapping. (	O	O	Review	10149
Fig.4)	O	O	Review	10149
RATING: Weak accept	O	O	Review	10149
REASONS FOR RATING (SUMMARY).	O	O	Review	10149
Using deep learning to create an encoding of syntactic structure with minimal supervision is an important goal and the paper proposes a clever way of doing this.	O	O	Review	10149
The only ‚Äòsupervision‚Äô here comes from (i) the function/content-word distinction (C1 above): two grammatical sentences are structurally equivalent if [but not only if] one can be derived from the other by replacing one content word with another; and (ii) filtering candidate replacement words to match the POS of the replaced word.	O	O	Review	10149
BERT‚Äôs ability to guess a masked word is put to good use in providing suitable content word substitutions.	O	O	Review	10149
The experimental results are rather convincing.	O	O	Review	10149
<sep> REVIEW (beyond the summary above)	O	O	Review	10149
C1.	O	O	Review	10149
This assumption is famously not deemed to be true in linguistics, where the structural difference between ‚Äòcontrol‚Äô and ‚Äòraising‚Äô verbs is basic Ling 101 material: see <a href="https://en.wikipedia.org/wiki/Control_(linguistics)#Control_vs._raising."	B-Review	B-1	Review	10149
target="_blank" rel="nofollow">https://en.wikipedia.org/wiki/Control_(linguistics)#Control_vs._raising.</a> This particular structural contrast illustrates how verbs can differ in their argument structure, without there being function words to signal the difference.	I-Review	I-1	Review	10149
So substituting *verbs* in particular may be non-ideal for the purposes of this work.	I-Review	I-1	Review	10149
Even the third example given by the authors in Sec.3.1 illustrates a related  point, where function words do signal the contrast:  while the meaning of ‚Äòlet‚Äô and ‚Äòallow‚Äô may be very similar, their argument structures differ, so that replacing ‚Äòlets‚Äô with ‚Äòallows‚Äô in the first sentence, or the reverse in the second sentence, produces ungrammatical results:	I-Review	I-1	Review	10149
*their first project is software that *allows* players connect the company ‚Äôs controller to their device	I-Review	I-1	Review	10149
*the city offers a route-finding website that *lets* users to map personalized bike routes	I-Review	I-1	Review	10149
Therefore, contrary to the paper, relative to linguistic syntactic structure, it is not a good result that ‚Äòlets‚Äô in the original version of the first sentence is the closest neighbor in transformed embedding space to ‚Äòallows‚Äô in the second.	I-Review	I-1	Review	10149
Rather, it is probably meaning, not structure, that makes ‚Äòlet‚Äô and ‚Äòallow‚Äô similar.	I-Review	I-1	Review	10149
<sep> It would improve the paper to make note of this general concern with C1 and to provide a response.	I-Review	I-1	Review	10149
<sep> On another point, an important premise of the proposed method (C2 above) is that differences in vector space embeddings encode relations; this has been used by a number of previous authors since the famous Mikolov, Yih &amp; Zweig NAACL2013, and that work should be cited and discussed.	I-Review	I-1	Review	10149
We appreciate your constructive and detailed review!	O	O	Reply	10149
<sep> <sep> Your are right in noting that subtle differences in the surface level can mask substantial differences in the deep argument structure of the sentence, and that verbs are particularly sensitive in this respect.	B-Reply	B-1	Reply	10149
This is a limitation of the current approach, which we now acknowledge in the paper.	I-Reply	I-1	Reply	10149
Thanks for pointing this out.	I-Reply	I-1	Reply	10149
Indeed, in general we can expect the replacement process to yield a grammatical sentence with equivalent structures only to the extent that BERT implicitly encodes the grammatical restrictions that apply to the masked word (i.e., we can only capture raising vs control distinction to the extent BERT-like LM can captures them).	I-Reply	I-1	Reply	10149
While BERT is a powerful LM -- and that is the reason we used it rather than simple POS-based replacement -- it may at times violates some of those restrictions.	I-Reply	I-1	Reply	10149
As you point out, this reasoning behind the substitution process and the premises we made were not clearly stated in the paper, and made it clearer in the revisioned version.	I-Reply	I-1	Reply	10149
However, we note that the average sentences we generate seem grammatical, and do not diverge much from the structure of the original sentence; we therefore think this method does at least approximate our end goal of generating grammatical sentences of the same structure.	I-Reply	I-1	Reply	10149
<sep> Moreover, we remind that our method attempts to uncover the structural information that is encoded in the neural LMs.	I-Reply	I-1	Reply	10149
Thus, we find it reasonable to not capture structural distinctions that are not reflected in current state-of-the-art neural LMs.	I-Reply	I-1	Reply	10149
<sep> <sep> Thank you for pointing out to the works on vector-space arithmetic.	I-Reply	I-1	Reply	10149
This was our motivation for representing pairs as the difference between the corresponding word vectors, and we will explicitly mention that in the paper.	I-Reply	I-1	Reply	10149

The authors state a clear hypothesis: it is possible to extract syntactic information from contextualized word vectors in an unsupervised manner.	O	O	Review	10149
The method of creating syntactically equivalent (but semantically different) sentences is indeed interesting on its own.	O	O	Review	10149
Experiments do support the main hypothesis -- the distilled embeddings are stronger in syntactic tasks than the default contextualized vectors.	O	O	Review	10149
The authors provide the code for ease of reproducibility which is nice.	O	O	Review	10149
<sep> <sep> There is a short literature review, but I am wondering if something similar was done for static word embeddings.	B-Review	B-1	Review	10149
I understand that they are obsolete these days, but on the other hand, they are better researched, so were there any attempts to disentangle syntax and semantics in the classical static word vectors?	I-Review	I-1	Review	10149
<sep> <sep> Overall, I have no major concerns with the paper.	O	O	Review	10149
Thank you for you comments!	O	O	Reply	10149
<sep> <sep> We are only aware of the work [1] which demonstrated the existence of a semantics-syntax tradeoff in word vectors that capture different orders of similarity.	B-Reply	B-1	Reply	10149
They projected pre-trained word vectors to different orders by a parameter-free transformation which derives from the similarity matrix, and measured the performance on semantic and syntactic tasks.	I-Reply	I-1	Reply	10149
We now mention this work in the revised paper.	I-Reply	I-1	Reply	10149
We would appreciate pointers to other works in this direction, if any of the reviewers are aware of them.	I-Reply	I-1	Reply	10149
<sep> <sep> There are additional works which learn from scratch word embeddings that are tailored for syntax, some of them are mentioned by reviewer 2.	I-Reply	I-1	Reply	10149
These works are somewhat less relevant for the current study, as we aim to extract existing information from contextualized representations and make it more salient, rather than learning from scratch representations that capture syntax.	I-Reply	I-1	Reply	10149
Yet, we now note them in the new related work section.	I-Reply	I-1	Reply	10149
<sep> <sep> [1] Artetxe, Mikel, et al "Uncovering divergent linguistic information in word embeddings with lessons for intrinsic and extrinsic evaluation."	O	O	Reply	10149
arXiv preprint arXiv:1809.02094 (2018).	O	O	Reply	10149
APA<tab>	O	O	Reply	10149

Summary:	O	O	Review	10149
=========	O	O	Review	10149
This paper aims to disentangle semantics and syntax in contextualized word representations.	O	O	Review	10149
The main idea is to learn a transformation of the contexualized representations that will make two word representations to be more similar if they appear in the same syntactic context, but less similar if they appear in different syntactic contexts.	O	O	Review	10149
The efficacy of this transformation is evaluated through cluster analysis, showing that words better organize in syntactic clusters after the transformation, and through low-resource dependency parsing.	O	O	Review	10149
<sep> <sep> The paper presents a simple approach to transform word representations and expose their syntactic information.	B-Review	B-1	Review	10149
The experiments are mostly convincing.	I-Review	I-1	Review	10149
I would like to see better motivation, more engagement with a wider range of related work, and more thorough quantitative evaluations.	I-Review	I-1	Review	10149
Another important question to address is also what kind of semantic/syntactic types of information are targeted, and how to handle the tradeoff between them, for instance for different purposes.	I-Review	I-1	Review	10149
<sep> <sep> <sep> Main comments:	O	O	Review	10149
==============	O	O	Review	10149
1.	B-Review	B-1	Review	10149
Motivation: I found the motivation for the problem understudied a bit lacking.	I-Review	I-1	Review	10149
The main motivation seems to be to disentangle semantic and syntactic information.	I-Review	I-1	Review	10149
But why should we care about that?	I-Review	I-1	Review	10149
Beyond reference to disentangling in computer vision, some more motivation would be good.	I-Review	I-1	Review	10149
The few-shot parsing is a good such motivation, although the results are a bit disappointing (see more on this below).	I-Review	I-1	Review	10149
Another possible motivation is potential applications of disentanglement in language generation.	I-Review	I-1	Review	10149
There is a line of work on style transfer also in language generation, and it seems plausible that the methodology could be applied to such tasks.	I-Review	I-1	Review	10149
<sep> 2.	O	O	Review	10149
The present work is well-differentiated from work on extracting syntactic information from word representations via supervised ways, as the current work does so in an unsupervised way.	B-Review	B-2	Review	10149
I don't quite get the terminological differentiation between "mapping" and "extracting" in the introduction, but the idea is clear.	I-Review	I-2	Review	10149
<sep> 3.	B-Review	B-3	Review	10149
Have you considered alternative representations of word pairs besides the different of their transformations f(x)-f(y)?	I-Review	I-3	Review	10149
<sep> 4.	B-Review	B-4	Review	10149
I found it interesting that the word representation from BERT is the concatenation of layer 16 with the mean of all the other layers.	I-Review	I-4	Review	10149
This is motivated by Hewitt and Manning's findings, and [5] found similar results.	I-Review	I-4	Review	10149
However, the different between layer 16 and others is not that large as to warrant emphasizing it so much.	I-Review	I-4	Review	10149
Perhaps a scalar mix with fine-tuning may work better, as in [5], or another method.	I-Review	I-4	Review	10149
Have you tried other word representations?	I-Review	I-4	Review	10149
I also wonder whether it makes sense to use different layers for different parts of the triplet loss, depending on whether to emphasize syntactic vs. semantic similarity.	I-Review	I-4	Review	10149
<sep> 5.	O	O	Review	10149
The introduction lays out connections to some related work, but leaves several relevant pieces missing.	B-Review	B-5	Review	10149
See examples below.	I-Review	I-5	Review	10149
<sep> 6.	O	O	Review	10149
The results in 3.3 are limited but useful.	B-Review	B-6	Review	10149
The comparison with a PCA-ed and reduced representation is well thought of, because of the risk with low-resource and high dimensionality.	I-Review	I-6	Review	10149
That said, I found the gap between the proposed syntax model and the ELMo-reduced disappointingly small.	I-Review	I-6	Review	10149
Even in the LAS, it seems like the difference is very small, ~0.5, although it's hard to tell from the figure.	I-Review	I-6	Review	10149
Providing the actual numbers and a measure of statistical significance would be helpful here.	I-Review	I-6	Review	10149
<sep> 7.	B-Review	B-1	Review	10149
Some care should be taken to define what kind of semantics is targeted here.	I-Review	I-1	Review	10149
In several cases this is "lexical semantics", but then we have "meaning" in parentheses sometimes (end of intro).	I-Review	I-1	Review	10149
Obviously, there's much more to semantics and meaning that the lexical semantics, so a short discussion of how the work views other, say compositional semantics, would be good.	I-Review	I-1	Review	10149
<sep> <sep> <sep> Other comments:	O	O	Review	10149
===============	O	O	Review	10149
1.	O	O	Review	10149
The introduction seeks a representation that will ignore the similarity between "syrup" in (2) and (4).	B-Review	B-8	Review	10149
I wonder if "ignoring" is too strong.	I-Review	I-8	Review	10149
One may not want to lose all lexical semantic information.	I-Review	I-8	Review	10149
Moreover, the proposed triplet loss does not guarantee that information is ignored (and justly so, in my opinion).	I-Review	I-8	Review	10149
<sep> 2.	B-Review	B-9	Review	10149
In the example, "maple" and "neural" are said to be syntactically similar, although "maple syrup" is a noun compound while "neural networks" is an adjective-noun.	I-Review	I-9	Review	10149
Shouldn't they be treated differently then?	I-Review	I-9	Review	10149
Unless the notion of syntax is more narrow and just looks at unlabeled dependency arcs.	I-Review	I-9	Review	10149
<sep> 3.	B-Review	B-10	Review	10149
Some experimental choices are left unexplained, such as k=6 (section 2.1) or mapping to 27 dims (section 2.3); these two seem potentially important.	I-Review	I-10	Review	10149
<sep> 4.	B-Review	B-11	Review	10149
Section 2.3: do you also back-prop back into the BERT/ELMo model weights?	I-Review	I-11	Review	10149
<sep> 5.	B-Review	B-12	Review	10149
The dataset statistics in section 3 do not match those in section 2.2.	I-Review	I-12	Review	10149
Please clarify.	I-Review	I-12	Review	10149
<sep> 6.	O	O	Review	10149
The qualitative cluster analysis via t-SNE (3.1) is compelling.	B-Review	B-13	Review	10149
It could be made stronger by reporting quantitative clustering statistics such as cluster purity before and after transformation.	I-Review	I-13	Review	10149
<sep> 7.	O	O	Review	10149
In the examples showin in 3.1, it would be good to give also the nearest neighbor before the transformation for comparison.	B-Review	B-14	Review	10149
<sep> 8.	B-Review	B-15	Review	10149
The quantitative results in 3.2 convey the point convincingly.	I-Review	I-15	Review	10149
It's good to see also the lexical match measure going down.	I-Review	I-15	Review	10149
The random baseline is also a good sanity check to have.	I-Review	I-15	Review	10149
It would be good to provide full results with BERT, at least in the appendix and at least for section 3.2, maybe also for 3.3.	I-Review	I-15	Review	10149
<sep> 9.	O	O	Review	10149
More related work:	B-Review	B-16	Review	10149
+ Work that injects syntactic information into word representations in a supervised way, such as [1,2]	I-Review	I-16	Review	10149
+ Work that shows that word embeddings contain different kinds of information (syntactic/semantic), and propose simle linear transformations to uncover them.	I-Review	I-16	Review	10149
<sep> + Engaging with the literature on style transfer in language generation would be good, as mentioned above for motivation, but also to situate this work w.r.t to related style transfer work.	I-Review	I-16	Review	10149
<sep> + Another line of work that may be mentioned is the variety of papers trying to extract syntactic information from contextualized word representations, such as constructing trees from attention weights.	I-Review	I-16	Review	10149
There were a few such papers in BlackboxNLP 2018 and 2019.	I-Review	I-16	Review	10149
<sep> <sep> Typos, phrasing, formatting, etc.:	O	O	Review	10149
<sep> ============================	O	O	Review	10149
- Abstract: a various of semantic... task -&gt; various semantic... tasks; use metric-learning approach -&gt; use a metric-learning approach; in few-shot parsing setting -&gt; in a few-shot parsing setting	B-Review	B-7	Review	10149
- Wilcox et al does not have a year	I-Review	I-7	Review	10149
- Introduction: few-shots parsing -&gt; few-shot parsing	I-Review	I-7	Review	10149
- Method: extract vectors -&gt; extracts vectors; Operativly -&gt; Operatively	I-Review	I-7	Review	10149
- Section 3: should encourages -&gt; should encourage; a few-shots settings -&gt; a few-shot setting	I-Review	I-7	Review	10149
- 3.2: -- was not rendered properly	I-Review	I-7	Review	10149
- 3.3: matrix that reduce -&gt; reduces	I-Review	I-7	Review	10149
<sep> <sep> References	O	O	Review	10149
==========	O	O	Review	10149
[1] Levy and Goldberg.	O	O	Review	10149
2014.	O	O	Review	10149
Dependency-Based Word Embeddings	O	O	Review	10149
[2] Bansal et al 2014.	O	O	Review	10149
Tailoring Continuous Word Representations for Dependency Parsing	O	O	Review	10149
[3] Artetxe et al 2018.	O	O	Review	10149
Uncovering divergent linguistic information in word embeddings with lessons for intrinsic and extrinsic evaluation	O	O	Review	10149
[4] Tenney et al 2019.	O	O	Review	10149
BERT Rediscovers the Classical NLP Pipeline	O	O	Review	10149
[5] Liu et al 2019.	O	O	Review	10149
Linguistic Knowledge and Transferability of Contextual Representations	O	O	Review	10149
I appreciate the detailed response to my review.	O	O	Reply	10149
I think the revised paper is improved in terms of background and motivation, and more complete experiments.	B-Reply	B-1	Reply	10149
It's also good to see the quantitative clustering purity results.	I-Reply	I-1	Reply	10149
<sep> While I don't think getting very high parsing results is a must for this work, I agree with reviewer 1 that comparing with a POS-based baseline is in order.	I-Reply	I-1	Reply	10149
<sep> I hope to see the paper accepted and at this point will keep my current evaluation.	O	O	Reply	10149

This paper proposes to extend the Prototypical Network (NIPS17) to the semi-supervised setting with three possible	O	O	Review	293
strategies.	O	O	Review	293
One consists in self-labeling the unlabeled data and then updating the prototypes on the basis of the	O	O	Review	293
assigned pseudo-labels.	O	O	Review	293
Another is able to deal with the case of distractors i.e.  unlabeled samples not beloning to	O	O	Review	293
any of the known categories.	O	O	Review	293
In practice this second solution is analogous to the first, but a general 'distractor' class	O	O	Review	293
is added.	O	O	Review	293
Finally the third technique learns to weight the samples according to their distance to the original prototypes.	O	O	Review	293
<sep> <sep> These strategies are evaluated in a particular semi-supervised transfer learning setting:  the models are first trained	O	O	Review	293
on some source categories with few labeled data and large unlabeled samples (this setting is derived by subselecting	O	O	Review	293
multiple times a large dataset), then they are used on a final target task with again few labeled data and large	O	O	Review	293
unlabeled samples but beloning to a different set of categories.	O	O	Review	293
<sep> <sep> + the paper is well written, well organized and overall easy to read	O	O	Review	293
+/-  this work builds largely on previous work.	B-Review	B-1	Review	293
It introduces only some small technical novelty inspired by soft-k-means	I-Review	I-1	Review	293
clustering that anyway seems to be effective.	I-Review	I-1	Review	293
<sep> + different aspect of the problem are analyzed by varying the number of disctractors and varying the level of	O	O	Review	293
semantic relatedness between the source and the target sets	O	O	Review	293
<sep> Few notes and questions	O	O	Review	293
1) why for the omniglot experiment the table reports the error results?	B-Review	B-2	Review	293
It would be better to present accuracy as for the other tables/experiments	I-Review	I-2	Review	293
2) I would suggest to use source and target instead of train and test -- these two last terms are confusing because	B-Review	B-3	Review	293
actually there is a training phase also at test time.	I-Review	I-3	Review	293
<sep> 3) although the paper indicate that there are different other few-shot methods that could be applicable here,	B-Review	B-4	Review	293
no other approach is considered besides the prothotipical network and its variants.	I-Review	I-4	Review	293
An further external reference	I-Review	I-4	Review	293
could be used to give an idea of what would be the experimental result at least in the supervised case.	I-Review	I-4	Review	293
<sep> <sep> <sep> <sep> <sep> <sep> We appreciate the constructive comments from reviewer 2 and we are delighted to learn that the reviewer feels that our paper is well written and organized.	O	O	Reply	293
<sep> <sep> ‚Äúbuilds largely on previous work‚Ä¶ only some small technical novelty‚Ä¶‚Äù	O	O	Reply	293
We would like to emphasize that we introduce a new task for few-shot classification, incorporating unlabeled items.	B-Reply	B-1	Reply	293
This is impactful as follow-up work can use our dataset as a public benchmark.	I-Reply	I-1	Reply	293
In fact, there are several concurrent ICLR submissions and arxiv pre-prints [1,2] that also introduce semi-supervised few-shot learning.	I-Reply	I-1	Reply	293
However compared to these concurrent papers, our benchmark extends beyond this work into more realistic and generic settings, with hierarchical class splits and unlabeled distractor classes, which we believe will make positive contributions to the community.	I-Reply	I-1	Reply	293
<sep> <sep> The fact that our semi-supervised prototypical network can be trained end-to-end from scratch is non-trivial, especially under many distractor clusters (note that each distractor class has the same number of images as a non-distractor class).	I-Reply	I-1	Reply	293
We argue that our extension is simple yet effective, serving as another layer on top of the regular prototypical network layer, and provides consistent improvement in the presence of unlabeled examples.	I-Reply	I-1	Reply	293
Further, to our knowledge, our best-performing method, the masked soft k-means, is novel.	I-Reply	I-1	Reply	293
<sep> <sep> ‚ÄúIt would be better to present accuracy‚Ä¶‚Äù	O	O	Reply	293
Thank you for the suggestion.	B-Reply	B-2	Reply	293
We will revise it in our next version.	I-Reply	I-2	Reply	293
<sep> <sep> ‚Äúno other approach is considered besides the prototypical network and its variants.	O	O	Reply	293
‚Äù	O	O	Reply	293
ProtoNets is one of the top performing methods for few-shot learning and our proposed extensions each naturally forms another layer on top of the Prototypical layer.	B-Reply	B-4	Reply	293
To address the concern, we are currently running other variants of the models such as a nearest neighbor baseline, and will report results before the ICLR discussion period ends.	I-Reply	I-4	Reply	293
In the Omniglot dataset literature, many simple baselines has been extensively explored, and Prototypical Networks are so far the state-of-the-art.	I-Reply	I-4	Reply	293
Table 1 summarizes the performance for a 5-way 5-shot benchmark (results reported by [3])	I-Reply	I-4	Reply	293
<sep> Table 1 - Omniglot dataset baselines	B-Reply	B-4	Reply	293
Method             Accuracy	I-Reply	I-4	Reply	293
KNN pixel          48%	I-Reply	I-4	Reply	293
KNN deep         69%	I-Reply	I-4	Reply	293
Mann et al [3]   88%	I-Reply	I-4	Reply	293
ProtoNet            99.7%	I-Reply	I-4	Reply	293
<sep> References:	O	O	Reply	293
[1]: Few-Shot Learning with Graph Neural Networks.	O	O	Reply	293
Anonymous.	O	O	Reply	293
Submitted to ICLR, 2017.	O	O	Reply	293
<sep> [2]: Semi-Supervised Few-Shot Learning with Prototypical Networks.	O	O	Reply	293
Rinu Boney and Alexander Ilin.	O	O	Reply	293
CoRR, abs/1711.10856, 2017.	O	O	Reply	293
<sep> [3]: One-shot learning with Memory-Augmented Neural Networks.	O	O	Reply	293
ICML 2016.	O	O	Reply	293

In this paper, the authors studied the problem of semi-supervised few-shot classification, by extending the prototypical networks into the setting of semi-supervised learning with examples from distractor classes.	O	O	Review	293
The studied problem is interesting, and the paper is well-written.	O	O	Review	293
Extensive experiments are performed to demonstrate the effectiveness of the proposed methods.	O	O	Review	293
While the proposed method is a natural extension of the existing works (i.e., soft k-means and meta-learning).On top of that, It seems the authors have over-claimed their model capability at the first place as the proposed model cannot properly classify the distractor examples but just only consider them as a single class of outliers.	B-Review	B-1	Review	293
Overall, I would like to vote for a weakly acceptance regarding this paper.	O	O	Review	293
Thank you for the comments.	B-Reply	B-1	Reply	293
We‚Äôd like to clarify our setup here: The problem as we have defined it is to correctly perform the given N-way classification in each episode (similarly as in the previous work).	I-Reply	I-1	Reply	293
Distractors are introduced to make the problem harder in a more realistic way, but the goal is not to be able to classify them.	I-Reply	I-1	Reply	293
Specifically, our model needs to understand which points are irrelevant for the given classification task (‚Äúdistractors‚Äù) in order to not take them into account, but actually classifying these distractors into separate categories is not required in order to perform the given classification task, so our models make no effort to do this.	I-Reply	I-1	Reply	293
<sep> <sep> Further, we would like to emphasize that adding distractor examples in few-shot classification settings is a novel and more realistic learning environment compared to previous approaches in supervised few-shot learning and as well as concurrent approaches in semi-supervised few-shot learning [1,2]. It is non-trivial to show that various versions of semi-supervised clustering can be trained end-to-end from scratch as another layer on top of prototypical networks, with the presence of distractor clusters  (note that each distractor class has the same number of images as a non-distractor class).	I-Reply	I-1	Reply	293
<sep> <sep> References:	O	O	Reply	293
[1]: Few-Shot Learning with Graph Neural Networks.	O	O	Reply	293
Anonymous.	O	O	Reply	293
Submitted to ICLR, 2017.	O	O	Reply	293
<sep> [2]: Semi-Supervised Few-Shot Learning with Prototypical Networks.	O	O	Reply	293
Rinu Boney and Alexander Ilin.	O	O	Reply	293
CoRR, abs/1711.10856, 2017.	O	O	Reply	293

This paper is an extension of the ‚Äúprototypical network‚Äù which will be published in NIPS 2017.	O	O	Review	293
The classical few-shot learning has been limited to using the unlabeled data, while this paper considers employing the unlabeled examples available to help train each episode.	O	O	Review	293
The paper solves a new semi-supervised situation, which is more close to the setting of the real world, with an extension of the prototype network.	O	O	Review	293
Sufficient implementation detail and analysis on results.	O	O	Review	293
<sep> <sep> However, this is definitely not the first work on semi-supervised formed few-shot learning.	B-Review	B-1	Review	293
There are plenty of works on this topic [R1, R2, R3]. The authors are advised to do a thorough survey of the relevant works in Multimedia and computer vision community.	I-Review	I-1	Review	293
<sep> Another concern is that the novelty.	B-Review	B-2	Review	293
This work is highly incremental since it is an extension of existing prototypical networks by adding the way of leveraging the unlabeled data.	I-Review	I-2	Review	293
<sep> <sep> The experiments are also not enough.	B-Review	B-3	Review	293
Not only some other works such as [R1, R2, R3]; but also the other na√Øve baselines should also be compared, such as directly nearest neighbor classifier, logistic regression, and neural network in traditional supervised learning.	I-Review	I-3	Review	293
Additionally, in the 5-shot non-distractor setting on tiered ImageNet, only the soft kmeans method gets a little bit advantage against the semi-supervised baseline, does it mean that these methods are not always powerful under different dataset?	B-Review	B-4	Review	293
<sep> <sep> [R1] ‚ÄúVideostory: A new multimedia embedding for few-example recognition and translation of events,‚Äù in ACM MM, 2014	O	O	Review	293
<sep> [R2] ‚ÄúTransductive Multi-View Zero-Shot Learning‚Äù, IEEE TPAMI 2015	O	O	Review	293
<sep> [R3] ‚ÄúVideo2vec embeddings recognize events when examples are scarce,‚Äù IEEE TPAMI 2014	O	O	Review	293
<sep> ‚ÄúThere are plenty of works on this topic‚Ä¶‚Äù	O	O	Reply	293
We also thank the reviewer for pointing out related zero-shot learning literature and we will study them and add those references to the next version of the paper.	B-Reply	B-1	Reply	293
Based on our preliminary reading, [1] is a journal version that builds on top of [2], with both papers presenting very similar approaches for the application of event recognition in videos.	I-Reply	I-1	Reply	293
Transductive Multi-View Zero-Shot Learning [3] uses a similar label propagation procedure as ours.	I-Reply	I-1	Reply	293
However, while [3] uses standalone deep feature extractors, we show that our semi-supervised prototypical network can be trained completely end-to-end.	I-Reply	I-1	Reply	293
One of the non-trivial results of our paper is that we show that end-to-end meta-learning significantly improves the performance (see Semi-supervised Inference vs. Soft K-means).	I-Reply	I-1	Reply	293
We would like to emphasize that end-to-end semi-supervised learning in a meta-learning framework is, to the best of our knowledge, a novel contribution.	I-Reply	I-1	Reply	293
<sep> <sep> ‚Äú...other na√Øve baselines should also be compared...‚Äù	O	O	Reply	293
The recent literature on few-shot learning has established that meta-learning-based approaches outperform kNN and standard neural network based approaches.	B-Reply	B-3	Reply	293
For the Omniglot dataset, Mann et al [4] has previously studied baselines such as KNN either in pixel space or deep features, and feedforward NNs.	I-Reply	I-3	Reply	293
They found these baselines all lag behind their method by quite a lot, and meanwhile Prototypical Networks outperform Mann et al by another significant margin.	I-Reply	I-3	Reply	293
For example, Table 1 summarizes the performance for 5-shot, 5-way classification.	I-Reply	I-3	Reply	293
Therefore, we will provide supervised nearest neighbor, logistic regression, and neural network baselines for completeness; however, we believe that our work is built on top of state-of-the-art methods, and should beat these simple baselines.	I-Reply	I-3	Reply	293
<sep> <sep> Table 1 - Omniglot dataset baselines	B-Reply	B-3	Reply	293
Method             Accuracy	I-Reply	I-3	Reply	293
KNN pixel          48%	I-Reply	I-3	Reply	293
KNN deep         69%	I-Reply	I-3	Reply	293
Mann et al [4]   88%	I-Reply	I-3	Reply	293
ProtoNet            99.7%	I-Reply	I-3	Reply	293
<sep> ‚Äú...not always powerful under different dataset?‚Äù	O	O	Reply	293
For completeness we ran both 1-shot and 5-shot settings and found that our method consistently outperforms the baselines.	B-Reply	B-4	Reply	293
While in 5-shot the improvement is less, this is reasonable since the number of labeled items is larger and the benefit brought by unlabeled items is considerably smaller than in 1-shot settings.	I-Reply	I-4	Reply	293
We disagree with the comment that our model is not robust under different datasets, since the best settings we found is consistent across all three, quite diverse, datasets, including the novel and much larger tieredImageNet.	I-Reply	I-4	Reply	293
<sep> <sep> References:	O	O	Reply	293
[1] ‚ÄúVideo2vec embeddings recognize events when examples are scarce,‚Äù IEEE TPAMI 2014	O	O	Reply	293
[2] ‚ÄúVideostory: A new multimedia embedding for few-example recognition and translation of events,‚Äù in ACM MM, 2014.	O	O	Reply	293
<sep> [3]: Transductive Multi-View Zero-Shot Learning, IEEE TPAMI 2015.	O	O	Reply	293
<sep> [4]: One-shot learning with Memory-Augmented Neural Networks.	O	O	Reply	293
ICML 2016.	O	O	Reply	293

This paper presents a novel multi-scale architecture that achieves a better trade-off speed/accuracy than most of the previous models.	O	O	Review	293
The main idea is to decompose a convolution block into multiple resolutions and trade computation for resolution, i.e. low computation for high resolution representations and higher computation for low resolution representations.	O	O	Review	293
In this way the low resolution can focus on having more layers and channels, but coarsely, while the high resolution can keep all the image details, but with a smaller representation.	O	O	Review	293
The branches (normally two) are merged at the end of each block with linear combination at high resolution.	O	O	Review	293
Results for image classification on ImageNet with different network architectures and for speech recognition on Switchboard show the accuracy and speed of the proposed model.	O	O	Review	293
<sep> <sep> Pros:	O	O	Review	293
- The idea makes sense and it seems GPU friendly in the sense that the FLOPs reduction can be easily converted in a real speed-up	O	O	Review	293
- Results show that the joint use of two resolution can provide better accuracy and lower computational cost, which is normally quite difficult to obtain	O	O	Review	293
- The paper is well written and experiments are well presented.	O	O	Review	293
<sep> - The appendix shows many interesting additional experiments	O	O	Review	293
<sep> Cons:	O	O	Review	293
- The improvement in performance and speed is not exceptional, but steady on all models.	B-Review	B-1	Review	293
<sep> - Alpha and beta seem to be two hyper-parameters that need to be tuned for each layer.	B-Review	B-2	Review	293
<sep> <sep> Overall evaluation:	O	O	Review	293
Globally the paper seems well presented, with an interesting idea and many thorough experiments that show the validity of the approach.	O	O	Review	293
In my opinion this paper deserves to be published.	O	O	Review	293
<sep> <sep> <sep> Additional comments:	O	O	Review	293
- - In the introduction (top of pag.	B-Review	B-3	Review	293
2) and in the contributions, the advantages of this approach are explained in a different manner that can be confusing.	I-Review	I-3	Review	293
More precisely in the introduction the authors say that bL-Net yeald 2x computational saving with better accuracy.	I-Review	I-3	Review	293
In the contributions they say that the savings in computation can be up to 1/2 with no loss in accuracy.	I-Review	I-3	Review	293
<sep> We thank the reviewer for the positive comments on our approach.	O	O	Reply	293
We have revised the manuscript to clarify our contributions in the introduction.	B-Reply	B-3	Reply	293
For the parameters alpha and beta in bLNet, although they could be tuned for each layer, we fixed them (alpha=2 and beta=4) in all our experiments except in the ablation study.	B-Reply	B-2	Reply	293
We found that this universal setting in general leads to good tradeoffs between accuracy and computation cost among all the models consistently.	B-Reply	B-1	Reply	293
In the future, we are interested in exploring reinforcement learning to search for optimal alpha and beta to achieve a better tradeoff.	I-Reply	I-1	Reply	293

The authors propose a new CNN architecture and show results on object and speech recognition.	O	O	Review	293
In particular, they propose a multi-scale CNN module that processes feature maps at various scales.	O	O	Review	293
They show compelling results on IN and a reduction of compute complexity	O	O	Review	293
<sep> Pros:	O	O	Review	293
(+) The paper is well written	O	O	Review	293
(+) The method is elegant and reproducible	O	O	Review	293
(+) Results are compelling and experimentation is thorough	O	O	Review	293
Cons:	O	O	Review	293
(-) Transfer to other visual tasks, beyond IN, is missing	B-Review	B-1	Review	293
(-) Memory requirements are not mentioned, besides FLOPs, speed and parameters	B-Review	B-2	Review	293
<sep> Overall, the proposed approach is elegant and clear.	O	O	Review	293
The impact of the multi-scale module is evident, in terms of FLOPs and performance.	O	O	Review	293
While their approach performs a little worse than NASNet, both in terms of FLOP efficiency and top1-error, it is simpler and easier to train.	B-Review	B-2	Review	293
I'd like for the authors to also discuss memory requirements for training and testing the network.	I-Review	I-2	Review	293
<sep> <sep> Finally, various papers have appeared over the recent years showing improvements over baselines on ImageNet.	B-Review	B-1	Review	293
However, most of these papers are not impactful, because they do not show any impact to other visual tasks, such as detection.	I-Review	I-1	Review	293
On the contrary, methods that do transfer get adopted very fast.	I-Review	I-1	Review	293
I would be much more convinced of this approach, if the authors showed similar performance gains (both in terms of complexity and metrics) for COCO detection.	I-Review	I-1	Review	293
<sep> <sep> We thank the reviewer for the constructive comments.	O	O	Reply	293
<sep> <sep> - Transfer capability of bLNet:	O	O	Reply	293
We used bLNet as a backbone network for feature extraction in the Faster RCNN + FPN detector.	B-Reply	B-1	Reply	293
<sep> The detection results on PASCAL VOC and COCO datasets are included in Table 10 in Appendix A6.	I-Reply	I-1	Reply	293
<sep> Our bLNet achieves comparable or better accuracy than the baseline detectors while reducing FLOPs by about 1.5 times.	I-Reply	I-1	Reply	293
<sep> Please refer to Table 10 in Appendix A6 for more detail.	I-Reply	I-1	Reply	293
<sep> <sep> - Memory requirements of bLNet:	O	O	Reply	293
We benchmarked the GPU memory consumption in runtime at both the training and test phases for all the models evaluated in Fig.3.	B-Reply	B-2	Reply	293
<sep> The results are shown in Fig.5 in Appendix A7.	I-Reply	I-2	Reply	293
The batch size was set to 8, which is the largest number allowed for NASNet on a P100 GPU card (16 GiB memory).	I-Reply	I-2	Reply	293
The image size for any model in this benchmark experiment is the same as that used in the experiment reported in Fig.3.	I-Reply	I-2	Reply	293
For bLNet, the input image size is 224x224 in training and 256x256 in test.	I-Reply	I-2	Reply	293
<sep> <sep> From Fig.5, we can see that bLNet is the most memory-efficient for training among all the approaches.	I-Reply	I-2	Reply	293
<sep> In test, bL-ResNeXt consumes more memory than inception-resnet-v2 and inception-v4 at the same accuracy,	I-Reply	I-2	Reply	293
but bL-SEResNeXt outperforms all the approaches.	I-Reply	I-2	Reply	293
Note that NASNet and PNASNet are not memory friendly.	I-Reply	I-2	Reply	293
<sep> This is largely because they are trained on a larger image size (331x331) and these models are composed of many layers.	I-Reply	I-2	Reply	293

The big-little module is an extension of the multi-scale module.	O	O	Review	293
Different scales takes different complexities: higher complexity for low-scale, and lower complexity for high scale.	O	O	Review	293
Two schemes of merging two branches are also discussed, and the linear combination is empirically better.	O	O	Review	293
<sep> <sep> As expected, the results are better than ResNets, ResNexts, SEResNexts.	O	O	Review	293
I do not have  comments except ablation study is needed to show the results for more choices of alpha, beta, e.g., alpha =1, beta =1.	B-Review	B-1	Review	293
We thank the reviewer for the positive comments on our approach.	O	O	Reply	293
We have included in Table 11 (Page 18) the results of bL-ResNet-50 and bL-ResNet-101 with alpha and beta both set to be 1.	B-Reply	B-1	Reply	293
Not surprisingly, both models achieve the best accuracy, but they also become most costly in computation and are parameter heavy.	I-Reply	I-1	Reply	293

This paper presents the search algorithm A*MCTS to find the optimal policies for problems in Reinforcement Learning.	O	O	Review	293
In particular, A*MCTS combines the A* and MCTS algorithms to use the pre-trained value networks for facilitating the exploration and making optimal decisions.	O	O	Review	293
A*MCTS refers the value network as a black box and builds a statistical model for the prediction accuracies, which provides theoretical guarantees for the sample complexity.	O	O	Review	293
The experiments verify the effectiveness of the proposed A*MCTS.	O	O	Review	293
<sep> <sep> In summary, I think the proposed A*MCTS algorithm is promising to push the frontier of studies of the tree search for optimal actions in RL.	O	O	Review	293
But the experiments should be improved to illustrate the reasons for the hyper-param setting.	B-Review	B-1	Review	293
For example, in Sec.6.2, the authors should give some explanations on why the depth of the tree is set as 10 and the number of children per state is set as 5.	I-Review	I-1	Review	293
<sep> <sep> <sep> Our main focus is on developing a principled prioritized search algorithm with a deep learning component (e.g., Monte Carlo Tree Search algorithm with policy/value network) with provable theoretical guarantees, which is currently lacking in this space.	B-Reply	B-1	Reply	293
The selection of models is not an emphasis of our paper, they mainly offer a sanity check that our algorithm also performs well in practice.	I-Reply	I-1	Reply	293
We set the parameters for the tree so that we would have a reasonable model that could offer a valid sanity check.	I-Reply	I-1	Reply	293

This paper proposes A*MCTS, which combines A* and MCTS with policy and value networks to prioritize the next state to be explored.	O	O	Review	293
It further establishes the sample complexity to determine optimal actions.	O	O	Review	293
Experimental results validate the theoretical analysis and demonstrate the effectiveness of A*MCTS over benchmark MCTS algorithms with value and policy networks.	O	O	Review	293
<sep> <sep> Pros:	O	O	Review	293
This paper presents the first study of tree search for optimal actions in the presence of pretrained value and policy networks.	O	O	Review	293
And it combines A* search with MCTS to improve the performance over the traditional MCTS approaches based on UCT or PUCT tree policies.	O	O	Review	293
Experimental results show that the proposed algorithm outperform the MCTS algorithms.	O	O	Review	293
<sep> <sep> Cons:	O	O	Review	293
However, there are several issues that should be addressed including the presentation of the paper:	O	O	Review	293
‚Ä¢<tab>The algorithm seeks to combine A* search with MCTS (combined with policy and value networks), and is shown to outperform the baseline MCTS method.	B-Review	B-1	Review	293
However, it does not clearly explain the key insights of why it could perform better.	I-Review	I-1	Review	293
For example, what kind of additional benefit will it bring when integrating the priority queue into the MCTS algorithms?	I-Review	I-1	Review	293
How could it improve over the traditional tree policy (e.g., UCT) for the selection step in MCTS?	I-Review	I-1	Review	293
These discussions are critical to understand the merit of the proposed algorithms.	I-Review	I-1	Review	293
In addition, more experimental analysis should also be presented to support why such a combination is the key contribution to the performance gain.	I-Review	I-1	Review	293
<sep> ‚Ä¢<tab>Many design choices for the algorithms are not clearly explained.	B-Review	B-2	Review	293
For example, in line 8 of Algorithm 2, why only the top 3 child nodes are added to the queue?	I-Review	I-2	Review	293
<sep> ‚Ä¢<tab>The complexity bound in Theorem 1 is hard to understand.	B-Review	B-3	Review	293
It does not give the explicit relations of the sample complexity with respect to different quantities in the algorithms.	I-Review	I-3	Review	293
In particular, the probability in the second term of Theorem 1 is hard to parse.	I-Review	I-3	Review	293
The authors need to give more discussion and explanation about it.	I-Review	I-3	Review	293
This is also the case for Theorems 2-4.	I-Review	I-3	Review	293
The authors give some concrete examples in Section 6.2 for these bounds.	I-Review	I-3	Review	293
However, it would be better to have some discussion earlier right after these theorems are presented.	I-Review	I-3	Review	293
<sep> ‚Ä¢<tab>The experimental results are carried out under the very simplified settings for both the proposed algorithm and the baseline MCTS.	B-Review	B-4	Review	293
In fact, it is performed under the exact assumption where the theoretical analysis is done for the A*MCTS.	I-Review	I-4	Review	293
This may bring some advantage for the proposed algorithm.	I-Review	I-4	Review	293
It is not clear whether such assumptions hold for practical problems.	I-Review	I-4	Review	293
More convincing experimental comparison should be done under real environment such as Atari games (by using the simulator as the environment model as shown in [Guo et al 2014] ‚ÄúDeep learning for real-time atari game play using offline monte-carlo tree search planning‚Äù).	I-Review	I-4	Review	293
<sep> Other comments:	O	O	Review	293
‚Ä¢<tab>It is assumed that the noise of value and policy network is zero at the leaf node.	B-Review	B-5	Review	293
In practice, this is not true because even at the leaf node the value could still be estimated by an inaccurate value network (e.g., AlphaGo or AlphaZero).	I-Review	I-5	Review	293
How would this affect the results?	I-Review	I-5	Review	293
<sep> ‚Ä¢<tab>In fact, the proof of the theorems could be moved to appendices.	I-Review	I-5	Review	293
<sep> ‚Ä¢<tab>In the first paragraph of Section 6.2, there is a typo: V*=V_{l*}=\eta should be V*-V_{l*}=\eta ?	I-Review	I-5	Review	293
We address the concerns in the "Cons" section in order.	O	O	Reply	293
<sep> <sep> 1. [	O	O	Reply	293
Our scheme vs MCTS] We hypothesize that the averaging in the back-propagation step in MCTS is ineffective, since the goal is to estimate the value of the optimal policy, any averaging will inevitably bring down this value.	B-Reply	B-1	Reply	293
Note that back propagation in classical value iteration, for example, takes the max, rather than the average of the different Q values.	I-Reply	I-1	Reply	293
Our technique does not use the averaging scheme in MCTS.	I-Reply	I-1	Reply	293
<sep> <sep> However, we are hesitant to put such a big emphasis on this intuition because there is little theoretical understanding behind MCTS and UCT applied on the entire search tree.	I-Reply	I-1	Reply	293
It could be possible that the averaging could alleviate some issues in MCTS (e.g., when the value function of a node over-estimates).	I-Reply	I-1	Reply	293
While we leave this to future work, the main goal of our work is to provide a tree search algorithm with provable guarantees that also works well in practice, and we think that our contribution is valuable to the ICLR community.	I-Reply	I-1	Reply	293
<sep> <sep> 2.	B-Reply	B-2	Reply	293
Line 8 of Algorithm 2 has an ‚Äúor‚Äù condition which is crucial, we do not just add the top 3 child nodes.	I-Reply	I-2	Reply	293
Depending on the probabilities given by the policy network, we may add all the children nodes to the queue.	I-Reply	I-2	Reply	293
We add the top 2 (ordered by the probabilities given by the policy network) to the queue by default.	I-Reply	I-2	Reply	293
For the k-th child node, where k &gt; 2, we add this child if there is a small gap between the probability of the k-1-th child and the probability of the top child, as given by the policy network, where the threshold for the gap is given by the noise model.	I-Reply	I-2	Reply	293
Intuitively, we are saying that if the gap is sufficiently big, even after accounting for the noise in the policy network, there is no way that this k-th child is part of the optimal policy, so we do not have to add it to the queue.	I-Reply	I-2	Reply	293
The proof for Theorem 2 establishes in Section 4.1 why our condition is sufficient.	I-Reply	I-2	Reply	293
We can add more explanation for this.	I-Reply	I-2	Reply	293
<sep> <sep> 3.	O	O	Reply	293
The complexity bound in Theorem 1 is actually based on one very simple observation, which we explain in the proof of Theorem 1.	B-Reply	B-3	Reply	293
A sub-optimal internal node s is chosen if V^* &lt;= U_s + c_d = V_s + X_s + c_d.	I-Reply	I-3	Reply	293
U_s is the value network estimate for state s, c_d is the upper bound on the possible error for the value estimate.	I-Reply	I-3	Reply	293
So we end up choosing a sub-optimal node if the value network estimate plus the upper bound on the possible error (optimism) is higher than the true optimal value.	I-Reply	I-3	Reply	293
Otherwise we will not choose to expand that node, since we are sure that it will not be the optimal node.	I-Reply	I-3	Reply	293
U_s is equal to V_s (true value of node s) plus X_s, which is the noise random variable.	I-Reply	I-3	Reply	293
V^* - V_s is the expression for the gap of state s, therefore we end up with the expression in Theorem 1.	I-Reply	I-3	Reply	293
Notice that we should also account for the ancestors of s, if we are lucky enough to be able to rule out one of the ancestors of s, we would never expand beyond that ancestor to reach s, and s would not be in our priority queue.	I-Reply	I-3	Reply	293
We can give more explanation (and/or provide graphical illustration) on this in the manuscript, and we can introduce the concrete examples earlier.	I-Reply	I-3	Reply	293
<sep> 4. [	O	O	Reply	293
On experiments] We give a general analysis for A*MCTS in our main theorems that can be applied to a broad range of problems and models.	B-Reply	B-4	Reply	293
In this paper, our main focus is on developing a principled search algorithm and providing provable theoretical guarantees, which is completely lacking in this space.	I-Reply	I-4	Reply	293
The selection of models is not an emphasis of our paper, they mainly offer a sanity check that our algorithm also performs well in practice.	I-Reply	I-4	Reply	293
That being said, we will definitely perform more elaborate experiments in the real situations (e.g., Atari or even self-play in AlphaZero) in the future work.	I-Reply	I-4	Reply	293
<sep> <sep> 5.	O	O	Reply	293
We can handle the case where there is error even at the leaf node.	B-Reply	B-5	Reply	293
If there is error even at the leaf node, then our scheme would produce an approximation of the optimal value and an approximately optimal policy, this would be exactly similar to the results in Section 5.	I-Reply	I-5	Reply	293
In Section 5, we consider the use case where we are willing to tolerate an approximately optimal policy and an approximately optimal value estimate, this basically means that we are willing to stop at a depth, where the noise at level is smaller than the approximation tolerance.	I-Reply	I-5	Reply	293
When there is error even at the leaf nodes, then we will find an approximately optimal policy and value estimate, where the approximation depends on the error at the leaf nodes.	I-Reply	I-5	Reply	293
It also makes sense, intuitively, that getting an approximation is the best that one can hope for when there is error even at the leaf nodes.	I-Reply	I-5	Reply	293

The paper presents a novel search algorithm that uses the policy and value predictors to guide search and provides theoretical guarantee on the sample complexity.	O	O	Review	293
The aim is to estimate the optimal value of an initial state as well as the one-step optimal action to take.	O	O	Review	293
<sep> The algorithm uses a priority queue to store all states being visited so far and picks the most optimistic one to expand, according to an upper confidence bound heuristic function.	O	O	Review	293
The algorithm assumes access to pre-trained value and policy networks and it uses calls to these networks to prioritize the next state to be explored.	O	O	Review	293
<sep> <sep> The authors consider a very restrictive setting:	B-Review	B-1	Review	293
- Finite horizon Markov decision tree:  no backtrack	I-Review	I-1	Review	293
- No intermediate reward and only reward at the end of the episode.	I-Review	I-1	Review	293
<sep> - Deterministic transition	I-Review	I-1	Review	293
- Importantly, access to value network that gives noisy estimates of the optimal value function	I-Review	I-1	Review	293
- The noise model is additive and i.i.d and satisfies a concentration inequality	I-Review	I-1	Review	293
<sep> All this assumption makes the setting very simple and unrealistic.	I-Review	I-1	Review	293
Moreover, I think we can frame the problem into bandit problem and solve it easily with sample complexity independent of the horizon D.	I-Review	I-1	Review	293
In fact, given an initial state s, we consider the K possible actions  a_1, a_2, ‚Ä¶, a_K that lead deterministically to next states (r_1, r_2, ‚Ä¶, r_K).	I-Review	I-1	Review	293
As the intermediate reward is zero, the state-action value of (s, a_k) is equal to V_{r_k}. As we have noisy estimates of V_{r_k} and we know precisely the noise model, we can run UCB-like algorithm for multi-armed bandit where each arm corresponds to action a_k and expected reward correspond to V_{r_k}. This determines the optimal action in constant time with respect to the horizon.	I-Review	I-1	Review	293
We think that this reviewer misunderstood our problem setting.	B-Reply	B-1	Reply	293
The value network is a pre-trained and *deterministic* function that outputs the same value estimate for a particular node, no matter how many times it is called.	I-Reply	I-1	Reply	293
This is standard in applications like AlphaZero.	I-Reply	I-1	Reply	293
In our formulation, the noise random variable was instantiated once at each particular node and is fixed afterwards.	I-Reply	I-1	Reply	293
Therefore, one cannot call the value network repeatedly on the same node and average over the results to achieve the true value.	I-Reply	I-1	Reply	293
Instead, one must expand further down to children nodes, because the value network estimates for the children nodes are less noisy.	I-Reply	I-1	Reply	293
<sep> <sep> The finite horizon Markov Decision tree is standard in applications, in our opinion.	I-Reply	I-1	Reply	293
We are not aware of any study on infinite horizon Markov Decision trees.	I-Reply	I-1	Reply	293
<sep> <sep> We are not sure what you mean by ‚Äúno backtracking‚Äù.	I-Reply	I-1	Reply	293
If you mean the averaging operation following the parents from a new node in the regular MCTS, our algorithm also has it, by always replacing the old value of a node with the new one from more accurate child estimates.	I-Reply	I-1	Reply	293
<sep> <sep> The transition and reward assumptions are valid for a lot of applications, ie games.	I-Reply	I-1	Reply	293
These assumptions are also a good starting point on which to develop our results because they make the problem simpler while preserving the main challenges that we want to tackle.	I-Reply	I-1	Reply	293
The value network that we assume in our paper is increasingly becoming an integral part of deep reinforcement learning.	I-Reply	I-1	Reply	293

This paper tackles the task of automatically inducing a curriculum for agents learning through reinforcement.	O	O	Review	10171
Specifically, they use two agents ‚Äî a setter agent that sets goals, and a solver agent that solves the goals provided by the setter.	O	O	Review	10171
While this has been explored before, the difficulty lies in training both agents simultaneously in a robust fashion.	O	O	Review	10171
If the goals are too difficult, the solver will be unable to solve them and if they are too easy, the solver will be unable to improve.	O	O	Review	10171
The authors propose a combination of different losses to help the setter balance its goal predictions ‚Äî validity, feasibility and coverage.	O	O	Review	10171
In addition, they train a judge model predict the reward that the solver agent would achieve on a goal proposed by the setter.	O	O	Review	10171
Empirical results on two setups demonstrate the effectiveness of this approach in learning a good curriculum.	O	O	Review	10171
<sep> <sep> Pros:	O	O	Review	10171
1.	O	O	Review	10171
Clear writing, method is easy to understand.	O	O	Review	10171
<sep> 2.	O	O	Review	10171
Novel objectives for a multi-agent training setup	O	O	Review	10171
<sep> Cons:	O	O	Review	10171
1.	O	O	Review	10171
Empirical results do not contain any baselines or prior work comparisons (only ablations of the proposed model)	B-Review	B-1	Review	10171
<sep> ‚Äî‚Äî	O	O	Review	10171
Updates:	O	O	Review	10171
Thanks to the authors for their response.	O	O	Review	10171
I realize I was not very clear in my comment above.	B-Review	B-1	Review	10171
I wanted to point out that the authors could consider adding other (simpler) baselines such as Sukhbaatar et al (2017) to make their empirical results more complete for the navigation tasks (even though these methods make certain assumptions, it would be interesting to see how much of an effect they have compared to the proposed method).	I-Review	I-1	Review	10171
If you are able to, I‚Äôm convinced the paper will be much stronger.	I-Review	I-1	Review	10171
Nevertheless, I think this is very interesting work!	I-Review	I-1	Review	10171
Thank you for the thoughtful comments.	O	O	Reply	10171
We would like to highlight that we empirically compare our basic approach to prior work in section 4.4, and show that in complex environments it outperforms a recent approach to automated curriculum generation for goal-conditioned RL.	B-Reply	B-1	Reply	10171
In fig.8 in the supplemental material, we explore part of the reason for this, showing that our approach to curriculum generation more reliably produces tasks that challenge the solver in the complex environments.	I-Reply	I-1	Reply	10171
<sep> <sep> We are not aware of any other prior work that can generate automated curricula for goal-conditioned RL in a variable environment, or that optimizes the curriculum towards a desired goal distribution, and so we were unable to compare to prior work in that setting.	I-Reply	I-1	Reply	10171
We think part of the contribution of our paper is to highlight these challenges and hopefully inspire further work in this area.	I-Reply	I-1	Reply	10171

This paper proposes an autocurricula scheme to train a goal-conditional agent in a dynamic and sparse-rewarding environment.	O	O	Review	10171
The main idea is to train a setter model to sample goals for next-step training, where the setter can make the decision either based on the training history or the environmental observation (conditional case).	O	O	Review	10171
The paper proposes three criteria which leads to three types of loss to train the setter model, i.e., goal validity (the goal should be achievable by some existing policy), goal feasibility (how probable the current policy can achieve the goal), and goal coverage (the sampled goals by the setter need to cover all possible goals).	O	O	Review	10171
A judge model is needed to output the feasibility of a given goal.	O	O	Review	10171
So the autocurricula scheme contains the solver (agent), the setter, and the judge, each having its own combination of loss and they are trained together.	O	O	Review	10171
Given a desired goal distribution, the paper proposes to additionally train a discriminator whose optimization objective is Wasserstein loss.	O	O	Review	10171
In experiments, they evaluate the proposed method on three types of tasks in two environments, i.e., 3D color finding and grid world alchemy.	O	O	Review	10171
The goals in the two environments are similar in that they all aim to achieve some color or color pairs.	O	O	Review	10171
The difference lies in that the first one finds colors while the second pick up colors.	O	O	Review	10171
Each environment can be changed between episodes by changing the colors of objects in the scenes.	O	O	Review	10171
Experimental results show that different combinations of the three types of losses can bring improvements in some scenarios.	O	O	Review	10171
Making setter and judge conditioned on environment observation can further improve the success rate.	O	O	Review	10171
Given a desired distribution of goals, the learning becomes more efficient.	O	O	Review	10171
The paper compares this method with Goal GAN as a baseline and outperforms it on the three tasks.	O	O	Review	10171
<sep> <sep> This paper is an early exploration of the effectiveness of autocurricula on goal-conditional tasks.	O	O	Review	10171
The experiments to some extent verify the effectiveness of the proposed method.	O	O	Review	10171
The high-level idea of setter-solver learning can be possibly generalized to other tasks.	B-Review	B-1	Review	10171
However, it is not convincing that the detailed techniques proposed in this paper can be easily generalized to more complicated environments and tasks.	I-Review	I-1	Review	10171
The writing of this paper is not clear and enough and the whole paper is difficult to understand.	I-Review	I-1	Review	10171
The experimental comparison is insufficient since only one baseline of curriculum (goal GAN) is compared (some of the methods mentioned in Section 2 can be easily applied though some of them were not specifically designed for goal-conditional tasks).	I-Review	I-1	Review	10171
<sep> <sep> Detailed comments:	O	O	Review	10171
<sep> 1) There are too many details and hyperparameters involved when applied to specific tasks as shown in this paper.	B-Review	B-1	Review	10171
Considering the two environments in this paper is easier than most game environments studied in other papers (many of them also uses some types of the curriculum), the experimental result is not very strong.	I-Review	I-1	Review	10171
The proposed scheme is possible to be too simple for a slightly more complicated environment or task.	I-Review	I-1	Review	10171
<sep> <sep> 2) The success of training relies on interactions between the three to four types of losses, but they all have the same weights in the combined loss.	B-Review	B-2	Review	10171
Is there any special reason for not setting different weights for different losses?	I-Review	I-2	Review	10171
<sep> <sep> 3) It is not clear how the inverse transform of the setter model (i.e., S^{-1} in L_val) is achieved.	B-Review	B-3	Review	10171
<sep> <sep> 4) There are three random quantities involved in the loss terms, i.e., the noise \xi applied to the sampled goals, the latent input z, the feasibility f. It is not clear whether the randomness on them will dominate the curriculum or not.	B-Review	B-4	Review	10171
<sep> <sep> 5) The setter model takes z and f as inputs, where z is a vector but f is a scalar.	B-Review	B-5	Review	10171
Will it result in a setter model whose output does not change too much when changing f?	I-Review	I-5	Review	10171
<sep> <sep> 6) How does the proposed method compare to simple goal selection by uncertainty, hardness, or curiosity?	B-Review	B-6	Review	10171
How does it compare to hindsight experience reply methods?	I-Review	I-6	Review	10171
<sep> <sep> 7) It is helpful to visualize the generated curriculum, i.e., the trajectory of selected goals during training in the 2D/3D grid.	B-Review	B-7	Review	10171
<sep> <sep> 8) Computing L_judge requires to test whether the agent can finally achieve the sampled goals.	B-Review	B-8	Review	10171
Is it too computational expensive during training?	I-Review	I-8	Review	10171
<sep> <sep> ---------------------------	O	O	Review	10171
<sep> Update after rebuttal:	O	O	Review	10171
<sep> Thanks for the detailed reply from the authors!	O	O	Review	10171
They answer most of my questions.	O	O	Review	10171
I think this paper has a moderate contribution and thus will keep my "weakly accept" rating.	O	O	Review	10171
Thank you for the detailed and thoughtful review.	O	O	Reply	10171
We respond to your comments inline below.	O	O	Reply	10171
<sep> <sep> 1) There are too many details and hyperparameters involved when applied to specific tasks as shown in this paper.	O	O	Reply	10171
Considering the two environments in this paper is easier than most game environments studied in other papers (many of them also uses some types of curriculum), the experimental result is not very strong.	O	O	Reply	10171
The proposed scheme is possible to be too simple for a slightly more complicated environment or task.	O	O	Reply	10171
<sep> <sep> We believe our results represent a substantial increase in complexity beyond the environments used in prior work.	B-Reply	B-1	Reply	10171
Indeed, our comparison to a prior paper in section 4.4 (and the analysis of it in supplemental fig.8) shows that in simple tasks like those used in the prior work their algorithm performs comparably to ours, but that the complicated version of our tasks are complex enough that their algorithm fails.	I-Reply	I-1	Reply	10171
Recent exploration-based pretraining, like Diversity is All You Need, has also used relatively simple environments, such as simple control tasks.	I-Reply	I-1	Reply	10171
Furthermore, we are not aware of any prior work that considers goal-conditioned tasks with variable environments, or targets desired goals.	I-Reply	I-1	Reply	10171
While we have not demonstrated these results on a task as complex as starcraft, say, we believe they nevertheless represent a substantial increase in the complexity of the environments on which automated curriculum generation schemes have been demonstrated.	I-Reply	I-1	Reply	10171
We hope that our paper, if accepted, will help to inspire further work tackling even more complex tasks.	I-Reply	I-1	Reply	10171
<sep> <sep> 2) The success of training relies on interactions between the three to four types of losses, but they all have the same weights in the combined loss.	O	O	Reply	10171
Is there any special reason for not setting different weights for different losses?	O	O	Reply	10171
<sep> <sep> We found that this was not necessary for the three basic losses, and so we did not add these additional hyperparameters.	B-Reply	B-2	Reply	10171
However, we did need to increase the weight slightly for the desirability loss in order for it to have a similar magnitude to the other losses and perform optimally.	I-Reply	I-2	Reply	10171
This is the hyperparameter Beta_{des} noted in the description of the desired goal distributions loss, and the exact values used are given in appendix C.	I-Reply	I-2	Reply	10171
<sep> 3) It is not clear how the inverse transform of the setter model (i.e., S^{-1} in L_val) is achieved.	O	O	Reply	10171
<sep> <sep> The setter model is an Real-valued Non-volume preserving generative model (<a href="https://arxiv.org/pdf/1605.08803.pdf)," target="_blank" rel="nofollow">https://arxiv.org/pdf/1605.08803.pdf),</a> one of the benefits of this model class is that it allows exact inference of the latents given a sample (i.e. exact inversion of the model).	B-Reply	B-3	Reply	10171
We have added a section in the appendix briefly explaining how and why these models are invertible.	I-Reply	I-3	Reply	10171
<sep> <sep> 4) There are three random quantities involved in the loss terms, i.e., the noise \xi applied to the sampled goals, the latent input z, the feasibility f. It is not clear whether the randomness on them will dominate the curriculum or not.	O	O	Reply	10171
<sep> <sep> The noise applied to the sampled goals is quite small, and is only used for training the setter.	B-Reply	B-4	Reply	10171
While the randomness of z and f presumably contributes to the success of the curriculum, we would like to note a few observations that suggest it is not the primary driving factor: 1) Uniformly randomly sampled tasks result in little to no solver learning in our environments (this is shown in Fig.4 for the observation conditioned case, e.g., and we also observed it in the basic tasks).	I-Reply	I-4	Reply	10171
2) The coverage loss alone, which increases the randomness of the setter outputs, does not alone result in any learning on the color pair finding or alchemy tasks (although it is reasonably successful in the single-color-finding task).	I-Reply	I-4	Reply	10171
3) Removing the coverage loss results in no learning in the color-pair finding environment, suggesting that the randomness of the setter inputs is not enough to result in good learning without equally random outputs.	I-Reply	I-4	Reply	10171
4) As we show in our response to your next question, f is not just a source of randomness, but the setter is actually using it to choose tasks of variable difficulty for the solver.	I-Reply	I-4	Reply	10171
<sep> <sep> (Continued in next comment, due to character limit.)	O	O	Reply	10171

The paper studied the problem of reinforcement learning under the sparse or dynamic rewarding environment.	O	O	Review	10171
<sep> The authors propose a promising automated curricula generation scheme, which considers goal validity, goal	O	O	Review	10171
feasibility, and goal coverage to construct useful curricula for the underlying agents.	O	O	Review	10171
Rewards and loss functions	O	O	Review	10171
are proposed individually for the solver, judge, and setter.	O	O	Review	10171
Empirical studies demonstrate the capability of the	O	O	Review	10171
proposed model in generating task curricula across several complex goals.	O	O	Review	10171
In general, I believe the studied	O	O	Review	10171
problem is interesting, and the proposed model is promising.	O	O	Review	10171
However, I am not familiar with the curricula	O	O	Review	10171
generation in the reinforcement learning setting.	O	O	Review	10171
All I can say is the approach is intuitively appealing, the text is	O	O	Review	10171
well written and easy to follow, even for an outsider.	O	O	Review	10171
A minor concern is about the experiments.	O	O	Review	10171
Most of the	O	O	Review	10171
experiments are presented in the metric of Reward (% of best).	B-Review	B-1	Review	10171
It would be helpful if the authors can conduct	I-Review	I-1	Review	10171
some illustrative case studies (better in different scenarios) to show some specific tasks, the generated task-oriented	I-Review	I-1	Review	10171
curriculum, and provide some intuitive discussion to show the readers why the generated curriculum is beneficial	I-Review	I-1	Review	10171
for the agent.	I-Review	I-1	Review	10171
Thank you for the thoughtful review!	O	O	Reply	10171
We appreciate your comments.	O	O	Reply	10171
We‚Äôve included a plot of the progression of the curriculum on the 2D location finding task in the appendix, which shows how the setter first learns to propose locations closest to the agent, and then gradually expand them throughout the entire valid space the agent can explore.	B-Reply	B-1	Reply	10171
We hope that this is a useful case study for seeing that our setter algorithm is behaving basically sensibly.	I-Reply	I-1	Reply	10171
<sep> <sep> It is more difficult to visualize the curricula for the color tasks, since the task spaces are higher dimensional.	I-Reply	I-1	Reply	10171
However, we think that there are intuitive reasons a curriculum might work in the color-pair finding tasks.	I-Reply	I-1	Reply	10171
The setter could learn to first generate matching colors in the two pairs at first, to effectively reduce the problem to the easier one-color finding problem initially.	I-Reply	I-1	Reply	10171
It could then first generate simple goals for the agent to achieve that are relatively easy, such as looking at the ceiling or the floor.	I-Reply	I-1	Reply	10171
Then it could move on to generate more complex goals, such as finding different colors that only appear on rare objects within the room, and to finding simple pairs, such as a two colors that always appear next to each other, like a piece of furniture next to a wall.	I-Reply	I-1	Reply	10171
This would finally allow for learning the most complex combinations, one rare color next to another, one of which is demonstrated in the video linked from the paper.	I-Reply	I-1	Reply	10171
Hopefully this helps guide your intuitions.	I-Reply	I-1	Reply	10171

The paper presents an architecture to parallelize the optimization of nested functions based on the method of auxiliary coordinates (MAC) (Carreira-Perpinan and Wang, 2012).	O	O	Review	594
This method decomposes the optimization into training individual layers and updating the auxiliary coordinates.	O	O	Review	594
The paper focuses on binary autoencoders and proposes to partition the data onto several machines allowing the parameters to move between machines.	O	O	Review	594
Relatively good speedup factors are reported especially on larger datasets and a theoretical model of performance is presented that matches with the experiments.	O	O	Review	594
<sep> <sep> My main concern is that even though the method is presented as a general framework for nested functions, experiments focus on a restricted family of models (i.e. binary autoencoders with linear or kernel encoders and linear decoders) with only two components.	O	O	Review	594
While the speedup factors are encouraging, it is hard to get a sense of their importance as the binary autoencoder model considered is not well studied by other researchers and is not widely used.	O	O	Review	594
I encourage the authors to apply this framework to more generic architectures and problems.	O	O	Review	594
<sep> <sep> Questions:	O	O	Review	594
1- Does this framework apply to some form of generic multi-layer neural network?	B-Review	B-1	Review	594
If so, some experimental results are useful.	I-Review	I-1	Review	594
<sep> 2- What is the implication of applying this framework to more than two components (an encoder and a decoder) and non-linear components?	B-Review	B-2	Review	594
<sep> 3- It is desired to see a plot of performance as a function of time for different setups to demonstrate the speedup after convergence.	B-Review	B-3	Review	594
It seems the paper only focuses on the speedup factors per iteration.	I-Review	I-3	Review	594
For example, increasing the mini-batch size may improve the speed per iteration but may hurt the convergence speed.	I-Review	I-3	Review	594
<sep> 4- Did you consider a scenario where the dataset is too big that storing the data and auxiliary variables on multiple machines simultaneously is not possible?	B-Review	B-4	Review	594
<sep> <sep> The paper cites an ArXiv manuscript with the same title by the authors multiple times.	O	O	Review	594
Please make the paper self-contained and include any supplementary material in the appendix.	O	O	Review	594
<sep> <sep> I believe without applying this framework to a more generic architecture beyond binary autoencoders, this paper does not appeal to a wide audience at ICLR, hence weak reject.	O	O	Review	594
<sep> <sep> Regarding the choice of the binary autoencoder for the experiments, see our "response to reviewers".	O	O	Reply	594
Regarding your other questions:	O	O	Reply	594
1,2- The framework does apply to generic multilayer networks.	B-Reply	B-2	Reply	594
See our response to "Q: what are the benefits of the distributed optimization for deep models in general?"	I-Reply	I-2	Reply	594
from AnonReviewer1.	I-Reply	I-2	Reply	594
With more components (layers), there will be more submodels in the M step and so more parallelism.	I-Reply	I-2	Reply	594
<sep> 3- You make a good point (how a parameter affects the total runtime of the algorithm), but one that concerns MAC rather than ParMAC.	B-Reply	B-3	Reply	594
The focus of this paper was to propose a distributed framework for MAC, ParMAC, and understand its parallel speedup.	I-Reply	I-3	Reply	594
That said, we did give the total runtimes for all our experiments, besides the speedup achieved.	I-Reply	I-3	Reply	594
<sep> 4- "Scenario where the dataset is too big...".	B-Reply	B-4	Reply	594
For the binary autoencoder this is not an issue because the auxiliary variables take very little space.	I-Reply	I-4	Reply	594
For a deep net the auxiliary coordinates' size can be comparable to that of the training set (depending on the net architecture).	I-Reply	I-4	Reply	594
Whether this is an issue depends on how much memory/disk space is at a premium in the application under consideration.	I-Reply	I-4	Reply	594
We think the ability to achieve high speedups by adding extra machines will compensate.	I-Reply	I-4	Reply	594

UPDATE:	O	O	Review	594
I looked at the arxiv version of the paper.	O	O	Review	594
It is much longer and appears more rigorous.	O	O	Review	594
Fig 3 there is indeed more insightful.	O	O	Review	594
<sep> However, I am reviewing the submission and my overall assessment does not change.	O	O	Review	594
This is not a minor incremental contribution, and if you want to compress it into a conference submission of this type, I would recommend choosing message you want to convey, and focus on that.	O	O	Review	594
As you say, "...ICLR submission focus on the ParMAC algorithm...", I would focus on this properly - and remove or move to appendix all extensions and theoretical remarks, and have an extra page on explaining the algorithm.	O	O	Review	594
Additionally, make sure to clearly explain the relation of the arxiv paper, in particular that the submission was a compressed version.	O	O	Review	594
<sep> <sep> ORIGINAL REVIEW:	O	O	Review	594
The submission proposes ParMAC, based on MAC (Method of Auxiliary Coordinates), formulating a distributed variant of the idea.	O	O	Review	594
<sep> <sep> Related Work: In the part on convex ERM and methods, I would recommend citing general communication efficient frameworks, COCOA (Ma et al) and AIDE (Reddi et al).	O	O	Review	594
I believe these works are most related to the practical objectives authors of this paper set, while number of the papers cited are less relevant.	O	O	Review	594
<sep> <sep> Section 2, explaining MAC, is quite clearly written, but I do not find part on MAC and EM particularly useful.	B-Review	B-1	Review	594
<sep> <sep> Section 3 is much less clearly written.	B-Review	B-2	Review	594
I have trouble following notation, particularly in the speedups part, as different symbols were introduced at different places.	I-Review	I-2	Review	594
Perhaps a quick summary or paragraph on notation in the introduction would be helpful.	I-Review	I-2	Review	594
In paragraph 2, you write as if reader knew how data/anything is distributed, but this was not mentioned yet; it is specified later.	I-Review	I-2	Review	594
It is not clear what is meant by "submodel".	I-Review	I-2	Review	594
Perhaps a more precise example pointing back to eqs (1) & (2) would be useful.	I-Review	I-2	Review	594
As far as I understand from what is written, there are P independent sets of submodels, that traverse the machines in circular fashion.	I-Review	I-2	Review	594
I don't understand how are they initialized (identically?),	I-Review	I-2	Review	594
and more importantly I don't understand what would be a single output of the algorithm (averaging?	I-Review	I-2	Review	594
does not seem to make sense).	I-Review	I-2	Review	594
Since this is not addressed, I suppose I get it wrong, leaving me to guess what was actually meant.	I-Review	I-2	Review	594
<sep> The fact that I am not able to understand what is actually happening, I see as major issue.	O	O	Review	594
<sep> <sep> I don't like the later paragraphs on extensions, model for speedup, convergence and topologies.	B-Review	B-3	Review	594
I don't understand whether these are novel contributions or not, as the authors refer to other work for details.	I-Review	I-3	Review	594
If these are novel, the explanation is not sufficient, particularly speedup part, which contains undefined quantities, e.g. T(P) (or I can't find it).	I-Review	I-3	Review	594
If this is not novel, It does not provide enough explanation to understand anything more, compared with a its version compressed to 1/4 of its size and referring to the other work.	I-Review	I-3	Review	594
The statement that we can recover the original convergence guarantees seems strong and I don't see why it should be trivial to show (but author point to other work which I did not look at).	I-Review	I-3	Review	594
In topologies part, claiming that something does "true SGD", without explaining what is "true SGD" seems very strange.	I-Review	I-3	Review	594
Other statements in this section seem also very vague and unjustified/unexplained.	I-Review	I-3	Review	594
<sep> <sep> Experimental section seems to suggest that the method is interesting for binary autoencoders, but I don't see how would I conclude anything about any other models.	B-Review	B-4	Review	594
ParMAC is also not compared to alternative methods, only with itself, focusing on scaling properties.	I-Review	I-4	Review	594
<sep> <sep> Conclusion contains statements that are too strong or misleading based on what I saw.	B-Review	B-5	Review	594
In particular, "we analysed its parallel speedup and convergence" seems ungrounded.	I-Review	I-5	Review	594
Further, the claim "The convergence properties of MAC remain essentially unaltered in ParMAC" is unsupported, regardless of the meaning of "essentially unchanged".	I-Review	I-5	Review	594
<sep> <sep> In summary, the method seems relevant for particular model class, binary autoencoders, but clarity of presentation is insufficient - I wouldn't be able to recreate the algorithm used in experiments - and the paper contains a number of questionable claims.	O	O	Review	594
Regarding clarity of presentation, we regret you didn't find the paper sufficiently clear and thank you for your suggestions.	O	O	Reply	594
We tried to make it approachable and point to the longer arXiv version as needed.	O	O	Reply	594
But, given the MAC and ParMAC frameworks are very different from the standard practice (backpropagation, SGD, GPUs, etc.),	O	O	Reply	594
this is bound to be a denser than usual paper.	O	O	Reply	594
We do find the analogy of MAC and EM very helpful in order to explain how ParMAC works based on our experience in describing this work to people who are familiar with EM (this would include most machine learning researchers).	O	O	Reply	594
In particular, it should help understand the notion of "submodels" and "coordinates" (since what these exactly are depends on the model used).	O	O	Reply	594
<sep> <sep> We try to answer your specific questions, as follows.	O	O	Reply	594
<sep> <sep> - Firstly, the notion of submodels only applies during a W step.	B-Reply	B-2	Reply	594
In the Z step, we have a single model, the binary autoencoder.	I-Reply	I-2	Reply	594
In the W step, this single model splits into submodels because the objective function additively separates given Z.	I-Reply	I-2	Reply	594
<sep> - There are M (not P) independent submodels and P processors.	B-Reply	B-2	Reply	594
Each submodel indeed traverses the machines in circular fashion (in the W step).	I-Reply	I-2	Reply	594
<sep> <sep> - Crucially, each submodel is trained on different data (different input dimensions or different output dimensions), so different submodels will differ at the end of the W step.	B-Reply	B-2	Reply	594
Specifically, each encoder l has the same input vector x but a different output bit z_l; and each decoder d has the same input vector z but a different output dimension x_d (see pseudocode in fig.1).	I-Reply	I-2	Reply	594
<sep> In the analogy with EM, each Gaussian (= submodel) trains on different data: the training points, and the posterior probabilities (= auxiliary coordinates), which are different for each Gaussian.	I-Reply	I-2	Reply	594
<sep> <sep> - Initialisation of each submodel: from PCA.	B-Reply	B-2	Reply	594
But, since different submodels train on different data, they will differ anyway.	I-Reply	I-2	Reply	594
Besides, in the binary autoencoder), each submodel is a convex problem (encoder = a binary SVM, decoder = a linear regressor).	I-Reply	I-2	Reply	594
<sep> <sep> - "what would be a single output of the algorithm?":	B-Reply	B-2	Reply	594
we don't understand what you mean, but hopefully the above explanation has cleared this up.	I-Reply	I-2	Reply	594
There is one overall model (the binary autoencoder), it's just that during the W step it splits into M independently trained submodels (L encoders, D decoders), given the training data and auxiliary coordinates.	I-Reply	I-2	Reply	594
<sep> Perhaps fig.3 in the arXiv paper (which works best as an animation) may help you understand better the training of the independent submodels in the W step.	I-Reply	I-2	Reply	594
<sep> <sep> - "later paragraphs on extensions, model for speedup, >convergence and topologies": all those parts are novel contributions indeed and are more fully explained in the arXiv paper.	B-Reply	B-3	Reply	594
Unfortunately we can't fit all the details in a conference paper.	I-Reply	I-3	Reply	594
We think it is better to have the ICLR submission focus on the ParMAC algorithm, which is the most important part, and point to the longer paper for these other things.	I-Reply	I-3	Reply	594
<sep> We did omit the definition of T(P): T(P) = TW(P) + TZ(P).	I-Reply	I-3	Reply	594
<sep> "True SGD" means SGD as it would run in a single machine.	I-Reply	I-3	Reply	594
<sep> The statement that we can recover the original convergence guarantees follows by realising that the critical condition we need to ensure for MAC to converge is "to reduce the gradient of the penalised function below a tolerance for each value of \mu" (arXiv p. 19).	I-Reply	I-3	Reply	594
Proposition 1 in Bertsekas/Tsisiklis00 guarantees this for SGD even for nonconvex functions.	I-Reply	I-3	Reply	594
Essentially, if you run the W steps (= SGD on each submodel) for sufficiently many epochs, you follow the path over \mu closely enough, and you converge in the limit.	I-Reply	I-3	Reply	594
For full details, see section 6 in the arXiv paper.	I-Reply	I-3	Reply	594
<sep> <sep> Regarding the choice of the binary autoencoder for the experiments, see our "response to reviewers".	O	O	Reply	594
<sep> <sep> The ICLR submission (together with the arXiv paper) does contain a detailed theoretical analysis of the speedup.	O	O	Reply	594
The arXiv paper does describe the convergence properties.	O	O	Reply	594
We provide the full C/MPI code in our website to recreate the experiments in either a shared- or a distributed-memory system.	O	O	Reply	594

This paper proposes an extension of the MAC method in which subproblems are trained on a distributed cluster arranged in a circular configuration.	O	O	Review	594
The basic idea of MAC is to decouple the optimization between parameters and the outputs of sub-pieces of the model (auxiliary coordinates); optimization alternates between updating the coordinates given the parameters and optimizing the parameters given the outputs.	O	O	Review	594
In the circular configuration.	O	O	Review	594
Because each update is independent, they can be massively parallelized.	O	O	Review	594
<sep> <sep> This paper would greatly benefit from more concrete examples of the sub-problems and how they decompose.	B-Review	B-1	Review	594
For instance, can this be applied effectively for deep convolutional networks, recurrent models, etc?	I-Review	I-1	Review	594
From a practical perspective, there's not much impact for this paper beyond showing that this particular decoupling scheme works better than others.	I-Review	I-1	Review	594
<sep> <sep> There also seem to be a few ideas worth comparing, at least:	B-Review	B-2	Review	594
- Circular vs. parameter server configurations	I-Review	I-2	Review	594
- Decoupled sub-problems vs. parallel SGD	I-Review	I-2	Review	594
<sep> Parallel SGD also has the benefit that it's extremely easy to implement on top of NN toolboxes, so this has to work a lot better to be practically useful.	O	O	Review	594
<sep> <sep> Also, it's a bit hard to understand what exactly is being passed around from round to round, and what the trade-offs would be in a deep feed-forward network.	B-Review	B-3	Review	594
Assuming you have one sub-problem for every hidden unit, then it seems like:	I-Review	I-3	Review	594
<sep> 1.	I-Review	I-3	Review	594
In the W step, different bits of the NN walk their way around the cluster, taking SGD steps w.r.t.the coordinates stored on each machine.	I-Review	I-3	Review	594
This means passing around the parameter vector for each hidden unit.	I-Review	I-3	Review	594
<sep> 2.	I-Review	I-3	Review	594
Then there's a synchronization step to gather the parameters from each submodel, requiring a traversal of the circular structure.	I-Review	I-3	Review	594
<sep> 3.	I-Review	I-3	Review	594
Then each machine updates it's coordinates based on the complete model for a slice of the data.	I-Review	I-3	Review	594
This would mean, for a feed-forward network, producing the intermediate activations of each layer for each data point.	I-Review	I-3	Review	594
<sep> <sep> So for something comparable to parallel SGD, you could do the following: put a mini-batch of size B on each machine with ParMAC, compared to running such mini-batches in parallel.	B-Review	B-4	Review	594
Completing steps 1-2-3 above would then be roughly equivalent to one synchronized PS type implementation step (distribute model to workers, get P gradients back, update model.)	I-Review	I-4	Review	594
<sep> <sep> It would be really helpful to see how this compares in practice.	B-Review	B-5	Review	594
It's hard for me to understand intuitively why the proposed method is theoretically any better than parallel SGD (except for the issue of non-smooth function optimization); the decoupling also can fundamentally change the problem since you're not doing back-propagation directly anymore, so that seems like it would conflate things as well and it's not necessarily going to just work for other types of architectures.	I-Review	I-5	Review	594
ParMAC does apply to other models, such as deep nets, but in this particular paper we choose a specific model to illustrate it, namely the binary autoencoder (see our "response to reviewers" for our reasons for this choice).	O	O	Reply	594
This also allows us to show one notable feature of MAC: its ability to handle non-differentiable models, where the chain rule doesn't apply.	O	O	Reply	594
In the binary autoencoder the gradients wrt the parameters either are zero or don't exist, because the bottleneck layer outputs are binary, so the objective function is piecewise constant.	O	O	Reply	594
Hence, backpropagation or SGD applied directly to the binary autoencoder doesn't apply, and it makes no sense to apply parallel SGD to a binary autoencoder.	O	O	Reply	594
The CVPR 2015 paper "Hashing with binary autoencoders" did compare with approximate approaches to train a binary autoencoder (e.g. relaxing the step function) and showed they give worse models.	O	O	Reply	594
<sep> <sep> You are correct in your description of steps 1-2-3 as they would apply to a deep feedforward network.	B-Reply	B-3	Reply	594
But, regarding your statements about parallel SGD, if we understand you correctly (you are trying to train binary autoencoder replicas), this requires the *gradients*, which do not exist for the binary autoencoder, as mentioned above.	I-Reply	I-3	Reply	594
If you are trying to combine parallel SGD with ParMAC, note that in the W step the submodels are independent.	I-Reply	I-3	Reply	594
So the existing processors are best used in training the independent submodels than in running parallel SGD on each submodel.	I-Reply	I-3	Reply	594
<sep> <sep> You are right that for differentiable architectures parallel SGD does apply and it would be of interest to compare ParMAC with it.	B-Reply	B-4	Reply	594
But, within the scope of this paper, we limited ourselves to the binary autoencoder.	I-Reply	I-4	Reply	594

This paper proposes a novel approach ParMAC, a parallel and distributed framework of MAC (the Method of Auxiliary Coordinates) to learn nested and non-convex models which is based on the composition of multiple processing layers (i.e., deep nets).	O	O	Review	594
The basic idea of MAC to optimise the nested objective function, which is traditionally learned using methods based on the chain-rule gradients but inconvenient and is hard to parallelise, is to break nested functional relationships judiciously by introducing new variables ( the auxiliary coordinates) as equality constraints, and then to optimise a penalised function using alternating optimisation over the original parameters (W step) and over the coordinates (Z step).	O	O	Review	594
The minimisation (W step) updates the parameters by splitting the nested model into independent submodels and training them using existing algorithms, and the coordination (Z step) ensures that corresponding inputs and outputs of submodels eventually match.	O	O	Review	594
In this paper, the basic assumptions of ParMAC are that with large datasets in distributed systems, it is imperative to minimise data movement over the network because of the communication time generally far exceeds the computation time in modern architectures.	O	O	Review	594
Thus, the authors propose the ParMAC to translate the parallelism inherent in MAC into a distributed system by data parallelism and model parallelism.	O	O	Review	594
They also analyse its parallel speedup and convergence, and demonstrated it with MPI-based implementation to optimise binary autoencoders.	O	O	Review	594
The proposed ParMAC is tested on 3 colour image retrieval datasets.	O	O	Review	594
<sep> <sep> The organization of the paper is well written, and the presentation is clear.	O	O	Review	594
My questions are included in the following:	O	O	Review	594
- The MAC framework solves the original problem approximately.	B-Review	B-1	Review	594
If people use the sigmoid function to smooth the stepwise function, the naive optimization methods can be easier applied.	I-Review	I-1	Review	594
What is the difference between these two?	I-Review	I-1	Review	594
Or why do we want to use a new approach to solve it?	I-Review	I-1	Review	594
<sep> - The authors do not compare their ParMAC model with other distributed approaches for the same nested function optimization problem.	B-Review	B-2	Review	594
Regarding the use of a sigmoid function to smooth the step function, this is a good point and is addressed in the CVPR 2015 paper "Hashing with binary autoencoders" (briefly described in page 4, paragraph 2 of the ICLR submission).	B-Reply	B-1	Reply	594
This work did compare MAC with approximate approaches to train a binary autoencoder that are popular in the binary hashing literature.	I-Reply	I-1	Reply	594
One of them is what you mention: relaxing the step function to a sigmoid.	I-Reply	I-1	Reply	594
That paper showed the sigmoid gives significantly worse models in terms of the objective function, i.e. the reconstruction error (around 20% larger error in figure 2 in that paper).	I-Reply	I-1	Reply	594
<sep> <sep> So yes, one could train a continuous autoencoder (for which one would be able to use parallel SGD), but one would be training the wrong model, which badly approximates the binary autoencoder.	B-Reply	B-1	Reply	594
<sep> <sep> On this topic, recent research on binary hashing to learn the binary hash function has moved from relaxation approaches to methods that use optimisation over the binary variables natively, such as MAC, because they learn better hash functions.	I-Reply	I-1	Reply	594
In deep learning, networks with binary outputs (or binary weights) are just beginning to be explored.	I-Reply	I-1	Reply	594
<sep> <sep> Regarding "the authors do not compare their ParMAC model with other distributed approaches for the same nested function optimization problem", we don't know other distributed approaches for training binary autoencoders, but please do tell us if you know of any.	B-Reply	B-2	Reply	594

This paper looks at developing 'unit tests' for stochastic optimization algorithms, which consist of toy objective functions and corresponding gradient noise that are assembled randomly from a suite of various components.	O	O	Review	54
The hope is that these tests would allow one to analyse the specific failure cases for various methods, perhaps in order to inform improvements to them.	O	O	Review	54
<sep> <sep> This paper is mostly just engineering, but the authors seem to have created a fairly versatile tool for generating toy problems with many different characteristics which may well be quite useful in the future.	O	O	Review	54
The paper itself doesn't contain much in the way of useful conclusions about the optimization algorithms (mostly different versions of SGD) that are tried.	O	O	Review	54
I also have several issues with various aspects of the unit tests themselves, and am not fully convinced that they are testing the 'right' kind of thing or if these tests can tell us much of use about the optimization problems we really care about.	B-Review	B-1	Review	54
<sep> <sep> It would have been nice if the paper had demonstrated how these tests could actually inform algorithm design.	B-Review	B-18	Review	54
<sep> <sep> Nonetheless I would recommend that it be accepted.	O	O	Review	54
I hope the authors can address some of the issues I've brought up.	O	O	Review	54
<sep> <sep> <sep> Detailed comments:	O	O	Review	54
<sep> Are these optimization surfaces unimodal?	B-Review	B-2	Review	54
If not, couldn't it be the case that some optimization methods simply will get 'lucky' and bounce their way into a better local basin, whereas other that might be more careful about remaining stable in the face of noise will miss these?	B-Review	B-3	Review	54
This seems to me like it might not be a realistic analogy of the kinds of optimizations we care about, where multimodal landscapes with multiple modes of highly variable quality don't seem to exist.	O	O	Review	54
I'm thinking about neural network optimization in particular here, and going on my experience that typically the lowest achievable error from run to run doesn't vary all that much (if at all).	O	O	Review	54
<sep> <sep> Another major issue I have is that by testing local convergence of methods you are really only testing one them in a single and likely not too important phase of optimization: fine convergence to a local min.	B-Review	B-4	Review	54
Often in these cases the method that can deal with the noise the best wins.	I-Review	I-4	Review	54
I'm not sure if this is the best analogy to what happens in deep net optimization, where fine convergence to a local min seems to be only a small and not particularly important phase of optimization (which is often just associated with overfitting).	I-Review	I-4	Review	54
<sep> <sep> I would wager that the most significant aspect of optimization is the journey towards a local min from very far away along a very curvy path that can possibly lead to other local mins of roughly equivalent quality.	I-Review	I-4	Review	54
It is not clear to me that your unit tests properly capture this aspect of optimization by focusing either on fine convergence to local optima, or the tendency for an optimizer to jump out of one local min into a closely situated and much higher quality one.	O	O	Review	54
<sep> <sep> <sep> Page 1:  In what sense do you mean that these weaknesses are separate from 'raw performance'.	B-Review	B-5	Review	54
If an algorithm is performing well on some task, why would I care if it has some invisible issues on that task, as long as it appears to be working?	I-Review	I-5	Review	54
I think I'm misinterpreting what you meant here.	I-Review	I-5	Review	54
<sep> <sep> Page 1: I don't really understand what you are saying in the 'locally' paragraph.	B-Review	B-6	Review	54
Are you saying that you want to assume local optimization because your units tests, if they are to be run quickly, can only consider toy examples with a simple local structure (unlike a neural network which has a 'global structure')?	I-Review	I-6	Review	54
And what does this have to do with non-stationary algorithms (or do you mean non-stationary objective functions?)	I-Review	I-6	Review	54
or 'initialization bias'?	I-Review	I-6	Review	54
Don't you still need to initialize the algorithms in the unit tests and won't this choice affect the relative performance of different methods?	B-Review	B-7	Review	54
<sep> <sep> Page 3: With these noise prototypes, is it obvious why their mean must recover the gradient (i.e. so they are unbiased)?	O	O	Review	54
For the additive case this is clear, since the noise has mean 0, but it is less clear for multiplicative noise.	O	O	Review	54
I suppose if the average scale is alpha the multiplicative noise would on average estimate alpha*gradient.	O	O	Review	54
<sep> This is an important point, since the stochastic gradients need to be unbiased for many stochastic optimization algorithms to work, at least in theory.	O	O	Review	54
<sep> <sep> Cauchy noise, for example, doesn't even have a mean, so this seems a bit problematic.	O	O	Review	54
Although I suppose for certain choices of its parameters, the distribution is at least centred around 0.	O	O	Review	54
Perhaps this might be good enough in practice.	O	O	Review	54
Is this what you did?	O	O	Review	54
<sep> <sep> The mask-out noise is unbiased as far as I can tell.	O	O	Review	54
<sep> <sep> You really should discuss the issue of unbiasedness of your noise in general, as this is very important to the theory of these methods.	B-Review	B-8	Review	54
<sep> <sep> Page 4:  How are you generating these random rotations?	B-Review	B-9	Review	54
Are these just like random orthonormal matrices?	I-Review	I-9	Review	54
Generated how?	I-Review	I-9	Review	54
<sep> <sep> Page 4:  It is not clear to me why gradient descent should work at all when it is given vectors from a vector field that is not actually a gradient field.	B-Review	B-10	Review	54
And assuming it does work for certain such fields, the reasons are probably subtle and highly situation dependent.	I-Review	I-10	Review	54
I don't imagine that this can be easily simulated by applying a fixed rotation to the gradient.	B-Review	B-11	Review	54
In fact, I can't even imagine how gradient descent could ever converge if it were given gradient with a fixed rotation.	O	O	Review	54
For example, you could just permute the coordinates.	O	O	Review	54
That is a valid rotation, but surely this would cause most reasonable algorithms to fail catastrophically.	O	O	Review	54
<sep> <sep> Also, you should explain concept of curl etc for this audience.	O	O	Review	54
<sep> <sep> Page 5:  What do you mean in the sentence: 'However, non-stationary optimization can even be important in large stationary tasks, when the algorithm itself chooses to track a particular aspect of the problem, rather than solve the problem globally.'	B-Review	B-12	Review	54
What do you mean by 'aspect', 'track' and 'globally' here?	O	O	Review	54
This goes back to my previous question.	O	O	Review	54
<sep> <sep> Page 5:  I think a better way of simulating non-stationarity of the objective function would be to perhaps randomly jiggle or move the various shape and scale parameters that define your objective.	B-Review	B-13	Review	54
Mere translation doesn't seem particularly hard to deal with, or realistic.	O	O	Review	54
<sep> <sep> Page 6:  Why didn't you test the method(s) from [9]??	B-Review	B-14	Review	54
<sep> <sep> Page 6:  Double the progress of vanilla SGD doesn't seem particularly 'excellent' to me.	O	O	Review	54
Perhaps merely 'good'.	O	O	Review	54
<sep> <sep> Page 7:  What are these 'groups'?	B-Review	B-15	Review	54
Where do you describe what they are?	I-Review	I-15	Review	54
<sep> Page 7:  So if I understand correctly, the vertical axis gives the different methods with different hyper parameter choices for each method?	B-Review	B-16	Review	54
<sep> Many of these methods, such as Nesterov's accelerated gradient, have automatically adapted hyperparameters, which is sometimes done according to a fixed schedule.	I-Review	I-16	Review	54
The momentum parameter in particular usually isn't supposed to be constant, at least in theory.	I-Review	I-16	Review	54
<sep> <sep> And in general, for stochastic optimization methods, there usually are no guarantees for a fixed learning rate.	I-Review	I-16	Review	54
Some methods like ADAGRAD implicitly anneal the learning rate, while with others, like plain SGD, or accelerated gradient SGD, you need to reduce the learning rate adaptively or at least with a schedule if you plan to have fine convergence to a local min.	I-Review	I-16	Review	54
<sep> <sep> Are you keeping these fixed, are you are instead varying the hyper-hyperparameters of the methods that adjust the hyperparameters?	I-Review	I-16	Review	54
<sep> Are methods with 'thicker' regions ones with more adjustable hyperparameters?	O	O	Review	54
<sep> <sep> It seems to me that it doesn't really make sense to plot the values for all hyper-parameters, when some are clearly crazy.	B-Review	B-17	Review	54
If a method has lots of hyperparameters, it shouldn't be judged to be 'less robust' if for certain crazy choices of these it diverges.	I-Review	I-17	Review	54
And it isn't always true that we have no way of determining good hyperparameters for methods that have them.	O	O	Review	54
Binary search, or perhaps Bayesian optimization are certainly better than exhaustive sweeps.	O	O	Review	54
More simply than that, one can just adjust these things on the fly, with a heuristic or manually if needed, as partial progress with sub-optimal hyperparameter choices doesn't need to be thrown out (unless very bad divergence has taken place, and then you can always backtrack to a previous snap-shot of the parameters).	O	O	Review	54
Thank you for your constructive and detailed comments, we‚Äôve revised the paper to take them into account, and here are some specific answers:	O	O	Reply	54
<sep> > I am not fully convinced that they are testing the 'right' kind of thing or if these tests can tell us much of use about the optimization problems we really care about.	O	O	Reply	54
<sep> <sep> As reviewer 5afd point out, this paper aims to be a start in this direction.	B-Reply	B-1	Reply	54
Different users of stochastic gradient methods may care more or less about different issues (e.g. high dimensions, local optima of varying quality, etc), and so a lot is being left to future work.	I-Reply	I-1	Reply	54
Nevertheless, we argue that most of our proposed unit tests are more or less representative of a (part of an) optimization surface that could be encountered, and that a good algorithm should behave robustly on most of them.	I-Reply	I-1	Reply	54
<sep> <sep> > Are these optimization surfaces unimodal?	O	O	Reply	54
<sep> <sep> Yes, most of the surfaces are unimodal.	B-Reply	B-2	Reply	54
<sep> <sep> > If not, couldn't it be the case that some optimization methods simply will get 'lucky' and bounce their way into a better local basin, whereas other that might be more careful about remaining stable in the face of noise will miss these?	O	O	Reply	54
<sep> <sep> All experiments are repeated many times to minimize the effect of ‚Äúlucky‚Äù runs.	B-Reply	B-3	Reply	54
Careful algorithms have different properties than more aggressive or stochastic algorithms, and this is should be reflected in them having different strengths and weaknesses on different sets of unit tests -- including but not limited to multimodal surfaces.	I-Reply	I-3	Reply	54
<sep> <sep> > Another major issue I have is that by testing local convergence of methods you are really only testing one them in a single and likely not too important phase of optimization: fine convergence to a local min. [...]	O	O	Reply	54
I would wager that the most significant aspect of optimization is the journey towards a local min from very far away along a very curvy path that can possibly lead to other local mins of roughly equivalent quality.	O	O	Reply	54
<sep> <sep> Indeed, some unit tests test fine convergence to a local minimum, but there are many others as well, that test for example non-divergence under high noise, or the local optimization dynamics on shape prototypes that have their optimum at infinity (linear slope, sigmoid, exponential, saddle points, etc.) --	B-Reply	B-4	Reply	54
so these latter unit tests verify that an algorithm keeps making progress.	I-Reply	I-4	Reply	54
In other words, they check for sane behavior during the long ‚Äújourney‚Äù that characterizes most early phases of optimization.	I-Reply	I-4	Reply	54
<sep> <sep> > Page 1: In what sense do you mean that these weaknesses are separate from 'raw performance'.	O	O	Reply	54
If an algorithm is performing well on some task, why would I care if it has some invisible issues on that task, as long as it appears to be working?	O	O	Reply	54
<sep> <sep> For any given task, the best algorithm is determined by its raw performance (and may be a different one each time).	B-Reply	B-5	Reply	54
This is a separate question from which algorithm is robust in general and likely to work well on new, unknown problems.	I-Reply	I-5	Reply	54
<sep> <sep> > Page 1: I don't really understand what you are saying in the 'locally' paragraph.	O	O	Reply	54
<sep> <sep> We have revised this paragraph for clarity.	B-Reply	B-6	Reply	54
<sep> <sep> > Don't you still need to initialize the algorithms in the unit tests and won't this choice affect the relative performance of different methods?	O	O	Reply	54
<sep> <sep> Yes, initialization and algorithm state are one currently unresolved issue, but in section 4.1, we discuss a possible way of addressing this in future work.	B-Reply	B-7	Reply	54
<sep> <sep> > You really should discuss the issue of unbiasedness of your noise in general.	O	O	Reply	54
<sep> <sep> We have clarified in section 2.3 that the noise is not necessarily unbiased.	B-Reply	B-8	Reply	54
<sep> <sep> > Page 4: How are you generating these random rotations?	O	O	Reply	54
Are these just like random orthonormal matrices?	O	O	Reply	54
<sep> <sep> Yes.	B-Reply	B-9	Reply	54
<sep> <sep> > Page 4: It is not clear to me why gradient descent should work at all when it is given vectors from a vector field that is not actually a gradient field.	O	O	Reply	54
And assuming it does work for certain such fields, the reasons are probably subtle and highly situation dependent.	O	O	Reply	54
<sep> <sep> This is true, and in the cited reinforcement literature the issue of when it may converge anyway has been studied extensively.	B-Reply	B-10	Reply	54
<sep> <sep> > I don't imagine that this can be easily simulated by applying a fixed rotation to the gradient.	O	O	Reply	54
<sep> <sep> In some simple cases, such as the one in Figure 4, it can, indeed, there the vector field is exactly a gradient field combined with a rotation (and a large class of algorithms do converge in this scenario) -- we have clarified this point in the latest revision.	B-Reply	B-11	Reply	54
<sep> <sep> > Page 5: What do you mean in the sentence: 'However, non-stationary optimization can even be important in large stationary tasks, when the algorithm itself chooses to track a particular aspect of the problem, rather than solve the problem globally.'?	O	O	Reply	54
<sep> <sep> We have clarified this in section 2.6, with the details being deferred to the cited [21].	B-Reply	B-12	Reply	54
<sep> > Page 5: I think a better way of simulating non-stationarity of the objective function would be to perhaps randomly jiggle or move the various shape and scale parameters that define your objective.	O	O	Reply	54
<sep> <sep> Thank you, have added these modifiers to expand the set of unit tests to include all three types of non-stationarity in the revised version.	B-Reply	B-13	Reply	54
<sep> <sep> > Page 6: Why didn't you test the method(s) from [9]?	O	O	Reply	54
<sep> <sep> We are presently working on more robust variants of that method, with the help of the presented unit tests actually, to be published shortly.	B-Reply	B-14	Reply	54
<sep> <sep> > Page 7: What are these 'groups'?	O	O	Reply	54
Where do you describe what they are?	O	O	Reply	54
<sep> <sep> Vertically, each group of rows is one algorithm with different hyperparameters, horizontally, each group of columns is a collection of unit tests with a certain property -- this is now described more clearly in the text.	B-Reply	B-15	Reply	54
<sep> <sep> > Page 7: So if I understand correctly, the vertical axis gives the different methods with different hyper parameter choices for each method? [...]	O	O	Reply	54
Are methods with 'thicker' regions ones with more adjustable hyperparameters?	O	O	Reply	54
<sep> <sep> Yes and yes.	B-Reply	B-16	Reply	54
Section 3.1 gives the overview of what these hyperparameters are for each algorithm, and which values are swept over (full details are in the published code).	I-Reply	I-16	Reply	54
<sep> <sep> > If a method has lots of hyperparameters, it shouldn't be judged to be 'less robust' if for certain crazy choices of these it diverges.	O	O	Reply	54
<sep> <sep> We try not to make a judgement on which hyperparameters are reasonable.	B-Reply	B-17	Reply	54
Instead we want to show that our unit tests can be a tool for determining whether a single setting of hyperparameters can be robust in most scenarios, or whether some algorithms have to be tuned to the problem.	I-Reply	I-17	Reply	54

This paper bravely proposes to test the empirical convergence of stochastic optimization algorithms using a vast collection of simple and relatively standardized tests.	O	O	Review	54
They explain how they construct the tests and perform experiments that lead to a striking visualization (figure 5).	O	O	Review	54
Unfortunately none of the compared algorithms appear to solve all the problems robustly.	B-Review	B-1	Review	54
<sep> <sep> This idea could appear na√Øve because it is not supported by theoretical considerations and represents a purely empirical perspective.	O	O	Review	54
However there are many reasons to consider that this idea has great potential.	O	O	Review	54
First, similar ideas have worked in other fields.	B-Review	B-2	Review	54
It is customary to compare general optimization codes on a collection of well known benchmark problems, not because it provides a guarantee, but because it provides a sanity check.	I-Review	I-2	Review	54
Second, we must recognize optimization in deep learning systems is still beyond the reach of theoretical analysis.	I-Review	I-2	Review	54
According to the current theoretical knowledge, it should not work.	O	O	Review	54
Therefore the best way to investigate such algorithms remains a well designed collection of empirical comparisons.	O	O	Review	54
The comparison described in this paper is a good start in that direction.	O	O	Review	54
Thank you for your comments!	O	O	Reply	54
<sep> <sep> > The existence of some prototype in real data is easy to assert, but the	O	O	Reply	54
> probability that you will have to deal with said prototype is hard.	O	O	Reply	54
<sep> <sep> Indeed.	B-Reply	B-1	Reply	54
We try to argue that the scenarios covered by the proposed unit tests could occur, not that they necessarily occur a lot.	I-Reply	I-1	Reply	54
But a good algorithm should behave robustly on most of them when they do occur.	I-Reply	I-1	Reply	54
<sep> <sep> > While the paper mentions that there are tools for visualizing these	O	O	Reply	54
> results, there are not many details given about these tools.	O	O	Reply	54
I think an	O	O	Reply	54
> interesting question on its own is what are the write visualization of the	O	O	Reply	54
> results and how to interpret them, a question which I don't think is fully	O	O	Reply	54
> answer by the current work.	O	O	Reply	54
<sep> <sep> In fact, Figure 5 is such a proposed visualization, and it is described in section 3 (fuller details are available in the published code).	O	O	Reply	54
It is designed to provide a quick qualitative overview and flag potential weaknesses of an algorithm.	O	O	Reply	54

The paper presents an approach based on generative adversarial models for the unconditional  generation of audio.	O	O	Review	54
The authors take inspiration from WaveGAN, to which they add more sophisticated upsampling blocks (called the bandwidth extension module) instead of transposed convolutions.	O	O	Review	54
They also propose to add a sinc convolution layer to the discriminators to improve training.	O	O	Review	54
Finally, they propose a progressive training scheme similar in spirit to the progressive training of GANs in images.	O	O	Review	54
Experiments are performed on generating audio pronunciation of digits, and the authors compare their work in terms of inception score, human evaluation and computation cost to WaveGAN.	O	O	Review	54
<sep> <sep> As stated by the authors, one of the main motivation oof their approach is the reduction of computation cost.	O	O	Review	54
The motivation, expressed in terms of the 10ms "interactive rate" follows a good story.	O	O	Review	54
The measurements performed at the end of the paper show a ~ x2 performance gains compared to WaveGAN on CPU and about same running times on GPU, which is significant but not compelling.	O	O	Review	54
<sep> <sep> Overall, I liked the story of the paper, but the paper lacks clarity and details.	B-Review	B-1	Review	54
An important aspect of the paper is the progressive training, which is detailed nowhere (e.g., what is the stopping criterion to get to the next stage), should there be a special initialization of the last block of a new stage, etc.).	I-Review	I-1	Review	54
The "Bandwidth extension module", which from my understanding is one of thee main contribution of the paper, is detailed in the appendix and comes essentially without justification.	I-Review	I-1	Review	54
One of the main motivations of the paper is to be able to generate 44kHz audio, but the only results available at this resolution are inception scores that are below those of the 16kHz generation, which leaves open the question of whether the goal is effectively achieved.	I-Review	I-1	Review	54
<sep> <sep> I found the different versions of PUGAN difficult to read.	B-Review	B-2	Review	54
The picture uses 2 blocks of bandwidth extension to generate 16kHz, whereas the evaluations are done with PUGAN-1 (1 block), which if I understand correctly is based on the lightweight WaveGAN that generates at 8kHz (whereas Section 4.1 suggests that 16kHz is generated from 4kHz generations by WaveGAN and two blocks).	I-Review	I-2	Review	54
Also, the fact that evaluations are carried out with PUGAN-1 suggests that the progressive training does not really works well past a single block.	I-Review	I-2	Review	54
<sep> <sep> In the text it is suggested that spectral normalization and sinc conv on the discriminator is an "improvement" of WaveGAN, and an independent contribution of the article.	O	O	Review	54
While Table 2 clearly shows an improvement in terms of inception score, the human evaluation is not that clear: the accuracy of human labelers drops to 0.52 from 0.63 and the quality seems totally within the variance (2.7 +/- 1.5 vs 2.6 +/- 1.3).	B-Review	B-3	Review	54
While Table 3 also shows clear improvement over the basic WaveGAN with the changes made by the authors (in particular in terms of win ratio vs PUGAN-1), the loss of accuracy should be discussed.	I-Review	I-3	Review	54
<sep> <sep> The performance obtained by PUGAN-1 is nonetheless noticeable -- +1 quality score over WaveGAN, and much better pairwise win ratios.	O	O	Review	54
Nonetheless, the paper lacks clarity and motivation for the exact form of the bandwidth extraction module, and does not fulfill its promises (importance of progressive training, high quality generation at 44kHz), so I am leaning towards rejection.	B-Review	B-1	Review	54
<sep> <sep> <sep> To demonstrate the effectiveness of our progressive training, we added a figure to the appendix, which includes a step-by-step result from the same latent vector.	B-Reply	B-1	Reply	54
We updated the demo webpage with these results.	I-Reply	I-1	Reply	54
Overall, it can be seen that the high-frequency band is progressively learned.	I-Reply	I-1	Reply	54
In the current PUGAN structure, we failed to train the model with no progressive training.	I-Reply	I-1	Reply	54
<sep> <sep> *	O	O	Reply	54
Finally, we uploaded the code for our experiment to our demo page.	B-Reply	B-4	Reply	54
One can check out the code from the link below and reproduce our experiment results by following the readme.txt file.	I-Reply	I-4	Reply	54
<sep> <a href="https://pugan-iclr-demo.herokuapp.com/static/pugan-code.zip" target="_blank" rel="nofollow">https://pugan-iclr-demo.herokuapp.com/static/pugan-code.zip</a>	I-Reply	I-4	Reply	54

The authors detail PUGAN, architectural changes to models for raw waveform generation with GANs.	O	O	Review	54
They do a good job of motivating the challenge of raw audio generation with GANs and of methods for progressive training.	O	O	Review	54
PUGAN incorporates U-Net modules in the generator ("Bandwidth expansion"), sinc convolution as bandlimiting inputs to the generators, and the "style gan" type method of adding the noise at each level of the generator.	O	O	Review	54
Using listener studies and inception score, they show modest improvements over the state of the art (at time of submission), WaveGAN.	O	O	Review	54
Notably, their architecture is also more computation and parameter efficient.	O	O	Review	54
<sep> <sep> The paper is well motivated and experiments are correct, but the quality improvements overall are a little underwhelming.	B-Review	B-3	Review	54
To some extent, that can't be helped, and the authors wisely focus on the improvements in inference time as one of their central claims, and indeed produce evidence to support this claim.	I-Review	I-3	Review	54
<sep> <sep> More problematic, however, the paper motivates the problem of multi-scale generation of waveforms, but does not clearly show that the proposed architectures address those issues.	B-Review	B-1	Review	54
The motivation in terms of interpolation artifacts and band-limited upsampling in Figure 1 give a misleading sense that Kaiser resampling is explicitly incorporated into the model.	B-Review	B-2	Review	54
The authors argue that the U-Net layers implicitly learn an upsampling method, but the lack of model comparison / ablation makes it difficult to see if that really is the case.	B-Review	B-4	Review	54
It would help support the claim to show samples from the model at different resolutions and demonstrate the lack of artifacts at each level.	I-Review	I-4	Review	54
In the appendix, the authors mention that any alterations to the architecture resulted in failed training, but the lack of an ablation study makes it hard to know the relative value of each component.	I-Review	I-4	Review	54
For example, it is unclear how important the sinc layers and bandlimiting are for the discriminators, the intermediate noise, and the use of the BWE architectures.	I-Review	I-4	Review	54
<sep> <sep> Despite these shortcomings I still recommend a weak accept, as the problem is difficult and the paper documents a well-motivated avenue for approaching it.	O	O	Review	54
<sep> <sep> *** More problematic, however, the paper motivates the problem of multi-scale generation of waveforms, but does not clearly show that the proposed architectures address those issues. ****	O	O	Reply	54
<sep> <sep> To demonstrate the effectiveness of progressive training, we added a figure to the appendix, which includes a step-by-step result from the same latent vector.	B-Reply	B-1	Reply	54
We added sound samples to the demo webpage.	I-Reply	I-1	Reply	54
As a result, it can be seen that the high-frequency band is progressively learned.	I-Reply	I-1	Reply	54
In the current PUGAN structure, we failed to train the model with no progressive training.	I-Reply	I-1	Reply	54
<sep> <sep> <sep> *** The motivation in terms of interpolation artifacts and band-limited upsampling in Figure 1 give a misleading sense that Kaiser resampling is explicitly incorporated into the model.***	O	O	Reply	54
<sep> <sep> We thank the reviewer for insightful suggestions.	B-Reply	B-2	Reply	54
We renamed the kaiser resample as ‚Äúideal‚Äù in Figure 1 and changed the figure descriptions accordingly.	I-Reply	I-2	Reply	54
<sep> <sep> *	O	O	Reply	54
Finally, we uploaded the code for our experiment to our demo page.	B-Reply	B-5	Reply	54
One can check out the code from the link below and reproduce our experiment results by following the readme.txt file.	I-Reply	I-5	Reply	54
<sep> <a href="https://pugan-iclr-demo.herokuapp.com/static/pugan-code.zip" target="_blank" rel="nofollow">https://pugan-iclr-demo.herokuapp.com/static/pugan-code.zip</a>	I-Reply	I-5	Reply	54

Summary:	O	O	Review	54
<sep> This work is a follow-up of WaveGAN.	O	O	Review	54
It uses the first few layers of the original WaveGAN to synthesize low resolution waveform (4kHz), and applies several bandwidth extension modules to progressively output the higher resolution raw audios.	O	O	Review	54
<sep> <sep> pros:	O	O	Review	54
- The proposed PUGAN has significantly smaller number of parameters than WaveGAN (e.g., 20x smaller).	O	O	Review	54
<sep> <sep> cons:	O	O	Review	54
- WaveGAN was a preliminary and encouraging trial for raw audio synthesis with GAN.	B-Review	B-1	Review	54
Note that, its audio fidelity is far away from the state-of-the-art results and it was only tested on simple dataset (sounds of ten-digit commands).	I-Review	I-1	Review	54
In contrast, the state-of-the-art autoregressive models (e.g., WaveNet) and parallel flow-based models (e.g., Parallel WaveNet) have been tested on challenging high-fidelity speech synthesis.	I-Review	I-1	Review	54
As a result, one may focus on improving the audio fidelity of GAN on more challenging tasks.	I-Review	I-1	Review	54
However, the proposed PUGAN was still tested on very simple dataset (sounds of ten-digit commands), and the quality of generated samples are only comparable to WaveGAN.	I-Review	I-1	Review	54
<sep> <sep> Detailed comment:	O	O	Review	54
<sep> -- The attached samples are pretty noisy (e.g., noticeable artifacts on posted spectrograms).	B-Review	B-2	Review	54
One may introduce the feature matching (e.g., STFT loss in ClariNet) as an auxiliary loss to improve the audio fidelity.	I-Review	I-2	Review	54
<sep> <sep> -- Did the authors try conditional generation, e.g., conditioned on the digit label?	B-Review	B-3	Review	54
The posted failure cases and some samples tend to have overlapped sounds from different digits.	I-Review	I-3	Review	54
*** Note that, its audio fidelity is far away from the state-of-the-art results and it was only tested on simple dataset (sounds of ten-digit commands) ***	O	O	Reply	54
<sep> As the reviewer mentioned, autoregressive models such as WaveNet performed well in the text-to-speech (TTS) applications.	B-Reply	B-1	Reply	54
However, a comparative analysis of autoregressive models was done in the original WaveGAN paper, so it was not further evaluated in this paper.	I-Reply	I-1	Reply	54
The current evaluations are based on a short sound of the duration of one second, where the previous study mentioned WaveNet did not perform very well, as can also be found in the official WaveGAN webpage at <a href="https://chrisdonahue.com/wavegan_examples/.." target="_blank" rel="nofollow">https://chrisdonahue.com/wavegan_examples/..</a>	I-Reply	I-1	Reply	54
<sep> While WaveNet is usually applied in TTS, the task of our scope is to learn to generate a short audio clip with no input text.	I-Reply	I-1	Reply	54
That is, our goal is not to make sound close to WaveNet or long speech in a TTS setting.	I-Reply	I-1	Reply	54
With this goal in mind, we also updated the demo webpage by training on the drum sound dataset and the greatest hits dataset.	I-Reply	I-1	Reply	54
We have uploaded the generated samples to the demo page.	I-Reply	I-1	Reply	54
<sep> <sep> TTS can be tackled by the autoregressive model, but our application is real-time sound effects generation in interactive content.	I-Reply	I-1	Reply	54
Given user interaction in VR and AR, it creates the appropriate sound effect accordingly because GAN has a latent space.	I-Reply	I-1	Reply	54
Also, as we mentioned in the introduction, it should generate at an interactive rate (about 10ms).	I-Reply	I-1	Reply	54
There exist studies to speed up parallel wavenets, but the autoregressive model cannot solve this problem.	I-Reply	I-1	Reply	54
<sep> <sep> ***The attached samples are pretty noisy (e.g., noticeable artifacts on posted spectrograms).	O	O	Reply	54
One may introduce the feature matching (e.g., STFT loss in ClariNet) as an auxiliary loss to improve the audio fidelity. ***	O	O	Reply	54
<sep> <sep> We use only one-dimensional waveforms for both the generator and discriminators.	B-Reply	B-2	Reply	54
We think that the current goal of GANs to produce sound is to produce sound that is significant rather than reducing noise.	I-Reply	I-2	Reply	54
The current accuracy is around 70%, and it is likely that a lot of research will be made to reduce the noise if the accuracy is somewhat higher.	I-Reply	I-2	Reply	54
If we do not force the discriminator to receive a one-dimensional waveform, we may try to apply the STFT loss.	I-Reply	I-2	Reply	54
However, looking at tSpecGAN and WaveGAN comparisons in WaveGAN paper and comparing accuracy in WaveGAN and Improved WaveGAN in this paper, noiselessness does not necessarily increase accuracy.	I-Reply	I-2	Reply	54
<sep> <sep> <sep> *** Did the authors try conditional generation, e.g., conditioned on the digit label?	O	O	Reply	54
The posted failure cases and some samples tend to have overlapped sounds from different digits. ***	O	O	Reply	54
<sep> <sep> In this paper, we focused on the idea of progressive generation as the main idea, which shows that it helps to make it possible and better quality sound and reduce the number of parameters.	B-Reply	B-3	Reply	54
Therefore, conditional generation is not considered in our problem setting.	I-Reply	I-3	Reply	54
<sep> <sep> On the other hand, when we talk about overlapping voices of several digits or people, we have found that this problem occurs as we conduct experiments and write papers.	I-Reply	I-3	Reply	54
However, this does not only occur in our PUGAN, but also in existing WaveGAN, and I would like to say that PUGAN does not have this problem as compared to WaveGAN.	I-Reply	I-3	Reply	54
<sep> <sep> *	O	O	Reply	54
Finally, we uploaded the code for our experiment to our demo page.	B-Reply	B-4	Reply	54
One can check out the code from the link below and reproduce our experiment results by following the readme.txt file.	I-Reply	I-4	Reply	54
<sep> <a href="https://pugan-iclr-demo.herokuapp.com/static/pugan-code.zip" target="_blank" rel="nofollow">https://pugan-iclr-demo.herokuapp.com/static/pugan-code.zip</a>	I-Reply	I-4	Reply	54

This submission belongs to the area of multi-view modelling.	O	O	Review	20268
In particular, the submission describes construction of multi-view language models that (i) can generate text simultaneously in multiple languages, (ii) can generate text in one or more languages conditioned on text from another language.	O	O	Review	20268
This submission extends previously proposed KERMIT from two views to more than two views.	O	O	Review	20268
I believe this paper could be of interest to multi-view modelling/learning community.	O	O	Review	20268
<sep> <sep> Though the original KERMIT approach is very interesting and you application of it to more than two views is also interesting I find the presentation to be poor.	B-Review	B-1	Review	20268
In particular I find section 2 to be hard if not impossible to understand without referring to the original paper where the story, equations, nomenclature are much more clearly explained.	I-Review	I-1	Review	20268
Even though your extension from two views to multiple is simple I find reliance on a diagram to be a mistake as I find your description not to be very clear.	I-Review	I-1	Review	20268
Given that there are no equations to support the reader and that the original equations are not adequate I find it hard to understand Sections 2 and 3.	I-Review	I-1	Review	20268
The key experimental result in Table 1 is only briefly commented on despite featuring multiple models with different strength and weaknesses, multiple types of inference.	I-Review	I-1	Review	20268
If space is of concern I would suggest removing Figure 2 (or changing input from non-English to English and removing or removing another qualitative table).	I-Review	I-1	Review	20268
<sep> <sep> Thank you for taking the time to review our paper, especially for the constructive feedback on how to improve the clarity of the presentation.	B-Reply	B-1	Reply	20268
We will revise section 2 and 3 to be more clear and self-contained in the future revision, without relying too much on the diagram.	I-Reply	I-1	Reply	20268
We will also expand on the discussion related to Table 1.	I-Reply	I-1	Reply	20268

This paper proposes a multichannel generative language model (MGLM), which models the joint distribution p(channel_1, ..., channel_k) over k channels.	O	O	Review	20268
MGLM can be used for both conditional generation (e.g., machine translation) and unconditional sampling.	O	O	Review	20268
In the experiments, MGLM uses the Multi30k dataset where multiple high quality channels are available, in the form of multilingual translations.	O	O	Review	20268
<sep> <sep> I feel that this paper is not ready for publication at ICLR due to the following major issues:	O	O	Review	20268
<sep> * Missing important related work: This paper seems unaware of an important related work "Multi-Task Learning for Multiple Language Translation" by Dong et al, ACL 2015.	B-Review	B-1	Review	20268
In fact, Dong et al investigated the problem of learning a machine translation model that can simultaneously translate sentences from one source language to multiple target languages.	I-Review	I-1	Review	20268
Although machine translation is just an example of MGLM, Dong et al is highly relevant to the conditional generation with MGLM, needless to say that they share the same multi-language translation problem domain.	I-Review	I-1	Review	20268
Thus, this paper will be much stronger if comparison with important baseline methods is provided.	I-Review	I-1	Review	20268
<sep> <sep> * Limited novelty: This paper extends Chan et al's KERMIT by applying its objective on tasks with more than 2 sequences, in order to learn the joint distribution p(channel_1, ..., channel_k) over k channel sequences.	B-Review	B-2	Review	20268
Most of the math in this paper can be found in the original Chan et al's paper.	I-Review	I-2	Review	20268
The extension to the multichannel case is incremental as it is hard to justify the challenge of such extensions.	I-Review	I-2	Review	20268
<sep> <sep> Besides, as minor suggestions, it would help readers if more illustrations of Figure 1 (especially the inference part) can be provided.	B-Review	B-3	Review	20268
Thank you for taking the time to review our paper, especially for bringing to our attention an important related work by Dong et al We will revise the paper to include their work in the related work section and discussion.	B-Reply	B-1	Reply	20268
<sep> <sep> One difference with Dong et al to our approach is that during the multi-target generation, our model‚Äôs output at each time step can be conditioned on both the source sentence and the partial translations of all the target languages, while Dong et al‚Äôs model only conditions on the input and the partial translation of the particular target language (in parallel).	I-Reply	I-1	Reply	20268
Our experiment compares the effects of conditioning only on one partial target versus all partial targets inference time.	I-Reply	I-1	Reply	20268
<sep> <sep> On novelty: while our specific implementation can be considered incremental from KERMIT, we believe that the task of learning a generative model over several channels is an underexplored direction that is worthwhile to pursue.	B-Reply	B-2	Reply	20268
Despite the vast interest in unconditional generative modeling in images (GANs, VAEs, etc.),	I-Reply	I-2	Reply	20268
we have seen much less interest in the text domain.	I-Reply	I-2	Reply	20268
We also believe that our empirical contributions will help increase interest in this direction by showing what is possible even with using a relatively simple model.	I-Reply	I-2	Reply	20268

[Paper summary]	O	O	Review	20268
This work is an extension of KERMIT (Chan et al 2019) to multiple languages and the proposed model is called ‚Äúmultichannel generative language models‚Äù.	O	O	Review	20268
KERMIT is an extension of ‚ÄúInsertion Transformer‚Äù (Stern et al, 2019), a non-autoregressive model that can jointly determine which word and which place the translated words should be inserted.	O	O	Review	20268
KERMIT shares the encoder and decoder of insertion Transformer, and the source sentence and target sentence are concatenated to train a generative model (also, various loss functions are included).	O	O	Review	20268
In this work, parallel sentences from more than two languages are concatenated together and fed into KERMIT.	O	O	Review	20268
Each language is associated with a language embedding.	O	O	Review	20268
This work demonstrates that a joint distribution p(x1, . . . ,	O	O	Review	20268
xk) over k channels/languages can be properly modeled through a single model.	O	O	Review	20268
The authors carry out experiments on multi30k dataset.	O	O	Review	20268
<sep> <sep> [Pros] Some discoveries of this work are interesting, including: (1) It is possible to use a single model to translate a sentence into different languages in a non-autoregressive way. (	O	O	Review	20268
2) The unconditional multilingual generation in Section 4.5 is interesting, especially, the generation order is determined by the model rather than left-to-right.	O	O	Review	20268
<sep> <sep> [Questions]	O	O	Review	20268
1.	O	O	Review	20268
<tab>The authors work on multi30k dataset, which is not a typical dataset for machine translation.	B-Review	B-1	Review	20268
<sep> (A)<tab>The dataset and the corresponding information is at <a href="https://github.com/multi30k/dataset."	B-Review	B-1	Review	20268
target="_blank" rel="nofollow">https://github.com/multi30k/dataset.</a> The number of words in a sentence is smaller than 15, which is too short for a machine translation.	I-Review	I-1	Review	20268
Also, the pattern of sentences is relatively simple.	I-Review	I-1	Review	20268
<sep> (B)<tab>For real world application, I am not sure whether it is possible to collect a large amount of k-parallel data where.	B-Review	B-1	Review	20268
Therefore, the application scenario is limited.	I-Review	I-1	Review	20268
What if we have a large amount of bilingual data instead of k-parallel data?	I-Review	I-1	Review	20268
How should we leverage the large amount of monolingual data?	I-Review	I-1	Review	20268
<sep> 2.	O	O	Review	20268
<tab>For novelty, this is an extension of KERMIT to a multilingual version, which limits the novelty of this wok.	B-Review	B-2	Review	20268
<sep> 3.	O	O	Review	20268
<tab>The best results on En-&gt;De in Table 1 are inconsistent.	B-Review	B-3	Review	20268
On tst16, bilingual en&lt;-&gt;de is the best; on tst17, en&lt;-&gt;{rest} is the best; on mscoco, any&lt;-&gt;rest is the best.	I-Review	I-3	Review	20268
In Table 2, seems using bilingual data only is the best choice.	I-Review	I-3	Review	20268
This makes me confuse about how to use your proposed method.	I-Review	I-3	Review	20268
However,	I-Review	I-3	Review	20268
<sep> Thank you for taking the time to review our paper.	O	O	Reply	20268
We address your questions below:	O	O	Reply	20268
<sep> 1.	B-Reply	B-1	Reply	20268
Indeed, we agree that Multi30k is not a typical large scale machine translation dataset.	I-Reply	I-1	Reply	20268
However, we chose the Multi30k dataset because it provided us with multiple high quality channels that expresses the same underlying meaning (i.e. the image) under different viewpoint (languages in this case), in order to highlight our approach.	I-Reply	I-1	Reply	20268
While we have not performed experiments with datasets that have partially (m&lt;k) parallel data (such as bilingual pairs or monolingual data as suggested), we believe that our approach should also be able to take advantage of partially parallel data.	I-Reply	I-1	Reply	20268
The partially parallel data should also be weighted by the prior on how often we believe that combination of channels is encountered.	I-Reply	I-1	Reply	20268
<sep> <sep> 2.	O	O	Reply	20268
While the Multilingual KERMIT approach can be considered incremental conceptually, we believe that we contributed the novelty in terms of the empirical investigations and characterizing the (unconditional and (partially) conditional) samples from the model.	B-Reply	B-2	Reply	20268
In addition, multilingual KERMIT is only one possible implementation of the proposed MGLM framework, with the hopes that this helps encourage others in the community to pursue this line of generative modeling of multichannel texts.	I-Reply	I-2	Reply	20268
<sep> <sep> 3.	O	O	Reply	20268
We will clarify our interpretation of these results in the main paper with more details about the test sets and our hypothesis of the model‚Äôs performance.	B-Reply	B-3	Reply	20268
The Flickr test sets are considered ‚Äúin-domain‚Äù, while the MSCOCO are the harder ‚Äúout-of-domain‚Äù where the captions were selected to contain ambiguous verbs, which makes the translation task harder.	I-Reply	I-3	Reply	20268
In those cases, we found that training the model on the more difficult task (i.e. multi-target (any language -&gt; rest) helped with generalization to the MSCOCO test set in the case of English -&gt; German.	I-Reply	I-3	Reply	20268
In the case of English -&gt; French, we hypothesize that the bilingual model performed the best because there is a high mutual information between English and French, such that training on additional languages do not help the model generalize, but rather even distracts the model.	I-Reply	I-3	Reply	20268

The mental fatigue is an important factor in road accidents.	O	O	Review	669
Finding a direct mapping between EEG features and reaction time is difficult and error-prone, combining the noise measurement of EEG and individual variation of RT.	O	O	Review	669
The authors introduce a measure called BDrank based on partial ordering instead of regression.	O	O	Review	669
Formulating the measure as a MAP problem, the authors propose a generalized EM algorithm for prediction.	O	O	Review	669
An online extension, relying on iterative L-BFGS optimization over mini-batches.	O	O	Review	669
<sep> <sep> Figure 3 shows the indegree sequence for 4 selected subjects.	B-Review	B-1	Review	669
What is the criterion to select these subjects?	I-Review	I-1	Review	669
These cases seem interesting, but is it representative for the best/worst case?	B-Review	B-2	Review	669
It could provide some information to show some of the few cases where SVR is more accurate than BDrank.	I-Review	I-2	Review	669
<sep> Regarding the identification of noisy channels, the 33rd channel is indicated as a non-EEG one.	B-Review	B-3	Review	669
What is it?	I-Review	I-3	Review	669
<sep> <sep> Some minor questions and suggestions:	O	O	Review	669
- It could be interesting to mention the performance of this measure using only a limited set of EEG channels to evaluate its robustness.	B-Review	B-4	Review	669
<sep> - The introduction indicates that de Naurois et al .,	B-Review	B-5	Review	669
2017 rely on EEG to estimate the RT, but it is not the case.	I-Review	I-5	Review	669
<sep> - The formulation of the assumption (2) on page 3 is unclear, as sensors are not supposed to make any emission and there is a high correlation between channels.	B-Review	B-6	Review	669
<sep> - The model do not consider transition between type-1 and -2 preference, could it be a problem with confidence interval	B-Review	B-7	Review	669
Q1: Figure 3 shows the indegree sequence for 4 selected subjects.	O	O	Reply	669
What is the criterion to select these subjects?	O	O	Reply	669
These cases seem interesting, but is it representative for the best/worst case?	O	O	Reply	669
<sep> A1: As we already mentioned in the paper, we selected participants P19, P38, P42, P43 with the most representative (best) performance (See Figure 3).	B-Reply	B-1	Reply	669
Although we only present the results of the participants with the best performance, we insist the statement also applies to other participants for the two reasons: (1) Figure 3 is just the visualization of Table 2.	I-Reply	I-1	Reply	669
Therefore, similar observations can be found on the results of 39 participants. (	I-Reply	I-1	Reply	669
2) The performance of SVR is calculated with the optima parameters for each participants, while fixed parameters are adopted for all participants in the experiment of LOR and BDrank.	I-Reply	I-1	Reply	669
It means the performance for BDrank can be further improved by fine tuning the parameter for each participant.	I-Reply	I-1	Reply	669
<sep> <sep> Q2: It could provide some information to show some of the few cases where SVR is more accurate than BDrank.	O	O	Reply	669
<sep> A2: Thank you very much for the suggestion.	O	O	Reply	669
<sep> We have investigated the principle behind the statistics of the participants which could achieve superior performance using SVR instead of BDrank.	B-Reply	B-2	Reply	669
The two metrics on P14, P21, P23, P32, P33 using SVR are superior to BDrank.	I-Reply	I-2	Reply	669
The reaction time of P14 and P21 indeed have many extreme values, but these extreme values are even distributed, which can be regarded as kind of smoothness.	I-Reply	I-2	Reply	669
The reaction time of P32 and P33 even do not have too extreme values, and there are among 300 trials completed by these participants.	I-Reply	I-2	Reply	669
P23 have only one extreme value but it has sufficient (334) trials.	I-Reply	I-2	Reply	669
<sep> In the following, we summarize the situations where SVR can achieve comparable or better performance: (1) no or a small number of extreme values; (3) even distributed extreme values; (3) sufficient trials a.k.a.	I-Reply	I-2	Reply	669
training samples.	I-Reply	I-2	Reply	669
<sep> It is interesting to note that the above conclusion also consistent with our claim that the regression-based model is not suitable for the tasks with non-smooth response variable.	I-Reply	I-2	Reply	669
<sep> <sep> Q3: Regarding the identification of noisy channels, the 33rd channel is indicated as a non-EEG one.	O	O	Reply	669
What is it?	O	O	Reply	669
<sep> A3: This is the channel receiving the information about vehicle position with the same sampling rate as EEG channels and contains the data about only one axis in the direction of deviation.	B-Reply	B-3	Reply	669
This is the reason we called it non-EEG channel.	I-Reply	I-3	Reply	669
<sep> <sep> Q4: It could be interesting to mention the performance of this measure using only a limited set of EEG channels to evaluate its robustness.	O	O	Reply	669
<sep> A4: Thanks for your suggestion.	B-Reply	B-4	Reply	669
Actually the current experiment results can provide us some preliminary results for the experiment the reviewer suggested.	I-Reply	I-4	Reply	669
There are two kinds of parameters in the proposed BDrank model, namely the regression weight w and channel reliability \pi_n, n = 1, 2, ..., 33.	I-Reply	I-4	Reply	669
In the following, we give our detailed analysis to support our claims that the number of the EEG channels do not affect the performance of our BDrank model.	I-Reply	I-4	Reply	669
<sep> (1) The estimation of two parameters is independent from the number of EEG channels.	B-Reply	B-4	Reply	669
In terms of w, it is a low dimension (493*1) vector.	I-Reply	I-4	Reply	669
Therefore, it could be estimated very well using the EEG signals from limited or only one channels.	I-Reply	I-4	Reply	669
Note that BDrank degenerates to LOR when learning from single channel.	I-Reply	I-4	Reply	669
In terms of \pi_n, it is a scalar introduced for each channel.	I-Reply	I-4	Reply	669
It could be trained well as usual as long as the corresponding channel is used.	I-Reply	I-4	Reply	669
(2) The two parameters could still be estimated well when a considerable proportion of channels are noisy channels.	B-Reply	B-4	Reply	669
See Fig.4, we list the reliability of different channels for forty four participants.	I-Reply	I-4	Reply	669
Note that P32, P35, P42 could still achieve very high performance (ACC > 77%, in Table 1) when about one third of channels are recognized as noisy channels (the noisy channels are automatically eliminated from the training process by our BDrank.).	I-Reply	I-4	Reply	669
<sep> In summary, our BDrank is robust to the number of channels as long as majority of channels are reliable (positive or negative).	B-Reply	B-4	Reply	669
<sep> <sep> Q5: The introduction indicates that de Naurois et al .,	O	O	Reply	669
2017 rely on EEG to estimate the RT, but it is not the case.	O	O	Reply	669
<sep> A5: That‚Äôs correct, this work is derived from behaviour information (expert rating) of drowsiness level which is highly correlated related with RT but less noisy information.	B-Reply	B-5	Reply	669
Therefore, de Naurois et al .,	I-Reply	I-5	Reply	669
2017 was listed under methods related to RT.	I-Reply	I-5	Reply	669
We agree with the reviewer to separate that reference with more details.	I-Reply	I-5	Reply	669

The paper proposes an algorithm for mental fatigue monitoring, relating a subjects' EEG signals to their reaction time (RT) during a simulated driving task, as an ordinal regression problem.	O	O	Review	669
The authors argue that RTs could be heavily skewed and/or non-smooth, making traditional regression approaches unstable due to outlier values.	O	O	Review	669
They propose a brain dynamic ranking algorithm,  BDrank, using a generalized EM algorithm to estimate its parameters, and compare it to support vector regression and Logistic Ordinal Regression, where they show improved performance by accuracy and root mean squared error (RMSE) over a database of 44 subjects.	O	O	Review	669
<sep> <sep> General comments, in no particular order:	O	O	Review	669
<sep> 1.	B-Review	B-1	Review	669
There are some minor grammatical errors throughout.	I-Review	I-1	Review	669
The paper could benefit from another read-through to correct these errors.	I-Review	I-1	Review	669
<sep> <sep> 2.	O	O	Review	669
It is unclear to me how the model works at test time; as the model is essentially building a relational structure in the data, does the user have to provide multiple EEG trials at time of prediction?	B-Review	B-2	Review	669
<sep> <sep> 3.	O	O	Review	669
There is notation early on in the paper that doesn't appear to be appropriately defined.	B-Review	B-3	Review	669
For example, Equation (1) describes two sets of propositions, with M1 and M2 elements, respectively.	I-Review	I-3	Review	669
How is M1 and M2, the total set of propositions, calculated?	I-Review	I-3	Review	669
It appears to be all pair-wise comparisons of RTs but then it's unclear why there are two indexes associated with them.	I-Review	I-3	Review	669
Also, what does it mean for the orderings to be significant? (	B-Review	B-4	Review	669
i.e.: that the "type-1 preference propositions that the orderings between the RTs are significant").	I-Review	I-4	Review	669
The authors then switch to a new notation x^1 and x^2 without defining them.	B-Review	B-5	Review	669
Notational problems also persist throughout the paper, making it hard to gauge what is being done at each step.	I-Review	I-5	Review	669
<sep> <sep> 4.	O	O	Review	669
The authors describe using an FFT to transform the EEG data into the frequency domain.	B-Review	B-6	Review	669
I'm assuming they are doing the FFT on the entire 10-s interval but the paper does not make this clear.	I-Review	I-6	Review	669
Also, the authors state using EEG power between 0-30Hz for their analysis; do they further sub-divide this range (for example, to the standard theta/alpha/beta power ranges) or just use the power across the entire 0-30Hz band?	I-Review	I-6	Review	669
<sep> <sep> 5.	O	O	Review	669
I am concerned with the relatively sparse set of comparison algorithms the authors use.	B-Review	B-7	Review	669
The authors only compare to relatively simple approaches (support vector regression and logistic ordinal regression), yet they cite many previous works in this area but do not compare against them, instead just leaving a pretty generic statement of "The regression assumption of this method between EEG signals and RT is not correct"; they do not elaborate on this aspect.	I-Review	I-7	Review	669
<sep> <sep> Overall I think there is limited novelty in the approach; the idea to learn the structure of the data relationally instead of absolutely is pretty straight-forward, and is a standard practice for example in non-parametric statistical modeling.	B-Review	B-8	Review	669
I am also not positive that ICLR is the best venue for this work; perhaps a better avenue for this would be in a more BCI/neural engineering-focused venue.	I-Review	I-8	Review	669
<sep> <sep> Thanks for your comments and suggestions regarding our paper.	O	O	Reply	669
We summarize your comments into the following sub-problems and answer each one separately.	O	O	Reply	669
<sep> <sep> Q1: It is unclear to me how the model works at test time; as the model is essentially building a relational structure in the data, does the user have to provide multiple EEG trials at time of prediction?	O	O	Reply	669
<sep> A1: Yes, we need to refer to some baseline trials with known RTs when we do prediction.	B-Reply	B-2	Reply	669
Through the pairwise comparisons with these trials using the learned model, we can get a coarse estimation of the RT.	I-Reply	I-2	Reply	669
Furthermore, these baseline trials are easy to access as long as their RTs are diverse enough, e.g. some trails in the training dataset with diverse RTs.	I-Reply	I-2	Reply	669
<sep> <sep> Q2:  Equation (1) describes two sets of propositions, with M1 and M2 elements, respectively.	O	O	Reply	669
How is M1 and M2, the total set of propositions, calculated?	O	O	Reply	669
It appears to be all pair-wise comparisons of RTs but then it's unclear why there are two indexes associated with them.	O	O	Reply	669
<sep> A2: D1 denotes the type-1 preference propositions that the orderings between the RTs are significant.	B-Reply	B-3	Reply	669
M1 is the total number of D1; while D2 denotes the type-2 preference propositions that the RTs in each comparison are comparable.	I-Reply	I-3	Reply	669
M2 is the total number of D2.	I-Reply	I-3	Reply	669
We use different indexes for D1 and D2 for the convenience of explanation in the optimization part.	I-Reply	I-3	Reply	669
<sep> <sep> Q3: What does it mean for the orderings to be significant? (	O	O	Reply	669
i.e.: that the "type-1 preference propositions that the orderings between the RTs are significant").	O	O	Reply	669
<sep> A3: The word "significant" denotes the difference between RTs is significant, namely RT1 is significantly greater/smaller than RT2, regardless of random unknown noisy introduced by the instrument error.	B-Reply	B-4	Reply	669
We empirically realize this as RT2 < min (RT2+1, 1.5*RT2) < RT1 in the experiment part.	I-Reply	I-4	Reply	669
<sep> <sep> Q4: The authors then switch to a new notation x^1 and x^2 without defining them.	O	O	Reply	669
<sep> The pairwise brain dynamics preference (x^1_{n,m}, x^2_{n,m}) is first introduced after Equation 1,  denoting the features recorded within the n-th channel for each preference proposition in D1 or D2.	B-Reply	B-5	Reply	669
In Section 2b, we omitted the subscript (n,m) for the sake of simplicity.	I-Reply	I-5	Reply	669
<sep> <sep> Q5: The authors describe using an FFT to transform the EEG data into the frequency domain.	O	O	Reply	669
I'm assuming they are doing the FFT on the entire 10-s interval but the paper does not make this clear.	O	O	Reply	669
Also, the authors‚Äô state using EEG power between 0-30Hz for their analysis; do they further sub-divide this range (for example, to the standard theta/alpha/beta power ranges) or just use the power across the entire 0-30Hz band?	O	O	Reply	669
<sep> A5: Yes, Your understanding is correct.	B-Reply	B-6	Reply	669
We do the FFT on the entire 10-s interval.	I-Reply	I-6	Reply	669
And we use the power across the entire 0-30Hz band as the feature vector.	I-Reply	I-6	Reply	669
<sep> If needed, we can further introduced the group loss on the regression weight w, with each group corresponding to the standard theta/alpha/beta power ranges, respectively.	I-Reply	I-6	Reply	669
Let our model to select the most relevant power ranges in a data-driven approach.	I-Reply	I-6	Reply	669
<sep> <sep> Q6: I am concerned with the relatively sparse set of comparison algorithms the authors use.	O	O	Reply	669
The authors only compare to relatively simple approaches (support vector regression and logistic ordinal regression),	O	O	Reply	669
A6: SVR and LOR are selected with careful consideration.	B-Reply	B-7	Reply	669
The two baselines are considered to be a strong support for our claims: (1) Ordinal Classification based attempts are more suitable for mental fatigue evaluation, especially with non-smooth response variable (RTs); (2) the channel state indeed affects the performance of the learning model.	I-Reply	I-7	Reply	669
<sep> <sep> SVR is chosen as the representative for the regression based attempts for the following concerns: (1) SVR is considered to achieve the same performance with the shallow neural networks, while the parameters for SVR are much more easier to tune to the best using cross validation, as we did in the paper. (	I-Reply	I-7	Reply	669
2) The number of trials for each participant is about 200, which is too small to train a deep neural network. (	I-Reply	I-7	Reply	669
3) As it shown in Figure 3, even the SVR (using 5-fold cross validation) is still easier to overfit due to the non-smooth property of RTs, let alone other neural network based attempts.	I-Reply	I-7	Reply	669
<sep> <sep> LOR is chosen as the representative for the ordinal classification based attempts due to its simplicity.	I-Reply	I-7	Reply	669
LOR is optimized with L-BFGS with the default setting for all participants.	I-Reply	I-7	Reply	669
The surprised result of LOR is a strong support to our claim that ordinal classification based attempts are more suitable for mental fatigue evaluation.	I-Reply	I-7	Reply	669
Of course, LOR can be easily replaced to more complex structures, e.g. deep neural network, to achieve more superior performance.	I-Reply	I-7	Reply	669
Furthermore, LOR can also be extended to input image data, like fRMI.	I-Reply	I-7	Reply	669
Note that our BDrank, introducing a transition matrix on top of LOR, still enjoys the superiority of LOR.	I-Reply	I-7	Reply	669
Those extensions, which are not the focus of this paper, are left for later studies.	I-Reply	I-7	Reply	669

The paper studies fatigue monitoring of EEG driving simulator experiments using various EEG analysis algorithms, one also based on ranking.	O	O	Review	669
The data used was from a prior experiment.	O	O	Review	669
<sep> <sep> The paper is written in a rather confusing manner, which makes the assessment of originality and significance a hard task for the reviewer.	B-Review	B-1	Review	669
A novel algorithm Bdrank (based on raking is defined) and compared to 2 other algorithms; unclear why with these and not with others.	I-Review	I-1	Review	669
The paper ignores a large portion of the literature, starting with Kohlmorgen et al 2007, Blankertz group, Lee group etc.	B-Review	B-2	Review	669
<sep> The results  are only somewhat interesting, no understanding of the underlying physiological processes is given.	B-Review	B-3	Review	669
<sep> <sep> Overall, I consider the paper somewhat preliminary.	O	O	Review	669
Thanks for your comments and questions regarding our paper.	O	O	Reply	669
We summarize your comments into the following three sub-problems and answer each one separately.	O	O	Reply	669
<sep> <sep> Q1: It is unclear why the paper compares with two algorithms (SVR and LOR) and not with others.	O	O	Reply	669
<sep> A1: Considering the non-smooth property of human response time during data collection, regular regression methods generally suffer from poor generalization performance.	B-Reply	B-1	Reply	669
In this paper, we introduce BDrank, which could learn from brain dynamics preferences.	I-Reply	I-1	Reply	669
Particularly, BDrank aims at preserving the ordering corresponding to the whole RTs instead of estimating the exact value of a single RT like previous attempts.	I-Reply	I-1	Reply	669
Therefore, the main argument of this paper lies in Regression V.S. Ordinal Classification.	I-Reply	I-1	Reply	669
<sep> SVR is chosen as the representative for the regression-based attempts for the following concerns: (1) SVR is considered to achieve the same performance with the shallow neural networks, while the parameters for SVR are much easier to tune to the best using cross-validation, as we did in the paper. (	I-Reply	I-1	Reply	669
2) The number of trials for each participant is about 200, which is too small to train a deep neural network. (	I-Reply	I-1	Reply	669
3) As is shown in Figure 3, even the SVR (using 5-fold cross validation) is still easier to overfit due to the non-smooth property of RTs, let alone other neural network based attempts.	I-Reply	I-1	Reply	669
<sep> LOR is chosen as the representative for the ordinal classification based attempts due to its simplicity.	I-Reply	I-1	Reply	669
LOR is optimized with L-BFGS with the default setting for all participants.	I-Reply	I-1	Reply	669
The surprising result of LOR is a strong support to our claim that ordinal classification based attempts are more suitable for mental fatigue evaluation.	I-Reply	I-1	Reply	669
Of course, LOR can be easily replaced with more complex structures, e.g. neural network, to achieve more superior performance.	I-Reply	I-1	Reply	669
Furthermore, LOR can also be extended to input image data, like fMRI.	I-Reply	I-1	Reply	669
<sep> In a word, SVR and LOR are selected with careful consideration.	I-Reply	I-1	Reply	669
The two baselines are considered to be a strong support for our claims: (1) Ordinal Classification based attempts are more suitable for mental fatigue evaluation, especially with non-smooth response variable (RTs); (2) the channel state indeed affects the performance of the learning model.	I-Reply	I-1	Reply	669
Note that our BDrank, introducing a transition matrix on top of LOR, still enjoys the superiority for LOR.	I-Reply	I-1	Reply	669
Those extensions, which are not the focus of this paper, are left for later studies.	I-Reply	I-1	Reply	669
<sep> <sep> Q2: The results are only somewhat interesting, no understanding of the underlying physiological processes is given.	O	O	Reply	669
<sep> Page 2, Experiment Paradigm section mentioned that data recorded from the previous study from Huang et al 2015, showed that EEG related activity is correlated with behavioural information like reaction time (RT) and demonstrated that how the decline in vigilance occur during driving.	B-Reply	B-3	Reply	669
The results presented in this paper further demonstrated that indeed behavioural information like RT is highly related to EEG brain dynamics.	I-Reply	I-3	Reply	669
<sep> Further, Table 1 adopts the Wilcoxon-Mann-Whitney statistic to verify whether the learning model could maintain the pairwise comparison between two EEG signals (See Figure 1B).	I-Reply	I-3	Reply	669
In terms of LOR and our BDrank, we just collect the prediction accuracy for each pairwise comparison and average on the whole dataset.	I-Reply	I-3	Reply	669
In terms of SVR, we followed the standard procedure to train the learning model for each participant and then get the predicted RTs on the training and test dataset, respectively.	I-Reply	I-3	Reply	669
Instead of calculating the RMSE loss, we calculate the classification error on the generated pairwise comparisons as what we do for LOR and BDrank.	I-Reply	I-3	Reply	669
<sep> Table 2 and Figure 3 adopt the indegree sequence to verify whether the learning model could preserving the global ordering corresponding to RTs.	I-Reply	I-3	Reply	669
We first collected the indegree sequences (See Appendix) of the constructed directed graph using the predicted RTs and then measured the indegree discrepancy between the calculated indegree sequences and the ground truth using the root-mean-squared error (RMSE).	I-Reply	I-3	Reply	669
See Figure 3, if the predicted indegree sequences could closely align with the ground truth, the learning model can perfectly preserve the whole ordering w.r.t.RTs.	I-Reply	I-3	Reply	669
<sep> Figure 4 presents the estimated state of different channels for forty-four participants.	I-Reply	I-3	Reply	669
Each column denotes the states of 33 channels for each participant.	I-Reply	I-3	Reply	669
According to our analysis, the parameter \pi_n in the transition matrix indicates the channel reliability.	I-Reply	I-3	Reply	669
Then we classify the 33 channels into positive (\pi_n>0.85), noisy (0.15<\pi_n<0.85) and negative (\pi_n<0.15) channels according to the estimated channel reliability \pi_n.	I-Reply	I-3	Reply	669

This paper proposes a novel variant of Q-learning, called Maxmin Q-learning, to address the issue of overestimation bias Q-learning suffers from (variance of the reward of best action leading to overestimated reward).	O	O	Review	20696
The idea is to keep a number of estimators each estimated using a different sub-sample, and taking the minimum of the (maximum) reward value of each.	O	O	Review	20696
The paper gives theoretical analyses, in terms of the reduction in the overestimation bias, as well as the convergence of a class of generalized Q-learning methods including Maxmin Q-learning.	O	O	Review	20696
The experiment section presents a thorough evaluation of the proposed method, including how the obtained rewards vary as a function of the variance of the reward function and as a function of learning steps, as compared to a number of existing methods such as the Double Q-learning method and its variants.	O	O	Review	20696
The experimental results are quite convincing, and the theoretical analyses seem solid.	O	O	Review	20696
Overall this is a well balanced paper which proposes a reasonable new idea, simple but effective, backed by sound theoretical analysis and well executed experimental evaluation.	O	O	Review	20696
Thank you for your positive comments!	O	O	Reply	20696

This paper proposes a new Q learning algorithm framework: maxmin Q-learning, to address the overestimation bias issue of Q learning.	O	O	Review	20696
The main contributions of this paper are three folds: 1) It provides an inspiring example on overestimation/underestimation of Q learning.	O	O	Review	20696
2) Generalize Q learning by a new maxmin Q-learning by maintaining independent Q estimator and interact them in a max-min way for the update.	O	O	Review	20696
3) Provide both theoretical and empirical analyses of their algorithm.	O	O	Review	20696
<sep> <sep> I have two main concerns for this paper:	O	O	Review	20696
1) When is your algorithm useful?	B-Review	B-1	Review	20696
What's your criterion of picking the hyper-parameters (e.g. number of Q functions you want to learn).	I-Review	I-1	Review	20696
<sep> 2) Comparison to more intriguing way for jointly update of multiple Q functions, like soft Q learning.	B-Review	B-2	Review	20696
<sep> <sep> For the first concern, the paper has shown an interesting example in Figure 2.	B-Review	B-1	Review	20696
However, it seems that we cannot decide whether overestimation or underestimation will help the exploration, since the reward function is often unknown in real world.	I-Review	I-1	Review	20696
And in both cases, maxmin Q learning is not the best algorithm than either Q learning and double q learning.	I-Review	I-1	Review	20696
On the other hand, if we use a softmax policy for Q function, e.g., a drift for Q learning(e.g.	I-Review	I-1	Review	20696
Q(s,a) = Q*(s,a) + c) has no effect on our policy.	I-Review	I-1	Review	20696
I believe in this case we should more focusing on the inner difference between different value of Q function, rather than comparing our estimate Q function with the true Q*.	I-Review	I-1	Review	20696
<sep> For the second concern, we can view the framework of maxmin q learning as a joint update scheme for different Q function.	B-Review	B-2	Review	20696
In experimental part, the comparison is not fair since the paper use multiple Q function to compare with single or double Q function.	I-Review	I-2	Review	20696
One reasonable baseline is to update N different Q function, and take the minimum of the final Q function as our decision policy, compare with maxmin Q learning with N different Q function.	I-Review	I-2	Review	20696
Another baseline the paper should consider is soft Q learning, where it maintain multiple Q function and jointly update Q different function to maximize the entropy while moving towards an improvement Q.	I-Review	I-2	Review	20696
<sep> Overall, I believe the idea of the paper is novel and interesting, but further improvements should be added in order to improve the score the paper.	O	O	Review	20696
We appreciate your feedback.	O	O	Reply	20696
<sep> <sep> For the first concern, you are right, we cannot know for an unknown environment whether overestimation or underestimation will help.	B-Reply	B-1	Reply	20696
This is exactly what we show in section 3 -- the optimal bias is environment dependent.	I-Reply	I-1	Reply	20696
So the optimal N is also environment dependent.	I-Reply	I-1	Reply	20696
N is a parameter that can be tuned, to specialize to each different problem.	I-Reply	I-1	Reply	20696
However, the theory does provide some guidance, namely by setting to remove bias.	I-Reply	I-1	Reply	20696
For example, when M=4, a choice of N=3 reduces the bias to near 0 (more results are shown in Figure 5).	I-Reply	I-1	Reply	20696
This may not be the right choice, though, if the noise does not satisfy the assumptions.	I-Reply	I-1	Reply	20696
In our experiments, we found that the optimal N was usually between 2 to 9, and that performance was usually improved with relatively small N. But, more work is needed to better understand more generally how to select N automatically.	I-Reply	I-1	Reply	20696
<sep> <sep> The MDP we present in section 3 is designed as a motivating example to show that overestimation and underestimation bias can both help and hurt.	I-Reply	I-1	Reply	20696
Note that we fixed the step-size and other hyperparameters for all algorithms (instead of tuning them in order to achieve the best performance) since this MDP was not used as a benchmark for performance comparison.	I-Reply	I-1	Reply	20696
It is just an illustrative example.	I-Reply	I-1	Reply	20696
<sep> <sep> We are not exactly sure what you mean by your comment that "a drift for Q learning (e.g.) has no effect on our policy".	I-Reply	I-1	Reply	20696
What is c?	I-Reply	I-1	Reply	20696
If it is a constant for all actions, absolutely it has no effect.	I-Reply	I-1	Reply	20696
But, the problem we are solving is that, due to stochasticity, a different constant could be added for each.	I-Reply	I-1	Reply	20696
This will effect the policy.	I-Reply	I-1	Reply	20696
If c is random, could you clarify further what you mean here?	I-Reply	I-1	Reply	20696
<sep> <sep> You are right that our Maxmin Q-learning is a joint update scheme for different Q functions, and one of our contributions is that we provide a convergence proof for such a framework under reasonable assumptions.	B-Reply	B-2	Reply	20696
However, we politely disagree with your claim that our empirical comparison is unfair.	I-Reply	I-2	Reply	20696
Note that on Mountain Car (Figure 3), we compare Double Q-learning, Averaged Q-learning (N=2), and Maxmin Q-learning (N=2).	I-Reply	I-2	Reply	20696
Here, all three algorithms have two Q functions and Maxmin Q-learning shows significant robustness and achieves better performance.	I-Reply	I-2	Reply	20696
Similarly, in the other seven more complex environments, both Maxmin DQN and Averaged DQN learn multiple Q functions.	I-Reply	I-2	Reply	20696
And the number of Q functions is tuned in the same scope.	I-Reply	I-2	Reply	20696
Again, Maxmin DQN outperforms Averaged DQN.	I-Reply	I-2	Reply	20696
So we believe the comparison is fair.	I-Reply	I-2	Reply	20696
<sep> <sep> We are also unsure about what you mean by "one reasonable baseline is to update N different Q function, and take the minimum of the final Q function as our decision policy."	I-Reply	I-2	Reply	20696
This could mean the following.	I-Reply	I-2	Reply	20696
N Q functions are learned with Q-learning (rather than say with the Maxmin update).	I-Reply	I-2	Reply	20696
On each step, the agent selects actions using the max action from the minimum of the Q functions. (	I-Reply	I-2	Reply	20696
If this is not what you intended, please do clarify).	I-Reply	I-2	Reply	20696
Theoretically, this strategy also incurs overestimation bias since it uses the same target action-value as Q-learning to update.	I-Reply	I-2	Reply	20696
Further it does not reduce estimation variance because it uses only one Q function to update.	I-Reply	I-2	Reply	20696
<sep> <sep> For Soft Q-learning (SQL), we assume you mean the algorithm from the paper Reinforcement Learning with Deep Energy-Based Policies by Haarnoja et al (again, please correct us if we are wrong).	I-Reply	I-2	Reply	20696
Maxmin Q-learning is a value-based method for discrete control to flexibly control bias and reduce variance.	I-Reply	I-2	Reply	20696
In contrast, SQL is a policy-based method for continuous control, with just one action-value function (the policy is a Gibbs distribution on Q function).	I-Reply	I-2	Reply	20696
It is not clear why we would compare to SQL, since it only uses one Q function and tackles a different problem.	I-Reply	I-2	Reply	20696
If you can further clarify why we should compare to SQL, we would be happy to respond further.	I-Reply	I-2	Reply	20696

The paper tackles the problem of bias in target Q-values when performing Q-learning.	O	O	Review	20696
The paper proposes a technique for computing target Q-values, by first taking the min over an ensemble of learned Q-values and then taking the max over actions.	O	O	Review	20696
The paper provides some theoretical properties of this technique: (1) the bias of the estimator can be somewhat controlled by the size of the ensemble; (2) performing Q-learning with these target values is convergent.	O	O	Review	20696
Experimental results show that the proposed technique can provide performance improvement on a number of tasks.	O	O	Review	20696
<sep> <sep> Overall, this paper is a modest contribution to the field, since variants of this technique are known and the theoretical arguments are derivatives of known arguments, which places it roughly borderline for an ICLR conference paper.	O	O	Review	20696
<sep> <sep> My comments:	O	O	Review	20696
-- The paper is very well-written.	O	O	Review	20696
Thank you for putting the effort to provide clear writing.	O	O	Review	20696
<sep> -- The idea of computing a target value as the minimum of an ensemble is well-known in continuous control.	B-Review	B-1	Review	20696
See <a href="https://arxiv.org/abs/1802.09477" target="_blank" rel="nofollow">https://arxiv.org/abs/1802.09477</a> as well as a number of works which follow it.	I-Review	I-1	Review	20696
<sep> -- The method is motivated as a way to control over/under-estimation.	B-Review	B-2	Review	20696
However, the theoretical arguments show that this depends on N, M, and tau (unknown).	I-Review	I-2	Review	20696
Are there any ways to choose N other than hyperparameter tuning?	I-Review	I-2	Review	20696
Thank you for your valuable comments.	O	O	Reply	20696
We will address your concerns point by point.	O	O	Reply	20696
<sep> <sep> First, thank you for pointing us to this control work, which we were not aware of.	B-Reply	B-1	Reply	20696
However, we would like to point out the significant difference between Maxmin Q-learning and TD3 in the paper you mentioned when computing the target value.	I-Reply	I-1	Reply	20696
For Maxmin Q-learning, we first take the minimum of action-values among all N estimators and then choose the action that maximizes these minimum action-values, i.e.. However, in TD3, the action is chosen first by some policy, and then the minimum action-value is selected as the target value, i.e.. The policy is expected to converge to the optimal policy, so.	I-Reply	I-1	Reply	20696
Thus, we have.	I-Reply	I-1	Reply	20696
Note that the order of taking minimum and maximum is different.	I-Reply	I-1	Reply	20696
By the max‚Äìmin inequality, it is easy to get.	I-Reply	I-1	Reply	20696
Furthermore, using the same method as in our paper, we can get where.	I-Reply	I-1	Reply	20696
Thus TD3 still suffers from the overestimation bias, while we can adjust in Maxmin Q-learning to reduce the bias from positive to negative.	I-Reply	I-1	Reply	20696
In conclusion, these two techniques may seem to be similar at first glance, but they are actually quite different and lead to different properties.	I-Reply	I-1	Reply	20696
We will cite the TD3 paper and add one more paragraph to discuss the difference in our revised paper.	I-Reply	I-1	Reply	20696
<sep> <sep> Also, there is no theoretical analysis for applying the minimum operator in TD3 paper, whereas we present a theoretical analysis not only for bias control but also for variance reduction.	I-Reply	I-1	Reply	20696
Actually, when we first tried to solve the overestimation bias problem, we also considered a similar approach to TD3 (we called it Minmax Q-learning as a counterpart).	I-Reply	I-1	Reply	20696
However, after some derivatives and analyses, we found that Maxmin Q-learning would be better than Minmax Q-learning theoretically, in terms of reducing overestimation bias.	I-Reply	I-1	Reply	20696
These theoretical analyses guided our design of the Maxmin Q-learning algorithm.	I-Reply	I-1	Reply	20696
They are important and non-trivial.	I-Reply	I-1	Reply	20696
You are right that "the theoretical arguments are derivatives of known arguments", but this is the case for many theoretical arguments.	I-Reply	I-1	Reply	20696
We have not come up with a new proof technique, but do have a novel theoretical result characterizing a new algorithm.	I-Reply	I-1	Reply	20696
<sep> <sep> Choosing the optimal N is not straightforward.	B-Reply	B-2	Reply	20696
It is a parameter that can be tuned, to specialize for each different problem setting.	I-Reply	I-2	Reply	20696
The theory does provide some guidance, namely by setting to remove bias.	I-Reply	I-2	Reply	20696
For example, when M=4, a choice of N=3 reduces the bias to near 0 (more results are shown in Figure 5).	I-Reply	I-2	Reply	20696
This may not be the right choice, though, if the noise does not satisfy the assumptions.	I-Reply	I-2	Reply	20696
In our experiments, we found that the optimal N was usually between 2 to 9, and that performance was usually improved with relatively small N. You are correct that future work should investigate how best to select N.	I-Reply	I-2	Reply	20696

This paper proposes a method for estimating the context sensitivity of paraphrases and uses that to inform a word embedding learning model.	O	O	Review	625
The main idea and model are presented convincingly and seem plausible.	O	O	Review	625
The main weaknesses of the paper are shortcomings in the experimental evaluation and in the model exploration.	O	O	Review	625
The evaluation does not convincingly determine whether the model is a significant improvement over simpler methods (particularly those that do not require the paraphrase database!).	B-Review	B-1	Review	625
Likewise, the model section did not convince me that this was the most obvious model formulation to try.	I-Review	I-1	Review	625
The paper would be stronger if model choices were explained more convincingly or - better yet - alternatives were explored.	I-Review	I-1	Review	625
<sep> <sep> On balance I lean towards rejecting the paper and encouraging the authors to submit a revised and improved version at a near point in the future.	O	O	Review	625
<sep> <sep> Detailed/minor points below:	O	O	Review	625
<sep> 1) While the paper is grammatically mostly correct, it would benefit from revision with the help of a native English speaker.	B-Review	B-2	Review	625
In its current form long sections are very difficult to understand due to the unconventional sentence structure.	I-Review	I-2	Review	625
<sep> 2) The tables need better and more descriptive labels.	B-Review	B-3	Review	625
<sep> 3) The results are somewhat inconclusive.	B-Review	B-4	Review	625
Particularly in the analogy task in Table 4 it is surprising that CBOW does better on the semantic aspect of the task than your embeddings which are specifically tailored to be good at this?	I-Review	I-4	Review	625
<sep> 4) Why was "Enriched CBOW" not included in the analogy task?	B-Review	B-5	Review	625
<sep> 5) In the related work section several papers are mentioned that learn embeddings from a combination of lexica and corpora, yet it is repeatedly said that this was the first work of such a kind / that there hasn't been enough work on this.	B-Review	B-6	Review	625
That feels a little misleading.	I-Review	I-6	Review	625
Hello.	O	O	Reply	625
Thank you again for your reviews.	O	O	Reply	625
<sep> <sep> We have made some additional revisions as our final version before the decision.	O	O	Reply	625
<sep> <sep> 1.	O	O	Reply	625
We realized that the benchmarks are testing different aspects of the vectors.	O	O	Reply	625
We do not think the inconsistency for best parameters is an issue now.	O	O	Reply	625
We put the changes of the benchmark scores under different vector dimensions from section 3.2 to 3.3 as it is about the effect of vector dimensions.	O	O	Reply	625
We also revised the title of section 3.2 from "Issues about benchmarks" to "Benchmarks."	O	O	Reply	625
<sep> 2.	O	O	Reply	625
We used our proposed model instead of fastText to test the margin of errors for the benchmarks and revised section 3.2.	O	O	Reply	625
<sep> 3.	O	O	Reply	625
We also revised the discussion on the parameters and gave a more detailed discussion in section 3.	O	O	Reply	625
<sep> 4.	B-Reply	B-3	Reply	625
We revised the y labels in the figures to keep the same float format.	I-Reply	I-3	Reply	625
<sep> 5.	B-Reply	B-1	Reply	625
We add an explanation of the transpose mark for Equation (5) in section 2.4.	I-Reply	I-1	Reply	625
<sep> 6.	O	O	Reply	625
We add the missed introduction of Figure 2 in section 3.3.	O	O	Reply	625
<sep> We recheck the misspellings and grammar mistakes.	B-Reply	B-2	Reply	625
<sep> <sep> Thank you again for spending the time to read our papers and the helpful advice.	O	O	Reply	625

This paper tries to leverage an external lexicon / knowledge base to improve corpus-based word representations by determining (in a fuzzy way) which potential paraphrase is the most appropriate in a particular context.	O	O	Review	625
<sep> <sep> I think this paper is a bit lost in translation.	B-Review	B-1	Review	625
The grammatical and storytelling styles made it really difficult for me to concentrate, and even unintelligible at times.	I-Review	I-1	Review	625
One of the most important criteria in a conference paper is to communicate one's ideas clearly; unfortunately, I do not feel that this paper meets that standard.	I-Review	I-1	Review	625
<sep> <sep> In addition, the evaluation is rather lacking.	B-Review	B-2	Review	625
There are many ways to evaluate word representations, and Google's analogy dataset has many issues (see, for example, Linzen's paper from RepEval 2016, as well as Drozd et al COLING 2016).	I-Review	I-2	Review	625
<sep> <sep> Finally, this work does not provide any qualitative result or motivation.	B-Review	B-3	Review	625
Why does this method work better?	I-Review	I-3	Review	625
Where does it fail?	I-Review	I-3	Review	625
What have we learned about word representations / lexicons / corpus-based methods in general?	I-Review	I-3	Review	625
Hello.	O	O	Reply	625
Thank you again for your reviews.	O	O	Reply	625
<sep> <sep> We have made some additional revisions as our final version before the decision.	O	O	Reply	625
<sep> <sep> 1.	O	O	Reply	625
We realized that the benchmarks are testing different aspects of the vectors.	O	O	Reply	625
We do not think the inconsistency for best parameters is an issue now.	O	O	Reply	625
We put the changes of the benchmark scores under different vector dimensions from section 3.2 to 3.3 as it is about the effect of vector dimensions.	O	O	Reply	625
We also revised the title of section 3.2 from "Issues about benchmarks" to "Benchmarks."	O	O	Reply	625
<sep> 2.	O	O	Reply	625
We used our proposed model instead of fastText to test the margin of errors for the benchmarks and revised section 3.2.	O	O	Reply	625
<sep> 3.	O	O	Reply	625
We also revised the discussion on the parameters and gave a more detailed discussion in section 3.	O	O	Reply	625
<sep> 4.	O	O	Reply	625
We revised the y labels in the figures to keep the same float format.	O	O	Reply	625
<sep> 5.	O	O	Reply	625
We add an explanation of the transpose mark for Equation (5) in section 2.4.	O	O	Reply	625
<sep> 6.	O	O	Reply	625
We add the missed introduction of Figure 2 in section 3.3.	O	O	Reply	625
<sep> We recheck the misspellings and grammar mistakes.	B-Reply	B-1	Reply	625
<sep> <sep> Thank you again for spending the time to read our papers and the helpful advice.	O	O	Reply	625

This paper introduces the concept of fuzzy paraphrases to aid in the learning of distributed word representations from a corpus augmented by a lexicon or ontology.	O	O	Review	625
Sometimes polysemy is context-dependent, but prior approaches have neglected this fact when incorporating external paraphrase information during learning.	O	O	Review	625
The main idea is to introduce a function that essentially judges the context-sensitivity of paraphrase candidates, down-weighting those candidates that depend strongly on context.	O	O	Review	625
This function is inferred from bilingual translation agreement.	O	O	Review	625
<sep> <sep> The main argumentation leading to the model selection is intuitive, and I believe that the inclusion of good paraphrases and the elimination of bad paraphrases during training should in principle improve word representation quality.	O	O	Review	625
However, the main questions are how well the proposed method achieves this goal, and, even if it achieves it well, whether it makes much difference in practical terms.	B-Review	B-1	Review	625
<sep> <sep> Regarding the first question, I am not entirely convinced that the parameterization of the control function f(x_ij) is optimal.	B-Review	B-2	Review	625
It would have been nice to see some experiments investigating different choices, in particular some baselines where the effect of f is diminished (so that it reduces to f=1 in the limit) would have been interesting.	I-Review	I-2	Review	625
I also feel like there would be a lot to gain from having f be a function of the nearby word embeddings, though this would obvious incur a significant slowdown. (	I-Review	I-2	Review	625
See for example 'Efficient Non-parametric Estimation of Multiple Embeddings per Word in Vector Space' by Neelakantan et al, which should probably be cited.)	I-Review	I-2	Review	625
As it stands, the experimental results do not clearly distinguish the fuzzy paraphrase approach from prior work, i.e. tables 3 and 4 do not show major trends one way or the other.	I-Review	I-2	Review	625
<sep> <sep> Regarding the second question, it is hard to draw many conclusions from analogy tasks alone, especially when effects unrelated to good/bad paraphrasing such as corpus size/content, window size, vocabulary size, etc.,	B-Review	B-3	Review	625
can have an outsize effect on performance.	I-Review	I-3	Review	625
<sep> <sep> Overall, I think this is a good paper presenting a sensible idea, but I am not convinced by the experiments that the specific approach is achieving its goal.	O	O	Review	625
With some improved experiments and analysis, I would wholeheartedly recommend this paper for acceptance; as it stands, I am on the fence.	O	O	Review	625
Hello.	O	O	Reply	625
Thank you again for your reviews.	O	O	Reply	625
<sep> <sep> We have made some additional revisions as our final version before the decision.	O	O	Reply	625
<sep> <sep> 1.	O	O	Reply	625
We realized that the benchmarks are testing different aspects of the vectors.	O	O	Reply	625
We do not think the inconsistency for best parameters is an issue now.	O	O	Reply	625
We put the changes of the benchmark scores under different vector dimensions from section 3.2 to 3.3 as it is about the effect of vector dimensions.	O	O	Reply	625
We also revised the title of section 3.2 from "Issues about benchmarks" to "Benchmarks."	O	O	Reply	625
<sep> 2.	O	O	Reply	625
We used our proposed model instead of fastText to test the margin of errors for the benchmarks and revised section 3.2.	O	O	Reply	625
<sep> 3.	O	O	Reply	625
We also revised the discussion on the parameters and gave a more detailed discussion in section 3.	O	O	Reply	625
<sep> 4.	O	O	Reply	625
We revised the y labels in the figures to keep the same float format.	O	O	Reply	625
<sep> 5.	O	O	Reply	625
We add an explanation of the transpose mark for Equation (5) in section 2.4.	O	O	Reply	625
<sep> 6.	O	O	Reply	625
We add the missed introduction of Figure 2 in section 3.3.	O	O	Reply	625
<sep> We recheck the misspellings and grammar mistakes.	O	O	Reply	625
<sep> <sep> Thank you again for spending the time to read our papers and the helpful advice.	O	O	Reply	625

<sep> Summary:	O	O	Review	10105
<sep> The paper proposes to expand the VAE architecture with a	O	O	Review	10105
mixture-of-experts latent representation, with a	O	O	Review	10105
mixture-component-specific decoder that can specialize in a specific	O	O	Review	10105
cluster.	O	O	Review	10105
Importantly, the method can take advantage of a similarity	O	O	Review	10105
matrix to help with the clustering.	O	O	Review	10105
<sep> <sep> Overall, I recommend a weak accept.	O	O	Review	10105
The method seems reasonable, and	O	O	Review	10105
the paper is well-written, but the results are only marginally better	O	O	Review	10105
than other methods, and there are several weaknesses with the proposed	O	O	Review	10105
architecture and experimental setup.	O	O	Review	10105
<sep> <sep> Positives:	O	O	Review	10105
<sep> * The idea of a more expressive variational distribution seems good,	O	O	Review	10105
although it is not novel.	O	O	Review	10105
<sep> <sep> * The ability to have multiple decoder networks seems reasonable.	O	O	Review	10105
<sep> <sep> * The ability to incorporate domain knowledge (in the form of a	O	O	Review	10105
similarity matrix S) is a plus.	O	O	Review	10105
<sep> <sep> * The experiments are thorough, although the method is generally only	O	O	Review	10105
slightly better than competing methods.	O	O	Review	10105
<sep> <sep> Negatives:	O	O	Review	10105
<sep> * It's not clear if the similarity matrix S is already solving the	B-Review	B-1	Review	10105
clustering problem - in which case, why do we need the rest of the	I-Review	I-1	Review	10105
model?	I-Review	I-1	Review	10105
For example, in your experiments you often used UMAP to	I-Review	I-1	Review	10105
cluster data.	I-Review	I-1	Review	10105
How does using UMAP by itself work?	I-Review	I-1	Review	10105
(Along these	I-Review	I-1	Review	10105
lines, it was not clear if your GMM experiments clustered data in	I-Review	I-1	Review	10105
the original space, or in the UMAP'd space - please clarify this).	I-Review	I-1	Review	10105
<sep> A good ablation would be to somehow remove the S matrix, to see if	I-Review	I-1	Review	10105
the model can accurately cluster samples.	I-Review	I-1	Review	10105
<sep> <sep> * There is little variance in the generated samples.	B-Review	B-2	Review	10105
<sep> * There is not a one-to-one mapping of clusters to labels, so it is	B-Review	B-3	Review	10105
hard to use this method to generate a specific type of data (for	I-Review	I-3	Review	10105
example, it is hard to generate a specific digit).	I-Review	I-3	Review	10105
This is a big	I-Review	I-3	Review	10105
difference from, say, a conditional sampler as learned by a GAN.	I-Review	I-3	Review	10105
<sep> This also arises in Fig.3, where it is clear that latent cluster	I-Review	I-3	Review	10105
assignments do not match human-interpretable cluster assignments.	I-Review	I-3	Review	10105
I	I-Review	I-3	Review	10105
suppose this is to be expected, but taken with the previous point	I-Review	I-3	Review	10105
(little variance in generated samples) I think it seriously weakens	I-Review	I-3	Review	10105
the paper's claim that this is an "accurate an efficient data	I-Review	I-3	Review	10105
generation method."	I-Review	I-3	Review	10105
<sep> <sep> * The method does not do well when the number of clusters is large.	B-Review	B-4	Review	10105
<sep> Regular GMMs seem to outperform it.	I-Review	I-4	Review	10105
<sep> <sep> * I felt that this paper made excessive use of the appendix.	B-Review	B-5	Review	10105
The	I-Review	I-5	Review	10105
paper is not self-contained enough, effectively violating the length	I-Review	I-5	Review	10105
restrictions.	I-Review	I-5	Review	10105
Please make an effort to move key results back in to	I-Review	I-5	Review	10105
the main body of the paper.	I-Review	I-5	Review	10105
<sep> <sep> <sep> Experiments to run:	B-Review	B-1	Review	10105
<sep> An ablation regarding the similarity matrix S.	I-Review	I-1	Review	10105
<sep> Clarification of whether GMM experiments are run in data-space, or	B-Review	B-6	Review	10105
UMAP'd space.	I-Review	I-6	Review	10105
<sep> <sep> MIXAE features prominently in your related works, but is not compared	B-Review	B-7	Review	10105
to in your experiments.	I-Review	I-7	Review	10105
It sounds like a natural comparison.	I-Review	I-7	Review	10105
Please	I-Review	I-7	Review	10105
run this experiment, or explain why it is not a comparable method.	I-Review	I-7	Review	10105
<sep> <sep> <sep> <sep> Thank you very much for reviewing our paper and your overall positive feedback.	O	O	Reply	10105
Reviewer comments are pasted and marked with ***, author responses follow below:	O	O	Reply	10105
<sep> **** It's not clear if the similarity matrix S is already solving the	O	O	Reply	10105
clustering problem - in which case, why do we need the rest of the	O	O	Reply	10105
model?	O	O	Reply	10105
For example, in your experiments you often used UMAP to	O	O	Reply	10105
cluster data.	O	O	Reply	10105
How does using UMAP by itself work?	O	O	Reply	10105
(Along these	O	O	Reply	10105
lines, it was not clear if your GMM experiments clustered data in	O	O	Reply	10105
the original space, or in the UMAP'd space - please clarify this).	O	O	Reply	10105
<sep> A good ablation would be to somehow remove the S matrix, to see if	O	O	Reply	10105
the model can accurately cluster samples.	O	O	Reply	10105
<sep> <sep> Experiments to run:	O	O	Reply	10105
<sep> An ablation regarding the similarity matrix S.***	O	O	Reply	10105
<sep> The similarity matrix in combination with the clustering network is a key component of the model.	B-Reply	B-1	Reply	10105
We followed your advice to assess in more detail whether the similarity matrix already solves the clustering problem and performed an ablation study on the similarity matrix.	I-Reply	I-1	Reply	10105
We did so by rerunning the experiment on MNIST and setting the loss coefficient for L_Similarity to zero and thereby effectively removing the similarity matrix from our model.	I-Reply	I-1	Reply	10105
As a result, we observed that the clustering network is not able to perform the clustering anymore, mainly because the separation of the different classes in the latent representation is heavily impaired.	I-Reply	I-1	Reply	10105
We added the results to the revised version of our manuscript to section 4.2 and additionally with a figure (A4) in the appendix.	I-Reply	I-1	Reply	10105
<sep> <sep> ‚Äî‚Äî‚Äî‚Äî--	O	O	Reply	10105
<sep> ***Clarification of whether GMM experiments are run in data-space, or	O	O	Reply	10105
UMAP'd space.***	O	O	Reply	10105
<sep> <sep> Similarly, as in our model, we run the GMM experiments also on the data space.	B-Reply	B-6	Reply	10105
The UMAP projection is only used as a transformation and similarity measure to include domain knowledge encoded in the similarity matrix and therefore also to show the advantage of our model.	I-Reply	I-6	Reply	10105
<sep> <sep> ‚Äî‚Äî‚Äî‚Äî--	O	O	Reply	10105
<sep> **** There is not a one-to-one mapping of clusters to labels, so it is	O	O	Reply	10105
hard to use this method to generate a specific type of data (for	O	O	Reply	10105
example, it is hard to generate a specific digit).	O	O	Reply	10105
This is a big	O	O	Reply	10105
difference from, say, a conditional sampler as learned by a GAN.	O	O	Reply	10105
<sep> This also arises in Fig.3, where it is clear that latent cluster	O	O	Reply	10105
assignments do not match human-interpretable cluster assignments.	O	O	Reply	10105
I	O	O	Reply	10105
suppose this is to be expected, but taken with the previous point	O	O	Reply	10105
(little variance in generated samples) I think it seriously weakens	O	O	Reply	10105
the paper's claim that this is an "accurate an efficient data	O	O	Reply	10105
generation method."***	O	O	Reply	10105
<sep> <sep> We fully agree with your feedback on the one-to-one mapping between cluster-ID and labels.	B-Reply	B-3	Reply	10105
This is indeed a disadvantage in comparison to the conditional GANs you mentioned.	I-Reply	I-3	Reply	10105
Future work could incorporate a feature in the framework to be able to condition on the label for generation purposes.	I-Reply	I-3	Reply	10105
Nevertheless, we believe that currently with little effort one can interpret the latent representation and therefore also find a mapping between the experts and label IDs.	I-Reply	I-3	Reply	10105
<sep> <sep> ‚Äî‚Äî‚Äî‚Äî--	O	O	Reply	10105
<sep> **** There is little variance in the generated samples. ***	O	O	Reply	10105
<sep> <sep> We discuss this issue in the conclusion.	B-Reply	B-2	Reply	10105
It is a known ‚Äúproblem‚Äù with VAE that the sample variances and also the sharpness of generated images is lower in comparison to for example images generated with GANs [Dumoulin et al ‚ÄúAdversarially Learned Inference‚Äù;  Theis et al ‚ÄúA note on the evaluation of generative models‚Äù]. We expect that adding adversarial training could be a remedy to generate even more realistic samples as discussed in the conclusion.	I-Reply	I-2	Reply	10105
<sep> <sep> ‚Äî‚Äî‚Äî‚Äî--	O	O	Reply	10105
<sep> ***MIXAE features prominently in your related works, but is not compared	O	O	Reply	10105
to in your experiments.	O	O	Reply	10105
It sounds like a natural comparison.	O	O	Reply	10105
Please	O	O	Reply	10105
run this experiment, or explain why it is not a comparable method.***	O	O	Reply	10105
<sep> <sep> Due to an oversight on our end, we missed to include the results from MIXAE, which we discuss in our related work section.	B-Reply	B-7	Reply	10105
We added them to the manuscript now (Table 1).	I-Reply	I-7	Reply	10105
<sep> <sep> We hope that this addresses your questions and concerns.	O	O	Reply	10105
If you have any other suggestions on how we could improve our paper, please do let us know.	O	O	Reply	10105

The authors present an extension of variational autoencoders (VAEs), where Gaussian distribution of the latent variable is replaced by a mixture of Gaussians.	O	O	Review	10105
The approach can be used for clustering and generation.	O	O	Review	10105
The authors carry out experiments to evaluate the performance of the method in these tasks and compare it to competing methods.	O	O	Review	10105
The paper is well written and easy to read and understand.	O	O	Review	10105
Specialized related work is discussed.	O	O	Review	10105
I find the extension of VAEs to GMMs interesting for the ICLR community, although it is somewhat straight forward in terms of its technical difficulty.	O	O	Review	10105
However, the technical novelty together with the fine empirical evaluation are just good enough for ICLR, in my opinion.	O	O	Review	10105
Thank you very much for reviewing our paper and your overall positive feedback.	O	O	Reply	10105

The proposed method of mixture-of-experts variational autoencoders	O	O	Review	10105
is valuable and insightful.	O	O	Review	10105
<sep> On the other hand the work could be improved and clarified at some points:	O	O	Review	10105
<sep> - in the abstract it is claimed that the method works for high-dimensional data.	B-Review	B-1	Review	10105
However, it should be better explained why this is the case.	I-Review	I-1	Review	10105
The method is largely based on density estimation with a mixture of Gaussians which is known to have limitations in higher dimensions (see e.g. classical textbooks like Bishop 1995)	I-Review	I-1	Review	10105
<sep> - the similarity matrix and the similarity values should be carefully defined.	B-Review	B-2	Review	10105
Is there also an underlying similarity function assumed?	I-Review	I-2	Review	10105
<sep> <sep> - a main shortcoming is that there is no discussion or experimental comparison with methods like spectral clustering and kernel spectral clustering.	B-Review	B-3	Review	10105
Given that the paper and the proposed method relates to similarity-based representations it would be important to know how it compares to such methods.	I-Review	I-3	Review	10105
Though e.g. in Table 1 the authors compare with about 10 other methods it would be more relevant that among some of these would have been spectral clustering and kernel spectral clustering, because of the similarity-based representations.	I-Review	I-3	Review	10105
<sep> <sep> - in section 4.1 the MNIST data are taken with k=10.	B-Review	B-4	Review	10105
Though it is nicely explained and illustrated on this data set, it is possibly somewhat misleading as an example.	I-Review	I-4	Review	10105
The reason is that this is a classification problem with 10 classes, therefore the choice k=10 is obvious.	I-Review	I-4	Review	10105
It would be more important to consider benchmark problems for clustering, instead of classification, for which the choice of k is also an important model selection issue and for which k is unknown (how should k be selected then?).	I-Review	I-4	Review	10105
<sep> <sep> - is each cluster always be assumed to be a Gaussian (which seems to be a strong assumption in general, and possibly not always realistic)?	B-Review	B-5	Review	10105
Could other components be used in the mixture?	I-Review	I-5	Review	10105
Thank you very much for reviewing our paper.	O	O	Reply	10105
We addressed your concerns and suggestions as follows.	O	O	Reply	10105
Reviewer comments are pasted and marked with ***, author responses follow below:	O	O	Reply	10105
<sep> ***- in the abstract it is claimed that the method works for high-dimensional data.	O	O	Reply	10105
However, it should be better explained why this is the case.	O	O	Reply	10105
The method is largely based on density estimation with a mixture of Gaussians which is known to have limitations in higher dimensions (see e.g. classical textbooks like Bishop 1995)***	O	O	Reply	10105
<sep> The reviewer is right about the issues of GMMs with high dimensional input.	B-Reply	B-1	Reply	10105
The input data for our model can readily be high-dimensional since the Variational Autoencoders have been demonstrated to be able to handle very well, i.e. to generate informative representations in a lower-dimensional latent space [Aljalbout et al ‚ÄúClustering with deep learning: Taxonomy and new methods‚Äù]. While being low-dimensional these representations capture the main differences in variance to be able to reconstruct the data.	I-Reply	I-1	Reply	10105
We fit our GMMs in this lower-dimensional latent space.	I-Reply	I-1	Reply	10105
We agree that one has to find a trade-off when choosing the dimensionality of the latent representation: it should be large enough to find separation and capture the variability of the input data, but also small enough such that the Gaussian mixtures can fit the clusters.	I-Reply	I-1	Reply	10105
We updated the manuscript to alert potential users about this issue and make this tradeoff clearer.	I-Reply	I-1	Reply	10105
We specifically address it in section 2 where we introduce the model and specify how we train the GMM on the latent representation.	I-Reply	I-1	Reply	10105
Specifically, for the MNIST application (d=68) and the real biological data (d=9) and we found good clustering performance where GMMs have been demonstrated to operate well [Jiang et al ‚ÄúVariational deep embedding: An unsupervised and generative approach to clustering‚Äù].	I-Reply	I-1	Reply	10105
<sep> ‚Äî‚Äî‚Äî‚Äî--	O	O	Reply	10105
<sep> ***- the similarity matrix and the similarity values should be carefully defined.	O	O	Reply	10105
Is there also an underlying similarity function assumed?***	O	O	Reply	10105
<sep> <sep> The similarity matrix indeed has to be defined carefully, since otherwise, the clustering network attempts to cluster data objects which might not be similar and therefore also the latent representation might not separate the clusters.	B-Reply	B-2	Reply	10105
The similarity matrices for each training batch in our experiments are defined either via k-nearest neighbors or via distance thresholds where the similarity function is the Euclidean distance.	I-Reply	I-2	Reply	10105
Both are applied to the transformed data using UMAP.	I-Reply	I-2	Reply	10105
To define the similarity matrix like that was the most straightforward way we could think of but could be easily replaced by a different approach in the MoE-Sim-VAE framework.	I-Reply	I-2	Reply	10105
The details are stated in the sections of the respective experiments.	I-Reply	I-2	Reply	10105
Further, we added an ablation study on the similarity matrix to our paper to section 4.2 and additionally with a figure (A4) in the appendix.	I-Reply	I-2	Reply	10105
Herewith, we show the importance and also the positive influence of the similarity matrix on the separation of the clusters in the latent representation.	I-Reply	I-2	Reply	10105
It shows a lower separation of the different classes in the latent representation when ignoring the similarity matrix when training the model.	I-Reply	I-2	Reply	10105
<sep> <sep> ‚Äî‚Äî‚Äî‚Äî--	O	O	Reply	10105
<sep> ***- a main shortcoming is that there is no discussion or experimental comparison with methods like spectral clustering and kernel spectral clustering.	O	O	Reply	10105
Given that the paper and the proposed method relates to similarity-based representations it would be important to know how it compares to such methods.	O	O	Reply	10105
Though e.g. in Table 1 the authors compare with about 10 other methods it would be more relevant that among some of these would have been spectral clustering and kernel spectral clustering, because of the similarity-based representations.***	O	O	Reply	10105
<sep> <sep> Thanks for the pointer towards spectral clustering methods.	B-Reply	B-3	Reply	10105
We added results from a recent ICLR publication which performs spectral clustering in various forms on MNIST and compare accuracies and NMIs to the results of our model in Table 1 and show better performance with the MoE-Sim-VAE.	I-Reply	I-3	Reply	10105

The authors propose a neural network approach to variable unification and	O	O	Review	20030
reasoning by example as a way to mimic the human ability to identify invariant	O	O	Review	20030
patterns in examples and then apply them more generally in practice.	O	O	Review	20030
<sep> This general idea of identifying invariates and mapping new instances to	O	O	Review	20030
them is well motivated by the authors, citing work in philosophy of mind,	O	O	Review	20030
cognitive science, and developmental psychology.	O	O	Review	20030
<sep> <sep> The authors go on to propose MLP, CNN and Memory Network models	B-Review	B-1	Review	20030
of unification for sequence, grid, and story reasoning tasks respectively.	I-Review	I-1	Review	20030
<sep> Experiments on the sequence and grid datasets demonstrate the data efficiency	I-Review	I-1	Review	20030
of this approach.	I-Review	I-1	Review	20030
MLP and CNN models with unification achieve near perfect	I-Review	I-1	Review	20030
performance in fewer iterations (an order of magnitude fewer in the MLP case!)	I-Review	I-1	Review	20030
<sep> than their non-unification enabled counter parts.	I-Review	I-1	Review	20030
<sep> Unification enabled models also demonstrate high performance in a reduced	I-Review	I-1	Review	20030
training set setting (using only 50 training examples).	I-Review	I-1	Review	20030
<sep> While this is encouraging, these are very simple toy tasks.	I-Review	I-1	Review	20030
<sep> <sep> I also am in doubt as to whether the representation of these problems	B-Review	B-2	Review	20030
causes some issues.	I-Review	I-2	Review	20030
In the sequence task, one question the models are	I-Review	I-2	Review	20030
trying to solve is what symbol is the head or tail of the sequence.	I-Review	I-2	Review	20030
<sep> Modeling variables over the sequence of symbols here is, in a sense, the	I-Review	I-2	Review	20030
wrong object of study.	I-Review	I-2	Review	20030
The position of the symbols would need to be	I-Review	I-2	Review	20030
represented, e.g.	I-Review	I-2	Review	20030
<sep> a b c d	I-Review	I-2	Review	20030
1 4 3 1	I-Review	I-2	Review	20030
<sep> where I've represented positions as a-d, and the learned invariant about	I-Review	I-2	Review	20030
head questions would be:	I-Review	I-2	Review	20030
<sep> X:a b c d	I-Review	I-2	Review	20030
Y:1 4 3 1	I-Review	I-2	Review	20030
<sep> As is, by mapping symbols and not positions to variables, one cannot,	B-Review	B-3	Review	20030
at the variable level distinguish between the two 1s in the sequence above.	I-Review	I-3	Review	20030
<sep> My guess is that in practice the bi-GRU model that produces embedding	I-Review	I-3	Review	20030
features of the symbols in sequence is implicitly representing head/tail	I-Review	I-3	Review	20030
positioning.	I-Review	I-3	Review	20030
<sep> <sep> Similar arguments could be made about the grid example.	O	O	Review	20030
<sep> <sep> I don't find the experiments/analysis on the bAbI dataset very convincing.	B-Review	B-4	Review	20030
<sep> For instance, in the example given in Figure 4b (reproduced below)	I-Review	I-4	Review	20030
is shown as an example of	I-Review	I-4	Review	20030
temporal reasoning, where a symbol Z is mapped to the	I-Review	I-4	Review	20030
word morning (a symbol distinguishing a time), and the question asked is	I-Review	I-4	Review	20030
where was Bill before school.	I-Review	I-4	Review	20030
<sep> If logical reasoning is being used to solve this question, surely the	I-Review	I-4	Review	20030
symbol 'before' must also be represented as a variable.	I-Review	I-4	Review	20030
Its possible that	I-Review	I-4	Review	20030
the model is instead learning a trick about mutual exclusivity, i.e. that	I-Review	I-4	Review	20030
Y:school is the only location symbol not mentioned in question but this	I-Review	I-4	Review	20030
could fail as a general strategy.	I-Review	I-4	Review	20030
<sep> <sep> <sep> this Z:morning X:bill went to the Y:school	O	O	Review	20030
yesterday X:bill journeyed to the A:park	O	O	Review	20030
where was X:bill before the Y:school	O	O	Review	20030
A:park	O	O	Review	20030
<sep> Figure 4b	O	O	Review	20030
<sep> It would make for a much more interesting paper if the authors took	B-Review	B-5	Review	20030
examples such as these and formed counter-factuals to probe the way	I-Review	I-5	Review	20030
the models are answering the questions.	I-Review	I-5	Review	20030
E.g., transforming the question	I-Review	I-5	Review	20030
in 4b to "where was X:bill today" or "where was X:bill after school."	I-Review	I-5	Review	20030
<sep> <sep> Because the authors use soft unification, interpretability is difficult	B-Review	B-6	Review	20030
to assess.	I-Review	I-6	Review	20030
Interpretability is crucial here because to claim that unification and reasoning by logical induction	I-Review	I-6	Review	20030
is being used to solve tasks, it becomes important to show how the neural networks	I-Review	I-6	Review	20030
make their decisions.	I-Review	I-6	Review	20030
Given the instances of extra variables and one to many	I-Review	I-6	Review	20030
mappings on the bAbI dataset it seems very likely that the models are not	I-Review	I-6	Review	20030
solving many tasks	I-Review	I-6	Review	20030
using unification as it would be possible to learn to use the symbols directly	I-Review	I-6	Review	20030
to learn to answer.	I-Review	I-6	Review	20030
As such, I think these issues are not addressed in the	I-Review	I-6	Review	20030
paper sufficiently to warrant acceptance.	I-Review	I-6	Review	20030
<sep> <sep> <sep> Minor Notes	O	O	Review	20030
<sep> - In definition 1, the definition of Variable is a little confusing because there are two different senses of the word in use.	B-Review	B-7	Review	20030
I understand them to be (1) Variable (X) in the logical template that is intended to be learned and used in problem solving, and	I-Review	I-7	Review	20030
(2) variable (x) in the neural network model that is a soft asignment of	I-Review	I-7	Review	20030
the Variable to a default symbol s. It would be nice if this distinction could	I-Review	I-7	Review	20030
be noted or made clearer.	I-Review	I-7	Review	20030
<sep> <sep> - In the definition 2, in the phrase "is the invariant example such as a tokenized story" it might be worth stating that the tokens are the symbols in S.	B-Review	B-8	Review	20030
<sep> <sep> - My understanding is that each unique symbol in the invariate is a potential	B-Review	B-9	Review	20030
variable.	I-Review	I-9	Review	20030
Does this mean there are no co-referent symbols in the invariate?	I-Review	I-9	Review	20030
<sep> Would be helpful to state whether babi contains co-referent expressions	I-Review	I-9	Review	20030
and how these might affect the model.	I-Review	I-9	Review	20030
<sep> <sep> <sep> - It might be interesting to see how model architecture affects variable	B-Review	B-10	Review	20030
learning.	I-Review	I-10	Review	20030
For example, does a CNN result in more sensible variable	I-Review	I-10	Review	20030
assignments  than the mlp on a flattened representation of the grid problem?	I-Review	I-10	Review	20030
<sep> <sep> <sep> - What is the strongly supervised case?	B-Review	B-11	Review	20030
These are token level annotations I think (at least for babi) but it might be good to specify in more detail what	I-Review	I-11	Review	20030
they  are.	I-Review	I-11	Review	20030
<sep> <sep> - The figure and explanation of the UMN are not very clear.	B-Review	B-12	Review	20030
From the figure	I-Review	I-12	Review	20030
is does not seem that the variables interact with the memory at all.	I-Review	I-12	Review	20030
More	I-Review	I-12	Review	20030
space could be devoted to this section.	I-Review	I-12	Review	20030
<sep> <sep> Possibly Relevant Related Work	B-Review	B-13	Review	20030
<sep> Brenden Lake.	I-Review	I-13	Review	20030
Compositional generalization through metasequence-to-sequence learning.	I-Review	I-13	Review	20030
NeurIPS 2019.	I-Review	I-13	Review	20030
<sep> <sep> <sep> <sep> <sep> <sep> <sep> Dear reviewer, thank you for your detailed constructive feedback.	O	O	Reply	20030
We are happy to answer your comments:	O	O	Reply	20030
<sep> ‚Äúthese are very simple toy tasks‚Äù - We must first understand how these architectures work and analyse them in a controlled environment in order to mitigate the black box effect they create.	B-Reply	B-1	Reply	20030
In order to analyse the invariants, it is crucial to work in a fixed setting where the data generating distribution is known for comparison.	I-Reply	I-1	Reply	20030
This learning task has never been attempted before and the paper demonstrates the validity of the idea and its effectiveness, enabling work towards addressing more complex tasks.	I-Reply	I-1	Reply	20030
<sep> <sep> ‚ÄúModelling variables over the sequence of symbols here is, in a sense, the wrong object of study‚Äù - Our approach is indifferent to the underlying structure of the task, demonstrated by the different datasets.	B-Reply	B-2	Reply	20030
There is no right or wrong task with respect to learning variables since the model does not make assumptions about the data.	I-Reply	I-2	Reply	20030
We present 3 different structures still using the same definitions from Section 2.	I-Reply	I-2	Reply	20030
The soft unification function ‚Äúg‚Äù potentially learns different features with different structures, as you have guessed in the next comment below.	I-Reply	I-2	Reply	20030
<sep> <sep> ‚ÄúMy guess is that in practice the bi-GRU model that produces embedding features of the symbols in sequence is implicitly representing head/tail positioning.	O	O	Reply	20030
‚Äù - Your guess is correct!	B-Reply	B-3	Reply	20030
We state this in Section 2 as the unifying properties that can be learned.	I-Reply	I-3	Reply	20030
In the example you‚Äôve provided, 1 4 3 1, the unifying features of 1s will be different due to the bi-GRU.	I-Reply	I-3	Reply	20030
This also gives great capacity to the network and the ability to unify the head of a sequence with the tail of another sequence (Appendix D).	I-Reply	I-3	Reply	20030
<sep> <sep> ‚ÄúIf logical reasoning is being used to solve this question, surely the symbol 'before' must also be represented as a variable‚Äù - We must be careful in projecting our understanding of natural language and logical reasoning to dictate what should and shouldn‚Äôt be a variable.	B-Reply	B-4	Reply	20030
If this was an alien language with unknown symbols, we wouldn‚Äôt be able to say a symbol should be a variable nor assume a certain logical reasoning is involved.	I-Reply	I-4	Reply	20030
Hence, only variations in the data can tell, as is the case in our approach, whether a symbol should be a variable.	I-Reply	I-4	Reply	20030
Since the model can optimise to use 1 variable where we might expect 2, Figure 5b, it might not follow the data generating distribution exactly but still solve the task by exploiting these commonalities.	I-Reply	I-4	Reply	20030
We discuss this in ‚ÄúInterpretability versus Ability‚Äù, Section 6.	I-Reply	I-4	Reply	20030
<sep> <sep> ‚Äú.. formed counter-factuals to probe the way the models are answering the questions‚Äù - This is an interesting point we also make in our relevant work in Section 7.	B-Reply	B-5	Reply	20030
Our objective of learning invariants to some extent uses counter-factuals as unification changes the facts of a story.	I-Reply	I-5	Reply	20030
Furthermore, your question is not a counter-factual as it can be answered with ‚Äúunknown‚Äù looking at the story facts.	I-Reply	I-5	Reply	20030
The question ‚Äúwhere would X:bill have been before Y:school should he have gone to the garden yesterday‚Äù is a counter-factual as it yields an answer of garden against the facts presented in the story.	I-Reply	I-5	Reply	20030
<sep> <sep> ‚ÄúInterpretability is crucial here because to claim that unification and reasoning by logical induction is being used to solve tasks ...‚Äù - We don‚Äôt claim this is logical unification, reasoning or induction.	B-Reply	B-6	Reply	20030
In fact, we refrain from using those terms ‚Äúsince neither the invariant structure needs to be rule-like nor the variables carry logical semantics‚Äù.	I-Reply	I-6	Reply	20030
The reason is because the ‚Äúg‚Äù and the ‚Äúf‚Äù are learned end-to-end and could learn elements of logical unification, reasoning or not; hence, it is inappropriate to assume or claim that it is any sort of logical induction.	I-Reply	I-6	Reply	20030
<sep> <sep> ‚ÄúDoes this mean there are no co-referent symbols in the invariate?‚Äù Yes, each symbol is considered unique and a potential variable independently.	B-Reply	B-9	Reply	20030
In bAbI co-reference task,11, ‚ÄúHe‚Äù etc.	I-Reply	I-9	Reply	20030
are unique symbols and treated equally.	I-Reply	I-9	Reply	20030
Detailed results, including task 11, are in Appendix D Table 6.	I-Reply	I-9	Reply	20030
<sep> <sep> ‚Äúdoes a CNN result in more sensible variable assignments  than the mlp on a flattened representation of the grid problem?‚Äù - It is a good question.	B-Reply	B-10	Reply	20030
It depends on what we mean by sensible.	I-Reply	I-10	Reply	20030
If we refer to them following the data generating distribution then the answer is similar to asking whether an MLP or a CNN solves the task better.	I-Reply	I-10	Reply	20030
This is because the variables are learned with respect to an upstream ‚Äúf‚Äù and that network provides the gradients for which symbols should be variables.	I-Reply	I-10	Reply	20030
In either case, we observe occasional ‚Äúinsensible‚Äù variables (Appendix D Figure 9) in which the invariants can still solve the task.	I-Reply	I-10	Reply	20030
<sep> <sep> ‚ÄúWhat is the strongly supervised case?‚Äù - These experiments use the supporting facts provided in the bAbI dataset as done in literature around memory networks.	B-Reply	B-11	Reply	20030
This is mentioned in Section 5: ‚Äúand, in the strongly supervised cases, the negative log-likelihood for the context attentions are also added to the objective function.	I-Reply	I-11	Reply	20030
‚Äù We do not supervise soft unification nor label correct tokens.	I-Reply	I-11	Reply	20030

This paper presents a novel approach for learning invariants that can capture underlying patterns in the tasks through Unification Networks.	O	O	Review	20030
This effectively allows the machine to learn the notion of `variable`, which is a symbol that can take on different values.	O	O	Review	20030
<sep> <sep> Pros:	O	O	Review	20030
The authors evaluated and presented empirical results on four common benchmark datasets, showing superiority over plain baseline without unification.	O	O	Review	20030
<sep> They further performed analysis on the learned invariants, and verified the sensibility.	O	O	Review	20030
<sep> The paper overall is well written and structured.	O	O	Review	20030
<sep> <sep> Cons:	O	O	Review	20030
Despite its superiority over plain baseline, the paper does not provide thorough comparison with other state-of-the-art methods on reasoning related tasks.	B-Review	B-1	Review	20030
<sep> <sep> Some of the technical details regarding the choice of hyperparameters are missing.	B-Review	B-2	Review	20030
For example:	I-Review	I-2	Review	20030
In section 6, what‚Äôs the rationale of setting differently for bAbI solely?	I-Review	I-2	Review	20030
<sep> In Equation 5, how is the sparsity regularization parameter chosen optimally for a particular task?	B-Review	B-3	Review	20030
A bit more discussion on these choices would be helpful.	I-Review	I-3	Review	20030
<sep> <sep> Overall, this paper presents a seemingly promising architecture capable of learning and using variables, with the caveat for lack of experiments and comparison with other state-of-the-art methods.	B-Review	B-4	Review	20030
<sep> <sep> Dear reviewer, thank you for your feedback and we are glad you have found the paper well written and structured.	O	O	Reply	20030
To answer your questions and comments:	O	O	Reply	20030
<sep> ‚Äúthe paper does not provide thorough comparison with other state-of-the-art methods on reasoning related tasks‚Äù - If we are referring to the bAbI and the logical reasoning tasks as reasoning related tasks, we provide a detailed comparison of each task with all of the state-of-the-art models in Appendix D Table 7 and 8.	B-Reply	B-1	Reply	20030
We present similar (related to our memory network architecture) memory based architectures in the main body of the paper and the rest of the state-of-the-art models in the appendix due to space limitations.	I-Reply	I-1	Reply	20030
<sep> <sep> ‚ÄúIn section 6, what‚Äôs the rationale of setting - threshold differently for bAbI solely?‚Äù - This question is answered at the beginning of Section 6, ‚ÄúThe magnitude of this threshold seems to depend on the amount of regularisation, equation 5, and the number of training steps along with batch size all controlling how much is pushed towards 0.‚Äù Thus, after training is complete there will be a lower bound on depending on those aspects which is different for bAbI from the other datasets.	B-Reply	B-2	Reply	20030
<sep> <sep> ‚Äúhow is the sparsity regularization parameter chosen optimally for a particular task?‚Äù - It is not chosen optimally, we used 0.1 as a reasonable coefficient in recognising that is an L1 regularisation applied to.	B-Reply	B-3	Reply	20030
We haven‚Äôt performed hyper-parameter tuning.	I-Reply	I-3	Reply	20030
<sep> <sep> ‚Äúthe caveat for lack of experiments and comparison with other state-of-the-art methods‚Äù - We disagree with this statement as we present 4 datasets, 3 different architectures, different experimental setups (strong vs weak, 1k vs 50 training examples), analysis of invariants, analysis of soft unification as well as comparison to existing state-of-the-architectures in Sections 4, 5 and 6 respectively with detailed results and further analysis in Appendix D.	B-Reply	B-4	Reply	20030
<sep> We hope we have answered your questions individually and highlighted the novelty, the results of the experimental setup and comparison to the state-of-the-art models presented in this work.	I-Reply	I-4	Reply	20030

This paper explores a very interesting idea: can a model learn what variables are and how to use them?	O	O	Review	20030
Unfortunately, the paper doesn't seem quite ready: the model description was very hard to follow and it's not clear the approach has found a compelling use case.	O	O	Review	20030
<sep> <sep> I read the paper carefully three times, and try as I might, I simply can't get my head around the entire architecture.	O	O	Review	20030
The modeling section jumps straight into a series of definitions, without trying to build intuition or provide a worked example.	B-Review	B-1	Review	20030
There is an example in Figure 2, but it isn't really explained and I didn't find it helpful.	I-Review	I-1	Review	20030
Unification seems to be implemented as a form of attention (or self-attention) where the model can control the degree to which a symbol acts as variable.	I-Review	I-1	Review	20030
But the relationship between soft unification and attention isn't really spelled out -- what's the same, what's different?	I-Review	I-1	Review	20030
Ultimately it's not clear to me what the model is attending over during soft unification.	B-Review	B-2	Review	20030
<sep> <sep> There are various other aspects of the paper that aren't clear:	B-Review	B-3	Review	20030
- strong vs. weak supervision	I-Review	I-3	Review	20030
- comparison models DMN and IMA are not introduced at all, and include no references	B-Review	B-4	Review	20030
- the logical reasoning experiment is not clearly described	B-Review	B-5	Review	20030
- there is only a cursory conclusion	B-Review	B-6	Review	20030
<sep> I am not sure the model has found a compelling use case.	B-Review	B-7	Review	20030
On bAbi with weak supervision, the model is worse than the comparison models.	I-Review	I-7	Review	20030
It only slightly beats out memory networks with strong supervision.	I-Review	I-7	Review	20030
For logical reasoning, it's not clear what it is compared against or if the comparison is fair.	I-Review	I-7	Review	20030
The clearest win over standard networks is on the simple synthetic experiments.	I-Review	I-7	Review	20030
<sep> <sep> Finally, the authors mention the paper has a cognitive science motivation, in that "Humans learn what variables are and how to use then at a young age" or that "symbolic thought with variables is learned...", taking a strong "nurture" stance on the origin of variables.	B-Review	B-8	Review	20030
But variables could very well be innate and simply early emerging.	I-Review	I-8	Review	20030
Any discussion of the origin of variables in the mind requires more nuance.	I-Review	I-8	Review	20030
<sep> <sep> I am excited about this research direction, and it could ultimately be a very nice contribution as the work matures.	O	O	Review	20030
I don't think the paper is ready in its current form.	O	O	Review	20030
<sep> <sep> Dear reviewer, thank you for your feedback.	O	O	Reply	20030
We are excited that you find the idea interesting and important.	O	O	Reply	20030
To answer your questions and comments:	O	O	Reply	20030
<sep> ‚ÄúBut the relationship between soft unification and attention isn't really spelled out -- what's the same, what's different?‚Äù - The difference / similarity is mentioned multiple times in the paper, firstly in the introduction: ‚Äúwe consider unification a selection of the most appropriate value .., we can reframe it as a form of attention.	B-Reply	B-1	Reply	20030
‚Äù ; secondly in Section 2: ‚ÄúFor example, ‚Ä¶ would become a weighted sum of symbol embeddings as in conventional attention models‚Äù, and finally in Definition 3 where soft unification is defined as a dot product attention, equation 3.	I-Reply	I-1	Reply	20030
Hence, soft unification is implemented as a form of dot product attention.	I-Reply	I-1	Reply	20030
<sep> <sep> ‚ÄúUltimately it's not clear to me what the model is attending over during soft unification.	O	O	Reply	20030
‚Äù - Following equation 3, soft unification attends over the symbols present in the example K. This K is another example from the dataset and could be a sequence, grid, a story or a logic program as setup in the datasets section and detailed for each architecture in Section 3.	B-Reply	B-2	Reply	20030
<sep> <sep> ‚Äústrong vs. weak supervision‚Äù - We mention the strongly supervised experiments in Section 5: ‚Äúin the strongly supervised cases, the negative log-likelihood for the context attentions are also added to the objective function.	B-Reply	B-3	Reply	20030
‚Äù In the memory networks literature surrounding the bAbI dataset, this refers to using the supporting facts.	I-Reply	I-3	Reply	20030
We do not supervise the soft unification mechanism in any of the experiments.	I-Reply	I-3	Reply	20030
<sep> <sep> ‚Äúcomparison models DMN and IMA are not introduced at all, and include no references‚Äù - We do not provide detailed previous work to reduce clutter, distinguish our work and adhere to space constraints.	B-Reply	B-4	Reply	20030
The reference for them are in the caption of Table 3: ‚Äúand DMN, IMA by Cingillioglu &amp; Russo (2019).‚Äù We ask the readers to refer to the cited paper for further details.	I-Reply	I-4	Reply	20030
Similarly N2N, GN2N, EntNet are not details and we ask the readers to refer to the citations.	I-Reply	I-4	Reply	20030
<sep> <sep> ‚Äúthe logical reasoning experiment is not clearly described‚Äù - We use an existing data generation procedure as mentioned, ‚Äúusing the procedure by Cingillioglu &amp; Russo (2019).‚Äú and only give details of the specific settings we used to generate the data such as the arity and size of the data.	B-Reply	B-5	Reply	20030
Similar to the bAbI dataset, for the logical reasoning dataset we ask readers to refer to the original papers that introduce the individual tasks.	I-Reply	I-5	Reply	20030
<sep> <sep> ‚Äúthere is only a cursory conclusion‚Äù - This is quite subjective as the conclusion of the paper clearly states a novel approach to incorporating variables to neural network architectures and learning invariants.	B-Reply	B-6	Reply	20030
We present the concrete output of this approach: the invariants learnt by analysing soft unification mechanism implemented as an attention.	I-Reply	I-6	Reply	20030
<sep> <sep> ‚ÄúI am not sure the model has found a compelling use case.	O	O	Reply	20030
‚Äù - This is interesting as the judgement seems to be made on the final accuracy based performance of the model in the bAbI and the logical reasoning dataset.	B-Reply	B-7	Reply	20030
The objective is ‚Äúlearning invariants‚Äù rather than to lower error rates further.	I-Reply	I-7	Reply	20030
We urge the readers to consider the qualitative novel output of our approach instead of a win or lose against other models in certain datasets.	I-Reply	I-7	Reply	20030
Our approach is flexible in the network architecture (UMLP, UCNN, UMN) as well as the tasks it can solve, in some cases  better or as good as other models.	I-Reply	I-7	Reply	20030
<sep> <sep> ‚ÄúBut variables could very well be innate and simply early emerging.	O	O	Reply	20030
‚Äù - This is also very interesting, it may very well be.	B-Reply	B-8	Reply	20030
We followed the line of work cited in the introduction and the related work to establish our argument showing evidence such as pretend play etc.	I-Reply	I-8	Reply	20030
as to why the notion of a variable could be learned.	I-Reply	I-8	Reply	20030
The discussion about whether it could be innate is more appropriate in the field of developmental psychology that is outside the scope and focus of this work.	I-Reply	I-8	Reply	20030
We would be happy to incorporate references showing evidence for the innateness of variables in human reasoning.	I-Reply	I-8	Reply	20030
<sep> <sep> Please note that, Reviewer 4 supports the motivation of a cognitive background and Reviewer 1 points out the paper is well written, structured and clear.	B-Reply	B-9	Reply	20030
These seem to counter your two main concerns.	I-Reply	I-9	Reply	20030
We fail to find in the review any further scientific or technical grounds for disputing the validity or novelty of the work to hamper its publication.	I-Reply	I-9	Reply	20030
We believe we have addressed your questions and comments and highlighted the novelty and contribution this work brings.	I-Reply	I-9	Reply	20030

The paper presents a generalization of classical definitions of entropy and mutual information that can capture computational constraints.	O	O	Review	20391
Intuitively, information theoretic results assume infinite computational resources, so they may not correspond to how we treat "information" in practice.	O	O	Review	20391
One example is public-key encryption.	O	O	Review	20391
An adversary that has infinite time will eventually break the code so the decrypted message conveys the same amount of information (in a classical sense) as the plaintext message.	O	O	Review	20391
In practice, this depends on computational time.	O	O	Review	20391
<sep> <sep> The authors' approach is to first restrict the class of conditional probability distribution p(Y|X) to a restricted family F that satisfies certain conditions.	O	O	Review	20391
Unfortunately, the main condition in Def 1 that the authors assume is not natural and is only added to ensure that mutual information remains positive.	O	O	Review	20391
However, putting this aside, the subsequent definitions that general entropy, conditional entropy, and mutual information are well-motivated.	O	O	Review	20391
<sep> <sep> The authors, then, show that many measures of "uncertainty" can be viewed as "entropies" under this generalized definition including the Mean Absolute Deviation and the Coefficient of Determination.	O	O	Review	20391
<sep> <sep> The overall framework can justify practices that we commonly use in machine learning, which would be justifiable using classical information.	O	O	Review	20391
One important example is Representation Learning, which is a post-processing of data to aid the prediction task.	O	O	Review	20391
According to classical information theory, this post-processing shouldn't help because it cannot add more information about the label Y than what was original available in X. Under the formulation presented in this paper, postprocessing can help if we keep in mind information about Y in X are hard to extract to begin with.	O	O	Review	20391
<sep> <sep> In terms of practical applications, the main advantage of the new definition is that F-information can be estimated from a finite sample, simply because F is a restricted set.	O	O	Review	20391
However, this restriction helps compared to using state-of-the-art estimators for Shannon mutual information as shown in the experiments.	O	O	Review	20391
<sep> <sep> Finally, the literature review section is quite excellent.	O	O	Review	20391
<sep> <sep> I find the overall approach to be quite interesting and definitely worth publishing.	B-Review	B-1	Review	20391
The only suggestion I have is that the authors include immediately after Definition 1 a concrete example that illustrates it.	I-Review	I-1	Review	20391
For example, suppose that Y is a scalar and X is a noisy estimate of Y. Suppose we restrict F to the family of Gaussian distributions.	I-Review	I-1	Review	20391
That is, with side information x, f[x](y)  = N(x, s).	I-Review	I-1	Review	20391
Without side information, f[empty](y) = N(u, s).	I-Review	I-1	Review	20391
The functions f are parameterized by u and s.	I-Review	I-1	Review	20391
Is this a "predictive family"?	I-Review	I-1	Review	20391
To make sure I understand it correctly, can you please walk me through the Eq 1 for this particular example?	I-Review	I-1	Review	20391
<sep> <sep> Some minor remarks:	B-Review	B-2	Review	20391
- Reference Shannon and Weaver was published in 1963, not 1948.	I-Review	I-2	Review	20391
<sep> - In Page 5, "maybe not expressive" should be "may not be expressive".	I-Review	I-2	Review	20391
<sep> <sep> <sep> Thank you for your review and suggestions	O	O	Reply	20391
<sep> Q: Suppose that Y is a scalar and X is a noisy estimate of Y. Suppose we restrict F to the family of Gaussian distributions.	O	O	Reply	20391
That is, with side information x, f[x](y)  = N(x, s).	O	O	Reply	20391
Without side information, f[empty](y) = N(u, s).	O	O	Reply	20391
The functions f are parameterized by u and s.	O	O	Reply	20391
Is this a "predictive family"?	O	O	Reply	20391
To make sure I understand it correctly, can you please walk me through the Eq 1 for this particular example?	O	O	Reply	20391
<sep> <sep> Response: This is not a predictive family because Eq.1 doesn‚Äôt hold.	B-Reply	B-1	Reply	20391
We can break down Eq 1 for this example into two parts	I-Reply	I-1	Reply	20391
<sep> ‚ÄúFor every f \in F, P \in range(f)‚Äù translates to ‚Äî&gt; for any Gaussian distribution N(c, s) where c is any real number	I-Reply	I-1	Reply	20391
<sep> ‚ÄúThere exists f‚Äô \in F, f‚Äô[x] = P, f‚Äô[empty] = P‚Äù translates to ‚Äî&gt; there is an f such that f[empty] = N(c, s), f[x] = N(c, s).	I-Reply	I-1	Reply	20391
In this example, such an f cannot always be found because we are ‚Äúforced‚Äù to use x as the mean of the Gaussian (i.e., we cannot ignore it).	I-Reply	I-1	Reply	20391
<sep> <sep> This will be an F information with a small modification: f[x] = N(ax+b, s), f[empty]=N(u, s) where a, b, u are parameters we can optimize.	I-Reply	I-1	Reply	20391
To check Eq 1 we can verify	I-Reply	I-1	Reply	20391
<sep> ‚ÄúThere exists f‚Äô \in F, f‚Äô[x] = P, f‚Äô[empty] = P‚Äù -&gt; this can be achieved by choosing a=0, b=c, u=c	I-Reply	I-1	Reply	20391
<sep> In fact, this quantity is equal to the R^2 coefficient (Proposition 1.5) ‚Äî a common measurement of dependence between two random variables.	I-Reply	I-1	Reply	20391
<sep> <sep> Note that many nice properties continue to hold, but without Eq.1 F-information can be negative.	I-Reply	I-1	Reply	20391
<sep> <sep> Q: Reference Shannon and Weaver was published in 1963, not 1948.	O	O	Reply	20391
In Page 5, "maybe not expressive" should be "may not be expressive".	O	O	Reply	20391
<sep> <sep> Response: Thank you for the correction.	B-Reply	B-2	Reply	20391
We have fixed them.	I-Reply	I-2	Reply	20391

Summary	O	O	Review	20391
The paper introduces a framework for quantifying information about one random variable, given another random variable (‚Äúside information‚Äù) and, importantly, a function class of allowed transformations that can be applied to the latter.	O	O	Review	20391
This matches the typical scenario in machine learning, where observations (playing the role of side information) can be transformed (with a restricted class of transformation-functions) such that they become maximally predictive about another random variable of interest (‚Äúlabels‚Äù).	O	O	Review	20391
Using this framework, the paper defines the notion of conditional F-entropy and F-entropy (by conditioning on an empty set).	O	O	Review	20391
Interestingly, both entropic quantities are shown to have many desirable properties known from Shannon entropy - and when allowing the function class of transformations to include all possible models F-entropies are equivalent to Shannon entropies.	O	O	Review	20391
The paper then further defines ‚Äúpredictive F-information‚Äù which quantifies the increase in predictability about one random variable when given side information, under a restricted function-class of allowed transformations of the side information.	O	O	Review	20391
Importantly, transformations of side information can increase predictive F-information (which is the basis for the notion of ‚Äúusable‚Äù information), which is in contrast to the data processing inequality that applies to Shannon information and states that no transformation of a variable can increase predictability of another variable further than the un-transformed variable (information cannot be generated by transforming random variables).	O	O	Review	20391
The paper highlights interesting properties of the F-quantities, most notably a PAC bound on F-information estimation from data, which gives reason to expect F-information estimation to be more data-efficient than estimating Shannon-information (particularly in the high-dimensional regime).	O	O	Review	20391
This finding is confirmed by four types of interesting experiments, some of which make use of a modified version of a tree-structure learning algorithm proposed in the paper (using predictive F-information instead of Shannon mutual information).	O	O	Review	20391
<sep> <sep> Contributions	O	O	Review	20391
i) Proposal of a framework for measuring and reasoning about information that transformed random variables have about other random variables, when the class of transformation functions is restricted.	O	O	Review	20391
Interesting properties are highlighted and corresponding proofs are given.	O	O	Review	20391
Important conclusions to Shannon-information measures are drawn.	O	O	Review	20391
<sep> <sep> ii) PAC guarantees for estimating F-information quantities from data.	O	O	Review	20391
A nice result that justifies some optimism about the scalability of F-information estimation.	O	O	Review	20391
<sep> <sep> iii) Modification of a tree-structure learning algorithm, and application to four types of experiments with comparisons against methods for estimating Shannon(-mutual)-information.	O	O	Review	20391
<sep> <sep> Quality, Clarity, Novelty, Impact	O	O	Review	20391
The paper is very well written, the motivation and main results are clear and connections to known measures for information in complex systems are drawn (which often appear as corner-cases, or unrestricted cases of F-information).	O	O	Review	20391
I am not an expert on various information measures, thus I cannot fully judge the novelty of the framework (given that the central idea is fairly simple and quite elegant, the main work lies in the proofs and connections to other frameworks).	O	O	Review	20391
However, I have not seen the framework being discussed in the machine learning literature before.	O	O	Review	20391
I personally would rate the potential impact of the F-information framework as high because it addresses many problems that Shannon-(mutual-)information has (hard to estimate, generality means complete blindness against model-classes).	O	O	Review	20391
The experiments in the paper already illustrate how F-information could be very useful for a range of ML problems that cannot be tackled by strong competitor methods based on Shannon-information estimation.	O	O	Review	20391
My only criticism is that the paper does not clearly state current limitations and shortcomings and does not comment on the difficulties / potential problems with solving the variational problem that is part of the definition of (conditional) F-information.	B-Review	B-7	Review	20391
I currently vote and argue for accepting the paper, though my assessment is of medium confidence only, and I am happy to take issues raised by the other reviewers and the rebuttal into account.	I-Review	I-7	Review	20391
I have not checked the proofs in the appendix in great detail.	I-Review	I-7	Review	20391
<sep> <sep> Improvements	O	O	Review	20391
i) Please add a short section of current shortcomings and caveats, especially with regard to applying the methods in practice.	B-Review	B-1	Review	20391
<sep> <sep> ii) Please comment on solving the variational optimization problem (the infimum) which is part of the definition of (conditional) F-information.	B-Review	B-2	Review	20391
In particular, are there any theoretical statements / bounds / etc.	I-Review	I-2	Review	20391
to be made for the case where the infimum is not found exactly - does the measure degrade gracefully or can small errors in this optimization lead to wildly varying/divergent F-information?	I-Review	I-2	Review	20391
From a practical point-of-view: how was this optimization done in the experiments (particularly when involving a neural network model), how much computational overhead did this optimization add (and how does it compare against other methods, e.g. in terms of wall-clock time or other reasonable metrics, the more the better)?	I-Review	I-2	Review	20391
<sep> <sep> iii) This is a minor one and feel free to completely ignore it.	B-Review	B-3	Review	20391
The name F-information might easily get confused with the use of f-divergences, perhaps there is a better, more informative name.	I-Review	I-3	Review	20391
Also, while I personally like the term ‚Äúusable‚Äù in the title, I‚Äôm not so sure about ‚Äúcomputational constraints‚Äù - the latter somehow suggests that the method has small computational footprint, or can easily scale to different computational budget.	I-Review	I-3	Review	20391
Perhaps there is a way that more strongly indicates that this refers to restrictions on the model-/function-class (which the term ‚Äúusable‚Äù does already to some degree admittedly).	I-Review	I-3	Review	20391
<sep> <sep> <sep> Minor Comments	O	O	Review	20391
a) Have you had any thoughts on how F-information could be used in a rate-distortion / information-bottleneck type framework for a theory of ‚Äúrelevant usable information‚Äù?	B-Review	B-4	Review	20391
This is probably beyond the scope of this paper, just out of curiosity.	I-Review	I-4	Review	20391
<sep> <sep> b) The paragraph above 3.3 almost sounds a bit like Shannon (and the data processing inequality) was wrong.	B-Review	B-5	Review	20391
I‚Äôd rather phrase this as a ‚Äúno-free-lunch problem‚Äù - while the DPI and Shannon (mutual) information is very elegant, it is necessary to make further assumptions/restrictions (the function class of allowed transformations) to make more fine-grained statements and define more precise (but less general) informational-quantities tailored to the specific function class.	I-Review	I-5	Review	20391
<sep> <sep> c) When choosing function classes that allow for universal function approximation, would F-information degrade to Shannon information?	B-Review	B-6	Review	20391
Thank you for your review and suggestions.	O	O	Reply	20391
<sep> <sep> Q: Please add a short section of current shortcomings and caveats, especially with regard to applying the methods in practice.	O	O	Reply	20391
<sep> <sep> Response: We have added a limitations section, reproduced below:	B-Reply	B-1	Reply	20391
<sep> F-information is empirically useful and has appealing theoretical properties.	I-Reply	I-1	Reply	20391
However, some elegant properties of Shannon information are lost.	I-Reply	I-1	Reply	20391
For example, Shannon information can be manipulated with algebra (e.g. H(X, Y) = H(X) + H(Y | X)), while F-Information cannot (for general F).	I-Reply	I-1	Reply	20391
Additionally, for F-Information to be useful in practice, the predictive family F should be easy to optimize over.	I-Reply	I-1	Reply	20391
Machine learning research has identified many such functions (e.g. linear functions, convex functions, ReLU neural networks) suitable for a variety of data types.	I-Reply	I-1	Reply	20391
Nevertheless one should be cautious when applying F-Information to functions and data types that are not well understood in the machine learning literature.	I-Reply	I-1	Reply	20391
In the finite data regime, overfitting is also an issue to consider, and standard techniques to prevent it (e.g., crossvalidation) should be applied.	I-Reply	I-1	Reply	20391
<sep> <sep> An interesting direction for future work is to better integrate F-Information with other areas of machine learning.	I-Reply	I-1	Reply	20391
The production of usable information (representation learning), acquisition of usable information (active learning) and exploitation of usable information (classification and reinforcement learning) could potentially benefit from the F-information concept.	I-Reply	I-1	Reply	20391
<sep> <sep> <sep> Q: Please comment on solving the variational optimization problem (the infimum) which is part of the definition of (conditional) F-information.	O	O	Reply	20391
<sep> <sep> Response: F-information estimation degrades gracefully with sub-optimal optimization.	B-Reply	B-2	Reply	20391
Let I be the true F-information, I‚Äô be its finite-data estimation with perfect optimization (the infimum is achieved), and I‚Äô‚Äô be its estimation with imperfect optimization.	I-Reply	I-2	Reply	20391
Theorem 1 upper bounds | I - I‚Äô |, and we can immediately derive an upper bound on | I - I‚Äô‚Äô | by triangle inequality | I  - I‚Äô‚Äô | \leq | I - I‚Äô | + | I‚Äô - I‚Äô‚Äô |	I-Reply	I-2	Reply	20391
<sep> In other words, the estimation error can only increase by | I‚Äô - I‚Äô‚Äô |, which is the gap between perfect optimization and imperfect optimization.	I-Reply	I-2	Reply	20391
<sep> <sep> In practice, machine learning research has identified many function families that are empirically easy to optimize (including modern deep neural networks) ‚Äî which we use as our function family F. We used standard optimization algorithms (e.g. SGD for neural networks) and the wall clock time is identical to other estimators.	I-Reply	I-2	Reply	20391
<sep> <sep> <sep> Q: The name F-information might easily get confused with the use of f-divergences, perhaps there is a better, more informative name.	O	O	Reply	20391
<sep> <sep> Response: Thank you for this suggestion.	B-Reply	B-3	Reply	20391
We are considering a name change to V-information as in variational information.	I-Reply	I-3	Reply	20391
<sep> <sep> <sep> Q: Have you had any thoughts on how F-information could be used in a rate-distortion / information-bottleneck type framework for a theory of ‚Äúrelevant usable information‚Äù?	O	O	Reply	20391
<sep> <sep> Response: The application to information-bottleneck should be straight-forward.	B-Reply	B-4	Reply	20391
In fact, our fairness experiment can be thought of as the opposite of an information bottleneck:	I-Reply	I-4	Reply	20391
<sep> Fairness:<tab><tab><tab>   minimize F information between the learned representation and target (sensitive attributes) and maximize F information w.r.t input.	I-Reply	I-4	Reply	20391
<sep> <sep> Information bottleneck: maximize F information between the learned representation and target (labels) and minimize F information w.r.t input.	I-Reply	I-4	Reply	20391
<sep> <sep> <sep> Q: The paragraph above 3.3 almost sounds a bit like Shannon (and the data processing inequality) was wrong.	O	O	Reply	20391
I‚Äôd rather phrase this as a ‚Äúno-free-lunch problem‚Äù	O	O	Reply	20391
<sep> Response: We have reworded a few sentences to highlight the no-free-lunch perspective.	B-Reply	B-5	Reply	20391
<sep> <sep> <sep> Q: When choosing function classes that allow for universal function approximation, would F-information degrade to Shannon information?	O	O	Reply	20391
<sep> <sep> Response: Yes, this is an expected and desirable property as in Proposition 1.	B-Reply	B-6	Reply	20391
Roughly speaking, if F contains every function and every probability measure ‚Äî there are no computational constraints ‚Äî then all information is usable, which is exactly what Shannon information measures.	I-Reply	I-6	Reply	20391
The statistical and computational burden however, makes this a poor design choice for many machine learning problems.	I-Reply	I-6	Reply	20391

The paper proposes a conditional graph generation that directly optimizes the properties of the graph.	O	O	Review	850
The paper is very weak.	O	O	Review	850
<sep> 1.	B-Review	B-1	Review	850
I think almost all probabilistic graph generative models are differentiable.	I-Review	I-1	Review	850
If the  objective is differentiable function of real	I-Review	I-1	Review	850
variables, it is usually differentiable.	I-Review	I-1	Review	850
<sep> <sep> 2.	O	O	Review	850
The authors claim that existing works Simonovsky and Komodakis (2018) and Cao & Kipf (2018) are restricted to use small graphs with predefined maximum size.	B-Review	B-2	Review	850
This work does not overcome the limitation of small graphs issue too.	I-Review	I-2	Review	850
<sep> <sep> 3.	O	O	Review	850
The authors do not show any measure on validity, novelty or uniqueness which are now standard in literature.	B-Review	B-3	Review	850
<sep> Also I do not find any comparison with molGAN paper which tackles a similar objective.	I-Review	I-3	Review	850
<sep> <sep> 4.	O	O	Review	850
Could the authors show if the decoding process is permutation invariant?	B-Review	B-4	Review	850
I am not really sure of that.	I-Review	I-4	Review	850
I was trying to prove that thing formally, but I failed.	I-Review	I-4	Review	850
<sep> <sep> <sep> We thank the reviewer for his comments and will answer to these one by one.	O	O	Reply	850
<sep> <sep> 1.	O	O	Reply	850
<sep> We also state in the paper that probabilistic graph generative models are differentiable.	B-Reply	B-1	Reply	850
In the abstract ‚Äú In  this  work  we  propose  a  model  for  conditional  graph  generation  that directly  optimises  properties  of  the  graph,  and  generates  a  probabilistic graph,  making  the  decoding  process  differentiable‚Äù	I-Reply	I-1	Reply	850
<sep> <sep> 2.	O	O	Reply	850
They are limited to very small graph because of their parametriazations : the number of parameters depends on the predefined maximum graph size they have set.	B-Reply	B-2	Reply	850
If their last hidden layer is of size d, the number of edges r, and the maximum graph size of size n then the weight matrix mapping the last layer to the edge tensor  will be of size n*n*r*d which is very limiting.	I-Reply	I-2	Reply	850
<sep> <sep> Our factorization model does not have this limitation (the number of parameters only depends on the size of the embeddings we choose), and keeping in  memory of the full probabilistic graph is not an issue when working with molecules -> we are talking here of graphs with a maximum number of heavy atoms around 100.	I-Reply	I-2	Reply	850
So we overcome this limitation by having a model whose number of parameters does not depend on the maximum size of the graph.	I-Reply	I-2	Reply	850
We will change the manuscript to be more precise regarding that point.	I-Reply	I-2	Reply	850
<sep> <sep> <sep> 3.	O	O	Reply	850
<sep> Those measures are standard for purely generative models (where the task is to generate molecules without other objective, and the molecules are sampled form the prior).	B-Reply	B-3	Reply	850
Let us cite JT-VAE‚Äôs description of the reconstruction task to that extent :  ‚Äú <tab>We test the VAE models on the task of reconstructing input molecules from their latent representations, and decoding valid molecules when sampling from prior distribution. ‚	I-Reply	I-3	Reply	850
Äú	I-Reply	I-3	Reply	850
<sep> Our model is a conditional autoencoder, which is a new setting (we do not put any prior on the latent code).	I-Reply	I-3	Reply	850
<sep> <sep> MolGAN does not tackle the constrained optimization scenario at all and its formulation is not easily transferable to that setting : MolGAN is an implicit generative model.	I-Reply	I-3	Reply	850
One way to constrain the generation process could be to add a reward signal computing the similarity between the generator output and the query molecule (the prototype) but :	I-Reply	I-3	Reply	850
This would mean retraining/fine-tuning the model for each query molecule	I-Reply	I-3	Reply	850
The constrained scenario would be explicit : which is not the case of other models (JT-VAE, GCPN and ours) in which the similarity constraint is not directly specified.	I-Reply	I-3	Reply	850
JT-VAE finetunes the encoded representation, GCPN uses the prototype as a starting point, and we used a conditional formulation without retraining needed so such a comparison would be difficult and unfair anyway.	I-Reply	I-3	Reply	850
<sep> <sep> We will add in the appendix a comparative table of previous models to that extent and to justify the comparison effectively made in our manuscript.	I-Reply	I-3	Reply	850
To the best of our knowledge, only JT-VAE and GCPNN are comparable models in the implicitly constrained optimization scenario.	I-Reply	I-3	Reply	850
<sep> <sep> 4.	O	O	Reply	850
<sep> We never claimed that the decoding process  was permutation invariant.	B-Reply	B-4	Reply	850
We only made sure that we can make the encoder robust to permutations by training it on different permutations of the embeddings it encodes.	I-Reply	I-4	Reply	850
However the decoder is trained to match the domain canonical order (heavy atoms are ordered as they appear in their SMILES canonical representation).	I-Reply	I-4	Reply	850
<sep> <sep> We thank the reviewer again and  hope our comments shed a clearer light on our manuscript.	I-Reply	I-4	Reply	850
<sep> <sep> The authors	O	O	Reply	850

This paper proposed a variant of the graph variational autoencoder [1] to do generative modeling of graphs.	O	O	Review	850
The author introduced an additional conditional variable (e.g., property value) into the decoder.	O	O	Review	850
By backpropagating through the discriminator, the model is able to find the graph with desired property value.	O	O	Review	850
<sep> <sep> Overall the paper reads well and is easy to follow.	O	O	Review	850
The conditional generation of graphs seems also helpful regarding the empirical performance.	O	O	Review	850
However, there are several concerns regarding the paper:	O	O	Review	850
<sep> 1) The edge factorization-based modeling is not new.	B-Review	B-1	Review	850
In fact [1] already uses the node embeddings to factorize the adjacency matrix.	I-Review	I-1	Review	850
This paper models extra information including node tags and edge types, but these are not fundamental differences compared to [1].	I-Review	I-1	Review	850
<sep> 2) The paper claims the method is ‚Äòcheaper‚Äô and ‚Äòscalable‚Äô.	B-Review	B-2	Review	850
Since essentially the computation cost is similar to [1] which requires at least O(n^2) to generate a graph with n nodes, I‚Äôm not super confident about the author‚Äôs claim.	I-Review	I-2	Review	850
Though this can be parallelized, but the memory cost is still in this order of magnitude, which might be too much for a sparse graph.	I-Review	I-2	Review	850
Also there‚Äôs no large graph generative modeling experiments available.	I-Review	I-2	Review	850
<sep> <sep> 3) Continue with 2), the adjacency matrix of a large graph (e.g., graph with more than 1k nodes) doesn‚Äôt have to be low rank.	B-Review	B-3	Review	850
So modeling with factorization (with typically ~256 embedding size) may not be suitable in this case.	I-Review	I-3	Review	850
<sep> <sep> Some minor comments:	O	O	Review	850
4) Regarding Eq (2), why the lstm is used, instead of some simple order invariant aggregation?	B-Review	B-4	Review	850
<sep> <sep> 5) the paper needs more refinement.	B-Review	B-5	Review	850
E.g., in the middle of page 2 there is a missing citation.	I-Review	I-5	Review	850
<sep> <sep> [1]  Kipf & Welling, Variational Graph Auto-Encoders, <a href="https://arxiv.org/pdf/1611.07308.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1611.07308.pdf</a>	O	O	Review	850
<sep> We thank the reviewer for the detailed and useful comments.	O	O	Reply	850
We will proceed to the rebuttal as follows :	O	O	Reply	850
<sep> - Specific answers/clarifications on issues raised by the reviewer sequentially	O	O	Reply	850
- Summary of clarifications made in the answer	O	O	Reply	850
- Summary of changes in the manuscript implied by the review	O	O	Reply	850
<sep> ----- SEQUENTIAL: Clarifications/Answers -----	O	O	Reply	850
<sep> Our Answer  on 1) Novelty of the model  :	O	O	Reply	850
As referenced in  step 4 in section 3.1, we utilise the edge-factorization described in [1] (VGAE).	B-Reply	B-1	Reply	850
The goal here is to generate graphs of varying size given some input condition.	I-Reply	I-1	Reply	850
In practice this means being to generate both the nodes and edges of the graph, conditional on some latent  code.	I-Reply	I-1	Reply	850
<sep> <sep> In contrast the VGAE has been designed in the context of relational inference (eg.link prediction in citation network), where the number of nodes is fixed, and task is to learn a suitable representation for the nodes, such that we‚Äôre able to reconstruct/predict missing links.	I-Reply	I-1	Reply	850
<sep> <sep> Because of the assumptions of this setting the VGAE only solves half of the problem we are trying to address: given a set of node embeddings [1] reconstructs the adjacency tensor.	I-Reply	I-1	Reply	850
In contrast we want to be able to generate both the node embeddings whose number is unknown a priori and their adjacency tensor given some latent code.	I-Reply	I-1	Reply	850
<sep> <sep> In practice this is achieved by adding a new component (see step 3.	I-Reply	I-1	Reply	850
Sec 3.1) to model how to go from a latent code z to an actual set of node embeddings.	I-Reply	I-1	Reply	850
That specific node embeddings generator (that we parametrize with an LSTM)  is  the major contribution of our model.	I-Reply	I-1	Reply	850
<sep> <sep> To clarify the differences between [1] and our DEFactor  we added a short paragraph in the related work section on edge-factorization.	I-Reply	I-1	Reply	850
<sep> <sep> <sep> Our Answer  on 2) and 3)  Clarification on "large" "cheap" and  "scalable":	O	O	Reply	850
On the use of ‚Äúscalable‚Äù  and ‚Äúcheap‚Äù In the manuscript we state that scalable ``[..] means that the number of parameters of the decoder should not depend on a fixed pre-defined maximum graph size.	B-Reply	B-2	Reply	850
`` and the number of parameters in DEFactor is independent of the (max) size of the graph unlike  [2] and [3]. We fixed the misleading use in the manuscript	I-Reply	I-2	Reply	850
<sep> On the large graph modeling concern : the model‚Äôs focus is on molecular graphs (which we think is an important problem on its own) thus ‚Äúlarge‚Äù and ‚Äúsmall‚Äù do not have the same signification here when compared to general graphs/ networks (that is why we put large in italic style in the first version of the manuscript in the bullet points of the related work section  but we updated it into ‚Äúlarge molecular graphs‚Äù) .	B-Reply	B-3	Reply	850
Small = less than 10 heavy atoms (like in [2] and [3], they specify small in their title) Large = around 60 heavy atoms which is large enough in the optimization tasks we are interested in the drug discovery pipeline.	I-Reply	I-3	Reply	850
<sep> <sep> <sep> 4) Minor comments , Reviewer :  ‚ÄúRegarding Eq (2), why the lstm is used, instead of some simple order invariant aggregation?the paper needs more refinement.	O	O	Reply	850
E.g., in the middle of page 2 there is a missing citation.	O	O	Reply	850
‚Äù	O	O	Reply	850
<sep> We actually tried the simpler order invariant aggregation function (avg and max)  but the convergence was bad so we directly went for a more complex/richer feature extractor such as LSTM.	B-Reply	B-4	Reply	850
We agree that concerns can be raised concerning the matter of the order when we use such sequential aggregation functions however (as specified in section 3.1 (step 1 and 2) ) we trained the LSTM with a randomly permuted order of the embeddings it has to encode and did not notice any change in the performance of the model.	I-Reply	I-4	Reply	850
<sep> <sep> Broken link fixed, thanks :)	B-Reply	B-5	Reply	850
<sep> <sep> -----  SUMMARY : What we think  we clarified ------	B-Reply	B-6	Reply	850
<sep> - The  novelty of the proposed decoder ( = autoregressive generation of nodes embeddings for graphs of varying size) which we think has been misunderstood by the reviewer.	I-Reply	I-6	Reply	850
<sep> - The misleading use of words ‚Äúscalable‚Äù and ‚Äúcheap‚Äù : we meant only meant that the number of parameters should not depend on the graph size (when compared to [2] and [3]).	I-Reply	I-6	Reply	850
<sep> - The meaning of ‚Äúlarge‚Äù graphs in the context of molecular graphs (which we find is a relevant and important problem on its own).	I-Reply	I-6	Reply	850
<sep> <sep> ---- ACTION POINTS : What we modified in the manuscript ----	B-Reply	B-7	Reply	850
<sep> - Corrected the misleading use of ‚Äúscalable‚Äù and ‚Äúcheap‚Äù in the manuscript	I-Reply	I-7	Reply	850
- Replace large graphs by large molecular graphs to specify the scale of graphs we are referring to	I-Reply	I-7	Reply	850
- Added a paragraph in the related work section on the edge-factorization to further emphasize the true novelty of our decoder.	I-Reply	I-7	Reply	850
<sep> - Fixed the broken references	I-Reply	I-7	Reply	850
<sep> We hope that our answers clarified our contribution and thank the reviewer again,	O	O	Reply	850
<sep> The Authors	O	O	Reply	850
<sep> --- REFERENCES ---	O	O	Reply	850
<sep> [1] Kipf & Welling, Variational Graph Auto-Encoders , <a href="https://arxiv.org/pdf/1611.07308.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1611.07308.pdf</a>	O	O	Reply	850
[2] De Cao & Kipf,  MolGAN : An implicit generative model for small molecular graphs, <a href="https://arxiv.org/abs/1805.11973" target="_blank" rel="nofollow">https://arxiv.org/abs/1805.11973</a>	O	O	Reply	850
[3] Simonovsky & Komodakis, GraphVAE : Towards Generation of Small Graphs Using Variational Autoencoders, <a href="https://arxiv.org/abs/1802.03480" target="_blank" rel="nofollow">https://arxiv.org/abs/1802.03480</a>	O	O	Reply	850

In this paper, authors propose a deep generative model and a variant for graph generation and conditional graph generation respectively.	O	O	Review	850
It exploits an encoder which is built based on GCN and GraphSAGE, a autoregressive LSTM decoder which generates the graph embedding, and a factorized edge based probabilistic model for generating edge and node type.	O	O	Review	850
For conditional generation, authors also propose a discriminating training scheme based on maximizing the mutual information.	O	O	Review	850
Experiments on ZINC dataset show that the proposed method is promising.	O	O	Review	850
<sep> <sep> Strength:	O	O	Review	850
<sep> 1, The problem this paper tries to tackle is very challenging and of great significance.	O	O	Review	850
Especially, the conditional graph generation direction under the deep learning context is novel.	O	O	Review	850
<sep> <sep> 2, The overall model is interesting although it is a bit complicated as it combines quite a few modules.	O	O	Review	850
<sep> <sep> Weakness:	O	O	Review	850
<sep> 1, In the reconstruction experiment, comparisons with several recent competitive methods are missing.	B-Review	B-1	Review	850
For example, the methods which have been already discussed in the related work, Li et al (2018a), You et al (2018a) and You et al (2018b).	I-Review	I-1	Review	850
Moreover, it is not explained whether the comparison setting is the same as Jin et al (2018) and what the size of the latent code of their method is.	I-Review	I-1	Review	850
It seems less convincing by just taking results from their paper and do the comparison.	I-Review	I-1	Review	850
<sep> <sep> 2, Authors motive their work by saying in the abstract that ‚Äúother graph generative models are either computationally expensive, limiting their use to only small graphs or are formulated as a sequence of discrete actions needed to construct a graph, making the output graph non-differentiable w.r.t the model parameters‚Äù.	B-Review	B-2	Review	850
However, if I understood correctly, in Eq. (7), authors compute the soft adjacency tensor which is a dense tensor and of size #node by #node by #edge types.	I-Review	I-2	Review	850
Therefore, I did not see why this method can scale to large graphs.	I-Review	I-2	Review	850
<sep> <sep> 3, The overall model exploits a lot of design choices without doing any ablation study to justify.	B-Review	B-3	Review	850
For example, how does the pre-trained discriminator affect the performance of the conditional graph generation?	I-Review	I-3	Review	850
Why not fine-tune it along with the generator?	I-Review	I-3	Review	850
The overall model has quite a few loss functions and associated weights of which the values are not explained at all.	I-Review	I-3	Review	850
<sep> <sep> 4, Conditional generation part is not written clearly.	B-Review	B-4	Review	850
Especially, the description of variational mutual information phase is so brief that I do not understand the motivation of designing such an objective function.	I-Review	I-4	Review	850
What is the architecture of the discriminator?	I-Review	I-4	Review	850
<sep> <sep> 5, How do authors get real attributes from the conditionally generated molecules?	B-Review	B-5	Review	850
It is not explained in the paper.	I-Review	I-5	Review	850
<sep> <sep> Typos:	O	O	Review	850
<sep> 1, There are a few references missing (question mark) in the first and second paragraphs of section 2.	B-Review	B-6	Review	850
<sep> <sep> 2, Methods in the experiment section are given without explicit reference, like GCPN.	B-Review	B-7	Review	850
<sep> <sep> 3, Since edge type is introduced, I suggest authors explicitly mention the generated graphs are multi-graph in the beginning of model section.	B-Review	B-8	Review	850
<sep> <sep> Overall, I do not think this paper is ready for publishing and it could be improved significantly.	O	O	Review	850
<sep> <sep> ---------------------------------------------------------------------------------------------------------------------------------------------------------------------	O	O	Review	850
<sep> Update:	O	O	Review	850
<sep> Thanks for the detailed explanation.	O	O	Review	850
The new figure 1 is indeed helpful for demonstrating the overall idea.	O	O	Review	850
<sep> <sep> However, I still found some claims made by authors problematic.	B-Review	B-9	Review	850
<sep> For example, it reads in the abstract that "...or are formulated as a sequence of discrete actions needed to construct a graph, making the output graph non-differentiable w.r.t the model parameters...".	I-Review	I-9	Review	850
<sep> Clearly, Li et al 2018b has a differentiable formulation which falls under your description.	I-Review	I-9	Review	850
<sep> <sep> Besides, I suggest authors adjust the experiment such that it focuses more on comparing conditional generation.	B-Review	B-10	Review	850
<sep> Also, please set up some reasonable baselines based on previous work rather than saying it is not directly comparable.	B-Review	B-11	Review	850
<sep> Directly taking numbers from other papers for a comparison is not a good idea given the fact that these experiments usually involve quite a few details which could potentially vary significantly.	I-Review	I-11	Review	850
<sep> <sep> Therefore, I would like to keep my original rating.	O	O	Review	850
<sep> <sep> We thank the reviewer for his useful comments and will address his concerns sequentially.	O	O	Reply	850
<sep> <sep> 1.	B-Reply	B-1	Reply	850
For the comparison with Jin et Al [1], we recomputed the results in the same settings as ours in the revised version : deterministic AE, 2D molecular graphs, 56 latent size.	I-Reply	I-1	Reply	850
<sep> <sep> Concerning the missing comparison with the competitive methods suggested by the reviewer we would like to clarify that :	I-Reply	I-1	Reply	850
- We do discuss those methods in the related work part as existing generative models on molecular graphs but they were not designed to reconstruct a particular graph, and though are not adapted to an exact reconstruction task.	I-Reply	I-1	Reply	850
<sep> - In fact those methods do not come with an inference network whose output can be used to condition the whole generation process to match the condition.	I-Reply	I-1	Reply	850
<sep> <sep> Let us suppose that we equip those generative models with an encoder (typically ours), their decoding schemes involve a prediction of very long sequences of action and coming with a good training procedure in that context is not trivial at all  :	I-Reply	I-1	Reply	850
- How do we choose the sequences order ?	I-Reply	I-1	Reply	850
GCPN (and others) actually argues that using a fixed order as the domain suggested one (SMILES) yields overfitting of their model.	I-Reply	I-1	Reply	850
To that end they make use of randomly selected state transition in the training set.	I-Reply	I-1	Reply	850
Naturally this training procedure is not applicable to the task of exact graph reconstruction (where we want to reconstruct the exact full sequence of actions).	I-Reply	I-1	Reply	850
<sep> - Li et al actually states : ‚Äú The generation process used by the graph model is typically a long sequence of decisions.	I-Reply	I-1	Reply	850
If other forms of graph linearization is available, e.g. SMILES, then such sequences are typically 2-3x shorter.	I-Reply	I-1	Reply	850
This is a significant disadvantage for the graph model, it not only makes it harder to get the likelihood right, but also makes training more difficult.[...]We have found that training such graph models is more difficult than training typical LSTM models.	I-Reply	I-1	Reply	850
The sequences these models are trained on are typically long, and the model structure is constantly changing, which leads to unstable training.	I-Reply	I-1	Reply	850
Lowering the learning rate can solve a lot of instability problems, but more satisfying solutions may be obtained by tweaking the model.	I-Reply	I-1	Reply	850
‚Äù	I-Reply	I-1	Reply	850
<sep> We overall think that redesigning the suggested models so that they can perform well on an exact reconstruction task is not trivial and would constitute potentially completely different models in the end.	I-Reply	I-1	Reply	850
Spending considerable amount of time  trying to repurpose existing generative models does not seem reasonable.	I-Reply	I-1	Reply	850
The very example of the JT-VAE that was designed (by its architecture) to reconstruct graphs exactly support our opinion : we tried to go from the probabilistic VAE framework to the deterministic AE one and the best reconstruction result we could get with an available code was lower that the reported one on the VAE setting.	I-Reply	I-1	Reply	850
<sep> <sep> 2.	O	O	Reply	850
We  agree on the misleading for use of ‚Äòscalable‚Äô and ‚Äòcheap‚Äô in the manuscript.. Actually it was supposed to be understood as it is defined in the original related work section ( ‚Äú Scalable :  this means that the number of parameters of the decoder should not depend on a fixed predefined maximum graph size‚Äù  like it is the cas for [2] and [3]).	B-Reply	B-2	Reply	850
We fixed the misuse in the manuscript.	I-Reply	I-2	Reply	850
<sep> <sep> Concerning the large graph statement, the model‚Äôs focus is on molecular graphs (which we find is an important problem on its own) thus ‚Äúlarge‚Äù and ‚Äúsmall‚Äù do not have the same signification here when compared to general graphs/ networks.	B-Reply	B-2	Reply	850
Small = less than 10 heavy atoms (like in [2] and [3], they specify small in their title) Large = around 60 heavy atoms which is large enough in the optimization tasks we are interested in the drug discovery pipeline.	I-Reply	I-2	Reply	850

I do not necessarily see something wrong with the paper, but I'm not convinced of the significance (or sufficient novelty) of the approach.	O	O	Review	758
<sep> <sep> The way I understand it, a translator is added on top of the top layer of the student, which is nothing but a few conv layers that project the output to potentially the size of the teacher (by the way, why do you need both a paraphraser and translator, rather than making the translator always project to the size of the teacher which basically will do the same thing !? )	B-Review	B-1	Review	758
<sep> And then a distance is minimized between the translated value of the students and the teacher output layer.	B-Review	B-2	Review	758
The distance is somewhat similar to L2 (though the norm is removed from the features -- which probably helps with learning in terms of gradient norm).	I-Review	I-2	Review	758
<sep> <sep> Comparing with normal distillation I'm not sure how significant the improvement is.	B-Review	B-3	Review	758
And technically this is just a distance metric between the output of the student and teacher.	I-Review	I-3	Review	758
Sure it is a more involved distance metric, however it is in the spirit of what the distillation work is all about and I do not see this as being fundamentally different, or at least not different enough for an ICLR paper.	I-Review	I-3	Review	758
<sep> <sep> Some of the choices seem arbitrary to me (e.g. using both translator and paraphraser).	B-Review	B-4	Review	758
Does the translator need to be non-linear?	I-Review	I-4	Review	758
Could it be linear?	I-Review	I-4	Review	758
What is this mapping doing (e.g. when teacher and student have the same size) ?	I-Review	I-4	Review	758
Is it just finding a rotation of the features?	I-Review	I-4	Review	758
Is it doing something fundamentally more interesting?	I-Review	I-4	Review	758
<sep> <sep> Why this particular distance metric between the translated features?	B-Review	B-5	Review	758
Why not just L2?	I-Review	I-5	Review	758
<sep> <sep> In the end I'm not sure the work as is, is ready for ICLR.	B-Review	B-6	Review	758
<sep> <sep> Thanks for the review, but I think that your questions are out of focus.	O	O	Reply	758
In the abstract of our paper, at the line 6, we noted that our algorithm is extension of FT[1], and we also mentioned in the third paragraph of the second page that we utilize the translator of FT.	B-Reply	B-7	Reply	758
<sep> Most of the questions you ask are not obliged for us to answer them because our paper is not supposed to claim, but the FT paper could answer.	I-Reply	I-7	Reply	758
<sep> <sep> Our point is:	O	O	Reply	758
Using stronger teacher has many drawbacks.	B-Reply	B-1	Reply	758
As Lan et al(2018)[3] mentioned and we noted on our paper that, cases are possible where stronger teacher may not exist.	I-Reply	I-1	Reply	758
Knowledge Transfer(KT) methods such as KD[2] can use ensemble teacher instead of stronger teacher with large numbers of parameters, but KT methods that does not use predictions(labels) are incompatible with label ensemble.	I-Reply	I-1	Reply	758
<sep> What we claim is that our method could manage these problems, and also delivering knowledge at feature map layer may have advantages with giving more specific information, and could get decent results.	B-Reply	B-4	Reply	758
<sep> <sep> [1] Kim et al Paraphrasing Complex Network: Network Compression via Factor Transfer, 2018	O	O	Reply	758
[2] Hinton et al Distilling the Knowledge in a Neural Network, 2015	O	O	Reply	758
[3] Lan et al Knowledge distillation by on-the-fly native ensemble, 2018	O	O	Reply	758

In summary, I think this paper contains some reasonable results based on a reasonable, moderately novel, idea, but unfortunately, it is not yet ready for publication.	O	O	Review	758
Reading it made me rather confused.	O	O	Review	758
<sep> <sep> Good things:	O	O	Review	758
- The main idea is sensible, though distilling into the same architecture (sFEED) is not that novel.	B-Review	B-6	Review	758
I think the pFEED is probably the more novel part.	I-Review	I-6	Review	758
<sep> - The numerical results are quite good.	O	O	Review	758
<sep> - It's a fairly simple method.	O	O	Review	758
If others reproduced these results, I think it would be useful.	O	O	Review	758
<sep> <sep> Problems:	O	O	Review	758
- Some parts of the paper are written in a way that makes the reader confused about what this paper is about.	B-Review	B-1	Review	758
For example the first paragraph.	I-Review	I-1	Review	758
Some motivations I just did not understand.	I-Review	I-1	Review	758
<sep> - Some parts of the paper are repeating itself.	B-Review	B-2	Review	758
For example "introduction" and "related works".	I-Review	I-2	Review	758
The section on related work also includes some quite unrelated papers.	I-Review	I-2	Review	758
<sep> - The references in the paper are often pointing to work that came much later than the original idea or some pretty random recent papers.	B-Review	B-3	Review	758
For example the idea of model compression (or knowledge distillation) is much older than Hinton et al I believe it was first proposed by Bucila et al [1] (which the authors mention later as if knowledge distillation and model compression were very different ideas), it definitely doesn't come from Kim et al (2018).	I-Review	I-3	Review	758
Learning from intermediate representations of the network is at least as old as Romero et al [2]. Compression into a network of the same architecture is definitely older than Furnarello et al (2018).	I-Review	I-3	Review	758
It was done, for example, by Geras et al [3]. The paper also cites Goodfellow et al (2016) in some pretty random contexts.	I-Review	I-3	Review	758
I don't want to be too petty about references, but unfortunately, this paper is just below a threshold that I would still find acceptable in this respect.	I-Review	I-3	Review	758
<sep> - The comparison in Table 6 would make more sense if the same architectures would be clearly compared.	B-Review	B-4	Review	758
As it is, it is difficult to be certain where the improvement is coming from and how it actually compares to different methods.	I-Review	I-4	Review	758
<sep> <sep> Typos: Titap X, ResNext, prarphraser.	B-Review	B-5	Review	758
<sep> <sep> References:	O	O	Review	758
[1] Bucila et al Model Compression.	O	O	Review	758
2006.	O	O	Review	758
<sep> [2] Romero et al FitNets: Hints for Thin Deep Nets.	O	O	Review	758
2014.	O	O	Review	758
<sep> [3] Geras et al Blending LSTMs into CNNs.	O	O	Review	758
2016.	O	O	Review	758
Thank you for your constructive feedback.	O	O	Reply	758
I appreciate it and it was helpful in many points	O	O	Reply	758
First, for the novelty issue, I admit that sFEED is not that novel because it is similar with BANs[1]. While we were working on our paper, we came across with BANs and found sFEED is similar with BANs, but I thought it is worth reporting it because sFEED performed better at ImageNet.	B-Reply	B-6	Reply	758
<sep> Second, for the motivations, sorry for our bad at writing it clearly.	B-Reply	B-1	Reply	758
We mentioned our point again at Answer to reviewer #1.	I-Reply	I-1	Reply	758
<sep> <sep> For the related works and reference parts, we found that it was messy, and we will deliberately reflect what you pointed out.	B-Reply	B-2	Reply	758
<sep> <sep> For the experiments, we agree on your point that it would be better if we had compared ours with other knowledge transfer algorithms that use information from feature map level(you pointed out AT[3])	B-Reply	B-4	Reply	758
For the comparison on Table 6, since our purpose is to show that our method can deliver ensemble knowledge at feature map level, we just wanted to show that the performance is decent level.	I-Reply	I-4	Reply	758
<sep> Actually, we tried, but failed to reproduce the base DenseNet[2] models that BANs[1] used for their base network which are their own modulation.	I-Reply	I-4	Reply	758
Maybe the only one that can be compared is WRN-28-10 with BAN-1 and our sFEED with one iteration.	I-Reply	I-4	Reply	758
<sep> <sep> Thanks for pointing out the typos.	B-Reply	B-5	Reply	758
<sep> <sep> [1] Furlanello et al Born-Again Neural Networks, 2018	O	O	Reply	758
[2] Huang et al Densely Connected Convolutional Networks, 2016	O	O	Reply	758
[3] Zagoruyko et al Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer, 2016	O	O	Reply	758

In this paper, the authors present two methods, Sequential and Parallel-FEED for learning student networks that share architectures with their teacher.	O	O	Review	758
<sep> <sep> Firstly, it would be a good idea to cite <a href="https://arxiv.org/abs/1312.6184," target="_blank" rel="nofollow">https://arxiv.org/abs/1312.6184,</a> it precedes knowledge distillation and is basically the same thing minus a temperature parameter and a catchy name.	B-Review	B-1	Review	758
<sep> <sep> The paper could do with some further grammar/spell checks.	B-Review	B-2	Review	758
<sep> <sep> It isn't clear to me where the novelty lies in this work.	B-Review	B-3	Review	758
Sequential-FEED appears to be identical to BANs (<a href="https://arxiv.org/abs/1805.04770)" target="_blank" rel="nofollow">https://arxiv.org/abs/1805.04770)</a> with an additional non-linear transformation on the network outputs as in <a href="https://arxiv.org/abs/1802.04977."	I-Review	I-3	Review	758
target="_blank" rel="nofollow">https://arxiv.org/abs/1802.04977.</a> Parallel-FEED is just an ensemble of teachers; please correct me if I'm wrong.	I-Review	I-3	Review	758
<sep> <sep> The experimental results aren't convincing.	B-Review	B-4	Review	758
There aren't any fair comparisons.	I-Review	I-4	Review	758
For instance, in table 6 a WRN-28-10(sFEED) after 5 whole training iterations is compared to a WRN-28-1(BAN) after 1.	I-Review	I-4	Review	758
It would be good to run BAN for as many iterations.	I-Review	I-4	Review	758
A comparison to attention transfer (<a href="https://arxiv.org/abs/1612.03928)" target="_blank" rel="nofollow">https://arxiv.org/abs/1612.03928)</a> would be ideal for the ImageNet experiments.	I-Review	I-4	Review	758
Furthermore, if one isn't interested in compression, then Table 4 indicates that an ensemble is largely preferable.	I-Review	I-4	Review	758
<sep> <sep> This work would benefit from a CIFAR-10 experiment as it's so widely used (interestingly, BANs perform poorly on CIFAR-10), also a task that isn't image classification would be helpful to get a feel of how the method generalizes.	B-Review	B-5	Review	758
<sep> <sep> In summary I believe this paper should be rejected, as the method isn't very novel, and the experimental merits are unclear.	B-Review	B-6	Review	758
<sep> <sep> Pros:	O	O	Review	758
- Simple method	O	O	Review	758
- Largely written with clarity	O	O	Review	758
<sep> Cons:	O	O	Review	758
- Method is not very novel	B-Review	B-6	Review	758
- No compared thoroughly enough to other work	B-Review	B-4	Review	758
Thank you for the constructive review.	O	O	Reply	758
<sep> <sep> First, the sFEED, though the purpose of BANs[1] and ours are different, sFEED in our work and BANs ended up with similar training structure, and we admit that it lacks its novelty for their similarity in architecture with BANs.	B-Reply	B-3	Reply	758
<sep> However, for the pFEED, we did not, and could not use ‚Äòensemble of teachers‚Äô that you noted, because our purpose is to deliver the knowledge of ensemble at feature map level without using teachers‚Äô predictions.	I-Reply	I-3	Reply	758
<sep> <sep> The purpose of Table 6 is not to show that our method beat others, but to show that ours are fairly good.	B-Reply	B-4	Reply	758
We actually tried to reproduce the BANs, but unfortunately we could not reproduce the base DenseNet models that BANs used.	I-Reply	I-4	Reply	758
They reported that error of base DenseNet-80-80 is 17.16, but our reproduction of it only could achieve 17.71.	I-Reply	I-4	Reply	758
To the best of our knowledge, their DenseNet models such as DenseNet-80-80 or DenseNet-80-120 are not public release, and they are modulation of BANs, so we could not find differences in detail.	I-Reply	I-4	Reply	758
The WRN-28-10 with first iteration at sFEED can be fair to compare with WRN-28-10 at BAN-1, but sFEED with 1 iteration is just FT without paraphraser.	I-Reply	I-4	Reply	758
<sep> <sep> However, we think that the Table 4.	B-Reply	B-4	Reply	758
can give fair and meaningful comparison.	I-Reply	I-4	Reply	758
The KD column in Table 4 are those who really use ‚Äòensemble of teachers‚Äô for training.	I-Reply	I-4	Reply	758
Comparing ours with them shows that ours can be beneficial with giving specific knowledge with knowledges of ensemble at feature map level.	I-Reply	I-4	Reply	758
<sep> <sep> For the CIFAR-10 experiment, I do not necessarily feels the importance to report since it already performs well on CIFAR-100, which is more difficult task, but I had experimented for few networks with sFEED, but did not report it on our paper.	B-Reply	B-5	Reply	758
The result was	I-Reply	I-5	Reply	758
ResNet-56   6.97 -> 6.16	I-Reply	I-5	Reply	758
ResNet-110 6.43 -> 5.92	I-Reply	I-5	Reply	758
WRN28-10   4.00 -> 3.62	I-Reply	I-5	Reply	758
<sep> Testing on the tasks other than classification that you suggested would be good idea to try, and can be our future work.	B-Reply	B-5	Reply	758
<sep> <sep> [1] Furlanello et al Born-Again Neural Networks, 2018	O	O	Reply	758

[Overview]	O	O	Review	758
<sep> In this paper, the authors proposed a simple but effective way to augmentation the language model through memorization.	O	O	Review	758
Specifically, after obtaining a language model on a dataset, the model further uses the dataset to build a lookup table and then a k-nearest neighbor is used to searching the closest tokens for a token during inference.	O	O	Review	758
Based on this, the output distribution of a target token during the inference time would be modified accordingly.	O	O	Review	758
Through a comprehensive experiments and ablation studies, the authors showed that the proposed strategy can improve the performance of language models significantly for both the in-domain and out-domain testing scenarios.	O	O	Review	758
This is very insightful considering recently a lot of language models are focusing on increasing the size of model and training data.	O	O	Review	758
<sep> <sep> [Pros]:	O	O	Review	758
<sep> Overall I think the paper is well-written and presents clearly.	O	O	Review	758
Detailed points below:	O	O	Review	758
<sep> 1.	O	O	Review	758
the authors proposed a simple but effective method for increasing the generalization ability of language model through a memorization strategy.	O	O	Review	758
Specifically, the authors proposed to build a lookup table which memorizes the representation and output token pairs which are then used for the inference of language model.	O	O	Review	758
Different from conventional way, the proposed strategy does not introduce any more parameters in the model and also does not need any more training or fine-tuning on the target dataset.	O	O	Review	758
<sep> <sep> 2.	O	O	Review	758
The authors showed that the proposed strategy can improve the performance of language generation model (i.e., transformer) without any extra training or data, as shown in Table 1.	O	O	Review	758
Also, using the continuous caches  with KNN-LM further improve the performance.	O	O	Review	758
<sep> <sep> 3.	O	O	Review	758
Besides the main results shown in Table 1 and Table 2, the authors also showed using kNN-LM can probably outperforms the model which is directly trained on it.	O	O	Review	758
Also, it also supports domain adaptation from one language domain to another domain.	O	O	Review	758
<sep> <sep> 4.	O	O	Review	758
Finally, the authors presented a number of ablation studies to investigate how the performance is affected by the method of building datastore, including the size of nearest neighbor, the interpolation parameter, etc.	O	O	Review	758
These results are also insightful and meaningful for the readers to understand the method.	O	O	Review	758
<sep> <sep> [Cons]:	O	O	Review	758
<sep> I think this paper is a solid paper.	O	O	Review	758
So I would have some suggestions below:	O	O	Review	758
<sep> 1.	O	O	Review	758
The first concern about the method is the efficiency.	B-Review	B-1	Review	758
At page 3, the authors mentioned that the proposed strategy will bring more time cost.	I-Review	I-1	Review	758
It would be good if the authors can perform more systematical analysis on the time cost of building the datastore and inference for the proposed model.	I-Review	I-1	Review	758
<sep> <sep> 2.	O	O	Review	758
Second, the authors should not only evaluate the proposed method based on transformers.	B-Review	B-2	Review	758
It would be good to test on various language models to verify the generalization ability across different models, including the old-fashioned one like RNN and CNN.	I-Review	I-2	Review	758
<sep> <sep> 3.	B-Review	B-3	Review	758
Also, the authors should try to extend the proposed model to other language tasks, such as translation.	I-Review	I-3	Review	758
<sep> <sep> [Summary]	O	O	Review	758
<sep> In this paper, the authors introduced a simple but effective method to augment the pertained language model through memorizations.	O	O	Review	758
Though this is not absolutely new and relatively simple , the authors successfully demonstrate that it can be applied to improve the generation of language model much.	O	O	Review	758
The.	O	O	Review	758
thorough ablation studies help to understand the property of the proposed strategy.	O	O	Review	758
I think this paper overall is insightful and thoughtful.	B-Review	B-3	Review	758
It would be good to see the authors add more analysis on the computational complexity and also evaluate on more type of language models.	I-Review	I-3	Review	758
<sep> <sep> Hello Reviewer1,	O	O	Reply	758
<sep> Thanks for your comments.	O	O	Reply	758
We‚Äôre glad you enjoyed the paper!	O	O	Reply	758
<sep> <sep> Efficiency:	O	O	Reply	758
Building the datastore: A single epoch of training over the Wikitext-103 data takes ~5 hours on a single GPU.	B-Reply	B-1	Reply	758
In comparison, a single forward pass over the same dataset to save keys/values took ~4 hours.	I-Reply	I-1	Reply	758
Then, creating the datastore using FAISS took two hours on a single CPU.	I-Reply	I-1	Reply	758
Hence, building the datastore is is comparable to a single epoch of training.	I-Reply	I-1	Reply	758
In addition, the saving of keys/values as well as creating the datastore are trivial to parallelize.	I-Reply	I-1	Reply	758
<sep> <sep> Inference: We measured the decoding speed of kNN-LM and found that it can sample roughly 60 tokens per second on one GPU, which is easily fast enough for most applications (albeit slower than the vanilla LM, which can sample roughly 500 tokens per second).	B-Reply	B-1	Reply	758
Improving the efficiency is not a focus of this work, but it is likely that it could be significantly improved - for example, by downsampling frequent words from the datastore.	I-Reply	I-1	Reply	758
<sep> <sep> Other architectures:	O	O	Reply	758
We are in the process of evaluating the model on a CNN-based LM as well!	B-Reply	B-2	Reply	758
Thanks for the suggestion!	O	O	Reply	758
<sep> <sep> Future work:	O	O	Reply	758
We also agree that applying kNN-LM to translation would be an exciting next step which we hope to pursue in followup work!	B-Reply	B-3	Reply	758
<sep> <sep> Thanks!	O	O	Reply	758

<sep> Summary:	O	O	Review	758
The authors extend a pretrained LM by interpolating its next word distribution with a KNN model.	O	O	Review	758
The authors show retrieving nearest neighbor from corpus achieve quite large perplexity decrease in several language modeling benchmarks.	O	O	Review	758
<sep> <sep> Decision:	O	O	Review	758
Overall, the idea seems simple but is quite effective.	B-Review	B-1	Review	758
Even with some discussions on the related work with cache based LM and the work that use training examples explicitly, I feel it is a simple extension/usage of previous approaches.	I-Review	I-1	Review	758
Hence I am borderline with my decision.	O	O	Review	758
<sep> <sep> Supporting argument:	O	O	Review	758
1.	O	O	Review	758
The proposed idea uses KNN to look up training examples for interpolating the prediction.	B-Review	B-1	Review	758
As discussed by the authors, this approach is effective in factual knowledge, names, and near-duplicate sentences.	I-Review	I-1	Review	758
<sep> 2.	B-Review	B-1	Review	758
There are several experiments and ablation study in showing the effectiveness of the approach.	I-Review	I-1	Review	758
<sep> 3.	O	O	Review	758
The related work that uses training examples explicitly is quite similar to the proposed approach, though the authors claim that one is at the level of individual tokens and the other is the whole training sentences.	B-Review	B-1	Review	758
<sep> <sep> Additional feedback:	O	O	Review	758
1.	B-Review	B-2	Review	758
In reference, ‚ÄòBert‚Äô -&gt; ‚ÄòBERT‚Äô	I-Review	I-2	Review	758
2.	B-Review	B-3	Review	758
Missing reference: Yogatama et al Memory Architectures in Recurrent Neural Network Language Models, 2018, <a href="https://arxiv.org/abs/1410.3916," target="_blank" rel="nofollow">https://arxiv.org/abs/1410.3916,</a> <a href="https://arxiv.org/abs/1803.02400" target="_blank" rel="nofollow">https://arxiv.org/abs/1803.02400</a>	I-Review	I-3	Review	758
Hello Reviewer2,	O	O	Reply	758
<sep> Thanks for your comments.	O	O	Reply	758
<sep> <sep> As per your suggestion, we‚Äôll add more details comparing our method against related work!	B-Reply	B-1	Reply	758
The difference between kNN-LM and prior work is certainly larger than just operating at the token vs. the sentence level: prior work uses training examples very differently.	I-Reply	I-1	Reply	758
Guu et al (2018) sample a training example at random and edit it into a new sentence.	I-Reply	I-1	Reply	758
Gu et al (2018) look up training examples using edit distance against the test string that needs to be translated.	I-Reply	I-1	Reply	758
Both Gu et al (2018) and Weston et al (2018) train their models with the retriever and use the embeddings retrieved as inputs to the model.	I-Reply	I-1	Reply	758
In contrast, our kNN module requires no training and uses retrieved examples as the model‚Äôs prediction directly.	I-Reply	I-1	Reply	758
<sep> <sep> This model highlights the effectiveness of the similarity function that is learned by the LM.	I-Reply	I-1	Reply	758
In fact, our work shows that instead of using large models trained on large datasets, we may be able to use smaller models that learn effective similarity functions to generalize to larger datasets as well as to other domains, without any additional training necessary.	I-Reply	I-1	Reply	758
This sets us on an exciting path of thinking about using kNN to make our models more effective without necessarily scaling them up!	I-Reply	I-1	Reply	758
<sep> <sep> Thanks for your notes on the memory networks literature.	B-Reply	B-2	Reply	758
We‚Äôre working on adding a contrast there as well as a note on work from Walter Daelemans on pre-neural memory based language processing (2005)!	I-Reply	I-2	Reply	758
<sep> <sep> Thanks!	O	O	Reply	758

This work utilizes the kNN method on dense vectors to augment the LMs.	O	O	Review	758
The method is simple and straightforward, meanwhile, the performance seems great if only in terms of PPL.	O	O	Review	758
<sep> Three of my most concerns:	O	O	Review	758
1)<tab>It seems that this approach heavily relies on the similarity of context distribution between the training and test set.	B-Review	B-1	Review	758
Intuitively, higher performance will be achieved with more similar examples between training and test set.	I-Review	I-1	Review	758
This question should be discussed more in this work.	I-Review	I-1	Review	758
This similarity cannot always satisfied in practice, I thus quite doubt the proposed method can work for general case.	I-Review	I-1	Review	758
<sep> 2)<tab>The evaluation is only done for PPL, I notice the LM was trained in a corpus scale as pre-trained BERT, though none of real downstream tasks were evaluated like BERT.	B-Review	B-2	Review	758
Expect to see some MRC or NLI results with the proposed LM.	I-Review	I-2	Review	758
<sep> 3)<tab>Furthermore, though FAISS is very fast, it is hard to get great results with only a small datastore which makes the retrieving slow.	B-Review	B-3	Review	758
So it seems not suitable for tasks such as generations but maybe open-domain QA can be the scene for this method.	I-Review	I-3	Review	758
It would be great if there are some experiments on such tasks, and also combining with models such as BERT could be much better and convincing.	I-Review	I-3	Review	758
<sep> <sep> Questions	O	O	Review	758
What about other distance functions such as cosine distance?	B-Review	B-4	Review	758
The author only said L2 is better but there is no analysis on it.	I-Review	I-4	Review	758
<sep> <sep> Hi AnonReviewer3,	O	O	Reply	758
<sep> There might be some misunderstanding regarding your second point.	B-Reply	B-2	Reply	758
<sep> This is not a representation learning paper.	I-Reply	I-2	Reply	758
The authors propose to apply kNN on top of a pre-trained LM which requires no additional training.	I-Reply	I-2	Reply	758
Evaluations on downstream tasks (like MRC or NLI) are not applicable in their case.	I-Reply	I-2	Reply	758
<sep> However, this is totally understandable.	I-Reply	I-2	Reply	758
I also had this wrong impression when I read the paper for the first time.	I-Reply	I-2	Reply	758
<sep> <sep> Also, I believe it's common in the LM community to report just PPL (or BPC for character-level LM).	I-Reply	I-2	Reply	758
<sep> For example, Baevski &amp; Auli (ICLR 2019) and Dai et al (ACL 2019).	I-Reply	I-2	Reply	758
<sep> Admittedly, I personly would be interested in seeing kNN-LM being applied to other generation tasks where they can use other metrics such as ROUGE-L for summarization.	I-Reply	I-2	Reply	758
I imagine this may be a followup paper.	I-Reply	I-2	Reply	758

This paper proposed a piecewise linear close form expression for the Stein‚Äôs unbiased risk estimator and use this formulation to construct a new Encoder-decoder convolutional neural network.	O	O	Review	10158
The author claimed that this closely related to bagging.	O	O	Review	10158
Improved experimental results on two inverse problems are presented.	O	O	Review	10158
Overall, the experiment results are encouraging but the paper need clarification on a few points.	O	O	Review	10158
<sep> <sep> 1.	B-Review	B-1	Review	10158
In the model description part, the intuition behind the attention modules is never mentioned.	I-Review	I-1	Review	10158
It will be nice to explain the intuition and possibly attached the derivation of the loss function the attention modules.	I-Review	I-1	Review	10158
<sep> <sep> 2.	B-Review	B-2	Review	10158
the author seems misunderstand the difference between boosting and bagging.	I-Review	I-2	Review	10158
The way described in the paper is bagging and in order to do boosting, a sequential type of network structure probably need to be proposed.	I-Review	I-2	Review	10158
<sep> <sep> 3.	O	O	Review	10158
How will be model performance compared with a simple bagging for the baseline compared in the experiment part?	B-Review	B-3	Review	10158
<sep> <sep> General Comments:	O	O	Reply	10158
==&gt; We appreciate the reviewer for careful reading and constructive comments.	O	O	Reply	10158
We have revised the paper accordingly.	O	O	Reply	10158
In particular, we have clearly explained the motivation and provided experimental results that clearly show the advantages of the weighted average from the attention module over the standard bagging baseline.	B-Reply	B-3	Reply	10158
<sep> <sep> 1.	O	O	Reply	10158
In the model description part, the intuition behind the attention modules is never mentioned.	O	O	Reply	10158
It will be nice to explain the intuition and possibly attached the derivation of the loss function to the attention modules.	O	O	Reply	10158
<sep> <sep> ==&gt;  Thank you for the constructive comments.	B-Reply	B-1	Reply	10158
Although the standard way of aggregation in the bagging estimator is a simple average of the overall results from the regression network, this may not be the best method when the number of bootstrap subsampling is limited.	I-Reply	I-1	Reply	10158
Therefore,   we propose a weighted averaging scheme whose weight is calculated by the data attention module so that it efficiently combines all data by adaptively incorporating output from various bootstrap sub-sampling patterns.	I-Reply	I-1	Reply	10158
As shown in Fig.5, the weighted averaging from the weights calculated by the attention module significantly improved the performance.	I-Reply	I-1	Reply	10158
4 and Fig.	I-Reply	I-1	Reply	10158
<sep> <sep> 2.	O	O	Reply	10158
the author seems misunderstand the difference between boosting and bagging.	O	O	Reply	10158
The way described in the paper is bagging and in order to do boosting, a sequential type of network structure probably need to be proposed.	O	O	Reply	10158
<sep> <sep> ==&gt; Thanks for your careful reading.	B-Reply	B-2	Reply	10158
Although the term "boosting" could be used for general performance improvements, we agree with the reviewer and this revision uses the more accurate term "bootstrap and subsampling (bagging)".	I-Reply	I-2	Reply	10158
<sep> <sep> 3.	O	O	Reply	10158
How will be model performance compared with simple bagging for the baseline compared in the experiment part?	O	O	Reply	10158
<sep> <sep> ==&gt; Thanks for the suggestion.	B-Reply	B-3	Reply	10158
Fig.5 now clearly show that the proposed weighted average significantly outperformed the simple bagging baseline.	I-Reply	I-3	Reply	10158
4 and Fig.	I-Reply	I-3	Reply	10158

Summary: The authors consider an encoder decoder setup for linear deblurring problem and propose efficient boosting estimators.	O	O	Review	10158
Specifically, they use the Stein's unbiased risk estimator for the problem when the noise is gaussian.	O	O	Review	10158
In the case when the encoder and decoder is represented by a convolutional neural network with RELU activations, they show how they can exploit the recent theoretical results that show the kernel type results to make their procedure efficient.	O	O	Review	10158
They then propose using a set of models (boosting) and prove that the boosted loss function lower bounds the "nonboosted" loss function.	O	O	Review	10158
<sep> <sep> 1.	B-Review	B-1	Review	10158
I think Proposition 1 has minor errors, there is no need to apply Jensen's inequality since there's nothing random, but I think the claim is correct -- it is trivial.	I-Review	I-1	Review	10158
In experiments, they use attention network which is not a CNN, so I'm not sure how any of the theory applies to this case, can you please clarify?	I-Review	I-1	Review	10158
<sep> <sep> 2.	B-Review	B-2	Review	10158
Experimental focus of the paper is to analyze biomedical datasets -- HCP, EDX and the authors compared their method to *only* one baseline.	I-Review	I-2	Review	10158
I suggest that they perform some more comparisons on natural images like <a href="http://vllab.ucmerced.edu/wlai24/cvpr16_deblur_study/" target="_blank" rel="nofollow">http://vllab.ucmerced.edu/wlai24/cvpr16_deblur_study/</a>	I-Review	I-2	Review	10158
General Comments:	O	O	Reply	10158
==&gt; Thanks for the constructive comments.	O	O	Reply	10158
In the revised article and in this letter we have done our best to clarify the contents of the article and to avoid confusion by the reviewers.	O	O	Reply	10158
<sep> <sep> 1.(1) I think Proposition 1 has minor errors, there is no need to apply Jensen's inequality since there's nothing random, but I think the claim is correct -- it is trivial.	O	O	Reply	10158
<sep> <sep> ==&gt; We would like to assure the reviewer that Jensen's inequality does NOT necessarily require a random variable since it relates the value of a convex function of an integral (or sum) to the integral (or sum) of the convex function (Please see <a href="https://en.wikipedia.org/wiki/Jensen%27s_inequality" target="_blank" rel="nofollow">https://en.wikipedia.org/wiki/Jensen%27s_inequality</a> ).	B-Reply	B-1	Reply	10158
In fact, Jensen's inequality in the probability theory is a special case of the original Jensen's inequality when a convex function of a random variable is used.	I-Reply	I-1	Reply	10158
<sep> <sep> 1.(2)- In experiments, they use attention network which is not a CNN, so I'm not sure how any of the theory applies to this case, can you please clarify?	O	O	Reply	10158
<sep> <sep> ==&gt; Thanks for the comment.	O	O	Reply	10158
We would also like to assure the reviewer that the attention module provides only weighting factors $ \ {w_k \} $ for the weighted average calculation in (13), which has nothing to do with the kernel-type results for the encoder-decoder CNN that can simplify the divergence term in the SURE Estimator in (8).	B-Reply	B-1	Reply	10158
Therefore, it does not matter whether it is either in the form of CNN or a fully connected network.	I-Reply	I-1	Reply	10158
Since we only calculate the K-scalar values in the attention module, the operation is similar to the last layer in a classifier.	I-Reply	I-1	Reply	10158
This led us to use a simple fully connected layer.	I-Reply	I-1	Reply	10158
<sep> <sep> 2.	O	O	Reply	10158
Experimental focus of the paper is to analyze biomedical datasets -- HCP, EDX and the authors compared their method to *only* one baseline.	O	O	Reply	10158
I suggest that they perform some more comparisons on natural images like <a href="http://vllab.ucmerced.edu/wlai24/cvpr16_deblur_study/" target="_blank" rel="nofollow">http://vllab.ucmerced.edu/wlai24/cvpr16_deblur_study/</a>	O	O	Reply	10158
<sep> ==&gt; Thanks for the constructive comment.	O	O	Reply	10158
In our revised manuscript (which has been uploaded),  more comparison results on natural images for the super-resolution task are also provided in the Appendix.	B-Reply	B-2	Reply	10158
Moreover, the comparison results with the standard bagging baseline are also provided.	I-Reply	I-2	Reply	10158
We believe that the additional experimental results clearly showed that the proposed method provides better performance.	I-Reply	I-2	Reply	10158

1.	O	O	Review	10158
Summary	O	O	Review	10158
The authors address the problem of efficiently employing the SURE estimator as a network training regularizer.	O	O	Review	10158
They show that for CNN autoencoders this can be efficiently computed.	O	O	Review	10158
Their other contribution is a bagging/boosting technique which is proved to avoid trivial solutions.	O	O	Review	10158
The proposed architecture, motivated by the theoretical statements, is shown to outperform classic and 2019 state of the art image reconstruction algorithms in MRI and EDX.	O	O	Review	10158
<sep> 2.	O	O	Review	10158
Decision and arguments	O	O	Review	10158
Unfortunately this paper is outside my expertise so I can‚Äôt evaluate the novelty of the theoretical accomplishments.	B-Review	B-4	Review	10158
However taking that as a given, they well-motive the proposed architecture and achieve impressive experimental results.	I-Review	I-4	Review	10158
The experiments are well described.	I-Review	I-4	Review	10158
<sep> 3.	O	O	Review	10158
Questions	O	O	Review	10158
a) Why do Table 1 and Figure 3 provide different PSNR and SSIM values?	B-Review	B-1	Review	10158
<sep> b) Is there any way to measure accuracy to ground-truth with the EDX data?	B-Review	B-2	Review	10158
Or are the results just qualitative?	I-Review	I-2	Review	10158
<sep> c) With respect to Figure 2, and in general for autoencoders, the input and output have the same dimension.	B-Review	B-3	Review	10158
So how do you reconcile this with undersampled MRI and EDX data?	I-Review	I-3	Review	10158
I understand you train on fully sampled data‚Äîthen how do you input undersampled data?	I-Review	I-3	Review	10158
Are the unknown samples set to zero?	I-Review	I-3	Review	10158
<sep> <sep> However taking that as a given, they well-motive the proposed architecture and achieve impressive experimental results.	O	O	Reply	10158
The experiments are well described.	O	O	Reply	10158
<sep> <sep> ==&gt; Thanks for your understanding.	O	O	Reply	10158
We have also added additional experiments for the super-resolution tasks with natural images in the revised paper.	B-Reply	B-4	Reply	10158
Additionally, the revised paper also provides a comparison with the standard bagging baseline to show that adaptive averaging with the help of the attention module improves the performance.	I-Reply	I-4	Reply	10158
The results consistently show that the proposed method is better than the existing approaches.	I-Reply	I-4	Reply	10158
<sep> <sep> 3.	O	O	Reply	10158
Questions	O	O	Reply	10158
a) Why do Table 1 and Figure 3 provide different PSNR and SSIM values?	O	O	Reply	10158
<sep> <sep> ==&gt; Fig.3 was the PSNR/SSIM value for the individual figures, whereas Table 1 provides the average values for the *entire* test data set.	B-Reply	B-1	Reply	10158
We have clarified this in the main context in the revised paper.	I-Reply	I-1	Reply	10158
<sep> <sep> b) Is there any way to measure accuracy to ground-truth with the EDX data?	O	O	Reply	10158
Or are the results just qualitative?	O	O	Reply	10158
<sep> <sep> ==&gt; For the EDX case, no truth-relevant data is available for supervised training.	B-Reply	B-2	Reply	10158
This was the main reason why we developed our method.	I-Reply	I-2	Reply	10158
However, we would like to assure the reviewer that our material scientist has confirmed that the denoised images are clearly consistent with the expected layered structures of the quantum dots that they had expected from their manufacturing protocols.	I-Reply	I-2	Reply	10158
To provide more experimental results with the groud-truth data, the revised manuscript also provides the additional experimental results for super-resolution tasks.	I-Reply	I-2	Reply	10158
The results clearly show that the proposed method improves the performance.	I-Reply	I-2	Reply	10158
<sep> <sep> c) With respect to Figure 2, and in general for autoencoders, the input and output have the same dimension.	O	O	Reply	10158
So how do you reconcile this with undersampled MRI and EDX data?	O	O	Reply	10158
I understand you train on fully sampled data‚Äîthen how do you input undersampled data?	O	O	Reply	10158
Are the unknown samples set to zero?	O	O	Reply	10158
<sep> <sep> ==&gt;  Yes, you are right.	B-Reply	B-3	Reply	10158
Thanks for your careful observation.	I-Reply	I-3	Reply	10158
For the MRI case, we use the zero-filled k-space data as our network input, and for the EDX case, we used the noisy image as input since they are the same size as the network output.	I-Reply	I-3	Reply	10158

The authors provide a long text to justify their contributions and I have read it thoroughly.	O	O	Review	20247
Unfortunately, I find the responses don't really address my concerns.	O	O	Review	20247
<sep> <sep> My major concern is that I cannot understand how quadratic discriminator can be treated as WGAN.	B-Review	B-1	Review	20247
The authors replied that the regularization considered in the paper might be treated as Lipschitz constraint for bounded data sets.	I-Review	I-1	Review	20247
However, the data sets can‚Äôt be bounded because in the paper, the authors consider a special case where the data sets generated from a teacher network where the input is Gaussian noise.	I-Review	I-1	Review	20247
Moreover, the authors said that they would add an explanation of this important point in the revision but I haven‚Äôt found any revision yet.	I-Review	I-1	Review	20247
<sep> <sep> My another concern is that why the authors don‚Äôt study the two layer network discriminator.	B-Review	B-2	Review	20247
The authors replied that the choice of discriminator is designed in tandem with the choice of generator.	I-Review	I-2	Review	20247
If they use a standard two layer ReLU network as discriminator, this would hurt the sample complexity.	I-Review	I-2	Review	20247
I partly agree with that it will be nice if we can design a better discriminator according to the different choice of generator.	I-Review	I-2	Review	20247
However, it will be more convincing to show the convergence of WGAN if the authors consider NN discriminator rather than quadratic discriminator which hardly be used in GAN.	I-Review	I-2	Review	20247
<sep> <sep> ==================================================================================================	O	O	Review	20247
I found this paper over claims its contribution a lot, which is quite misleading.	B-Review	B-3	Review	20247
The title of this work is SGD LEARNS ONE-LAYER NETWORKS IN WGANS.	I-Review	I-3	Review	20247
And the authors claim that they analyze the convergence of stochastic gradient descent ascent for Wasserstein GAN on learning a single layer generator network.	I-Review	I-3	Review	20247
But actually this paper only considers two kinds of simplified discriminators: a (rectified) linear discriminator and quadratic discriminator, which are very different from WGAN used in practice.	I-Review	I-3	Review	20247
The analysis of two special cases are hard to be extended to the analysis of WGAN and thus can hardly help to explain why WGAN is successfully trained by SGD in practice.	I-Review	I-3	Review	20247
<sep> <sep> In section 3, the authors consider the rectified linear discriminator, which is quite similar to the standard two layer network with relu activation but the first layer is fixed.	B-Review	B-4	Review	20247
The authors prove that the generator can learn the marginal distribution but may not learn the joint distribution.	I-Review	I-4	Review	20247
In the beginning of section 4, the authors explain that this is because there is no interaction between different coordinates of the random vector.	I-Review	I-4	Review	20247
To learn joint distribution, the authors extend the linear discriminator to the quadratic discriminator and think of it as a natural idea.	I-Review	I-4	Review	20247
<sep> <sep> For the rectified linear discriminator, the regularization of the discriminator is the norm the output layer of discriminator which can be related to the Lipschitz constraint in WGAN.	B-Review	B-5	Review	20247
But for quadratic discriminator, I cannot understand how this setting can be treated as WGAN without further explanation from the authors.	I-Review	I-5	Review	20247
<sep> <sep> I wonder why this work doesn‚Äôt consider the standard two layer network discriminator which also has the interaction between different coordinates in the first layer.	B-Review	B-6	Review	20247
<sep> <sep> Thank you for your reviews.	O	O	Reply	20247
Unfortunately there is a significant misunderstanding of our contributions.	O	O	Reply	20247
We will try to clarify some concerns here and hope it will justify our contributions more clearly.	O	O	Reply	20247
<sep> <sep> We want to emphasize our contributions first.	O	O	Reply	20247
<sep> 1.	O	O	Reply	20247
To begin with, the global convergence of gradient descent-ascent in the GAN setting has not been extensively studied.	B-Reply	B-3	Reply	20247
We provide the to show for.	I-Reply	I-3	Reply	20247
The difficulty in analyzing gradient descent-ascent is twofold: the generator dynamics and discriminator dynamics.	I-Reply	I-3	Reply	20247
On the discriminator side, our choice of quadratic discriminator not only simplifies the dynamics but also has sufficient discriminating power (we will justify it  below).	I-Reply	I-3	Reply	20247
On the generator side, its minimization problem is non-convex, and therefore our convergence result to global equilibria is highly non-trivial.	I-Reply	I-3	Reply	20247
Our primary contribution in gradient descent-ascent analysis is to choose a proper discriminator set and to understand the generator dynamics.	I-Reply	I-3	Reply	20247
<sep> <sep> 2.	O	O	Reply	20247
For the generator class we are considering, we proved the quadratic discriminator both and (see point 3 below).	B-Reply	B-3	Reply	20247
Had we chosen to use a more complex discriminator, even if the maximization step were tractable, this would increase the sample complexity, potentially to a non-parametric rate (Feizi et al 2017; Bai et al 2018).	I-Reply	I-3	Reply	20247
<sep> <sep> 3.	O	O	Reply	20247
Our sample analysis also matches the upper bound of on dependence of the error provided in (Wu et al 2019).	B-Reply	B-3	Reply	20247
This is also a side proof that with WGAN we could via.	I-Reply	I-3	Reply	20247
<sep> <sep> Next we justify our choice of discriminator class.	O	O	Reply	20247
<sep> We want to emphasize that our goal is to show that SGD learns the ground truth generating distribution, with minimal requirements for the discriminator class.	B-Reply	B-2	Reply	20247
<sep> <sep> Our choice of discriminator class, quadratic discriminators, already to learn the family of distributions parametrized by our generator class.	I-Reply	I-2	Reply	20247
As shown in Theorem 3, the quadratic discriminator class is sufficient to learn the optimal generator.	I-Reply	I-2	Reply	20247
In fact using a larger discriminator family will only make the learning harder by increasing the sample complexity; see (Feizi et al 2017; Bai et al 2018) for a discussion of the importance of appropriately constraining the discriminator class to attain parametric sample complexity.	I-Reply	I-2	Reply	20247
Our choice of small discriminator class is a strength, not a weakness.	I-Reply	I-2	Reply	20247
<sep> <sep> When more complex discriminators are necessary (on studying more complicated generators for future work), we believe the discriminator dynamics can be analyzed using recent developments in the training of neural networks for classification problems (e.g. NTK results).	I-Reply	I-2	Reply	20247
However, this is not the focus of our paper since we are learning to recover one-layer generator, which does not need a complex discriminator.	I-Reply	I-2	Reply	20247
<sep> <sep> Finally we clarify some other points you‚Äôve raised.	O	O	Reply	20247
<sep> Q: ‚ÄúFor quadratic discriminator, I cannot understand how this setting can be treated as WGAN‚Äù	O	O	Reply	20247
A: For quadratic discriminator, the square norm regularizer enforces that the Lipschitz constant of the discriminator is upper bounded by 1, for bounded data sets.	B-Reply	B-5	Reply	20247
We will add an explanation of this important point in the revision.	I-Reply	I-5	Reply	20247
<sep> <sep> Q: ‚Äúwhy not study the two layer network discriminator‚Äù	O	O	Reply	20247
A: As we explained above, the choice of discriminator is designed in tandem with the choice of generator.	B-Reply	B-6	Reply	20247
If we use a standard two layer ReLU network as discriminator, this would hurt the sample complexity.	I-Reply	I-6	Reply	20247
<sep> <sep> Reference:	O	O	Reply	20247
(Feizi et al 2017) Feizi, S., Farnia, F., Ginart, T., &amp; Tse, D. (2017).	O	O	Reply	20247
Understanding GANs: the LQG setting.	O	O	Reply	20247
arXiv preprint arXiv:1710.10793.	O	O	Reply	20247
<sep> (Bai et al 2018) Bai, Y., Ma, T., &amp; Risteski, A. (2018).	O	O	Reply	20247
Approximability of discriminators implies diversity in GANs.	O	O	Reply	20247
arXiv preprint arXiv:1806.10586.	O	O	Reply	20247
<sep> (Wu et al 2019) Wu, S., Dimakis, A. G., &amp; Sanghavi, S, ‚ÄúLearning Distributions Generated by One-Layer ReLU Networks‚Äù, NeurIPS 2019	O	O	Reply	20247

I have read the authors response.	O	O	Review	20247
In the response the authors clarified the contributions of this paper.	O	O	Review	20247
I agree with the authors that the analysis of gradient descent-ascent is a difficult problem, and the optimization results given in this paper is a contribution of importance.	O	O	Review	20247
Because of this I have improved my score.	O	O	Review	20247
<sep> <sep> However, I do not agree with the authors that studying quadratic discriminators instead of more complicated ones should be considered as a contribution instead of drawback.	B-Review	B-1	Review	20247
In my opinion, as long as the focus is on WGAN, results involving standard neural networks are still more desired compared with the results in this submission.	I-Review	I-1	Review	20247
For example, similar results for a neural network discriminator might be even more impactful, because the optimization problem is even more difficult.	I-Review	I-1	Review	20247
Therefore I still consider the simple discriminator and generator as a weak point of this paper.	I-Review	I-1	Review	20247
<sep> <sep> <sep> ======================================================================================================	O	O	Review	20247
<sep> This paper studies the training of WGANs with stochastic gradient descent.	O	O	Review	20247
The authors show that for one-layer generator network and quadratic discriminator, if the target distribution is modeled by a teacher network same as the generator, then stochastic gradient descent-ascent can learn this target distribution in polynomial time.	O	O	Review	20247
The authors also provide sample complexity results.	O	O	Review	20247
<sep> <sep> The paper is well-written and the theoretical analysis seems to be valid and complete.	O	O	Review	20247
However, I think the WGANs studied in this paper are simplified too much that the analysis can no longer capture the true nature of WGAN training.	B-Review	B-2	Review	20247
<sep> <sep> First, the paper only studies linear and quadratic discriminators.	B-Review	B-3	Review	20247
This is not very consistent with the original intuition of WGAN, which is to use the worst Lipschitz continuous neural network to approximate the worst function in the set of all Lipschitz continuous functions in the definition of Wasserstein distance.	I-Review	I-3	Review	20247
When the discriminator is as simple as linear or quadratic functions, there is pretty much no ‚ÄúWasserstein‚Äù in the optimization problem.	I-Review	I-3	Review	20247
<sep> <sep> Moreover, the claim that SGD learns one-layer networks can be very misleading.	B-Review	B-4	Review	20247
In fact what is a ‚Äúone-layer‚Äù neural network?	I-Review	I-4	Review	20247
<sep> - if the authors meant ‚Äútwo-layer network‚Äù or ‚Äúsingle hidden layer network‚Äù, then this is not true.	I-Review	I-4	Review	20247
Because as far as I can tell, the model is much more difficult than the model.	I-Review	I-4	Review	20247
The former is a standard single hidden layer network which is non-convex, while the latter is essentially a linear model especially when \phi is known.	I-Review	I-4	Review	20247
<sep> - if the authors meant ‚Äúa linear model with elementwise monotonic transform‚Äù, then I would like to suggest that a more appropriate name should be used to avoid unnecessary confusion.	I-Review	I-4	Review	20247
<sep> <sep> As previously mentioned, the discriminators are too simple to approximate the Wasserstein distance, and therefore in general it should not be possible to guarantee recovery of the true data distribution.	B-Review	B-5	Review	20247
However, in this paper it is still shown that certain true distributions can be learned.	I-Review	I-5	Review	20247
This is due to the extremely simplified true model.	I-Review	I-5	Review	20247
In fact, even if the activation function is unknown, it seems that one can still learn well (for example, by Kendall‚Äôs tau).	I-Review	I-5	Review	20247
<sep> <sep> Thank you for your reviews.	O	O	Reply	20247
Unfortunately there is a significant misunderstanding of our contributions.	O	O	Reply	20247
We will try to clarify some concerns here and hope it will justify our contributions more clearly.	O	O	Reply	20247
<sep> <sep> We want to emphasize our contributions first.	O	O	Reply	20247
<sep> 1.	O	O	Reply	20247
To begin with, the global convergence of gradient descent-ascent in the GAN setting has not been extensively studied.	B-Reply	B-1	Reply	20247
We provide the to show for.	I-Reply	I-1	Reply	20247
The difficulty in analyzing gradient descent-ascent is twofold: the generator dynamics and discriminator dynamics.	I-Reply	I-1	Reply	20247
On the discriminator side, our choice of quadratic discriminator not only simplifies the dynamics but also has sufficient discriminating power (we will justify it  below).	I-Reply	I-1	Reply	20247
On the generator side, its minimization problem is non-convex, and therefore our convergence result to global equilibria is highly non-trivial.	I-Reply	I-1	Reply	20247
Our primary contribution in gradient descent-ascent analysis is to choose a proper discriminator set and to understand the generator dynamics.	I-Reply	I-1	Reply	20247
<sep> <sep> 2.	O	O	Reply	20247
For the generator class we are considering, we proved the quadratic discriminator both and (see point 3 below).	B-Reply	B-1	Reply	20247
Had we chosen to use a more complex discriminator, even if the maximization step were tractable, this would increase the sample complexity, potentially to a non-parametric rate (Feizi et al 2017; Bai et al 2018).	I-Reply	I-1	Reply	20247
<sep> <sep> 3.	B-Reply	B-1	Reply	20247
Our sample analysis also matches the upper bound of on dependence of the error provided in (Wu et al 2019).	I-Reply	I-1	Reply	20247
This is also a side proof that with WGAN we could via.	I-Reply	I-1	Reply	20247
<sep> <sep> Next we justify our choice of discriminator class.	O	O	Reply	20247
<sep> We want to emphasize that our goal is to show that SGD learns the ground truth generating distribution, with minimal requirements for the discriminator class.	B-Reply	B-3	Reply	20247
<sep> <sep> Our choice of discriminator class, quadratic discriminators, already to learn the family of distributions parametrized by our generator class.	I-Reply	I-3	Reply	20247
As shown in Theorem 3, the quadratic discriminator class is sufficient to learn the optimal generator.	I-Reply	I-3	Reply	20247
In fact using a larger discriminator family will only make the learning harder by increasing the sample complexity; see (Feizi et al 2017; Bai et al 2018) for a discussion of the importance of appropriately constraining the discriminator class to attain parametric sample complexity.	I-Reply	I-3	Reply	20247
Our choice of small discriminator class is a strength, not a weakness.	I-Reply	I-3	Reply	20247
<sep> <sep> When more complex discriminators are necessary (on studying more complicated generators for future work), we believe the discriminator dynamics can be analyzed using recent developments in the training of neural networks for classification problems (e.g. NTK results).	I-Reply	I-3	Reply	20247
However, this is not the focus of our paper since we are learning to recover one-layer generator, which does not need a complex discriminator.	I-Reply	I-3	Reply	20247
<sep> <sep> Finally we clarify some other points you‚Äôve raised.	O	O	Reply	20247
<sep> Q: ‚Äúwhat is one-layer generator‚Äù &amp; ‚Äúit can be learned easily‚Äù	O	O	Reply	20247
A: By one-layer generator we mean the second case as you have suggested.	B-Reply	B-4	Reply	20247
This terminology is also used in some prior work, for instance in (Wu et al 2019).	I-Reply	I-4	Reply	20247
As we have emphasized, our goal is not just to learn the one-layer generator by any method, but to understand the dynamics of gradient descent-ascent with WGAN on learning the distribution.	I-Reply	I-4	Reply	20247
We also demonstrate the near optimal sample complexity when learning with WGAN.	I-Reply	I-4	Reply	20247
Even though the generator is a simple formulation, this work still provides the first result on successful learning a non-linear generator with WGAN setting.	I-Reply	I-4	Reply	20247
<sep> <sep> Reference:	O	O	Reply	20247
(Feizi et al 2017) Feizi, S., Farnia, F., Ginart, T., &amp; Tse, D. (2017).	O	O	Reply	20247
Understanding GANs: the LQG setting.	O	O	Reply	20247
arXiv preprint arXiv:1710.10793.	O	O	Reply	20247
<sep> (Bai et al 2018) Bai, Y., Ma, T., &amp; Risteski, A. (2018).	O	O	Reply	20247
Approximability of discriminators implies diversity in GANs.	O	O	Reply	20247
arXiv preprint arXiv:1806.10586.	O	O	Reply	20247
<sep> (Wu et al 2019) Wu, S., Dimakis, A. G., &amp; Sanghavi, S, ‚ÄúLearning Distributions Generated by One-Layer ReLU Networks‚Äù, NeurIPS 2019	O	O	Reply	20247

In this paper, the authors attempt to prove that the Stochastic Gradient Descent-Ascent could converge to a global solution to the min-max problem of WGAN, in the setting of a one-layer generator and simple discriminator.	O	O	Review	20247
They also show that the linear discriminator could be used to learn the marginal distributions of each coordinate, while a quadratic one could obtain joint distributions of every two coordinates.	O	O	Review	20247
Since the linear discriminator and the quadratic one could be solved in one step Gradient Ascent, the author applied the standard analysis method to reveal the property of the Gradient Descent method.	O	O	Review	20247
Experiments are also carried out to justify their theory that the WGAN could recover the distribution.	O	O	Review	20247
<sep> <sep> However, the most significant drawback of this paper is that the settings for the discriminator are too simple, which leads to the following two problems: 1) Revealing the joint distributions of two coordinates is still much weaker than the desired result of recovering the true distribution of the data.	B-Review	B-1	Review	20247
2) The analysis of this paper could not be extended to a complex discriminator since it would be suffered from the training error propagation in the Gradient Ascent step, instead of getting an accurate solution for the Gradient Ascent step.	B-Review	B-2	Review	20247
<sep> <sep> Therefore, more explanations are desired to be given to bound the error propagation and what will the complimentary discriminator learn from the data distribution.	B-Review	B-2	Review	20247
Thank you for your reviews.	O	O	Reply	20247
Unfortunately there is a significant misunderstanding of our contributions.	O	O	Reply	20247
We will try to clarify some concerns here and hope it will justify our contributions more clearly.	O	O	Reply	20247
<sep> <sep> We want to emphasize our contributions first.	B-Reply	B-3	Reply	20247
<sep> 1.	I-Reply	I-3	Reply	20247
To begin with, the global convergence of gradient descent-ascent in the GAN setting has not been extensively studied.	I-Reply	I-3	Reply	20247
We provide the to show for.	I-Reply	I-3	Reply	20247
The difficulty in analyzing gradient descent-ascent is twofold: the generator dynamics and discriminator dynamics.	I-Reply	I-3	Reply	20247
On the discriminator side, our choice of quadratic discriminator not only simplifies the dynamics but also has sufficient discriminating power (we will justify it  below).	I-Reply	I-3	Reply	20247
On the generator side, its minimization problem is non-convex, and therefore our convergence result to global equilibria is highly non-trivial.	I-Reply	I-3	Reply	20247
Our primary contribution in gradient descent-ascent analysis is to choose a proper discriminator set and to understand the generator dynamics.	I-Reply	I-3	Reply	20247
<sep> <sep> 2.	O	O	Reply	20247
For the generator class we are considering, we proved the quadratic discriminator both and (see point 3 below).	B-Reply	B-3	Reply	20247
Had we chosen to use a more complex discriminator, even if the maximization step were tractable, this would increase the sample complexity, potentially to a non-parametric rate (Feizi et al 2017; Bai et al 2018).	I-Reply	I-3	Reply	20247
<sep> <sep> 3.	O	O	Reply	20247
Our sample analysis also matches the upper bound of on dependence of the error provided in (Wu et al 2019).	B-Reply	B-3	Reply	20247
This is also a side proof that with WGAN we could via.	I-Reply	I-3	Reply	20247
<sep> <sep> Next we justify our choice of discriminator class.	B-Reply	B-4	Reply	20247
<sep> We want to emphasize that our goal is to show that SGD learns the ground truth generating distribution, with minimal requirements for the discriminator class.	I-Reply	I-4	Reply	20247
<sep> <sep> Our choice of discriminator class, quadratic discriminators, already to learn the family of distributions parametrized by our generator class.	I-Reply	I-4	Reply	20247
As shown in Theorem 3, the quadratic discriminator class is sufficient to learn the optimal generator.	I-Reply	I-4	Reply	20247
In fact using a larger discriminator family will only make the learning harder by increasing the sample complexity; see (Feizi et al 2017; Bai et al 2018) for a discussion of the importance of appropriately constraining the discriminator class to attain parametric sample complexity.	I-Reply	I-4	Reply	20247
Our choice of small discriminator class is a strength, not a weakness.	I-Reply	I-4	Reply	20247
<sep> <sep> When more complex discriminators are necessary (on studying more complicated generators for future work), we believe the discriminator dynamics can be analyzed using recent developments in the training of neural networks for classification problems (e.g. NTK results).	I-Reply	I-4	Reply	20247
However, this is not the focus of our paper since we are learning to recover one-layer generator, which does not need a complex discriminator.	I-Reply	I-4	Reply	20247
<sep> <sep> Finally we clarify some other points you‚Äôve raised.	O	O	Reply	20247
<sep> Q: ‚Äúrevealing the joint distributions of two coordinates is still much weaker than the desired result of recovering the true distribution of the data‚Äù	O	O	Reply	20247
A: We prove in Theorem 1 that the gradient descent-ascent recovers the optimal generator, so we do achieve the desired result of recovering the true distribution of the data.	B-Reply	B-1	Reply	20247
<sep> <sep> Q: ‚Äúmore complex discriminator will cause train error propagation‚Äù	O	O	Reply	20247
A: As we have shown in Theorem 1, it is unnecessary to have a complex discriminator for our generator architecture.	B-Reply	B-2	Reply	20247
<sep> <sep> For more complex discriminator architectures, we believe it is possible to apply NTK results on the discriminator to analyze the discriminator dynamics.	I-Reply	I-2	Reply	20247
However, this is not the focus of our paper since we are learning to recover one-layer generator, which does not need a complex discriminator.	I-Reply	I-2	Reply	20247
<sep> <sep> Reference:	O	O	Reply	20247
(Feizi et al 2017) Feizi, S., Farnia, F., Ginart, T., &amp; Tse, D. (2017).	O	O	Reply	20247
Understanding GANs: the LQG setting.	O	O	Reply	20247
arXiv preprint arXiv:1710.10793.	O	O	Reply	20247
<sep> (Bai et al 2018) Bai, Y., Ma, T., &amp; Risteski, A. (2018).	O	O	Reply	20247
Approximability of discriminators implies diversity in GANs.	O	O	Reply	20247
arXiv preprint arXiv:1806.10586.	O	O	Reply	20247
<sep> (Wu et al 2019) Wu, S., Dimakis, A. G., &amp; Sanghavi, S, ‚ÄúLearning Distributions Generated by One-Layer ReLU Networks‚Äù, NeurIPS 2019	O	O	Reply	20247

This paper mainly tackles the problem of heterogeneous tasks in meta-learning by proposing a new meta-learning framework ARML, which contains a module extracting relations across classes and a module representing meta-knowledge.	O	O	Review	727
When processing a new task, a graphical task representation is firstly constructed based on class prototypes, and then information propagation is conducted on a super-graph to find the most relevant meta-knowledge in the meta-knowledge graph.	O	O	Review	727
Ideally, the higher similarity between a prototype and a meta-knowledge node means the higher the correlation between a class and a specific type of meta-knowledge.	O	O	Review	727
In order to construct task-specific meta-learners, the authors utilize two auto-encoders to encode task representations with and without meta-knowledge graph.	O	O	Review	727
After that, a modulating function is applied to a set of shared parameters, which finishes the calculation of task-specific parameters.	O	O	Review	727
The authors empirically evaluated the proposed method on several datasets and it seems that ARML outperforms some compared methods.	O	O	Review	727
<sep> <sep> This paper should be rejected.	O	O	Review	727
Firstly, the proposed method is not well motivated.	B-Review	B-6	Review	727
It‚Äôs true that tasks in meta-learning may be sampled from a complex (or multi-modal) task distribution, but why to represent a task as a graph?	I-Review	I-6	Review	727
I think the relation between tasks can be simply obtained from instances (CNN embeddings).	I-Review	I-6	Review	727
Secondly, it‚Äôs hard to say the meta-knowledge graph can really capture knowledge with ‚Äòexact meanings‚Äô even though in some situations, a subset of nodes is activated and others are not.	B-Review	B-2	Review	727
<sep> <sep> Main arguments	O	O	Review	727
1.	O	O	Review	727
<tab>The whole framework is too complex and it‚Äôs hard to say every module in the framework really works even ablation study is done.	B-Review	B-1	Review	727
<sep> 2.	O	O	Review	727
<tab>The meta-knowledge graph lacks interpretability.	B-Review	B-2	Review	727
From my perspective, it‚Äôs just a set of learnable parameters without any exact meanings.	I-Review	I-2	Review	727
Authors tried to analyze the constructed meta-knowledge graph by some experiments, but these discussions are farfetched.	I-Review	I-2	Review	727
<sep> <sep> Things to improve the paper	O	O	Review	727
1.	O	O	Review	727
<tab>Simplify the proposed method.	B-Review	B-3	Review	727
<sep> 2.	O	O	Review	727
<tab>Make it clear why should we represent a task as a graph.	B-Review	B-4	Review	727
<sep> 3.	O	O	Review	727
<tab>Some most widely used benchmark datasets such as mini-imagenet and tiered-imagenet are not used.	B-Review	B-5	Review	727
For a fair and convincing comparison, I suggest the authors test the proposed method on these benchmark datasets.	I-Review	I-5	Review	727
Moreover, more methods should be compared.	I-Review	I-5	Review	727
Thank you for your constructive and valuable comments.	O	O	Reply	727
We‚Äôve revised our paper following the suggestions and will explain your concerns in the following.	O	O	Reply	727
<sep> <sep> Q1: Framework is too complex (‚ÄúThings to improve the paper 1/Main argument 1‚Äù)	O	O	Reply	727
A1: Each component of our model speaks for itself and they collectively fulfill the entire goal.	B-Reply	B-1	Reply	727
We clarify the motivation of each major component and its corresponding ablation models:	I-Reply	I-1	Reply	727
- Prototype-based relational graph is used to summarize samples (use prototype) and extract the inner relation between prototypes.	I-Reply	I-1	Reply	727
Ablation models I, II, and III demonstrate its contribution.	I-Reply	I-1	Reply	727
<sep> - Meta-knowledge graph is used to organize previous learned knowledge by extracting the relationship between previous tasks.	B-Reply	B-1	Reply	727
Ablation models IV verify its effectiveness.	I-Reply	I-1	Reply	727
<sep> - Task-specific adaptation is used to customize the globally shared initialization by using task-specific information.	B-Reply	B-1	Reply	727
The superior performance over globally shared models proves its ability to leverage task relation.	I-Reply	I-1	Reply	727
Ablation models VII, VIII, and IX provide some variants of its implementation.	I-Reply	I-1	Reply	727
<sep> <sep> <sep> Q2: Motivation of modeling a task as a graph (‚ÄúThings to improve the paper 2‚Äù)	O	O	Reply	727
A2: To summarize and represent a task, we extract and aggregate the information across multiple prototypes, which serves as one of the key steps in our solution.	B-Reply	B-4	Reply	727
To achieve this goal, we propose to construct a graph between prototypes within a task and then use it to interact with meta-knowledge graph.	I-Reply	I-4	Reply	727
Finally, we aggregate the information of enhanced prototypes to derive the task embedding.	I-Reply	I-4	Reply	727
The graph structure is chosen as we not only need to model the prototype information but also the complex relationship among prototypes, as prototypes may be correlated to each other.	I-Reply	I-4	Reply	727
<sep> To further verify the effectiveness of graph structure, we further conduct one more ablation:	I-Reply	I-4	Reply	727
- Removing the link between prototypes (ablation III in the revised paper):	I-Reply	I-4	Reply	727
- Results of Plain-Multi: bird 72.53¬±0.72% | texture 49.25¬±0.68% | aircraft 74.46¬±0.64% | fungi 57.10¬±0.81%	I-Reply	I-4	Reply	727
- Results of Art-Multi: ave.	I-Reply	I-4	Reply	727
original 61.23¬±0.75% | ave.	I-Reply	I-4	Reply	727
blur 58.43¬±0.76% | ave.	I-Reply	I-4	Reply	727
pencil 54.76¬±0.72%	I-Reply	I-4	Reply	727
The better performance of ARML than ablation model III and ablation model I (no prototype-based graph) demonstrates the effect of the relation between prototypes.	I-Reply	I-4	Reply	727
<sep> <sep> <sep> Q3: Results of MiniImagenet and tieredImagenent (‚ÄúThings to improve the paper 3‚Äù)	O	O	Reply	727
A3: For MiniImagenet, the performance had already been reported.	B-Reply	B-5	Reply	727
Please refer to Section D in the appendix.	I-Reply	I-5	Reply	727
For tieredImagenet, we show the performance on 5-way 1-shot as follows (several MAML-based models are selected for comparison):	I-Reply	I-5	Reply	727
- Performance on globally shared models: MAML: 51.37 ¬± 1.80% | Reptile: 49.41 ¬± 1.82% | MetaSGD 51.48 ¬± 1.79%	I-Reply	I-5	Reply	727
- Task-specific models: MT-Net: 51.95 ¬± 1.83% | MUMOMAML: 51.95 ¬± 1.80% | HSML: 52.67 ¬± 1.85%	I-Reply	I-5	Reply	727
- Our ARML 52.91 ¬± 1.83%	I-Reply	I-5	Reply	727
Since these two benchmarks do not have obvious task heterogeneity, similar to the settings in [Finn NeurIPS‚Äô18], the goal is to compare our model with other MAML-based models and report the results.	I-Reply	I-5	Reply	727
We can see our ARML achieves comparable performance on these two homogeneous benchmarks but better performance on heterogeneous datasets (i.e., Plain-Multi and Art-Multi).	I-Reply	I-5	Reply	727

################################################################################	O	O	Review	727
Summary:	O	O	Review	727
<sep> The paper provides a interesting direction in the meta-learning filed.	O	O	Review	727
In particular, it proposes to enhance meta learning performance by fully exploring relations across multiple tasks.	O	O	Review	727
To capture such information, the authors develop a heterogeneity-aware meta-learning framework by introducing a novel architecture--meta-knowledge graph, which can dynamically find the most relevant structure for new tasks.	O	O	Review	727
<sep> <sep> <sep> ################################################################################	O	O	Review	727
Reasons for score:	O	O	Review	727
<sep> Overall, I vote for accepting.	O	O	Review	727
I like the idea of mining the relation between tasks and handle it by the proposed meta-knowledge graph.	O	O	Review	727
My major concern is about the clarity of the paper and some additional ablation models (see cons below).	O	O	Review	727
Hopefully the authors can address my concern in the rebuttal period.	O	O	Review	727
<sep> <sep> ################################################################################	O	O	Review	727
Pros:	O	O	Review	727
<sep> 1.	O	O	Review	727
The paper takes one of the most important issue of meta-learning: task heterogeneity.	O	O	Review	727
For me, the problem itself is real and practical.	O	O	Review	727
<sep> <sep> 2.	O	O	Review	727
The proposed meta-knowledge graph is novel for capturing the relation between tasks and address the problem of task heterogeneity.	O	O	Review	727
<sep> Graph structure provides a more flexible way of modeling relations.	O	O	Review	727
<sep> The design for using the prototype-based relational graph to query the meta-knowledge graph is reasonable and interesting.	O	O	Review	727
<sep> <sep> 3.	O	O	Review	727
This paper provides comprehensive experiments, including both qualitative analysis and quantitative results,  to show the effectiveness of the proposed framework.	O	O	Review	727
The newly constructed Art-Multi dataset further enhances the difficulty of tasks and makes the performance more convincing.	O	O	Review	727
<sep> <sep> ################################################################################	O	O	Review	727
Cons:	O	O	Review	727
<sep> 1.	O	O	Review	727
Although the proposed method provides several ablation studies, I still suggest the authors to conduct the following ablation studies to enhance the quality of the paper:	B-Review	B-1	Review	727
(1) It might be valuable to investigate the modulation function.	I-Review	I-1	Review	727
In the paper, the authors compare sigmoid, tanh, and Film layer.	I-Review	I-1	Review	727
Can the authors analyze the results by reducing the number of gating parameters in Eq.10 by sharing the gate value of each filter in Conv layers?	I-Review	I-1	Review	727
<sep> <sep> (2) What is the performance of the proposed model by changing the type of aggregators?	B-Review	B-1	Review	727
<sep> <sep> 2.	B-Review	B-2	Review	727
For the autoencoder aggregator, it would be better to provide more details about it, which seems not very clear to me.	I-Review	I-2	Review	727
<sep> <sep> 3.	B-Review	B-3	Review	727
In the qualitative analysis (i.e., Figure 2 and Figure 3), the authors provide one visualization for each task.	I-Review	I-3	Review	727
It would be more convincing if the authors can provide more cases in the rebuttal period.	I-Review	I-3	Review	727
<sep> <sep> <sep> ################################################################################	O	O	Review	727
Questions during rebuttal period:	O	O	Review	727
<sep> Please address and clarify the cons above	O	O	Review	727
<sep> ################################################################################	O	O	Review	727
Some typos:	B-Review	B-4	Review	727
(1) Table 7: I. no sample-level graph -&gt; I. no prototype-based graph	I-Review	I-4	Review	727
(2) 5.1 Hyperparameter Settings: we try both sigmoid, tanh Film -&gt; we try both sigmoid, tanh,	I-Review	I-4	Review	727
Film.	I-Review	I-4	Review	727
<sep> (3) parameteric -&gt; parametric	I-Review	I-4	Review	727
(4) Table 2: Origninal -&gt; original	I-Review	I-4	Review	727
(5) Section 4 first paragraph:  The enhanced prototype representation -&gt; The enhanced prototype representations	I-Review	I-4	Review	727
<sep> <sep> Updates: Thanks for the authors' response.	O	O	Review	727
The newly added experimental results address my concerns.	O	O	Review	727
I believe this paper will provide new insights for this field and I recommend this paper to be accepted.	O	O	Review	727
<sep> <sep> We greatly appreciate your comments and thoughtful suggestions.	O	O	Reply	727
You may find our corresponding explanations and solutions below for the issues.	O	O	Reply	727
<sep> <sep> Q1: More ablation studies	O	O	Reply	727
A1: We‚Äôve conducted the ablation studies and show the results of 5-way 5-shot as follows (see the revised paper for 5-way 1-shot results) as follows:	B-Reply	B-1	Reply	727
- We change the encode and decode model from GRU to MLP (ablation model VI in the revised paper):	I-Reply	I-1	Reply	727
- Results of Plain-Multi: bird 72.36¬±0.72% | texture 48.93¬±0.67% | aircraft 74.28¬±0.65% | fungi 56.91¬±0.83%	I-Reply	I-1	Reply	727
- Results of Art-Multi: ave.	I-Reply	I-1	Reply	727
original 60.62¬±0.73% | ave.	I-Reply	I-1	Reply	727
blur 58.04¬±0.72% | ave.	I-Reply	I-1	Reply	727
pencil 54.85¬±0.72%	I-Reply	I-1	Reply	727
The better performance of ARML indicates GRU may be a better choice due to its higher expressive power.	B-Reply	B-1	Reply	727
<sep> - The results of sharing gate within each filter in Conv layers are (ablation model VII in the revised paper):	I-Reply	I-1	Reply	727
- Results of Plain-Multi: bird 72.83¬±0.72% | texture 48.66¬±0.68% | aircraft 74.13¬±0.66% | fungi 56.83¬±0.81%	I-Reply	I-1	Reply	727
- Results of Art-Multi: ave.	I-Reply	I-1	Reply	727
original 60.65¬±0.74% | ave.	I-Reply	I-1	Reply	727
blur 57.51¬±0.75% | ave.	I-Reply	I-1	Reply	727
pencil 53.23¬±0.74%	I-Reply	I-1	Reply	727
Compared with ablation VII, ARML achieves better performance, indicating the benefits of the customized gate for each parameter.	I-Reply	I-1	Reply	727
<sep> <sep> <sep> Q2: Detailed description of autoencoder aggregator	O	O	Reply	727
A2: The autoencoder aggregator consists of one encoder and one decoder model.	B-Reply	B-2	Reply	727
In this paper, we adopt GRU as the encoder model and decoder model.	I-Reply	I-2	Reply	727
The input of GRU is [#prototype, #embeded dim]. Then, a mean pooling layer is applied to the output of GRU to calculate task representation [1, #embeded dim]. To enhance the learning stability, like [Srivastava ICML‚Äô15], the decoder is used to reversely reconstruct the input.	I-Reply	I-2	Reply	727
The output of the decoder is still [#prototype, #embedd dim]. Then, the reconstruction error is calculated by the mean square loss between the output of the decoder and the input.	I-Reply	I-2	Reply	727
<sep> <sep> <sep> Q3: More qualitative cases	O	O	Reply	727
A3: We‚Äôve added more qualitative cases in Appendix H.2.	B-Reply	B-3	Reply	727
The observations are similar to the discussion in the paper (i.e., Figure 2 and 3).	I-Reply	I-3	Reply	727
The results further support the motivation for constructing the meta-knowledge graph.	I-Reply	I-3	Reply	727
<sep> <sep> <sep> References:	O	O	Reply	727
[Srivastava ICML‚Äô15] Srivastava, Nitish, Elman Mansimov, and Ruslan Salakhudinov. "	O	O	Reply	727
Unsupervised learning of video representations using lstms."	O	O	Reply	727
International conference on machine learning.	O	O	Reply	727
2015.	O	O	Reply	727

This paper proposed a knowledge-based meta-learning framework, called ARML(Automated Relational Metal-Learning) that automatically extracts cross-task relations and constructs a meta-knowledge graph.	O	O	Review	727
ARML wanted to solve the task heterogeneity problem in meta-learning through knowledge graph learning using graph neural networks.	O	O	Review	727
To do this, the authors introduced a framework consisting of (1) finding a prototype-based relational structure, (2) constructing a meta-knowledge graph, and (3) adapting the task-specific knowledge.	O	O	Review	727
Experimental results show that the proposed algorithm outperforms other competitive algorithms in few-shot learning tasks, which is justified by experimentally showing that the learned meta-knowledge graph has a meaningful interpretation.	O	O	Review	727
<sep> <sep> The paper was well-motivated and well-written, which made it very interesting to read.	O	O	Review	727
Looking at the task heterogeneity problem of meta-learning as a knowledge graph learning problem is the most important contribution of this paper.	O	O	Review	727
Since then, the framework's proposal to learn it as a graph neural network is a very natural extension, which can greatly increase the performance of existing few-shot learning tasks.	O	O	Review	727
<sep> <sep> The question here is whether the meta-learning method for finding relational structures through knowledge graphs is the first one proposed in this paper.	B-Review	B-1	Review	727
The paper "Few-shot learning with graph neural networks, ICLR-2018" performed the few-shot learning task with very similar motivation.	I-Review	I-1	Review	727
What is the difference compared to this paper?	I-Review	I-1	Review	727
<sep> <sep> And as mentioned in the paper, HSML is the closest study to ARML in that it considers high-level relations between cross-tasks.	B-Review	B-2	Review	727
The reviewer is very curious about the qualitative comparison of the high-level structures found by the two algorithms, and I confident that this comparison will enrich the paper.	I-Review	I-2	Review	727
Thanks a lot for the constructive comments and pointing out the potential confusion.	O	O	Reply	727
<sep> Q1: Difference between ICLR 2018	O	O	Reply	727
A1: Thank you for offering us a chance to explain the differences between the paper in ICLR‚Äô2018 and our approach.	O	O	Reply	727
The major differences are listed as follows:	O	O	Reply	727
- ICLR 2018: Like other globally shared meta-learning models [Finn ICML‚Äô17;Snell NeurIPS‚Äô17], the goal of that paper is to learn a globally-shared meta-learner to facilitate the learning process on new tasks.	B-Reply	B-1	Reply	727
They regard the few-shot learning problem as a semi-supervised learning task and adopt graph-based semi-supervised learning method to solve it.	I-Reply	I-1	Reply	727
The contribution of this paper is to infer labels in test set by passing messages in a constructed graph.	I-Reply	I-1	Reply	727
Specifically, the graph is constructed by treating each sample as a vertex.	I-Reply	I-1	Reply	727
The edge weights are gauged by the embedding similarity between corresponding vertices.	I-Reply	I-1	Reply	727
Then, they propagate the labels in the training set to infer unknown labels in the test set.	I-Reply	I-1	Reply	727
- Ours: We utilize a meta-knowledge graph in our model in order to enable relevant information retrieval from historical knowledge.	B-Reply	B-1	Reply	727
In other words, instead of utilizing a graph to propagate label information in ICLR 2018, we aim to learn from the knowledge propagated from relevant summarized historical tasks to enhance the representation learning of the current task.	I-Reply	I-1	Reply	727
To the best of our knowledge, we are the first to capture cross-task relationship by learning and leveraging meta-knowledge graph.	I-Reply	I-1	Reply	727
<sep> <sep> <sep> Q2: Comparison of learned structure between HSML and ARML(ours)	O	O	Reply	727
A2: The relation between tasks in HSML is expressed by a predefined tree structure.	B-Reply	B-2	Reply	727
Thus, the setting of input structure requires external human prior knowledge, which involves massive labor efforts to explore the optimal structure.	I-Reply	I-2	Reply	727
For instance, it requires careful setting with # layers and # nodes in each layer.	I-Reply	I-2	Reply	727
On the contrary, ARML provides a fully automatic solution by introducing a graph to capture the task dependencies.	I-Reply	I-2	Reply	727
Note that, the hierarchical structure is a special case in the graph.	I-Reply	I-2	Reply	727
<sep> <sep> Furthermore, the tree structure in HSML requires the aggregation across prototype representations to be ready before querying the historical knowledge.	I-Reply	I-2	Reply	727
Different from HSML, our graph structure is constructed with the goal of tapping into the input task with the historical knowledge by fully exploring the prototype-prototype, prototype-knowledge and knowledge-knowledge relations simultaneously.	I-Reply	I-2	Reply	727
More specifically, the prototype representation is enriched by leveraging relevant information from the knowledge-knowledge structure.	I-Reply	I-2	Reply	727
The task representation, which summarizes the internal categories and their pairwise relations, is more complete and comprehensive, as the information aggregation is conducted at the very last step with almost no information loss.	I-Reply	I-2	Reply	727
<sep> <sep> In the revised version, we add the comparison of case studies between HSML and ARML in Appendix H.1.	I-Reply	I-2	Reply	727
Four tasks sampled from bird, bird blur, aircraft, aircraft blur are selected for case studies (these four tasks are also used in the original analysis in Figure 3).	I-Reply	I-2	Reply	727
For HSML, we follow the setting of case study in the original paper.	I-Reply	I-2	Reply	727
In each task, we show the soft-assignment probability to each cluster and the activated clusters in the tree structure.	I-Reply	I-2	Reply	727
For ARML, we show the learned structure and the similarity heatmap between prototypes and meta-knowledge vertices.	I-Reply	I-2	Reply	727
From the visualized structures in different tasks, we can observe that our proposed model involves historical knowledge in a more flexible way.	I-Reply	I-2	Reply	727
More specifically, while HSML activates the relevant clusters in a hierarchical way, ARML provides more possibilities to leverage summarized historical knowledge.	I-Reply	I-2	Reply	727
Note that, a hierarchical/tree structure is a special case in a graph structure.	I-Reply	I-2	Reply	727
<sep> <sep> <sep> References:	O	O	Reply	727
[Finn ICML‚Äô17] Finn, Chelsea, Pieter Abbeel, and Sergey Levine. "	O	O	Reply	727
Model-agnostic meta-learning for fast adaptation of deep networks."	O	O	Reply	727
Proceedings of the 34th International Conference on Machine Learning-Volume 70.	O	O	Reply	727
JMLR.	O	O	Reply	727
org, 2017.	O	O	Reply	727
<sep> [Snell NeurIPS‚Äô17] Snell, Jake, Kevin Swersky, and Richard Zemel. "	O	O	Reply	727
Prototypical networks for few-shot learning."	O	O	Reply	727
Advances in Neural Information Processing Systems.	O	O	Reply	727
2017.	O	O	Reply	727

Clarity:	O	O	Review	1174
The work is a clear introduction/overview of this area of research.	O	O	Review	1174
The reviewer enjoyed the connections to Multiple-Gradient Descent and clear distinctions/contrasts with previous approaches to weighting the outputs of multiple discriminators.	O	O	Review	1174
All in all, the paper is quite clear in what its contributions are and how it differs from previous approaches.	O	O	Review	1174
The details and motivations of the Hypervolume Maximization  (HVM) method (especially as it relates to and interacts with the slack method of picking the nadir point) were a bit harder to follow intuitively given the standalone information in the paper.	O	O	Review	1174
Originality:	O	O	Review	1174
Adapts a technique to approximate MGD called HVM (Miranda 2016) and applies it to multi-discriminator training in GANs.	O	O	Review	1174
As far as the reviewer is aware, this is a novel application of HVM to this task and well motivated under the MGD interpretation of the problem.	O	O	Review	1174
Significance:	O	O	Review	1174
Unclear.	O	O	Review	1174
This work in isolation appears to present an improvement over prior work in this sub-field, but it is not obvious that the findings in these experiments will continue to be robust in more competitive settings.	O	O	Review	1174
For instance, the worst performing model on CIFAR10, WGAN-GP (according to the experiments run) WGAN-GP also holds near SOTA Inception scores on CIFAR10 when appropriately tuned.	O	O	Review	1174
Without any experimental results extending beyond toy datasets like MNIST and CIFAR10 the reviewer is not confident whether fundamental issues with GAN training are being addressed or just artifacts of small scale setups.	O	O	Review	1174
Closely related previous work (Neyshabur 2017) scaled to 128x128 resolution on a much more difficult dataset - Imagenet Dogs but the authors did not compare in this case.	O	O	Review	1174
Quality:	O	O	Review	1174
Some concerns about details of experiments (see cons list and significance section for further discussion).	O	O	Review	1174
Pros:	O	O	Review	1174
+ The work provides a clear overview of previous work on approaches using multiple discriminators.	O	O	Review	1174
+ The connections of this line of work to MGD and the re-interpretation of various other approaches in this framework is valuable.	O	O	Review	1174
+ The author provides direct comparisons to similar methods, which increases confidence in the results.	O	O	Review	1174
+ On the experiments run, the HVM method appears to be an improvement over the two previous approaches of softmax weighting and straightforward averaging for multiple discriminators.	O	O	Review	1174
Cons:	O	O	Review	1174
- Performance of GANs is highly dependent on both model size and compute expended for a given experiment (see Miyato 2018 for model size and training iterations and Brock 2018 for batch size).	O	O	Review	1174
Training multiple discriminators (in this paper up to 24) significantly increases compute cost and effective model size.	O	O	Review	1174
No baselines controlling for the effects of larger models and batch sizes are done.	O	O	Review	1174
- The paper lacks experiments beyond toy-ish tasks like MNIST and CIFAR10 and does not do a good job comparing to the broader established literature and contextualizing its results on certain tasks such as CIFAR10 (reporting ratios to a baseline instead of absolute values, for instance).	O	O	Review	1174
The absolute inception score of the baseline DCGAN needs to be reported to allow for this.	O	O	Review	1174
Is the Inception Score of the authors DCGAN implementation similar to the 6 to 6.5 reported in the literature?	O	O	Review	1174
- Figure 3 is slightly strange in that the x axis is time to best result result instead of just overall wallclock time.	O	O	Review	1174
Without additional information I can not determine whether it is admissible.	O	O	Review	1174
Do all models achieve their best FID scores at similar points in training?	O	O	Review	1174
Why is this not just a visualization of FID score as a function of wallclock time?	O	O	Review	1174
A method which has lower variance or continues to make progress for longer than methods which begin to diverge would be unfairly represented by the current Figure.	O	O	Review	1174
Additional comments:	O	O	Review	1174
In section 3.1 Eq 5 appears to be wrong.	O	O	Review	1174
The loss of the discriminator is presented in a form to be minimized so exponentiating the negative loss in the softmax weighting term as presented will do the opposite of what is desired and assign lower weight to higher loss discriminators.	O	O	Review	1174
In Fig 6 FID scores computed on a set of 10K samples are shown.	O	O	Review	1174
The authors appear to draw the line for the FID score of real data at 0.	O	O	Review	1174
But since it is being estimated with only 10K samples there will be sampling error resulting in non-zero FID score.	O	O	Review	1174
The authors should update this figure to show the box-plot for FID scores computed on random draws of 10K real samples.	O	O	Review	1174
I have only worked with FID on Imagenet where FID scores for random batches of 10K samples are much higher than 0.	O	O	Review	1174
I admit there is some chance the value is extremely low on CIFAR10 to make this point irrelevant, however.	O	O	Review	1174
Thank you once more for your time and suggestions.	O	O	Reply	1174
We hope to have addressed your concerns and would appreciate if you take the results included during the rebuttal into consideration when reviewing your score.	O	O	Reply	1174
We are looking forward to hearing back from you and open to discuss any further concern.	O	O	Reply	1174

This paper studies the problem of training of Generative Adversarial Networks employing a set of discriminators, as opposed to the traditional game involving one generator against a single model.	O	O	Review	1174
Specifically, this paper claims two contributions:	O	O	Review	1174
1.	O	O	Review	1174
We offer a new perspective on multiple-discriminator GAN training by framing it in the context of multi-objective optimization, and draw similarities between previous research in GANs variations and MGD, commonly employed as a general solver for multi-objective optimization.	O	O	Review	1174
2.	O	O	Review	1174
We propose a new method for training multiple-discriminator GANs: Hypervolume maximization, which weighs the gradient contributions of each discriminator by its loss.	O	O	Review	1174
Overall, the proposed method is empirical and the authors show its performance by experiments.	O	O	Review	1174
First, I want to discuss the significance of this work (or this kind of work).	O	O	Review	1174
As surveyed in the paper, the idea of training of Generative Adversarial Networks employing a set of discriminators has been explored by several previous work, and showed some performance improvement.	O	O	Review	1174
However, this idea (methods along this line) is not popular in GAN applications, like image-to-image translation.	O	O	Review	1174
I guess that the reason may be that: the significant computational cost (both in FLOPS and memory consumption) increase due to multiple discriminators destroys the benefit from the small performance improvement.	O	O	Review	1174
Maybe I‚Äôm wrong.	O	O	Review	1174
In Appendix C Figure 10, the authors compares the wall-lock time between DCGAN, WGAN-GP and multiple-discriminator, and claims that the proposed approach is cheaper than WGAN-GP.	O	O	Review	1174
However, WGAN-GP is more expensive due to its loss function involves gradients, while the proposed method does not.	O	O	Review	1174
If directly compared with DCGAN, we can see an obvious increase in wall-clock time (FLOPS).	O	O	Review	1174
In addition, the additional memory consumption is hidden there, which is a bigger problem in practice when the discriminators are large.	O	O	Review	1174
SN-GAN have roughly the same computational cost and memory consumption of DC-GAN, but inception and FID are much higher.	O	O	Review	1174
From my perspective, a fair comparison is under roughly the same FLOPS and memory consumption.	O	O	Review	1174
The paper is well-written.	O	O	Review	1174
The method is well-motivated by the multi-objective optimization perspective.	O	O	Review	1174
Although the presentation of the Hypervolume maximization method (Section 3.2) is not clear, the resulting loss function (Equation 10) is simple, and shares the same form with other previous methods.	O	O	Review	1174
The hyperparameter \eta is problematic in the new formulation.	O	O	Review	1174
The authors propose the Nadir Point Adaption to set this parameter.	O	O	Review	1174
The authors conduct extensive experiments to compare different methods.	O	O	Review	1174
The authors emphasize that the performance is improved with more discriminators, but it‚Äôs good to contain comparison of the computational cost (FLOPS and memory consumption) at the same time.	O	O	Review	1174
There are some small questions for the experiments.	O	O	Review	1174
The reported FID is computed from a pretrained classifier that is specific to the dataset, instead of the commonly used Inception model.	O	O	Review	1174
I recommend the authors also measure the FID with the Inception model, so that we have a direct comparison with existing reported scores.	O	O	Review	1174
Overall, I found that this work is empirical, and I‚Äôm not convinced by its experiments about the advantage of multiple-discriminator training, due to lacking of fair computational cost comparison with single-discriminator training.	O	O	Review	1174
Thank you once more for your time and suggestions.	O	O	Reply	1174
We hope to have addressed your concerns and would appreciate if you take the results included during the rebuttal into consideration when reviewing your score.	O	O	Reply	1174
We are looking forward to hearing back from you and open to discuss any further concern.	O	O	Reply	1174

The paper investigates the use of multi-objective optimization techniques in GAN-setups where there are multiple discriminators.	O	O	Review	1174
Using multiple discriminators was proposed in Durugkar et al, Arora et al, Neyshabur et al and others.	O	O	Review	1174
The twist here is to focus on the Pareto front and to import multiple gradient descent and hypervolume-maximization based methods into GANs.	O	O	Review	1174
<sep> <sep> The results are decent.	B-Review	B-1	Review	1174
The authors find that optimizing with respect to multiple discriminators increases diversity of samples for a computational cost.	I-Review	I-1	Review	1174
However, just scaling up (and carefully optimizing), can yield extremely impressive samples, <a href="https://arxiv.org/abs/1809.11096."	I-Review	I-1	Review	1174
target="_blank" rel="nofollow">https://arxiv.org/abs/1809.11096.</a> It is unclear how the tradeoffs in optimizing against multiple discriminators stack-up against bigger GANs.	I-Review	I-1	Review	1174
<sep> <sep> From my perspective, the paper is interesting because it introduces new methods into GANs from another community.	O	O	Review	1174
However, the results themselves are not sufficient for publication.	B-Review	B-2	Review	1174
<sep> <sep> We thank the reviewer for the feedback and taking the time for reading our paper.	O	O	Reply	1174
We are glad that the reviewer found our method interesting and hope that the following response, added to the new results included in the manuscript, will make her/him more confident about our contributions.	O	O	Reply	1174
<sep> <sep> Regarding the mentioned trade-off, we understood that the reviewer is referring to the addition of ‚Äúcapacity‚Äù (in terms of the number of parameters) on the discriminators side, as in the multiple-discriminators settings, or in the generator side, as in the pointed reference (Brock et al 2018).	B-Reply	B-1	Reply	1174
We would like to point out that such approaches have different goals: while adding capacity in the generator side is intended to yield generators able to scale to higher resolution settings and higher quality samples, multiple-discriminators are aimed at stabilizing training, avoiding common issues such as mode-collapse and divergence, which makes final performance of the generator highly dependent of careful hyperparameters tuning.	I-Reply	I-1	Reply	1174
If enough resources are available, both approaches should be used jointly.	I-Reply	I-1	Reply	1174
As we also observed multiple-discriminators training to yield higher quality and diversity when compared to their single-discriminator equivalents, we believe higher scales settings would also benefit.	I-Reply	I-1	Reply	1174
<sep> <sep> Regarding the insufficiency of results, we would like to respectfully highlight that we presented quantitative and qualitative results (comparing with both single- and multiple-discriminators GANs) in 4 datasets (namely, MINIST, CIFAR-10, Stacked MNIST, and CelebA), with consistent conclusions.	B-Reply	B-2	Reply	1174
We also included samples on a higher resolution for CelebA at 128x128 in Appendix D.2, and are currently running experiments to compare different versions of GANs in the single  vs. multiple discriminators settings.	I-Reply	I-2	Reply	1174
Some preliminary results which will be added to the manuscript as soon as we conclude the new experiments, show that adding discriminators yield the following relative improvement in terms of FID: DCGAN - 55.21%; LSGAN - 57.93% (we are currently running similar experiments on other GANs such as wGAN-GP and hingeGAN [2]).	I-Reply	I-2	Reply	1174
Moreover, we would highly appreciate if the reviewer could suggest any further experiment in order to increase her/his confidence in our results.	I-Reply	I-2	Reply	1174
<sep> <sep> [2] Miyato, Takeru, et al "Spectral normalization for generative adversarial networks."	O	O	Reply	1174
arXiv preprint arXiv:1802.05957 (2018).	O	O	Reply	1174

Summary: This paper considers the addition of self-supervised learning techniques in the few-shot learning setting.	O	O	Review	20709
Extensive experiments are done to show that it can be helpful, including in cases where the labeled data is corrupted.	O	O	Review	20709
The paper also considers the domain mismatch issue where unlabeled images come from a different domain.	O	O	Review	20709
<sep> <sep> Review: This paper is thorough and clearly written.	O	O	Review	20709
Applying self-supervised learning techniques to the few-shot learning regime is a simple idea, and this paper clearly shows that it can be beneficial.	O	O	Review	20709
It includes extensive experiments on a wide variety of image datasets, including many additional studies in the appendix.	O	O	Review	20709
The only possible criticisms of this paper are that it is limited to the image domain (as are most few-shot learning/self-supervised learning studies, so we can probably ignore this) and that it does not produce a huge delta in understanding compared to Gidaris et al (2019).	B-Review	B-1	Review	20709
Gidaris et al (2019) was posted to arxiv in June, I'm not sure if this work was also on arxiv around the same time, and even if it wasn't I'm not sure what to consider "concurrent".	I-Review	I-1	Review	20709
However, as the authors note they include additional experimental settings (like the domain-selection idea) that are not in Gidaris et al (2019), so the works are somewhat complementary.	I-Review	I-1	Review	20709
The only other comment I have is that the paper is quite large in scope for a conference submission and as a result there are many details and experiments that are left for the appendix.	B-Review	B-2	Review	20709
I could also see the domain selection experiments constituting their own submission.	I-Review	I-2	Review	20709
For example the definition of the "'distance' between a pair of domains" is only introduced in passing in the midst of Section 4.2 covering domain shift experiments, and the method for training a domain classifier is similarly only mentioned in passing in 4.2.	I-Review	I-2	Review	20709
Of course, it is not really valid to criticize a paper for being too exhaustive.	I-Review	I-2	Review	20709
Overall, I recommend acceptance.	I-Review	I-2	Review	20709
<sep> <sep> Specific comments:	O	O	Review	20709
- Truly a minor suggestion but I suggest moving Figure 1 to the top of page 2.	B-Review	B-3	Review	20709
<sep> - Snell et al (2017) needs a \citep	B-Review	B-4	Review	20709
- You ought to cite "S4L: Self-Supervised Semi-Supervised Learning", which is related to your discussion of connections between self- and semi-supervised learning (though not few-shot).	B-Review	B-5	Review	20709
<sep> - The paragraph beginning "The focus of most prior work..." in the Related Work section provides a nice framing of your work and so might make more sense in the introduction.	B-Review	B-6	Review	20709
<sep> - "we consider self-supervised losses based on labeled data ... that can be derived from inputs x alone" All labels (can be derived from in the inputs x alone, given an oracle (or human labeler).	B-Review	B-7	Review	20709
I think you mean "that can be derived automatically without any human labeling".	I-Review	I-7	Review	20709
<sep> - You state "Our final loss function combines the two losses".	B-Review	B-8	Review	20709
Is there no scalar multiplier on either loss term to trade-off the importance of each?	I-Review	I-8	Review	20709
<sep> - The gains from the self-supervised auxiliary tasks are over and above any gains from data augmentation alone.	B-Review	B-9	Review	20709
More experimental details are in Appendix A.5."	I-Review	I-9	Review	20709
I don't see any information to substantiate the claim that the self-supervised tasks result in a bigger improvement than data augmentation alone, can you provide those details?	I-Review	I-9	Review	20709
<sep> - "However, does more unlabeled data always help for a task in hand?"	B-Review	B-10	Review	20709
This question actually was addressed somewhat in "Realistic Evaluation of Semi-Supervised Learning Algorithms", see sections 4.4 and 4.5 therein.	I-Review	I-10	Review	20709
** Comparing to Gidaris et al **	O	O	Reply	20709
Gidaris et al is a concurrent work of ours.	B-Reply	B-1	Reply	20709
While there are many differences (e.g. they use 64*64 images and a WRN-28 model while we use 224*224 images and a ResNet18 model), the improvements on mini-ImageNet and tiered-ImageNet on 5-way 5-shot classification are in the same range as ours.	I-Reply	I-1	Reply	20709
We also additionally report results on several fine-grained domains.	I-Reply	I-1	Reply	20709
<sep> <sep> ** Scalar multiplier **	O	O	Reply	20709
We found using equal weights for the two losses works well (same conclusion as Gidaris et al), so we did not include the scalar term in the main text.	B-Reply	B-1	Reply	20709
The only exception is on mini-ImageNet and tiered-ImageNet which is explained in Appendix A.5.	I-Reply	I-1	Reply	20709
<sep> <sep> ** ‚ÄúThe gains from the self-supervised auxiliary tasks are over and above any gains from data augmentation alone‚Äù **	O	O	Reply	20709
We meant that even after extensive data augmentation (cropping, jittering, flipping, etc.),	B-Reply	B-9	Reply	20709
SSL provides consistent improvements.	I-Reply	I-9	Reply	20709
A.5 describes the details of the data augmentation.	I-Reply	I-9	Reply	20709
Apologies for the confusion.	I-Reply	I-9	Reply	20709
<sep> <sep> As an additional experiment we ran the baselines without data augmentation as shown below.	I-Reply	I-9	Reply	20709
The results are worse, but SSL provides consistent improvements.	I-Reply	I-9	Reply	20709
<sep> ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê	I-Reply	I-9	Reply	20709
Dataset	I-Reply	I-9	Reply	20709
Method                                    Birds     Cars    Aircrafts   Dogs    Flowers	I-Reply	I-9	Reply	20709
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ	I-Reply	I-9	Reply	20709
ProtoNet (w/o aug)                 74.0      75.7       78.1       59.3        80.7	I-Reply	I-9	Reply	20709
ProtoNet+Jigsaw (w/o aug)   77.7      83.5       80.7       60.3        86.8	I-Reply	I-9	Reply	20709
ProtoNet (w/ aug)                    87.3      91.7       91.4       83.0        89.2	I-Reply	I-9	Reply	20709
ProtoNet+Jigsaw (w/ aug)      89.8      92.4       91.8       85.7        92.2	I-Reply	I-9	Reply	20709
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê	I-Reply	I-9	Reply	20709
<sep> ** Related work **	O	O	Reply	20709
Indeed the two works are related and complementary to ours;  Zhai et al show that self-supervised and semi-supervised learning methods can be complementary when a large unlabeled dataset (ImageNet) is used.	B-Reply	B-6	Reply	20709
Oliver et al investigate the effect of extra unlabeled data and the domain mismatch for semi-supervised learning.	I-Reply	I-6	Reply	20709
However, it is not clear if the same conclusion holds for few-shot learning, the main focus of this paper.	I-Reply	I-6	Reply	20709
We also focus our evaluation on several fine-grained domains.	I-Reply	I-6	Reply	20709
We will include a discussion in the related work.	I-Reply	I-6	Reply	20709

Summary &amp; Pros	O	O	Review	20709
- This paper proposes a few-shot learning method that uses self-supervision as an auxiliary label and trains primary and auxiliary labels via multi-task learning.	O	O	Review	20709
<sep> - This paper provides extensive experiments for analyzing the effect of self-supervision on various few-shot learning settings: (1) self-supervision can improve various few-shot learning algorithms, ProtoNet &amp; MAML; (2) self-supervision with similar samples can provide more improvements.	O	O	Review	20709
<sep> <sep> Concerns #1: Novelty of the proposed method	O	O	Review	20709
- This paper uses a multi-task learning approach with self-supervision.	B-Review	B-1	Review	20709
But this approach is already used in various tasks, e.g., domain adaptation, semi-supervised learning, training GANs.	I-Review	I-1	Review	20709
Thus, the proposed method (in Section 3) using a multi-task learning objective with self-supervised losses seems to be incremental.	I-Review	I-1	Review	20709
<sep> <sep> Concerns #2: Somewhat unsurprising experimental results	O	O	Review	20709
- This paper shows various experimental results, but some experiments seem to be trivial.	B-Review	B-2	Review	20709
For example, the performance gap is typically increased when learning harder tasks, e.g., when the number of training samples is decreasing, the performance gap between methods is typically increasing in a fully-supervised setting.	I-Review	I-2	Review	20709
Thus I think results in the paragraph "Gains are larger for harder tasks" might be predictable.	I-Review	I-2	Review	20709
Other examples are Figure 4a and 4b in Section 4.2 because one can easily expect that using training more in-domain samples can provide more performance gain.	I-Review	I-2	Review	20709
<sep> - In the case of Figure 4d in Section 4.2, the authors claimed that the effectiveness of SSL decreases as the distance from the supervised domain increases.	B-Review	B-3	Review	20709
However, I think Figure 4d is not matched to the claim.	I-Review	I-3	Review	20709
For example, in the case of Dogs, better performance is achieved when using a more dissimilar domain for self-supervision except for D_s=D_ss.	I-Review	I-3	Review	20709
So I wonder how to draw the lines in Figure 4d.	I-Review	I-3	Review	20709
<sep> <sep> Some experimental results provide meaningful messages, e.g., single self-supervision can improve performance significantly while joint self-supervision does marginally.	B-Review	B-4	Review	20709
However, the contribution of the methodology is limited and some experimental results seem to incremental.	I-Review	I-4	Review	20709
<sep> <sep> ** Concern 1 about novelty **	O	O	Reply	20709
Our novelty lies in the result that self-supervised learning improves few-shot learning on small datasets, with state-of-the-art deep networks, and on fine-grained domains.	B-Reply	B-1	Reply	20709
We also systematically estimate the effect of domain shifts through extensive experiments across datasets.	I-Reply	I-1	Reply	20709
These results are likely of interest to the community.	I-Reply	I-1	Reply	20709
<sep> <sep> ** Concern 2 about unsurprising results **	O	O	Reply	20709
We do think that some of these results are surprising.	O	O	Reply	20709
For example:	O	O	Reply	20709
- The harder tasks we consider use only 20% of the training data, amounting to only one or two thousand images.	B-Reply	B-2	Reply	20709
It is surprising that SSL is effective with such small-sized datasets since the conventional wisdom is that SSL requires orders of magnitude more data to be effective.	I-Reply	I-2	Reply	20709
<sep> - Despite numerous advances, SSL still dramatically lags behind supervised learning.	B-Reply	B-2	Reply	20709
Ours is one of the first results showing that SSL provides improvements on top of supervised learning in the few-shot setting.	I-Reply	I-2	Reply	20709
<sep> - The results in Figure 4a and 4b are perhaps less surprising, but we are not aware of any work that systematically conducted these experiments.	B-Reply	B-2	Reply	20709
For example, more data but from a different domain makes SSL less effective, even worse than no SSL.	I-Reply	I-2	Reply	20709
Thus simply relying on the few within-domain images is the best strategy for novel domains.	I-Reply	I-2	Reply	20709
This result is of practical significance for learning in domains where even unlabeled data is hard to obtain.	I-Reply	I-2	Reply	20709
<sep> <sep> Figure 4d is indeed confusing.	B-Reply	B-3	Reply	20709
The difficulty stems from how to measure the domain distance, which is an open research problem.	I-Reply	I-3	Reply	20709
The main result still holds, i.e., domain shift makes the SSL less effective (as also seen in Figure 4b), but the right way to measure a domain distance that is predictive of transfer is an open question.	I-Reply	I-3	Reply	20709
We will remove the trend lines in the figures.	I-Reply	I-3	Reply	20709
Also see the response to R2.	I-Reply	I-3	Reply	20709

Summary:	O	O	Review	20709
There are three main contributions of the paper:	O	O	Review	20709
i) The authors present an empirical study of different self-supervised learning (SSL) methods in the context of self-supervised learning.	O	O	Review	20709
<sep> ii) They point out how SSL helps more when the dataset is harder.	O	O	Review	20709
<sep> iii) They point out how domain matters while using SSL for training and present a method to choose samples from an unlabeled dataset.	O	O	Review	20709
<sep> <sep> Strengths:	O	O	Review	20709
1) They confirm the results of [7] and provide additional evidence of the benefit of the self-supervised learning in the few-shot setting.	O	O	Review	20709
They also showcase an interesting new result that self-supervised learning helps more in case of harder problems.	O	O	Review	20709
<sep> 2) The authors have a done a commendable job of coming up with a meaningful set of experiments by varying base-models, self-supervised methods, datasets, and few-shot learning methods in Section 4.1.	O	O	Review	20709
This is quite a comprehensive study.	O	O	Review	20709
<sep> 3)  The paper is well-written and well-motivated.	O	O	Review	20709
<sep> <sep> Weaknesses:	O	O	Review	20709
1) The main weakness of the paper is Section 4.2's experimental setup.	O	O	Review	20709
<sep> <sep> i) The definition of domain distance in not quite meaningful.	B-Review	B-1	Review	20709
Since the chosen datasets have very different classes (airplanes vs dogs etc), the average embeddings for different datasets/classes will be far from each other.	I-Review	I-1	Review	20709
In Figure 4d, it is misleading to show a trendline that includes the same domain as that will always be 0.	I-Review	I-1	Review	20709
If that datapoint is removed the trend line is mostly flat.	I-Review	I-1	Review	20709
The authors want to present a quantifiable way to show how domain distribution affect performance on self-supervised learning methods.	I-Review	I-1	Review	20709
But this definition of domain distance is more meaningful in the domain adaptation setting (like Amazon-Office dataset used for domain adaptation (<a href="https://people.eecs.berkeley.edu/~jhoffman/domainadapt/))" target="_blank" rel="nofollow">https://people.eecs.berkeley.edu/~jhoffman/domainadapt/))</a> as in that case the requirement is to get the embeddings close to each other for the same class but from different domains.	I-Review	I-1	Review	20709
<sep> <sep> ii) The authors go on to create an "unlabeled pool" by combining images from many domains.	B-Review	B-2	Review	20709
Then they train a domain classifier by labeling in-domain images as positive and  labeling the images in pool as negative.	I-Review	I-2	Review	20709
Considering all images in the pool as negative is not correct as there can be images of same class in unlabeled pool.	I-Review	I-2	Review	20709
<sep> <sep> iii) Then they choose the samples which the classifier predicts comes from the same domain.	B-Review	B-3	Review	20709
This probably succeeds as it is done on top of ResNet-101 features (that has seen all of ImageNet).	I-Review	I-3	Review	20709
This technique probably works possibly due to the ResNet being pre-trained with so many labeled classes.	I-Review	I-3	Review	20709
One baseline might have just been to choose the k-nearest neighbors (from unlabled pool)  to the average embedding of all the images of the chosen dataset.	I-Review	I-3	Review	20709
Since, it is quite easy for classifiers to detect from which dataset an image came from [6] it might be easy to choose an image from similar domain by using nearest neighbor in the embedding space.	I-Review	I-3	Review	20709
<sep> <sep> I am not sure how well their heuristic will work for an unlabeled pool that the classifier has never seen.	B-Review	B-1	Review	20709
Additionally, a portion of the dataset has been created by combining existing datasets.	I-Review	I-1	Review	20709
Since statistics of different datasets vary a lot artificially, the creation of an unlabeled pool by combining different datasets might work in the favor of the proposed heuristic of looking at "domain distance" to choose the samples.	I-Review	I-1	Review	20709
<sep> <sep> 2) Effect of domain shift in SSL (Figure 4b) is studying an extreme case where the domain shift results in almost no common classes in the SSL training phase.	B-Review	B-4	Review	20709
It would make more sense to include datasets where at least some of the classes are shared so that self-supervised learning methods get to see some relevant classes.	I-Review	I-4	Review	20709
In practice, a self-supervised learning method would be applied on a large unlabeled pool of images.	I-Review	I-4	Review	20709
Hopefully with increasing diversity and number of images, there might be some images on which ding SSL helps the downstream few-shot task.	I-Review	I-4	Review	20709
Hence comparison with such a dataset like ImageNet/iNatrualist is important here.	I-Review	I-4	Review	20709
<sep> <sep> Decision:	O	O	Review	20709
The paper presents an well thought-out empirical study on self-supervised learning for few-shot learning.	B-Review	B-4	Review	20709
But there are  major concerns with the empirical setup and methods presented in the section where they propose a method to choose samples for SSL from an unlabeled pool of images.	I-Review	I-4	Review	20709
<sep> <sep> <sep> Minor Comments:	B-Review	B-5	Review	20709
1)  ‚ÄúIn contrast, we humans can quickly learn new concepts from limited training data‚Äù - Remove we.	I-Review	I-5	Review	20709
<sep> 2) ‚ÄúDespite recent advances, these techniques have only been applied to a few domains (e.g., entry-level classes on internet imagery), and under the assumption that large amounts of unlabeled images are available.	I-Review	I-5	Review	20709
‚Äù This is not true.	I-Review	I-5	Review	20709
Self-supervised learning methods have been used for continuous control in reinforcement learning[1, 2], cross-modal learning[3], navigation [5], action recognition[4] etc.	I-Review	I-5	Review	20709
Later on in related work the authors list many papers that use self-supervised learning in different contexts.	I-Review	I-5	Review	20709
This line should be modified to reflect how common self-supervised learning methods are in other fields as well and with less data.	I-Review	I-5	Review	20709
<sep> 3) ‚Äúmaking the rotation task too hard or too trivial to benefit main task‚Äù - add respectively.	I-Review	I-5	Review	20709
<sep> 4) "With random sampling, the extra unlabeled data often hurts the performance, while those sampled using the ‚Äúdomain weighs‚Äù improves performance on most datasets."	I-Review	I-5	Review	20709
replace weighs with weights	I-Review	I-5	Review	20709
5) [8] points out how self-supervised learning on a large dataset but with a domain shift (YFCC100M) is not as effective for pre-training as it is doing self-supervised learning on the downstream task's dataset (ImageNet).	I-Review	I-5	Review	20709
While it is a different setting it is inline with one of the main conclusions of the paper.	I-Review	I-5	Review	20709
<sep> <sep> References:	O	O	Review	20709
[1] ‚ÄúPVEs: Position-Velocity Encoders for Unsupervised Learning of Structured State Representations‚Äù Rico Jonschkowski, Roland Hafner, Jonathan Scholz, and Martin Riedmiller.	O	O	Review	20709
<sep> [2] ‚ÄúLearning Actionable Representations from Visual Observations‚Äù Debidatta Dwibedi, Jonathan Tompson, Corey Lynch, Pierre Sermanet	O	O	Review	20709
[3] ‚ÄúLook, Listen and Learn‚Äù Relja Arandjeloviƒá, Andrew Zisserman	O	O	Review	20709
[4] ‚ÄúSelf-supervised Spatiotemporal Learning via Video Clip Order Prediction‚Äù Dejing Xu, Jun Xiao, Zhou Zhao, Jian Shao, Di Xie, Yueting Zhuang.	O	O	Review	20709
<sep> [5] ‚ÄúScaling and Benchmarking Self-Supervised Visual Representation Learning‚Äù Priya Goyal, Dhruv Mahajan, Abhinav Gupta, Ishan Misra	O	O	Review	20709
[6] "Unbiased Look at Dataset Bias" Antonio Torralba and Alexei A. Efros.	O	O	Review	20709
<sep> [7] "Boosting ¬¥few-shot visual learning with self-supervision."	O	O	Review	20709
Spyros Gidaris, Andrei Bursuc, Nikos Komodakis, Patrick Perez, and Matthieu Cord.	O	O	Review	20709
<sep> [8] "Deep clustering for unsupervised learning of visual features" Mathilde Caron, Piotr Bojanowski, Armand Joulin, and Matthijs Douze	O	O	Review	20709
<sep> We thank R2 for noting the strengths of the paper.	O	O	Reply	20709
We wish to clarify some of the issues related to the experiments.	O	O	Reply	20709
<sep> <sep> ** Concern 1-1 the definition of domain distance is not quite meaningful **	O	O	Reply	20709
The trend lines in 4d are indeed not meaningful.	B-Reply	B-1	Reply	20709
We will update this figure.	I-Reply	I-1	Reply	20709
The main issues are the domains are indeed very different and measuring domain distance across different tasks and domains is an open research problem.	I-Reply	I-1	Reply	20709
Figure 4b, where we systematically replace part of the domain from the other datasets allows us to continuously vary the domain distance and the trend lines are more clear.	I-Reply	I-1	Reply	20709
<sep> <sep> ** Concern 1-2 considering all images in the pool as negative is not correct as there can be images of the same class in unlabeled pool **	O	O	Reply	20709
We create the pool in a leave-one-out manner, i.e. images from the target dataset are excluded.	B-Reply	B-2	Reply	20709
Note that the goal of the domain classifier is to simply find images (or compute their importance weights) from the pool that are similar to the source domain, and approaches based on image similarity are also likely to work.	I-Reply	I-2	Reply	20709
<sep> <sep> ** Concern 1-3 about using ResNet-101 features for training the domain weighted model **	O	O	Reply	20709
We are not sure what the reviewer is concerned about and would appreciate a clarification.	B-Reply	B-3	Reply	20709
<sep> <sep> Your intuition is right, in that the goal of the domain classifier is to simply predict which images are likely to come from a dataset.	I-Reply	I-3	Reply	20709
This might be possible to predict even with hand-crafted image features.	I-Reply	I-3	Reply	20709
We note that although we use a ResNet model trained on ImageNet to estimate the domain distance, most of the datasets used in our experiments do not contain images from ImageNet.	I-Reply	I-3	Reply	20709
Even the classes are quite disjoint from ImageNet classes.	I-Reply	I-3	Reply	20709
<sep> <sep> ** Concern 2 include datasets where at least some of the classes are shared for Figure 4b **	O	O	Reply	20709
Figure 4c conducts this experiment exactly where we create a much larger pool of image by including the iNaturalist and ImageNet datasets.	B-Reply	B-4	Reply	20709
Selecting the right images from this larger pool benefits the Birds and Dogs since the pool has images closer to this domain.	I-Reply	I-4	Reply	20709
Also note that figure 4b simulates a scenario where the pool contains a mixture of within and out of domain images of different proportions.	I-Reply	I-4	Reply	20709

A new auto-encoder method is proposed.	O	O	Review	84
Features are learned by minimizing the sum of the square reconstruction error and a penalty on feature dissimilarity weighted according to a variety of criteria.	O	O	Review	84
The basic idea is to weight more strongly the features that are in the neighborhood of the training sample or based on the class labels.	O	O	Review	84
<sep> A multi-layer version of the autoencoder is proposed by following the layer-wise training protocol.	O	O	Review	84
<sep> The method is tested using several metric on a few small datasets.	O	O	Review	84
<sep> <sep> Strengths	O	O	Review	84
The problem is relevant and interesting.	O	O	Review	84
<sep> The method is technically sound.	O	O	Review	84
<sep> <sep> Weaknesses	O	O	Review	84
The paper lacks clarity.	B-Review	B-4	Review	84
It does not read well and the language is often vague (what does it mean ‚Äúrepresent well‚Äù or ‚Äúpositive impact‚Äù or ‚Äúhurt numerical optimization‚Äù?).	I-Review	I-4	Review	84
<sep> The paper is also rather incremental.	B-Review	B-3	Review	84
The idea is similar to [6] but also related to methods for dimensionality reduction like deep parametric t-sne (see R. Min, L.J.P. van der Maaten, Z. Yuan, A. Bonner, and Z. Zhang.	I-Review	I-3	Review	84
Deep Supervised t-Distributed Embedding.	I-Review	I-3	Review	84
In Proceedings of the International Conference on Machine Learning (ICML), pages 791-798, 2010 ) and methods like H. Mobahi, R. Collobert, J. Weston.	O	O	Review	84
Deep Learning from Temporal Coherence in Video.	O	O	Review	84
ICML 2009.	O	O	Review	84
<sep> In this light, it would be valuable to add a discussion of the advantages of this method versus [6], for instance.	B-Review	B-1	Review	84
The major difference is that the reconstruction error replaces the ‚Äúpull apart‚Äù term in the loss function.	I-Review	I-1	Review	84
What‚Äôs the advantage of having an explicit decoder?	I-Review	I-1	Review	84
Doesn‚Äôt it introduce even more parameters in the model?	I-Review	I-1	Review	84
<sep> Finally, the empirical validation could be more convincing if the authors used larger datasets where many other authors already benchmarked (e.g., cifar, mnist, timit, svhn, to mention a few).	B-Review	B-2	Review	84
Thanks for the comments.	O	O	Reply	84
We have some responses below, and uploaded a new version of paper to clarify some problems.	O	O	Reply	84
In our new version, we mainly revised Section 1 and Section 2, and we add some experiments at Section 4.1.	O	O	Reply	84
The experiments we add may give some insights about the comparison to [6] and the meaning of the reconstruction error.	O	O	Reply	84
<sep> -------------------------------------------	O	O	Reply	84
‚Äú‚Ä¶related to methods for dimensionality reduction like deep parametric t-sne‚Ä¶. Deep Supervised t-Distributed Embedding‚Äù	O	O	Reply	84
For the similar works ‚ÄòDeep Learning from Temporal Coherence in Video‚Äô and ‚ÄòDeep Supervised t-Distributed Embedding‚Äô mentioned.	B-Reply	B-3	Reply	84
The inspiration of pairwise constraint is different.	I-Reply	I-3	Reply	84
The pairwise constraints in these papers are derived from supervised or human knowledge information while ours, derived from a manifold property, which is more slight and available in an unsupervised work.	I-Reply	I-3	Reply	84
<sep> -------------------------------------------	O	O	Reply	84
‚ÄúIn this light, it would be valuable to add a discussion of the advantages of this method versus [6], for instance.	O	O	Reply	84
The major difference is that the reconstruction error replaces the ‚Äúpull apart‚Äù term in the loss function.	O	O	Reply	84
What‚Äôs the advantage of having an explicit decoder?	O	O	Reply	84
Doesn‚Äôt it introduce even more parameters in the model?‚Äù	O	O	Reply	84
Compared with [6], the convolutional neural network may be a reason, making it can be trained with a single graph loss function.	B-Reply	B-1	Reply	84
In our case of fully connected neural network, we can‚Äôt minimize the graph regularizer directly, we need layer-wise pre-training.	I-Reply	I-1	Reply	84
Furthermore, in our experiment, pre-training with only graph regularization cannot work.	I-Reply	I-1	Reply	84
It may give some insights on the reconstruction error term.	I-Reply	I-1	Reply	84
<sep> Besides, in supervised learning, one can fine-tune the deep architecture with supervised weight matrix since they have training labels.	I-Reply	I-1	Reply	84
However, in unsupervised learning, samples with different labels may be connected in unsupervised weight matrix.	I-Reply	I-1	Reply	84
If we fine-tune the deep architecture with unsupervised graph regularization, clustering result might be worse since the wrong information would be fitted better.	I-Reply	I-1	Reply	84
So we only use pre-training since the reconstruction error and the graph regularization can interact on each other, and we can find the balance through grid based search so that the local invariants are kept and the effect of wrong information is small.	I-Reply	I-1	Reply	84
<sep> -------------------------------------------	O	O	Reply	84
‚ÄúFinally, the empirical validation could be more convincing if the authors used larger datasets‚Äù	O	O	Reply	84
The datasets we choose are more frequently used for clustering, which is an evaluation method of dimension reduction techniques.	B-Reply	B-2	Reply	84
We would like to take experiments on large dataset for supervised learning in future work.	I-Reply	I-2	Reply	84

Summary of contributions:	O	O	Review	84
<tab>Proposes to regularize auto encoders so that the encoded dataset has a similar nearest neighbor graph structure to the raw pixels.	O	O	Review	84
This method is advocated specifically for images.	O	O	Review	84
<sep> <sep> Novelty: moderate (note: the authors seem to believe they are introducing the use of multi-layer auto encoders on images, but they are not)	O	O	Review	84
Quality of results: low - moderate	O	O	Review	84
Quality of presentation: low	O	O	Review	84
<sep> Pros:	O	O	Review	84
<tab>Demonstrates improvements in clustering and semi-supervised learning performance	O	O	Review	84
Cons:	O	O	Review	84
<tab>Presentation is confusing and in many cases factually incorrect	B-Review	B-1	Review	84
<tab>Presentation lacks motivation and reasoning about why the method should work	B-Review	B-19	Review	84
<tab>Quantitative results are on small and obscure datasets, and improvements are relative to baselines of unclear value	B-Review	B-14	Review	84
<sep> Detailed comments:	O	O	Review	84
<sep> Abstract:	O	O	Review	84
<tab>The abstract is ramble and not very focused.	B-Review	B-1	Review	84
This is a conference on representation learning, we don't need you to explain representation learning and deep nets in the abstract.	I-Review	I-1	Review	84
Focus on how you've changed the auto encoder.	I-Review	I-1	Review	84
<sep> <tab>	O	O	Review	84
<tab>'we introduce the multiple- layer auto-encoder into image representation': definitely not true, you even cite papers from 5 years ago that use multi-layer auto encoders on images.	B-Review	B-2	Review	84
<sep> <sep> <tab>The abstract should say something about what your new method actually is / does and why you think it is a good idea.	O	O	Review	84
I can't tell from the abstract what your method is except that you've changed auto-encoders in some way.	O	O	Review	84
<sep> <sep> <tab>'Extensive experiments on image clustering show encouraging results of the proposed algorithm in comparison to the state-of-the-art algorithms on real-word cases.'	B-Review	B-3	Review	84
<sep> <tab>Be up-front about what your results are.	I-Review	I-3	Review	84
What does encouraging mean?	I-Review	I-3	Review	84
<sep> <sep> Introduction	O	O	Review	84
<tab>Par 1	B-Review	B-4	Review	84
<tab>f(H)?	I-Review	I-4	Review	84
H hasn't been introduced yet.	I-Review	I-4	Review	84
Do you mean f(X)?	I-Review	I-4	Review	84
<sep> <tab>What do you mean by well approximate X?	I-Review	I-4	Review	84
If H is meant to be similar to X, what's the point of switching to it?	I-Review	I-4	Review	84
Do you mean it should preserve info about X?	I-Review	I-4	Review	84
<sep> <sep> <tab>Par 2	O	O	Review	84
<tab>You cite a purely supervised method (Krivhevsky et al's ImageNet classifier) and then say 'Those methods normally need to use the auto-encoders to pre-train‚Ä¶' Not true.	B-Review	B-5	Review	84
<sep> <tab>'It has been generally accepted as the consensus that the pre-trained network does provide a better representation for the original data.'	O	O	Review	84
Definitely not true!	O	O	Review	84
See for example Charle's Cadieu's work presented at ICLR last year.	O	O	Review	84
<sep> <sep> <tab>Par 3	O	O	Review	84
<tab>Typo: Locally Linear Embedding is LLE, not LEE	B-Review	B-6	Review	84
<tab>	O	O	Review	84
<tab>Par 4	O	O	Review	84
<tab>What does 'weighted connected' mean?	B-Review	B-7	Review	84
<sep> <tab>The wording of this paragraph is not especially clear, but I take it to mean you want f(x_1) to be near f(x_2) if x_2 is a nearest neighbor of x_1.	I-Review	I-7	Review	84
Why do you think this is a desirable property?	I-Review	I-7	Review	84
It's well known that Euclidean distances in images are not very meaningful.	I-Review	I-7	Review	84
That's the whole reason we want to use representation learning on them.	I-Review	I-7	Review	84
<sep> <sep> Section 3 Graph Regularized Auto-Encoder	B-Review	B-8	Review	84
<tab>Par 1	I-Review	I-8	Review	84
<tab>This paragraph seems incredibly dismissive of the body of work that develops our understanding of auto encoders as learning manifolds, and how these manifolds relate to classification problems.	I-Review	I-8	Review	84
I would say previous work such as the manifold tangent classifier definitely explores ideas related to the 'geometrical and discriminating structure of the data'	I-Review	I-8	Review	84
<sep> <tab>Par 2	O	O	Review	84
<tab>This paragraph consists of nothing but the letter 'f'	B-Review	B-9	Review	84
<sep> Section 3.1	O	O	Review	84
<sep> <tab>Equations 4 and 5: 'sigmoid' should not be in all caps, that makes it looks like the product between variables s, i, g, etc.	B-Review	B-10	Review	84
(This comment applies throughout the paper, not just these equations)	I-Review	I-10	Review	84
<tab>	O	O	Review	84
<tab>Equation 7: when you say V is 'the weight matrix' do you mean it is a weighted adjacency matrix describing which examples should be near each other?	B-Review	B-11	Review	84
Usually in auto encoder literature people use 'the weight matrix' to refer to W_H or W_Q. If V is indeed this adjacency matrix you should describe how it is computed and what the weights mean.	I-Review	I-11	Review	84
Even just putting in a forward reference to section 3.3 can help the reader be less confused.	I-Review	I-11	Review	84
<sep> <sep> Section 3.2	O	O	Review	84
<sep> <tab>You really do not need to spend so much space describing the extremely well-known concept of greedy layer wise pre training	B-Review	B-12	Review	84
<sep> Section 3.3	O	O	Review	84
<tab>OK, so V is the graph encoding matrix.	O	O	Review	84
<sep> <sep> <tab>3.3.1: Could you please explain the motivation for each of these?	B-Review	B-19	Review	84
i.e., what effect you are hoping their use will have on the learning algorithm?	I-Review	I-19	Review	84
<sep> <sep> Section 4	O	O	Review	84
<tab>What is ORL?	B-Review	B-13	Review	84
You should cite the publication that introduced it.	I-Review	I-13	Review	84
Is this ORL?	I-Review	I-13	Review	84
<a href="http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html" target="_blank" rel="nofollow">http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html</a> It looks like the name has changed.	I-Review	I-13	Review	84
<sep> <sep> <tab>You might want to get the datasets you work on added here: <a href="http://rodrigob.github.io/are_we_there_yet/build/" target="_blank" rel="nofollow">http://rodrigob.github.io/are_we_there_yet/build/</a>	O	O	Review	84
<tab>This will make it easier for reviewers to understand your work in context.	O	O	Review	84
<sep> <sep> <tab>In general I do not find these experiments very compelling because they are mostly done on small and obscure datasets.	B-Review	B-14	Review	84
It's also not clear to me which of the baselines you ran yourself and which if any are taken from the literature.	I-Review	I-14	Review	84
Baselines that you ran yourself are less compelling because you may not have the same familiarity with pre-existing methods as the inventors of those methods, and you certainly have less incentive to make them perform well.	I-Review	I-14	Review	84
<sep> <sep> <tab>At a minimum, I'd like to see some more explanation of why the baselines you're improving upon are impressive.	B-Review	B-15	Review	84
What would be better is to demonstrate good results on datasets that are used more frequently by people in the deep learning community.	I-Review	I-15	Review	84
You are introducing a new kind of auto encoder so you should compare it to pre-existing auto encoders on datasets where auto encoders are frequently used, such as MNIST or Cover Type.	I-Review	I-15	Review	84
<sep> <sep> Section 4.1	O	O	Review	84
<tab>I notice you specify the hyper parameters for GAE and GNMF are optimized by grid search, but you have no mention of this for the SAE.	B-Review	B-16	Review	84
Did you also optimize the SAE hyper parameters by grid search?	I-Review	I-16	Review	84
<sep> <sep> <tab>You say that the GAE has 2 coefficients to be set by grid search, k and lambda, but it seems like there must be a whole lot of other values to set, such as the dimensionality of H. What did you do about these?	B-Review	B-17	Review	84
<sep> <sep> Section 4.2	O	O	Review	84
<tab>Footnote 3: why is a single sample per class 'meaningless'?	B-Review	B-18	Review	84
I agree it's really hard to do well in this case, but why is 1 sample totally worthless and 2 acceptable?	I-Review	I-18	Review	84
If you've added more labels, isn't your work no longer comparable to previous work on the same data set?	I-Review	I-18	Review	84
Thanks for the comments.	O	O	Reply	84
We have some responses below, and uploaded a new version of paper to clarify some problems.	O	O	Reply	84
In our new version, we mainly revised Section 1 and Section 2, and we add some experiments at Section 4.1.	O	O	Reply	84
<sep> -------------------------------------------	O	O	Reply	84
Abstract:	O	O	Reply	84
‚ÄúThe abstract is ramble and not very focused. ‚	O	O	Reply	84
Ä¶‚Äù	O	O	Reply	84
We have revised our abstract.	B-Reply	B-1	Reply	84
<sep> -------------------------------------------	O	O	Reply	84
‚Äú‚Äòwe introduce the multiple- layer auto-encoder into image representation‚Äô: definitely not true‚Äù	O	O	Reply	84
We have deleted this claim in our new version, we want to express that we introduce the combination of graph regularizer and deep architecture for image representation.	B-Reply	B-2	Reply	84
<sep> -------------------------------------------	O	O	Reply	84
‚ÄúWhat does encouraging mean?‚Äù	O	O	Reply	84
Compare to sparse regularization auto-encoder and GNMF, GAE implements the similar or better clustering results.	B-Reply	B-3	Reply	84
We try to combine the expressive power of deep architecture and the idea of local Euclidean preservation to implement a non-linear dimension reduction algorithm, or at least an option to the existing deep techniques on unsupervised or semi-supervised tasks.	I-Reply	I-3	Reply	84
<sep> -------------------------------------------	O	O	Reply	84
Introduction	O	O	Reply	84
Par 1	O	O	Reply	84
‚Äúf(H)?	O	O	Reply	84
H hasn't been introduced yet.	O	O	Reply	84
Do you mean f(X)?	O	O	Reply	84
What do you mean by well approximate X?‚Äù	O	O	Reply	84
It means f(X), and we mean H should preserve information about X. We have revised in our new version.	B-Reply	B-6	Reply	84
<sep> -------------------------------------------	O	O	Reply	84
Par 2	O	O	Reply	84
‚ÄúYou cite a purely supervised method‚Ä¶‚Äù	O	O	Reply	84
We have removed this claim in our new version.	B-Reply	B-8	Reply	84
<sep> -------------------------------------------	O	O	Reply	84
Par 3	O	O	Reply	84
‚ÄúTypo: Locally Linear Embedding is LLE, not LEE‚Äù	O	O	Reply	84
We have revised in our new version.	O	O	Reply	84
<sep> -------------------------------------------	O	O	Reply	84
Par 4	O	O	Reply	84
‚ÄúWhat does ‚Äòweighted connected‚Äô mean?	O	O	Reply	84
The wording of this paragraph is not especially clear‚Ä¶‚Äù	O	O	Reply	84
This paragraph has been removed in our new version.	B-Reply	B-7	Reply	84
<sep> -------------------------------------------	O	O	Reply	84
We rewrite the Par2 and Par4 at the perspective of dimension reduction, and clarify the motivation of our method.	B-Reply	B-19	Reply	84
And Par3 has been moved to section 2 as related works.	I-Reply	I-19	Reply	84
<sep> -------------------------------------------	O	O	Reply	84
Section 3 Graph Regularized Auto-Encoder	O	O	Reply	84
Par 1	O	O	Reply	84
‚ÄúThis paragraph seems incredibly dismissive of the body of work that develops our understanding of auto encoders as learning manifolds, and how these manifolds relate to classification problems.	O	O	Reply	84
I would say previous work such as the manifold tangent classifier definitely explores ideas related to the ‚Äògeometrical and discriminating structure of the data‚Äô‚Äù	O	O	Reply	84
We have removed this claim in our new version.	O	O	Reply	84
<sep> -------------------------------------------	O	O	Reply	84
Par 2	O	O	Reply	84
‚ÄúThis paragraph consists of nothing but the letter 'f'‚Äù	O	O	Reply	84
The letter has been removed in our new version.	B-Reply	B-9	Reply	84
<sep> -------------------------------------------	O	O	Reply	84
Section 3.1	O	O	Reply	84
‚ÄúEquations 4 and 5: 'sigmoid' should not be in all caps‚Ä¶‚Äù	O	O	Reply	84
We have revised all ‚Äòsigmoid‚Äô we used throughout the paper as ‚ÄòS(x)‚Äô.	B-Reply	B-10	Reply	84
<sep> -------------------------------------------	O	O	Reply	84
‚ÄúEquation 7: when you say V is 'the weight matrix' do you mean‚Ä¶‚Äù	O	O	Reply	84
We have put in a forward reference to section 3.3 in our new version.	B-Reply	B-11	Reply	84
<sep> -------------------------------------------	O	O	Reply	84
Section 3.2	O	O	Reply	84
‚ÄúYou really do not need to spend so much space describing‚Ä¶‚Äù	O	O	Reply	84
We want to make the definition clear and show that graph regularizer is applied to the training process at each layer.	B-Reply	B-12	Reply	84
<sep> -------------------------------------------	O	O	Reply	84
Section 4	O	O	Reply	84
‚ÄúWhat is ORL?	O	O	Reply	84
You should cite‚Ä¶‚Äù	O	O	Reply	84
We have cited the publication in the new version.	B-Reply	B-13	Reply	84
<sep> -------------------------------------------	O	O	Reply	84
‚ÄúIn general I do not find these experiments very compelling because they are mostly done on small and obscure datasets.	O	O	Reply	84
It's also not clear to me which of the baselines you ran yourself and which if any are taken from the literature.	O	O	Reply	84
Baselines that you ran yourself are less compelling because you may not have the same familiarity with pre-existing methods as the inventors of those methods, and you certainly have less incentive to make them perform well.	O	O	Reply	84
‚Äù	O	O	Reply	84
The datasets we choose are more frequently used for clustering, which is an evaluation method of dimension reduction techniques.	B-Reply	B-14	Reply	84
We would like to take experiments on large dataset for supervised learning in future work.	I-Reply	I-14	Reply	84
<sep> For the baselines, we download the code of GNMF from the author‚Äôs website, and the CNMF is implemented by ourselves which achieves similar performance as the results on their papers.	I-Reply	I-14	Reply	84
<sep> -------------------------------------------	O	O	Reply	84
‚ÄúAt a minimum, I'd like to see some more explanation of why the baselines you're improving upon are impressive.	O	O	Reply	84
What would be better is to demonstrate good results on datasets that are used more frequently by people in the deep learning community.	O	O	Reply	84
You are introducing a new kind of auto encoder so you should compare it to pre-existing auto encoders on datasets where auto encoders are frequently used, such as MNIST or Cover Type.	O	O	Reply	84
‚Äù	O	O	Reply	84
We compare our method to sparse auto-encoder, the result tells that the graph regularization can capture the manifold of the input data.	B-Reply	B-15	Reply	84
We think the similar or better results compared to SAE show the effectiveness of graph regularization as we wanted.	I-Reply	I-15	Reply	84
Besides, the comparison to GNMF and CNMF proves that expressive power is important when we want to capture the manifold structure of data set.	I-Reply	I-15	Reply	84
We choose deep network to achieve better performance beyond the existing many interesting linear functions with its nonlinearity.	I-Reply	I-15	Reply	84
Finally, at the perspective of dimensional reduction, clustering is often used for evaluation, so we take experiments on clustering to evaluate our method (like Deng.	I-Reply	I-15	Reply	84
Cai et al‚Äôs Graph regularized nonnegative matrix factorization for data representation ).	I-Reply	I-15	Reply	84
<sep> -------------------------------------------	O	O	Reply	84
Section 4.1	O	O	Reply	84
‚ÄúDid you also optimize the SAE hyper parameters by grid search?‚Äù	O	O	Reply	84
Yes, we have specified this point in our new version.	B-Reply	B-16	Reply	84
<sep> -------------------------------------------	O	O	Reply	84
‚ÄúYou say that the GAE has 2 coefficients to be set by grid search, k and lambda, but it seems like there must be a whole lot of other values to set, such as the dimensionality of H. What did you do about these?‚Äù	O	O	Reply	84
Like all the method we compare, the dimensionality of H is set to be the number of the classes in the input data set.	B-Reply	B-17	Reply	84
<sep> -------------------------------------------	O	O	Reply	84
Section 4.2	O	O	Reply	84
‚ÄúFootnote 3: why is a single sample per class ‚Äòmeaningless‚Äô?...	O	O	Reply	84
If you've added more labels, isn't your work no longer comparable to previous work on the same data set?‚Äù	O	O	Reply	84
The weight between two samples which have the same labels will be denote as 1, since single sample per class means there are no sample have the same labels to others.	B-Reply	B-18	Reply	84
So it‚Äôs meaningless.	I-Reply	I-18	Reply	84
We implement the experiment follow the work in CNMF.	I-Reply	I-18	Reply	84
They use 10% or 20% labeled samples in their experiment.	I-Reply	I-18	Reply	84
More labels won‚Äôt influence our performance.	I-Reply	I-18	Reply	84

In this paper, authors proposes an algorithm to use Dirichlet prior on the variational auto-encoder (VAE).	O	O	Review	1583
They used this prior as natural conjugate to likelihood distributtion of multinomial (categorical).	O	O	Review	1583
The paper proposes a way to use scalability power of VAE for data distributed by categorical distribution.	O	O	Review	1583
In order to apply reparametrization trick, authors have used iid Gamma random variable to construct draw from Dirichlet distribution and have used approximation with inverse gamma CDF,  it is discussed how this method has better performance than other approximations method for gamma distribution such as Weibull and logistic Gaussian.	O	O	Review	1583
Authors pointed out, one of the weak points in competing models such as  Guassian softmax prior or Griffith -Engen-McCloskey prior which has been used for Stick breaking VAE is to not encouraging of having multi-modal posteriori, while this prior empower having multi-modal posteriori distribution which give them advantage over previous papers.	O	O	Review	1583
In experimental results, paper has used different datasets of MNIST, MNIST+rotation , OMNIGLOT , 20newsgroup and RCVI and used different measures to compare the existing method with the baselines.	O	O	Review	1583
To summarize the contribution of this paper, following three points can be named as main contribution of this paper:	O	O	Review	1583
- proposed a Dirichlet prior, for categorical likelihood which encourages having multi-modal posteriori.	O	O	Review	1583
paper demonstrates couple of techniques  to apply the reparametrization trick on Dirichlet distribution, by using sum of iid Gamma random variables.	O	O	Review	1583
- used method of moments estimator to update the hyper parameter of the Dirichlet distribution which helps to have closer approximation of log likelihood.	O	O	Review	1583
They update hyper-parameters after every few updates of VAE parameters.	O	O	Review	1583
-discussed how to overcome  Stick-breaking VAE ‚Äúcomponent collapse‚Äù issue.	O	O	Review	1583
Experiments show superior results on supervised and semi supervised, and authors claimed the main reason of this superiority being due to not having disadvantage of component collapse which happens in SBVAE.	O	O	Review	1583
Quality and Novelty:	O	O	Review	1583
claims in paper are supported by proofs and/or experimental results and there does not exist significant technical issues with the details of claims made in this paper and proofs provided.	O	O	Review	1583
There are following issues with novelty and quality of paper that I would like discuss them under following three points:	O	O	Review	1583
- Authors need to be clear about the motivation of the paper, if the motivation of the paper is to encourage the multi-modality in posteriori distribution, using Gaussian prior and methods like normalizing flow Rezende, Danilo Jimenez, and Shakir Mohamed. "	O	O	Review	1583
Variational inference with normalizing flows.	O	O	Review	1583
"&nbsp;arXiv preprint arXiv:1505.05770&nbsp;(2015) or similar may be able to do the same work in which case paper should compare its results to those ideas which has not been done in this paper.	O	O	Review	1583
- second appealing point that this paper can make is to use Dirichlet prior for the purposes like community detection, topic modeling and LDA  etc etc.	O	O	Review	1583
In this case, I did not find significant difference between the proposed method and what is found in Srivastava, Akash, and Charles Sutton. "	O	O	Review	1583
Autoencoding variational inference for topic models.	O	O	Review	1583
"&nbsp;arXiv preprint arXiv:1703.01488&nbsp;(2017), but due to the encourages of multi-modality authors show in average DirVAE performs better in measures like perplexity and NPMI.	O	O	Review	1583
Under this condition, my main concern is interpretablity of posteriori.	O	O	Review	1583
That will be discussed under next point	O	O	Review	1583
- Main motivation behind using Dirichlet prior, is to have posteriori with a few significant related topic and many unrelated topic for every word.	O	O	Review	1583
By changing the concentration parameter in stick-breaking, it is possible that performance of stick-breaking method increase in perplexity and NPMI scores in cost of loosing interpretability of the model.	O	O	Review	1583
So having higher concentration parameter can show better performance in the cost of interpretablity that put second point of the paper at risk	O	O	Review	1583
Clarity:	O	O	Review	1583
The paper is well written and previous relevant methods have been reviewed well.	O	O	Review	1583
The organization of paper is good, experiments well explained and proofs and mathematical reasoning are clear.	O	O	Review	1583
Significance of experiments:	O	O	Review	1583
As discussed,in previous sections, the results show superior performance and compared to other methods on semi-supervised and supervised classification on different datasets.	O	O	Review	1583
Also it has shown in average better perplexity and NPMI score for topic modeling, the only issue can be these scores come as cost of interpretablity of the model.	O	O	Review	1583
Also it is possible that other competing models can be matching to this results if they do not aim for sparse posteriori.	O	O	Review	1583
For better representation, we modified all t-SNE figures in the paper.	O	O	Reply	1583
Sincerely.	O	O	Reply	1583

This paper proposes DirVAE, a variational autoencoder with Dirichlet prior on latent variables.	O	O	Review	1583
The advantage of using Dirichlet distribution is that due the nature of Dirichlet distribution the model does not suffer from decoder weight collapsing and latent value collapsing.	O	O	Review	1583
Stochastic gradient variational Bayes with inverse CDF reparametrization of gamma distribution is presented.	O	O	Review	1583
<sep> <sep> The motivation behind using Dirichlet instead of GEM makes sense, but other than that I fail to find any novelty in the paper.	B-Review	B-1	Review	1583
The authors should tone down the statement "to our knowledge, combining the two statistical results is the first finding in the machine learning field".	I-Review	I-1	Review	1583
Even though left unpublished, I've been using this combination of inverse CDF gamma reparametrization and transformation to Dirichlet all the time for my own problems.	I-Review	I-1	Review	1583
It's just trivial once we have both techniques.	I-Review	I-1	Review	1583
See also [2], where an improved way of reparametrizing gamma and Dirichlet distribution is presented.	I-Review	I-1	Review	1583
The observation that DirVAE does not suffer from latent value collapsing is interesting, but not really surprising.	I-Review	I-1	Review	1583
<sep> <sep> Minor question	O	O	Review	1583
- What is the difference between negative LL's and reconstruction losses in experiments?	B-Review	B-2	Review	1583
<sep> - The approximation for inverse CDF of gamma works well only when alpha < 1.	B-Review	B-3	Review	1583
How did you treat the regime alpha > 1?	I-Review	I-3	Review	1583
<sep> <sep> <sep> References	O	O	Review	1583
[1] Diederik P Kingma, Max Welling, Auto-encoding variational Bayes, ICLR, 2014.	O	O	Review	1583
<sep> [2] Michael Figurnov, Shakir Mohamed, Andriy Mnih, Implicit reparametrization gradients, arXiv, 2018.	O	O	Review	1583
Thank you for your review.	O	O	Reply	1583
<sep> <sep> Firstly, we would like to say thank you for introducing the paper [2]. Even though the paper [2] and our paper lie on the same path in terms of reparametrizing Gamma distribution, paper [2] deals with a general reparametrization trick on various probabilistic distributions while our paper focuses on the advantages and the applicabilities of Dirichlet prior in VAE.	B-Reply	B-1	Reply	1583
We believe that our contribution is not based on reparametrizing Gamma or Dirichlet distiribution, but introducing Dirichlet prior, which is a conjugate multi-modal prior of categorical distribution, on VAE which has better learned latent representation due to no component collapsing.	I-Reply	I-1	Reply	1583
To support this, we did extensive experiments including topic modeling experiments and experimentally showed that DirVAE with the Dirichlet prior does not have component collapsing for the first time in this field.	I-Reply	I-1	Reply	1583
This component collapsing was not experimented and discussed in the prior work of [2]. Moreover, our experiments on the topic modeling shows the consistent performance increases when we apply the DirVAE, which was not discusses in [2].	I-Reply	I-1	Reply	1583
<sep> The below is the response to your questions.	O	O	Reply	1583
<sep> The log likelihood (LL) is the log-probability that a learner optimizes to train a model given an observed dataset.	B-Reply	B-2	Reply	1583
However, since the likelihood or log-likelihood function is intractable given a latent variable in VAE, so we use the evidence lower bound (ELBO) to optimize the LL.	I-Reply	I-2	Reply	1583
ELBO is a tractable alternative of LL, so the optimization on ELBO is feasible.	I-Reply	I-2	Reply	1583
ELBO term consists of two parts: Reconstruction Error (or Reconstruction Loss, which you asked) and KL divergence terms.	I-Reply	I-2	Reply	1583
Here, Reconstruction Error measures the error between the input and the output, which is an auto-encoder reconstructed input.	I-Reply	I-2	Reply	1583
Additionally, for your information, equation (1) in our paper, can be re-written as follows: Negative Log-likelihood <= Negative ELBO = Reconstruction Loss + KL Divergence.	I-Reply	I-2	Reply	1583
<sep> <sep> The author of paper [3] on the inverse Gamma recommends a finite difference approximation method when alpha>1.	B-Reply	B-3	Reply	1583
We only encountered such alpha>1 cases when we updated alphas, and the topic modeling often sets the alpha to be in the range of [0,1]. In the cases of alpha>1, we approached this problem via approximating the inverse function of the Gamma CDF with a Newton method, but the learning performance was not satisfactory.	I-Reply	I-3	Reply	1583
Thus, we left the updated alpha parameters with values greater than one in the appendix.	I-Reply	I-3	Reply	1583
<sep> <sep> Sincerely.	O	O	Reply	1583
<sep> <sep> References	O	O	Reply	1583
[1] Diederik P Kingma, Max Welling, Auto-encoding variational Bayes, ICLR, 2014.	O	O	Reply	1583
<sep> [2] Michael Figurnov, Shakir Mohamed, Andriy Mnih, Implicit reparametrization gradients, arXiv, 2018.	O	O	Reply	1583
<sep> [3] David.	O	O	Reply	1583
A. Knowles.	O	O	Reply	1583
Stochastic gradient variational bayes for gamma approximating distributions.	O	O	Reply	1583
arXiv, 2015.	O	O	Reply	1583

Review:	O	O	Review	1583
<sep> This paper proposes to change the typical Gaussian posterior distribution (and prior) for the latent features z associated to an image x that is used in Variational Autoencoders by a Dirichlet distribution.	O	O	Review	1583
The work improves over previous attempts based on a soft-max + Gaussian distribution and the soft-max + Weibull distribution.	O	O	Review	1583
The trick proposed to make feasible training the model includes approximating the inverse CDF of the gamma distribution and using the fact that the Dirichlet distribution can also be obtained as a normalized sum of gamma random variables.	O	O	Review	1583
The method is compared in several problems.	O	O	Review	1583
Some analysis of the reasons why it performs better is also carried out.	O	O	Review	1583
<sep> <sep> Quality:	O	O	Review	1583
<sep> <tab>I think the quality of the paper is high.	O	O	Review	1583
It is a well written paper in which the choices made are well supported.	O	O	Review	1583
It also has a strong experimental section.	O	O	Review	1583
<sep> <sep> Clarity:	O	O	Review	1583
<sep> <tab>The paper is well written and reads very smoothly.	B-Review	B-1	Review	1583
I have missed however a more clear statement in the introduction supporting the use of the Dirichlet for the prior and posterior of the latent variables, simply because it seems to give better results and the typical Gaussian choice.	I-Review	I-1	Review	1583
<sep> <sep> Originality:	O	O	Review	1583
<tab>	O	O	Review	1583
<tab>The paper is based on ideas already known.	B-Review	B-2	Review	1583
E.g., Dirichlet a normalized sum of gamma random variables and approximation of the inverse CDF of the gamma random variable.	I-Review	I-2	Review	1583
The combination of these two techniques is however novel.	O	O	Review	1583
<sep> <sep> Significance:	O	O	Review	1583
<sep> <tab>The results obtained indicate that the proposed approach improves over previous work on the Dirichlet VAE and on the Gaussian VAE.	O	O	Review	1583
So I believe the significance of the paper is high.	O	O	Review	1583
<sep> <sep> pros:	O	O	Review	1583
<sep> <tab>- Good results.	O	O	Review	1583
<sep> <sep> <tab>- Simple method proposed.	O	O	Review	1583
<sep> <sep> <tab>- Extensive experiments.	O	O	Review	1583
<sep> <sep> <tab>- Well written paper.	O	O	Review	1583
<sep> <sep> cons:	O	O	Review	1583
<tab>	O	O	Review	1583
<tab>- The idea is a combination of already known techniques put in practice for the VAE.	B-Review	B-2	Review	1583
<sep> <sep> <tab>- A better motivation that the Dirichlet VAE gives good results should be given at the introduction.	B-Review	B-1	Review	1583
<sep> <sep> Thank you for your review.	O	O	Reply	1583
<sep> <sep> Firstly, as a motivation for the better result, we can state as the following, and if you are okay with the below sentences, we would like to add it to the introduction part.	B-Reply	B-1	Reply	1583
<sep> "Due to the component collapsing issues, the existing VAEs have less meaningful latent values or could not effectively use its latent representation.	I-Reply	I-1	Reply	1583
Meanwhile, DirVAE does not have component collapsing due to the multi-modal prior which possibly leads to superior qualitative and quantitative performances.	I-Reply	I-1	Reply	1583
We experimentally showed that the DirVAE has more meaningful or disentangled latent representation by image generation and latent value visualizations."	I-Reply	I-1	Reply	1583
<sep> <sep> Secondly, although the techniques are already known, we've rather wanted to focus our paper on the characteristic of Dirichlet prior on VAE such as better latent representation due to no component collapsing, or its applicability like topic modeling.	B-Reply	B-2	Reply	1583
<sep> <sep> Thanks again for your valuable comments.	O	O	Reply	1583
<sep> <sep> Sincerely.	O	O	Reply	1583

This simple paper shows that the normalization of softmax causes a loss of information compared to using the unnormalized logits when trying to do OOD and adversarial example detection.	O	O	Review	20548
The main reason for this is of course the normalization used by the softmax.	O	O	Review	20548
The paper is mostly empirical following this specific observation, and uses a number of examples on MNIST and CIFAR to show the improvement in performance by using unnormalized logits instead of softmax.	O	O	Review	20548
<sep> <sep> While interesting, it is to be noted that methods such as ODIN and temperature scaling specifically include a temperature to exactly overcome this same issue with softmax.	B-Review	B-1	Review	20548
The lack of comparison to such baselines makes this paper quite incomplete, especially as it is an empirical paper itself.	I-Review	I-1	Review	20548
Thank you for your comments and feedback.	B-Reply	B-1	Reply	20548
Indeed, temperature scaling does limit the effect of using the exponential function to amplify differences in logits.	I-Reply	I-1	Reply	20548
However, it does not change the impact of the normalization, as the information about the logit absolute values is still lost after temperature.	I-Reply	I-1	Reply	20548
But we agree that this method and ODIN are interesting comparison baselines and we will include them in the next version of the paper.	I-Reply	I-1	Reply	20548

Summary	O	O	Review	20548
<sep> This paper showed that out-of-distribution and adversarial samples can be detected effectively if we utilize logits (without softmax activations).	O	O	Review	20548
Based on this observation, the authors proposed 2-logit based detectors and showed that they outperform the detectors utilizing softmax activations using MNIST and CIFAR-10 datasets.	O	O	Review	20548
<sep> <sep> I‚Äôd like to recommend "reject" due to the following	O	O	Review	20548
<sep> The main observation (removing softmax activation can be useful for detecting abnormal samples) is a bit interesting (but not surprising) but there is no theoretical analysis for this.	B-Review	B-1	Review	20548
It would be better if the authors can provide the reason why softmax activation hinders the novelty detection.	I-Review	I-1	Review	20548
<sep> <sep> The logit-based detectors proposed in the paper are simple variants of existing methods.	B-Review	B-2	Review	20548
Because of that, it is hard to say that technical contributions are very significant.	I-Review	I-2	Review	20548
<sep> <sep> Questions	O	O	Review	20548
<sep> For evaluation, could the authors compare the performance with feature-based methods like Mahalanobis [1] and LID [2]?	B-Review	B-3	Review	20548
<sep> <sep> I would be appreciated if the author can evaluate their hypothesis using various datasets like CIFAR-100, SVHN, and ImageNet.	B-Review	B-4	Review	20548
<sep> <sep> [1] Lee, K., Lee, K., Lee, H. and Shin, J., 2018.	O	O	Review	20548
A simple unified framework for detecting out-of-distribution samples and adversarial attacks.	O	O	Review	20548
In Advances in Neural Information Processing Systems (pp.7167-7177).	O	O	Review	20548
<sep> <sep> [2] Ma, X., Li, B., Wang, Y., Erfani, S.M., Wijewickrema, S., Schoenebeck, G., Song, D., Houle, M.E. and Bailey, J., 2018.	O	O	Review	20548
Characterizing adversarial subspaces using local intrinsic dimensionality.	O	O	Review	20548
arXiv preprint arXiv:1801.02613.	O	O	Review	20548
Thank you for you comments and feedback.	O	O	Reply	20548
We agree that our work would benefit from using more datasets for evaluation and comparing with more methods.	B-Reply	B-4	Reply	20548
We will include these improvements in the next version of the paper.	O	O	Reply	20548

This paper suggests that the logits cary more information than the maximum softmax probability for OOD detection.	O	O	Review	20548
They suggest this with scatterplots and develop techniques to support this claim.	O	O	Review	20548
<sep> They use logits for as features for OOD detection with by using a kernel density estimator.	O	O	Review	20548
They also use a NN trained with logits features, but this assumes we can peak at the test distribution, so I ignore this entirely in this evaluation.	O	O	Review	20548
<sep> Unfortunately their KDE density estimator does not perform better than the maximum softmax probability for OOD detection on CIFAR-10 (74.3 vs 91.7).	O	O	Review	20548
<sep> They do not show results on CIFAR-100, but since the dimensionality of the logits would increase by an order of magnitude, one would expect kernel density estimation to perform much worse.	B-Review	B-1	Review	20548
The authors should include an evaluation on CIFAR-100 for completeness.	I-Review	I-1	Review	20548
<sep> <sep> Small comments:	O	O	Review	20548
<sep> Table 3 is a comment about featurization.	B-Review	B-2	Review	20548
Does this hold when taking the log of the softmax probabilities (not the same as logits)?	I-Review	I-2	Review	20548
If not, then this isn't much a count against the softmax per se.	I-Review	I-2	Review	20548
Even then, this is a comment on using softmax information for KDE, not using the maximum softmax probability itself for OOD detection.	I-Review	I-2	Review	20548
<sep> <sep> The full results for Table 2 are needed.	B-Review	B-3	Review	20548
Perhaps place this in an appendix.	I-Review	I-3	Review	20548
<sep> <sep> They repeat that the logits contain more information than the maximum softmax probability, but so does the raw input.	B-Review	B-4	Review	20548
The challenge is not introducing more noise/variance when introducing more information.	I-Review	I-4	Review	20548
<sep> <sep> I was confused at the experimental description.	B-Review	B-5	Review	20548
The information should be contained in one location.	I-Review	I-5	Review	20548
They train one of their CIFAR networks for 30 epochs, which isn't enough training time.	I-Review	I-5	Review	20548
Consequently, I suspect that those results are not worth drawing implications from since the accuracy is presumably low.	I-Review	I-5	Review	20548
<sep> <sep> Thank you for your comment and feedback.	B-Reply	B-1	Reply	20548
We respectfully disagree that the experiments with the NN-based detector should be ignored in your evaluation.	I-Reply	I-1	Reply	20548
As the goal of this paper is not to compare differences in performances between methods, but to compare differences in performances when using logit vs softmax values, we believe that the NN-based detector represents a best-case scenario where relevant features can be computed by the NN.	I-Reply	I-1	Reply	20548
We consider that it is interesting to observe that, even with an advantage as unfair as being able to peak at the test distribution, the softmax NN detector obtain overall worse results than the logits KDE detector on adversarial examples.	I-Reply	I-1	Reply	20548
Thus we argue that these experiments should be taken into account.	I-Reply	I-1	Reply	20548
<sep> <sep> We agree that it would be interesting to evaluate the KDE on datasets with more classes such as CIFAR-100.	B-Reply	B-2	Reply	20548
We will include this experiment in the next version of the paper.	I-Reply	I-2	Reply	20548

General:	O	O	Review	1685
The paper proposed an algorithm named Select Via Proxy(SVP), which can be used for data sampling.	O	O	Review	1685
The idea is simple and straightforward: 1) use a proxy model to get decision boundary 2) train the large target model on the data points close to the decision boundary.	O	O	Review	1685
<sep> <sep> Strength:	O	O	Review	1685
1.	O	O	Review	1685
Roughly this is a well-written paper.	O	O	Review	1685
The main idea is quite clear to me.	O	O	Review	1685
<sep> 2.	O	O	Review	1685
Empirical validation of the experiments looks good.	O	O	Review	1685
The results show that SVP help reduce the training time with ResNet.	O	O	Review	1685
The author(s) also showed the influence of different quantifying uncertainty methods.	O	O	Review	1685
<sep> <sep> Possible Improvements:	O	O	Review	1685
1.	O	O	Review	1685
In Related Work, several previous works were mentioned.	B-Review	B-1	Review	1685
Although the author(s) claimed that SVP can be combined with them, it's better to show the performance of SVP compared with them.	I-Review	I-1	Review	1685
This would show the significance of the work.	I-Review	I-1	Review	1685
<sep> 2.	O	O	Review	1685
In the experiments, I was hoping to see how well SVP works on ImageNet.	B-Review	B-2	Review	1685
The problem is that: For ResNet152 and ResNet164, they are relatively too deep on such small data sets.	I-Review	I-2	Review	1685
Since the dimension of the data points(images) is not high, SVP can easily catch a reasonable decision boundary with a smaller model.	I-Review	I-2	Review	1685
I am almost sure ResNet20 is good enough to do this.	I-Review	I-2	Review	1685
I am more concerned about the situation where the capacity of the model is challenged by the size of the dataset.	I-Review	I-2	Review	1685
e.g. The data sets of autonomous driving are usually extremely large and even very deep models cannot be fully trained on that.	I-Review	I-2	Review	1685
<sep> 3.	O	O	Review	1685
The data points close to the decision boundary can be considered as tough data points, whose features might be hard to be caught by the model.	B-Review	B-3	Review	1685
If training model only on these data points, the trained model may just memorize tough data points and not learn the other data points from the data set.	I-Review	I-3	Review	1685
One solution is that, while training on tough data points, the model should also be trained on a small portion of well-learned data points.	I-Review	I-3	Review	1685
I don't think training only on the points close to the decision boundary is enough and was more expecting to see some discussion about this in the paper.	I-Review	I-3	Review	1685
<sep> <sep> Conclusion:	O	O	Review	1685
My two biggest concerns are: 1) The algorithm is not tested on large data seta 2) The algorithm is not tested with the models of limited capacity.	B-Review	B-3	Review	1685
As a conclusion, I tend to vote for rejection.	I-Review	I-3	Review	1685
Thank you for your thoughtful review and suggestions.	O	O	Reply	1685
Here are our responses:	O	O	Reply	1685
<sep> 1) We agree that it would be valuable to provide more comparison against related work.	B-Reply	B-1	Reply	1685
The work in the ‚ÄúOptimization and Importance Sampling‚Äù section shares the closest relation to our approach by improving convergence and in some cases training time.	I-Reply	I-1	Reply	1685
In particular, we aimed to compare against ‚ÄúNot All Samples Are Created Equal: Deep Learning with Importance Sampling‚Äù from Katharopoulos & Fleuret (2018) as it represents the most recent published work in the area.	I-Reply	I-1	Reply	1685
Unfortunately, we were unable to complete the experiments before the response deadline.	I-Reply	I-1	Reply	1685
<sep> <sep> 2) We are currently running experiments on ImageNet, but the results will not be ready before the response deadline.	B-Reply	B-2	Reply	1685
However, for both SVHN and CIFAR10, the larger model improves accuracy significantly over the proxy.	I-Reply	I-2	Reply	1685
For CIFAR10, there is a 2.5% difference in absolute error (47% relative error) between ResNet20 and ResNet164 .	I-Reply	I-2	Reply	1685
With partial training, the difference in absolute error between the ResNet20 and ResNet164 is ~12%.	I-Reply	I-2	Reply	1685
Interestingly, despite the limited capacity of the proxy models, our approach still selects a subset that maintains accuracy and performs much better than random.	I-Reply	I-2	Reply	1685
In fact, for CIFAR10, using ResNet20 as the select proxy performs better than using ResNet164 (the target model) for selection as shown in Table 1.	I-Reply	I-2	Reply	1685
<sep> <sep> 3) This is a great observation.	B-Reply	B-3	Reply	1685
We have preliminary results that suggest the diversity of the subset is an important factor in maintaining quality.	I-Reply	I-3	Reply	1685
Looking at the CDF of entropy on CIFAR10, for example, shows that only around 20% of points have relatively high entropy and that entropy quickly decays after the first 20%.	I-Reply	I-3	Reply	1685
However, the target model is only able to match the same level of accuracy with a larger subset as shown in Table 1.	I-Reply	I-3	Reply	1685
This suggests that the subset needs to be sufficiently representative in addition to containing the most difficult.	I-Reply	I-3	Reply	1685
Fortunately, we hypothesize that the proxy model can also give us an efficient way to calculate the representativeness of each example as well as uncertainty, allowing us to algorithmically construct such as subset.	I-Reply	I-3	Reply	1685
We are already looking into this but couldn‚Äôt complete the necessary experiments while also attempting to address your feedback above.	I-Reply	I-3	Reply	1685
However, we can include CDFs of entropy and some preliminary discussion of this point.	I-Reply	I-3	Reply	1685

# Summary	O	O	Review	1685
The paper presents a method for identifying and selecting the most informative subset of the training dataset in order to reduce training time while maintaining test accuracy.	O	O	Review	1685
The method consists of training a proxy model that is smaller and has been trained for fewer epochs, and which can optionally be ensembled.	O	O	Review	1685
Experiments show promising results, indicating that some datasets can be reduced to half the size without impacting model performance.	O	O	Review	1685
<sep> <sep> # Quality	O	O	Review	1685
The paper appears sound and of good quality.	O	O	Review	1685
Background literature is cited and the proposed method is discussed in sufficient detail.	O	O	Review	1685
<sep> <sep> I would, however, like to see some additional comparative experiments.	B-Review	B-1	Review	1685
All experiments are constructed to show that the method can indeed achieve accuracy comparable to the full model but with a smaller training set.	I-Review	I-1	Review	1685
I would like to see how it compares to existing strategies -- are there any reason to pick this method over existing ones?	I-Review	I-1	Review	1685
<sep> Since the last sentence in section 2 states that the proposed method is orthogonal to previous subsampling techniques, and therefore can be combined with any of them, it would be interesting to see how SVP compares to these and whether a combination of, say, SVP and importance sampling will in fact achieve better performance than the importance sampling on its own.	B-Review	B-2	Review	1685
<sep> Additionally, given the model's high resemblance to active learning, it would be interesting to see it compared to some prominent active learning methods.	B-Review	B-3	Review	1685
<sep> <sep> # Clarity	O	O	Review	1685
The paper reads quite well.	O	O	Review	1685
I particularly like the paragraph headlines, which makes it easy to get an overview of the paper.	O	O	Review	1685
<sep> <sep> The figures are generally nice and readable, except for figure 3, which I don't understand.	B-Review	B-5	Review	1685
Maybe I am missing it, but I can't find an explanation for what the rows and columns indicate, and the labels themselves should also be increased in size.	I-Review	I-5	Review	1685
<sep> <sep> # Originality	O	O	Review	1685
I do not find the paper particularly novel.	B-Review	B-3	Review	1685
To me, the proposed method seems to be a variant of active learning, not orthogonal to this as it is claimed in section 2.	I-Review	I-3	Review	1685
The choice of surrogate model and uncertainty metric might be new, but the method itself boils down to uncertainty sampling, a well-known strategy in active learning.	I-Review	I-3	Review	1685
<sep> However, I am happy to change my mind if the authors can explain to me exactly how their method differs from active learning.	I-Review	I-3	Review	1685
<sep> <sep> # Significance	O	O	Review	1685
While techniques for speeding up training without sacrificing performance are, of course, always interesting, I find the proposed method to be rather incremental and not significant enough for ICLR.	B-Review	B-3	Review	1685
It would be better suited as a workshop paper.	I-Review	I-3	Review	1685
<sep> <sep> # Other notes	O	O	Review	1685
In the last paragraph of section 1, you write that "Our proposed framework is robust to the choice of proxy model architecture."	B-Review	B-4	Review	1685
I am not sure what you mean by this.	I-Review	I-4	Review	1685
Do you mean that one can choose any model as the proxy (which is clearly correct) or do you mean that the method is "proxy agnostic" in the sense that any proxy model will work better than no proxy?	I-Review	I-4	Review	1685
If the latter is the case, I would like some arguments for this.	I-Review	I-4	Review	1685
Also, if the method is indeed proxy agnostic, it should be possible to remove the proxy completely and select the data in some other way.	I-Review	I-4	Review	1685
<sep> <sep> Thank you for your thoughtful review and suggestions.	O	O	Reply	1685
Here are our responses:	O	O	Reply	1685
<sep> # SVP and importance sampling	O	O	Reply	1685
We agree that more comparison against existing methods such as importance sampling would be valuable.	B-Reply	B-2	Reply	1685
We aimed to compare against ‚ÄúNot All Samples Are Created Equal: Deep Learning with Importance Sampling‚Äù from Katharopoulos & Fleuret (2018) as it represents the most recent published work in the area.	I-Reply	I-2	Reply	1685
Unfortunately, we were unable to complete the experiments before the response deadline.	I-Reply	I-2	Reply	1685
<sep> <sep> # Active learning, originality, and significance	O	O	Reply	1685
We agree that we leverage uncertainty sampling (Lewis & Gale, 1994) from active learning to select the points with highest informativeness.	B-Reply	B-3	Reply	1685
However, in active learning a model is generally trained to select the next point (Settles, 2012) or batch (Sener & Savarese, 2018), which is efficient in terms of labels, but often computationally expensive.	I-Reply	I-3	Reply	1685
While this can be effective when deciding which data to acquire labels for from an expensive labeler (e.g. a human), the computational cost is too high to accelerate training over an existing large labeled dataset.	I-Reply	I-3	Reply	1685
Using a proxy reduces the cost of selection by up to a 100x for Amazon Review Polarity or 30x for CIFAR10.	I-Reply	I-3	Reply	1685
This is such a substantial improvement that uncertainty sampling can now be extended to reduce computational costs of training in addition to labeling costs.	I-Reply	I-3	Reply	1685
To clarify this point, we added more detail in the introduction.	I-Reply	I-3	Reply	1685
<sep> <sep> # Figure 3: model correlation	O	O	Reply	1685
We increased the size of the labels and improved the figure caption.	B-Reply	B-5	Reply	1685
The key takeaway is that ensembling multiple small models together through rank combination improves our approximation of the large model‚Äôs uncertainty as shown by the increase in correlation ranking.	I-Reply	I-5	Reply	1685
<sep> <sep> # Robustness to the choice of proxy model architecture	O	O	Reply	1685
By ‚Äúrobust to the choice of proxy model architecture‚Äù we mean that while we discussed different steps in Section 3.1 to create the proxy model, and explored various uncertainty measures in Section 3.2 to select data points via proxy, our approach allows for a wide range of configurations.	B-Reply	B-4	Reply	1685
The proxy is important but it is easy to find one that is good enough in practice and doesn‚Äôt require extensive hyperparameter tuning.	I-Reply	I-4	Reply	1685

This paper studies a very simple and intuitive method to boost the training speed of deep neural networks.	O	O	Review	1685
The authors first train some light weighted proxy models, using these models to rank the data according to its uncertainty, and then pick the most uncertain subset to train the final model.	O	O	Review	1685
Experiments on CIFAR10/SVHN/Amazon Review Polarity demonstrates the effectiveness.	O	O	Review	1685
<sep> <sep> In general, I think the authors did a decent job in showing that such a simple idea could surprisingly work well to boost NN training.	O	O	Review	1685
I believe it will inspire future works on speeding up NN training.	O	O	Review	1685
However, to form a solid ICLR publication, plenty of future works need to be done.	O	O	Review	1685
<sep> <sep> 1)<tab>I will not be fully convinced if an idea aiming to speed up, is only verified on small scale dataset (e.g., CIFAR10).	B-Review	B-1	Review	1685
It will be much better if there are large scale experiments conducted such as on ImageNet and WMT neural machine translation.	I-Review	I-1	Review	1685
<sep> <sep> 2)<tab>Please well position some related works.	B-Review	B-2	Review	1685
First, it would be more interesting and informative if some baselines in section 2 (especially those in ‚ÄúOptimization and Importance Sampling‚Äô), are compared with.	I-Review	I-2	Review	1685
Second, there are important related works omitted such as L2T [1], which also talks/shows the possibly of using partial training data to achieve speed up.	B-Review	B-3	Review	1685
<sep> <sep> 3)<tab>Some writing issues: it would be better to *clearly* demonstrate the final accuracy of different models (i.e. ResNet 164 trained on whole data and selected subset), such as putting them into a table, but not merely showing them vaguely in the curves and text.	B-Review	B-5	Review	1685
I‚Äôm also note sure about the meaning of `epoch‚Äô in Table 1: does it mean how many epochs the proxy model is trained?	I-Review	I-5	Review	1685
If so, I can hardly get the intuition of why smaller epochs works better.	I-Review	I-5	Review	1685
I noted a conjecture raised by the authors in the last sentence of paragraph ‚Äúcomparing different proxies‚Äù.	I-Review	I-5	Review	1685
However, I cannot catch the exact meaning.	I-Review	I-5	Review	1685
<sep> <sep> [1] Fan, Y., Tian, F., Qin, T., Li, X. Y., & Liu, T. Y. Learning to Teach.	O	O	Review	1685
ICLR 2018	O	O	Review	1685
<sep> Thank you for your thoughtful review and suggestions.	O	O	Reply	1685
Here are our responses:	O	O	Reply	1685
<sep> # large-scale experiments	O	O	Reply	1685
We are currently running experiments on ImageNet, but the results will not be ready before the response deadline.	B-Reply	B-1	Reply	1685
<sep> <sep> # Comparison against baselines in section 2	O	O	Reply	1685
We agree that more comparison against existing methods such as importance sampling would be valuable.	B-Reply	B-2	Reply	1685
we aimed to compare against ‚ÄúNot All Samples Are Created Equal: Deep Learning with Importance Sampling‚Äù from Katharopoulos & Fleuret (2018) as it represents the most recent published work in the area.	I-Reply	I-2	Reply	1685
Unfortunately, we were unable to complete the experiments before the response deadline.	I-Reply	I-2	Reply	1685
<sep> <sep> # Learning to teach (L2T)	O	O	Reply	1685
We agree learning to teach is relevant and included it in the related work section.	B-Reply	B-3	Reply	1685
<sep> <sep> # Final accuracy of different models in a table	O	O	Reply	1685
We believe Table 1 should address this concern, and we changed the structure to make it more clear.	B-Reply	B-4	Reply	1685
The most important data from Figure 4 and 5 is captured in the table.	I-Reply	I-4	Reply	1685
We could add the additional metrics from Figure 5, but the main point of that figure is to show that all of the metrics perform about the same, which would just add redundant rows to the table.	I-Reply	I-4	Reply	1685
<sep> <sep> # Smaller number of epochs	O	O	Reply	1685
Great question.	B-Reply	B-5	Reply	1685
Yes, "epoch" in Table 1 means how many epochs the proxy model is trained.	I-Reply	I-5	Reply	1685
We have preliminary results that suggest the diversity of the subset is an important factor in maintaining quality.	I-Reply	I-5	Reply	1685
Looking at the CDF of entropy on CIFAR10, for example, shows that only around 20% of points have relatively high entropy and that entropy quickly decays after the first 20%.	I-Reply	I-5	Reply	1685
However, the target model is only able to match the same level of accuracy with a larger subset as shown in Table 1.	I-Reply	I-5	Reply	1685
This suggests that the subset needs to be sufficiently representative in addition to containing the most difficult.	I-Reply	I-5	Reply	1685
We hypothesize that the higher error of smaller architectures and partial training might result in increased randomness, which could improve the representativeness of the resulting subsets.	I-Reply	I-5	Reply	1685

The submission aims to analyze deep neural network (DNN) features in terms of how well they measure the perceptual severity of image distortions.	O	O	Review	10192
It proposes to characterize each DNN feature in terms of two well known properties of the human visual system: a) sensitivity to changes in visual frequency and b) orientation selectivity.	O	O	Review	10192
Both properties are evaluated with respect to the known human Contrast Sensitivity Function (CSF) and measured empirically from the feature‚Äôs response to (oriented) sinusoidal gratings.	O	O	Review	10192
The results are quantified by a composite score termed Perceptual Efficacy (PE).	O	O	Review	10192
<sep> In a set of comprehensive experiments (several pre-trained DNNs, several layers per DNN and two different datasets of distorted images with human perceptual quality annotations) it is demonstrated that feature representation consisting of a layer‚Äôs features with high PE better agree with human perceptual quality judgments than low PE feature representations from the same layer.	O	O	Review	10192
<sep> <sep> I believe the submission convincingly demonstrates a statistical association between the proposed PE score of a DNN feature and human perceptual quality assessments.	O	O	Review	10192
<sep> Though, it remains unclear whether the characteristics captured by the PE score are necessary or sufficient to explain the success of DNNs to guide image generation tasks by providing a perceptual loss function.	O	O	Review	10192
<sep> For that I believe it is necessary to demonstrate that the present empirical results can be used to improve results of an image generation task, e.g. super-resolution.	B-Review	B-1	Review	10192
<sep> Furthermore the limits of the PE score could be explored by hand-crafting image representations with maximal PE score and comparing their usefulness in guiding e.g. a super-resolution task compared to a pre-trained DNN.	B-Review	B-2	Review	10192
<sep> <sep> Thus, overall I believe the submission reports interesting initial results but falls short of showing that they capture general properties that can be transferred to improving perceptual loss functions.	B-Review	B-1	Review	10192
Thank you for taking the time to read our manuscript and providing a thorough review.	O	O	Reply	10192
We are pleased that you agree that our proposed analysis and attributes can correlate the ability of pre-trained CNN channels to deliver good perceptual quality features  (as demonstrated by perceptual quality experiments).	O	O	Reply	10192
The prime focus of this paper is to link basic human visual perception to interpret the ability of pre-trained CNN channels as perceptual quality features, a problem that has never been addressed.	O	O	Reply	10192
<sep> <sep> Your prime concern is whether the experimental techniques that we have employed (OQA and 2AFC tests) can be considered sufficient evidence to explain the ability of perceptual loss metrics in practical problems, such as super-resolution.	B-Reply	B-1	Reply	10192
An interesting question.	I-Reply	I-1	Reply	10192
We would like to point out that these experimental techniques have been satisfactorily been used to address perceptual loss metrics in prior works such as [1] and are the primary experimental tests when it comes to analyzing the perceptual efficacy of metrics.	I-Reply	I-1	Reply	10192
The loss function provides a singular value that is to be optimized, if the value transitions correspond well with human judgement of perceptual differences, they should be consequential for CNN based Imaging problems.	I-Reply	I-1	Reply	10192
As per [1], superiority in OQA and 2AFC tests should be consequential for practical CNN based imaging problems.	I-Reply	I-1	Reply	10192
<sep> <sep> However, to demonstrate, we have included an ADDITIONAL SUPER-RESOLUTION EXPERIMENT in the Appendix (section C).	I-Reply	I-1	Reply	10192
The aim of the experiment is to serve as an indicator that the conclusions of our experimental methods are consequential for; as you have said "image generation tasks such as SR".	I-Reply	I-1	Reply	10192
The additional experimental results should be sufficient to address your major concern, demonstrating that the results are transferable to practical imaging problems.	I-Reply	I-1	Reply	10192
The experiment is not and should not be considered an attempt to surpass state of the art methods, as the primary concern of this paper is understanding and interpretation.	I-Reply	I-1	Reply	10192
Thank you again for your time and thorough review, we are at your disposal for any more queries.	I-Reply	I-1	Reply	10192
<sep> <sep> [1]: Zhang, Richard et al ‚ÄúThe Unreasonable Effectiveness of Deep Features as a Perceptual Metric.	O	O	Reply	10192
‚Äù 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (2018): 586-595.	O	O	Reply	10192

This paper proposes an analysis of convolutional neural networks (CNNs) features the basis for making perceptual quality comparisons.	O	O	Review	10192
The analysis is based on the proposed Perceptual Efficacy (PE) Score that measures spatial frequency and orientation selectivity of CNN features.	O	O	Review	10192
The hypothesis put forward by the authors is that a CNN features with high PE score can be used to formulate a perceptual loss (Eq.1) that correlates well with human image quality judgement.	O	O	Review	10192
The authors use a dataset of human image quality judgements to assess their hypothesis.	O	O	Review	10192
<sep> <sep> One issue I see with the hypothesis as stated is that in the definition of frequency selective features, the authors make use of	B-Review	B-1	Review	10192
the Contrast Sensitivity Function (CSF) which quantifies the dependency of human perceptual characteristics on frequency.	I-Review	I-1	Review	10192
So in the definition of the PE score we have embedded knowledge of human perceptual sensitivity.	I-Review	I-1	Review	10192
Is it therefore surprising  that we see correlation between the high PE features and human judgements of quality?	I-Review	I-1	Review	10192
<sep> <sep> Experimental results: The scatterplot presented in Figure 4 does not say to me what the authors claim it should.	B-Review	B-2	Review	10192
I do not see a significant difference between the low-PE features and the high-PE features in terms of their correlation with human image quality judgement (as measures in this case by the DMOS).	I-Review	I-2	Review	10192
I also find the large table of number in Table 1 to be rather	I-Review	I-2	Review	10192
impenetrable.	I-Review	I-2	Review	10192
I would recommend an alternative method of presentation to make the desired point.	I-Review	I-2	Review	10192
<sep> Clarity: There are many undefined terms and acronyms (eg.SISR, HVS are not defined, while DMOS and SROCC are not described).	B-Review	B-3	Review	10192
Also, the description of visual masking in Sec.4.3 was confusing and difficult to follow.	I-Review	I-3	Review	10192
Otherwise the writing was reasonably clear.	I-Review	I-3	Review	10192
<sep> <sep> Impact and significance: Overall, the findings of the paper are not terribly surprising and as discuss above, given the use of the CSF (quantifying human perceptual characteristics) in the definition of the CNN Perceptual Efficacy (PE) score, it would seem rather surprising that a correlations would not be found.	B-Review	B-1	Review	10192
As a result of this as well as the rather narrow nature of the study involved, I am inclined to think that the impact potential of this paper would be rather low.	I-Review	I-1	Review	10192
Thank you for taking the time to read our manuscript and providing a thorough review.	O	O	Reply	10192
The prime focus of this paper is to link basic human visual perception to interpret the ability of pre-trained image classification CNN channels as perceptual quality features.	B-Reply	B-1	Reply	10192
The PROBLEM STATEMENT we have posted in our manuscript states "Are all of the channels equally effective in delivering good perceptual quality features?	I-Reply	I-1	Reply	10192
Are some channels better than others and if so, what attributes make them better?",	I-Reply	I-1	Reply	10192
a problem that has never been addressed.	I-Reply	I-1	Reply	10192
<sep> <sep> We are pleased to know that you think our conclusions are not surprising.	B-Reply	B-1	Reply	10192
Quite a majority of the Deep Learning community is still resistant to works that provide a human vision based perspective to neural networks.	I-Reply	I-1	Reply	10192
Our main approach has been to link basic human visual characteristics such as frequency sensitivity and orientation selectivity to interpret deep CNN representations as perceptual quality features.	I-Reply	I-1	Reply	10192
The result may not be that surprising, it might be quite intuitive  (considering what we know about human visual perception), which is good from an interpretation point of view, but we believe it is not inconsequential as it adequately address the unaddressed problem statement we have put forward.	I-Reply	I-1	Reply	10192
Firstly, linking human visual perception characteristics to CNNs has been a bottleneck (as we have explained).	I-Reply	I-1	Reply	10192
Only after our novel approach of using gratings to quantify frequency and orientation selectivity of CNN channels, it becomes possible to apply our knowledge of perception (CSF etc) to design models to explain and interpret them.	I-Reply	I-1	Reply	10192
Secondly, despite rapid progress towards new and complex DL methods, the interpretation of CNN models has not received much attention, we are moving rapidly into a direction where we know less and less about what is actually going on.	I-Reply	I-1	Reply	10192
It is important from a scientific perspective, to understand and interpret learned representations, which is also a major focus of the ICLR.	I-Reply	I-1	Reply	10192
It is quite interesting that learned representations which have the prime task of classifying images, deliver remarkable perceptual quality features, and we can use human vision perception to get insight on why.	I-Reply	I-1	Reply	10192
This is the first work that dives into the why and how, from a perspective of visual perception.	I-Reply	I-1	Reply	10192
Thirdly, we have added an ADDITIONAL EXPERIMENT in the appendix (section C) to demonstrate how our analysis is actually consequential for practical perception-oriented imaging problems, such as super-resolution.	I-Reply	I-1	Reply	10192
As we have explained, understanding perceptual aspects of deep representations can also impact perception-oriented applications like CNN based image compression etc.	I-Reply	I-1	Reply	10192
<sep> <sep> Regarding interpreting Fig.4 visually, the ideal quality metric would be on which all the points lie on a straight line.	B-Reply	B-2	Reply	10192
What we do not want is images with multiple levels of distortions giving the same metric score, and vice versa, Image with the same level of distortion giving varying metric scores.	I-Reply	I-2	Reply	10192
If you compare the image in Fig.4, you can observe that with the high PE result, the vertical spread of points wrt to constant metric scores is reduced, which means that images with the same metric scores are now less variant in perceptual quality, and vice versa.	I-Reply	I-2	Reply	10192
Also, kindly refer to Fig.5 in the appendix for further results.	I-Reply	I-2	Reply	10192
If you prefer, I can replace Fig.4 with a plot that is more interpretable.	I-Reply	I-2	Reply	10192
<sep> <sep> Regarding Table.	B-Reply	B-2	Reply	10192
1, I understand the a jargon of number is often difficult to understand, plus its not visually pleasing.	I-Reply	I-2	Reply	10192
However, the experimental techniques and reported evaluation metrics are the standard to analyze perceptual quality metrics.	I-Reply	I-2	Reply	10192
Considering that we analyzed multiple layers of multiple network using three evaluation metrics, graphical representations would have been very difficult.	I-Reply	I-2	Reply	10192
I apologize for the inconvenience.	I-Reply	I-2	Reply	10192
I have added additional explanation in the results section to help readers understand the table better, I hope that helps.	I-Reply	I-2	Reply	10192
<sep> <sep> I have added full forms of the terms such as HVS, SISR and added additional explanations for DMOS and SROCC.	B-Reply	B-3	Reply	10192
<sep> <sep> Considering firstly that interpretation of learned representations is important and this is the first work to address interpretation of this specific problem (see PROBLEM STATEMENT), secondly , the additional experiment now demonstrating that the analysis can be consequential for practical imaging problems as well, I hope I have sufficiently addressed you major concerns.	B-Reply	B-1	Reply	10192
Thank you again for your time and thorough review, we are at your disposal for any more queries.	O	O	Reply	10192

I thank the authors for their detailed response.	O	O	Review	10192
Some of my questions have been addressed in the rebuttal, but as far as I can tell very few modifications have been made to the paper: mainly an additional super-resolution experiment in the appendix, which goes in a good direction, but currently comes across as quite preliminary.	O	O	Review	10192
So I think the paper still has most of the weaknesses I mentioned and thus it is not quite fit for publication.	B-Review	B-1	Review	10192
But I do encourage the authors to strengthen the experiments (for instance by addressing the points I raised, or by some other means) and resubmit elsewhere.	I-Review	I-1	Review	10192
<sep> <sep> ---	O	O	Review	10192
<sep> The paper proposes an approach to analyzing the properties of "perceptual metrics" used in deep learning image generation methods. "	O	O	Review	10192
Perceptual metrics" are computed by measuring distances between images not in the pixel space, but i na feature space of a pre-trained cNN.	O	O	Review	10192
The proposed analysis method, inspired by studies of human perception, is based on measuring the response of these features to sinusoidal gratings of varying frequency or orientation.	O	O	Review	10192
Based on these responses, the paper proposes a "Perceptual Efficacy Score" that should measure the importance of certain feature in the feature maps for the performance of a perceptual metric.	O	O	Review	10192
Experiments show that indeed distances measured between features with high score better correlate with human judgement of image similarity than distances between features with a lower score.	O	O	Review	10192
<sep> <sep> I find the paper quite interesting, but lean towards rejection at this point.	O	O	Review	10192
This i smainly because the experiments seem somewhat anecdotal and incomplete, see below for further details.	O	O	Review	10192
<sep> <sep> Pros:	O	O	Review	10192
1) Application of methods from psychology/neuroscience to artificial neural networks is an interesting avenue of work.	O	O	Review	10192
Moreover, better unsderstanding of "perceptual metrics" is of wide interest for various image processing applications.	O	O	Review	10192
<sep> 2) The proposed score seems to indeed correlate quite well with the importance of features for human judgement of image similarity.	O	O	Review	10192
<sep> 3) Presentation is mainly clear.	O	O	Review	10192
<sep> <sep> Cons:	O	O	Review	10192
1) Experiments are not very exhaustive and at times a bit confusing.	O	O	Review	10192
For instance:	O	O	Review	10192
1a) Results are sometimes presented in a confusing way.	B-Review	B-1	Review	10192
In Figure 4 first of all it is not quite clear what points correspond to I guess each point is an image) and, second, it is not very obvious that the correlation is higher i none of the plots.	I-Review	I-1	Review	10192
In tables 1 and 2 it is confusing that different percentiles for H and L are used for different networks/layers.	I-Review	I-1	Review	10192
Is this based on some tuning?	I-Review	I-1	Review	10192
Then the tuning process should be clearly explained.	I-Review	I-1	Review	10192
Moreover, it might be useful to report the full curves of performance as a function of the percentage of features used.	I-Review	I-1	Review	10192
<sep> 1b) There are no baselines and there is not much justification of computing the "Perceptual Efficacy" score the way it is computed.	B-Review	B-2	Review	10192
What if one uses only the orientation-based score?	I-Review	I-2	Review	10192
Or only the frequency-based?	I-Review	I-2	Review	10192
What if one selects the most relevant features in a data-driven way (based on correlation on a training set)?	I-Review	I-2	Review	10192
What if one selects subsets of features randomly?	I-Review	I-2	Review	10192
<sep> 1c) While the method is inspired by methods used for studying natural vision systems, there is no connection to human experiments.	B-Review	B-3	Review	10192
It would be interesting to see a comparison of frequency and orientation tuning of features in a CNN to human cells (as I understand, the latter should be available in prior works?).	I-Review	I-3	Review	10192
<sep> 1d) It would be great to see the selected features be used not only for offline image similarity assessment, but also for training image processing models - in the end, this has been the main use of "perceptual metrics".	B-Review	B-4	Review	10192
Do they lead to improved results?	I-Review	I-4	Review	10192
<sep> 1e) Since the paper is about (subjective) image quality, it might be useful to show some qualitative results, potentially in the appendix if space is an issue.	B-Review	B-5	Review	10192
<sep> <sep> 2) There are some issues with the presentation:	O	O	Review	10192
2a) I had a hard time understanding what exactly "Contrast Sensitivity Function" and "contrast masking" are.	B-Review	B-6	Review	10192
<sep> 2b) Minor issues:	B-Review	B-6	Review	10192
- In the abstract: "trained object detection deep CNNs" - I guess image classification is meant	I-Review	I-6	Review	10192
- Beginning of Section 2: "Section.	I-Review	I-6	Review	10192
2", "convolution layer as collection channels"	I-Review	I-6	Review	10192
- Section 4: "corresponds the the peak:	I-Review	I-6	Review	10192
- Section 5.2 "Berkeley-Adobpe"	I-Review	I-6	Review	10192
Thank you for taking the time to read our manuscript and providing a thorough review.	O	O	Reply	10192
The prime focus of this paper is to link basic human visual perception to interpret the ability of pre-trained image classification CNN channels as perceptual quality features, a problem that has never been addressed.	O	O	Reply	10192
I would try my best to address your concerns.	O	O	Reply	10192
<sep> <sep> Regarding interpreting Fig.4 visually, the ideal quality metric would be on which all the points lie on a straight line.	B-Reply	B-1	Reply	10192
Each point does indeed represent an Image, the y-axs being a score of how humans evaluated it in comparison to the ground truth, the x-axs being how the metric evaluated it.	I-Reply	I-1	Reply	10192
What we do not want is images  with multiple levels of distortions giving the same metric score, and vice versa, Image with the same level of distortion giving varying metric scores.	I-Reply	I-1	Reply	10192
If you compare the image in Fig.4, you can observe that with the high PE result, the vertical spread of points wrt to constant metric scores is reduced, which means that images with the same metric scores are now less variant in perceptual quality, and vice versa.	I-Reply	I-1	Reply	10192
Also, kindly refer to Fig.5 in the appendix for further results.	I-Reply	I-1	Reply	10192
If you prefer, I can replace Fig.4 with a plot that is more interpretable.	I-Reply	I-1	Reply	10192
<sep> <sep> Regarding the different percentiles in Table.	B-Reply	B-1	Reply	10192
1 and 2.	I-Reply	I-1	Reply	10192
They were not due to any tuning characteristics or intrinsic properties of channels.	I-Reply	I-1	Reply	10192
The different values were chosen to see that the results are valid for a wide variety of divisions, also it is important to remember that all layers do not have the same number of channels i.e a 5% subset from a layer with 512 channels makes sense, not so much for a layer with 32 or 64 channels.	I-Reply	I-1	Reply	10192
They divisions are in no way biased or influenced by some prior.	I-Reply	I-1	Reply	10192
<sep> <sep> Regarding the issue of relation to human experiments, we actually have human perceptual input in our experiments, which exists in the form of DMOS (human quality scores), derived from a population of human subjects.	B-Reply	B-3	Reply	10192
The CSF is actually a representation of overall human perception of visual stimulus, which is a result of a combination of different levels of neural activation's.	I-Reply	I-3	Reply	10192
As the problem scope is towards overall psychophysics and PERCEPTION OF DISTORTIONS, not individual activation's on a neuron level, that route was not very helpful here, but it is a very good idea for some other study, more focused in understanding CNN activation similarities with the visual cortex.	I-Reply	I-3	Reply	10192
To the best of our knowledge, you will not find any prior work on the problem and approach we have adopted.	I-Reply	I-3	Reply	10192
<sep> <sep> Regarding training for image processing models, an ADDITIONAL EXPERIMENT has been added in the appendix, which demonstrates that our analysis is consequential for practical imaging problems such as super-resolution.	B-Reply	B-4	Reply	10192
That result also further reinforces the validity of hypothesis are techniques.	I-Reply	I-4	Reply	10192
The additional experiment hopefully alleviates some of your concerns regarding the experiments.	I-Reply	I-4	Reply	10192
<sep> <sep> Furthermore, the minor issues have been mitigated with additional explanations and corrections.	B-Reply	B-6	Reply	10192
<sep> <sep> I hope I have sufficiently addressed your major concerns.	O	O	Reply	10192
Thank you again for your time and thorough review, we are at your disposal for any more queries.	O	O	Reply	10192

In the article the authors propose to measure quality of CNN-features by quantifying the orientation tuning and spatial frequency sensitivity of the features.	O	O	Review	10192
The underlying hypothesis is that properties of features in the human visual cortex are also indicators for quality in CNNs.	O	O	Review	10192
The authors devise an experiment similar to experiments performed on mammals to check which features are active under which types of basic patterns.	O	O	Review	10192
Afterwards, a loss-function is devised that uses proportions of the best or worst features according to the metrics and it is shown that features that have high values on the metrics also lead to good performance.	O	O	Review	10192
<sep> -----------------------------------------------------------------------------------------	O	O	Review	10192
I have a problem understanding some of the metrics used.	B-Review	B-1	Review	10192
In the introduction, the following claim is made:	I-Review	I-1	Review	10192
"The first attribute is sensitivity to spatial frequencies at which there is minimal contrast masking in human visual perception".	I-Review	I-1	Review	10192
To my understanding, the metric to measure this is (2) in 4.2.	I-Review	I-1	Review	10192
a_m^k is to my understanding the average response of the feature when given an image with orientation-frequency f. therefore, the derivative should be "the change of activation under change of frequency".	I-Review	I-1	Review	10192
I feel unable to connect this with the initial hypothesis, as it does not mention change of frequencies.	I-Review	I-1	Review	10192
i would have expected the correlation between CSF(f) and a^k_m(f),	I-Review	I-1	Review	10192
did you have a reason why you did not chose correlation?	I-Review	I-1	Review	10192
<sep> <sep> Similarly, for mu_2 in (3) you are using the maximum value.	B-Review	B-2	Review	10192
Is there a reason not to use the mean?	I-Review	I-2	Review	10192
in that case mu_2 would be the variance, which would be a natural measure for orientation selectivity.	I-Review	I-2	Review	10192
<sep> <sep> ------------------	O	O	Review	10192
Is there a way to make Table 1 more pleasing for the human eye wrt the discussion of the results?	B-Review	B-3	Review	10192
Thank you very much for taking the time to review our manuscript and providing a thorough review.	O	O	Reply	10192
You have raised some interesting questions.	O	O	Reply	10192
The prime focus of this paper is to link basic human visual perception to interpret the ability of pre-trained image classification CNN channels as perceptual quality features, a problem that has never been addressed.	O	O	Reply	10192
<sep> <sep> Firstly, let us explain why we have employed the concept of sensitivity to important (low contrast masking, high CSF valued) spatial frequencies rather than using correlation, which at first glance seems a more logical choice.	B-Reply	B-1	Reply	10192
What needs to be remembered is that the perceptual loss is a differential metric i.e It is designed to quantify perceptual differences between two images.	I-Reply	I-1	Reply	10192
Therefore, what should actually be preferred is not absolute activation, rather the activation should changes with perceptually important distortions (because the difference in activation between distorted and ground truth is the thing we are interested in).	I-Reply	I-1	Reply	10192
For example, lets suppose two CNN channel's have an all pass type response, would they be good for the perceptual loss?	I-Reply	I-1	Reply	10192
The answer is no, because they will not change their activation much according to the distortion on the input image, relative to the ground truth.	I-Reply	I-1	Reply	10192
What should be preferred is a sharp change in activation at high CSF valued spatial frequencies, so that the CNN channels are able to respond much better to perceptually important distortions, COMPARED to unaffected ground truth images.	I-Reply	I-1	Reply	10192
<sep> <sep> Secondly, regarding our quantification of orientation selectivity and why we have not used the mean.	B-Reply	B-2	Reply	10192
Suppose for a random data stream, one may take the mean and variance, which will give us a distribution.	I-Reply	I-2	Reply	10192
The orientation selectivity of channels is actually somewhat analogous to a distribution (a peak at some orientation and a fall-off).	I-Reply	I-2	Reply	10192
Orientation selectivity, as per our definition is how selective a channel is to a particular orientation (the peak).	I-Reply	I-2	Reply	10192
Therefore, In order to maximize selectivity, we prefer a fast fall-off in tuning around the peak.	I-Reply	I-2	Reply	10192
The formulation in the manuscript rewards higher selectivity of a particular orientation (the peak orientation) wrt to all other orientations, which is what we desire.	I-Reply	I-2	Reply	10192
If we were to use the mean, it would compute the spread wrt to the average orientation selectivity over all orientations, which is not what we are after.	I-Reply	I-2	Reply	10192
<sep> <sep> Regarding Table.	B-Reply	B-3	Reply	10192
1, I understand the a jargon of number is often difficult to understand, plus its not visually pleasing.	I-Reply	I-3	Reply	10192
However, the experimental techniques and reported evaluation metrics are the standard to analyze perceptual quality metrics.	I-Reply	I-3	Reply	10192
Considering that we analyzed multiple layers of multiple network using three evaluation metrics, graphical representations would have been very difficult.	I-Reply	I-3	Reply	10192
I apologize for the inconvenience.	I-Reply	I-3	Reply	10192
I have added additional explanation in the results section to help readers understand the table better, I hope that helps.	I-Reply	I-3	Reply	10192
<sep> <sep> Furthermore, we have added an additional experiment in the Appendix (Section.	B-Reply	B-4	Reply	10192
C) that demonstrates that our results are also consequential for practical imaging problems such as SR, reinforcing our analysis.	I-Reply	I-4	Reply	10192
I hope you like it.	I-Reply	I-4	Reply	10192
Thank you very again for taking the time to review our manuscript and providing a thorough review, we are at your disposal for any more queries that you may have.	O	O	Reply	10192

Summary	O	O	Review	604
===	O	O	Review	604
This paper extends and analyzes the gradient regularizer of Hariharan and	O	O	Review	604
Girshick 2016.	O	O	Review	604
In that paper a regularizer was proposed which penalizes	O	O	Review	604
gradient magnitudes and it was shown to aid low-shot learning performance.	O	O	Review	604
<sep> This work shows that the previous regularizer is equivalent to a direct penalty	O	O	Review	604
on the magnitude of feature values weighted differently per example.	O	O	Review	604
<sep> <sep> The analysis goes to to provide two examples where a feature penalty	O	O	Review	604
favors a better representation.	O	O	Review	604
The first example addresses the XOR	O	O	Review	604
problem, constructing a network where a feature penalty encourages	O	O	Review	604
a representation where XOR is linearly separable.	O	O	Review	604
<sep> The second example analyzes a 2 layer linear network, showing improved stability	O	O	Review	604
of a 2nd order optimizer when the feature penalty is added.	O	O	Review	604
<sep> One last bit of analysis shows how this regularizer can be interpreted as	O	O	Review	604
a Gaussian prior on both features and weights.	O	O	Review	604
Since the prior can be	O	O	Review	604
interpreted as having a soft whitening effect, the feature regularizer	O	O	Review	604
is like a soft version of Batch Normalization.	O	O	Review	604
<sep> <sep> Experiments show small improvements on a synthetic XOR test set.	O	O	Review	604
<sep> On the Omniglot dataset feature regularization is better than most baselines,	O	O	Review	604
but is worse than Moment Matching Networks.	O	O	Review	604
An experiment on ImageNet similar	O	O	Review	604
to Hariharan and Girshick 2016 also shows effective low-shot learning.	O	O	Review	604
<sep> <sep> <sep> Strengths	O	O	Review	604
===	O	O	Review	604
<sep> * The core proposal is a simple modification of Hariharan and Girshick 2016.	O	O	Review	604
<sep> <sep> * The idea of feature regularization is analyzed from multiple angles	O	O	Review	604
both theoretically and empirically.	O	O	Review	604
<sep> <sep> * The connection with Batch Normalization could have broader impact.	O	O	Review	604
<sep> <sep> <sep> Weaknesses	O	O	Review	604
===	O	O	Review	604
<sep> * In section 2 the gradient regularizer of Hariharan and Girshick is introduced.	B-Review	B-1	Review	604
<sep> While introducing the concept, some concern is expressed about the motivation:	I-Review	I-1	Review	604
"And it is not very clear why small gradients on every sample produces	I-Review	I-1	Review	604
good generalization experimentally."	I-Review	I-1	Review	604
This seems to be the central issue to me.	I-Review	I-1	Review	604
<sep> The paper details some related analysis, it does not offer a clear answer to	I-Review	I-1	Review	604
this problem.	I-Review	I-1	Review	604
<sep> <sep> <sep> * The purpose and generality of section 2.1 is not clear.	B-Review	B-2	Review	604
<sep> <sep> The analysis provides a specific case (XOR with a non-standard architecture)	I-Review	I-2	Review	604
where feature regularization intuitively helps learn a better representation.	I-Review	I-2	Review	604
<sep> However, the intended take-away is not clear.	I-Review	I-2	Review	604
<sep> <sep> The take-away may be that since a feature penalty helps in this case it	I-Review	I-2	Review	604
should help in other cases.	I-Review	I-2	Review	604
I am hesitant to buy that argument because of the	I-Review	I-2	Review	604
specific architecture used in this section.	I-Review	I-2	Review	604
The result seems to rely on the	I-Review	I-2	Review	604
choice of an x^2 non-linearity, which is not often encountered in recent neural	I-Review	I-2	Review	604
net literature.	I-Review	I-2	Review	604
<sep> <sep> The point might also be to highlight the difference between a weight	I-Review	I-2	Review	604
penalty and a feature penalty because the two seem to encourage	I-Review	I-2	Review	604
different values of b in this case.	I-Review	I-2	Review	604
However, there is no comparison to	I-Review	I-2	Review	604
a weight penalty on b in section 2.1.	I-Review	I-2	Review	604
<sep> <sep> <sep> * As far as I can tell, eq.3 depends on either assuming an L2 or cross-entropy	B-Review	B-3	Review	604
loss.	I-Review	I-3	Review	604
A more general class of losses for which eq.3 holds is not provided.	I-Review	I-3	Review	604
This	I-Review	I-3	Review	604
should be made clear before eq.3 is presented.	I-Review	I-3	Review	604
<sep> <sep> <sep> * The Omniglot and ImageNet experiments are performed with Batch Normalization,	B-Review	B-4	Review	604
yet the paper points out that feature regularization may be similar in effect	I-Review	I-4	Review	604
to Batch Norm.	I-Review	I-4	Review	604
Since the ResNet CNN baseline includes Batch Norm and there are	I-Review	I-4	Review	604
clear improvements over that baseline, the proposed regularizer has a clear	I-Review	I-4	Review	604
additional positive effect.	I-Review	I-4	Review	604
However, results should be provided without	I-Review	I-4	Review	604
Batch Norm so a 1-1 comparison between the two methods can be performed.	I-Review	I-4	Review	604
<sep> <sep> <sep> * The ImageNet experiment should be more like Hariharan and Girshick.	B-Review	B-5	Review	604
<sep> In particular, the same split of classes should be used (provided in	I-Review	I-5	Review	604
the appendix) and performance should be measured using n > 1 novel examples	I-Review	I-5	Review	604
per class (using k nearest neighbors).	I-Review	I-5	Review	604
<sep> <sep> <sep> Minor:	O	O	Review	604
<sep> * A brief comparison to Matching Networks is provided in section 3.2, but the	B-Review	B-6	Review	604
performance of Matching Networks should also be reported in Table 1.	I-Review	I-6	Review	604
<sep> <sep> * From the approach section: "Intuitively when close to convergence, about half	B-Review	B-7	Review	604
of the data-cases recommend to update a parameter to go left, while	I-Review	I-7	Review	604
the other half recommend to go right."	I-Review	I-7	Review	604
<sep> <sep> Could the intuition be clarified?	B-Review	B-7	Review	604
There are many directions in high	I-Review	I-7	Review	604
dimensional space and many ways to divide them into two groups.	I-Review	I-7	Review	604
<sep> <sep> * Is the SGM penalty of Hariharan and Girshick implemented for this paper	B-Review	B-8	Review	604
or using their code?	I-Review	I-8	Review	604
Either is acceptable, but clarification would be appreciated.	I-Review	I-8	Review	604
<sep> <sep> * Should the first equal sign in eq.13 be proportional to, not equal to?	B-Review	B-9	Review	604
<sep> <sep> * The work is dense in nature, but I think the presentation could be improved.	B-Review	B-10	Review	604
<sep> In particular, more detailed derivations could be provided in an appendix	I-Review	I-10	Review	604
and some details could be removed from the main version in order to increase	I-Review	I-10	Review	604
focus on the results (e.g., the derviation in section 2.2.1).	I-Review	I-10	Review	604
<sep> <sep> <sep> Overall Evaluation	O	O	Review	604
===	O	O	Review	604
<sep> This paper provides an interesting set of analyses, but their value is not clear.	O	O	Review	604
<sep> There is no clear reason why a gradient or feature regularizer should improve	O	O	Review	604
low-shot learning performance.	O	O	Review	604
Despite that, experiments support that conclusion,	O	O	Review	604
the analysis is interesting by itself, and the analysis may help lead to a	O	O	Review	604
clearer explanation.	O	O	Review	604
<sep> <sep> The work is a somewhat novel extension and analysis of Hariharan and Girshick 2016.	O	O	Review	604
<sep> Some points are not completely clear, as mentioned above.	O	O	Review	604
To AnonReview3:	O	O	Reply	604
We appreciate your valuable comments and suggestions.	O	O	Reply	604
We have modified our paper accordingly and submitted a revised version on Jan 11th.	O	O	Reply	604
Sorry for the long delay.	O	O	Reply	604
It takes us a while to carry out experiments on the large-scale ImageNet benchmark.	O	O	Reply	604
<sep> <sep> * About why feature regularizer works and how it improves in case of low-shot learning:	O	O	Reply	604
This is the central question we try to answer in our paper, and we are carefully rethinking about this problem.	B-Reply	B-2	Reply	604
In the origin paper of SGM, the intuitive explanation is that a large gradient might be outlier and should be penalized.	I-Reply	I-2	Reply	604
<sep> In several supervised learning tasks in the paper, the CNN model achieves almost 100% accuracy on training and lower accuracy on testing.	I-Reply	I-2	Reply	604
We regard the performance discrepancy is actually from over-fitting, due to the complexity and parameter amount of neural network models.	I-Reply	I-2	Reply	604
The training/testing performance discrepancy could be reduced if a good regularizer (with both feature penalty and weight decay) is introduced.	I-Reply	I-2	Reply	604
The regularizer acts like a "max-margin" (an analogy with SVM) to limit the selection of parameter space and thus further reduce the "VC-dimension".	I-Reply	I-2	Reply	604
<sep> <sep> This is our preliminary guess and we have included some analysis in our revised version.	I-Reply	I-2	Reply	604
We are working on improving it.	I-Reply	I-2	Reply	604
<sep> <sep> * Comparison with Batch-Normalization:	O	O	Reply	604
Great thanks for the very good suggestion.	B-Reply	B-4	Reply	604
We add classification performance comparison between our feature penalty method (FP) and batch normalization (BN).	I-Reply	I-4	Reply	604
It is a little tricky to set up a fair comparison, since our model only includes regularization on the last hidden layer and BN modules are generally added on every layer.	I-Reply	I-4	Reply	604
For now we still keep BN layers in previous layers in our FP.	I-Reply	I-4	Reply	604
Our current comparison on supervised learning tasks indicates that FP and BN achieves similar performance on MNIST, CIFAR-10 and Omniglot; on ImageNet, BN is slightly better than FP (75% v.s.	I-Reply	I-4	Reply	604
74%).	I-Reply	I-4	Reply	604
Both BN and FP outperforms baseline CNN, and the best classification performance can be achieved with both modules added.	I-Reply	I-4	Reply	604
<sep> <sep> We include this part in our revised version.	I-Reply	I-4	Reply	604
We notice that FP can substitute BN in every layer rather than only the last layer.	I-Reply	I-4	Reply	604
We are working on a more complete comparison.	I-Reply	I-4	Reply	604
<sep> <sep> * More general forms of cost functions; Experiment setup of ImageNet; Inclusion of Matching Network in Table; Implementation of SGM and more:	O	O	Reply	604
Great thanks.	B-Reply	B-5	Reply	604
We carried out some derivation on other cost function forms and found that general convex costs (e.g., the L2 and cross entropy loss) will favor our model when SGD is applied in optimization.	I-Reply	I-5	Reply	604
<sep> We use our own implementation by TensorFlow to compare with original SGM paper.	I-Reply	I-5	Reply	604
We are currently asking the original authors for their setup on ImageNet and some details of their implementation.	I-Reply	I-5	Reply	604
We will make it clear in our final version.	I-Reply	I-5	Reply	604
<sep> We already include the performance of Matching Network in our revised paper.	I-Reply	I-5	Reply	604
<sep> We have modified some presentations and will carefully proof-read it.	I-Reply	I-5	Reply	604
<sep> <sep> * About the case study of XOR classification:	O	O	Reply	604
Thanks for the suggestion.	B-Reply	B-5	Reply	604
We did some re-derivation on the model and find that the choice of the uncommon non-linear layer h2=h11*h12 favors centralizing the features by moving "offsets".	I-Reply	I-5	Reply	604
Previously, we chose this special form on purpose to emphasize the whitening effect of feature penalty.	I-Reply	I-5	Reply	604
In case of common non-linear activation like ReLU, we find that the XOR classification becomes moving points on the simplex and regularization still helps.	I-Reply	I-5	Reply	604
We will try to work out an example to better demonstrate the influence of the regularizer intuitively and understand the problem better.	I-Reply	I-5	Reply	604
<sep> <sep> * Reorganization of the paper:	O	O	Reply	604
Admittedly, current version is a little bit too dense.	B-Reply	B-10	Reply	604
And our recent revised version is beyond page-limit (11 pages now).	I-Reply	I-10	Reply	604
<sep> We manage to include new experimental results and analysis in our revised paper.	I-Reply	I-10	Reply	604
<sep> It is a great idea to trim it down within 9 pages, with some detailed derivations left in supplemental materials.	I-Reply	I-10	Reply	604

This paper proposes analysis of regularization, weight Froebius-norm and feature L2 norm, showing that it is equivalent to another proposed regularization, gradient magnitude loss.	O	O	Review	604
They then argue that: 1) it is helpful to low-shot learning, 2) it is numerically stable, 3) it is a soft version of Batch Normalization.	O	O	Review	604
Finally, they demonstrate experimentally that such a regularization improves performance on low-shot tasks.	O	O	Review	604
<sep> <sep> First, this is a nice analysis of some simple models, and proposes interesting insights in some optimization issues.	B-Review	B-1	Review	604
Unfortunately, the authors do not demonstrate, nor argue in a convincing manner, that such an analysis extends to deep non-linear computation structures.	I-Review	I-1	Review	604
I feel like the authors could write a full paper about "results can be derived for œÜ(x) with convex differentiable non-linear activation functions such as ReLU", both via analysis and experimentation to measure numerical stability.	I-Review	I-1	Review	604
<sep> <sep> Second, the authors again show an interesting correspondance to batch normalization, but IMO fail to experimentally show its relevance.	B-Review	B-2	Review	604
<sep> <sep> Finally, I understand the appeal of the proposed method from a numerical stability point of view, but am not convinced that it has any effect on low-shot learning in the high dimensional spaces that deep networks are used for.	B-Review	B-3	Review	604
<sep> <sep> I commend the authors for contributing to the mathematical understanding of our field, but I think they have yet to demonstrate the large scale effectiveness of what they propose.	O	O	Review	604
At the same time, I feel like this paper does not have a clear and strong message.	O	O	Review	604
It makes various (interesting) claims about a number of things, but they seem more or less disparate, and only loosely related to low-shot learning.	O	O	Review	604
<sep> <sep> notes:	B-Review	B-4	Review	604
- "an expectation taken with respect to the empirical distribution generated by the training set", generally the training set is viewed as a "montecarlo" sample of the underlying, unknown data distribution \mathcal{D}.	I-Review	I-4	Review	604
- "we can see that our model learns meaningful representations", it gets a 6.5% improvement on the baseline, but there is no analysis of the meaningfulness of the representations.	I-Review	I-4	Review	604
<sep> - "Table 13.2" should be "Table 2".	I-Review	I-4	Review	604
<sep> - please be mindful of formatting, some citations should be parenthesized and there are numerous extraneous and missing spacings between words and sentences.	I-Review	I-4	Review	604
<sep> <sep> To AnonReview1:	O	O	Reply	604
We appreciate your valuable comments and suggestions.	O	O	Reply	604
We have modified our paper accordingly and submitted a revised version on Jan 11th.	O	O	Reply	604
Sorry for the long delay.	O	O	Reply	604
It takes us a while to carry out experiments on the large-scale ImageNet benchmark.	O	O	Reply	604
<sep> <sep> * About Non-linear cases to derive similar results:	O	O	Reply	604
Great thanks.	B-Reply	B-1	Reply	604
More general idea could be derived for (1) non-linear ReLU and max-pooling as well as (2) deeper models with 3+ layers.	I-Reply	I-1	Reply	604
Many other popular forms such as tanh could also be used.	I-Reply	I-1	Reply	604
<sep> We are working on this question and focus on ReLU case here.	I-Reply	I-1	Reply	604
The ReLU operator on a hidden "h" and changes the 1st order gradient of dE/dh.	I-Reply	I-1	Reply	604
A tricky problem is that ReLU is not 2nd-order differentiable with infinite Hessian.	I-Reply	I-1	Reply	604
If we substitute ReLU(x)=max{0,x} with a 2nd-order differentiable version CReLU(x)=ln(1+e^x), the revised Hessian of Eqn(11) is still convex and could be numerically more stable with regularizer added.	I-Reply	I-1	Reply	604
Also, for max-pooling case, the selected max-value among the max operation channels will dominate the computation and set the 1st and 2nd order derivatives of non-maximum elements to zero.	I-Reply	I-1	Reply	604
<sep> <sep> These are our preliminary extension to the more common non-linear scenario and added in the revised version.	B-Reply	B-1	Reply	604
Though linear case is also non-trivial due to the non-convexity of the optimization problem as a whole, a more general analysis will make our conclusion more complete.	I-Reply	I-1	Reply	604
We are working on the extension now.	I-Reply	I-1	Reply	604
<sep> <sep> * About comparison with batch-normalization	O	O	Reply	604
Great thanks for the very good suggestion.	B-Reply	B-2	Reply	604
This issue is raised by several reviewers and is of importance to evaluate the proposed model completely.	I-Reply	I-2	Reply	604
We add classification performance comparison between our feature penalty method (FP) and batch normalization (BN).	I-Reply	I-2	Reply	604
It is a little tricky to set up a fair comparison, since our model only includes regularization on the last hidden layer and BN modules are generally added on every layer.	I-Reply	I-2	Reply	604
For now we still keep BN layers in previous layers.	I-Reply	I-2	Reply	604
Our current comparison on supervised learning tasks indicates that the two methods achieves similar performance on MNIST, CIFAR-10 and Omniglot; on ImageNet, BN is slightly better than FP (75% v.s.	I-Reply	I-2	Reply	604
74%).	I-Reply	I-2	Reply	604
Both BN and FP outperforms baseline CNN, and the best classification performance can be achieved with both modules added.	I-Reply	I-2	Reply	604
<sep> We include this part in our revised version.	I-Reply	I-2	Reply	604
We notice that FP can substitute BN in every layer rather than only the last layer.	I-Reply	I-2	Reply	604
We are working on a more complete comparison.	I-Reply	I-2	Reply	604
<sep> <sep> * About why feature regularizer works in case of low-shot learning:	O	O	Reply	604
This is the central question we try to answer in our paper, and we are carefully rethinking about this problem from the angle of generalization ability.	B-Reply	B-3	Reply	604
<sep> <sep> In the origin paper of SGM, the intuitive explanation is that a large gradient might be outlier.	I-Reply	I-3	Reply	604
<sep> <sep> We observe that in the supervised learning the CNN model achieves almost 100% accuracy on training and lower accuracy on testing, especially the several low-shot scenarios experimentally.	I-Reply	I-3	Reply	604
We regard the performance discrepancy is actually from over-fitting, due to the complexity and parameter amount of neural network models.	I-Reply	I-3	Reply	604
The training/testing performance discrepancy could be reduced if a good regularizer (with both feature penalty and weight decay) is introduced.	I-Reply	I-3	Reply	604
The regularizer acts like a "max-margin" (an analogy to SVM, the distance from support vectors to the plane) to limit the selection of parameter space and thus further reduce the "VC-dimension".	I-Reply	I-3	Reply	604
<sep> <sep> This is our preliminary guess and we have included some analysis in our revised version.	I-Reply	I-3	Reply	604
We are working on improving it.	I-Reply	I-3	Reply	604
<sep> <sep> * Strict in presentation and reorganization of the paper:	O	O	Reply	604
Great thanks for the suggestions of presentation improvement.	B-Reply	B-4	Reply	604
We have already modified some of them accordingly in our revised version.	I-Reply	I-4	Reply	604
We will further proof-read to make it better.	I-Reply	I-4	Reply	604
<sep> Also, current version is a little bit too dense.	I-Reply	I-4	Reply	604
We manage to include new experimental results and analysis in our revised paper.	I-Reply	I-4	Reply	604
We will trim it down within 9 pages, with some detailed derivations left in supplemental materials.	I-Reply	I-4	Reply	604

The paper proposes to use a last-layer feature penalty as regularization on the last layer of a neural net.	O	O	Review	604
<sep> Although the equations suggest a weighting per example, dropping this weight (alpha_i) works equally well.	O	O	Review	604
<sep> The proposed approach relates to Batch Norm and weight decay.	O	O	Review	604
<sep> Experiments are given on "low-shot" settting.	O	O	Review	604
<sep> There seem to be two stories in the paper: feature penalty as a soft batch norm version, and low-shot learning; why is feature penalty specifically adapted to low-shot learning and not a more classical supervised task?	B-Review	B-1	Review	604
<sep> Regarding your result on Omniglot, 91.5, I believe it is still about 2% worse than the Matching Networks, which you refer to but don't put in Table 1.	B-Review	B-2	Review	604
Why?	I-Review	I-2	Review	604
<sep> Overall, the idea is simple but feels like preliminary: while it is supposed to be a "soft BN", BN itself gets better performance than feature penalty, and both together give even better results.	B-Review	B-3	Review	604
Is something still missing in the explanation?	I-Review	I-3	Review	604
<sep> <sep> -- edits after revised version:	O	O	Review	604
<sep> Thank you for adding more information to the paper.	O	O	Review	604
I feel it is still too long but hopefully you can reduce it to 9 pages as promised.	O	O	Review	604
However, I'm still not convinced the paper is ready to be accepted, mainly for the following reasons:	O	O	Review	604
- on Omniglot, the paper is still significantly far from the current state of the art.	B-Review	B-4	Review	604
<sep> - the new experiments do not really confirm/infirm the relationship with BN.	B-Review	B-5	Review	604
<sep> - you added an explanation of why FP works for low-shot setting, by showing it controls the VC dimension and hence is good to control overfitting with a small number of training examples, but this discussion is basic and does not really shed more light than the obvious.	B-Review	B-6	Review	604
<sep> I'm pushing up your score from 4 to 5 for the improved version, but I still think it is below acceptance level.	O	O	Review	604
<sep> <sep> <sep> To AnonReview2:	O	O	Reply	604
We would like to thank your reviews and suggestions.	O	O	Reply	604
We have modified our paper accordingly and submitted a revised version on Jan 11th.	O	O	Reply	604
Sorry for the long delay.	O	O	Reply	604
It takes us a while to carry out experiments on the large-scale ImageNet benchmark.	O	O	Reply	604
<sep> <sep> * About why feature regularizer works and how it improves in case of low-shot learning and normal supervised learning:	O	O	Reply	604
This is the central question we try to answer in our paper, and we are carefully rethinking about this problem.	B-Reply	B-1	Reply	604
In the origin paper of SGM, the intuitive explanation is that a large gradient might be outlier.	I-Reply	I-1	Reply	604
<sep> We observe that in supervised learning the CNN model achieves almost 100% accuracy on training and lower accuracy on testing experimentally.	I-Reply	I-1	Reply	604
Regarding the performance discrepancy from over-fitting, the training/testing performance discrepancy could be reduced if a good regularizer (with both feature penalty and weight decay) is introduced.	I-Reply	I-1	Reply	604
The regularizer acts like a "max-margin" to limit the selection of parameter space and thus further reduce the "VC-dimension".	I-Reply	I-1	Reply	604
<sep> <sep> This is our preliminary guess and we have included some analysis in our revised version.	I-Reply	I-1	Reply	604
We are working on a more strict answer.	I-Reply	I-1	Reply	604
<sep> <sep> * Comparison with Batch-Normalization:	O	O	Reply	604
Great thanks for the very good suggestion.	B-Reply	B-3	Reply	604
We add classification performance comparison between our feature penalty method (FP) and batch normalization (BN).	I-Reply	I-3	Reply	604
It is a little tricky to set up a fair comparison, since our model only includes regularization on the last hidden layer and BN modules are generally added on every layer.	I-Reply	I-3	Reply	604
For now we still keep BN layers in previous layers.	I-Reply	I-3	Reply	604
Our current comparison on supervised learning tasks indicates that the two methods achieves similar performance on MNIST, CIFAR-10 and Omniglot; on ImageNet, BN is slightly better than FP (75% v.s.	I-Reply	I-3	Reply	604
74%).	I-Reply	I-3	Reply	604
Both BN and FP outperforms baseline CNN, and the best classification performance can be achieved with both modules added.	I-Reply	I-3	Reply	604
<sep> <sep> We include this part in our revised version.	I-Reply	I-3	Reply	604
We notice that FP can substitute BN in every layer rather than only the last layer.	I-Reply	I-3	Reply	604
We are working on a more complete comparison.	I-Reply	I-3	Reply	604
<sep> <sep> * Inclusion of performance of Matching Network	O	O	Reply	604
We have already added it in our revised version.	O	O	Reply	604
<sep> <sep> * Though some of the analysis in our paper is preliminary on shallow networks, some insight could still be valuable and extended to more general network structures.	B-Reply	B-3	Reply	604
We wish the revised version could address some of the issues and we are now trying to improve our analysis to make it more general.	I-Reply	I-3	Reply	604

*Synopsis*:	O	O	Review	604
This paper focuses on current limitations of deploying RL approaches onto real world robotic systems.	O	O	Review	604
They focus on three main points: the need to use raw sensory data collected by the robot, the difficulty of handcrafted reward functions without external feedback, the lack of algorithms which are robust outside of episodic learning.	O	O	Review	604
They propose a complete system which addresses these concerns, combining approaches from the literature and novel improvements.	O	O	Review	604
They then provide an empirical evaluation and ablation testing of their approach and other popular systems, and show a demonstration on a real robotic system.	O	O	Review	604
<sep> Main Contributions:	O	O	Review	604
- A discussion of the current limitations of RL on real robotic systems	O	O	Review	604
- A framework for doing real world robotic RL without extra instrumentation (outside of the robot).	O	O	Review	604
<sep> <sep> *Review*:	O	O	Review	604
Overall, I think the paper is well written and provides some nice analysis of the current state of RL and robotics.	O	O	Review	604
I am not as familiar with the RL for robotics literature, but from some minor snooping around I believe these ideas to be novel and useful for the community.	O	O	Review	604
I have a few suggestions for the authors, and a few critical pieces I would like added to the main text.	O	O	Review	604
<sep> <sep> Critical additions:	O	O	Review	604
1.	B-Review	B-3	Review	604
I would like some more details on your simulation experiments.	I-Review	I-3	Review	604
Specifically:	I-Review	I-3	Review	604
- How many runs were your experiments?	I-Review	I-3	Review	604
<sep> - What are the error bars on your plots?	B-Review	B-3	Review	604
<sep> - What ranges of hyper-parameters did you test for tuning?	B-Review	B-3	Review	604
<sep> <sep> 2.	B-Review	B-1	Review	604
I would quite like the discussion of the real world tasks from the appendix to appear in the main text.	I-Review	I-1	Review	604
Specifically, giving the evaluation metrics you mentioned in the appendix.	I-Review	I-1	Review	604
<sep> <sep> Suggestions/Questions:	O	O	Review	604
<sep> S1: It is not clear if a VAE is the best choice for unsupervised representation learning for RL agents.	B-Review	B-2	Review	604
Although a reasonable choice, Yashua Bengio recently released a look at several unsupervised techniques for representation learning in Atari which you may want to look at: <a href="https://arxiv.org/pdf/1906.08226.pdf."	I-Review	I-2	Review	604
target="_blank" rel="nofollow">https://arxiv.org/pdf/1906.08226.pdf.</a>	I-Review	I-2	Review	604
<sep> Q1: Did you try any of the other approaches on the real robotics system?	B-Review	B-4	Review	604
Or was there no way to deploy these algorithms to your specific setup without instrumentation?	I-Review	I-4	Review	604
We thank the reviewer for their insightful and constructive feedback!	O	O	Reply	604
We have run additional hardware comparisons and quantitative evaluations as requested (Section 6.3) and have updated the paper according to your suggestions and comments to better discuss related work.	B-Reply	B-1	Reply	604
We respond to individual concerns in detail below:	O	O	Reply	604
<sep> ‚Äúdiscussion of the real world tasks from the appendix to appear in the main text.	O	O	Reply	604
‚Äù	O	O	Reply	604
-&gt; We have moved this discussion from the Appendix to Section 6.3.	B-Reply	B-1	Reply	604
Additional comparisons to a VICE (Fu et al) baseline have been added for real world experiments in Section 6.3, Fig 8.	I-Reply	I-1	Reply	604
We see that our algorithm is able to outperform this baseline on the real world tasks.	I-Reply	I-1	Reply	604
<sep> <sep> ‚ÄúIt is not clear if a VAE is the best choice for unsupervised representation learning for RL agents.	O	O	Reply	604
‚Äú	O	O	Reply	604
-&gt; While a VAE works well in the domains we considered in this paper, we certainly agree that a VAE is not necessarily the optimal choice for all RL domains.	B-Reply	B-2	Reply	604
We have updated Section 4.2 to reflect this explicitly, and have included references to Anand et al, Hjelm et al and Lee et al as you pointed out as alternative methods for representation learning.	I-Reply	I-2	Reply	604
We did not mean to claim that VAE‚Äôs were the only representation learning scheme that might suffice in this scenario, and many of the schemes suggested might also be effective.	I-Reply	I-2	Reply	604
<sep> <sep> ‚ÄúI would like some more details on your simulation experiments‚Ä¶‚Äù	O	O	Reply	604
-&gt; We have updated Section 6 and Appendix C to include details about the experimental setup, both in simulation and in the real world.	B-Reply	B-3	Reply	604
We have updated Fig 7 after removing a small visual artifact in the environment, which allows the baselines to perform a bit better, but still maintains the same trends.	I-Reply	I-3	Reply	604
<sep> -- The plots are averaged over 5 random seeds for each method and task	I-Reply	I-3	Reply	604
-- The (shaded) error regions correspond to the variance of the seeds for each curve	B-Reply	B-3	Reply	604
-- Appendix B has been updated to include information on ranges of hyperparameters tuned, in addition to the optimal values used to generate the plots in figures 7 &amp; 8	B-Reply	B-3	Reply	604
<sep> ‚ÄúQ1: Did you try any of the other approaches on the real robotics system?	O	O	Reply	604
Or was there no way to deploy these algorithms to your specific setup without instrumentation?‚Äù	O	O	Reply	604
-&gt; Yes we did add a new real-world comparison to the VICE baseline, as requested, in Fig 8.	B-Reply	B-4	Reply	604
We have updated Section 6.3 with a comparison in the real world on the valve rotation and bead manipulation tasks.	I-Reply	I-4	Reply	604
A quantitative evaluation corroborates findings from the simulated environments and shows that our method outperforms these methods in terms of sample efficiency and robustness.	I-Reply	I-4	Reply	604

This paper presents approaches to handle three aspects of real-world RL on robotics: (1)learning from raw sensory inputs (2) minimal reward design effort (3) no manual resetting.	O	O	Review	604
Key components:(1) learn a perturbation policy that allows the main policy to explore a wide variety of state. (	O	O	Review	604
2) learn a variational autoencoder to transform images to low dimensional space.	O	O	Review	604
<sep> <sep> Experiments in simulation on the physical robots are performed to demonstrate the effectiveness of these components.	O	O	Review	604
Close related work is also used for comparison.	O	O	Review	604
The only concern I have is that the tasks considered involve robots that can automatically reset themselves pretty easily.	B-Review	B-1	Review	604
I doubt that this will scale to unstable robots such as biped/quadruped, where once they fail, the recovering/resetting tasks will be as much or more difficult than the main locomotion tasks.	I-Review	I-1	Review	604
But I understand this is too much to address in one paper and limitation is also briefly discussed in the final section.	I-Review	I-1	Review	604
<sep> <sep> Overall I think this is a good paper and valuable to the community.	O	O	Review	604
<sep> <sep> We thank the reviewer for their encouraging feedback!	O	O	Reply	604
We are excited about further exploring the possibilities of this line of research!	O	O	Reply	604

The paper takes seriously the question of having a robotic system learning continuously without manual reset nor state or reward engineering.	O	O	Review	604
The authors propose a first approach using vison-based SAC, shown visual goals and VICE, and show that it does not provide a satisfactory solution.	O	O	Review	604
Then they add a random pertubation controller which brings the robot or simulated system away from the goal and a VAE to encode a compressed state, and show that it works better.	O	O	Review	604
<sep> <sep> The paper is a nice read, it contains useful messages thus I'm slightly in favor of accepting it, but I may easily change my mind as it suffers from serious weaknesses.	O	O	Review	604
<sep> <sep> First, and most importantly, the experimental study is very short, the authors have chosen to spend much more space on careful writing of the problem they are investigating.	B-Review	B-4	Review	604
<sep> <sep> To mention a few experimental weaknesses, in Section 6.2 the authors could have performed much more detailed ablation studies and stress in more details the impact of using the VAE alone versus using the random pertubation controller alone, they could say more about the goals they show to the system, etc.	B-Review	B-4	Review	604
There is some information in Figure 7, but this information is not exploited in a detailed way.	I-Review	I-1	Review	604
Furthermore, Figure 7 is far to small, it is hard to say from the legend which system is which.	I-Review	I-1	Review	604
<sep> <sep> About Fig.8, we just have a qualitative description, the authors claim that without instrumenting they cannot provide a quantitative study, which I don't find convincing: you may instrument for the sake of science (to measure the value of what you are doing, even if the real-world system won't use this instrumentation).	B-Review	B-2	Review	604
<sep> <sep> So the authors have chosen to spend more space on the positionning than on the empirical study, which may speak in favor of sending this paper to a journal or magazine rather than a technical conference.	O	O	Review	604
But there is an issue about the positionning too: the authors fail to mention a huge body of literature trying to address very close or just similar questions.	B-Review	B-5	Review	604
Namely, their concern is one the central leitmotives of Developmental Robotics and some of its "subfields", such as Lifelong learning, Open-ended learning, Continual learning etc.	I-Review	I-5	Review	604
The merit of the paper in this respect is to focus on a specific question and provide concrete results on this question, but this work should be positionned with respect to the broader approaches mentioned above.	I-Review	I-5	Review	604
The authors will easily find plenty of references in these domains, I don't want to give my favorite selection here.	I-Review	I-5	Review	604
<sep> <sep> Knowing more about the literature mentioned above, the authors could reconsider their framework from a multitask learning perspective: instead of a random perturbation controller, the agent may learn various controllers to bring the system into various goal states (using e.g. goal-conditioned policies), and switching from goal to goal to prevent the system fro keeping stuck close to some goal.	B-Review	B-6	Review	604
<sep> <sep> More local points:	O	O	Review	604
<sep> In the middle of page 5, it is said that the system does not learn properly just because it is stuck at the goal.	B-Review	B-7	Review	604
This information comes late, and makes the global message weaker.	I-Review	I-7	Review	604
<sep> <sep> in Fig.4, I would like to know what is the threshold for success.	B-Review	B-3	Review	604
<sep> <sep> <sep> We thank the reviewer for their detailed, insightful and constructive feedback!	O	O	Reply	604
We acknowledge a number of clarity issues in the presentation and positioning of our results, which make the actual results somewhat hard to understand.	O	O	Reply	604
We have updated the paper to make several of the points much more clear and have run additional hardware experiments to address the points raised in the review, as described in detail below:	O	O	Reply	604
<sep> ‚Äúthey could say more about the goals they show to the system, etc.	O	O	Reply	604
‚Äù	O	O	Reply	604
-&gt; We have added some visualizations about goals provided to the system to Appendix C.	B-Reply	B-1	Reply	604
<sep> ‚Äúyou may instrument for the sake of science (to measure the value of what you are doing, even if the real-world system won't use this instrumentation).‚Äù	O	O	Reply	604
-&gt; Yes, this is a good point!	B-Reply	B-2	Reply	604
We have now performed these experiments on the hardware and have included additional comparisons to baselines on hardware in Section 6.3, Fig 8.	I-Reply	I-2	Reply	604
We find that the same trends observed in simulation hold on the hardware as well.	I-Reply	I-2	Reply	604
<sep> <sep> ‚ÄúIn Fig.4, I would like to know what is the threshold for success.	O	O	Reply	604
‚Äù	O	O	Reply	604
-&gt; Fig.4 analyzes the sample complexity for the task of valve rotation.	B-Reply	B-3	Reply	604
The experiment is considered successful when the learned policy achieves average training performance of less than 0.15 in pose distance (defined in Appendix C.1.3) across 3 seeds.	I-Reply	I-3	Reply	604
Fig.4 has now been updated to clarify this.	I-Reply	I-3	Reply	604
<sep> <sep> ‚ÄúIn Section 6.2 the authors could have performed much more detailed ablation studies and stress in more details the impact of using the VAE alone versus using the random perturbation controller alone‚Äù	O	O	Reply	604
-&gt; We have modified the Figure 7 legend and caption to make it more legible, and a discussion on the effects of the individual components based on these ablation experiments is now included in Section 6.2 in the updated manuscript.	B-Reply	B-4	Reply	604
We have also updated the results after removing a small visual artifact in the environment, which allows the baselines to perform a bit better, but still maintains the same trends.	I-Reply	I-4	Reply	604
We agree that the presentation of data in Figure 7 was hard to parse, and many of the comparisons (including the two requested by the reviewer) that we did actually already perform were hard to discern from the figure.	I-Reply	I-4	Reply	604
The methods marked [VAE + VICE] and [RND + VICE] show the performance curves corresponding to the ablations suggested.	I-Reply	I-4	Reply	604
A discussion on comparisons to explicit goal-based reset mechanisms and goal-conditioned policies has also been added to Section 6.2.	I-Reply	I-4	Reply	604
<sep> <sep> ‚Äúthere is an issue about the positioning too: the authors fail to mention a huge body of literature trying to address very close or just similar questions...central motives of Developmental Robotics and some of its "subfields"	O	O	Reply	604
-&gt; We have expanded our related work with appropriate discussion with respect to the field of developmental robotics.	B-Reply	B-5	Reply	604
The goal of our work is to enable reinforcement learning systems to handle the practicalities of learning in the real world without human instrumentation or interruption, even for a single task setting, without multi-task considerations.	I-Reply	I-5	Reply	604
The insights we make should also be applicable for developmental robotics algorithms!	I-Reply	I-5	Reply	604
Though our investigation doesn‚Äôt touch on all aspects of developmental robotics such as lifelong learning, open-ended learning, psychology, cognition etc.,	I-Reply	I-5	Reply	604
our proposed work R3L does bear strong relationship with respect to continual learning, intrinsic motivation, perceptual development, and sensory-motor development involving proprioceptive manipulation.	I-Reply	I-5	Reply	604
We thank the reviewer for bringing out this interesting connection, and have added appropriate citations in the text.	I-Reply	I-5	Reply	604
<sep> <sep> ‚Äúauthors could reconsider their framework from a multitask learning perspective...agent may learn various controllers to bring the system into various goal states and switching from goal to goal to prevent the system for keeping stuck close to some goal.	O	O	Reply	604
‚Äù	O	O	Reply	604
-&gt; We agree that this is indeed an interesting and valuable perspective on this problem, and we have added some discussion of this to Section 6.2.	B-Reply	B-6	Reply	604
We found in our experimental study that when we consider the case of using 2 goals, and switching between them (the Eysenbach et al comparison in Fig 7), it was not as effective and robust as using the perturbation controller.	I-Reply	I-6	Reply	604
While this scheme chooses between only 2 goal options, and a more involved scheme could be chosen to pick multiple different goals, the performance of such an algorithm is dependent on the specific choice of goals.	I-Reply	I-6	Reply	604
We find that the simpler solution via the perturbation controller can be very effective without the need for multiple meaningful alternative goals to be specified, although a better algorithm for self-supervised multi-goal selection is an interesting avenue for future work.	I-Reply	I-6	Reply	604

* Overview*	O	O	Review	26
The paper tackles instance segmentation for images of beef cattle.	O	O	Review	26
<sep> Mostly the paper is badly written and important details of the proposed approach are missing.	O	O	Review	26
Overall the results are extremely underwhelming on the public benchmarks, and the gains on the in-house cattle dataset are very small.	O	O	Review	26
Most importantly, the novelty of the approach is non-existent.	O	O	Review	26
See below for clarifications.	O	O	Review	26
<sep> <sep> * Details*	O	O	Review	26
The authors build on FCN, a method designed for instance segmentation as they correctly mention in the intro.	B-Review	B-1	Review	26
During the description of the approach, they mention that they predict blobs from the FCN output.	I-Review	I-1	Review	26
There is no mention of what that is, how they obtain it from the semantic mask predictions.	I-Review	I-1	Review	26
Unless I am missing this information, this is a crucial point.	I-Review	I-1	Review	26
Moving beyond that important detail, the authors propose two modules, which are essentially hard negative mining (similar to Training Region-based Object Detectors with Online Hard Example Mining, Shrivastava et al CVPR 2016) and another layer of classification.	O	O	Review	26
<sep> If I were to ignore the extremely limited novelty of the proposed approach, the results (Table 1) are not compelling at all.	O	O	Review	26
The authors build on a shallow architecture and show underwhelming results on the public benchmarks.	O	O	Review	26
On top of that, the hyper-parameters used for computing published approaches are suboptimal (e.g. image size) which lead to lower performance than the ones reported by the original papers.	O	O	Review	26
<sep> <sep> Last, while the above review sounds harsh I want to emphasize that it is quite legitimate to study a problem of particular interest (here image of beef cattle) and to care to obtain good results with low compute and at a low cost presumably.	O	O	Review	26
However, a publication is not necessarily justified based on the observations.	O	O	Review	26
I truly believe that there is people that will be interested in this approach (e.g. farmers, producers etc.)	O	O	Review	26
but a publication at an ICLR workshop is not the right venue for this paper.	O	O	Review	26
The network was not designed to compete against leaders in MS COCO/Pascal datasets, it is specific to this problem, like tumor segmentation or similar.	B-Reply	B-1	Reply	26
Results for MS COCO and Pascal were produced for reference, which is stated in the paper.	I-Reply	I-1	Reply	26
On our test data finetuned state-of-the-art algorithm Mask R-CNN produces 68.7% AP at 0.5 threshold and 27.7% mAP (at 50%:95% thresholds) vs FCN+MaskExtractor+BadOverlapsExtractor producing 69.4% AP at 0.5 threshold and 35.2% mAP (at 50%:95% thresholds).	I-Reply	I-1	Reply	26
Reported improvements in benchmark datasets are rarely larger.	I-Reply	I-1	Reply	26
<sep> <sep> Giving all the details is simply intractable in a 3-page paper, it was intended to demonstrate the applicability and the potential of the idea of transforming (ignore pixels) and extracting additional information from the ground truth mask (count the number of 'bad' overlaps, e.g. 1 prediction/2+ cows or 2+ predictions/1 cow).	O	O	Reply	26
There are two additional modules, one that learns good predictions and one that learns which ones are 'bad'.	O	O	Reply	26
They were intended to get the network to output single prediction (mask) per single observation (cow, in this case).	O	O	Reply	26
This solution is perfectly transferable to any object vs background problem with heavy partial occlusion.	O	O	Reply	26
I didn't use any negative hardmining: only positive blobs were segmented in the ground truth.	O	O	Reply	26

Summary:	O	O	Review	20462
This paper explores the properties of an auto-encoder to behave as an associative memory retrieval mechanism.	O	O	Review	20462
The authors show really interesting results where they are able to retrieve a small subset of encoded images (mnist) by giving the autoencoder random noise.	O	O	Review	20462
They also show they can retrieve full videos by giving the autoencoder the output frame from the previous timestep.	O	O	Review	20462
<sep> <sep> The overall problem is a really interesting one which is to try to develop associative memory, retrieval models.	O	O	Review	20462
<sep> <sep> Decision:	O	O	Review	20462
Reject	O	O	Review	20462
<sep> Reasons:	O	O	Review	20462
1.	O	O	Review	20462
Although the work is interesting, the only related work the authors cover is hopfield networks.	B-Review	B-1	Review	20462
A cursory search indicates that this has been done before (k. Niki IEEE, Trischler 2016, M.A.Kramer 1992).	I-Review	I-1	Review	20462
<sep> <sep> Improvement:	O	O	Review	20462
1.	O	O	Review	20462
A more thorough discussion of related work would be helpful.	B-Review	B-1	Review	20462
<sep> 2.	B-Review	B-1	Review	20462
A direct qualitative comparison to related work would also be helpful.	I-Review	I-1	Review	20462
We thank the reviewer for the comments and for emphasizing that the problem we consider is interesting.	O	O	Reply	20462
<sep> In writing our paper, we have performed a careful literature review.	B-Reply	B-1	Reply	20462
<sep> <sep> The phenomenon that networks trained using standard optimization methods store training examples as attractors or sequences of examples as limit cycles has to the best of our knowledge not been observed before in the literature.	I-Reply	I-1	Reply	20462
<sep> <sep> Thank you for the references, but after carefully checking, none of the papers make the observation that training examples become attractors: (1) M.A. Kramer merely introduces and defines autoencoders.	I-Reply	I-1	Reply	20462
(2) K. Niki is work from 1989 that studies small networks in the binary input setting. (	I-Reply	I-1	Reply	20462
3) Trischler 2016 studies how to train recurrent networks to model dynamical systems.	I-Reply	I-1	Reply	20462
<sep> <sep> We hope this addresses your concerns and please let us know if there are any other questions.	O	O	Reply	20462

This paper empirically demonstrates that DNNs can be trained to be identity mappings for small quantities of samples.	O	O	Review	20462
It also demonstrates that for many parameterizations, these identity DNNs also have a small number of attractors, iterative fixed points, and can also learn short circular sequences of examples.	O	O	Review	20462
The paper is well written and easy to understand, although the presentation could be improved a bit (see comments).	O	O	Review	20462
Its contents aren't particularly novel in terms of ideas, but they investigate memorization and attractors much further than previous studies.	O	O	Review	20462
In a way, the memorization results are unsurprising.	O	O	Review	20462
We know that DNNs can memorize perfectly, including sequences, so it is natural that by increasing capacity, at some point they should be able to memorize entire images (in fact this is what Zhang et al (2019)'s Figure 1 appears to be showing).	O	O	Review	20462
The more novel and surprising aspect of this is that DNNs would learn such strong (and so few) attractor basins.	O	O	Review	20462
The fact that deep autoencoders could have attractors centered on the training points has been postulated before (see [1]), but this work makes a stronger case for it.	O	O	Review	20462
A crucial aspect that is missing from this paper in order for me to give in an accept is that there is very little about how this paper positions itself in the current literature.	O	O	Review	20462
There could be much more discussion about related work, and much more discussion about the impacts of these findings.	O	O	Review	20462
I have given this paper a 'weak reject' mark but I think with some work this paper could be of interest to many.	O	O	Review	20462
To reiterate, I am unable to see anything wrong with this paper, but at the same time I am unable to see how impactful these findings are.	O	O	Review	20462
Detailed comments:	O	O	Review	20462
- It's interesting that DNNs can implement associative memory, but what is the cost of doing that?	O	O	Review	20462
Should we be using that in practice?	O	O	Review	20462
Since there is no sense of how costly the presented experiments are, it is hard to tell.	O	O	Review	20462
- Again, these results are interesting, but after some time pondering about it, I can't really convince myself that knowing the results of this paper will be beneficial to future research.	O	O	Review	20462
That being said, there are many areas of Machine Learning that I am unfamiliar with.	O	O	Review	20462
It should be part of the paper to familiarize readers with areas where these results could be impactful.	O	O	Review	20462
- "the function interpolates the training images" not sure what this means.	O	O	Review	20462
Interpolation means making a prediction for a point `u` that is "between" two points `x,y` with known values	O	O	Review	20462
- "black and white" should be "grayscale" if values are in [0,1]	O	O	Review	20462
- Figure 2b is interesting, but I wonder what happens if e.g. a perturbed version of e.g. Example 6 is fed.	O	O	Review	20462
Presumably since Example 6 is not an attractor (Jacbian with an eigeinvalue &gt; 1), it should converge to another example.	O	O	Review	20462
- Figure 2b's caption numbers, which say you use 1k example, to not correspond to numbers earlier in the text, which say you use 10k examples.	O	O	Review	20462
- "Since overparameterized autoencoders interpolate the training data", again this is a fairly important assumption and it needs to be defined very clearly, because it could mean many things.	O	O	Review	20462
- "it is essential that we interpolate to numerical precision", I don't think you are using the word "interpolate" correctly, do you mean "inference"? "	O	O	Review	20462
train"?	O	O	Review	20462
- Adam citation should be "Adam: A Method for Stochastic Optimization, Diederik P. Kingma, Jimmy Ba", not Goodfellow et al RMSprop should also have a citation, Hinton et al 2012	O	O	Review	20462
- ReLU citation should be "Rectified linear units improve restricted Boltzmann machines, Nair &amp; Hinton", Leaky ReLU should be Maas et al 2013, SELU should be Klambauer et al 2017.	O	O	Review	20462
- The combination of section 3.1 and Figure 3 doesn't make it clear if models trained with Adam and RMSprop have weight decay or not.	O	O	Review	20462
Can you clarify?	O	O	Review	20462
- "Note that a minimum width of 100 is needed to allow for interpolation."	O	O	Review	20462
Again I think you mean "learning" rather than "interpolation".	O	O	Review	20462
- You say that you trained black and white images, but all the images of CIFAR10 in the figures are colored, including the inputs and outputs.	O	O	Review	20462
Can you clarify why?	O	O	Review	20462
- You might be interested in [2], which is much older work about perceptrons, but still relevant to what is studied here.	O	O	Review	20462
- The linked supplemental material gives a 404 for me.	O	O	Review	20462
I replicated the MNIST Figure 6 experiment.	O	O	Review	20462
I was unable to replicate exactly your results but they were similar enough.	O	O	Review	20462
In particular, the activation function choice seems to be critical.	O	O	Review	20462
[1] The Potential Energy of an Autoencoder, Hanna Kamyshanska, Roland Memisevic	O	O	Review	20462
[2] Basins of Attraction in a Perceptron-like Neural Network, Werner Krauth, Marc Mezard, Jean-Pierre Nadal	O	O	Review	20462
Thank you for the careful reading of our paper and helpful comments.	O	O	Reply	20462
Comparison to Zhang et al, 2019.	O	O	Reply	20462
We would like to point out that the first arXiv version of our paper precedes the first version of Zhang, et al  Just like our paper, Zhang et al has only been presented in a workshop, which does not count as a refereed publication.	O	O	Reply	20462
Furthermore, a version of Zhang et al is concurrently under review in this same venue.	O	O	Reply	20462
Therefore, we strongly feel that our paper should be reviewed on its own merits and not compared against Zhang, et al	O	O	Reply	20462
In addition, we would like to clarify the following comment:	O	O	Reply	20462
‚ÄúThe fact that deep autoencoders could have attractors centered on the training points has been postulated before (see [1])‚Äù.	O	O	Reply	20462
It is well-known that attractors can be used as a form of memory, e.g., Hopfield networks.	O	O	Reply	20462
However, the work [1] and to the best of our knowledge other work in this area do not observe the central phenomenon of our submission, the emergence of attractors in overparameterized networks trained using standard optimization methods.	O	O	Reply	20462
In the following, we provide a point-by-point response to the detailed comments provided by the reviewer.	O	O	Reply	20462
(1) The computational cost of these methods is an interesting question as a connection to biological memory, but at this point, we concentrate on identifying the phenomenon.	O	O	Reply	20462
(2) With respect to the impact of our results: (a) A question of considerable interest in machine learning is identifying the inductive bias of neural networks.	O	O	Reply	20462
In the overparameterized setting, a neural network can achieve zero training error.	O	O	Reply	20462
There are many functions that can achieve zero training error.	O	O	Reply	20462
What are the functions learned by a neural network, i.e. what is its inductive bias?	O	O	Reply	20462
Our study identifies a novel form of inductive bias of deep networks that persists across different architectures: deeper networks tend to store training examples as attractors.	O	O	Reply	20462
This means that deep networks learn functions that are contractive at the training examples, a form of self-regularization. (	O	O	Reply	20462
b) There is considerable interest in understanding the similarities and differences in artificial and biological neural networks.	O	O	Reply	20462
Our results provide a biologically plausible mechanism for memory retrieval.	O	O	Reply	20462
Namely, we show that iterating a trained autoencoder allows retrieving stored images. (	O	O	Reply	20462
c) Our results suggest an interesting hypothesis for biological neural networks, which we are currently following up on with neuroscientists.	O	O	Reply	20462
We demonstrated that it is ‚Äúeasier‚Äù for an artificial neural network to store sequences of images instead of individual images, or more precisely, smaller networks can be used to store sequences of images as compared to the same number of single images.	O	O	Reply	20462
Similar phenomena may be observed in biological neural networks.	O	O	Reply	20462
We thank the reviewer for this comment; we will add these points to the introduction/discussion sections in order to clarify the possible impact of our work.	O	O	Reply	20462
(3) By interpolation we mean that the training data is fit exactly, i.e., the training loss is 0.	O	O	Reply	20462
After training, an overparameterized neural network can interpolate the data, i.e., it  implements a continuous function that perfectly fits the training data.	O	O	Reply	20462
The term interpolation has been used in this way in a number of recent works, e.g. in: <a href="https://arxiv.org/abs/1806.05161," target="_blank" rel="nofollow">https://arxiv.org/abs/1806.05161,</a> <a href="https://arxiv.org/abs/1712.06559," target="_blank" rel="nofollow">https://arxiv.org/abs/1712.06559,</a> <a href="https://arxiv.org/abs/1903.08560," target="_blank" rel="nofollow">https://arxiv.org/abs/1903.08560,</a> <a href="https://arxiv.org/abs/1906.11300," target="_blank" rel="nofollow">https://arxiv.org/abs/1906.11300,</a> <a href="https://arxiv.org/abs/1810.07288."	O	O	Reply	20462
target="_blank" rel="nofollow">https://arxiv.org/abs/1810.07288.</a> We will make sure to clarify this in our paper.	O	O	Reply	20462
(4) We will change the text to ‚Äúgrayscale‚Äù.	O	O	Reply	20462
(5) You are correct: Since Figure 2b Example 6 is not an attractor, iterating the network on a perturbed version of this image will lead to a different training example.	O	O	Reply	20462
(6) Thanks for the careful reading of our paper.	O	O	Reply	20462
Figure 2b‚Äôs caption is correct as is.	O	O	Reply	20462
Earlier in the paper, we performed one experiment with 10k examples to demonstrate the robustness of this phenomenon.	O	O	Reply	20462
Since iterating 10k examples in every experiment is too computationally expensive and provides little additional insight, we only performed this large experiment once.	O	O	Reply	20462
(7) See (3).	O	O	Reply	20462
(8, 9) Since these are standard practice, we initially felt that it would be sufficient to refer to only one reference (the Deep Learning Book), but agree with the proposed change to add these citations to our paper.	O	O	Reply	20462
(10) We do not use weight decay in Adam or RMSProp.	O	O	Reply	20462
(11) See (3).	O	O	Reply	20462
(12) All of the figures provided are color CIFAR10 images, as we wanted to provide illustrative examples for the figures (these settings only use 10 training examples).	O	O	Reply	20462
The footnote on page 4 explains our reason for using grayscale images when running experiments on 100 images.	O	O	Reply	20462
(13) Thank you for pointing this out.	O	O	Reply	20462
(14) There seemed to be a glitch with the link, but it seems to be ok now.	O	O	Reply	20462
Please let us know if it is still not working.	O	O	Reply	20462
Thank you, again, for the careful reading and helpful comments.	O	O	Reply	20462
Please let us know if you have any further questions.	O	O	Reply	20462

The paper studies a phenomenon of unusual memorisation in deep overparametrized neural networks.	O	O	Review	20462
<sep> Authors observe that, if an auto-encoder overfits to machine precision on a number of images, they can be reliably decoded from random noise and that it is even possible to memorise this way a sequence of images.	O	O	Review	20462
<sep> Essentially, images from such a training set become attractors for the mapping defined by the auto-encoder.	O	O	Review	20462
<sep> The impact of network size, nonlinearity and initialization is studied and, quite surprisingly, very unusual trigonometric non-linearities performed the best.	O	O	Review	20462
<sep> <sep> I find the studied phenomenon rather interesting and the analysis well-performed, but I am not sure how practically important is this work.	B-Review	B-2	Review	20462
<sep> First, I would argue that to call the overfit auto-encoder a function associative memory, it must be able to retrieve stored images not just from random noise, but from a somehow distorted or partially known version.	I-Review	I-2	Review	20462
<sep> Otherwise we are just left with a ridiculously large network that can only recall a handful of images we could store in the raw format using much less numbers.	I-Review	I-2	Review	20462
<sep> Second, training until convergence takes prohibitively long time.	B-Review	B-3	Review	20462
<sep> <sep> I would be also interested to at least an interesting discussion, if not an answer, to the question of why and how exactly trained images become attractors.	I-Review	I-3	Review	20462
<sep> <sep> In terms of novelty, it feels like Zhang et al, 2019 already studied a very similar phenomenon and the submitted paper does not add much to understanding of memorisation in neural networks.	B-Review	B-1	Review	20462
However, memorization of sequences was indeed a surprise.	I-Review	I-1	Review	20462
<sep> <sep> Overall, I do not have a strong opinion on rejecting the paper, it just feels like more work in this direction will make the paper significantly better.	O	O	Review	20462
We thank the reviewer for the comments and  emphasizing that the phenomenon we identify is interesting and that our analysis is well performed.	O	O	Reply	20462
<sep> Regarding the comparison to Zhang et al, 2019:  We would like to point out that the first arXiv version of our paper precedes the first version of Zhang, et al Just like our paper, Zhang, et al has only been presented in a workshop, which does not count as a refereed publication.	B-Reply	B-1	Reply	20462
Furthermore, a version of Zhang, et al is concurrently under review in this same venue.	I-Reply	I-1	Reply	20462
Therefore, we strongly feel that our paper should be reviewed on its own merits and not compared against Zhang, et al	I-Reply	I-1	Reply	20462
<sep> In terms of the importance of this result, our method is the first for training a model to store and recover high dimensional inputs up to numerical precision.	B-Reply	B-2	Reply	20462
Moreover, there is considerable interest in understanding the similarities and differences in artificial neural networks and biological neural networks.	I-Reply	I-2	Reply	20462
Our results point to a biologically plausible mechanism for memory retrieval (while the biological plausibility of the training process still remains an open question).	I-Reply	I-2	Reply	20462
Namely, we show that iterating a trained autoencoder allows retrieving stored images.	I-Reply	I-2	Reply	20462
Our results also suggest an interesting hypothesis for biological neural networks, which we are currently following up on with neuroscientists.	I-Reply	I-2	Reply	20462
We demonstrated that it is ‚Äúeasier‚Äù for an artificial neural network to store sequences of images instead of individual images, or more precisely, smaller networks can be used to store sequences of images as compared to the same number of single images.	I-Reply	I-2	Reply	20462
Similar phenomena may be observed in biological neural networks.	I-Reply	I-2	Reply	20462
<sep> Moreover, a question of considerable interest in machine learning is the identification of the inductive bias of neural networks.	B-Reply	B-3	Reply	20462
In the overparameterized setting, a neural network can achieve zero training error.	I-Reply	I-3	Reply	20462
There are many different functions that can achieve zero training error.	I-Reply	I-3	Reply	20462
What are the functions learned by a neural network, i.e. what is its inductive bias?	I-Reply	I-3	Reply	20462
Our study identifies a novel form of inductive bias of deep networks that persists across different architectures: deeper networks tend to store training examples as attractors.	I-Reply	I-3	Reply	20462
This means that deep networks learn functions that are contractive at the training examples, a form of self-regularization.	I-Reply	I-3	Reply	20462
<sep> <sep> By the definition of an attractor, iterating the network on points within an open set around an attractor will converge to the attractor.	I-Reply	I-3	Reply	20462
Hence, the model does represent associative memory as small perturbations to an attractor (i.e. a point within this open set) will converge to the attractor upon iterating the network.	I-Reply	I-3	Reply	20462
Importantly, this condition is a mathematical guarantee for associative memory.	I-Reply	I-3	Reply	20462
Hence, the networks learned do implement associative memory mechanisms with mathematically verifiable conditions on which training examples are attractors.	I-Reply	I-3	Reply	20462
We will add some experiments to highlight this in the revision.	I-Reply	I-3	Reply	20462

The authors propose to use the combination of model ensemble and MC dropout in Bayesian deep active learning.	O	O	Review	865
They empirically show that there exists the mode collapse problem due to the MC dropout which can be regarded as a variational approximation.	O	O	Review	865
The authors introduce an ensemble of MC-Dropout models with different initialization to remedy this mode collapse problem.	O	O	Review	865
<sep> <sep> The paper is clearly written and easy to follow.	O	O	Review	865
It is interesting to empirically show that the mode collapse problem of MC-Dropout is important in active learning.	O	O	Review	865
<sep> The major concern I have is that the ensemble of MC-Dropout models is not an approximation of the posterior anymore.	B-Review	B-1	Review	865
Each MC-Dropout model is an approximation of the posterior, but the ensemble of them may not.	I-Review	I-1	Review	865
Therefore, it is a little misleading to still call it Bayesian active learning.	I-Review	I-1	Review	865
Also, the ensemble of MC-Dropout models does not have the theoretic support from the Bayesian perspective.	I-Review	I-1	Review	865
<sep> <sep> The motivation for the proposed method is to solve the mode collapse problem of MC-Dropout, but using ensemble loses the Bayesian support benefit of MC-Dropout.	B-Review	B-2	Review	865
So it seems not a reasonable solution for the mode collapse problem of MC-Dropout.	I-Review	I-2	Review	865
It is not clear to me why we need to add MC-Dropout to the ensemble.	I-Review	I-2	Review	865
What is the benefit of DEBAL over an ensemble method if both of them do not have Bayesian theoretic support?	I-Review	I-2	Review	865
<sep> <sep> In terms of the empirical results, the better performance of DEBAL compared to a single MC-Dropout model is not supervising as Beluch et al (2018) already demonstrated that an ensemble is better than a single MC-Dropout.	B-Review	B-3	Review	865
While the improvement of DEBAL compared to an ensemble is marginal but is reasonable.	I-Review	I-3	Review	865
<sep> <sep> The labels of figures are hard to read.	B-Review	B-4	Review	865
<sep> <sep> We thank the reviewer for its valuable and insightful comments.	O	O	Reply	865
<sep> <sep> We are reviewing our work from a theoretical point of view and will update the paper very soon to reflect this.	O	O	Reply	865
<sep> Even though we have not yet proved the above, we have empirically showed that the benefit of DEBAL over plain ensemble methods consists of a better representation of uncertainty, that is paramount in active learning.	B-Reply	B-2	Reply	865
By better we mean	I-Reply	I-2	Reply	865
1) more meaningful and closer to what one would expect (Fig 4 & Fig 6 (right))	I-Reply	I-2	Reply	865
2) better calibrated (Fig 6 (left)).	I-Reply	I-2	Reply	865
Our initial aim was not to compare stochastic ensembles with deterministic or single MC-dropout but to correct for the mode collapse issue in estimating posteriors with MC-dropout.	I-Reply	I-2	Reply	865
We have empirically shown that adding ensembles to this, greatly improves the MC-dropout technique and outperforms the deterministic ensembles as well.	I-Reply	I-2	Reply	865
<sep> We had similar doubts about the benefit of adding MC-Dropout to an ensemble.	I-Reply	I-2	Reply	865
Therefore, we contrasted the performance of DEBAL against the plain ensemble method and showed empirically that DEBAL gives rise to better measures of uncertainty.	I-Reply	I-2	Reply	865
Finally, as we strive to make our assumptions hold theoretically, we agree that adding theoretical Bayesian support to our method is of great importance if we are to further improve the understanding of Bayesian deep learning.	I-Reply	I-2	Reply	865
<sep> <sep> For your final point, although Beluch et al (2018) showed better performance for ensembles, we have shown this in the context of a small dataset problem (i.e. the size of the final dataset acquired during AL is only a small fraction of the entire available unlabelled dataset), which we believe is more relevant to the real world cases if AL is to become a widely used method.	B-Reply	B-3	Reply	865
<sep> <sep> As for the figures, we are aware of this and will try to make them more clear in a revised version.	B-Reply	B-4	Reply	865

The paper shows that Bayesian neural networks, trained with Dropout MC (Gal et al) struggle to fully capture the posterior distribution of the weights.	O	O	Review	865
<sep> This leads to over-confident predictions which is problematic particularly in an active learning scenario.	O	O	Review	865
<sep> To prevent this behavior, the paper proposes to combine multiple Bayesian neural networks, independently trained with Dropout MC, to an ensemble.	O	O	Review	865
<sep> The proposed method achieves better uncertainty estimates than a single Bayesian neural networks model and improves upon the baseline in an active learning setting for image classification.	O	O	Review	865
<sep> <sep> <sep> The paper addresses active deep learning which is certainly an interesting research direction since in practice, labeled data is notoriously scarce.	O	O	Review	865
<sep> <sep> However, the paper contains only little novelty and does not provide sufficiently new scientific insights.	B-Review	B-1	Review	865
<sep> It is well known from the literature that combining multiply neural networks to an ensemble leads to better performance and uncertainty estimates.	I-Review	I-1	Review	865
<sep> For instance, Lakshminarayanan et al[1] showed that Dropout MC can produce overconfident wrong prediction and, by simply averaging prediction over multiple models, one achieves better performance and confidence scores.	I-Review	I-1	Review	865
Also, Huand et al [2] showed that by taking different snapshots of the same network at different timesteps performance improves.	I-Review	I-1	Review	865
<sep> It would also be great if the paper could related to other existing work that uses Bayesian neural networks in an active learning setting such as Bayesian optimization [3, 4] or Bandits[5].	B-Review	B-2	Review	865
<sep> <sep> Another weakness of the paper is that the empirical evaluation is not sufficiently rigorous:	O	O	Review	865
<sep> 1) Besides an comparison to the work by Lakshminarayanan et al, I would also like to have seen a comparison to other existing Bayesian neural network approaches such as stochastic gradient Markov-Chain Monte-Carlo methods.	B-Review	B-3	Review	865
<sep> <sep> 2) To provide a better understanding of the paper, it would also be interesting to see how sensitive it is with respect to the ensemble size M.	B-Review	B-4	Review	865
3) Furthermore, for the experiments only one neural network architecture was considered and it remains an open question, how the presented results translate to other architectures.	B-Review	B-5	Review	865
The same holds for the type of data, since the paper only shows results for image classification benchmarks.	I-Review	I-5	Review	865
<sep> 4) Figure 3: Are the results averaged over multiple independent runs?	B-Review	B-6	Review	865
If so, how many runs did you perform and could you also report confidence intervals?	I-Review	I-6	Review	865
Since all methods are close to each other, it is hard to estimate how significant the difference is.	I-Review	I-6	Review	865
<sep> <sep> <sep> <sep> [1] Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles	O	O	Review	865
Balaji Lakshminarayanan, Alexander Pritzel, Charles Blundel	O	O	Review	865
NIPS 2017	O	O	Review	865
<sep> [2] Gao Huang and Yixuan Li and Geoff Pleiss and Zhuang Liu and John E. Hopcroft and Kilian Q. Weinberger	O	O	Review	865
Snapshot Ensembles: Train 1, get {M} for free}	O	O	Review	865
ICLR 2017	O	O	Review	865
<sep> [3] Bayesian Optimization with Robust Bayesian Neural Networks	O	O	Review	865
J. Springenberg and A. Klein and S.Falkner and F. Hutter	O	O	Review	865
NIPS 2016	O	O	Review	865
[4] J. Snoek and O. Rippel and K. Swersky and R. Kiros and N. Satish and N. Sundaram and M. Patwary and Prabhat and R. Adams	O	O	Review	865
Scalable Bayesian Optimization Using Deep Neural Networks	O	O	Review	865
ICML 2015	O	O	Review	865
<sep> [5] Deep Bayesian Bandits Showdown: An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling	O	O	Review	865
Carlos Riquelme, George Tucker, Jasper Snoek	O	O	Review	865
ICLR 2018	O	O	Review	865
We thank our second reviewer for his comments.	O	O	Reply	865
We first refer to your main comments and then answer each point in part.	O	O	Reply	865
<sep> <sep> The work of Lakshminarayanan et al indeed showed that deterministic ensembles can improve on the performance of MC-dropout techniques and provides a foundation for ours.	B-Reply	B-1	Reply	865
And as Beluch et al (2018) showed, this can be valuable in an active learning setting.	I-Reply	I-1	Reply	865
However, our work differs in two major ways:	I-Reply	I-1	Reply	865
<sep> i) We focus on showing the uncertainty representation in these methods suffer from overconfident predictions and that combining the two methods into a stochastic ensemble can be of great benefit and improve on the quality of the uncertainty.	I-Reply	I-1	Reply	865
<sep> <sep> ii) We believe the true novelty to be in applying them in an active learning setting, and in particular on a small dataset problem (i.e. the size of the final dataset acquired during AL is only a small fraction of the entire available unlabelled dataset).	B-Reply	B-1	Reply	865
As you mentioned, data is notoriously scarce and deep learning methods rarely work on small dataset problems.	I-Reply	I-1	Reply	865
<sep> <sep> We thank the reviewer for pointing us to the work of Huand et al Indeed this is an interesting method that would allow us to most likely achieve similar or better results with less computational overhead.	B-Reply	B-1	Reply	865
This is definitely something we will consider for future work, but it is somehow out of the main scope of the paper, which was to show the power of combining MC-dropout with ensembles in the active learning setting.	I-Reply	I-1	Reply	865
Taking into account more advanced ensemble methods is definitely of interest.	I-Reply	I-1	Reply	865
<sep> In terms of the Bayesian Optimization literature, this is definitely of interest if we are to focus on hyper-parameter tuning for our models, but we fail to see the connection of the work you mentioned to our active learning examples.	I-Reply	I-1	Reply	865
Our focus was not on fine-tuning our models.	I-Reply	I-1	Reply	865
<sep> <sep> In relation to your specific points, we answer these below:	O	O	Reply	865
<sep> 1) Gal has already showed in his PhD thesis that MC-Dropout almost always performs best in terms of prediction accuracy and uncertainty quality assessment when compared to alternative Bayesian neural network approaches such as Probabilistic Back Prop and other variants of stochastic gradient MCMC methods.	B-Reply	B-3	Reply	865
The aim of our paper was to improve upon MC-Dropout in the context of active learning, which would invariably translate into better performance w.r.t.other Bayesian NN approaches.	I-Reply	I-3	Reply	865
<sep> 2) Beluch et al (2018) showed that going beyond 3 networks in their deterministic ensemble method does not add any significant improvements in terms of performance.	B-Reply	B-4	Reply	865
Therefore, we used this number when benchmarking against their method.	I-Reply	I-4	Reply	865
<sep> 3) The aim of the paper was to improve upon the state-of-the-art in active learning for the image classification task.	B-Reply	B-5	Reply	865
We specifically chose this task due to its relevance to the real world especially in the medical imaging industry.	I-Reply	I-5	Reply	865
We agree that a more comprehensive study could be done in order to asses the viability of our method for ML tasks other than image classification.	I-Reply	I-5	Reply	865
As for other neural network architectures, we chose the one used in the benchmarked methods.	I-Reply	I-5	Reply	865
<sep> 4) Results are averaged over 5 multiple independent runs.	B-Reply	B-6	Reply	865
We will include both this and confidence scores in a revised version of our paper.	I-Reply	I-6	Reply	865

This paper introduces a technique using ensembles of models with MC-dropout to perform uncertainty sampling for active learning.	O	O	Review	865
<sep> <sep> In active learning, there is generally a trade-off between data efficiency and computational cost.	B-Review	B-1	Review	865
This paper proposes a combination of existing techniques, not just ensembling neural networks and not just doing MC dropout, but doing both.	I-Review	I-1	Review	865
The improvements over basic ensembling are rather minimal, at the cost of extra computation.	I-Review	I-1	Review	865
More specifically, the data efficiency (factor improvement in data to achieve some accuracy) of the proposed method over using a deterministic ensemble is around just 10% or so.	I-Review	I-1	Review	865
On the other hand, the proposed algorithm requires 100x more forward passes when computing the uncertainty (which may be significant, unclear without runtime experiments).	I-Review	I-1	Review	865
As a concrete experiment to determine the importance, what would be the accuracy and computational comparison of ensembling 4+ models without MC-dropout vs. 3 ensembled models with MC-dropout?	I-Review	I-1	Review	865
At the point (number of extra ensembles) where the computational time is equivalent, is the learning curve still better?	I-Review	I-1	Review	865
<sep> <sep> The novelty of this method is minimal.	B-Review	B-2	Review	865
The technique basically fills out the fourth entry in a Punnett square.	I-Review	I-2	Review	865
<sep> <sep> The paper is well-written, has good experiments, and has a comprehensive related work section.	O	O	Review	865
<sep> <sep> Overall, this paper is good, but is not novel or important enough for acceptance.	O	O	Review	865
We thank our third reviewer for his comment.	O	O	Reply	865
<sep> <sep> We do understand your concern about the significant increase in computational time.	B-Reply	B-1	Reply	865
However, we believe that in the context of active learning, the main problem is not related to computational power, rather to the scarcity of data.	I-Reply	I-1	Reply	865
Therefore, a better way of making the most out of little data is critical.	I-Reply	I-1	Reply	865
For example, a 10 \% increase for only 300 samples acquired, could make a huge difference in a critical field where active learning is most valuable.	I-Reply	I-1	Reply	865
We believe that this is exactly what we manage to achieve with our method and this comes as a result of a better representation of uncertainty during AL.	I-Reply	I-1	Reply	865
<sep> <sep> Furthermore,  Beluch et al (2018) showed that going beyond 3 networks in their deterministic ensemble method does not add any significant improvements in terms of performance.	B-Reply	B-1	Reply	865
Therefore we use 3 stochastic ensembles for our method.	I-Reply	I-1	Reply	865
<sep> <sep> As for the novelty of this method, although it seems more like an engineering solution, we believe that it makes a significant contribution in the field of deep active learning.	B-Reply	B-2	Reply	865

The authors present both a dataset of videos of a real-world foam ball bouncing and a model to learn the trajectory of the ball at collision (bounce) points in these videos.	O	O	Review	183
The model is comprised of a Physics Inference Module (PIM) and a Visual Inference Module (VIM).	O	O	Review	183
The PIM takes in both a vector of physical parameters (coefficient of restitution and collision normal) and a point cloud representation of the pre-bounce trajectory, and produces a point cloud representation of the post-bounce trajectory (or, rather, an encoded version of such).	O	O	Review	183
The VIM takes in an image and ground-truth bounce location and produces the physical parameters of the surface at that location.	O	O	Review	183
<sep> <sep> I find the paper well-written and clear.	O	O	Review	183
The motivation in the introduction is persuasive and the related work section is complete.	O	O	Review	183
However, the authors are introducing both a new training paradigm (to my knowledge unused in the literature) and a new model, and without any existing baselines to compare against I find it a bit difficult to understand how well the model works.	B-Review	B-1	Review	183
<sep> Overall, the authors‚Äô model is somewhat complicated and not as general as it initially seems.	B-Review	B-2	Review	183
To justify this complication I would like to see more convincing results and benchmarking or application to more than one single dataset (e.g. non-spheres bouncing).	I-Review	I-2	Review	183
<sep> <sep> Here are some specific concerns:	O	O	Review	183
<sep> 1)  I could not find a link to an open-sourced version of the dataset(s).	B-Review	B-3	Review	183
Given that the authors emphasize the dataset as a main contribution of the paper, they should open-source it and make the link prominent in the main text (apologies if I somehow missed it).	I-Review	I-3	Review	183
<sep> <sep> 2)  The authors claim in multiple places that the model is trained end-to-end, but this does not seem to be the case.	B-Review	B-4	Review	183
Specifically, the PIM is pre-trained on an auxiliary dataset from simulation.	I-Review	I-4	Review	183
The trajectory encoder also seems to be pre-trained (though I could be wrong about that, see my question below).	I-Review	I-4	Review	183
Furthermore, there is a bit of hand-holding:  The PIM uses ground-truth state for pre-training, and the VIM gets the ground-truth bounce location.	I-Review	I-4	Review	183
In light of this, the model seems a lot less general and end-to-end than implied in the abstract and introduction.	I-Review	I-4	Review	183
<sep> <sep> 3)  No comparison to existing baselines.	B-Review	B-5	Review	183
I would like to see how the authors‚Äô model compares to standard video prediction algorithms.	I-Review	I-5	Review	183
The authors could evaluate their model with respect to pixel loss (after ground-truth rendering) and compare to a video prediction algorithm (such as PredNet by Lotter, Kreiman, & Cox, 2016).	I-Review	I-5	Review	183
Given that the authors‚Äô method uses some extra ‚Äúprivileged‚Äù information (as described in point 2), it should far out-perform algorithms that train only on video data, and such a result would strengthen the paper a lot.	I-Review	I-5	Review	183
<sep> <sep> 4)  Table 1 is not a very convincing demonstration of performance.	B-Review	B-6	Review	183
Regardless of baselines, the table does not show confidence intervals.	I-Review	I-6	Review	183
I would love to see training curves with errorbars of the models on the most important metrics (e.g. Dist and COR Median Absolute Error).	I-Review	I-6	Review	183
<sep> <sep> I also was confused about a couple of things:	O	O	Review	183
<sep> 1)  How was the PointNet trajectory encoder trained?	B-Review	B-7	Review	183
I did not see this mentioned anywhere.	I-Review	I-7	Review	183
Were gradients passed through from the PIM?	I-Review	I-7	Review	183
Was the same network used for both the simulation and real-world data?	I-Review	I-7	Review	183
<sep> <sep> 2)  The performance of the center-based model in Table 1 seems surprisingly low.	B-Review	B-8	Review	183
The center-based model should be as good at the Train core, Fix traj.	I-Review	I-8	Review	183
enc.	I-Review	I-8	Review	183
model, since it has access to the ball‚Äôs position.	I-Review	I-8	Review	183
Why is it worse?	I-Review	I-8	Review	183
Is the VIM at fault?	I-Review	I-8	Review	183
Or is the sphere-fitting sub-optimal?	I-Review	I-8	Review	183
How does it compare on the simulated data with ground truth physical parameters?	I-Review	I-8	Review	183
<sep> <sep> 3)  Lastly, the color-scheme is a bit confusing.	B-Review	B-9	Review	183
It looks like the foam ball in the videos was rainbow-colored.	I-Review	I-9	Review	183
However, in the model outputs in trajectory figures time is also rainbow-colored.	I-Review	I-9	Review	183
This was initially a bit confusing.	I-Review	I-9	Review	183
Perhaps grayscale for the model outputs would be clearer.	I-Review	I-9	Review	183
<sep> <sep> We thank the reviewer for their feedback.	O	O	Reply	183
We address the concerns of the reviewer below.	O	O	Reply	183
<sep> <sep> 1) ‚ÄúThe authors are introducing both a new training paradigm (to my knowledge unused in the literature) and a new model, and without any existing baselines to compare against I find it a bit difficult to understand how well the model works.	O	O	Reply	183
‚Äù	O	O	Reply	183
We agree that due to the novelty of our training paradigm, model and data, there is a lack of existing literature/baselines to compare against.	B-Reply	B-1	Reply	183
This is an unavoidable challenge we face.	I-Reply	I-1	Reply	183
However, in order to better provide context for the performance of our models, we have conducted extensive quantitative and qualitative experiments and compared to relevant baselines (as also noted by other reviewers) including: (a) experiments dissecting the proposed model to localize the performance gains obtained due the PointNet trajectory encoders; (b) training the PIM on real-world data; and (c) a ground truth normals based experiment for reference.	I-Reply	I-1	Reply	183
Overall, we hope that our proposed approach can also serve as a useful baseline for future work in this direction.	I-Reply	I-1	Reply	183
<sep> <sep> 2) ‚ÄúOverall, the authors‚Äô model is somewhat complicated and not as general as it initially seems.	O	O	Reply	183
To justify this complication I would like to see more convincing results and benchmarking or application to more than one single dataset (e.g. non-spheres bouncing).‚Äù	O	O	Reply	183
As previously noted by the reviewer, prior work along the lines of estimating physical parameters and learning models of physics from real-world data is extremely scarce.	B-Reply	B-2	Reply	183
Therefore, there are no relevant datasets that can directly be used to benchmark our approach, which also emphasizes the need for such a dataset.	I-Reply	I-2	Reply	183
<sep> In the nascent stages of this field, we believe that addressing the problem with a spherical probe object provides a good starting point.	I-Reply	I-2	Reply	183
Non-spherical probe objects introduce additional complexity making exploration in this direction more challenging.	I-Reply	I-2	Reply	183
For example, results in [a] show how much the physical properties vary across the surface of an object.	I-Reply	I-2	Reply	183
The controlled setup of a spherical probe object ensures that the outcomes of bounces are dependent only on the physical properties of one object.	I-Reply	I-2	Reply	183
However, we agree that non-spherical probe objects could definitely be an interesting and essential next step to pursue as future work.	I-Reply	I-2	Reply	183
<sep> <sep> Specific concerns:	O	O	Reply	183
1) ‚ÄúA link to open source version of dataset is not available‚Äù	O	O	Reply	183
The double-blind submission of ICLR constrains the ability for us to provide the dataset publicly without revealing our identity.	B-Reply	B-3	Reply	183
The data will be made publicly available with the final version of the paper.	I-Reply	I-3	Reply	183
<sep> <sep> 2) ‚ÄúThe authors claim in multiple places that the model is trained end-to-end, but this does not seem to be the case.	O	O	Reply	183
Specifically, the PIM is pre-trained on an auxiliary dataset from simulation.	O	O	Reply	183
The trajectory encoder also seems to be pre-trained (though I could be wrong about that, see my question below).	O	O	Reply	183
Furthermore, there is a bit of hand-holding:  The PIM uses ground-truth state for pre-training, and the VIM gets the ground-truth bounce location.	O	O	Reply	183
In light of this, the model seems a lot less general and end-to-end than implied in the abstract and introduction.	O	O	Reply	183
‚Äù	O	O	Reply	183
The PIM (including the trajectory encoder) is pretrained initially using simulation data.	B-Reply	B-4	Reply	183
The VIM+PIM pipeline is then finetuned in end-to-end manner on the real data.	I-Reply	I-4	Reply	183
In the abstract/introduction, we refer to this end-to-end training.	I-Reply	I-4	Reply	183
It is true that the PIM uses simulation parameters in the pretraining phase and the VIM uses the ground truth location to index the feature maps.	I-Reply	I-4	Reply	183
However, the training is still ‚Äúend-to-end‚Äù  in the conventional usage of the term, since the model is fully differentiable and the gradients for the objective in Equation 3 are computed w.r.t all the parameters of both the VIM and PIM.	I-Reply	I-4	Reply	183
This is analogous to pretraining on ImageNet and finetuning with added parameters for other tasks which is also referred to as end-to-end training.	I-Reply	I-4	Reply	183
<sep> <sep> (Continued below)	O	O	Reply	183

This paper presents a method for inferring physical properties of the world (specifically, normals and coefficients of restitution) from both visual and dynamic information.	O	O	Review	183
Objects are represented as trajectories of point clouds used under an encoder/decoder neural network architecture.	O	O	Review	183
Another network is then learned to predict the post bounce trajectory representation given the prebounce trajectory representation given the surface parameters.	O	O	Review	183
This is used both to predict the post bound trajectory (with a forward pass) but also to estimate the surface parameters through an optimization procedure.	O	O	Review	183
This is coupled with a network which attempts to learn these properties from visual cues as well.	O	O	Review	183
This model can be either pretrained and fixed or updated to account for new information about a scene.	O	O	Review	183
The proposed model is trained on a newly collected dataset that includes a mixture of real sequences (with RGB, depth, surface normals, etc) and simulated sequences (additionally with physical parameters) generated with the help of a physics engine.	O	O	Review	183
It is compared with a number of relevant baseline approaches and ablation models.	O	O	Review	183
The results suggest that the proposed model is effective at estimating the physical properties of the scene.	O	O	Review	183
Overall the paper is well written and thoroughly evaluated.	O	O	Review	183
The problem is interesting and novel, the collected dataset is likely to be useful and the proposed solution to the problem is reasonable.	O	O	Review	183
We thank the reviewer for their time and appreciation of our work.	O	O	Reply	183

Paper summary:	O	O	Review	183
The paper proposes to predict bouncing behavior from visual data.	O	O	Review	183
The model has two main components: (1) Physics Interface Module, which predicts the output trajectory from a given incoming trajectory and the physical properties of the contact surface. (	O	O	Review	183
2) Visual Interface Module, which predicts the surface properties from a single image and the impact location.	O	O	Review	183
A new dataset called Bounce Dataset is proposed for this task.	O	O	Review	183
<sep> <sep> Paper strengths:	O	O	Review	183
- The paper tackles an interesting and important problem.	O	O	Review	183
<sep> - The data has been collected in various real scenes.	O	O	Review	183
<sep> - The idea of training the physics part of the network with synthetic data and later fine-tuning it with real images is interesting.	O	O	Review	183
<sep> - The experiments are thorough and well-thought-out.	O	O	Review	183
<sep> <sep> Paper weaknesses:	O	O	Review	183
- It would be more interesting if the dataset was created using multiple types of probe objects.	B-Review	B-1	Review	183
Currently, it is only a ball.	I-Review	I-1	Review	183
<sep> <sep> - It is not clear how the evaluation is performed.	B-Review	B-2	Review	183
For instance, the length of the groundtruth and predicted trajectories might be different.	I-Review	I-2	Review	183
How is the difference computed?	I-Review	I-2	Review	183
<sep> <sep> - The impact location (x,y) corresponds to multiple locations in 3D. Why not using a 3D point as input?	B-Review	B-3	Review	183
It seems the 3D information is available for both the real and synthetic cases.	I-Review	I-3	Review	183
<sep> <sep> - Why is it non-trivial to use a deconvolution network for predicting the output point cloud trajectory?	B-Review	B-4	Review	183
<sep> <sep> - The length of the input trajectory can vary, but it seems the proposed architecture assumes a fixed-length trajectory.	B-Review	B-5	Review	183
I am wondering how it handles a variable-length input.	I-Review	I-5	Review	183
<sep> <sep> - How is the bounce location encoded in VIM?	B-Review	B-6	Review	183
<sep> <sep> - I don't see any statistics about the objects being used for data collection.	B-Review	B-7	Review	183
That should be added to the paper.	I-Review	I-7	Review	183
<sep> <sep> >> Final score: The authors have addressed my concerns in the rebuttal.	O	O	Review	183
I believe this paper tackles an interesting problem, and the experiments are good enough since this is one of the first papers that tackle this problem.	O	O	Review	183
So I keep the initial score.	O	O	Review	183
<sep> <sep> We thank the reviewer for their appreciation of our work.	O	O	Reply	183
We address the reviewer‚Äôs concerns here:	O	O	Reply	183
<sep> 1) ‚ÄúIt would be more interesting if the dataset was created using multiple types of probe objects.	O	O	Reply	183
Currently, it is only a ball.	O	O	Reply	183
‚Äù	O	O	Reply	183
We agree that the eventual goal for research in this direction should be to generalize to multiple types of probe objects.	B-Reply	B-1	Reply	183
We discuss this further in the response to the review from AnonReviewer2. (	I-Reply	I-1	Reply	183
<a href="https://openreview.net/forum?id=BJxssoA5KX&noteId=ByekAQQo6Q" target="_blank" rel="nofollow">https://openreview.net/forum?id=BJxssoA5KX&noteId=ByekAQQo6Q</a> )	I-Reply	I-1	Reply	183
<sep> 2)‚ÄúThe length of the groundtruth and predicted trajectories might be different.	O	O	Reply	183
How is the difference computed?‚Äù	O	O	Reply	183
The evaluation is not dependent on the length of the trajectories recorded.	B-Reply	B-2	Reply	183
The distance between the predicted center and the ground-truth center is computed at timestep 10 (0.1 seconds post-bounce).	I-Reply	I-2	Reply	183
All trajectories in the dataset have length greater than 10 timesteps.	I-Reply	I-2	Reply	183
<sep> <sep> 3) ‚ÄúThe impact location (x,y) corresponds to multiple locations in 3D. Why not using a 3D point as input?	O	O	Reply	183
It seems the 3D information is available for both the real and synthetic cases.	O	O	Reply	183
‚Äù	O	O	Reply	183
In the physics model, the 3D collision point is currently used since the point cloud is represented with collision as origin.	B-Reply	B-3	Reply	183
In the VIM model, using the 3D points is similar to using a 2D (x,y) points since we eventually need to extract visual features from 2D input images.	I-Reply	I-3	Reply	183
<sep> <sep> 4) ‚ÄúWhy is it non-trivial to use a deconvolution network for predicting the output point cloud trajectory?‚Äù	O	O	Reply	183
There is very limited work on generating point clouds from embeddings.	B-Reply	B-4	Reply	183
Integrating a deconvolution model would have added an additional obstacle to an already challenging problem.	I-Reply	I-4	Reply	183
Furthermore, it would make localizing the errors more difficult.	I-Reply	I-4	Reply	183
<sep> <sep> Some relevant literature that demonstrate the challenges of generating point clouds:	B-Reply	B-4	Reply	183
[1] Achlioptas, Panos, et al "Representation learning and adversarial generation of 3D point clouds."	I-Reply	I-4	Reply	183
arXiv preprint arXiv:1707.02392 (2017).	I-Reply	I-4	Reply	183
<sep> [2] Insafutdinov, Eldar, and Alexey Dosovitskiy. "	I-Reply	I-4	Reply	183
Unsupervised Learning of Shape and Pose with Differentiable Point Clouds."	I-Reply	I-4	Reply	183
arXiv preprint arXiv:1810.09381 (2018).	I-Reply	I-4	Reply	183
<sep> [3] Lin, Chen-Hsuan, Chen Kong, and Simon Lucey. "	I-Reply	I-4	Reply	183
Learning efficient point cloud generation for dense 3D object reconstruction."	I-Reply	I-4	Reply	183
arXiv preprint arXiv:1706.07036 (2017).	I-Reply	I-4	Reply	183
<sep> [4] Achlioptas, Panos, et al "Learning Representations and Generative Models for 3D Point Clouds." (	I-Reply	I-4	Reply	183
2018).	I-Reply	I-4	Reply	183
<sep> <sep> <sep> 5) ‚ÄúThe length of the input trajectory can vary, but it seems the proposed architecture assumes a fixed-length trajectory.	O	O	Reply	183
I am wondering how it handles a variable-length input.	O	O	Reply	183
‚Äù	O	O	Reply	183
We observed that 10 frames before and after the collision contain sufficient information.	B-Reply	B-5	Reply	183
Therefore, we used these 20 frames in the proposed model.	I-Reply	I-5	Reply	183
For videos where more frames are available, we use only the 10 frames before and after collision.	I-Reply	I-5	Reply	183
<sep> <sep> 6) ‚ÄúHow is the bounce location encoded in VIM?‚Äù	O	O	Reply	183
The bounce location is used to index the feature map which is the output of the VIM.	B-Reply	B-6	Reply	183
We present this in Subsection 3.2 ‚ÄúTraining‚Äù paragraph - is obtained by indexing the output.	I-Reply	I-6	Reply	183
<sep> <sep> 7) ‚ÄúI don't see any statistics about the objects being used for data collection.	O	O	Reply	183
That should be added to the paper.	O	O	Reply	183
‚Äù	O	O	Reply	183
Thank you for the suggestion.	B-Reply	B-7	Reply	183
That would indeed be informative.	I-Reply	I-7	Reply	183
We shall add this to the final version of the paper since this would require some additional effort to label the objects.	I-Reply	I-7	Reply	183

This paper proposes a novel approach to training classifiers inspired by concepts from algorithmic information theory.	O	O	Review	183
Specifically, the inputs are augmented with additional features formed by encoding the image (using a source code).	O	O	Review	183
In addition, the paper argues to use the normalized compression distance as a loss criterion when training; this is a computationally tractable proxy for the normalized information distance, which the paper argues is what one really should use to generalize well, but which is not computationally tractable. (	O	O	Review	183
In particular, evaluating the Kolmogorov complexity, which is required to compute the normalized information distance, is not tractable.)	O	O	Review	183
The idea is demonstrated via experiments training common image classifiers (VGG-11 and ResNet-18) on clean and corrupted versions of the CIFAR-10 dataset, and comparing how they fare against adversarially trained methods on noisy and adversarial examples.	O	O	Review	183
<sep> <sep> I believe that this paper contains interesting and novel ideas, but there are also some inconsistencies and some points that are vague.	O	O	Review	183
I would consider raising my score if the authors address or clarify these issues, which are detailed below.	O	O	Review	183
<sep> <sep> The introduction discusses generalization very broadly, suggesting that the usual definition of generalization (e.g., accuracy on a hold-out set, drawn from the same distribution as the training set) is not the version of generalization that one should focus on.	B-Review	B-1	Review	183
However, the precise definition of generalization is never provided.	I-Review	I-1	Review	183
The intro also mentions briefly about adversarial examples, and this is the focus of the experiments.	I-Review	I-1	Review	183
It would help to clarify whether the paper focuses on being robust to adversarial examples as a form of generalization, or more precisely, what how is the concept of generalization defined/measured in this paper. (	I-Review	I-1	Review	183
E.g., the first sentence of Sec 2.1 mentions "our running definition of generalization," but no precise definition has yet been provided.	I-Review	I-1	Review	183
<sep> <sep> To make the paper self-contained, it would help to recall the formal definition of Kolmogorov complexity; this could be done in the appendix.	B-Review	B-2	Review	183
<sep> <sep> Sec 2 begins to make the connection between a classifier and a source code.	B-Review	B-3	Review	183
However, these definitions are not precise.	I-Review	I-3	Review	183
For example, in the usual PAC learning setting one has a distribution D over the training data (x,y).	I-Review	I-3	Review	183
After specifying a particular loss function, the Bayes-optimal classifier is well defined.	I-Review	I-3	Review	183
Does the source code C correspond this classifier?	I-Review	I-3	Review	183
I would guess not, since the paper seems to be introducing a specific loss criterion, but it would be good to clarify this in the paper.	I-Review	I-3	Review	183
Since you are assuming there is a "true output function" f, does this correspond to what is usually referred to as the "realizable" setting (i.e., where y = f(x) is a deterministic function of x)?	I-Review	I-3	Review	183
<sep> <sep> Notation is sometimes used without having been defined.	B-Review	B-4	Review	183
For example, what is?	I-Review	I-4	Review	183
<sep> <sep> It isn't clear how one can train using the criterion (4), or equivalently, solve the problem set forth in Prop 2, in practice, since the true source code C is not known.	B-Review	B-5	Review	183
Please elaborate on this.	I-Review	I-5	Review	183
<sep> <sep> In the experiments, how precisely is the VGG network modified to handle the encoded inputs?	B-Review	B-6	Review	183
Are these just passed as additional input channels?	I-Review	I-6	Review	183
Is the network architecture need to be modified in any other way to account for these additional inputs?	I-Review	I-6	Review	183
Also, what loss criterion is used for training?	I-Review	I-6	Review	183
Cross-entropy?	I-Review	I-6	Review	183
Or something related to normalized information distance?	I-Review	I-6	Review	183
This isn't clear from the discussion in Sec 3.	I-Review	I-6	Review	183
<sep> <sep> In Sec 3.2, is it really fair for the PGD attacks to only use the gradient of the loss wrt the uncoded input?	B-Review	B-7	Review	183
Is this still really "white box"?	I-Review	I-7	Review	183
How does the proposed approach perform if the attack also has access to the encoded input?	I-Review	I-7	Review	183
It would be good to report both settings in the paper.	I-Review	I-7	Review	183
<sep> <sep> The introduction made connections to other forms of generalization, including domain generalization and domain adaptation.	B-Review	B-8	Review	183
Based on this, I had expected to experiments illustrating the utility of the proposed for these problems.	I-Review	I-8	Review	183
<sep> <sep> The existing experiments do make clear that the encoded inputs are more robust to perturbations and aversarial attacks than uncoded inputs.	B-Review	B-9	Review	183
Is the encoding assumed to be performed on the perturbed input, or on an unperturbed input (i.e., before it is perturbed)?	I-Review	I-9	Review	183
<sep> <sep> I don't find the results in Table 1 fully convincing that the proposed approach should be preferred over previous approaches.	B-Review	B-10	Review	183
For instance, the approach of Madry et al (2018) achieves slightly lower test accuracy, but substantially higher inference accuracy.	I-Review	I-10	Review	183
In general, one expects to see a tradeoff here.	I-Review	I-10	Review	183
If one were to plot these points, would the proposed method clearly fall above the Pareto frontier?	I-Review	I-10	Review	183
Minor: Please clarify the definition of "inference accuracy" in the paper.	B-Review	B-11	Review	183
<sep> <sep> <sep> Thank you for the detailed responses and clarifications.	O	O	Reply	183
I read them and the revised version of the paper.	O	O	Reply	183
I appreciate the clarifications.	O	O	Reply	183
<sep> <sep> Regarding the response RW4, the idea that this may be used in combination with other techniques is reasonable, but this has not yet been demonstrated (e.g., in Section 3), so it is difficult to judge the value of this proposition.	B-Reply	B-6	Reply	183

The paper proposes a theoretical framework for studying the generalization of deep neural networks in a broader sense; i.e.,  generalizing with underrepresented or unrepresented training/test samples.	O	O	Review	183
The main idea is to cast the problem of improving generalization as the problem of minimizing the normalized information distance between the learned source code and the true source code, defined using the Kolmogorov complexity.	O	O	Review	183
Built upon this framework, the method of using extended encodings of an input sample is presented, which empirically seems to lead to better generalization in the settings of adversarial attack and corruptions.	O	O	Review	183
<sep> <sep> While the idea and the results seem to be appealing, and the concept is novel to the mainstream deep learning community, I suspect that some of the proofs in the paper might not be well grounded.	B-Review	B-1	Review	183
For example, in Equation (3), the authors claim that "a necessary and sufficient condition ensuring that ... the learned source code C_0 is more general than the learned source code C1 is ...".	I-Review	I-1	Review	183
However, this is not proved and does not seem obvious to me.	I-Review	I-1	Review	183
Also, in the proof of Theorem 1 in the Appendix, the authors state "Because a sufficiently high-capacity neural network can memorize its input samples (Zhang et al 2017), the Kolmogorov complexity of the true source code is larger than that of the source code".	B-Review	B-2	Review	183
This, to me, is more like some intuition or conjecture, rather than rigorous mathematical proof.	I-Review	I-2	Review	183
As a result, I am skeptical about the theoretical claims made in the paper.	I-Review	I-2	Review	183
<sep> <sep> RW:1 ‚ÄúWhile the idea and the results seem to be appealing, and the concept is novel to the mainstream deep learning community, I suspect that some of the proofs in the paper might not be well grounded.	O	O	Reply	183
For example, in Equation (3), the authors claim that "a necessary and sufficient condition ensuring that ... the learned source code C\_0 is more general than the learned source code C1 is ...".	O	O	Reply	183
However, this is not proved and does not seem obvious to me.	O	O	Reply	183
‚Äù	O	O	Reply	183
<sep> We thank Reviewer 1 for their valuable comments which have improved the clarity and the content of our manuscript.	O	O	Reply	183
Equation (3) is a direct result of using the normalized information distance as a universal cognitive similarity metric to determine whether learned source code or is more general with respect to the true source code.	B-Reply	B-1	Reply	183
The normalized information distance (Bennett et al 1998) is a metric that uncovers all effective similarities between the true source code and a learned source code.	I-Reply	I-1	Reply	183
Learning a source code that is closer to the true source code under this metric thus ensures achieving generalization.	I-Reply	I-1	Reply	183
We have updated the manuscript to clarify this point.	I-Reply	I-1	Reply	183
<sep> <sep> RW1: ‚ÄúAlso, in the proof of Theorem 1 in the Appendix, the authors state "Because a sufficiently high-capacity neural network can memorize its input samples (Zhang et al 2017), the Kolmogorov complexity of the true source code is larger than that of the source code".	O	O	Reply	183
This, to me, is more like some intuition or conjecture, rather than rigorous mathematical proof.	O	O	Reply	183
As a result, I am skeptical about the theoretical claims made in the paper.	O	O	Reply	183
‚Äù	O	O	Reply	183
<sep> This statement in the Proof of Theorem 1 is equivalent to simply stating that the set of available input samples on which a neural network is trained and tested is a subset of the empirical sample set which the trained neural network sees during inference; i.e.,.	B-Reply	B-2	Reply	183
This means that true source code bears information of all possible relations between input features that are useful for the classification task, whereas the learned source code bears information of a subset of all possible relations between the input features.	I-Reply	I-2	Reply	183
The Kolmogorov complexity of the true source code is thus larger than that of a source code learned from the set of available input samples by a sufficiently high-capacity neural network, which can memorize its input samples (Zhang et al 2017).	I-Reply	I-2	Reply	183
We have updated the Proof of Theorem 1 to clarify this point.	I-Reply	I-2	Reply	183

This paper provides a very interesting viewpoint for understanding the generalization in deep learning, where the concept of generalization is defined as ‚Äúthe difference between training error and inference error‚Äù, and covers the concept of adversarial robustness.	O	O	Review	183
More specifically,	O	O	Review	183
1.	O	O	Review	183
The author treats the deep model as a source code, and provides some theoretic analysis based on the Kolmogorov complexity.	O	O	Review	183
The insight drawn from this theory is: finding a better source code is equivalent to minimize a Kolmogorov complexity term given the true source code; as a result, a learned classification function needs to be sufficiently complex to minimize the generalization gap.	O	O	Review	183
<sep> 2.	O	O	Review	183
The author tries to approximate the normalized information distance and form an effectively computable optimization problem, which suggests that one can use channel codes on input features as additional inputs.	O	O	Review	183
<sep> 3.	O	O	Review	183
The experiments show that using additional encodings improve robustness in several settings, including in the sense of adversarial robustness.	O	O	Review	183
<sep> <sep> <sep> Pros:	O	O	Review	183
1.	O	O	Review	183
The writing is pretty clear.	O	O	Review	183
<sep> 2.	O	O	Review	183
The complexity viewpoint provides more insights for understanding generalization, which is something not covered by learning theory.	O	O	Review	183
<sep> 3.	O	O	Review	183
The empirical method that the authors proposed is simple, and computationally friendly.	O	O	Review	183
<sep> 4.	O	O	Review	183
I personally like the way adversarial robustness is covered in this paper, especially when comparing with tons of other adversarial robustness papers.	O	O	Review	183
<sep> <sep> <sep> Cons:	O	O	Review	183
1.	O	O	Review	183
Can you provide exact reference for the definition of normalized information distance?	B-Review	B-1	Review	183
It is not directly mentioned in (Bennett 1988) through a quick scan.	I-Review	I-1	Review	183
The normalization seems important for the theoretical analysis, so it would be better to explain where this definition comes from more clearly.	I-Review	I-1	Review	183
<sep> <sep> RW2: ‚ÄúCan you provide exact reference for the definition of normalized information distance?	O	O	Reply	183
It is not directly mentioned in (Bennett 1988) through a quick scan.	O	O	Reply	183
The normalization seems important for the theoretical analysis, so it would be better to explain where this definition comes from more clearly.	O	O	Reply	183
‚Äù	O	O	Reply	183
<sep> We thank Reviewer 2 for their positive comments and improving the clarity of our manuscript.	O	O	Reply	183
The normalized version of the information distance is referred to in Definition 4.1 and Theorem 4.2 in (Bennett et al 1998) and explicitly given in Equation (IV.1) in (Cilibrasi &amp; Vitanyi, 2005).	B-Reply	B-1	Reply	183
We have updated the manuscript to clarify this point.	I-Reply	I-1	Reply	183

The paper proposes an approach to generalization for deep networks based on kolmogorov complexity.	O	O	Review	183
The normalized information distance and its approximation via a compression algorithm were developed in earlier work, as noted by the authors.	O	O	Review	183
So the main contribution seems to be framing the deep learning classifier as a source code and developing a method to minimize the proposed information distance to improve generalization.	O	O	Review	183
<sep> <sep> I found a few gaps that I think the authors should clarify for me.	B-Review	B-1	Review	183
Why is framing the deep learning classifier as a source code important?	I-Review	I-1	Review	183
It seems to me that the K(C) is the same as K(f) where the f is the function mapping X -&gt; y, whether it is learned or not.	I-Review	I-1	Review	183
<sep> <sep> - Moreover, unless I'm missing something, the source code is a way to encode the values of a random variable such that communication is minimized.	B-Review	B-2	Review	183
If the C=f  is a map from X_i -&gt; y, X_i is an image, and y is a scalar, the source code as defined is not encoding X_i, it is simply encoding a part of X_i that is relevant to the classification task.	I-Review	I-2	Review	183
<sep> <sep> 1.	O	O	Review	183
The claim " Because a sufficiently high-capacity neural network can memorize its input samples the Kolmogorov complexity of the true source code is larger than that of the learned source code: i.e., K(C) &gt; K(C~)."	B-Review	B-3	Review	183
needs proof in itself.	I-Review	I-3	Review	183
This stands opposed to the intuition that an over-fit model has larger kolmogorov complexity because it is not "simple".	I-Review	I-3	Review	183
<sep> <sep> - Further, how does this square with the claim that the K(C~) is increased by adding encodings?	I-Review	I-3	Review	183
If K(C~) is increased, then I think one needs to show that K(C~)&lt; K(C) even with the encodings added?	I-Review	I-3	Review	183
<sep> - Finally, by adding the encodings, the task has been fundamentally changed to the classification on the dataset [x, E1(x), E2(x) .. ] .	I-Review	I-3	Review	183
So, the insight about minimizing information distance computed between C and C~ applies when the learned and the true "source code" correspond to the new task.	I-Review	I-3	Review	183
This does not seem to be addressed in the theory.	I-Review	I-3	Review	183
<sep> <sep> 2.	B-Review	B-4	Review	183
For the noise robustness experiments, there are no other baselines for robustness provided.	I-Review	I-4	Review	183
<sep> <sep> 3.	B-Review	B-5	Review	183
For the adversarial robustness claims, I don't believe that the justification provided in the paper is the necessarily only one.	I-Review	I-5	Review	183
The adversarial attacks are only done on the uncoded image.	I-Review	I-5	Review	183
So, if 'encodings' are robust to these attacks, the network could also be robust.	I-Review	I-5	Review	183
Unless this hypothesis is rejected, the provided theoretical justification and experiments do not exactly match-up.	I-Review	I-5	Review	183
<sep> <sep> (writing comments): I felt that the paper could use a better structure with terms like source code defined in a consolidated section.	B-Review	B-6	Review	183
RW3: ‚Äú3.	O	O	Reply	183
For the adversarial robustness claims, I don't believe that the justification provided in the paper is the necessarily only one.	O	O	Reply	183
The adversarial attacks are only done on the uncoded image.	O	O	Reply	183
So, if 'encodings' are robust to these attacks, the network could also be robust.	O	O	Reply	183
Unless this hypothesis is rejected, the provided theoretical justification and experiments do not exactly match-up.	O	O	Reply	183
‚Äù	O	O	Reply	183
<sep> The only input to the encoded model is the uncoded input features.	B-Reply	B-5	Reply	183
The encoder is simply a new layer of the neural network architecture, whose outputs are computed directly from the uncoded input features.	I-Reply	I-5	Reply	183
Changing the outputs of the encoder layer is tantamount to changing the outputs of any other layer of the neural network architecture, which is a threat model that falls out of the scope of our work.	I-Reply	I-5	Reply	183
We have not claimed that the encoded input features are more robust to common corruptions and adversarial perturbations.	I-Reply	I-5	Reply	183
The encoded input features simply bear information of relations between input features that are not represented by the uncoded input features, so a source code learned from a concatenation of uncoded and encoded input features bears more information of the true source code than a source code learned from uncoded input features alone.	I-Reply	I-5	Reply	183
A source code learned from a concatenation of uncoded and encoded input features is thus more robust than a source code learned from uncoded input features alone.	I-Reply	I-5	Reply	183
We have updated the manuscript to clarify this point.	I-Reply	I-5	Reply	183
<sep> <sep> RW3: ‚Äú(writing comments): I felt that the paper could use a better structure with terms like source code defined in a consolidated section.	O	O	Reply	183
‚Äù	O	O	Reply	183
<sep> We have included the definition of a source code in the Appendix.	B-Reply	B-6	Reply	183

The paper details an implementation of sparse-full convolutions and a model to work out the potential speed-up of various sparsity levels for CNNs.	O	O	Review	324
<sep> <sep> The first contribution is more about engineering, but the authors make the source code available which is greatly appreciated.	O	O	Review	324
<sep> <sep> The second contribution is perhaps more interesting, as so far pruning methods have focused on saving memory, with very modest speed gains.	O	O	Review	324
Imbuing knowledge of running speed into a pruning algorithm seems like the proper way to tackle this problem.	O	O	Review	324
The authors are very methodical in how they build the model and evaluate it very thoroughly.	O	O	Review	324
<sep> <sep> It seems that the same idea could be used not just for pruning existing models, but also when building new architectures: selecting layers and their parameters as to achieve an optimal throughput rate.	B-Review	B-1	Review	324
This could make for a nice direction for future work.	I-Review	I-1	Review	324
<sep> <sep> One point that is missing is some discussion of how transferable the performance model is to GPUs.	B-Review	B-2	Review	324
This would make the technique easier to adopt broadly.	I-Review	I-2	Review	324
<sep> <sep> Other areas for improvement: The points in Figure 4 are hard to distinguish (e.g. small red circle vs. small red square), and overall the figure could be made bigger; specifying whether the "base learning rate" in Section 3 is the start or end rate of the annealing schedule; typos: "punning" (p.4), "spares" (p.5).	B-Review	B-3	Review	324
<sep> <sep> We thank the reviewer‚Äôs appreciation of our sparse convolution algorithms as well as guided pruning techniques and the comment that the performance-model-guided techniques can be used in future work.	O	O	Reply	324
Indeed, there could be very interesting directions for future work on building new neural network architectures with our techniques.	B-Reply	B-1	Reply	324
As shown in GoogLeNet designs, building new network architectures with reduced computing demand is important.	I-Reply	I-1	Reply	324
However, as shown in our paper, the actual performance improvement is not a simple linear function of reduced FLOP count; instead, the convolution kernel size, input and output channel dimensions, and characteristics of a target platform among others, determine the actual speed of a neural network  on the target platform.	I-Reply	I-1	Reply	324
Our performance-model-guided approach can accurately project actual speedup of a neural network on specific target platforms (CPU/GPU/FPGA/ASIC).	I-Reply	I-1	Reply	324
Consequently, design decisions on new network architecture can be custom made for a specific hardware platform in question.	I-Reply	I-1	Reply	324
We will add an elaboration on this to our current paper.	I-Reply	I-1	Reply	324
<sep> <sep> Our model is very transferable to other platforms including GPUs.	B-Reply	B-2	Reply	324
For example, with a typical 90% sparsity, both Pascal Titian-X and P100 GPUs are projected to achieve similar ~3x speedups over their dense baselines.	I-Reply	I-2	Reply	324
Moreover, our model also reveals that sparse convolution becomes memory bandwidth bound and thus provide diminishing speedups earlier on Titan-X than on P100.	I-Reply	I-2	Reply	324
This is because Titan-X has a much higher flop to byte ratio than P100 equipped with a new high bandwidth memory technology, HBM2.	I-Reply	I-2	Reply	324
These insights shed light on designing sparse convolution on GPUs.	I-Reply	I-2	Reply	324

The authors provide a well engineered solution to exploiting sparsity in convolutional layers of a deep network by recasting it as sparse matrix-vector multiplication.	O	O	Review	324
This leads to very nice speedups and the analysis of when this is possible is also useful for practitioners.	B-Review	B-1	Review	324
My main concern with this paper is that the "research" aspect of it seems rather minimal, and it's mostly about performance engineering and comparisons.	I-Review	I-1	Review	324
It is upto the area chairs to decide how well such a paper fits in at ICLR.	I-Review	I-1	Review	324
We respectfully ask the reviewer to reconsider the assessment that there is a lack of research contribution in the present paper.	B-Reply	B-1	Reply	324
It is well accepted that deep learning is enabled by three similarly crucial components ‚Äì algorithm, data, and performance.	I-Reply	I-1	Reply	324
Each component benefited from a succession of original research efforts which are still active at present.	I-Reply	I-1	Reply	324
These include the invention of back propagation (past) to new optimization algorithms for training (present), the creation of the ImageNet dataset (past) to the Re‚Äôs ‚Äò‚Äôdata programming‚Äù approach (present), the lowering method that transforms convolution to matrix products (past) to computer architecture for special-purpose hardware accelerator (present).	I-Reply	I-1	Reply	324
<sep> <sep> The present paper belongs to the performance research area of sparsification.	I-Reply	I-1	Reply	324
While sparsification has been effective in memory footprint reduction, it has hitherto limited success in inference throughput enhancement.	I-Reply	I-1	Reply	324
The greatly enhanced throughput reported here cannot be achieved solely by our direct sparse convolution technique (which is a new fast algorithm by itself).	I-Reply	I-1	Reply	324
Preserving inference accuracy is an implicit requirement for all sparsification endeavor.	I-Reply	I-1	Reply	324
Sparsification for performance enhancement therefore cannot be successful without understanding where to ‚Äúuse the sparsification budget‚Äù for most effective performance gain.	I-Reply	I-1	Reply	324
And a simplistic ‚Äúengineering‚Äù trial-and-error approach is infeasible for the combinatorial number of choices offered by tens of layers and hundreds of channels.	I-Reply	I-1	Reply	324
We successfully identified sparsification targets by combining a high-resolution performance model and a sparsity allocation methodology, both of which contain original research that are applicable to performance research in general.	I-Reply	I-1	Reply	324

This paper tackles the problem of compressing trained convnets with the goal of reducing memory overhead and speeding up the forward pass.	O	O	Review	324
As I understand it, the main contribution of this work is to develop fast convolution routines for sparse conv weights int he case of general sparsity (as compared with structured sparsity).	B-Review	B-1	Review	324
They evaluate their method on both AlexNet and GoogLeNet as well as on various platforms.	O	O	Review	324
The authors make code available online.	O	O	Review	324
The paper is well written and does a good job of putting this work in the context of past model reduction techniques.	O	O	Review	324
<sep> <sep> My main request of the authors would be to provide a concise summary of the speedup/memory gains achievable with this new work compared with previously published work.	B-Review	B-2	Review	324
The authors do show the various sparsity level obtained with various methods of pruning but it is unclear to me how to translate the information given in the paper into an understanding of gains relative to other methods.	I-Review	I-2	Review	324
Please note that, in addition to our fast convolution algorithms, another important contribution is the performance model guiding the pruning process that allows pursuing desired speedup and model size reduction without falling into combinatorial number of choices offered by multiple layers.	B-Reply	B-1	Reply	324
Our performance model can also guide other methods discussed in related work as shown by our application to dynamic network surgery (GDNS in Figure 4(a)).	I-Reply	I-1	Reply	324
<sep> <sep> Thanks for the suggestion on summarizing inference speedups and model size reductions of related work.	O	O	Reply	324
A quick summary is shown below, which we will also consider including in our paper.	B-Reply	B-2	Reply	324
It is important to note that our work achieves highest speedup without accuracy loss among all the techniques below.	I-Reply	I-2	Reply	324
The speedups shown that are not our own measurements should be taken with a grain of salt because 1) many papers only provide relative speedups to a baseline whose efficiency is suboptimal (e.g. in some cases, the baseline is Caffe running on CPU, which is known to be suboptimal as it is tuned for GPU), and 2) what some papers report as "speedup" is actually FLOP reduction, not actual timing measurements.	I-Reply	I-2	Reply	324
As we did in our paper, for more scientific comparison among different CNN speedup techniques, we recommend using dense matrix multiplication (GEMM) FLOP/s of the evaluated platform as the baseline, because many platforms readily have vendor-provided extensively-optimized GEMM implementations which can be a proxy of highly-optimized dense CNN implementation.	I-Reply	I-2	Reply	324
This also aligns with a long-accepted common practice in the high-performance computing (HPC) community.	I-Reply	I-2	Reply	324
We omit Denton et al 2014, Jaderberg et al 2014, and Lebedev et al 2015 in the summary because they report improvements in a subset of conv and fc layers.	I-Reply	I-2	Reply	324
<sep> AlexNet	I-Reply	I-2	Reply	324
GESL (ours, 0% top-1 accuracy drop):                8.5x smaller model,                      2.5x speedup,                                      4.2x FLOP reduction	I-Reply	I-2	Reply	324
DNS (0.5% top-1 accuracy drop):                    17.7x smaller model,                      1.0x speedup (not enough sparsity in conv layers), 2.8x FLOP reduction	I-Reply	I-2	Reply	324
SSL (0% top-1 accuracy drop):                       1.01x smaller model (no sparsity in fc), 1.5x speedup,                                      1.3x FLOP reduction	I-Reply	I-2	Reply	324
Lebedev and Lempitsky (1.3% top-1 accuracy drop):   2.9x smaller model,                      3.0x speedup? (	I-Reply	I-2	Reply	324
not sure if this is a real speedup or FLOP reduction)	I-Reply	I-2	Reply	324
Liu et al (1% top-1 accuracy drop):                1.04x smaller model (no sparsity in fc), 4.4x speedup (not sure if lowering overhead included)	I-Reply	I-2	Reply	324
Kim et al (1.7% top-5 accuracy drop):              5.5x smaller model,                      1.8x speedup,                                      2.7x FLOP reduction	I-Reply	I-2	Reply	324
Tai et al (0.4% top-5 accuracy drop):              5.0x smaller model,                      1.8x speedup,                                      5.3x FLOP reduction	I-Reply	I-2	Reply	324
<sep> GoogLeNet	I-Reply	I-2	Reply	324
GESL (0.2% top-1 accuracy drop):                    3.3x smaller model,                      2.0x speedups in conv and fc layers,               3.0x FLOP reduction	I-Reply	I-2	Reply	324
DNS (our own evaluation, 2.5% top-1 accuracy drop): 1.5x smaller model,                      2.0x speedups in conv and fc layers,               2.6x FLOP reduction	I-Reply	I-2	Reply	324
SSL (our own evaluation, 2% top-1 accuracy drop):   2.1x smaller model,                      speedup N/A yet,                                   2.3x FLOP reduction	I-Reply	I-2	Reply	324
Kim et al (0.2% top-5 accuracy drop):              1.3x smaller model,                      1.2x speedup,                                      1.3x FLOP reduction	I-Reply	I-2	Reply	324
Ioannou et al (0.4% top-1 accuracy drop):          1.7x smaller model,                      speedup N/A,                                       1.4x FLOP reduction	I-Reply	I-2	Reply	324
Tai et al (0.4% top-5 accuracy drop):              2.8x smaller model,                      1.2x speedup,                                      2.9x FLOP reduction	I-Reply	I-2	Reply	324

The paper focuses on the problem learning state representations that can effectively capture historical information	O	O	Review	324
in POMDPs.	O	O	Review	324
Specifically, the paper proposes an alternative approach to using RNN's for capturing such history - the authors adopt a variant of recently proposed Invariant Information Clustering approach to discover important events in past observation and then use these events to learn a probability distribution over observations to represent the state information.	O	O	Review	324
The goal here is to address the unstable and inefficient training issues associated with RNN based architectures.	O	O	Review	324
The authors validate their approach with experiments on seven tasks on Atari 57 benchmark and Obstacle Tower, both with discrete action space and compare their performance against both original and RNN versions of PPO.	O	O	Review	324
<sep> <sep> The paper addresses an interesting problem to help learning better state representation in absence of  complete information about the environment.	O	O	Review	324
The approach of using IIC clustering (or any clustering approach) for learning state representations is novel.	O	O	Review	324
The overall goal of replacing RNN based methods in order to achieve stable, efficient learning in presence of budget constraints is very useful and hence this approach is potentially a good step in that direction.	O	O	Review	324
Although not adequate, the results in figure 3 provides good insight into effectiveness of the method in making training easier.	O	O	Review	324
<sep> <sep> However, I am inclining to reject this paper for the following reasons:	O	O	Review	324
(1) The motivation for using proposed clustering approach for history representation is neither clear  and nor well exposed.	B-Review	B-1	Review	324
MI based methods are inherently difficult to learn and hence this approach needs  rigorous analysis on why it works when it does and how it fails.	I-Review	I-1	Review	324
<sep> (2) The paper fails to position the new approach in comparison to related works both in discussions and experiments.	B-Review	B-2	Review	324
<sep> (3) The experiments are very limited in nature and fails to demonstrate the efficacy of the proposed approach effectively.	B-Review	B-3	Review	324
Further, the key contribution focusing on learning effective representations under constrained budget is not adequately tested.	I-Review	I-3	Review	324
<sep> <sep> Major concerns:	O	O	Review	324
<sep> Motivation	O	O	Review	324
-------------	O	O	Review	324
- It is not clear how the proposed clustering mechanism to discover events allows to successfully capture information that an RNN based approach does.	B-Review	B-4	Review	324
For instance, RNN helps to capture long-term dependencies but it is very hard to interpret the proposed model from that aspect.	I-Review	I-4	Review	324
Also, why is this particular clustering approach (Invariant Information Clustering) chosen?	I-Review	I-4	Review	324
The motivation for using this approach is not clear and overall combination appears adhoc.	I-Review	I-4	Review	324
<sep> - Further, RNN based methods can retain order information in sequential history of observations.	B-Review	B-4	Review	324
However,  this method appears to not consider that information.	I-Review	I-4	Review	324
Is this is true or am I mistaken here?	I-Review	I-4	Review	324
If this is true, why would this not create issues in learning good representations for task where order is indeed important?	I-Review	I-4	Review	324
<sep> - The paper discusses several articles that provide background on the methods used however it fails to position the exposition in comparison to existing RNN based approaches which is a big miss as the goal of the paper is to replace RNN based approaches [1,2,3,4].	B-Review	B-4	Review	324
<sep> Method	B-Review	B-5	Review	324
------	I-Review	I-5	Review	324
- In the event discovery stage, it is not clear why using consecutive observations is not useful.	I-Review	I-5	Review	324
Also, if one does use L=1 (consecutive observations), can one reduce this method to RNN as you end of capturing all the previous history?	I-Review	I-5	Review	324
Also, why L=3 is good across all different tasks?	I-Review	I-5	Review	324
does it have any relation with the use of 4 frames in I(t)?	I-Review	I-5	Review	324
<sep> - The authors mention tat H(t) matrix is highly sparse but also low-dimensional in all their experiments.	I-Review	I-5	Review	324
Would this is be the case for any other task?	I-Review	I-5	Review	324
If not, is this a limitation of the method that you need S and C  to be small?	I-Review	I-5	Review	324
<sep> - The authors attempt to use clustering based approach with the hope of recovering important information, however	I-Review	I-5	Review	324
mention that H(t) stores all the past events.	I-Review	I-5	Review	324
Isn't this contradictory?	I-Review	I-5	Review	324
Also, why can RNN with an attention based mechanism not achieve similar effect?	I-Review	I-5	Review	324
<sep> - It is also useful to analyse how will this method work in presence of long vs short history?	I-Review	I-5	Review	324
Will the clustering itself and hence the learned representations get affected by length of available history?	I-Review	I-5	Review	324
<sep> <sep> Experiments	B-Review	B-6	Review	324
----------	I-Review	I-6	Review	324
- Focusing only on PPO and designing an RNN version of PPO constrains the effectiveness of experiments in validating the approach.	I-Review	I-6	Review	324
Authors mention difficulty of training with RNN as one reason for PPO with RNN's under performance but this is not convincing Could the performance of PPO with RNN be limited only due to specific RNN architecture used?	I-Review	I-6	Review	324
<sep> - Authors must compare with other methods that use RNN approaches (e.g. [1]).	I-Review	I-6	Review	324
Also, if methods such [2],[3],[4] are not  directly applicable, they must atleast, use their RNN based architectures to modify PPO and compare several baselines.	I-Review	I-6	Review	324
<sep> - Why do the authors not report PPO with RNN for Obstacle Tower?	I-Review	I-6	Review	324
<sep> - For the experiments, authors use a specific 10000 steps budget but this seems to be highly curated.	I-Review	I-6	Review	324
The experiments	I-Review	I-6	Review	324
would be stronger if the authors show experiment over a range of budget.	I-Review	I-6	Review	324
This will also give insights on when does RNN becomes better and is there a budget after which both methods perform equally well or RNN based approaches	I-Review	I-6	Review	324
surpass the current approaches.	I-Review	I-6	Review	324
<sep> - Figure 3: Training dynamics seem to favor RNN approach for BreakOut, Gravitar.	I-Review	I-6	Review	324
Do the authors have insight on why	I-Review	I-6	Review	324
this is the case?	I-Review	I-6	Review	324
<sep> Minor points to improve submission not affecting the score:	O	O	Review	324
<sep> - The paper needs to be proofread for various typos and sentence construction issues	B-Review	B-7	Review	324
- Table 1: For Qbert, original PPO (Sch.)	B-Review	B-8	Review	324
is best performing, not EDHR	I-Review	I-8	Review	324
- [5] talks about difficulties in MI based methods and I encourage the authors to look at the analysis in	B-Review	B-9	Review	324
this paper.	I-Review	I-9	Review	324
As it is only an arXiv version and not published yet, I have not based my assessment on the	I-Review	I-9	Review	324
existence of this paper but still connection to such analysis will make this paper stronger.	I-Review	I-9	Review	324
<sep> <sep> <sep> [1] Deep Variational Reinforcement Learning for POMDPs, Igl et al	O	O	Review	324
[2] On improving deep reinforcement learning for POMDPs, Zhu et al	O	O	Review	324
[3] Policy Learning with continuous memory states in partially observed robotic control, Zhang et al	O	O	Review	324
[4] Memory-based control with recurrent neural networks, Heess et al	O	O	Review	324
[5] On Mutual Information Maximization and Representation Learning, Tschannen et al	O	O	Review	324
"[5] talks about difficulties in MI based methods and I encourage the authors to look at the analysis in this paper.	O	O	Reply	324
As it is only an arXiv version and not published yet, I have not based my assessment on the existence of this paper but still connection to such analysis will make this paper stronger."	O	O	Reply	324
<sep> <sep> Thank you for your suggestion, it's indeed an interesting paper and its analysis could improve the foundation of the IIC method.	B-Reply	B-9	Reply	324
However, it's quite a different direction with respect to our work.	I-Reply	I-9	Reply	324

This paper proposes a new way to represent past history as input to an RL agent, that consists in clustering states and providing the (soft) cluster assignment of past states in the input.	O	O	Review	324
The clustering algorithm comes from previous work based on mutual information, where close (in time) observations are assumed to be semantically similar.	O	O	Review	324
The proposed scheme, named EDHR (Event Discovery History Representation), is shown to perform better than PPO and an RNN variant of PPO on (most of) 7 representative Atari games, and better than PPO on the Obstacle Tower benchmark.	O	O	Review	324
<sep> <sep> I would like to see this paper eventually published as I find the proposed technique original and quite relevant to current RL research, however I feel like its empirical evaluation is too weak at this time, which is why I am recommending rejection.	B-Review	B-1	Review	324
I hope the results can be strengthened in a revised version so that I can increase my rating.	O	O	Review	324
<sep> <sep> The main limitations of the current empirical evaluation are:	O	O	Review	324
‚Ä¢<tab>Only 7 Atari games are used (vs 49 in the PPO paper the proposed technique is compared to), without justification for how they were chosen, and it seems like only 1 run is performed on each game (while RL algorithms are well known to exhibit high variance)	B-Review	B-2	Review	324
‚Ä¢<tab>On Obstacle Tower there seems to be also only one run of each algorithm (more runs could be done with different training &amp; testing seeds in order to get an idea of the variance)	B-Review	B-3	Review	324
‚Ä¢<tab>There is no comparison to PPO+RNN on Obstacle Tower	B-Review	B-4	Review	324
‚Ä¢<tab>I think a natural and important baseline to compare to is using the same architecture as in Fig.2 but where the mapping Phi(o_t) is learned through regular backprop (using the same loss as when learning the mapping I(t)).	B-Review	B-5	Review	324
This would validate that the advanced self-supervised clustering technique from Ji et al (2018) is actually useful, and thus that the observed improvements are not simply due to providing 32 frames of history vs. 4 as in vanilla PPO.	I-Review	I-5	Review	324
<sep> <sep> Other (more minor) remarks:	O	O	Review	324
‚Ä¢<tab>Please explain better how the clustering technique from Ji et al (2018) works, possibly in the Appendix if there is no room in the main body of the paper.	B-Review	B-6	Review	324
This will make the paper more self-contained.	I-Review	I-6	Review	324
<sep> ‚Ä¢<tab>Without fully understanding how this clustering technique works, it is difficult to me to get an intuition on how the clusters evolve during training, especially as new types of states are discovered by the agent.	B-Review	B-7	Review	324
Some discussion on this topic would be appreciated.	I-Review	I-7	Review	324
<sep> ‚Ä¢<tab>It would also be interesting to analyze the impact of varying the various new hyper-parameters (in particular S, C and L)	B-Review	B-8	Review	324
‚Ä¢<tab>On the first line of the last paragraph on p. 4, there is a missing reference ¬´ (Sec. )	B-Review	B-9	Review	324
¬ª	I-Review	I-9	Review	324
‚Ä¢<tab>Overall there are a bunch of typos throughout the paper that could easily be fixed	B-Review	B-9	Review	324
<sep> <sep> Follow-up on author response: I remain inclined to stick to my rejection recommendation.	O	O	Review	324
I appreciate the efforts in providing more results, but I find them too limited and not entirely convincing: Table 4 is only done on 3 games, and the only one where the proposed method has a clear edge over "Without self-supervision" is MsPacMan.	B-Review	B-5	Review	324
In addition, the fact that PPO+RNN shows much better performance than the proposed method on Obstacle Tower is also worrying.	B-Review	B-4	Review	324
"On the first line of the last paragraph on p. 4, there is a missing reference ¬´ (Sec. )	O	O	Reply	324
¬ª"	O	O	Reply	324
"Overall there are a bunch of typos throughout the paper that could easily be fixed"	O	O	Reply	324
<sep> We fixed the typos in the new version.	B-Reply	B-9	Reply	324

The authors study the problem of RL under partially observed settings.	O	O	Review	324
While most current (D)RL approaches use RNNs to tackle this problem, RNNS are trickier to optimise than FFNNs - in practice RNN-based DRL agents can perform well on partially observed problems, may require more effort to optimise, and may underperform FFNNs on domains with no/less partial observability.	O	O	Review	324
The proposed solution is to use a FFNN, but provide a "history representation", which is a set of feature vectors for previous timesteps that is extracted from a second network.	O	O	Review	324
The second network is trained separately using self-supervision (specifically, IIC, but adapted to use temporal consistency of observations rather than data augmentation).	O	O	Review	324
The proposed algorithm outperforms both PPO with a FFNN and PPO with an RNN on 5/7 Atari games (mainly games where partial observability is higher), as well as on the new and challenging Obstacle Tower benchmark - though PPO with RNN results are conspicuously missing on the latter!	O	O	Review	324
Given the promising approach (which also has a 2x better wall-clock training time than PPO with an RNN) and results, I would give this paper a weak accept.	O	O	Review	324
Some nice properties are that the instantaneous feature extractor is trained using RL, while the history feature extractor is trained using self-supervision at a high level (not pixel level), so that they are probably complementary; in addition it appears that in practice the resulting history features are sparse and usually binary, which is an intriguing and potentially useful property for future work.	O	O	Review	324
<sep> <sep> There are several things to be done to improve the paper however.	O	O	Review	324
First and foremost, the results should be run over several seeds with standard deviation/error reported (it appears that this might be the case for Obstacle Tower, but no error is reported).	B-Review	B-2	Review	324
I believe that the large improvements in some of the domains are significant, but it would be best to have this confirmed empirically.	I-Review	I-2	Review	324
The authors could improve the presentation of background material by giving techniques names instead of using just author names.	B-Review	B-3	Review	324
Although it would be expensive to show how changing L affects performance on all domains, some quantitative results on this hyperparameter would be useful - the same applies to C. The authors should also provide more clarity on choosing the history head - is the head identity fixed after pretraining?	B-Review	B-5	Review	324
It would be useful to know how the more standard PPO with RNN architecture performs, but the authors' choice of architecture is a fitting comparison to their method, and does perform well in practice on the more partially observed domains, so the current setup is satisfactory.	B-Review	B-1	Review	324
"It would be useful to know how the more standard PPO with RNN architecture performs, but the authors' choice of architecture is a fitting comparison to their method, and does perform well in practice on the more partially observed domains, so the current setup is satisfactory."	O	O	Reply	324
<sep> <sep> Additionally we added two models with experiments in 3 Atari environments in the appendix of the new version.	B-Reply	B-1	Reply	324

I Summary	O	O	Review	324
<sep> The authors present a method that computes a saliency map after each scale block of a CNN and combines them according to the weights of the prior layers in a final saliency map.	O	O	Review	324
The paper gives two main contributions: SMOE, which captures the informativeness of the corresponding layers of the scale block and LOVI, a heatmap based on HSV, giving information of the region of interest according to the corresponding scale blocks.	O	O	Review	324
The method is interesting as it does not require multiple backward passes such as other gradient-based method and thus prove to be more time-efficient.	O	O	Review	324
<sep> <sep> II Comments	O	O	Review	324
1.	O	O	Review	324
Content	O	O	Review	324
Overall the paper is very interesting, but it is not always clear what the contributions are.	B-Review	B-1	Review	324
The authors refer to "scale" in CNNs, this could be described a little as to explain what are scale blocks in a CNN, before introducing the terminology.	I-Review	I-1	Review	324
<sep> The proposed method "LOVI" is promising and I like the use of HSV for the different components.	I-Review	I-1	Review	324
However, it is hard to read, especially when alpha-blended with a grayscale version of the original image.	I-Review	I-1	Review	324
<sep> - The introduction doesn't clearly state what are the contributions of the method, an example of possible applications would be appreciated (the following about robotic for example but with more details)	I-Review	I-1	Review	324
- 3.1 I really enjoy the fact that different datasets are used for their different properties (foreground, background, sparsity), this is a nice touch	I-Review	I-1	Review	324
Figure 4 results are a little underwhelming, SMOE's scores are very close to the other methods	I-Review	I-1	Review	324
- 3.2 The authors refer to Smoothgrad squared method, it is indeed a good process to refine saliency maps, however why it is used could be detailed, just as the parameters chosen for its implementation.	I-Review	I-1	Review	324
<sep> - 4.	I-Review	I-1	Review	324
The authors claim their implementation is "approximately x times faster" but there is no quantitative proof of it, which seems to be one of the selling-point of the paper (or at least one of the best results)	I-Review	I-1	Review	324
<sep> 2.	O	O	Review	324
Writing	O	O	Review	324
Those typos do not impact the review score, I hope it can help the authors to gain more clarity in their writing.	B-Review	B-2	Review	324
<sep> - Abstract: "it is also quantitatively similar or better in accuracy" -&gt; shouldn't it be "and" instead of "or"?	I-Review	I-2	Review	324
<sep> - Intro	I-Review	I-2	Review	324
"a gradient saliency map by trying to back-propagate a signal from one end of the network and project it onto the image plane" not well articulated, "by trying to back-propagate" -&gt; "by back-propagating" (the claims seems weak otherwise)	I-Review	I-2	Review	324
"is running a fishing expedition post hoc" ;)	I-Review	I-2	Review	324
"An XAI tool which is too expensive will slow down training" Computationally expensive?	I-Review	I-2	Review	324
<sep> - 2.1	I-Review	I-2	Review	324
"The resemblance to conditional entropy should be apparent" -&gt; is apparent	I-Review	I-2	Review	324
"we might say it is" -&gt; it is (don't weaken your claims)	I-Review	I-2	Review	324
"we simple apply" -&gt; we simply	I-Review	I-2	Review	324
- 3.1	I-Review	I-2	Review	324
"if the results appeared terrible" -&gt; terrible is too strong/not adapted.	I-Review	I-2	Review	324
What is a bad result and why?	I-Review	I-2	Review	324
<sep> after eq 7 " the second method is in information" -&gt; an information	I-Review	I-2	Review	324
-3.2	I-Review	I-2	Review	324
"which locations are most salient correctly" -&gt; word missing?	I-Review	I-2	Review	324
<sep> - Figure 5: "Higher accuracy values are better results for it" -&gt; yield better results	I-Review	I-2	Review	324
<sep> The phrasing with"one" as in "if one would like to etc" is used a lot through the paper, it can be a little redundant at times.	I-Review	I-2	Review	324
<sep> <sep> III Conclusion	O	O	Review	324
The paper is interesting, however, one of the major contributions seems to be the speed of the method but no quantitative results have been reported.	B-Review	B-1	Review	324
I would really appreciate seeing some experiments over it.	I-Review	I-1	Review	324
Overall the results of the obtained maps are not very convincing compared to existing methods.	I-Review	I-1	Review	324
I believe the writing of the paper could be wrapped around the speed of the method and in which context it would be important (robotic, medical?).	I-Review	I-1	Review	324
The conclusion and discussion are short and could be filled a little more (some captions could be shortened in order to give more space).	I-Review	I-1	Review	324
<sep> <sep> Edit: The authors have answered most of my concerns and I am happy to re-evaluate my score to weak accept.	O	O	Review	324
##########################################################################	O	O	Reply	324
2.	O	O	Reply	324
Writing Those typos do not impact the review score, I hope it can help the authors to gain more clarity in their writing.	O	O	Reply	324
<sep> - Abstract: "it is also quantitatively similar or better in accuracy" -&gt; shouldn't it be "and" instead of "or"?	O	O	Reply	324
<sep> ##########################################################################	O	O	Reply	324
<sep> Changed.	B-Reply	B-2	Reply	324
<sep> <sep> ##########################################################################	O	O	Reply	324
- Intro "a gradient saliency map by trying to back-propagate a signal from one end of the network and project it onto the image plane" not well articulated,	O	O	Reply	324
##########################################################################	O	O	Reply	324
<sep> Fixed.	B-Reply	B-2	Reply	324
<sep> <sep> ##########################################################################	O	O	Reply	324
"by trying to back-propagate" -&gt; "by back-propagating" (the claims seems weak otherwise)	O	O	Reply	324
##########################################################################	O	O	Reply	324
<sep> Fixed.	O	O	Reply	324
<sep> <sep> ##########################################################################	O	O	Reply	324
"is running a fishing expedition post hoc" ;)	O	O	Reply	324
##########################################################################	O	O	Reply	324
<sep> Fixed.	O	O	Reply	324
<sep> <sep> ##########################################################################	O	O	Reply	324
"An XAI tool which is too expensive will slow down training" Computationally expensive?	O	O	Reply	324
<sep> ##########################################################################	O	O	Reply	324
<sep> Fixed.	O	O	Reply	324
<sep> <sep> ##########################################################################	O	O	Reply	324
- 2.1 "The resemblance to conditional entropy should be apparent" -&gt; is apparent	O	O	Reply	324
##########################################################################	O	O	Reply	324
<sep> Fixed.	O	O	Reply	324
<sep> <sep> ##########################################################################	O	O	Reply	324
"we might say it is" -&gt; it is (don't weaken your claims)	O	O	Reply	324
##########################################################################	O	O	Reply	324
<sep> We got similar feedback from peers we shared the paper with.	B-Reply	B-2	Reply	324
Fixed.	I-Reply	I-2	Reply	324
<sep> <sep> ##########################################################################	O	O	Reply	324
"we simple apply" -&gt; we simply	O	O	Reply	324
##########################################################################	O	O	Reply	324
<sep> Fixed.	O	O	Reply	324
<sep> <sep> ##########################################################################	O	O	Reply	324
- 3.1 "if the results appeared terrible" -&gt; terrible is too strong/not adapted.	O	O	Reply	324
What is a bad result and why?	O	O	Reply	324
<sep> ##########################################################################	O	O	Reply	324
<sep> Terrible was a terrible word to use.	B-Reply	B-2	Reply	324
Author 1 thought it seemed to sound awkward, but left it in anyways, bad choice.	I-Reply	I-2	Reply	324
<sep> <sep> ##########################################################################	O	O	Reply	324
after eq 7 " the second method is in information" -&gt; an information	O	O	Reply	324
##########################################################################	O	O	Reply	324
<sep> Fixed.	O	O	Reply	324
<sep> <sep> ##########################################################################	O	O	Reply	324
-3.2 "which locations are most salient correctly" -&gt; word missing?	O	O	Reply	324
<sep> ##########################################################################	O	O	Reply	324
<sep> Fixed.	O	O	Reply	324
<sep> <sep> ##########################################################################	O	O	Reply	324
- Figure 5: "Higher accuracy values are better results for it" -&gt; yield better results	O	O	Reply	324
##########################################################################	O	O	Reply	324
<sep> Fixed.	O	O	Reply	324
<sep> <sep> ##########################################################################	O	O	Reply	324
The phrasing with"one" as in "if one would like to etc" is used a lot through the paper, it can be a little redundant at times.	O	O	Reply	324
<sep> ##########################################################################	O	O	Reply	324
<sep> Author 1 has annoyed reviewers on more than one occasion with the over usage of a word in this exact same way.	B-Reply	B-2	Reply	324
Author 1 needs to be more vigilant in the future.	I-Reply	I-2	Reply	324

The paper presents a new approach, SMOE scale, to extract saliency maps from a neural network.	O	O	Review	324
The approach is deemed as efficient, because it does not require one or multiple backward passes, as opposed to other approaches based on gradients.	O	O	Review	324
The main idea is to process the output activation tensors of a few selected layers in a deep network using an operator combining mean and std.dev.	O	O	Review	324
called SMOE scale.	O	O	Review	324
The result of this operator can be combined through different scales to obtain a global saliency map, or visualized in such a way that shows the consistency of saliency maps at different scales.	O	O	Review	324
Experiments show some improvement against traditional gradient-based approaches.	O	O	Review	324
<sep> <sep> This paper is interesting in that it provides a different way to extract saliency maps from a network.	O	O	Review	324
The visualization at multiple scales is also nice and while I do not perfectly agree with the HSV encoding in Fig.2, I do see the potential.	O	O	Review	324
Being efficient is also a nice to have.	O	O	Review	324
There are three issues, however, which limits the novelty of the paper.	O	O	Review	324
First, the SMOE metric does not seem to bring much improvement compared to simple metrics.	B-Review	B-2	Review	324
Second, the few comparisons made against other methods do not reveal a significant improvement.	I-Review	I-2	Review	324
Third, at core, the paper suggests that the "high efficiency" of this approach is one of its main advantages, a statement I do not forcibly agree with.	B-Review	B-3	Review	324
More details follow.	I-Review	I-3	Review	324
<sep> <sep> For the first element, we have to consider the paper as the combination of two things.	B-Review	B-1	Review	324
1) the use of activation maps as source of salient information, and 2) the way we should process these activation maps.	I-Review	I-1	Review	324
1) is relatively straightforward, so the core of the contribution should lie in 2).	I-Review	I-1	Review	324
However, while the SMOE scale method definition (eq.2) is sound, it does not bring valuable improvement compared to other "trivial" metrics, like standard deviation.	I-Review	I-1	Review	324
For instance, Fig.4 caption tells that "SMOE Scale differentiates itself the most early on in the network", but it is actually only for the very first scale layer.	I-Review	I-1	Review	324
At every other scale, standard deviation (for instance) is at least as good.	I-Review	I-1	Review	324
Same thing can be said about Table 4 in appendix, and also about Table 2 (and the scores of Trunc.	I-Review	I-1	Review	324
Normal Entropy).	I-Review	I-1	Review	324
Overall, while SMOE is indeed novel, it is not highly convincing.	I-Review	I-1	Review	324
<sep> <sep> On a side note about the SMOE description, I did not find the list of "conditions and assumptions" at the beginning of Sec.2.1.	I-Review	I-1	Review	324
It looks more like an after-thought over which the proposed method coincidentally fits.	I-Review	I-1	Review	324
Moreover, point 3 is kind of conflicting in its formulation.	I-Review	I-1	Review	324
<sep> <sep> For the second element, the improvements in KAR and ROAR scores are quite minimal.	B-Review	B-2	Review	324
It does seem to have an edge on KAR score, but not by a huge amount.	I-Review	I-2	Review	324
Additionally, the methods compared are relatively old.	I-Review	I-2	Review	324
To give just two examples of missing new techniques, Smooth Grad-CAM++ (Omeiza et al) or even Grad-CAM++ (Chattopadhay et al) would presumably obtain better performances.	I-Review	I-2	Review	324
Moreover, Smooth Grad-CAM++ allows to target a particular feature map or even a specific neuron, which makes it even more relevant to this work.	I-Review	I-2	Review	324
<sep> <sep> Finally, a note about efficiency.	B-Review	B-3	Review	324
Generally speaking, I agree that it is always good to be more efficient.	I-Review	I-3	Review	324
However, I fail to see the high importance given to efficiency for this particular problem.	I-Review	I-3	Review	324
Sure, gradient-based approaches are probably not suitable to online, in-network applications, but is it an important requisite?	I-Review	I-3	Review	324
Computing saliency maps on a subset of the dataset once a few epochs already gives a good idea of what the network is doing.	I-Review	I-3	Review	324
In any case, since these saliancy maps are intended for human use, I am not convinced about the importance of computing them for each training example at each epoch.	I-Review	I-3	Review	324
Overall, in my opinion, being efficient at generating saliency maps is a nice to have, but not much more.	I-Review	I-3	Review	324
<sep> <sep> Some general comments:	O	O	Review	324
- In Sec.2.2, the last "con" seems a bit out of place.	B-Review	B-4	Review	324
This could be applied to pretty much anything.	I-Review	I-4	Review	324
<sep> - Sec.2.3 is interesting, but the explanations are convoluted.	B-Review	B-5	Review	324
In essence, what should be said is 1) value encompasses the importance of a pixel, 2) saturation presents the max-min of the distribution and 3) hue shows the position in the network.	I-Review	I-5	Review	324
Also, superimposing these HSV maps over gray scale version of the image like is Fig.2 is difficult to analyze because the "gray" of the image can be confused with the saturation channel.	I-Review	I-5	Review	324
<sep> - On p.2, "this is proceeded" -&gt; "this is preceded"?	B-Review	B-6	Review	324
<sep> <sep> In summary, this paper presents a nice way of generating saliency maps from activations inside a network.	O	O	Review	324
However, the comparison to other approaches does not show a clear advantage, and the related work (and experiments) lacks recent techniques.	B-Review	B-1	Review	324
I would thus ask this general question: what is the "selling point" of this method?	I-Review	I-1	Review	324
The current focus on efficiency does not convince me.	I-Review	I-1	Review	324
That being said, there are no clear flaws in the paper, so I am open to reconsider my assessment if improvements are made to the paper (better descriptions, comparison with more recent techniques, experimental justification for SMOE instead of simpler approaches, etc.).	B-Review	B-7	Review	324
<sep> <sep> On a final note, there is also the Score-CAM approach (Wang et al) that looks similar (in the idea of using activation maps).	B-Review	B-8	Review	324
I did not consider it in this review since it was published a few weeks ago on Arxiv, but it could be interesting to discuss it nevertheless.	I-Review	I-8	Review	324
##########################################################################	O	O	Reply	324
Some general comments:	O	O	Reply	324
<sep> - In Sec.2.2, the last "con" seems a bit out of place.	O	O	Reply	324
This could be applied to pretty much anything.	O	O	Reply	324
<sep> ##########################################################################	O	O	Reply	324
<sep> We got similar feedback from some of the peers we shared our paper with.	B-Reply	B-4	Reply	324
We will remove it.	I-Reply	I-4	Reply	324
<sep> <sep> ##########################################################################	O	O	Reply	324
- Sec.2.3 is interesting, but the explanations are convoluted.	O	O	Reply	324
In essence, what should be said is 1) value encompasses the importance of a pixel, 2) saturation presents the max-min of the distribution and 3) hue shows the position in the network.	O	O	Reply	324
<sep> ##########################################################################	O	O	Reply	324
<sep> We will try and massage this part a little more.	B-Reply	B-5	Reply	324
<sep> <sep> ##########################################################################	O	O	Reply	324
Also, superimposing these HSV maps over gray scale version of the image like is Fig.2 is difficult to analyze because the "gray" of the image can be confused with the saturation channel.	O	O	Reply	324
<sep> ##########################################################################	O	O	Reply	324
<sep> We got similar feedback from peers we shared the paper with.	B-Reply	B-5	Reply	324
The non-blended versions were in the appendix, but we will swap them into the main body figure.	I-Reply	I-5	Reply	324
The alpha blended versions, if anyone wants them, will still be in the appendix.	I-Reply	I-5	Reply	324
Updated figure can be seen below.	I-Reply	I-5	Reply	324
<sep> <sep> ##########################################################################	O	O	Reply	324
- On p.2, "this is proceeded" -&gt; "this is preceded"?	O	O	Reply	324
<sep> ##########################################################################	O	O	Reply	324
<sep> Fixed	B-Reply	B-6	Reply	324

This paper proposes Meta Q-Learning (MQL), an algorithm for efficient off-policy meta-learning.	O	O	Review	354
The method relies on a simple multi-task objective which provides initial parameter values for the adaptation phase.	O	O	Review	354
Adaptation is performed by gradient descent, minimizing TD-error on the new validation task (regularizing towards initial parameter values).	O	O	Review	354
To make adaptation data efficient, the method makes heavy use of off-policy data generated during meta-training, by minimizing its importance weighted TD-error.	O	O	Review	354
Importance weights are estimated via a likelihood ratio estimator, and are also used to derive the effective sample size of the meta-training batch, which is used to adaptively weight the regularization term.	O	O	Review	354
Intuitively, this has the effect of turning off regularization when meta-training trajectories are ‚Äúclose‚Äù to validation trajectories.	O	O	Review	354
One important but somewhat orthogonal contribution of the paper is to highlight the importance of context in meta-learning and fast adaptation.	O	O	Review	354
Concretely, the authors show that a simple actor-critic algorithm (TD3), whose policy and value are conditioned on a context variable derived from a recurrent network performs surprisingly well in comparison to SoTA meta-learning algorithms like PEARL.	O	O	Review	354
MQL is evaluated on benchmark meta-RL environments from continuous control tasks and is shown to perform competitively with PEARL.	O	O	Review	354
<sep> <sep> I have mixed opinions on this paper.	O	O	Review	354
On the positive side, and subject to further clarifications (see below), the paper seems to confirm that multi-task learning is almost sufficient to solve current meta-RL benchmarks in continuous control, without adaptation, as long as policy and critic are conditioned on a recurrent task context.	O	O	Review	354
This either highlights the strength of multi-task learning, or the inadequacies of current meta-RL benchmarks: either of which will be of interest to the community.	B-Review	B-1	Review	354
On the other hand, the proposed MQL algorithm is only shown to significantly outperform this new baseline TD3-context agent on 1 of 6 tasks (Ant-Goal-2D), and furthermore the ablative analysis seems to suggest that the importance weighting and adaptive weighting of trust region are not very effective, and do not significantly change the performance of the method.	I-Review	I-1	Review	354
The take-away seems to be that while context is crucial to generalization on these validation tasks, adaptation is not but can indeed be improved in a data-efficient manner with fine-tuning.	I-Review	I-1	Review	354
MQL is only then a second thread to this story.	I-Review	I-1	Review	354
<sep> <sep> <sep> Clarifying Questions:	O	O	Review	354
<sep> * The text and figures could be much clearer with respect to what is being measured/presented.	B-Review	B-2	Review	354
Can you confirm that you report average validation returns as a function of meta-training steps, where validation performance is estimated after training on (at most) 2x200 transitions from the validation task (|D_new|=400)?	I-Review	I-2	Review	354
This would match the protocol from PEARL.	I-Review	I-2	Review	354
Fig 4(a) would then imply that one can get close to SoTA results on Ant-Fwd-Back + Half-Cheetah-Fwd-Back with no adaptation whatsoever (using TD3-context).	I-Review	I-2	Review	354
<sep> * Could the authors provide more details about how context is generated, in particular whether the GRU is reset on episode boundaries or not?	B-Review	B-3	Review	354
If the recurrent context does span episode boundaries, are rewards being maximizing over a horizon greater than the episode length (similar to RL2)?	I-Review	I-3	Review	354
<sep> * How do you reconcile your result that a deterministic encoder is sufficient, compared to Figure 7 of PEARL which shows stochasticity is paramount for performing structured exploration during adaptation?	B-Review	B-4	Review	354
<sep> * Ablative analysis seems to suggest that off-policy learning plays a very minimal role during adaptation (beta=0).	B-Review	B-5	Review	354
Can you confirm this interpretation?	I-Review	I-5	Review	354
Would this not suggest that regularization via fine-tuning (regularized to multi-task prior) and context are sufficient to solve these meta-RL tasks?	I-Review	I-5	Review	354
This would be a sufficient contribution by itself but unfortunately does little to validate the proposed method.	I-Review	I-5	Review	354
<sep> * Could you repeat the ablative analysis on all of the 6 tasks?	B-Review	B-6	Review	354
Currently, this is performed on the two tasks for which TD3-context does best which leaves little room for improvement.	I-Review	I-6	Review	354
<sep> * Section 4.4.	B-Review	B-7	Review	354
Propensity Score Estimation. ‚	I-Review	I-7	Review	354
ÄúUse this model to sample transitions from the replay buffer that are similar to the new task‚Äù.	I-Review	I-7	Review	354
Is this done via rejection sampling?	I-Review	I-7	Review	354
This should be described more prominently in Section 3, along with a detailed description of the proposed MQL algorithm.	I-Review	I-7	Review	354
<sep> <sep> Detailed Comments:	O	O	Review	354
* Paper desperately needs an algorithmic box, which clear and concise description of algorithm (how losses are interleaved, etc).	B-Review	B-8	Review	354
Importantly, do the authors pretrain \theta_meta using the multi-task loss before doing adapation?	I-Review	I-8	Review	354
<sep> * Please add more informative labels to axes for all your figures: timesteps for [validation,training] ?	I-Review	I-8	Review	354
Same for return.	I-Review	I-8	Review	354
Please also augment captions to make figures as stand-alone as possible.	I-Review	I-8	Review	354
<sep> * MQL encompasses technique for off-policy training using a discriminator to estimate a likelihood ratio.	I-Review	I-8	Review	354
It would be nice to evaluate this in standard off-policy learning setting, instead of it being limited to meta-learning.	I-Review	I-8	Review	354
Thank you for your feedback.	O	O	Reply	354
Please also see the main comment above.	O	O	Reply	354
We hope you will consider increasing your score after seeing our response.	O	O	Reply	354
<sep> <sep> &gt;&gt; MQL is only shown to significantly outperform TD3-context on 1 of 6 tasks	O	O	Reply	354
Yes, the difference between TD3-context (which is a baseline we have proposed) and MQL is minor for these meta-RL benchmark tasks.	B-Reply	B-1	Reply	354
However the MQL is much better than TD3-context because of its explicit adaptation for out-of-distribution tasks.	I-Reply	I-1	Reply	354
Please see the summary of the results of this experiment in the comment above and the full results in Appendix D of the updated paper.	I-Reply	I-1	Reply	354
<sep> <sep> &gt;&gt;  furthermore the ablative analysis seems to suggest that the importance weighting and adaptive weighting of trust region are not very effective	O	O	Reply	354
It depends on the task.	B-Reply	B-1	Reply	354
For the Ant-Fwd-Back environment, where there is strong overlap between training and test tasks, the value of beta is almost one (Fig.5).	I-Reply	I-1	Reply	354
Due to this, MQL is much better (return ~1000 in Fig.2) for this environment.	I-Reply	I-1	Reply	354
3) than TD3-context (return ~825 in Fig.	I-Reply	I-1	Reply	354
A similar gap is also seen in the out-of-distribution experiment where beta ~ 0.2 throughout training.	I-Reply	I-1	Reply	354
The key point is that the two terms are self-adapting to the problem, they kick in when necessary and disable themselves without hurting performance when the new task is quite different (Fig.7 in Appendix D).	I-Reply	I-1	Reply	354
The user does not need to tune them by hand; they are essentially free terms.	I-Reply	I-1	Reply	354
<sep> <sep> &gt;&gt; take-away seems to be that while context is crucial to generalization on these validation tasks, adaptation is not.	O	O	Reply	354
<sep> Context is necessary but not sufficient, it takes you most of the way on these tasks.	B-Reply	B-1	Reply	354
Further, note that our GRU-based context variable does adapt the representation, it does not however use gradients.	I-Reply	I-1	Reply	354
As the out-of-distribution experiment suggests, explicit adaptation is essential to perform well on more challenging tasks.	I-Reply	I-1	Reply	354
So we would qualify the reviewer‚Äôs conclusion a bit: ‚Äúour context-based adaptation is sufficient for the current meta-RL benchmarks‚Äù.	I-Reply	I-1	Reply	354
Certainly more realistic benchmarks for meta-learning---the literature does not have them yet---would be ones that explicitly require meta-learning and strong adaptation.	I-Reply	I-1	Reply	354
<sep> <sep> &gt;&gt; MQL is only then a second thread to this story	O	O	Reply	354
There are two main points in our paper.	B-Reply	B-1	Reply	354
First, the fact our context-based multi-task training takes gets a bulk of the performance suggests that meta-RL benchmarks need rethinking.	I-Reply	I-1	Reply	354
Second, we have designed an algorithm for adaptation that is fundamentally sound and well-suited to off-policy learning.	I-Reply	I-1	Reply	354
This is in contrast to on-policy meta-RL methods (MAML, ProMP) which cannot exploit old data.	I-Reply	I-1	Reply	354
The out-of-distribution experiment validates our second contribution although this validation was not as strong in the initial draft.	I-Reply	I-1	Reply	354
The reviewer notes that they find the first contribution sufficient.	I-Reply	I-1	Reply	354
<sep> <sep> &gt;&gt; Make text and figures clearer.	O	O	Reply	354
Can you confirm that you report average validation returns as a function of meta-training steps?	O	O	Reply	354
<sep> We made the text and figures clearer.	B-Reply	B-2	Reply	354
For all experiments, we exactly followed (Rakelley et al have released their code and training logs) the evaluation protocol of PEARL.	I-Reply	I-2	Reply	354
As the reviewer identifies, indeed, our experiments suggest that one can get close to SoTA results on some environments with no gradient-based adaptation whatsoever with our context-based adaptation.	I-Reply	I-2	Reply	354
<sep> <sep> &gt;&gt; How is the context generated?	O	O	Reply	354
<sep> We use a Gated Recurrent Unit (GRU) to create context.	B-Reply	B-3	Reply	354
The GRU is reset after an episode finishes and is reinitialized to zero at the beginning of the next episode.	I-Reply	I-3	Reply	354
The sequence length of the GRU is upper bounded by the episode length.	I-Reply	I-3	Reply	354
The recurrent context does not span episode boundaries.	I-Reply	I-3	Reply	354
We made this choice because we wanted the simplest possible context mechanism.	I-Reply	I-3	Reply	354

Summary	O	O	Review	354
-------------	O	O	Review	354
The authors propose meta Q-learning, an algorithm for off-policy meta RL.	O	O	Review	354
The idea is to meta-train a context-dependent policy to maximize the expected return averaged over all training tasks, and then adapt this policy to any new task by leveraging both novel and past experience using importance sampling corrections.	O	O	Review	354
The proposed approach is evaluated on standard Mujoco benchmarks and compared to other relevant meta-rl algorithms.	O	O	Review	354
<sep> <sep> Comments	O	O	Review	354
--------------	O	O	Review	354
<sep> Meta-rl is a relevant direction for mitigating the sample-complexity of rl agents and allowing them to scale to larger domains.	O	O	Review	354
This work proposes interesting ideas and overall it constitutes an nice contribution.	O	O	Review	354
In particular, I found interesting (and at the same time worrying) that a simple q-learning algorithm with hidden contexts compares favorably to state-of-art meta-rl approaches in standard benchmarks.	O	O	Review	354
The paper is well-organized and easy to read.	O	O	Review	354
Some comments/questions follow.	O	O	Review	354
<sep> <sep> 1. (	B-Review	B-1	Review	354
15) is probably miss-written (theta is trained to maximize the TD error)	I-Review	I-1	Review	354
<sep> 2.	B-Review	B-2	Review	354
In the adaptation phase, are (18) and (19) performed one after the other?	I-Review	I-2	Review	354
Could they be done at the same time by setting to 1 the importance weights of the new trajectories and sampling from the whole experience (new and old)?	I-Review	I-2	Review	354
<sep> <sep> 3.	O	O	Review	354
Note that the ESS estimator (13) diverges to infinity when all weights are close to zero.	B-Review	B-3	Review	354
Is it clipped to [0,1] in the experiments?	I-Review	I-3	Review	354
See e.g. [1] or [2] for more robust estimators that are bounded.	I-Review	I-3	Review	354
<sep> <sep> 4.	O	O	Review	354
Since many recent works try to improve the generalization capabilities of meta-rl algorithms, I was wondering how the proposed approach generalizes to out-of-distribution tasks (i.e., tasks that are unlikely to occur at meta-training).	B-Review	B-4	Review	354
Though it is never mentioned in the paper, I believe the proposed method has the potential to be robust to negative transfer since the importance weights (which would be very small for very different tasks) should automatically discard old data and focus on new data alone.	I-Review	I-4	Review	354
This is in contrast to many existing methods where the meta-trained model might negatively bias the learning of very different tasks.	I-Review	I-4	Review	354
I think an experiment of this kind would be valuable to improve the paper.	I-Review	I-4	Review	354
<sep> <sep> [1] Elvira, V., Martino, L., &amp; Robert, C. P. (2018).	O	O	Review	354
Rethinking the effective sample size.	O	O	Review	354
arXiv preprint arXiv:1809.04129.	O	O	Review	354
<sep> [2] Tirinzoni, A., Salvini, M., &amp; Restelli, M. (2019, May).	O	O	Review	354
Transfer of Samples in Policy Search via Multiple Importance Sampling.	O	O	Review	354
In International Conference on Machine Learning (pp.6264-6274).	O	O	Review	354
Thank you for your feedback and suggested experiments.	O	O	Reply	354
Please also see the main comment above.	O	O	Reply	354
We hope you will consider increasing your score after seeing our response.	O	O	Reply	354
<sep> <sep> &gt;&gt; (15) is probably miss-written	O	O	Reply	354
Yes.	B-Reply	B-1	Reply	354
We have fixed this.	I-Reply	I-1	Reply	354
<sep> <sep> &gt;&gt; (18) and (19) performed one after the other?	O	O	Reply	354
Could they be done at the same time?	O	O	Reply	354
<sep> Yes, (18) and (19) can be performed at the same time.	B-Reply	B-2	Reply	354
We chose to implement them in two steps for ease of implementation.	I-Reply	I-2	Reply	354
Please also see the pseudo-code in Appendix A.	I-Reply	I-2	Reply	354
<sep> &gt;&gt; ESS estimator (13) diverges to infinity	O	O	Reply	354
No.	B-Reply	B-3	Reply	354
ESS does not diverge to infinity, it is upper bounded by the number of data and lower bounded by 1.	I-Reply	I-3	Reply	354
This is seen by noting that ESS = N/(1 + var(w); we simply normalize ESS by the number of data to get hat(ESS).	I-Reply	I-3	Reply	354
This is also the subject of Section 3.3 in Elvia et al 2018 ‚ÄúRethinking the effective sample size‚Äù.	I-Reply	I-3	Reply	354
<sep> <sep> &gt;&gt; Out-of-distribution tasks	O	O	Reply	354
Thanks, this is a great suggestion.	O	O	Reply	354
We did an experiment on the Half-Cheetah-Vel environment by making the set of meta-training and validation target velocities disjoint.	B-Reply	B-4	Reply	354
We find that the adaptation of MQL is essential to improve performance in this case.	I-Reply	I-4	Reply	354
In contrast, both our TD3-context and PEARL perform poorly on this out-of-distribution task.	I-Reply	I-4	Reply	354
Please see the common comment above for the results.	I-Reply	I-4	Reply	354
<sep> <sep> &gt;&gt; MQL is in contrast to many existing methods where the meta-trained model might negatively bias the learning of very different tasks	O	O	Reply	354
This is indeed a benefit of our method: MQL does not suffer from negative transfer.	B-Reply	B-4	Reply	354
If the new task is very different from the meta-training tasks then beta is close to zero which automatically discards old data.	I-Reply	I-4	Reply	354
The proximal penalty is large which prevents the policy from changing too much under such a distribution shift.	I-Reply	I-4	Reply	354
But the first term in (18) still benefits from new data.	I-Reply	I-4	Reply	354

The authors investigate meta-learning in reinforcement learning with respect to sample efficiency and the necessity of meta-learning an adaptation scheme.	O	O	Review	354
Based on their findings, they propose a new algorithm 'MQL' (Meta-Q-Learning) that is off-policy and has a fixed adaptation scheme but is still competitive on meta-RL benchmarks (a distribution of environments that differ slightly in their reward functions).	O	O	Review	354
<sep> <sep> They motivate the paper by data-inefficiency of current meta-learning approaches and empirical results suggesting that meta-learning the adaptation scheme is less important than feature reuse.	O	O	Review	354
<sep> <sep> On the other hand, their introduction section would benefit from additional references to the kind of meta-learning they describe.	B-Review	B-1	Review	354
In particular, their so-called "definition of meta-learning" is mostly about domain randomization (e.g. Tobin et al 2017 <a href="https://arxiv.org/abs/1703.06907)" target="_blank" rel="nofollow">https://arxiv.org/abs/1703.06907)</a> and not about the broader 'learning to learn' RL methodology (in particular Schmidhuber 1994 "On learning how to learn learning strategies").	I-Review	I-1	Review	354
<sep> <sep> **The authors make the following contributions:**	O	O	Review	354
<sep> 1.	O	O	Review	354
They show that Q-Learning trained on multiple tasks with a context variable as an input (an RNN state summarizing previous transitions) is competitive to related work when evaluated on a test task even though no adaptation is performed	O	O	Review	354
<sep> 2.	O	O	Review	354
Based on these observations, they introduce a new method for off-policy RL that does not directly optimize for adaptation but instead uses a fixed adaptation scheme	O	O	Review	354
<sep> 3.	O	O	Review	354
The new method leverages data during meta-testing that was collected during meta-training using importance weights for increased sample efficiency	O	O	Review	354
<sep> **Overall, we believe the contributions are significant and sufficiently empirically justified.**	O	O	Review	354
<sep> <sep> There are strong similarities, however, to parallel work on analyzing whether MAML relies on feature reuse or rapid learning (Raghu et al 2019 <a href="https://arxiv.org/abs/1909.09157)."	B-Review	B-2	Review	354
target="_blank" rel="nofollow">https://arxiv.org/abs/1909.09157).</a>	I-Review	I-2	Review	354
<sep> This work and the present submission conclude that feature reuse is much more significant than meta-learning an adaptation scheme when evaluated on current meta-RL benchmarks.	I-Review	I-2	Review	354
This is a significant result and supports the new method developed in this paper.	I-Review	I-2	Review	354
<sep> <sep> During meta-training, their proposed method maximizes only the average return across tasks, not the ability to adapt from the resulting parameters.	I-Review	I-2	Review	354
<sep> <sep> Their method introduces a fixed (non-learned) adaptation scheme that performs favorably compared to certain methods from the existing meta-learning literature and demonstrates that even dropping this adaptation still does well.	I-Review	I-2	Review	354
<sep> <sep> There are strong similarities to Nichol et al 2018 (<a href="https://arxiv.org/abs/1803.02999)."	I-Review	I-2	Review	354
target="_blank" rel="nofollow">https://arxiv.org/abs/1803.02999).</a> We encourage the authors to relate this work to Raghu et al 2019 and Nichol et al 2018.	I-Review	I-2	Review	354
<sep> <sep> **Despite these interesting results, we strongly disagree with the meta-learning narrative of their new method.**	B-Review	B-2	Review	354
<sep> <sep> Because the adaptation scheme is no longer optimized directly, instead a fixed adaptation scheme is assumed, hence the approach in this paper is no longer a meta-learning algorithm.	I-Review	I-2	Review	354
<sep> <sep> Instead, this method has strong similarities with transfer-learning and domain adaptation (first training on one distribution of tasks, then fine-tuning on another task).	I-Review	I-2	Review	354
<sep> <sep> The authors should discuss the links to these fields of research, and clarify what's really novel, already in the abstract.	I-Review	I-2	Review	354
<sep> <sep> For example, on page 2 the authors claim that optimizing the multi-task objective (the mean error across tasks) is the simplest form of meta-learning.	I-Review	I-2	Review	354
This objective, however, is NOT meta-learning.	I-Review	I-2	Review	354
<sep> <sep> **Decision.**	O	O	Review	354
<sep> <sep> The submission contains strong empirical results emphasizing the significance of feature reuse and the insignificance of learned adaptation on the tested meta-RL benchmarks.	O	O	Review	354
<sep> <sep> The reuse of experience from meta-training during meta-testing by employing importance weights is also an interesting contribution.	O	O	Review	354
<sep> <sep> In contrast, we are not satisfied with the presentation of their new approach as a meta-learning approach.	B-Review	B-2	Review	354
This method should be introduced along the lines of: 'Transfer Learning / Feature Reuse in RL is competitive to meta-learning across similar tasks'.	I-Review	I-2	Review	354
<sep> <sep> In its current form, we tend to reject the paper because it further obscures what the term meta-learning refers to.	I-Review	I-2	Review	354
The authors are confusing it with more limited transfer learning.	I-Review	I-2	Review	354
<sep> <sep> Additionally, it was not clear to us whether the quadratic penalty they add to their adaptation scheme is only empirically valid or whether there is a theoretical reason.	B-Review	B-3	Review	354
<sep> <sep> For now, we'd lean towards rejecting this submission, but we might change our minds, provided the comments above were addressed in a satisfactory way - let us wait for the rebuttal.	O	O	Review	354
<sep> <sep> Edit after rebuttal: score increased!	O	O	Review	354
Thank you for your feedback.	O	O	Reply	354
Please also see the main comment above.	O	O	Reply	354
The reviewer says, ‚Äúthe contributions of this paper are significant and sufficiently empirically justified‚Äù, ‚Äúthe submission contains strong empirical results emphasizing the significance of feature reuse and the insignificance of learned adaptation on the tested meta-RL benchmarks.	O	O	Reply	354
‚Äù, ‚ÄúThis is a significant result and supports the new method developed in this paper.	O	O	Reply	354
‚Äù.	O	O	Reply	354
We are extremely puzzled at the low score.	O	O	Reply	354
We hope you will consider increasing your score after seeing our response.	O	O	Reply	354
<sep> <sep> <sep> &gt;&gt; ‚Äúdefinition of meta-learning" is mostly about domain randomization‚Äù, ‚Äúwe are not satisfied with the presentation of their new approach as a meta-learning approach.	O	O	Reply	354
This method should be introduced along the lines of: 'Transfer Learning / Feature Reuse in RL is competitive to meta-learning across similar tasks‚Äù, ‚ÄúDespite these interesting results, we strongly disagree with the meta-learning narrative of their new method‚Äù, ‚Äúwe tend to reject the paper because it further obscures what the term meta-learning refers to.	O	O	Reply	354
The authors are confusing it with more limited transfer learning.	O	O	Reply	354
‚Äù	O	O	Reply	354
<sep> A meta-learner is an algorithm that has improved efficiency (statistically or computationally) of learning a new task by virtue of having seen related tasks in the past.	B-Reply	B-1	Reply	354
This is the definition in "On learning how to learn learning strategies" by Schmidhuber 1994, ‚ÄúIs learning the n^th thing any easier than learning the first?‚Äù by Thrun 1996 , ‚ÄúLearning to learn‚Äù by Thrun &amp; Pratt 1996, etc.	I-Reply	I-1	Reply	354
The improved efficiency of a meta-learner can be the result of two things: (i) a better prior (‚Äúshift its inductive bias‚Äù as Schmidhuber 1994 notes), or (ii) a better learning procedure that starts from the same prior, e.g., ‚ÄúOn the optimization of a synaptic learning rule‚Äù by Bengio et al 1992 or ‚ÄúMeta-Learning with Differentiable Convex Optimization‚Äù by Lee et al 2019.	I-Reply	I-1	Reply	354
The two notions of meta-learning above are complementary to each other and in fact, most recent literature using deep neural networks, e.g., MAML by Finn et al 2017, Prototypical Networks by Snell et al 2017 etc.	I-Reply	I-1	Reply	354
confirms to the first notion of building a better prior.	I-Reply	I-1	Reply	354
<sep> <sep> Our definition of meta-learning is (i).	I-Reply	I-1	Reply	354
The reviewer notes that ‚Äúadaptation scheme is no longer optimized directly‚Äù.	I-Reply	I-1	Reply	354
And this is one key point of our paper.	I-Reply	I-1	Reply	354
We perform multi-task learning at training time to learn a better prior for adaptation.	I-Reply	I-1	Reply	354
More the number of training tasks better the prior and more sample efficient the adaptation.	I-Reply	I-1	Reply	354
<sep> <sep> The current literature lacks a mathematically rigorous definition of meta-learning and we take the reviewer‚Äôs concerns in the right spirit.	I-Reply	I-1	Reply	354
We have added the above comments to the related work in Section 4.4.	I-Reply	I-1	Reply	354
<sep> <sep> We are at a loss at the connection of other concepts in machine learning with meta-learning by the reviewer.	I-Reply	I-1	Reply	354
Domain randomization is a data augmentation technique, it is not meta-learning.	I-Reply	I-1	Reply	354
Transfer Learning only adapts from one source task to another target task, it does not start from a family of training tasks; it is not meta-learning.	I-Reply	I-1	Reply	354
We do not perform feature reuse in MQL: we update the entire policy using both data from the new task and the meta-training tasks.	I-Reply	I-1	Reply	354
<sep> <sep> &gt;&gt; During meta-training, their proposed method maximizes only the average return across tasks, not the ability to adapt from the resulting parameters.	O	O	Reply	354
For example, on page 2 the authors claim that optimizing the multi-task objective (the mean error across tasks) is the simplest form of meta-learning.	O	O	Reply	354
This objective, however, is NOT meta-learning.	O	O	Reply	354
<sep> This is a key point of our paper.	B-Reply	B-2	Reply	354
Indeed, we perform multi-task learning at training time.	I-Reply	I-2	Reply	354
We do not train for the ability to adapt the parameters.	I-Reply	I-2	Reply	354
We instead learn a better prior for adaptation.	I-Reply	I-2	Reply	354
The multi-task objective is the simplest possible instantiation of meta-training, as suggested by the notion (i) in the previous remark because it provides a better prior than initializing the weights randomly before adaptation.	I-Reply	I-2	Reply	354
More the number of tasks during training time better the multi-task learnt prior.	I-Reply	I-2	Reply	354
The procedure is also similar to an existing state-of-the-art algorithm meta-learning named PEARL (‚ÄúEfficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables‚Äù by Rakelly et al 2019) which trains a value function conditioned on a probabilistic context variable on all the training tasks.	I-Reply	I-2	Reply	354

This paper proposes an unsupervised training objective based on patch contrasting for visual representation learning using deep neural networks.	O	O	Review	645
In particular, the feature representations of the patches from the same image are encouraged to be closer than the those from different images.	O	O	Review	645
The distance ratios of positive training pairs are optimized.	O	O	Review	645
The proposed method are empirically shown to be effective as an initialization method for supervised training.	O	O	Review	645
<sep> <sep> Strengths:	O	O	Review	645
<sep> - The training objective is reasonable.	O	O	Review	645
In particular, high-level features show translation invariance.	O	O	Review	645
<sep> <sep> - The proposed methods are effective for initializing neural networks for supervised training on several datasets.	O	O	Review	645
<sep> <sep> <sep> Weaknesses:	O	O	Review	645
<sep> - The methods are technically similar to the ‚Äúexemplar network‚Äù (Dosovitskiy 2015).	B-Review	B-1	Review	645
Cropping patches from a single image can be taken as a type of data augmentation, which is comparable to the data augmentation of positive sample (the exemplar) in (Dosovitskiy 2015).	I-Review	I-1	Review	645
<sep> <sep> - The paper is experimentally misleading.	B-Review	B-2	Review	645
<sep> The results reported in this paper are based on fine-tuning the whole network with supervision.	I-Review	I-2	Review	645
However, in Table 2, the results of exemplar convnets (Dosovitskiy 2015) is from unsupervised feature learning (the network is not finetuned with labeled samples, and only a classifier is trained upon the features).	I-Review	I-2	Review	645
Therefore, the comparison is not fair.	I-Review	I-2	Review	645
I suspect that exemplar convnets (Dosovitskiy 2015) would achieve similar improvements from fine-tuning; so, without such comparisons (head-to-head comparison with and without fine-tuning based on the same architecture except for the loss), the experimental results are not fully convincing.	I-Review	I-2	Review	645
<sep> <sep> Regarding the comparison to ‚ÄúWhat-where‚Äù autoencoder (Zhao et al, 2015), it will be interesting to compare against it in large-scale settings, as shown by Zhang et al, ICML 2016 (Augmenting Supervised Neural Networks with Unsupervised Objectives for Large-Scale Image Classification).	B-Review	B-3	Review	645
Training an AlexNet is not very time-consuming with latest (e.g., TITAN-X level) GPUs.	I-Review	I-3	Review	645
<sep> <sep> The proposed method seems useful only for natural images where different patches from the same image can be similar to each other.	O	O	Review	645
<sep> <sep> Thank you for the review, we appreciate your remarks and incorporated them into latest revision.	O	O	Reply	645
<sep> As you pointed out, this work shares motivation with that of Dosovitskiy, of learning unsupervised representations of images using the spatial invariance properties.	B-Reply	B-1	Reply	645
We do how note that this work suggests a novel method of achieving that goal, by explicitly learning features that correspond to the spatial invariance assumptions.	I-Reply	I-1	Reply	645
We claim that this method may hold several advantages over that of Dosovitsky, such as removing the need for surrogate classes of augmented images, and being able to apply it in parallel to standard classification objective.	I-Reply	I-1	Reply	645
We thus feel that both are viable methods for unsupervised learning on image data.	I-Reply	I-1	Reply	645
<sep> We understand your objection to the comparison without fine-tuning the exemplar network model, although we note that both models used exactly the same data in both cases.	B-Reply	B-3	Reply	645
We will include a clarifying remark over this issue.	I-Reply	I-3	Reply	645
<sep> We thank you for your suggestion for large-scale comparison of this work, and will try to incorporate it into later revision.	O	O	Reply	645

The proposed self supervised loss is formulated using a Siamese architecture and encourages patches from the same image to lie closer in feature space than a contrasting patch taken from a different, random image.	O	O	Review	645
The loss is very similar in spirit to that of Doersch et al ICCV 2015 and Isola et al ICLR 2016 workshop.	B-Review	B-1	Review	645
It seems that the proposed loss is actually a simplified version of Doersch et al ICCV 2015 in that it does not make use of the spatial offset, a freely available self supervised signal in natural images.	I-Review	I-1	Review	645
Intuitively, it seems that the self-supervised problem posed by this method is strictly simpler, and therefore less powerful, than that of the aforementioned work.	B-Review	B-2	Review	645
I would like to see more discussion on the comparison of these two approaches.	I-Review	I-2	Review	645
Nevertheless the proposed method seems to be effective in achieving good empirical results using this simple loss.	B-Review	B-3	Review	645
Though more implementation details should be provided, such as the effect of patch size, overlap between sampled patches, and any other important measures taken to avoid trivial solutions.	I-Review	I-3	Review	645
Thank you for the review, we appreciate your remarks and incorporated them into latest revision.	O	O	Reply	645
<sep> We would like to emphasize some difference between our work and that of Doersch 2015.	B-Reply	B-1	Reply	645
Although both works used patches from an image to learn unsupervised learning, the method is quite different.	I-Reply	I-1	Reply	645
Whereas Doersch used a classification criterion over the spatial location of each patch within a single image, our work is concerned comparing patches from several images to each other using a distance ratio loss.	I-Reply	I-1	Reply	645
We claim that this encourage discriminability between images (which we feel to be important aspect of feature learning), and is not an explicit goal in the work of Doersch.	I-Reply	I-1	Reply	645
Thus, we feel that both approaches are viable methods for unsupervised learning using samples from spatial data.	I-Reply	I-1	Reply	645
We will include this distinction in our revision as well as the implementation details that you indicated missing.	I-Reply	I-1	Reply	645

This paper presents a novel way to do unsupervised pretraining in a deep convolutional network setting (though likely applicable to fully-connected nets as well).	O	O	Review	645
The method is that of ‚Äòspatial constrasting‚Äô, i.e. of building triplets from patches of input images and learning a presentation that assigns a high score for patches coming from the same image and a low score for patches from diferent images.	O	O	Review	645
The method is simple enough that I am surprised that no-one has tried this before (at least according to the previous work in the submission).	O	O	Review	645
Here are some comments:	O	O	Review	645
<sep> <sep> The usage of P(f_i^1 | f_i^2) in Section 4.1 is a bit odd.	B-Review	B-1	Review	645
May be worth defining mathematically what kind of probability the authors are talking about, or just taking that part out (‚Äúprobability‚Äù can be replaced with another word).	I-Review	I-1	Review	645
<sep> <sep> I would like to know more about how the method is using the ‚Äúbatch statistics‚Äù (end of Section 4.2) by sampling from it, unless the authors simply mean that the just sample from all the possible triples in their batch.	B-Review	B-2	Review	645
<sep> <sep> Shouldn‚Äôt the number of patches sampled in Algorithm 1 be a hyper-parameter rather than just be 1?	B-Review	B-3	Review	645
Have the authors tried any other value?	I-Review	I-3	Review	645
<sep> <sep> I think there are some missing details in the paper, like the patch size or whether the authors have played with it at all (I think this is an important hyper-parameter).	B-Review	B-4	Review	645
<sep> <sep> The STL results are quite impressive, but CIFAR-10 maybe not so much.	B-Review	B-5	Review	645
For CIFAR I‚Äôd expect that one can try to pre-train on, say, Imagenet + CIFAR to build a better representation.	I-Review	I-5	Review	645
Have the authors considered this?	I-Review	I-5	Review	645
<sep> <sep> <sep> All in all, this is an interesting piece of work with some obvious applications, and it seems relatively straightforward to implemenent and try.	O	O	Review	645
I think I would‚Äôve liked more understanding of what the spatial contrasting actually learns, more empirical studies on the effects of various parameter choices (e.g., patch size) and more attempts at beating the state of the art (e.g. CIFAR).	O	O	Review	645
<sep> <sep> Thank you for the review, we appreciate your remarks and incorporated them into latest revision.	O	O	Reply	645
<sep> We will clarify our notation in section 4.1, thank you for indicating this is not well defined.	B-Reply	B-1	Reply	645
<sep> The batch statistics we were referring to is the fact that each image in a batch serves as contrasting noise to other samples.	B-Reply	B-2	Reply	645
This can be viewed as a simple sampling from the space of ‚Äúpatch features‚Äù.	I-Reply	I-2	Reply	645
We will try to make that more clear in our revision.	I-Reply	I-2	Reply	645
<sep> Missing implementation details that you mentioned will be added to the paper as well as code to reproduce our results.	B-Reply	B-4	Reply	645
<sep> We did not try to learn from Imagenet data, as this will not allow us to compare with previous works on CIFAR, we thank the reviewer for this suggestion.	B-Reply	B-5	Reply	645
<sep> We will try to shed some more light into what spatial contrasting learns and the effect of parameter choices.	O	O	Reply	645

The underlying problem considered in this manuscript is inferring depth from geometry of two dimensional images.	O	O	Review	645
The novelty here is to integrate a semantic classification model along with depth inference.	O	O	Review	645
It is a challenging problem and a neat idea to pursue.	O	O	Review	645
The paper is well-written and easy to follow.	O	O	Review	645
<sep> However, the empirical work in the paper is not persuasive.	B-Review	B-2	Review	645
Table 1 contains results whose significance is hard to judge.	I-Review	I-2	Review	645
What does a RMSE difference of 2.3 mean in the context of depth estimation?	I-Review	I-2	Review	645
Table 1 carries no uncertainty in results which is just not acceptable in a setting that has several sources of uncertainty.	B-Review	B-1	Review	645
Similarly, Fig 4 shows there is advantage in the use of the pre-trained semantic network, it is not clear if this difference is significant.	I-Review	I-1	Review	645
And I also think consideration should be given to the fact that in a deployment setting, new objects not previously seen in the semantic categories (UFO) may appear and one ought to understand if the semantic network might decrease performance (because of the unseen class).	I-Review	I-1	Review	645
Hence I think which the idea advanced in the paper has merits, the manuscript is not really ready for publication.	I-Review	I-1	Review	645
[Table 1 contains results whose significance is hard to judge.]	O	O	Reply	645
<sep> <sep> We agree with the reviewer that the standard depth metrics (abs_rel, RMSE, a1, etc) used by the community [1,2,3] can be opaque, making it difficult to correlate a particular metric with performance on a downstream task.	B-Reply	B-2	Reply	645
To alleviate this, we propose in our work to also consider a class-specific evaluation, thus allowing further introspection into the performance of our model.	I-Reply	I-2	Reply	645
This enables us to see improvements in particular classes, that might be more relevant for particular downstream tasks (i.e. road for ground plane extraction, or cars/pedestrians for object detection).	I-Reply	I-2	Reply	645
<sep> As for the metrics commonly used to evaluate depth performance, they are helpful in combination because they evaluate depth performance in different ways: Abs.	I-Reply	I-2	Reply	645
Rel (absolute relative error) and a1 (1.25 distance threshold) roughly measure the overall accuracy of depth estimates, while Sq.	I-Reply	I-2	Reply	645
Rel. (	I-Reply	I-2	Reply	645
square relative error) and RMSE (root mean squared error) focus on the variance of depth estimates, being particularly sensitive to outliers.	I-Reply	I-2	Reply	645
A typical year-over-year relative improvement on these metrics is around 5%, while our method improves by 11% over the previously published state of the art [3], and by 6% over the unpublished strong baseline [1]. Our significant improvements on Sq.	I-Reply	I-2	Reply	645
Rel.	I-Reply	I-2	Reply	645
and RMSE indicate that our proposed semantically-guided framework is particularly robust to appearance-related noise.	I-Reply	I-2	Reply	645
It  generalizes better to different object instances thanks to the introduction of semantic guiding information, where this domain gap is less apparent (i.e. all cars should be treated the same way, regardless of color).	I-Reply	I-2	Reply	645
This improvement in Sq.	I-Reply	I-2	Reply	645
Rel.	I-Reply	I-2	Reply	645
and RMSE can also be explained by the generation of sharper boundaries, as discussed in the paper (and shown in Figure 5), so there are fewer outliers that fall between two objects (a.k.a.	I-Reply	I-2	Reply	645
the "bleeding" effect).	I-Reply	I-2	Reply	645
<sep> <sep> <sep> [Table 1 carries no uncertainty in results.]	O	O	Reply	645
<sep> <sep> We agree that, although our trained model is deterministic, there are sources of uncertainty in the proposed approach, as in all learning-based methods.	B-Reply	B-1	Reply	645
On Table 1, we did not report uncertainty estimates because that is not a common practice in depth evaluation.	I-Reply	I-1	Reply	645
That being said, we agree with the reviewer.	I-Reply	I-1	Reply	645
Therefore, we added in Appendix A a study of the main source of uncertainty tied to our major contribution: how different initializations of the semantic network affect the depth fine-tuning process, including semantic training with fewer labels, which results in worse semantic predictions.	I-Reply	I-1	Reply	645
These experiments show that our proposed framework is robust to the degradation in semantic predictions, which is in line with expectations since we are not using the final semantic predictions themselves, but only guiding our depth network with features from the decoder of the semantic network.	I-Reply	I-1	Reply	645
This is further illustrated in Appendix B, with examples of situations where the semantic network produces erroneous predictions but the semantically-guided depth network is still able to properly reconstruct objects.	I-Reply	I-1	Reply	645
This is an indication that the uncertainty encoded in the semantic features is considered within the depth network itself, which learns when semantic information should be used and when it should be discarded to optimize the self-supervised photometric loss.	I-Reply	I-1	Reply	645
<sep> In addition, we plan to retrain our whole approach using multiple random seeds to evaluate the end-to-end variance of our method for the final version of the paper, as this takes a significant amount of computational resources and time (hence why no other related work we found does this in practice).	I-Reply	I-1	Reply	645

The paper proposes a using pixel-adaptive convolutions to leverage semantic labels in self-supervised monocular depth estimation.	O	O	Review	645
The semantic features are predicted by a pretrained network rather than relying on a ground truth.	O	O	Review	645
Moreover, a two-stage training process in proposed in order to filter out images leading to erroneous SfM predictions.	O	O	Review	645
The method is evaluated with different networks on the KITTY dataset.	O	O	Review	645
<sep> <sep> The paper is very well written and clear.	O	O	Review	645
The applications of per-pixel convolutions to this problem seems sound and the experimental validation seems satisfactory.	O	O	Review	645
I have however one main concern (1) and a few additional questions below:	O	O	Review	645
<sep> 1) While (Guizilini 2019) shows that using a larger set of unannotated videos and allows the self-supervised method to eventually outperform supervised methods, this study is not done here.	B-Review	B-1	Review	645
This makes me question the applicability of the approach, as using large unlabelled videos would probably lead to noisy segmentations that could be unhelpful to the depth estimation.	I-Review	I-1	Review	645
Showing an improvement over the supervised baseline would be a much stronger experimental validation, as for now it is difficult to know exactly why in which scenario this method should be used, rather than a supervised network or vanilla packnet.	I-Review	I-1	Review	645
<sep> <sep> 2) I see that you obtain the same numbers in Table 2 / PackNet / row 1 as in (Guizilini 2019); I would like to confirm that you used exactly their self-objective loss, in all your experiments?	B-Review	B-2	Review	645
I would suggest adding to section 3.1.	I-Review	I-2	Review	645
the fact the fact that the loss is the same is in (Guizlini 2019), as a reader could assume that there is novelty in the loss formulation.	I-Review	I-2	Review	645
<sep> <sep> 3) Have you tried fine-tuning the whole architecture including the semantic network end-to-end?	B-Review	B-3	Review	645
<sep> <sep> [It is difficult to know exactly why in which scenario this method should be used, rather than a supervised network or vanilla packnet.]	O	O	Reply	645
<sep> <sep> We apologize for the lack of clarity in the text, which we updated in the new draft, as the scenario described by the reviewer is actually what we do. (	B-Reply	B-1	Reply	645
Guizilini 2019) indeed showed that using unlabeled CityScapes videos improves the performance of self-supervised monocular depth estimation on KITTI to the point where it becomes competitive with fully supervised methods.	I-Reply	I-1	Reply	645
We use exactly this model as our baseline, with the same training protocol as mentioned in Section 5.1.	I-Reply	I-1	Reply	645
Our contribution lies in additionally leveraging the features of a fixed semantic network (pretrained on a separate dataset) to further improve the performance of the depth network, which is pre-trained in a self-supervised way on the same large unlabeled dataset as (Guizilini 2019).	I-Reply	I-1	Reply	645
As the reviewer points out, because we do not use semantic labels during fine-tuning, this could lead to noisy segmentations on the unlabeled videos, which might hurt self-supervised learning at scale.	I-Reply	I-1	Reply	645
However, as shown in the newly added Figure 6 in Appendix B, we find that our learned semantic guidance framework is able to leverage pretrained semantic features in a robust way, determining when their information should be used or discarded in order to further optimize the self-supervised photometric loss.	I-Reply	I-1	Reply	645
<sep> Furthermore, in Table 1 we compare our proposed framework with the supervised method of Ochs et al [1], which uses ground truth for both depth and semantic labels: we significantly outperform their results, even though our method is self-supervised.	I-Reply	I-1	Reply	645
In conclusion, our proposed semantic guidance for self-supervised depth estimation improves on state-of-the-art self-supervised (including the baseline PackNet) and supervised methods (including with semantic and depth supervision).	I-Reply	I-1	Reply	645
Furthermore, it is widely applicable, as it can leverage fixed semantic segmentation networks pretrained on different datasets and does not require semantic supervision in the target unlabeled dataset.	I-Reply	I-1	Reply	645
<sep> <sep> <sep> [I would like to confirm that you used exactly their self-objective loss, in all your experiments.]	O	O	Reply	645
<sep> <sep> We reproduced the state-of-the-art results of (Guizilini 2019) using the same network, loss, and settings, which allowed us to use their approach as our baseline.	B-Reply	B-2	Reply	645
Any improvements generated by our proposed framework are due exclusively to our proposed contributions, i.e. our semantically-guided representation learning and two stage training process.	I-Reply	I-2	Reply	645
We have added this information to Section 3.1.	I-Reply	I-2	Reply	645
<sep> <sep> <sep> [Have you tried fine-tuning the whole architecture including the semantic network end-to-end?]	O	O	Reply	645
<sep> <sep> We agree that exploring this further would yield interesting insights.	B-Reply	B-3	Reply	645
To this end we have performed an additional analysis in Appendix A as suggested.	I-Reply	I-3	Reply	645
Specifically, we study the effects of pre-training the semantic network on different amounts of data and the effects of fine-tuning both networks using only the self-supervised photometric loss.	I-Reply	I-3	Reply	645
We observe that:	I-Reply	I-3	Reply	645
When the semantic network is simply pre-trained on ImageNet and does not encode any dense semantic information, keeping it fixed significantly degrades depth estimation performance (0.197 vs 0.108 for the unguided baseline vs 0.102 for our method).	I-Reply	I-3	Reply	645
Fine-tuning both networks in this case improves performance, but it still falls short of the unguided baseline performance (0.116 vs 0.108).	I-Reply	I-3	Reply	645
<sep> When the semantic network is pre-trained on only half of the training set of CityScapes, it can still successfully guide the depth network, although the semantic predictions are degraded (-5% mIoU on Cityscapes).	I-Reply	I-3	Reply	645
Final depth estimation performance improves a bit less, but the difference is relatively small (0.104 vs 0.102 when fully training the semantic network), confirming the robustness of our approach to a suboptimal semantic network.	I-Reply	I-3	Reply	645
<sep> The previous observation holds as long as the semantic network is not fine-tuned.	I-Reply	I-3	Reply	645
If both networks are fine-tuned, the overall performance indeed suffers and returns to values similar to the baseline (0.107 vs 0.108 for the unguided baseline vs 0.102 for our method), which we attribute to overfitting (the number of free parameters augmenting drastically) and eventual forgetting of the semantic information in the semantic network (as can be attested by the degraded semantic predictions we observed).	I-Reply	I-3	Reply	645
<sep> <sep> <sep> [1] Matthias Ochs, Adrian Kretz, and Rudolf Mester.	O	O	Reply	645
Sdnet: Semantically guided depth estimation network.	O	O	Reply	645
In arXiv:1907.10659, 2019.	O	O	Reply	645

This work proposes to leverage a pre-trained semantic segmentation network to learn semantically adaptive filters for self-supervised monocular depth estimation.	O	O	Review	645
Additionally, a simple two-stage training heuristic is proposed to improve depth estimation performance for dynamic objects that move in a way that induces small apparent motion and thus are projected to infinite depth values when used in an SfM-based supervision framework.	O	O	Review	645
Experimental results are shown on the KITTI benchmark, where the approach improves upon the state-of-the-art.	O	O	Review	645
<sep> <sep> Overview:	O	O	Review	645
<sep> + Good results	O	O	Review	645
+ Doesn't require semantic segmentation ground truth in the monodepth training set	O	O	Review	645
<sep> - Not clear if semantic segmentation is needed	B-Review	B-2	Review	645
- Specific to street scenes	B-Review	B-4	Review	645
- Experiments only on KITTI	B-Review	B-4	Review	645
<sep> The qualitative results look great and the experiments show that semantic guidance improves quantitative performance by a non-trivial factor.	O	O	Review	645
The qualitative results suggest that the results produced with semantic guidance are sharper and more detailed.	O	O	Review	645
However, it is not clear that using features from a pre-trained semantic segmentation network is necessary.	B-Review	B-2	Review	645
The proposed technical approach is to use the pixel-adaptive convolutions by Su et al to learn content-adaptive filters that are conditioned on the features of the pre-trained semantic segmentation network.	I-Review	I-2	Review	645
These filters could in principle be directly learned from the input images, without needing to first train a semantic segmentation network.	I-Review	I-2	Review	645
The original work by Su et al achieved higher detail compared to their baseline by just training the guidance network jointly.	I-Review	I-2	Review	645
Alternatively, the guidance network could in principle be pre-trained for any other task.	I-Review	I-2	Review	645
The main advantage of the proposed scheme is that the guidance path doesn't need to be trained together with the depth network.	I-Review	I-2	Review	645
On the other hand, unless shown otherwise, we have to assume that the network needs to be pre-trained on some data that is sufficiently close to the indented application domain.	I-Review	I-2	Review	645
This would limit the approach to situations where a reasonable pre-trained semantic segmentation network is available.	I-Review	I-2	Review	645
<sep> <sep> The proposed heuristic to filter some dynamic objects is very specific to street scenes and to some degree even to the KITTI dataset.	B-Review	B-3	Review	645
It requires a dominant ground plane and is only able to detect a small subset of dynamic motion (e.g. apparent motion close to zero and object below the horizon).	I-Review	I-3	Review	645
It is also not clear what the actual impact of this procedure is.	I-Review	I-3	Review	645
Section 5.4.2 mentions that Abs.	I-Review	I-3	Review	645
Rel decreases from 0.121 to 0.119, but it is not clear to what this needs to be compared to as there is no baseline in any of the other tables with an Abs.	I-Review	I-3	Review	645
Rel of 0.121.	I-Review	I-3	Review	645
Additionally, while the authors call this a minor decrease, the order of magnitude is comparable to the decrease in error that this method shows over the state-of-the-art (which the authors call statistically significant) and also over the baselines (c.f.	I-Review	I-3	Review	645
Table 2).	I-Review	I-3	Review	645
Can the authors clarify this?	I-Review	I-3	Review	645
<sep> <sep> Related to being specific to street scenes: The paper shows experiments only on the KITTI dataset.	B-Review	B-4	Review	645
The apparent requirement to have a reasonable semantic segmentation model available, make it important to evaluate also in other settings (for example on an indoor dataset like NYU) to show that the approach works beyond street scenes (which is one of the in practice not so interesting settings for monocular depth estimation since it is rather easy to just equip cars with additional cameras to solve the depth estimation problem).	I-Review	I-4	Review	645
<sep> <sep> Need for a reasonable segmentation model: It is not clear in how far the quality of the segmentation network impacts the quality for the depth estimation task.	B-Review	B-1	Review	645
What about the domain shift where the segmentation model doesn't do so well?	I-Review	I-1	Review	645
Even if the segmentation result is not used directly, the features will still shift.	I-Review	I-1	Review	645
How much would depth performance suffer?	I-Review	I-1	Review	645
<sep> <sep> Summary:	O	O	Review	645
While the results look good on a single dataset, I have doubts both about the generality of the proposed approach as well as the need for the specific technical contribution.	B-Review	B-5	Review	645
<sep> <sep> === Post rebuttal update ===	O	O	Review	645
The authors have addressed many of my initial concerns and provided valuable additional experimental evaluations.	O	O	Review	645
While I'd like to upgrade my recommendation to weak accept, I strongly encourage the authors to provide additional experiments on different datasets (at least NYU).	O	O	Review	645
[It is not clear that using features from a pre-trained semantic segmentation network is necessary.	O	O	Reply	645
These filters could in principle be directly learned from the input images, without needing to first train a semantic segmentation network.]	O	O	Reply	645
<sep> <sep> We agree with the reviewer that testing this hypothesis was missing from our ablative analysis.	B-Reply	B-2	Reply	645
Therefore, we performed an additional experiment, added to Table 3 in Appendix A, in which we pretrain the semantic network only on ImageNet.	I-Reply	I-2	Reply	645
This significantly degrades performance (0.197 vs 0.108 for the baseline vs 0.102 Abs.	I-Reply	I-2	Reply	645
Rel.	I-Reply	I-2	Reply	645
for our method).	I-Reply	I-2	Reply	645
This can be partially mitigated when fine-tuning (self-supervised) the semantic and depth networks together, but it still degrades compared to the unguided baseline (0.116 vs 0.108).	I-Reply	I-2	Reply	645
This confirms that, in practice, pretraining the semantic segmentation network is necessary, and our method can effectively transfer indirectly related semantic representations without overfitting.	I-Reply	I-2	Reply	645
<sep> <sep> <sep> [Need for a reasonable segmentation model: It is not clear in how far the quality of the segmentation network impacts the quality for the depth estimation task.]	O	O	Reply	645
<sep> <sep> We agree with the reviewer that, even though we are not directly using semantic predictions, a better semantic network should improve our model, and "unreasonably bad" semantic features (e.g., due to a large domain gap) will degrade our approach.	B-Reply	B-1	Reply	645
Thus, it is important to estimate the relation between the quality (in the target domain) of the semantic network and our final self-supervised depth estimation performance.	I-Reply	I-1	Reply	645
In particular, our guided feature learning approach needs to be robust to suboptimal guiding features to be widely applicable.	I-Reply	I-1	Reply	645
<sep> <sep> Consequently, we added another experimental evaluation in Table 3 in Appendix A where we evaluate how depth estimation performance degrades with a worse semantic network.	I-Reply	I-1	Reply	645
We trained our semantic network on only half of the CityScapes dataset (resulting in a significant 5% decrease in mIoU and qualitatively degraded predictions on KITTI), and use the same self-supervised learning protocol.	I-Reply	I-1	Reply	645
We find only a minor performance degradation (0.104 vs 0.102 when using the fully trained semantic network).	I-Reply	I-1	Reply	645
Furthermore, as reported above, even with no semantic information (i.e. just an ImageNet pretrained semantic network), our performance does not entirely collapse, although it goes below the baseline and strongly benefits from end-to-end finetuning.	I-Reply	I-1	Reply	645
<sep> <sep> In addition, we provide new qualitative evidence in Appendix B Figure 6, showing that our depth network is robust to i) objects never seen by the semantic network (i.e. out of ontology), ii) pixels that have wrong semantic predictions, iii) objects hallucinated by the semantic network.	I-Reply	I-1	Reply	645
Our previous results and these additional ones together confirm our guided feature learning approach is robust to a degradation in the pretrained semantic network, while effectively leveraging its additional information when useful, thus showing wide applicability (i.e. one can re-use a fixed pretrained semantic network across potentially dissimilar unlabeled target domains).	I-Reply	I-1	Reply	645

<sep> I am putting "weak accept" because I think the paper addresses an important problem (domain adaptation) and has an interesting approach.	O	O	Review	134
As the other reviewers pointed out, it's maybe not *super* novel.	O	O	Review	134
But it's still interesting, and pretty readable for the most part.	O	O	Review	134
<sep> I do question the statistical significance of the TIMIT experiments: TIMIT has a very tiny test set to start with, and by focusing on the female portion only you are further reducing the amount.	B-Review	B-1	Review	134
<sep> <sep> Small point: I don't think GANs are technically nonparametric, as the neural nets do have parameters.	B-Review	B-2	Review	134
<sep> <sep> I am a little skeptical that this method would have as general applicability or usefulness as the authors seem to think.	B-Review	B-3	Review	134
The reason is that, since the cycle constraint no longer exists, there is nothing to stop the network from just figuring out the class label of the input (say) image, and treating all the rest of the  information in that image as noise the same way a regular non-cyclic GAN would treat it.	I-Review	I-3	Review	134
Of course, one wouldn't expect a convolutional network to behave like this, but in theory it could happen in general cases.	I-Review	I-3	Review	134
This is just speculation though.	I-Review	I-3	Review	134
Personally I would have tended to accept the paper, but I'm not going to argue with the other reviewers, who are probably more familiar with GAN literature than me.	I-Review	I-3	Review	134
<sep> <sep> --	O	O	Review	134
I am changing from "marginally above acceptance threshold" to "clear accept" after reading the response and thinking about the paper a bit more.	B-Review	B-4	Review	134
I acknowledge that the difference from previously published methods is not that large, but I still think it has value as it's getting quite close to being a practical method for generating fake training data for speech recognition.	I-Review	I-4	Review	134
<sep> <sep> - Comment on ‚Äústatistical significance on TIMIT experiments‚Äù:	O	O	Reply	134
We have chosen TIMIT dataset because of its inherent low-resource domain for different genders.	B-Reply	B-1	Reply	134
As shown in Table 3, when using only Male speech for training the network, testing on female	I-Reply	I-1	Reply	134

The authors propose an extension of cycle-consistent adversarial adaptation methods in order to tackle domain adaptation in settings where a limited amount of supervised target data is available (though they also validate their model in the standard unsupervised setting as well).	O	O	Review	134
The method appears to be a natural generalization/extension of CycleGAN/CyCADA.	O	O	Review	134
It uses the ideas of the semantic consistency loss and training on adapted data from CyCADA, but "fills out" the model by applying these techniques in both directions (whereas CyCADA only applied them in the source-to-target direction).	O	O	Review	134
<sep> <sep> The writing in this paper is a little awkward at times (many omitted articles such as "the" or "a'), but, with a few exceptions, it is generally easy to understand what the authors are saying.	B-Review	B-1	Review	134
They provide experiments in a variety of settings in order to validate their model, including both visual domain adaptation and speech domain adaptation.	I-Review	I-1	Review	134
The experiments show that their model is effective both in low-resource supervised adaptation settings as well as high-resource unsupervised adaptation settings.	I-Review	I-1	Review	134
An ablation study, provided in Section 4.1, helps to understand how well the various instantiations of the authors' model perform, indicating that enforcing consistency in both methods is crucial to achieving performance beyond the simple baselines.	I-Review	I-1	Review	134
<sep> <sep> It's a little hard to understand how this method stands in comparison to existing work.	B-Review	B-2	Review	134
Table 3 helps to show that the model can scale up to the high-resource setting, but it would also be nice to see the reverse: comparisons against existing work run in the limited data setting, to better understand how much limited data negatively impacts the performance of models that weren't designed with this setting in mind.	I-Review	I-2	Review	134
<sep> <sep> I would've also liked to see more comparisons against the simple baseline of a classifier trained exclusively on the available supervised target data, or with the source and target data together‚Äîin my experience, these baselines can prove to be surprisingly strong, and would give a better sense of how effective this paper's contributions are.	B-Review	B-3	Review	134
This corresponds to rows 2 and 3 of Table 1, and inspection of the numbers in that table shows that the baseline performance is quite strong even relative to the proposed method, so it would be nice to see these numbers in Table 2 as well, since that table is intended to demonstrate the model's effectiveness across a variety of different domain shifts.	I-Review	I-3	Review	134
<sep> <sep> While it's nice that the model is experimentally validated on the speech domain, the experiment itself is not explained well.	B-Review	B-4	Review	134
The speech experiments are hard to understand‚Äîit's unclear what the various training sets are, such as "Adapted Male" or "All Data," making it hard to understand exactly what numbers should be compared.	I-Review	I-4	Review	134
Why is there no CycleGAN result for "Female + Adapted Male," or "All Data + Adapted Male," for example?	I-Review	I-4	Review	134
The paper would greatly benefit from a more careful explanation and analysis of this experimental setting.	I-Review	I-4	Review	134
<sep> <sep> Ultimately, I think the idea is a nice generalization of previous work, and the experiments seem to indicate that the model is effective, but the limited scope of the experiments prevent me from being entirely convinced.	O	O	Review	134
The inclusion of additional baselines and a great deal of clarification on the speech experiments would improve the quality of this paper enormously.	O	O	Review	134
<sep> <sep> ---	O	O	Review	134
<sep> Update: After looking over the additional revisions and experiments, I'm bumping this to a weak accept.	O	O	Review	134
I agree with reviewer 3 that novelty is not the greatest, but there is a useful contribution here, and the demonstration of its effectiveness on low resource settings is valuable, since in a practical setting it is usually feasible to manually label a few examples.	O	O	Review	134
<sep> <sep> I'm still not convinced by the TIMIT experiments, now that I better understand them, since the F+M baseline is quite strong and very simple to run.	B-Review	B-5	Review	134
It simply doesn't seem worthwhile to introduce all of this extra machinery for such a marginal improvement, but the experiment does serve the job of at least demonstrating an improvement over existing methods.	I-Review	I-5	Review	134
Comment on ‚Äúlow-resource supervised adaptation, Table 2‚Äù:	O	O	Reply	134
To provide more baseline results on low-resource supervised adaptation, we ran additional experiments and replaced table 2 with bar plots in Figure 3.	B-Reply	B-1	Reply	134
Baselines include classifier trained on low-resource target data, and including source data, with no adaptation.	I-Reply	I-1	Reply	134
As shown in Figure 3, Augmented-Cyc algorithm outperforms FADA model and the two baselines.	I-Reply	I-1	Reply	134
<sep> <sep> Comment on ‚Äúcomparing with existing works on low-resource unsupervised adaptation‚Äù:	O	O	Reply	134
We added experiments on low-resource unsupervised adaptation to compare with CyCADA, and the results are shown in Figure 2.	B-Reply	B-2	Reply	134
This experiment  investigates the effectiveness and robustness of using two cycle with semantic consistency enforced by auxiliary task loss, compared to CyCADA, where semantic consistency is enforced by reconstruction loss.	I-Reply	I-2	Reply	134
As shown in Figure 2, CyCADA model fails to learn a good adaptation, where target domain contains few unsupervised data.	I-Reply	I-2	Reply	134
Additionally, CyCADA model shows high instability in low-resource situation.	I-Reply	I-2	Reply	134
Our model achieves more robust and better performance.	I-Reply	I-2	Reply	134
We think this is attributed to proper use of source classifier to enforce consistency and robustness that we get by using two cycles (also shown in ablation study in Table 1).	I-Reply	I-2	Reply	134
<sep> <sep> Comment on speech domain experiments:	O	O	Reply	134
We have edited the speech experiment section for more clarification.	B-Reply	B-4	Reply	134
To mention some, ‚ÄúAdapted Male‚Äù is changed to ‚ÄúMale-> Female‚Äù to preserve consistency in notation. ‚	I-Reply	I-4	Reply	134
ÄúAll Data‚Äù refers to ‚ÄúMale+Female‚Äù with no adaption.	I-Reply	I-4	Reply	134
CycleGAN results are added for"Female + Adapted Male," or "All Data + Adapted Male,‚Äù	I-Reply	I-4	Reply	134

This paper introduces a domain adaptation approach based on the idea of Cyclic GAN.	O	O	Review	134
Two different algorithms are proposed.	O	O	Review	134
The first one incorporates a semantic consistency loss based on domain-specific classifiers acting on full cycles of the of the generators.	O	O	Review	134
The second one also makes use of domain-specific classifiers, but acting either directly on the training samples or on the data mapped from one domain to the other.	O	O	Review	134
<sep> <sep> Strengths:	O	O	Review	134
- The different terms in the proposed loss functions are well justified.	O	O	Review	134
<sep> - The results on low-resources supervised domain adaptation indicate that the method works better than the that of Motiian et al 2017.	O	O	Review	134
<sep> <sep> Weaknesses:	O	O	Review	134
- Novelty is limited: The two algorithms are essentially small modification of the semantic consistency term used in Hoffman et al 2018.	B-Review	B-1	Review	134
They involve making use of both the source and target classifiers, instead of only the source one, and, for the relaxed version, making use of complete cycles instead of just one mapping from one domain to the other.	I-Review	I-1	Review	134
While the modifications are justified, I find this a bit weak for ICLR.	I-Review	I-1	Review	134
<sep> <sep> - It is not clear to me why it is worth presenting the relaxed cycle-consistency object, since it always yields worse results than the augmented one.	B-Review	B-2	Review	134
In fact, at first, I though both objectives would be combined in a single loss, and was thus surprised not to see Eq.5 appear in Algorithm 1.	I-Review	I-2	Review	134
It only became clear when reading the experiments that the authors were treating the two objectives as two different algorithms.	I-Review	I-2	Review	134
Note that, in addition to not performing as well as the augmented version, it is also unclear how the relaxed one could work in the unsupervised scenario.	I-Review	I-2	Review	134
<sep> <sep> - Experiments:	O	O	Review	134
* In 4.1, the authors mention that 10 samples per class are available in the target domain.	B-Review	B-3	Review	134
Are they labeled or unlabeled?	I-Review	I-3	Review	134
If labeled, are additional unlabeled samples also used?	I-Review	I-3	Review	134
<sep> * In Table 1, and in Table 3, is there a method that corresponds to CyCADA?	B-Review	B-4	Review	134
I feel that this comparison would be useful considering the similarity.	I-Review	I-4	Review	134
That said, I also understand that CyCADA uses both a reconstruction term (as in Eq.4) and a semantic consistency one, whereas here only a semantic reconstruction term is used.	I-Review	I-4	Review	134
I therefore suggest the authors to also compare with a baseline that replaces their objective with the semantic consistency one of CyCADA, i.e., CyCADA without reconstruction term.	I-Review	I-4	Review	134
<sep> * In 4.2, it is again not entirely clear if the authors use only the few labeled samples, or if this is complemented with additional unlabeled samples.	B-Review	B-5	Review	134
In any event, does this reproduce the setting used by Motiian et al 2017?	I-Review	I-5	Review	134
<sep> * As the argument is that the proposed loss is better than the reconstruction one and that of Hoffman et al 2018 for low-resource supervised adaptation, it would be worth demonstrating this empirically in Table 2.	B-Review	B-6	Review	134
<sep> <sep> Summary:	O	O	Review	134
The proposed objective functions are well motivated, but I feel that novelty is too limited and the current set of experiments not sufficient to warrant publication at ICLR.	O	O	Review	134
<sep> <sep> After Response:	O	O	Review	134
After the authors' response/discussion, while I appreciate the additional results provided by the authors, I still feel that the contribution is a bit weak for ICLR.	O	O	Review	134
<sep> <sep> Comment on Weakness, and similarity to CyCADA model:	O	O	Reply	134
To differentiate between our model and CyCADA, below is the detail of two models and how they perform semantic consistency, and enforcing style adaptation	B-Reply	B-4	Reply	134
CyCADA:	I-Reply	I-4	Reply	134
semantic (content) consistency is enforced by two loss; reconstruction loss (CycleGAN); and additionally using reconstruction at feature level.	I-Reply	I-4	Reply	134
<sep> Style adaptation is enforced using adversarial learning on pixel (observation) and feature (hidden) space.	I-Reply	I-4	Reply	134
Therefore, it need to learn additional model for representing data in feature space.	I-Reply	I-4	Reply	134
<sep> <sep> Augmented-Cyc:	I-Reply	I-4	Reply	134
semantic consistency is shown to be achieved by only using auxiliary task loss for each cycle.	I-Reply	I-4	Reply	134
<sep> Style adaptation is achieved by using adversarial learning on pixel (observation) space only.	I-Reply	I-4	Reply	134
<sep> We use cycles in both direction to achieve robust performance in low resource (either supervised or unsupervised) setting.	I-Reply	I-4	Reply	134
<sep> <sep> Therefor, CyCADA requires an additional adversarial learning at feature space, while our model achieve this by only adaptation at observation space.	I-Reply	I-4	Reply	134
Moreover, to compare the performance of the two model on variable-size target domain, we added more experiments for low resource unsupervised adaptation (see Figure 2).	I-Reply	I-4	Reply	134
It is evident that CyCADA model fails to provide suitable adaptation, while our model outperforms by large margin, when target domain data is small	I-Reply	I-4	Reply	134
Note: Both our ablation (see Table 1) and additional experiments (see Figure 2) suggest the benefit of using two cycles for low resource situation, whether supervised or unsupervised.	I-Reply	I-4	Reply	134
Therefore, we think this is an important aspect for robust domain adaptation under resource constraint.	I-Reply	I-4	Reply	134
<sep> <sep> Comment on relaxed cycle consistency:	O	O	Reply	134
The main purpose of presenting relaxed-consistency results in ablation study is to demonstrate the effectiveness of using auxiliary task loss in any or both cycles, rather than L1 reconstruction loss.	B-Reply	B-2	Reply	134
We have only evaluated relaxed-consistency in low-resource supervised setting, and it is not evaluated for unsupervised adaptation.	I-Reply	I-2	Reply	134
In unsupervised setting, we are using source classifier M_{S} as pseudo-labeler of target samples.	I-Reply	I-2	Reply	134
<sep> <sep> Note: In this setting, if we turn off using task model M_{T} to be trained using source data, this is similar to using relaxed version in unsupervised adaptation	I-Reply	I-2	Reply	134
<sep> <sep> Comments on Experiments:	O	O	Reply	134
<sep> For all low resource target domain experiment, only the denoted number of samples are used, irrespective if they are labeled or not.	O	O	Reply	134
For example, in supervised case, 10 labeled sample per class means we only use 10 labeled samples per class in the target domain is used and no other data is used in the target domain.	O	O	Reply	134
Similarly for unsupervised case, 5 samples per class means only used 5 unsupervised samples from target domain.	O	O	Reply	134
<sep> <sep> - Section 4.1:  we only used 10 labeled sample per class.	B-Reply	B-3	Reply	134
In this experiment, NO unlabeled data is used.	I-Reply	I-3	Reply	134
<sep> <sep> - Table 1: this table is intended for ablation of our model.	B-Reply	B-4	Reply	134
<sep> <sep> - Table 3: we have added CyCADA results in this table for comparison.	B-Reply	B-4	Reply	134
To directly compare our model with CyCADA, we added new experiments on variable-size target domain which is presented in Figure 2.	I-Reply	I-4	Reply	134
<sep> <sep> - Section 4.2: Table 2 is replaced with Figure 3, for low-resource supervised adaptation.	B-Reply	B-5	Reply	134
In this experiment, no unlabeled data is used, and it is a direct comparison between our model and FADA (Motiian et al 2017)	I-Reply	I-5	Reply	134
<sep> In Figure 2, we have shown the benefit of the proposed auxiliary task-specific loss to reconstruction loss (CyCADA) on low-resource unsupervised domain adaptation.	B-Reply	B-4	Reply	134

For news article it has been know since long that the LEAD baseline is a tough-to-beat competitor.	O	O	Review	134
This paper proposes to use this knowledge as self-supervision for training summarization models.	O	O	Review	134
<sep> For this the author download and clean 3 years of news articles and use this to (pre-)train a Tranformer model.	O	O	Review	134
This alone already provides a competitive baseline, which is greatly improved by fine-tuning it on 3 different data-sets.	O	O	Review	134
While the data-set can probably not be released, it would be very helpful to have the model available for reproductivity and benchmarking.	O	O	Review	134
<sep> <sep> The paper is clear and well-written.	O	O	Review	134
Section 4 I believe is very redundant for an ICLR audience and could be moved to the appendix, making space for a more detailed analysis.	O	O	Review	134
One criticism is that the paper is light: the author show that a simple idea works (this is a compliment), but I would have expected to have used the remaining space for ablation studies or a discussion on where this leads.	B-Review	B-1	Review	134
<sep> One important point which I would like to see before recommending acceptance is a comparison to know if what is helping is just more data, or the summarization objective.	B-Review	B-2	Review	134
Using lots of more data beats all those numbers (see BERTSUM paper, Liu &amp; Lapata 2019).	I-Review	I-2	Review	134
The comparison I am missing is training BERT on your crawled data-set, and use that for BERTSUM (the code is available).	I-Review	I-2	Review	134
If that helps as much as the summarization pre-training then it would be disappointing but a nice result in favor of language modeling.	I-Review	I-2	Review	134
If not, then it is a strong support for your idea.	I-Review	I-2	Review	134
<sep> <sep> Two other points which should at least be discussed, as it gives the impression of cherry-picking results instead:	B-Review	B-3	Review	134
1/ Table 1 is recall; Table 2&amp;3 F1.	I-Review	I-3	Review	134
Why?	I-Review	I-3	Review	134
<sep> 2/ The parameters of fine-tuning of the appendix vary wildly depending on the data-set (in particular, the difference in the width of the beam search is striking).	B-Review	B-4	Review	134
Was this optimized on test-data?	I-Review	I-4	Review	134
What is the sensitivity of the summaries to this?	I-Review	I-4	Review	134
<sep> <sep> I do not understand the last two sentences of Sect 4 ("A candidate word leading...).	B-Review	B-5	Review	134
Could you explain?	I-Review	I-5	Review	134
For where our result leads, we argue that taking advantage of positional bias or any structural information can help with model pretraining.	B-Reply	B-1	Reply	134
This has a lot of importance as nowadays large pretrained models have proved to be very effective in NLP.	I-Reply	I-1	Reply	134
Furthermore, our idea offers a different angle from the masked language model, which is more artificially created.	I-Reply	I-1	Reply	134
<sep> <sep> The idea of pretraining BERT on our large news corpus then using BERTSUM is very good.	B-Reply	B-2	Reply	134
Due to time limit, we could not finish this experiment before the rebuttal deadline.	I-Reply	I-2	Reply	134
But we will definitely follow this idea and conduct experiments.	I-Reply	I-2	Reply	134
In accordance with your idea, we add in results from the GPT-2 model for CNN/DailyMail and DUC2003/2004 (Table 3&amp;4), and it is outperformed by our pretrained-only method PL-NoFT.	I-Reply	I-2	Reply	134
As both models are pretrained on unlabeled data, this result shows the effectiveness of our approach.	I-Reply	I-2	Reply	134
<sep> <sep> For your questions,	O	O	Reply	134
1) We use recall on NYT and F1 in XSum/CNN exactly following BERTSUM (<a href="https://arxiv.org/pdf/1908.08345.pdf)" target="_blank" rel="nofollow">https://arxiv.org/pdf/1908.08345.pdf)</a> for fair comparison.	B-Reply	B-3	Reply	134
<sep> <sep> 2) The hyper-parameters are tuned on the validation data using the pre-trained model.	B-Reply	B-4	Reply	134
Then the finetuned model also takes the same set of hyper-parameters.	I-Reply	I-4	Reply	134
The result is not very sensitive to these parameters.	I-Reply	I-4	Reply	134
<sep> For example, in XSUM, the ROUGE-1 on validation data with different beam-width:	I-Reply	I-4	Reply	134
1<tab>23.355 (* we choose this)	I-Reply	I-4	Reply	134
2<tab>22.91	I-Reply	I-4	Reply	134
3<tab>23.011	I-Reply	I-4	Reply	134
4<tab>22.391	I-Reply	I-4	Reply	134
5<tab>22.318	I-Reply	I-4	Reply	134
<sep> 3) The last but one sentence means trigram blocking: if the next generated word triggers a duplicate trigram, we do not use it.	B-Reply	B-5	Reply	134
Like "A A B A A", if "B" is the next top word candidate, we ignore it as it will triggle a duplicate trigram AAB.	I-Reply	I-5	Reply	134
<sep> The last sentence means we compute the average cross entropy per word as criterion, which is a popular standard in generation.	I-Reply	I-5	Reply	134
If the sum is used,	I-Reply	I-5	Reply	134
shorter sentences are favored.	I-Reply	I-5	Reply	134

This paper suggests generating a large news summarization dataset by taking advantage of the fact that in news articles it is often the case that first few sentences contain the most important information.	O	O	Review	134
I have the following criticisms of this paper:	O	O	Review	134
- the idea is not novel.	B-Review	B-1	Review	134
The XSUM dataset cited had used this to create a large dataset based on BBC articles as the editorial guidelines are such that the first sentence is a summary of the article.	I-Review	I-1	Review	134
The lead1 baseline doesn't make sense, as it is the actual reference of the dataset.	I-Review	I-1	Review	134
As implemented, it actually picks the second sentence of the original article, and unsurprisingly works worse than the lead-X for the other two datasets.	I-Review	I-1	Review	134
<sep> - the filtering based on word overlap between the initial sentences and the rest of the document means that the training dataset will encourage models copying words; good summaries don't have high word overlap necessarily.	B-Review	B-2	Review	134
<sep> - no human evaluation is not conducted; ROUGE indicates small differences, but it can't be trusted without confirmation by human evaluation	B-Review	B-3	Review	134
- I don't agree that using positional information is bad for the models.	B-Review	B-4	Review	134
The point is that we need to do better than that, but we should still take it into account	I-Review	I-4	Review	134
For your questions:	O	O	Reply	134
1.	O	O	Reply	134
Our idea is novel in that we use the structural bias in our favor to pretrain a large-scale news summarization model.	B-Reply	B-1	Reply	134
For XSUM dataset, according to its paper, it uses the accompanying summary which is the first sentence in BOLD font in the article.	I-Reply	I-1	Reply	134
It is specially editted by editors to summarize an article.	I-Reply	I-1	Reply	134
So it's a special format of BBC articles which facilitates fast reading, not just the first sentence of the article.	I-Reply	I-1	Reply	134
Therefore, the LEAD-1 baseline, which is also used in XSUM and BERTSUM papers, is a valid leading part of the article.	I-Reply	I-1	Reply	134
<sep> <sep> 2.	O	O	Reply	134
The filtering is based on non-stopping words, and the overlapping ratio implies the amount of carried-over information.	B-Reply	B-2	Reply	134
As an evidence, we compute the overlapping ratio of non-stopping words between golden summary and the article in CNN/DailyMail dataset and the median is 0.87 (which is not surprising due to lead bias).	I-Reply	I-2	Reply	134
Then we compute the same ratio between the first 3 sentences and the rest of the article in CNN/DailyMail, and the median is 0.77.	I-Reply	I-2	Reply	134
Thus, a high overlapping ratio is typical for summaries written by human.	I-Reply	I-2	Reply	134
We add this information in Section 5.2.	I-Reply	I-2	Reply	134
<sep> <sep> 3.	O	O	Reply	134
We conduct human evaluation on 100 randomly chosen articles/summaries in CNN/DailyMail dataset and show the results in Section 5.7.	B-Reply	B-3	Reply	134
Our model outperforms the pointer-generator network and the result is statistically significant.	I-Reply	I-3	Reply	134
<sep> <sep> 4.	O	O	Reply	134
Positional bias helps with fast news reading, and it also eases the creation of news summarization datasets.	B-Reply	B-4	Reply	134
However, the positional bias lowers the bar for model to comprehend the article for summary generation.	I-Reply	I-4	Reply	134
Positional bias is not present in many tasks other than news, like document or dialogue transcript summarization.	I-Reply	I-4	Reply	134
Therefore, we propose our method to take advantage of lead bias and train a model that could summarize based more on the content, instead of the position.	I-Reply	I-4	Reply	134

This paper proposed an interesting idea on how we can leverage the lead bias in summarization datasets to pretrain abstractive news summarization models on large-scale unlabelled corpus in simple and effective way.	O	O	Review	134
<sep> <sep> For pre-training, they collected three years of online news articles data.	O	O	Review	134
Then, they take the top 3 sentences of the article as summary and the rest of the article as input document.	O	O	Review	134
For better choosing such article-summary pairs, they employ effective data cleaning and filtering process.	O	O	Review	134
Overall, they collected 21.4M articles for the pretraining.	O	O	Review	134
<sep> Overall, the pretrained model does decent on three summarization datasets without any fine-tuning.	O	O	Review	134
After fine-tuning the respective datasets, the gains seem significant.	O	O	Review	134
Especially on the XSum dataset, the improvements are remarkable.	O	O	Review	134
<sep> <sep> I believe that the idea is interesting but the experiments are incomplete and more investigation is required to make this paper stronger.	O	O	Review	134
Therefore I suggest to reject this paper.	O	O	Review	134
<sep> <sep> Arguments:	O	O	Review	134
1) The important experiments that are missing in this paper are evaluating the proposed method on better human written summarization datasets -- DUC.	B-Review	B-1	Review	134
The real world summarizations resemble more like the ones in the DUC dataset and it would be interesting to see if the transfer results of the pretrained model on the DUC datasets.	I-Review	I-1	Review	134
The important question is to understand whether the pretrained model which took advantage of lead-bias could achieve good summaries on real summarization samples.	I-Review	I-1	Review	134
This would also answer whether the pretrained just took advantage of the lead-bias issue of many large summarization datasets or does it really learn good summarization model.	I-Review	I-1	Review	134
<sep> <sep> 2) This paper has good idea but mainly missing ablation studies.	B-Review	B-2	Review	134
For example, how does the proposed model do compared with GPT-2 in the fine-tuning setting, and how do these two models perform on the DUC datasets.	I-Review	I-2	Review	134
<sep> <sep> 3) During the dataset filtering/collection, a check on the quality of the filtering process by doing a small human study would have been a great addition.	B-Review	B-3	Review	134
Also, instead of showing the output examples (which can go in the supplementary), human study comparing the quality of the pretrained model with fine-tuning and a baseline (can be from previous work) would have been better.	I-Review	I-3	Review	134
<sep> <sep> Other minor questions	O	O	Review	134
1) ‚Äúwe only keep articles with 10-150 words in the top three sentences and 150-1200 words in the rest‚Äù -- is there any reason on fixing to these numbers?	B-Review	B-4	Review	134
How did you make this decision ?	I-Review	I-4	Review	134
<sep> <sep> 2) Even though the performance gains look visibly significant, I would suggest to report the statistical significance scores.	B-Review	B-5	Review	134
<sep> <sep> For your questions:	O	O	Reply	134
1.	O	O	Reply	134
We add experiments on DUC-2003 and DUC-2004, using the dataset as test (Table 4).	B-Reply	B-1	Reply	134
Our pretrained model achieves state-of-the-art results among all unsupervised models.	I-Reply	I-1	Reply	134
<sep> <sep> 2.	O	O	Reply	134
We add GPT-2's result for CNN/DailyMail and DUC-2003/2004 datasets (Table 3,4).	B-Reply	B-2	Reply	134
GPT-2 is outperformed by our pretrained-only model PL-NoFT.	I-Reply	I-2	Reply	134
This is a fair comparison since these two models are both trained only on unlabeled corpus, although GPT-2 has general purposes.	I-Reply	I-2	Reply	134
Thus, we argue that our pretraining strategy works better in news summarization.	I-Reply	I-2	Reply	134
<sep> <sep> 3.	O	O	Reply	134
We conduct human evaluation on 100 randomly chosen articles/summaries in CNN/DailyMail dataset and show the results in Section 5.7.	B-Reply	B-3	Reply	134
Our model outperforms the pointer-generator network and the result is statistically significant.	I-Reply	I-3	Reply	134
<sep> <sep> Answers to minor questions:	O	O	Reply	134
1.	O	O	Reply	134
There are a few articles with excessively long content, and we filter them mainly to reduce memory consumption.	B-Reply	B-4	Reply	134
Also some leading sentences are very short (like "What?")	I-Reply	I-4	Reply	134
and we filter them as they contain little information and are unlikely to be a good summary.	I-Reply	I-4	Reply	134
As the pretraining task is very time-consuming, we did not try other settings.	I-Reply	I-4	Reply	134
We add these information in Section 5.2.	I-Reply	I-4	Reply	134
<sep> <sep> 2.	O	O	Reply	134
We conduct statistical test on the ROUGE-scores and update all tables.	B-Reply	B-5	Reply	134
Most of our results are statistically significant with p-value &lt; 0.05, compared with previous best result.	I-Reply	I-5	Reply	134

This is an interesting direction.	O	O	Review	318
There is still much to understand about the relative strengths and limitations of model based and model free techniques, and how best to combine them, and this paper discusses a new way to address this problem.	O	O	Review	318
The empirical results are promising and the ablation studies are good, but it also makes me wonder a bit about where the benefit is coming from.	O	O	Review	318
<sep> <sep> Could you please put a bit of discussion in about the computational and memory cost.	B-Review	B-1	Review	318
TDM is now parameterized with (state, action (goal) state, and the horizon tau).	I-Review	I-1	Review	318
Essentially it is now computing the distance to each possible goal state after starting in state (s,a) and taking a fixed number of steps.	I-Review	I-1	Review	318
<sep> It seems like this is less compact than learning a 1-step dynamics model directly.	B-Review	B-2	Review	318
<sep> The results are better than models in some places.	B-Review	B-3	Review	318
It seems likely this is because the model-based approach referenced doesn‚Äôt do multi-step model fitting, but essentially TDM is, by being asked to predict and optimize for C steps away.	I-Review	I-3	Review	318
If models were trained similarly (using multi-step loss) would models do as well as TDM?	I-Review	I-3	Review	318
<sep> How might this be extended to the stochastic setting?	B-Review	B-4	Review	318
<sep> <sep> Thank you for your feedback!	O	O	Reply	318
<sep> <sep> One concern brought up is the computation and memory cost of using TDMs.	B-Reply	B-1	Reply	318
To address this concern, we have added discussion of this point in Section 4.3, paragraph 2, as well as Figure 4 in the appendix.	I-Reply	I-1	Reply	318
In short, the learning for TDM and DDPG both have the number of updates per environment step as a hyperparameter, which largely determines the computation cost.	I-Reply	I-1	Reply	318
The empirical result we got is that as we increased the number of updates, the performance of TDM increased while the performance of DDPG stayed the same or degraded.	I-Reply	I-1	Reply	318
TDMs can benefit from more computation (number of updates per environment step) than DDPG since they can learn a lot more by relabeling goal states and horizon tau; we see this more as a benefit as it means TDMs can extract more information from the same amount of data.	I-Reply	I-1	Reply	318
We also would like to point out that one advantage of doing more computation at training time is that test time is relatively fast: to do multi-step planning, we simply set tau=5 in our TDM, whereas a typical multi-step model-based planning approach would need to unroll a model over five time steps and optimize over all intermediate actions.	I-Reply	I-1	Reply	318
Furthermore, we hope that this, in addition to the ablative studies in section 6.2, addresses the concern that, ‚Äú‚Ä¶ it also makes me wonder a bit about where the benefit is coming from.	I-Reply	I-1	Reply	318
‚Äù	I-Reply	I-1	Reply	318
<sep> For stochastic environments, the TDM would learn the expected distance to the goal, rather than the exact distance.	B-Reply	B-4	Reply	318
We have added this discussion to the second paragraph of the conclusion.	I-Reply	I-4	Reply	318
<sep> <sep> We agree that a more in-depth discussion of the connection to multi-step models would be appropriate.	B-Reply	B-3	Reply	318
We‚Äôve added discussion of two related works in Section 5, paragraph 4.	I-Reply	I-3	Reply	318
One critical distinction between these methods and TDMs is that TDMs can be viewed as goal conditioned models: the prediction is made T steps into the future, conditioned on a policy that is trying to reach a particular state.	I-Reply	I-3	Reply	318
Most model learning methods do not condition on a policy, requiring them to take in an entire sequence of future actions, which greatly increases the input space.	I-Reply	I-3	Reply	318

<sep> This paper proposes a "temporal difference model learning", a method that aims to combine the benefits of model-based and model-free RL.	O	O	Review	318
The proposed method essentially learns a time-varying goal-conditional value function for a specific reward formulation, which acts as a surrogate for a model in an MPC-like setting.	O	O	Review	318
The authors show that the method outperforms some alternatives on three continuous control domains and real robot system.	O	O	Review	318
<sep> <sep> I believe this paper to be borderline, but ultimately below the threshold for acceptance.	O	O	Review	318
On the positive side, there are certainly some interesting ideas here: the notion of goal-conditioned value functions as proxies for a model, and as a means of merging model-free and model-based approaches is very really interesting, and hints at a deeper structure to goal-conditioned value functions in general.	O	O	Review	318
Ultimately, though, I feel that there are two main issues that make this research feel as though it is still ultimately in the earlier stages: 1) the very large focus on the perspective that this approach is unifying model-based and model-free RL, when it fact this connection seems a bit tenuous; and 2) the rather lackluster experimental results, which show only marginal improvement over purely model-based methods (at the cost of much additional complexity), and which make me wonder if there's an issue with their implementation of prior work (namely the Highsight Experience Replay algorithm).	B-Review	B-5	Review	318
<sep> <sep> To address the first point, although the paper stresses it to a very high degree, I can't help but feel that the connection that the claimed advance of "unifying model-based and model-free RL" is overstated.	B-Review	B-1	Review	318
As far as I can tell, the connection is as follows: the learned quantity here is a time-varying goal-conditioned value function, and under some specific definition of reward, we can interpret the constraint that this value function equal zero as a proxy for the dynamics constraint in MPC.	I-Review	I-1	Review	318
But the exact correspondence between this and the MPC formulation only occurs for a horizon of size zero: longer horizons require a multi-step MPC for the definition of the model-free and model-based correspondence.	I-Review	I-1	Review	318
The fact that the action selection of a model-based method and this approach have some function which looks similar (but only under certain conditions), just seems like a fairly odd connection to highlight so heavily.	I-Review	I-1	Review	318
<sep> <sep> Rather, it seems to me that what's happening here is really quite simple: the authors are extending goal-conditioned value functions to the case of non-stationary finite horizon value functions (the claimed "key insight" in eq (5) is a completely standard finite-horizon MDP formulation).	B-Review	B-4	Review	318
This seems to describe perfectly well what is happening here, and it does also seem intuitive that this provides an advantage over stationary goal-conditioned value functions: just as goal conditioned value functions offer the advantage of considering "every state as a goal", this method can consider "every state as a goal for every time horizon".	I-Review	I-4	Review	318
This seems interesting enough on its own, and I admit I don't see the need for the method to be yet another claimed unification of model-free and model-based RL.	I-Review	I-4	Review	318
<sep> <sep> I would also suggest that the authors look into the literature on how TD methods implicitly learn models (see e.g. Boyan 1997 "Least-squares temporal difference learning", and Parr et al 2007 "An analysis of linear models...").	B-Review	B-2	Review	318
In these works it has been shown that least squares TD methods (at least in the linear feature setting), implicitly learn a dynamics model in feature space, but only the "projection" of the reward function is actually needed to learn the TD weights.	I-Review	I-2	Review	318
In building the proposed value functions, it seems like the authors are effectively solving for multiple rewards simultaneously, which would effectively preserve the learned dynamics model.	I-Review	I-2	Review	318
I feel like this may be an interesting line of analysis for the paper if the authors _do_ want to stick with the notion of the method as unifying model-free and model-based RL.	I-Review	I-2	Review	318
<sep> <sep> All these points may ultimately just be a matter of interpretation, though, if not for the second issue with the paper, which is that the results seem quite lackluster, and the claimed performance of HER seems rather suspicious.	B-Review	B-3	Review	318
But instead, the authors evaluate the algorithm on just three continuous control tasks (and a real robot, which is more impressive, but the task here is still so extremely simple for a real robot system that it really just qualifies as a real-world demonstration rather than an actual application).	I-Review	I-3	Review	318
And in these three settings, a model-based approach seems to work just as well on two of the tasks, and may soon perform just as well after a few more episodes on the last task (it doesn't appear to have converged yet).	I-Review	I-3	Review	318
And despite the HER paper showing improvement over traditional policy approaches, in these experiments plain DDPG consistently performs as well or better than HER.	I-Review	I-3	Review	318
Thank you for your feedback!	O	O	Reply	318
<sep> <sep> To address the reviewer‚Äôs concerns about the experiments, we ran our algorithm on more difficult tasks and have updated the experimental results.	B-Reply	B-4	Reply	318
We would like to emphasize is that a primary goal of our method is to achieve both sample-efficiency and good final performance.	I-Reply	I-4	Reply	318
While the asymptotic performance of TDMs may not always be far better than that the model-free methods, TDMs are substantially more sample-efficient, as shown in the updated Figure 2.	I-Reply	I-4	Reply	318
We consider this important, as sample efficiency is important in many real-world tasks, such as robotics, where collecting data is expensive.	I-Reply	I-4	Reply	318
For the model-based baseline, a concern brought up was that, ‚Äúmodel-based approach‚Ä¶may soon perform just as well after a few more episodes on the last task (it doesn't appear to have converged yet).‚Äù We ran the half-cheetah experiments for more iterations and see that the trend is the same: TDM converges to a better solution than the model-based baseline, by a significant margin.	I-Reply	I-4	Reply	318
We also evaluated our method on two substantially more complex 3D locomotion tasks using the ‚Äúant‚Äù quadrupedal robot.	I-Reply	I-4	Reply	318
We tested two tasks: asking the ant to run to a target location, and asking it to achieve a target location at the same time as a target velocity (this is meant to be representative, e.g., of the ant attempting to make a jump).	I-Reply	I-4	Reply	318
The latter task is particularly interesting, since the ant cannot maintain both the position and velocity goal at the same time, and must therefore achieve it at a single time step.	I-Reply	I-4	Reply	318
TDMs significantly outperform the model-based baseline on these tasks as well.	I-Reply	I-4	Reply	318
This supports the central claim of the paper, in Section 1, paragraph 5, which is that TDMs achieve learning times comparable to model-based methods, but asymptotic performance that is comparable to model-free algorithms.	I-Reply	I-4	Reply	318
We believe that this kind of improvement in learning performance is of substantial interest to the reinforcement learning community.	I-Reply	I-4	Reply	318
<sep> <sep> We were able to obtain the code for hindsight experience replay (HER) from the original authors.	B-Reply	B-3	Reply	318
Using this code as reference, we improved our implementation by incorporating their hyperparameter settings and implementation details, including ones that we had difficulty deducing from the original HER paper.	I-Reply	I-3	Reply	318
The performance of HER on our tasks did improve, and we have updated Figure 2 with the new results.	I-Reply	I-3	Reply	318
At this point, with the help of the original authors, we are confident that our implementation of HER is accurate.	I-Reply	I-3	Reply	318
An observation we would like to make is that the purpose of HER is not necessarily to improve the sample efficiency of tasks where dense rewards are sufficient for DDPG to learn.	I-Reply	I-3	Reply	318
Rather, a big selling point of HER is that it can improve the asymptotic performance of DDPG in tasks with sparse rewards.	I-Reply	I-3	Reply	318
To test this hypothesis, we ran an additional baseline of DDPG with sparse rewards (-1 if the goal state is not reach, 0 if it is).	I-Reply	I-3	Reply	318
HER definitively outperforms this baseline, so our results confirm that HER helps with sparse-reward tasks.	I-Reply	I-3	Reply	318
We wanted to improve the sample efficiency of DDPG, and not necessarily DDPG‚Äôs feasibility for sparse-reward tasks, and so we focused on tasks that DDPG could already solve, albeit after many samples.	I-Reply	I-3	Reply	318
It may be that the benefits of HER shine through on tasks where dense rewards will not lead to good policies.	I-Reply	I-3	Reply	318
<sep> <sep> We appreciate your comments regarding the connection between model-based and model-free RL.	B-Reply	B-1	Reply	318
In this paper, we presented two main contributions: one is a connection between model-free and model-based reinforcement learning, and another is an algorithm derived from this connection.	I-Reply	I-1	Reply	318
We have edited the paper (throughout the paper, and notably in Section 3.2, Paragraph 2) to balance the presentation better between these two components, and to avoid overstating the connection.	I-Reply	I-1	Reply	318
We would be happy to incorporate any other concrete suggestions you might have.	I-Reply	I-1	Reply	318
<sep> <sep> Thank you for the references to the earlier work connecting TD-methods and model-based methods.	B-Reply	B-2	Reply	318
We have added a discussion to this work in the related works (Section 5, paragraph 2).	I-Reply	I-2	Reply	318
While these papers also show a connection between TD-methods and model-based methods, their objective is rather different from ours.	I-Reply	I-2	Reply	318
Boyan shows an exact equivalence between a learned model and learned value function, but this requires a tabular value function which effective keeps track of every state-action-next-state transition.	I-Reply	I-2	Reply	318
Parr shows that for linear function approximators, a value function extracted using a learned model is the same as a value function learned with TD-learning.	I-Reply	I-2	Reply	318
Rather than analyzing equivalence at convergence, our primary contribution is how we can achieve sample complexity comparable to model-based RL while retaining the favorable asymptotic performance of model-free RL in complex tasks with function approximation.	I-Reply	I-2	Reply	318
<sep> <sep> We believe that we have addresses all the issues raised by the reviewer.	O	O	Reply	318
We would be happy to discuss and address any additional concerns.	O	O	Reply	318

The paper universal value function type ideas to learn models of how long the current policy will take to reach various states (or state features), and then incorporates these into model-predictive control.	O	O	Review	318
This looks like a reasonable way to approach the problem of model-based RL in a way that avoids the covariate shift produced by rolling learned transition models forward in time.	O	O	Review	318
Empirical results show their method outperforming Hindsight Experience Replay (which looks quite bad in their experiments), DDPG, and more traditional model-based learning.	B-Review	B-3	Review	318
It also outperforms DDPG quite a bit in terms of sample efficiency on a real robotic arm.	I-Review	I-3	Review	318
They also show the impact of planning horizon on performance, demonstrating a nice trade-off.	I-Review	I-3	Review	318
<sep> <sep> There are however a couple of relevant existing papers that the authors miss referencing / discussing:	O	O	Review	318
- "Reinforcement Learning with Unsupervised Auxiliary Tasks" (Jarderberg et al, ICLR 2017) - uses predictions about auxiliary tasks, such as effecting maximum pixel change, to obtain much better sample efficiency.	B-Review	B-1	Review	318
<sep> - "The Predictron: End-To-End Learning and Planning" (Silver et al, ICML 2017), which also provides a way of interpolating between model-based and model-free RL.	B-Review	B-2	Review	318
<sep> <sep> I don't believe that these pieces of work subsume the current paper, however the authors do need to discuss the relationship their method has with them and what it brings.	B-Review	B-4	Review	318
<sep> <sep> ** UPDATE Jan 9: Updated my rating in light of authors' response and updated version.	O	O	Review	318
I recommend that the authors find a way to keep the info in Section 4.3 (Dynamic Goal and Horizon Resampling) in the paper though, unless I missed where it was moved to. **	O	O	Review	318
<sep> <sep> Thank you for your feedback!	O	O	Reply	318
We have edited the paper to address all of the issues that you‚Äôve raised (see below).	O	O	Reply	318
We would appreciate any further feedback that you might have to provide.	O	O	Reply	318
<sep> <sep> We have added a discussion of the two papers suggested (Jaderberg et al ICML 2017, Silver et al, ICML 2017) to the paper in the related work section (Section 5, paragraph 6).	B-Reply	B-1	Reply	318
Our method shares the same motivation as those papers: to increase the amount of supervision in model-free RL to achieve sample-efficient learning.	B-Reply	B-2	Reply	318
We also include recent work on distributional RL (Bellemare et al, 2017) as another example of this general idea.	I-Reply	I-2	Reply	318
<sep> <sep> We were able to obtain the code for hindsight experience replay (HER) from the original authors.	B-Reply	B-4	Reply	318
Using this code as reference, we improved our implementation by incorporating their hyperparameter settings and implementation details, including ones that we had difficulty deducing from the original HER paper.	I-Reply	I-4	Reply	318
The performance of HER on our tasks did improve, and we have updated Figure 2 with the new results.	I-Reply	I-4	Reply	318
At this point, with the help of the original authors, we are confident that our implementation of HER is accurate.	B-Reply	B-3	Reply	318
An observation we would like to make is that the purpose of HER is not necessarily to improve the sample efficiency of tasks where dense rewards are sufficient for DDPG to learn.	I-Reply	I-3	Reply	318
Rather, a big selling point of HER is that it can improve the asymptotic performance of DDPG in tasks with sparse rewards.	I-Reply	I-3	Reply	318
To test this hypothesis, we ran an additional baseline of DDPG with sparse rewards (-1 if the goal state is not reach, 0 if it is).	I-Reply	I-3	Reply	318
HER definitively outperforms this baseline, so our results confirm that HER helps with sparse-reward tasks.	I-Reply	I-3	Reply	318
We wanted to improve the sample efficiency of DDPG, and not necessarily DDPG‚Äôs feasibility for sparse-reward tasks, and so we focused on tasks that DDPG could already solve, albeit after many samples.	I-Reply	I-3	Reply	318
It may be that the benefits of HER shine through on tasks where dense rewards will not lead to good policies.	I-Reply	I-3	Reply	318

the paper proposes an algorithm that adversarially filters out examples to reduce dataset-specific spurious bias.	B-Review	B-1	Review	318
the key intuition is that the datasets are curated in a way that easy to obtain samples have higher probability to be admitted to the dataset.	I-Review	I-1	Review	318
however, not all real world samples are easy to obtain.	I-Review	I-1	Review	318
in other words, real world samples may follow a completely different distribution than curated samples with easy-to-obtain ones.	I-Review	I-1	Review	318
<sep> <sep> the proposed approach discounts the data-rich head of the datasets and emphasizes the data-low tail.	B-Review	B-1	Review	318
they quantify data-rich / data-low by the best possible out-of-sample classification accuracy achievable by models when predicting.	I-Review	I-1	Review	318
<sep> <sep> then adjust the dataset via the expected out-of-sample classification accuracy.	B-Review	B-1	Review	318
the idea of the paper is interesting and the experiments show a substantial reduction in the performance of existing algorithms.	I-Review	I-1	Review	318
this make the paper a promising proposal.	I-Review	I-1	Review	318
<sep> <sep> We thank Reviewer 2 for their positive feedback.	O	O	Reply	318
Please also see our overall response for some new experimental evidence explicitly addressing the robustness of models trained on AFLite-filtered data:  <a href="https://openreview.net/forum?id=H1g8p1BYvS&amp;noteId=rJeVCr85sS" target="_blank" rel="nofollow">https://openreview.net/forum?id=H1g8p1BYvS&amp;noteId=rJeVCr85sS</a>	B-Reply	B-1	Reply	318

Summary: This paper hypothesizes that even though we are able to achieve very impressive performance on benchmark&nbsp;datasets as of now (e.g. image net), it might be due to the fact that benchmarks themselves have biases.	O	O	Review	318
They introduce an algorithm that selects more representative data points from the dataset that allow to get a better estimate of the performance&nbsp;in the wild.	O	O	Review	318
The algorithm ends up selecting more difficult/confusing instances.	O	O	Review	318
<sep> <sep> This paper is easy to read and follow (apart from some hickup with a copy of three paragraphs), but in my opinion of limited use/impact.	O	O	Review	318
<sep> <sep> Comments:	O	O	Review	318
1) There is a repetition of the " while this expression&nbsp;formalizes.." paragraph and the next paragraph and the paragraph "As opposed to .." is out of place.	B-Review	B-1	Review	318
Please fix	I-Review	I-1	Review	318
2) I am not sure	O	O	Review	318
- What applications the authors suggest.	B-Review	B-2	Review	318
They seem to say that benchmark authors should run their algorithm and make benchmarks harder.	I-Review	I-2	Review	318
To me it seems that benchmarks become harder because you remove most important instances from the training data (so Table 4 is not surprising - you remove the most representative instances so the model can't learn)	I-Review	I-2	Review	318
- how practically feasible it is.	I-Review	I-2	Review	318
Even if in previous point I am wrong, the algo requires retraining the models on subsets (m iterations).	I-Review	I-2	Review	318
How large is this m?	I-Review	I-2	Review	318
<sep> 3) Other potential considerations:	O	O	Review	318
-  When you change the training size, the model potentially needs to be re-tuned (regularization etc) (although it might be not that severe since the size of the training data is preserved at t)	B-Review	B-3	Review	318
- How do u chose the values of hyperparams&nbsp;(t, m,k eta), how is performance of your algorithm depends on it	I-Review	I-3	Review	318
4) I don't see any good baselines to compare with - what if i just chose instances that get the highest prediction score on a model and remove these.	B-Review	B-5	Review	318
How would that do?	I-Review	I-5	Review	318
For NLP (SNLI) task i think this would be a more reasonable baseline than just randomly dropping the instances,	I-Review	I-5	Review	318
5) I wonder if you actually retrain the features after creating filtered dataset, new representation would be able to recover the performance.&nbsp;	B-Review	B-4	Review	318
<sep> I read authors rebuttal and new experiments that show that the models trained on filtered data generalize better are proving the point, thanks.	O	O	Review	318
Changing to weak accept	O	O	Review	318
<sep> We thank Reviewer 1 for their comments, and address each of the concerns below:	O	O	Reply	318
<sep> Impact 1: AFLite recalibrates benchmarks:	O	O	Reply	318
[R1 (2)] We would like to clarify that the goal of this work is to recalibrate benchmarks, for the purpose of reporting true model performance.	B-Reply	B-2	Reply	318
This does not necessarily involve removing the most important instances from the training data, but those which are spuriously correlated with the ground truth, making the overall task trivially easier.	I-Reply	I-2	Reply	318
Once such correlations are minimized (i.e. after filtering with AFLite), the performance reduces.	I-Reply	I-2	Reply	318
<sep> <sep> Impact 2: Do models trained on AFLite-filtered data generalize better?	O	O	Reply	318
YES! :	O	O	Reply	318
<sep> A second contribution of our work is demonstrating that the presence of instances with spurious correlations with the ground truth prevents models from generalizing to real world data.	B-Reply	B-5	Reply	318
Our new results on three additional benchmarks show that a model trained on the AFLite-filtered dataset generalizes better than a model trained on the full SNLI dataset (Sec 3.2.1; also please see overall response: <a href="https://openreview.net/forum?id=H1g8p1BYvS&amp;noteId=rJeVCr85sS" target="_blank" rel="nofollow">https://openreview.net/forum?id=H1g8p1BYvS&amp;noteId=rJeVCr85sS</a> ).	I-Reply	I-5	Reply	318
<sep> <sep> Computational Overhead:	O	O	Reply	318
[R1 (2)] Our approach operates on precomputed representations of the instances and relies on inexpensive logistic regressions.	B-Reply	B-2	Reply	318
As a result, it is very efficient, scalable and parallelizable.	I-Reply	I-2	Reply	318
It can efficiently run on CPU machines as well, and an effective value for m is a multiple of the number of available cores (e.g., 64 or 128).	I-Reply	I-2	Reply	318
<sep> <sep> Hyperparameters:	O	O	Reply	318
[R1 (3)] We have updated the draft to provide more information about the different hyperparameters (Sec 2; Implementation).	B-Reply	B-3	Reply	318
These were selected based on the learning curves observed when training the model that we use to generate feature embeddings for the rest of the data, as well as the available computational budget (#CPU cores etc.).	I-Reply	I-3	Reply	318
The training size, t, is kept constant throughout the algorithm, as R1 correctly points out; hence we do not modify the hyperparameters across iterations.	I-Reply	I-3	Reply	318
<sep> <sep> New Baselines:	O	O	Reply	318
[R1 (4)] As Reviewer 1 suggested, we have now provided a baseline (Sec 3.2 paragraph 6) which filters out the most predictable examples in a single pass.	B-Reply	B-5	Reply	318
This corresponds to a non-iterative version of AFLite.	I-Reply	I-5	Reply	318
For the SNLI task, this baseline (dev acc = 72.1%), however, is not as powerful as the full AFLite model (dev acc = 62.6%).	I-Reply	I-5	Reply	318
This demonstrates the need for an iterative procedure involving models trained on multiple partitions in each iteration.	I-Reply	I-5	Reply	318
<sep> <sep> Retraining post-AFLite:	O	O	Reply	318
[R1 (5)] We do indeed completely retrain models after creating the filtered dataset.	B-Reply	B-4	Reply	318
With the exception of finetuning the same pretrained representations such as RoBERTa (publicly available), there is no sharing of parameters between the older model trained on the full dataset, and the newer model trained on the filtered dataset.	I-Reply	I-4	Reply	318
Moreover, the parameters used during the AFLite filtering are not reused when reporting benchmark performance.	I-Reply	I-4	Reply	318
As shown in our experiments, these new representations, however, are unable to recover the original performance.	I-Reply	I-4	Reply	318
<sep> <sep> Others:	O	O	Reply	318
[R1 (1)] We apologize for the duplicates, and have fixed the issue in the updated draft.	B-Reply	B-1	Reply	318

This paper proposes to learn a subset of a given dataset that acts as an adversary, that hurts the model performance when used as a training dataset.	O	O	Review	318
The central claim of the paper is that existing datasets on which models are trained are potentially biased, and are not reflective of real world scenarios.	O	O	Review	318
By discarding samples that add to this bias, the idea is to make the model perform better in the wild.	O	O	Review	318
The authors propose a method to do so, and then refine it so that the resulting solution is tractable.	O	O	Review	318
They implement the method on several datasets and show that by finding these adversarial samples, they indeed hurt model performance.	O	O	Review	318
<sep> <sep> COMMENTS:	O	O	Review	318
- Overall the method seems to be something like what is done in k-fold CV, except here we want to find a subset that is the worst at predicting model performance.	B-Review	B-1	Review	318
To this end, I find the introduction of terms like "representation bias" and "predictability scores" unnecessary.	I-Review	I-1	Review	318
Why not model the entire problem in terms of classification error?	I-Review	I-1	Review	318
<sep> <sep> - Page 3 : the last 2 paragraphs are repeated from above.	B-Review	B-2	Review	318
<sep> <sep> E: i read the author responses and they addressed my concern about model performance in the wild.	O	O	Review	318
I have updated my score to reflect this.	O	O	Review	318
<sep> <sep> - eqn (3) and the set of equations above: for the math to work, you need q(i) to have non-zero support on all samples.	B-Review	B-2	Review	318
To that end, the sentence that says it works for "any" q() is incorrect.	I-Review	I-2	Review	318
<sep> <sep> - The experiments back your claim that your method makes the data more challenging to train on.	B-Review	B-3	Review	318
But that does not address the central idea, that the resultant models do better in the wild.	I-Review	I-3	Review	318
If the aim is to make the models robust to real world, you have provided no evidence that your method does so.	I-Review	I-3	Review	318
<sep> <sep> - Table 1: the D_92k column is good comparison to have.	B-Review	B-4	Review	318
Thanks.	O	O	Review	318
<sep> <sep> <sep> We thank Reviewer 3 for their comments, and address their main points below.	O	O	Reply	318
<sep> <sep> AFLite and generalization:	O	O	Reply	318
We now have evidence suggesting resultant models trained on AFLite-filtered data indeed perform better in the wild.	B-Reply	B-3	Reply	318
Our new results on three additional benchmarks show that a model trained on the AFLite-filtered dataset generalizes better than a model trained on the full SNLI dataset (Sec 3.2.1; please also see overall response <a href="https://openreview.net/forum?id=H1g8p1BYvS&amp;noteId=rJeVCr85sS" target="_blank" rel="nofollow">https://openreview.net/forum?id=H1g8p1BYvS&amp;noteId=rJeVCr85sS</a> ).	I-Reply	I-3	Reply	318
<sep> <sep> Terminology:	O	O	Reply	318
The notion of predictability score is indeed related to classification error and its empirical estimate is indeed reminiscent of k-fold cross-validation.	B-Reply	B-1	Reply	318
Yet, to avoid confusion with the term classification error, we use the term ‚Äúpredictability score of an instance‚Äù for the out-of-sample classification accuracy averaged over several models trained on a number of random subsets of the data.	I-Reply	I-1	Reply	318
<sep> <sep> Others:	O	O	Reply	318
We have updated the contents of Page 3 to remove the repeated paragraphs, and have changed the description of q() to solely distributions with a non-zero support.	B-Reply	B-2	Reply	318

The authors consider meta-learning to learn a prior over neural network weights.	O	O	Review	564
This is done via amortized variational inference.	O	O	Review	564
This means that a good initialisation of the variational parameters are learned across tasks, such that a good set of hyperparameters per task can be found in a few gradient steps.	O	O	Review	564
The proposed approach is evaluated on a toy and several popular benchmarks (like miniImagenet).	O	O	Review	564
<sep> <sep> The topic is timely.	O	O	Review	564
The contribution is modest, essentially applying the same idea as the one proposed in MAML to a variational objective, but well executed.	O	O	Review	564
The paper is relatively well-written and the contributions clearly stated/motivated.	O	O	Review	564
Section 2 and 3 could be written in a more compact way (in particular the math), but it does not harm the flow.	B-Review	B-1	Review	564
The authors conducted a good set of experiments, but are missing comparisons Bayesian versions of MAML.	B-Review	B-2	Review	564
<sep> <sep> We appreciate your comments!	O	O	Reply	564
With regard to comparisons with bayesian versions of MAML, unfortunately, we could not find any source code available for these models.	B-Reply	B-2	Reply	564
For the cifar-100 and mini-Imagenet experiments, we cannot just take the results reported in these papers - our evaluation focuses on specific metrics used to quantify uncertainty so we would need to have the code for the models to calculate these metrics.	I-Reply	I-2	Reply	564
<sep> <sep> However, taking the reviewers‚Äô feedback into account, we have worked on our own implementation of Probabilistic MAML and based on preliminary experiments on mini-Imagenet, it does appear that our model has better predictive uncertainty (both in terms of calibration of the predictive distribution and confidence on out-of-distribution examples).	I-Reply	I-2	Reply	564
Our implementation does not exactly reproduce the results from the Probabilistic MAML paper and so we are in touch with the authors trying to make sure our implementation matches theirs.	I-Reply	I-2	Reply	564
We hope to add the results of these experiments to the paper by the end of the revision period.	I-Reply	I-2	Reply	564
<sep> <sep> For the contextual bandit experiments, even with the source code, it is not straightforward to apply the aforementioned techniques.	I-Reply	I-2	Reply	564
Probabilistic MAML does not maintain uncertainty in task-specific weights - all uncertainty in the posterior comes from uncertainty in global parameters which has fixed variance.	I-Reply	I-2	Reply	564
Therefore, as experience is accumulated on a new task, it is not possible to compute a posterior for the task that will become more certain.	I-Reply	I-2	Reply	564
This makes Probabilistic MAML inappropriate for the contextual bandit Thompson sampling setup.	I-Reply	I-2	Reply	564
Bayesian MAML could be applied to the contextual bandit experiments; however, it would likely require significant effort to tune the appropriate size of the ensemble (as Bayesian MAML maintains an approximate posterior consisting of M different copies of the model) and amount of parameter sharing so as to make experiments feasible and to have the appropriate amount of exploration.	I-Reply	I-2	Reply	564
If M were too small, then Thompson sampling would provide very limited exploration.	I-Reply	I-2	Reply	564
<sep> <sep> We would like to stress that our method is easy to apply to the problem because we can easily sample from our model‚Äôs approximate posterior and because the total number of parameters are only increased 2-fold (weights and variances).	I-Reply	I-2	Reply	564
We can calculate an approximate posterior over any commonly used network architecture for which we can compute gradients, making our method model-agnostic without introducing new hyperparameters such as the ensemble size or amount of parameter sharing which must be carefully tuned.	I-Reply	I-2	Reply	564

The authors proposed a meta-learning approach which amortizes hierarchical variational inference across tasks, learning an initial variational distribution such that, after a few steps of stochastic optimization with the reparametrization trick, they obtain a good task-specific approximate posterior.	O	O	Review	564
The optimization is performed by applying backpropagation through	O	O	Review	564
gradient updates.	O	O	Review	564
Experiments on a contextual bandit setting and on miniImage net show how the proposed approach can outperform a baseline based on the method MAML.	O	O	Review	564
Although in miniImagenet the proposed method does not produce	O	O	Review	564
gains in terms of accuracy, it does produce gains in terms of uncertainty estimation.	O	O	Review	564
<sep> <sep> Quality:	O	O	Review	564
<sep> The derivation of the proposed method is rigorous and well justified.	O	O	Review	564
The experiments performed show that the proposed method can result in gains.	O	O	Review	564
However, the comparison is only with respect to MAML and other techniques could have also be included to make it more meaningful.	B-Review	B-1	Review	564
For example,	O	O	Review	564
<sep> Gordon, Jonathan, et al "Decision-Theoretic Meta-Learning: Versatile and	O	O	Review	564
Efficient Amortization of Few-Shot Learning."	O	O	Review	564
arXiv preprint arXiv:1805.09921	O	O	Review	564
(2018).	O	O	Review	564
<sep> <sep> or the methods included in the related work section, or Garnelo et al 2018.	O	O	Review	564
<sep> <sep> The authors do not comment on the computational cost of the proposed method.	B-Review	B-2	Review	564
<sep> <sep> Clarity:	O	O	Review	564
<sep> The paper is clearly written and easy to read.	O	O	Review	564
<sep> <sep> Novelty:	O	O	Review	564
<sep> The proposed method is new up to my knowledge.	O	O	Review	564
This is one of the first methods to do Bayesian meta-learning.	O	O	Review	564
<sep> <sep> Significance:	O	O	Review	564
<sep> The experimental results show that the proposed method can produce gains.	O	O	Review	564
However, because the authors only compare with a non-Bayesian meta-learning method (MAML), it is not clear how significant the results are.	B-Review	B-1	Review	564
Furthermore, the computational cost of the proposed method is described well enough.	B-Review	B-2	Review	564
Thank you for your feedback!	O	O	Reply	564
We have addressed the two points you mentioned below.	O	O	Reply	564
<sep> <sep> => Baselines for comparison	O	O	Reply	564
<sep> Please see our response to Reviewer 1 with regards to comparisons to Bayesian versions of MAML for cifar and mini-Imagenet.	B-Reply	B-1	Reply	564
As mentioned, we have worked on our own implementation of Probabilistic MAML and based on preliminary experiments on mini-Imagenet, it does appear that our model has better predictive uncertainty.	I-Reply	I-1	Reply	564
Our implementation does not exactly reproduce the results from the Probabilistic MAML paper and so we are in touch with the authors trying to make sure our implementation matches theirs.	I-Reply	I-1	Reply	564
We hope to add the results of these experiments to the paper by the end of the revision period.	I-Reply	I-1	Reply	564
<sep> <sep> For the contextual bandit experiments, even with the source code, it is not straightforward to apply the aforementioned techniques.	I-Reply	I-1	Reply	564
Probabilistic MAML does not maintain uncertainty in task-specific weights - all uncertainty in the posterior comes from uncertainty in global parameters which has fixed variance.	I-Reply	I-1	Reply	564
Therefore, as experience is accumulated on a new task, it is not possible to compute a posterior for the task that will become more certain.	I-Reply	I-1	Reply	564
This makes Probabilistic MAML inappropriate for the contextual bandit Thompson sampling setup.	I-Reply	I-1	Reply	564
Bayesian MAML could be applied to the contextual bandit experiments; however, it would likely require significant effort to tune the appropriate size of the ensemble (as Bayesian MAML maintains an approximate posterior consisting of M different copies of the model) and amount of parameter sharing so as to make experiments feasible and to have the appropriate amount of exploration.	I-Reply	I-1	Reply	564
If M were too small, then Thompson sampling would provide very limited exploration.	I-Reply	I-1	Reply	564
Additionally, for Gordon et al, we have a similar issue, as the amortization network they use outputs the distribution of weights over the final layer (whereas the rest of the network weights are shared) and would require tinkering to get the appropriate network architecture to work in the contextual bandits setting.	I-Reply	I-1	Reply	564
<sep> <sep> We would like to stress that our method is easy to apply to the problem because we can easily sample from our model‚Äôs approximate posterior and because the total number of parameters are only increased 2-fold (weights and variances).	I-Reply	I-1	Reply	564
We can calculate an approximate posterior over any commonly used network architecture for which we can compute gradients, making our method model-agnostic without introducing new hyperparameters such as the ensemble size or amount of parameter sharing which must be carefully tuned.	I-Reply	I-1	Reply	564
<sep> <sep> As for Garnelo et al, we could not find details of their setup for the contextual bandit experiment (such as the network architecture, how often to update the models in each trial, how many batches to use for each update, what optimizer to use, etc), which prevented a fair comparison of inference methods.	I-Reply	I-1	Reply	564
We emailed the authors several times with these questions but received no response.	I-Reply	I-1	Reply	564
If the reviewers wish, we are happy to include the results from Garnelo et al in the paper, with an asterisk indicating we do not know the design of their experiment and cannot fairly compare MAML or our method to them because of the different hyperparameters we likely used.	I-Reply	I-1	Reply	564
<sep> <sep> => Computation cost of method	O	O	Reply	564
<sep> The computation cost of our method is similar to MAML except for the fact we need to compute stochastic gradients in the inner loop.	B-Reply	B-2	Reply	564
To reduce the variance of the stochastic gradients, we do the following (as has been commonly done in previous work involving bayesian neural networks):	I-Reply	I-2	Reply	564
a. Use fully-independent (or close to fully-independent) weight samples for each example in an episode.	I-Reply	I-2	Reply	564
<sep> b. Average over multiple weight samples when computing the expectation.	I-Reply	I-2	Reply	564
<sep> <sep> (a) is achieved using the local reparameterization trick for fully-connected layers and flipout for convolutional layers.	I-Reply	I-2	Reply	564
Both of these methods increase the complexity of the forward pass by 2 because they require two weight multiplications (or convolutions) rather than one for normal fully-connected or convolutional layers. (	I-Reply	I-2	Reply	564
b) is achieved by replicating the data.	I-Reply	I-2	Reply	564
Because we are in the few-shot learning setting, we can simply replicate the episode data enough times to get different samples and average and the replicated data still fits in a forward pass on the GPU.	I-Reply	I-2	Reply	564
Thus (b) doesn‚Äôt increase the time complexity too much because it corresponds to using a bigger batch of data for each episode while using the same amount of forward passes.	I-Reply	I-2	Reply	564
<sep> <sep> For example, for the cifar-100 experiments, our model took 2.6 times as long to train than MAML on a single GPU.	I-Reply	I-2	Reply	564
This is typical of the time tradeoff between training a bayesian vs non-bayesian deep network.	I-Reply	I-2	Reply	564
We will add more details about the computational cost to a new revision.	I-Reply	I-2	Reply	564

This work proposes an adaptation to MAML-type models that accounts for posterior uncertainty in task specific latent variables.	O	O	Review	564
This is achieved via a hierarchical Bayesian view of MAML, employing variational inference for the task-specific parameters.	O	O	Review	564
The key intuition of this paper is that one can perform fast and efficient test-time variational inference for the task-specific latent variables by learning a good initialization during meta-training.	O	O	Review	564
This is achieved in a very similar fashion to MAML, and allows for an interesting form of amortization of test-time inference.	O	O	Review	564
<sep> <sep> Pros:	O	O	Review	564
- For the most part, the approach presented is principled and well justified.	O	O	Review	564
<sep> - The motivation is clear: in the few-shot learning regime we expect to have little data to infer the task-specific latent variables, and so we should perform posterior inference to account for uncertainty.	O	O	Review	564
<sep> - The paper is well written, clear, and easy to follow.	O	O	Review	564
<sep> <sep> Cons (more details below):	O	O	Review	564
- It is not clear what the significant contributions of this paper are, as a number of methods have been proposed to account for uncertainty in the task-specific latent variables, and results for many of these methods appear to be better than those presented here.	B-Review	B-3	Review	564
<sep> - Experimental section does compare to many of the existing related methods	B-Review	B-6	Review	564
- There are some conceptual issues that need to be addressed by the authors.	B-Review	B-7	Review	564
<sep> <sep> I enjoyed reading this paper, and I think the ideas and work presented are, for the most part, solid.	O	O	Review	564
However, I am not sure to what extent the novel contribution of this paper is significant.	B-Review	B-3	Review	564
Several papers, including Grant et al (2018), but going back to Heskes (2000), have proposed the hierarchical Bayesian view of meta-learning.	I-Review	I-3	Review	564
Grant et al (2018) used a Laplace approximation to learn in such a model with MAML-type settings, presenting a method that accounts for uncertainty in this family of models.	I-Review	I-3	Review	564
More recently, Finn et al (2018) and Kim et al (2018) have done this in a variational manner, albeit with variations in the implementation details.	I-Review	I-3	Review	564
Gordon et al (2018) proposed a more general presentation, unifying the above works (and others) in a Bayesian framework that allows for different functional forms of posterior inference (both point estimates and distributional) of the task-specific parameters, including gradient based procedures.	I-Review	I-3	Review	564
All of these papers have been publicly available for a few months at the time of submission, such that this view of meta-learning as (amortized) Bayesian inference is not novel.	I-Review	I-3	Review	564
<sep> <sep> Here are some points that I would ask the authors to address during the rebuttal period:	O	O	Review	564
<sep> - The method presented in the paper does not account for the meta-training splits into query and test sets, other than to mention that these led to empirical performance gains (this is somewhat typical of probabilistic meta-learning papers).	B-Review	B-1	Review	564
However, it not clear that this is justified from a probabilistic inference perspective, which would favour conditioning on all available data at inference time.	I-Review	I-1	Review	564
Further, in the experimental section, the authors state that "For the few-shot learning experiments, we found it necessary to downweight the inner KL term for better performance in our model".	B-Review	B-2	Review	564
Put together, it is not quite clear exactly what form of approximate inference is being conducted here.	I-Review	I-2	Review	564
Can the authors comment on this?	I-Review	I-2	Review	564
<sep> <sep> - I am not sure I agree with the authors' interpretation of the term "amortized Bayesian inference", at least in that it deviates from the way the term is typically used in the related literature.	O	O	Review	564
The method negates the need to maintain variational parameters for each latent variable, and approximate posterior inference for unseen tasks may be performed relatively efficiently, which is highly desirable.	O	O	Review	564
However, a gradient optimization procedure must still be performed for inference of task-specific variables for new tasks at test time.	B-Review	B-4	Review	564
Thus, new variational parameters must be introduced and optimized at test time.	I-Review	I-4	Review	564
It is true that by finding good global initializations the authors may drastically reduce the computational cost of the inference process, but this implies that the cost of inference at test time has been reduced, not fully amortized to a fixed cost (unless one fixes the number of gradient steps, which is a further deviation from variational inference and requires a prior of the form used in Grant et al (2018)).	I-Review	I-4	Review	564
Full amortization of inference for the task-specific variables is proposed by Garnelo et al (2018) and Gordon et al (2018), as well as Edwards and Storkey (2016), all of which employ inference networks mapping directly from the query sets to the variational parameters of the latent variables.	B-Review	B-5	Review	564
In these cases, posterior inference of the latent variables for unseen tasks has the constant cost of a pass through an inference network, rather than several forward-backward passes, and does not require introducing new variational parameters to be optimized.	I-Review	I-5	Review	564
Further, these methods negate the need for differentiating through gradient-based procedures at meta-training time, which is not avoided in this paper, but rather dealt with in the standard Hessian-vector product form.	I-Review	I-5	Review	564
It would be highly useful in the paper (perhaps in the related work section) for the authors to conduct a more thorough comparison of their proposed method and the existing literature employing amortized inference for meta-learning, to put their work in context.	I-Review	I-5	Review	564
<sep> <sep> I also have a number of concerns regarding the experimental section of the paper, which I find to be lacking both in details and the empirical comparison of the method to existing works.	O	O	Review	564
<sep> - The authors' cite recent works on meta-learning that take into account uncertainty in the local latent variables (e.g., Grant et al (2018), Finn et al (2018), Kim et al (2018)), but do not compare to these methods.	B-Review	B-8	Review	564
<sep> - Results from Garnelo et al (2018) are not provided for the contextual bandits experiment.	I-Review	I-8	Review	564
Their results seem to be comparable or better to those presented in this paper.	I-Review	I-8	Review	564
Can the authors comment on this?	I-Review	I-8	Review	564
<sep> - The same is true for the few-shot learning case, where MAML is the only method compared to, despite there being, at the time of submission, many papers which have significantly improved upon these results.	I-Review	I-8	Review	564
<sep> - In terms of details, it is unclear how many gradient steps were taken at test time, and how this affects performance of the model.	I-Review	I-8	Review	564
<sep> - In terms of accuracy, the proposed method appears to be under-performing significantly (i.e., below confidence bounds in almost all cases).	I-Review	I-8	Review	564
<sep> - The statement "...we believe improvements could be made with better variance reduction methods for stochastic gradients" should, in my opinion, either be investigated or omitted from the paper.	I-Review	I-8	Review	564
<sep> - In terms of uncertainty quantification, I find this experimental evaluation highly interesting.	I-Review	I-8	Review	564
However, there is not a comparison to much of the existing work.	I-Review	I-8	Review	564
The comparison to MAML is only of moderate interest in this case, as MAML is a deterministic method and is not expected to perform well in this regard.	I-Review	I-8	Review	564
A comparison to Probabilistic or Bayesian MAML (at the least) would be more convincing if uncertainty calibration proved to be better for this method.	I-Review	I-8	Review	564
<sep> <sep> Overall, the paper proposes a principled approach to performing approximate posterior inference for task specific latent variables in meta-learning settings.	O	O	Review	564
The paper is well-written, and the method is clearly derived.	O	O	Review	564
However, it is my impression that the paper does not make significant novel contributions to the existing research in (probabilistic) meta-learning, does not properly acknowledge all existing work (much of which covers the main ideas presented in the paper), has a number of conceptual issues that might need addressing, and its experimental section lacks evaluation and comparisons to the existing similar works.	O	O	Review	564
As the method is, for the most part, principled and well-derived, and the paper well written, I am willing to reconsider my overall score if the authors can demonstrate either (i) significant novelty or (ii) that this particular flavour of inference for the task-specific parameters provides significant benefits over existing approaches.	O	O	Review	564
<sep> <sep> [1] - T. Heskes.	O	O	Review	564
Empirical Bayes for learning to learn.	O	O	Review	564
2000.	O	O	Review	564
<sep> [2] - E. Grant, C. Finn, S. Levine, T. Darrell, and T. Griffiths.	O	O	Review	564
Recasting gradient-based meta-learning as hierarchical Bayes.	O	O	Review	564
2018.	O	O	Review	564
<sep> [3] - C. Finn, K. Xu, and S. Levine.	O	O	Review	564
Probabilistic model-agnostic meta-learning.	O	O	Review	564
2018.	O	O	Review	564
<sep> [4] - T. Kim, J. Yoon, O. Dia, S. Kim, Y. Bengio, and S. Ahn.	O	O	Review	564
Bayesian model-agnostic meta-learning.	O	O	Review	564
2018.	O	O	Review	564
<sep> [5] - J. Gordon, J. Bronskill, M. Bauer, S. Nowozin, and R. Turner.	O	O	Review	564
Decision-theoretic meta-learning: versatile and efficient amortization of few-shot learning.	O	O	Review	564
2018.	O	O	Review	564
<sep> [6] - M. Garnelo, J. Schwarz, D. Rosenbaum, F. Viola, D. J. Rezende, S. Eslami, and Y. W. Teh.	O	O	Review	564
Neural processes.	O	O	Review	564
2018.	O	O	Review	564
<sep> [7] - H. Edwards, and A. Storkey.	O	O	Review	564
Towards a neural statistician.	O	O	Review	564
2016.	O	O	Review	564
Thank you for your review and detailed feedback!	O	O	Reply	564
We‚Äôve addressed the points you talked about below.	O	O	Reply	564
<sep> <sep> => ‚ÄúThe method presented...does not account for the meta-training splits into query and test sets‚Ä¶‚Äù	O	O	Reply	564
<sep> We are free to choose any parameterized procedure to produce an approximate posterior.	B-Reply	B-1	Reply	564
Therefore, we can choose to condition on only the support set when computing the approximate posterior.	I-Reply	I-1	Reply	564
It is true that conditioning on less information may give a looser lower bound whereas conditioning on all the data would make the bound tighter.	I-Reply	I-1	Reply	564
However, we only care about obtaining a tight bound during training insofar as it allows computing a good approximate posterior from the support set at test time.	I-Reply	I-1	Reply	564
Therefore, we choose to condition our approximate posterior on only the support set.	I-Reply	I-1	Reply	564
We wish our model‚Äôs performance to generalize from training to test, and so we ensure the training and test conditions are similar.	I-Reply	I-1	Reply	564
This is supported by empirical evidence - the model performs better during testing when the variational distribution is computed the same way during training and testing.	I-Reply	I-1	Reply	564
<sep> <sep> Also one can view the objective in Eqn 5 (specifically the part inside the brackets corresponding to each episode i) as the KL between the approximate posterior conditioned on the support set and the true posterior over task-specific latent variables phi conditioned on the support & query sets and theta.	I-Reply	I-1	Reply	564
This is similar to loss used in Bayesian MAML, which aims to minimize a dissimilarity function between an approximate posterior over task-specific parameters given the support set, and an approximate posterior over task-specific parameters given the support & query sets.	I-Reply	I-1	Reply	564
The loss there is presented without derivation from a probabilistic inference perspective and justified by empirical performance.	I-Reply	I-1	Reply	564
It‚Äôs interesting that our derived loss connects to theirs.	I-Reply	I-1	Reply	564
<sep> <sep> => ‚ÄúFurther...the authors state that ‚ÄòFor the few-shot learning experiments, we found it necessary to downweight the inner KL term for better performance in our model‚Äô...‚Äù	O	O	Reply	564
<sep> Downweighting the KL term can be justified from a probabilistic perspective as accounting for confidence in the data (controlled by label noise and # of examples).	B-Reply	B-2	Reply	564
The weight on the KL term allows us to control the assumed noise in the observation model.	I-Reply	I-2	Reply	564
We choose the weight on the KL term to maximize the validation performance.	I-Reply	I-2	Reply	564
<sep> <sep> => ‚ÄúI am not sure I agree with the authors' interpretation of the term ‚Äòamortized Bayesian inference‚Äô...‚Äù	O	O	Reply	564
<sep> We agree that our method could be characterized as ‚Äúsemi-amortized‚Äù, a la Semi-Amortized VAEs (Kim et al).	B-Reply	B-3	Reply	564
In practice, we do fix a small number of gradient steps, which effectively does mean that finding a task-specific posterior is a fixed cost.	I-Reply	I-3	Reply	564
<sep> Kim, Yoon et al Semi-Amortized Variational Autoencoders.	O	O	Reply	564
2018.	O	O	Reply	564
<sep> <sep> => ‚ÄúIt is true that by finding good global initializations the authors may drastically reduce the computational cost of the inference process, but this implies that the cost of inference at test time has been reduced, not fully amortized to a fixed cost (unless one fixes the number of gradient steps, which is a further deviation from variational inference and requires a prior of the form used in Grant et al).‚Äù	O	O	Reply	564
<sep> We disagree that the parameterized procedure we use (with fixed number of gradient steps) to produce an approximate posterior requires changing the structure of the prior.	B-Reply	B-4	Reply	564
Automatic-differentiation based variational inference (for example, the VAE) is based on the idea that given a parametric differentiable procedure (such as the forward pass through an encoder network) that produces an approximate posterior, we can train the parameters of that procedure in order to to produce a better approximate posterior (through maximizing the ELBO).	I-Reply	I-4	Reply	564
Importantly, this does not require changing the structure of the prior and is valid for any prior we define - as long as we can estimate the KL divergence.	I-Reply	I-4	Reply	564
Using gradient descent with a fixed number of steps from initial variational weights can be thought of analogously to using an encoder network.	I-Reply	I-4	Reply	564
It could be possible that our method suffers from an amortization gap (Cremer et al), as do encoder networks, because of using a fixed number of updates.	I-Reply	I-4	Reply	564
However, we didn‚Äôt observe this in practice - we experimented with different amounts of steps and found diminishing returns after a certain point.	I-Reply	I-4	Reply	564
Please do let us know if we have misunderstood what you meant and we‚Äôd be happy to discuss further.	I-Reply	I-4	Reply	564
<sep> Cremer, Chris et al Inference Suboptimality in Variational Autoencoders.	O	O	Reply	564
2018.	O	O	Reply	564
<sep> <sep> => ‚ÄúFull amortization of inference for the task-specific variables is proposed by Garnelo et al and Gordon et al, as well as Edwards & Storkey, all of which employ inference networks mapping directly from the query sets to the variational parameters of the latent variables.	O	O	Reply	564
In these cases, posterior inference of the latent variables for unseen tasks has the constant cost of a pass through an inference network, rather than several forward-backward passes...‚Äù [cont.]	O	O	Reply	564

The authors propose a clustering approach for time series that encourages instances with similar time profiles to be clustered together.	O	O	Review	564
The approach consists of three modules: an encoder, a cluster assigner and a (future outcome) predictor, all specified as neural networks.	O	O	Review	564
<sep> <sep> The objective of the model is to produce cluster embeddings that are as informative of the outcomes as possible, while not being a direct function of covariates.	B-Review	B-1	Review	564
Note that (2) may look misleading because it indicates that the outcome is a function of the cluster assignment, however, it does not show that the assignment is indeed a function of the covariates.	I-Review	I-1	Review	564
<sep> <sep> It is not entirely clear how a patient is assigned to a cluster provided that cluster assignments are a function of time.	B-Review	B-2	Review	564
<sep> <sep> It is desirable that performance metrics do not seem affected by the unknown number of clusters, however, this makes for difficult to interpret clusters.	B-Review	B-3	Review	564
More so in practice when the number of identified clusters is a function of the model architecture and hyperparameters (\alpha and \beta).	I-Review	I-3	Review	564
Is the number of clusters selected by cross-validation and if so, what performance metric is used to select the best choice?	I-Review	I-3	Review	564
<sep> <sep> In Table 3 for UKCF with 3 comorbidities, how are AUROC and AUPRC evaluated provided these are binary predictions?	B-Review	B-4	Review	564
We thank the reviewer for the valuable comments.	O	O	Reply	564
<sep> <sep> A1.	B-Reply	B-1	Reply	564
In the probabilistic definition of the KL-divergence in (2), it is not necessary to explicitly denote the dependency between (i.e., the random variable for cluster assignment at time) and (i.e., the random variable for the input subsequence at time).	I-Reply	I-1	Reply	564
Instead, the dependency between the random variables is further specified in (3) in terms of their realizations.	I-Reply	I-1	Reply	564
More specifically, in (3) is a function of that is drawn from a categorical distribution whose probability of each category is defined as a function of the input subsequence.	I-Reply	I-1	Reply	564
In the revised manuscript, we will clarify the description of the dependency between the two random variables in (2).	I-Reply	I-1	Reply	564
<sep> <sep> A2.	O	O	Reply	564
For a run-time (testing) example, suppose that we have a new patient whose time-series observations are given as.	B-Reply	B-2	Reply	564
Then, our method assigns cluster to this patient based on the input sequence.	I-Reply	I-2	Reply	564
When a new observation on this patient is collected at time, we can update the cluster assignment of this patient to given the input sequence.	I-Reply	I-2	Reply	564
<sep> <sep> A3.	O	O	Reply	564
We selected the hyperparameters of our network that give the minimum validation loss in (3).	B-Reply	B-3	Reply	564
It is worth highlighting that, given the hyperparameters selected, our method identifies the number of clusters in a data-driven fashion; please refer to A2 to Reviewer #1 to see how the identified number of clusters remains consistent throughout different.	I-Reply	I-3	Reply	564
We will clarify this in the revised manuscript.	I-Reply	I-3	Reply	564
<sep> <sep> A4.	O	O	Reply	564
In the experiments, we know the ground-truth binary labels of the future outcomes of interest (that is, development of diabetes, ABPA, and intestinal obstruction).	B-Reply	B-4	Reply	564
Thus, we can simply compute AUROC and AUPRC using the cluster-wise outcome predictions (i.e.,) and the outcome labels (i.e.,).	I-Reply	I-4	Reply	564
The AUROC and AURPC reported in Table 2 are averaged over the three comorbidities.	I-Reply	I-4	Reply	564
Similarly, the ground-truth cluster label can be computed as a combination of the three binary outcome labels which makes as described in Section 5.4.	I-Reply	I-4	Reply	564
We will clarify the description in the revised manuscript.	I-Reply	I-4	Reply	564

This paper proposes a temporal clustering algorithm for the medical domain.	O	O	Review	564
The main advantage of the proposed method is that it uses supervised information for temporal clustering.	O	O	Review	564
The proposed method is evaluated on two real-world datasets and showed improvements against a few other temporal clustering methods.	O	O	Review	564
<sep> <sep> Detailed Comments:	O	O	Review	564
<sep> Methodology:	O	O	Review	564
The actor-critic part of the loss is really just a type of policy gradient.	B-Review	B-1	Review	564
There is no estimation of a value function in Eqn.	I-Review	I-1	Review	564
7 or anywhere to be found in Appendix B. This is very misleading on the part of the authors because policy grad and AC are very different algorithms.	I-Review	I-1	Review	564
AC type of algorithms provide some variance reduction mechanisms for the classical policy gradient (not done here), but they require additional work to estimate a value function for future trajectories that incur bias.	I-Review	I-1	Review	564
If the authors claim a real AC algorithm for the predictive clustering loss, then some justification for bias-variance tradeoffs should be mentioned instead of attributing it to tuning the hyperparameters between the losses.	I-Review	I-1	Review	564
<sep> Perhaps a bigger issue is that there is a general tradeoff between reconstructing the time-series (the unsupervised learning portion) vs. predictive performance that is common to predictive clustering problems -- it is not addressed here.	B-Review	B-2	Review	564
One can increase the performance in one (in this case prediction accuracy) while sacrificing the other.	I-Review	I-2	Review	564
<sep> <sep> In the extreme case, one can just tune the hyperparameter of the loss function to turn this into a pure supervised learning problem while sacrificing the capacity of the embedding representations to have any meaning (e.g., to reconstruct time-series [SOM-VAE] or predict future ones).	B-Review	B-3	Review	564
The authors did not really propose a systematic way to control this tradeoff, nor did they provide some experiments to show how well the embeddings can be used to recover the temporal patterns.	I-Review	I-3	Review	564
<sep> <sep> Experiments:	O	O	Review	564
The baseline experiments are rather weak.	B-Review	B-4	Review	564
For example, 3 out of the 4 models (DTW, DCN extensions and SOM-VAE) were all unsupervised learning techniques that are not designed to take into account label information.	I-Review	I-4	Review	564
This is especially true for comparison against SOM-VAE (which the authors called state of the art for the proposed problem).	I-Review	I-4	Review	564
SOM-VAE is actually less intended for prognostication than the likes of Baytas et al (2017) and Madiraju et al (2018) and provides less informative baselines.	I-Review	I-4	Review	564
The authors should also provide more details regarding how these ``extensions'' are done for things like DCN and K-means clustering on deep neural networks.	I-Review	I-4	Review	564
A2.	O	O	Reply	564
We thank the reviewer for pointing such an important issue in the predictive clustering and for providing an opportunity to highlight our contributions.	B-Reply	B-2	Reply	564
In predictive clustering, it is true that the trade-off between the clustering performance (for better interpretability), which quantifies how the data samples are homogeneous within each cluster and heterogeneous across clusters with respect to the future outcomes of interest, and the prediction performance is a common issue.	I-Reply	I-2	Reply	564
It is worth highlighting that predictive clustering is an unsupervised task of finding groups of samples with similar future outcomes of interest(i.e.,	I-Reply	I-2	Reply	564
the label for true clusters is not available); therefore, it is not necessary to incorporate reconstruction of the original input.	I-Reply	I-2	Reply	564
<sep> <sep> The most important parameter that governs this trade-off is the number of clusters.	I-Reply	I-2	Reply	564
More specifically, increasing the number of clusters will make the predictive clusters have higher diversity to represent the output distribution and, thus, will increase the prediction performance while decreasing the clustering performance.	I-Reply	I-2	Reply	564
One extreme example is that there are as many clusters as data samples which will make the identified clusters fully individualized; as a consequence, each cluster will lose the interpretability as it no longer groups similar data samples.	I-Reply	I-2	Reply	564
<sep> <sep> To highlight this trade-off, we conducted extensive experiments under the same experimental setup with that of Section 5.6 where our aim is to identify underlying (unknown) clusters when the future outcome of interest is high-dimensional.	I-Reply	I-2	Reply	564
For the performance measures, we utilized the AUROC and AUPRC to assess the prediction performance, and utilized the Silhouette index [C] -- a widely used measure of how similar a member is to its own cluster (homogeneity within a cluster) compared to other clusters (heterogeneity across clusters ) when the ground-truth cluster labels are not available -- to assess the identified clusters.	I-Reply	I-2	Reply	564
Here, we used the L1-distance between the ground-truth output labels to compute the Silhouette index since our goal is to group input subsequences with similar future outcomes.	I-Reply	I-2	Reply	564
The formal description will be added in the appendix of the revised manuscript.	I-Reply	I-2	Reply	564
To control the number of identified clusters (i.e., the activated clusters) of our method, we set (since the embedding separation loss in (5) controls the activation of clusters) and reported the performance by increasing the number of possible clusters (which is the dimension of the softmax output layer of the selector).	I-Reply	I-2	Reply	564
<sep> <sep> As can be seen in the table below, the prediction performance increased with an increased number of clusters due to the higher diversity to represent the label distribution while having the identified clusters less interpretable (i.e., the cohesion and separation among clusters become ambiguous).	I-Reply	I-2	Reply	564
On the other hand, when we set (which is selected based on the validation loss in (3)), our method consistently identified a similar number of clusters for, i.e., 13.8 on average, in a data-driven fashion and provided slightly reduced prediction performance with significantly better interpretability, i.e., the Silhouette index 0.121 on average.	I-Reply	I-2	Reply	564
This highlights the usefulness of (5) which helps to identify clusters to have different label distributions.	I-Reply	I-2	Reply	564
Detailed results will be added to the revised manuscript.	I-Reply	I-2	Reply	564
<sep> <sep> -------------------------------------------------------------------------------------------------------------------------------	I-Reply	I-2	Reply	564
|Metrics                    |K=10            |K=20            |K=30            |K=40            |K=50	I-Reply	I-2	Reply	564
-------------------------------------------------------------------------------------------------------------------------------      |AUROC                    |0.680.01|0.730.01|0.750.01|0.760.01|0.770.01	I-Reply	I-2	Reply	564
|AUPRC                     |0.220.01|0.280.01|0.310.01|0.340.01|0.350.01	I-Reply	I-2	Reply	564
|Silhouette Index    |0.090.02|0.070.01|0.040.01|0.030.01|0.030.02	I-Reply	I-2	Reply	564
|Activated Clusters |10                |19.8             |29.4              |38.6             |47.6	I-Reply	I-2	Reply	564
-------------------------------------------------------------------------------------------------------------------------------      |AUROC                    |0.680.01|0.710.01|0.720.01|0.710.01|0.720.02	I-Reply	I-2	Reply	564
|AUPRC                     |0.210.01|0.240.01|0.260.01|0.250.01|0.260.01	I-Reply	I-2	Reply	564
|Silhouette Index    |0.090.02|0.120.01|0.120.01|0.110.02|0.110.02	I-Reply	I-2	Reply	564
|Activated Clusters | 9.6              |13.6              |13.7             |13.8             |14.1	I-Reply	I-2	Reply	564
-------------------------------------------------------------------------------------------------------------------------------	I-Reply	I-2	Reply	564

Summary:	O	O	Review	564
This work proposes a method to perform clustering on a time-series data for prediction purposes, unlike the classical clustering where it is done in an unsupervised manner.	O	O	Review	564
The authors use an encoder (RNN) to process the time-series medical records, a selector to sample the cluster label for each encoding, and a predictor to predict the labels based on the selected cluster centroids.	O	O	Review	564
Since the sampling process prevents the authors from using back-prop, they employ an actor-critic method.	O	O	Review	564
<sep> <sep> Strengths:	O	O	Review	564
- Although some would argue otherwise, patient similarity has some promise to be useful in clinical practice.	O	O	Review	564
<sep> - The proposed method clearly outperformed various baselines in terms of clustering (Table 1).	O	O	Review	564
<sep> - Table 3 and Figure 3 show that the proposed method can capture heterogeneous subgroups of the dataset.	O	O	Review	564
<sep> <sep> Concerns:	O	O	Review	564
- I'm not a clustering expert, but I'm skeptical this is the first work to combine clustering and supervised prediction using an RL technique.	B-Review	B-1	Review	564
<sep> - It is unclear what it means to train the embedding dictionary.	B-Review	B-2	Review	564
Are there trainable parameters in the embedding dictionary?	I-Review	I-2	Review	564
It seems that all it does is calculate the mean of the z_t's (i.e. centroid) in each cluster.	I-Review	I-2	Review	564
Or do you take the centroid embeddings and put that through a feed-forward network of some sort?	I-Review	I-2	Review	564
<sep> - The effect of Embedding Separation Loss (Eq.5) seems quite limited.	B-Review	B-3	Review	564
According to Table 2, it doesn't seem to help much.	I-Review	I-3	Review	564
And contrary to the authors' claim, using \beta increase the number of activated clusters from 8 to 8.4.	I-Review	I-3	Review	564
<sep> - Most importantly, the central theme of this work is combining clustering with prediction labels for the downstream prediction task.	B-Review	B-4	Review	564
But the authors do not compare the prediction performance of the proposed method with other clustering method or "patient similarity" methods, or even simple supervised models.	I-Review	I-4	Review	564
The only prediction performance metric to be found is Table 2 from the ablation study.	I-Review	I-4	Review	564
We thank the reviewer for the valuable comments.	O	O	Reply	564
<sep> <sep> A1.	O	O	Reply	564
To our best knowledge, this paper is the first to apply reinforcement learning for identifying predictive clusters.	B-Reply	B-1	Reply	564
Indeed, there exist some studies that explored clustering with reinforcement learning, such as to select a better initialization for K-means [A] and to design efficient feature space [B]. However, previous works mainly focused on conventional clustering problems without accounting for observed outcome labels of interest.	I-Reply	I-1	Reply	564
<sep> <sep> A2.	O	O	Reply	564
The embedding dictionary consists of embedding vectors in the latent space, i.e., where these embedding vectors are updated by minimizing the loss function in (9) based on the stochastic gradient descent method.	B-Reply	B-2	Reply	564
This is doable because both terms in (9) are defined as a function of the predictor outputs taking the embedding vectors as input; this makes (9) differentiable with respect to the embedding vectors.	I-Reply	I-2	Reply	564
Please refer to Algorithm 1 in Appendix F to see the formal descriptions of how we update the embedding vectors.	I-Reply	I-2	Reply	564
<sep> <sep> A3.	B-Reply	B-3	Reply	564
We inadvertently mistyped the values on the number of activated clusters for and; the correct number of activated clusters is 8.4 with and 8 with.	I-Reply	I-3	Reply	564
We will correct the typo in Table 2 in the revised manuscript.	I-Reply	I-3	Reply	564
Besides, please refer to A2 to Reviewer #1 to see how the embedding separation loss in (5) plays a significant role in identifying the number of clusters in a data-driven fashion.	I-Reply	I-3	Reply	564
<sep> <sep> A4.	O	O	Reply	564
As the reviewer suggested, we assessed the prognostic performance of our method and the clustering benchmarks which incorporate the label information during training ‚Äì that are KM-E2P ), KM-E2P ), DCN-E2P, and SOM-VAE-P. For the prognostic performance, we evaluated AUROC and AURPC based on the ground-truth binary outcomes ) and the cluster-specific outcome predictions that are calculated specifically to each clustering method:	B-Reply	B-4	Reply	564
- For KM-E2P ) and DCN-E2P, the cluster-specific outcome predictions are the predictor outcomes taking the average latent representations per cluster (i.e., the K-means centroids in the latent space) as input.	I-Reply	I-4	Reply	564
<sep> - For KM-E2P ), the cluster-specific outcome predictions are the average predictor outcomes per cluster (i.e., the K-means centroids in the outcome space).	I-Reply	I-4	Reply	564
<sep> - For SOM-VAE-P and our method, the cluster-specific outcome predictions are the predictor outcomes (i.e.,) taking the assigned embedding vectors as input.	I-Reply	I-4	Reply	564
<sep> Below, we reported the AUROC and AUPRC for UKCF and ADNI; our method outperformed all the tested benchmarks in both performance metrics.	I-Reply	I-4	Reply	564
We will update Table 1 in the revised manuscript accordingly.	I-Reply	I-4	Reply	564
<sep> <sep> ---------------------------------------------------------------------------------------------------	I-Reply	I-4	Reply	564
|UKCF                                         | ADNI	I-Reply	I-4	Reply	564
Methods       |--------------------------------------------------------------------------------	I-Reply	I-4	Reply	564
| AUROC          | AUPRC           | AUROC           | AUPRC<tab>	I-Reply	I-4	Reply	564
---------------------------------------------------------------------------------------------------	I-Reply	I-4	Reply	564
KM-E2P(Z)    | 0.726 0.01 | 0.425 0.02 | 0.707 0.01 | 0.509 0.01	I-Reply	I-4	Reply	564
KM-E2P(Y)    | 0.807 0.00 | 0.514 0.01 | 0.756 0.04 | 0.503 0.04	I-Reply	I-4	Reply	564
DCN-E2P      | 0.772 0.03 | 0.487 0.03 | 0.721 0.03 | 0.509 0.03	I-Reply	I-4	Reply	564
SOM-VAE-P  | 0.754 0.05 | 0.331 0.07 | 0.597 0.10 | 0.376 0.05	I-Reply	I-4	Reply	564
Proposed     | 0.843 0.01 | 0.605 0.01 | 0.768 0.02 | 0.515 0.02	I-Reply	I-4	Reply	564
---------------------------------------------------------------------------------------------------	I-Reply	I-4	Reply	564
<sep> References:	O	O	Reply	564
[A] S. Bose and M. Huber, ‚ÄúSemi-Unsupervised Clustering Using Reinforcement Learning,‚Äù AAAI 2016.	O	O	Reply	564
<sep> [B] W. Barbakh and C. Fyfe, ‚ÄúClustering with Reinforcement Learning,‚Äù IDEAL 2007	O	O	Reply	564

This work proposes an end-to-end graph encoder to sequence decoder model with an attention mechanism in between.	O	O	Review	1313
<sep> Pros (+) :	O	O	Review	1313
+ Overall, the paper provides a good first step towards flexible end-to-end graph-to-seq models.	O	O	Review	1313
<sep> + Experiments show promising results for the model to be tested in further domains.	O	O	Review	1313
<sep> Cons (-) :	O	O	Review	1313
- The paper would benefit more motivation and organization.	B-Review	B-1	Review	1313
<sep> <sep> Further details below (+ for pros / ~ for suggestions / - for cons):	O	O	Review	1313
<sep> The paper could benefit a little more motivation:	O	O	Review	1313
- Mentioning a few tasks in the introduction may not be enough.	B-Review	B-2	Review	1313
Explaining why these tasks are important may help.	I-Review	I-2	Review	1313
What is the greater problem the authors are trying to solve?	I-Review	I-2	Review	1313
<sep> - Same thing in the experiments, not well motivated, why these three?	B-Review	B-3	Review	1313
What characteristics are the authors trying to analyze with each of these tasks?	I-Review	I-3	Review	1313
<sep> <sep> Rephrase the novelty argument:	O	O	Review	1313
- The authors argue to present a ‚Äúnovel attention mechanism‚Äù but the attention mechanism used is not new (Bahdanau 2014 a & b).	B-Review	B-4	Review	1313
The fact that it is applied between a sequence decoder and graph node embeddings makes the paper interesting but maybe not novel.	I-Review	I-4	Review	1313
<sep> ~ The novelty added by this paper is the ‚Äúbi-edge-direction‚Äú aggregation technique with the exploration of various pooling techniques.	B-Review	B-5	Review	1313
This could be emphasized more.	I-Review	I-5	Review	1313
<sep> <sep> Previous work:	O	O	Review	1313
~ The Related Work section could mention Graph Attention Networks (<a href="https://arxiv.org/abs/1710.10903)" target="_blank" rel="nofollow">https://arxiv.org/abs/1710.10903)</a> as an alternative to the node aggregation strategy.	B-Review	B-6	Review	1313
<sep> <sep> Aggregation variations:	O	O	Review	1313
+ The exploration between the three aggregator architectures is well presented and well reported in experiments.	B-Review	B-7	Review	1313
<sep> ~ The two Graph Embedding methods are also well presented, however, I didn‚Äôt see them in experiments.	B-Review	B-8	Review	1313
Actually, it isn‚Äôt clear at all if these are even used since the decoder is attending over node embeddings, not graph embedding‚Ä¶ Could benefit a little more explanation	I-Review	I-8	Review	1313
<sep> Experiments:	O	O	Review	1313
+ Experiments show some improvement on the proposed tasks compared to a few baselines.	O	O	Review	1313
<sep> - The change of baselines between table 1 for the first two tasks and table 2 for the third task is not explained and thus confusing.	B-Review	B-9	Review	1313
<sep> ~ There are multiple references to the advantage of using ‚Äúbi-directional‚Äù node embeddings, but it is not clear from the description of each task where the edge direction comes from.	B-Review	B-10	Review	1313
A better explanation of each task could help.	I-Review	I-10	Review	1313
<sep> <sep> Results:	O	O	Review	1313
- Page 9, the ‚ÄúImpact of Attention Mechanism‚Äù is discussed but no experimental result is shown to support these claims.	B-Review	B-11	Review	1313
<sep> <sep> <sep> Some editing notes:	B-Review	B-12	Review	1313
(1) Page 1, in the intro, when saying ‚Äúseq2seq are excellent for NMT, NLG, Speech Reco, and drug discovery‚Äù: this last example breaks the logical structure of the sentence because it has nothing to do with NLP.	I-Review	I-12	Review	1313
<sep> (2) Page 1, in the intro, when saying that ‚Äú<...> a network can only be applied to sequential inputs‚Äù: replace network by seq2seq models to be exact.	I-Review	I-12	Review	1313
<sep> (3) Typo on page 3, in paragraph ‚ÄúNeural Networks on Graphs‚Äù, on 8th line ‚Äúusig‚Äù -> ‚Äúusing‚Äù	I-Review	I-12	Review	1313
(4) Page 3, in paragraph ‚ÄúNeural Networks on Graphs‚Äù, the following sentence: ‚ÄúAn extension of GCN can be shown to be mathematically related to one variant of our graph encoder on undirected graphs.	I-Review	I-12	Review	1313
‚Äù is missing some information, like a reference, or a proof in Appendix, or something else‚Ä¶	I-Review	I-12	Review	1313
(5) Page 9, the last section of the ‚ÄúImpact of Hop Size‚Äù paragraph talks about the impact of the attention strategy.	I-Review	I-12	Review	1313
This should be moved to the next paragraph which discusses attention.	I-Review	I-12	Review	1313
<sep> (6) Some references are duplicates:	I-Review	I-12	Review	1313
|_ Hamilton 2017 a & c	I-Review	I-12	Review	1313
|_ Bahdanau 2014 a & b	I-Review	I-12	Review	1313
<sep> Q5: The two Graph Embedding methods are also well presented, however, I didn‚Äôt see them in experiments.	O	O	Reply	1313
Actually, it isn‚Äôt clear at all if these are even used since the decoder is attending over node embeddings, not graph embedding‚Ä¶ Could benefit a little more explanation	O	O	Reply	1313
<sep> Answer: We indeed performed the experiments comparing these two graph embedding methods.	B-Reply	B-8	Reply	1313
We have included the additional experimental results in Table 2.	I-Reply	I-8	Reply	1313
It is worth noting that the graph embedding methods play an important role in the final performance as shown in Table 2.	I-Reply	I-8	Reply	1313
The graph-level embedding is computed as the initial input for our sequence decoder.	I-Reply	I-8	Reply	1313
The main reason for the significant performance discrepancy of these two graph embedding methods is that the super-node based graph embedding method artificially added a super node in the graph which changes the original graph topology and brings unnecessary noise into the graph.	I-Reply	I-8	Reply	1313
We have made it more clear in the updated submission.	I-Reply	I-8	Reply	1313
<sep> <sep> Q6: The change of baselines between table 1 for the first two tasks and table 2 for the third task is not explained and thus confusing.	O	O	Reply	1313
<sep> <sep> Answer: It appears that there is a misunderstanding.	B-Reply	B-9	Reply	1313
We realize now that our presentation obscured some important facets of the experimental settings of this paper.	I-Reply	I-9	Reply	1313
<sep> 1) For the third task, we changed the baselines to Seq2Seq based methods because the SQL-to-Text problem can be viewed as ‚Äúmachine translation‚Äù task which Seq2Seq is a state-of-the-art method for this problem.	I-Reply	I-9	Reply	1313
That is said, the previous baselines like LSTM, GGS-NN, and GCN cannot deal with problems well.	I-Reply	I-9	Reply	1313
<sep> 2) We have already shown in the previous tasks that Graph2Seq outperforms or matches LSTM, GGS-NN and GCN so here we just reported Graph2Seq to compare with other Seq2Seq based methods.	B-Reply	B-9	Reply	1313
<sep> <sep> Q7: Better explanation of ‚Äúbi-directional‚Äù node embeddings	O	O	Reply	1313
<sep> Answer: Our design of combining the forward and backward representations is inspired by the bi-LSTM architecture, that is, generating the representation of a node for each direction (forward or backward), and then concatenating them.	B-Reply	B-10	Reply	1313
Intuitively, this architecture could explicitly represent the context of a node, i.e., the forward context representation and backward context representation.	I-Reply	I-10	Reply	1313
We think this design is reasonable and could be better at capturing the graph structure.	I-Reply	I-10	Reply	1313
In each task, the graph is either a directed or undirected graph.	I-Reply	I-10	Reply	1313
In both cases combining the node embedding from both contexts of a node are indeed beneficial as shown in their results.	I-Reply	I-10	Reply	1313
<sep> <sep> Q8: ‚ÄúImpact of Attention Mechanism‚Äù	O	O	Reply	1313
<sep> Answer: Attention-based decoder is widely recognized as a useful component in most of the encoder-decoder architectures nowadays.	B-Reply	B-11	Reply	1313
Thus, we just put the results in Table 4 for these ‚Äúunsurprising results‚Äù.	I-Reply	I-11	Reply	1313
We refer the reviewer to Table 4 for more details in Appendix C.	I-Reply	I-11	Reply	1313
<sep> Q9: Other minor notes.	O	O	Reply	1313
<sep> <sep> Answer: we appreciated your careful reading and have fixed all of them based on your comments.	B-Reply	B-12	Reply	1313

This paper proposes a graph to sequence transducer consisting of a graph encoder and a RNN with attention decoder.	O	O	Review	1313
<sep> <sep> Strengths:	O	O	Review	1313
- Novel architecture for graph to sequence learning.	B-Review	B-7	Review	1313
<sep> - Improved performance on synthetic transduction tasks and graph to text generation.	O	O	Review	1313
<sep> Weaknesses:	O	O	Review	1313
- Experiments could provide more insight into model architecture design and the strengths and weaknesses of the model on non-synthetic data.	B-Review	B-1	Review	1313
<sep> <sep> Transduction with structured inputs such as graphs is still an under-explored area, so this paper makes a valuable contribution in that direction.	O	O	Review	1313
Previous work has mostly focused on learning graph embeddings producing outputs.	O	O	Review	1313
This paper extends the encoder proposed by Hamilton et al (2017a) by modelling edge direction through learning ‚Äúforward‚Äù and ‚Äúbackward‚Äù representations of nodes.	O	O	Review	1313
Node embeddings are pooled to a form a graph embedding to initialize the decoder, which is a standard RNN with attention over the node embeddings.	O	O	Review	1313
<sep> <sep> The model is relatively similar to the architecture proposed by Bastings et al (2017) that uses a graph convolutional encoder, although the details of the graph node embedding computation differs.	B-Review	B-2	Review	1313
Although this model is presented in a more general framework, that model also accounted for edge directionality (as well as edge labels, which this model do not support).	I-Review	I-2	Review	1313
<sep> <sep> This paper does compare the proposed model with graph convolutional networks (GCNs) as encoder experimentally, finding that the proposed approach performs better on shortest directed path tasks.	B-Review	B-3	Review	1313
However the paper could make difference between these architectures clearer, and provide more insight into whether different graph encoder architectures might be more suited to graphs with different structural properties.	I-Review	I-3	Review	1313
<sep> <sep> The model obtains strong performance on the somewhat artificial bAbI and Shortest path tasks, while the strongest result is probably that of strong improvement over the baselines in SQL to text generation.	B-Review	B-4	Review	1313
However, very little insight is provided into this result.	I-Review	I-4	Review	1313
It would be interesting to apply this model to established NLG tasks such as AMR to text generation.	I-Review	I-4	Review	1313
<sep> Overall, this is an interesting paper, and I‚Äôd be fine with it being accepted.	B-Review	B-5	Review	1313
However, the modelling contribution is relatively limited and it feels like for this to be a really strong contribution more insight into the graph encoder design, or more applications to real tasks and insight into the model‚Äôs performance on these tasks is required.	I-Review	I-5	Review	1313
<sep> <sep> Editing notes:	B-Review	B-6	Review	1313
Hamilton et al 2017a and 2017c is the same paper.	I-Review	I-6	Review	1313
<sep> In some cases the citation format is used incorrectly: when the citation form part of the sentence, the citation should be inline.	I-Review	I-6	Review	1313
E.g. (p3) introduced by (Bruna et al 2013)  -> introduced by Bruna et al (2013).	I-Review	I-6	Review	1313
<sep> <sep> We first would like to thank the referees for their very careful reading, for identifying subpar language, typos, and discrepancies in text, and for asking questions that will help us significantly improve the presentation such as motivation and organization.	O	O	Reply	1313
<sep> <sep> <sep> Q1: Novel architecture for graph to sequence learning‚Ä¶ Transduction with structured inputs such as graphs is still an under-explored area, so this paper makes a valuable contribution in that direction...	O	O	Reply	1313
<sep> We are very grateful for the kind comments of reviewers #1, in particular for your recognition of the key contributions of the paper.	B-Reply	B-7	Reply	1313
<sep> <sep> Q2: Experiments could provide more insight into model architecture design and the strengths and weaknesses of the model on non-synthetic data.	O	O	Reply	1313
<sep> <sep> Answer: we fully agree with the reviewer‚Äôs comments (which is also brought up by reviewer #3).	B-Reply	B-1	Reply	1313
According to your and reviewer #3‚Äôs comments, we have completely rewrite the paragraph that describes the experimental result of the SQL-to-Text task.	I-Reply	I-1	Reply	1313
We have also added/modified quite a few of paragraphs to better provide more insights on dataset selections, the motivation of the comparisons, and various characteristics of our Graph2Seq in terms of hop size, aggregation strategies, attention mechanism, and input graph sizes.	I-Reply	I-1	Reply	1313
<sep> <sep> Q3: The model is relatively similar to the architecture proposed by Bastings et al (2017)	O	O	Reply	1313
<sep> Answer: We noticed that Bastings et al (2017) has utilized GCN for improving the encoder of the neural machine translation system, as we discussed in the related work.	B-Reply	B-2	Reply	1313
However, we would like to point out three major differences between their model and our Graph2Seq model in terms of model architecture:	I-Reply	I-2	Reply	1313
<sep> 1) Since Bastings‚Äôs encoder are built on GCN, which itself is derived from spectral graph convolutional neural networks, their model can be only used under transductive settings.	I-Reply	I-2	Reply	1313
In contrast, our graph encoder can be used under both transductive and inductive settings.	I-Reply	I-2	Reply	1313
<sep> 2) Although Bastings‚Äôs encoder takes into account both incoming and outgoing edges as well as the edge labels, they only compute a single node embedding using the information from both directions.	B-Reply	B-2	Reply	1313
This is quite different from our bidirectional aggregation strategies, which is inspired from the bi-LSTM architecture, where we generate the representation of a node for each direction (forward or backward), and then concatenating them.	I-Reply	I-2	Reply	1313
Intuitively, this architecture could explicitly represent the context of a node, i.e., the forward context representation and backward context representation.	I-Reply	I-2	Reply	1313
<sep> 3) Bastings et al (2017) used the same attention based decoder of Bahdanau et al (2015) while we design an attention-based decoder over the graph node embeddings.	B-Reply	B-2	Reply	1313
Therefore, our attention mechanism is independent of underlying specific tasks and generally applicable to different tasks.	I-Reply	I-2	Reply	1313
<sep> <sep> Q4: However the paper could make difference between these architectures clearer, and provide more insight into whether different graph encoder architectures might be more suited to graphs with different structural properties.	O	O	Reply	1313
<sep> Answer: we thank for the reviewer‚Äôs suggestions and we have added some more discussions about the differences between different graph encoder.	B-Reply	B-3	Reply	1313
For different graph encoders, the most important advantages of our graph encoder lie in the fact that, when the graph size increases, all graph encoders started to perform poorer due to losing global information of a graph.	I-Reply	I-3	Reply	1313
However, our bi-directional node embeddings help converge rapidly to the optimal performance as shown in Figure 4.	I-Reply	I-3	Reply	1313
<sep> <sep> Q5:  However, very little insight is provided into this result.	O	O	Reply	1313
It would be interesting to apply this model to established NLG tasks such as AMR to text generation.	O	O	Reply	1313
<sep> Answer: please see our previous response for providing more insights into the SQL-to-Text task.	B-Reply	B-4	Reply	1313
Conceptually, the AMR-to-Text task would be similar to the SQL-to-Text task, which we would be happy to explore in the near future.	I-Reply	I-4	Reply	1313
<sep> <sep> Q6: Overall, this is an interesting paper, and I‚Äôd be fine with it being accepted.	O	O	Reply	1313
However, the modeling contribution is relatively limited and it feels like for this to be a really strong contribution more insight into the graph encoder design, or more applications to real tasks and insight into the model‚Äôs performance on these tasks is required.	O	O	Reply	1313
<sep> <sep> Answer: we hope that our previous responses have helped better explain the novelty of our Graph2Seq model architecture over existing works.	B-Reply	B-5	Reply	1313
According to your and reviewer #3‚Äôs comments, we have rephrased our key contributions of our model, that is, a novel graph encoder to learn a bi-directional node embedding for directed and undirected graphs with node attributes by employing various aggregation strategies, and to learn graph-level embedding by exploiting two different graph embedding techniques.	I-Reply	I-5	Reply	1313
In addition, to the best of knowledge, our attention mechanism to learn the alignments between nodes and sequence elements to better cope with larger graphs is also proposed for the first time.	I-Reply	I-5	Reply	1313

The submission discusses a graph2seq architecture that combines a graph encoder that mixes GGNN and GCN components with an attentional sequence encoder.	O	O	Review	1313
The resulting model is evaluated on three very simple tasks, showing small improvements over baselines.	O	O	Review	1313
<sep> <sep> I'm not entirely sure what the contribution of this paper is supposed to be.	O	O	Review	1313
The technical novelty seems to be limited to new notation for existing work:	O	O	Review	1313
- (Sect.	O	O	Review	1313
3.1) The separation of forward/backward edges was already present in the (repeatedly cited) Li et al 2015 paper on GGNN (and in Schlichtkrull et al 2017 for GCN).	B-Review	B-1	Review	1313
The state update mechanism (a FC layer of the concatenation of old state / incoming messages) seems to be somewhere between a gated unit (as in GGNN) and the "add self-loops to all nodes" trick used in GCN; but no comparison is provided with these existing baselines.	I-Review	I-1	Review	1313
<sep> - (Sect 3.2) The discussed graph aggregation mechanism are those proposed in Li et al and Gilmer et al; no comparison to these baselines is provided.	B-Review	B-2	Review	1313
<sep> - (Sect.	O	O	Review	1313
3.3) This is a standard attention-based decoder; the fact that the memories come from a graph doesn't change anything fundamental.	B-Review	B-3	Review	1313
<sep> <sep> The experiments are not very informative, as simple baselines already reach >95% accuracy on the chosen tasks.	B-Review	B-7	Review	1313
The most notable difference between GGS-NNs and this work seems to be the attention-based decoder, but that is not evaluated explicitly.	I-Review	I-7	Review	1313
For the rebuttal phase, I would like to ask the authors to provide the following:	I-Review	I-7	Review	1313
- Experimental results for either GGS-NN with an attentional decoder, or their model without an attentional decoder, to check if the reported gains come from that.	B-Review	B-4	Review	1313
The final paragraph in Sect.	I-Review	I-4	Review	1313
4 seems to indicate that the attention mechanism is the core enabler of the (small) experimental gains on the baselines.	I-Review	I-4	Review	1313
<sep> - The results of the GCN/GG-NN models (i.e., just as an encoder) with their decoder on the NLG task.	B-Review	B-5	Review	1313
<sep> - More precise definition of what they feel the contribution of this paper is, taking into account my comments from above.	B-Review	B-6	Review	1313
<sep> <sep> Overall, I do not think that the paper in its current state merits publication at ICLR.	O	O	Review	1313
<sep> <sep> Q5: (Sect.	O	O	Reply	1313
3.3) This is a standard attention-based decoder; the fact that the memories come from a graph doesn't change anything fundamental.	O	O	Reply	1313
<sep> <sep> Answer: Yes, this construction of attention is conceptually similar to the standard one.	B-Reply	B-3	Reply	1313
However, while we agree that our attention mechanism is *simple* once the construction is seen, we argue that it is not *trivial* to create this construction in the first place.	I-Reply	I-3	Reply	1313
If this were trivial, we might have expected earlier work such as (Li et al 2015) and (Schlichtkrull et al 2017) have already to use it, yet they did not.	I-Reply	I-3	Reply	1313
Therefore, we are the first one to design an attention mechanism between a sequence decoder and the graph node embeddings, which has also been demonstrated to be an important component for any Graph2Seq model with different graph encoder, as shown in Table 4 in Appendix C.	I-Reply	I-3	Reply	1313
<sep> Q6: The experiments are not very informative, as simple baselines already reach >95% accuracy on the chosen tasks.	O	O	Reply	1313
<sep> <sep> Answer: We assume the reviewer pointed to the results in Table 1.	B-Reply	B-7	Reply	1313
However, the simple baseline LSTM performed extremely poor in this task with only 25.2%, 8.1%, and 2.2% on bAbI T19, SP-S, and SP-L, respectively.	I-Reply	I-7	Reply	1313
Our approach and other state-of-the-art baselines such as GGS-NN and GCN can achieve the performance > 95%, highlighting the importance of considering a graph encoder for complex inputs like graphs.	I-Reply	I-7	Reply	1313
However, we can still see the large performance discrepancy when the graph size grows larger like SP-L, which challenges the effectiveness of existing graph encoders.	I-Reply	I-7	Reply	1313
The similar studies on the effect of the large graph are also provided in Figure 4.	I-Reply	I-7	Reply	1313
<sep> <sep> Q7: The most notable difference between GGS-NNs and this work seems to be the attention-based decoder, but that is not evaluated explicitly.	O	O	Reply	1313
<sep> <sep> Answer: Indeed, the attention mechanism plays an important role in our Graph2Seq model, which is not surprising since it has been widely recognized as a useful component in most of the encoder-decoder architectures nowadays.	B-Reply	B-7	Reply	1313
Thus, we just put the results in Table 4 for these ‚Äúunsurprising results‚Äù.	I-Reply	I-7	Reply	1313
We refer the reviewer to Table 4 for more details in Appendix C.	I-Reply	I-7	Reply	1313
<sep> Compared to GGS-NN, other important difference is our bi-directional node embedding, which plays an important role for converging rapidly to the optimal performance compared to other graph encoders as shown in Figure 4.	I-Reply	I-7	Reply	1313
<sep> <sep> Q8: Experimental results for either GGS-NN with an attentional decoder, or their model without an attentional decoder, to check if the reported gains come from that.	O	O	Reply	1313
The final paragraph in Sect.	O	O	Reply	1313
4 seems to indicate that the attention mechanism is the core enabler of the (small) experimental gains on the baselines.	O	O	Reply	1313
<sep> <sep> Answer: As we shown in Table 4, Attention mechanism is a core component for our graph encoder and GCN, which as discussed before is reasonable just like Seq2Seq with attention compared again vanilla Seq2Seq model.	B-Reply	B-4	Reply	1313
<sep> <sep> Q9: The results of the GCN/GG-NN models (i.e., just as an encoder) with their decoder on the NLG task.	O	O	Reply	1313
<sep> <sep> Answer: Although this is an interesting suggestion, this is slightly out of the scope of this paper.	B-Reply	B-5	Reply	1313
First of all, our Graph2Seq model is proposed to serve a generalized Seq2Seq model for graph inputs.	I-Reply	I-5	Reply	1313
On NLG task, we have already demonstrated the superior performance of Graph2Seq over Seq2Seq and Tree2Seq models.	I-Reply	I-5	Reply	1313
Second, in the previous two tasks (in Table 1), we also demonstrated the advantages of our Graph2Seq over GGS-NN and GCN.	I-Reply	I-5	Reply	1313
Finally, as we mentioned in the Introduction, ‚ÄúGraph2Seq is simple yet general and is highly extensible where its two building blocks, graph encoder and sequence decoder, can be replaced by other models‚Äù.	I-Reply	I-5	Reply	1313
We have released our code and data, and we would be happy to see more researchers and practitioners in using/adopting our Graph2Seq model for different tasks.	I-Reply	I-5	Reply	1313

This paper proposes an architecture that encodes a known physics motion equation of a trajectory of a moving object.	O	O	Review	20260
The modeled equation has 3 variables and the network works in a latent space- contrary to taking raw images.	O	O	Review	20260
It uses an auxiliary network (named InferNet) to train the final one used at inference time (named RelateNet).	O	O	Review	20260
The former aims to reconstruct the input sequence of positions representing trajectory, and has intermediate 3 latent variables that correspond to the 3 variables of the modeled equation, while as decoder it uses the modeled known equation itself.	O	O	Review	20260
The latter is a mapping from the relative position of the object to 2 latent variables of the former InferNet, and is trained with MSE loss.	O	O	Review	20260
At inference, RelateNet takes as input the relative position of the object, predicts 2 variables of the equation and finally uses the motion equation to calculate the trajectory.	O	O	Review	20260
<sep> <sep> It is not easy for me to understand the use-case of the proposed method.	B-Review	B-1	Review	20260
In which real-world scenarios we would have the exact motion equation, and why given that we know such an equation we would want to learn a mapping from the relative position to a trajectory.	I-Review	I-1	Review	20260
In other words, it would be much more useful to learn the projectile motion equation itself.	I-Review	I-1	Review	20260
How does the proposed method handle input sequences which do not follow equation 5?	I-Review	I-1	Review	20260
To use this method do we need to know in advance the exact motion equation and its relevant ‚Äòin-game variables‚Äô?	I-Review	I-1	Review	20260
In which cases would the former hold and in which cases would the latter be easy to obtain from raw pixels?	I-Review	I-1	Review	20260
Could the authors elaborate on it?	I-Review	I-1	Review	20260
<sep> <sep> If I understand correctly, the trajectories (the input to InferNet) were generated with known, and (the 3 latent variables of InferNet).	B-Review	B-2	Review	20260
It is not clear to me why the authors don‚Äôt use these for the MSE loss used to train InferNet (rather than using the projectile motion equation).	I-Review	I-2	Review	20260
<sep> <sep> In my opinion, the introduction and related work sections do not reflect what is proposed in the paper.	B-Review	B-3	Review	20260
As an example, paragraph 2 of the introduction refers to use-cases where we would like to learn dynamics that govern certain motions directly from observations, whereas the proposed method uses extracted positions as input, and handcrafts the motion equation.	I-Review	I-3	Review	20260
The third paragraph of page 2 mentions agents failing to solve a game with Newtonian physics, whereas the method in this paper does not demonstrate empirically a way that this architecture could be used by an agent.	I-Review	I-3	Review	20260
<sep> <sep> - Is the ‚Äòprojectile motion equation‚Äô missing from Fig.2-right; is it used for inference?	B-Review	B-4	Review	20260
Is G from InferNet also input to RelateNet?	I-Review	I-4	Review	20260
<sep> <sep> In summary, in my opinion, the technical novelty of this paper is limited as it uses MLP mappings that in some sense aim at learning the inverse of the equation that generated the data.	B-Review	B-6	Review	20260
Moreover, after reading the paper the use-case of the proposed method is not clear to me and the writing is unclear (see examples above and below).	I-Review	I-5	Review	20260
<sep> <sep> ‚Äî Minor ‚Äî	B-Review	B-5	Review	20260
- The term ‚Äòin-game variables‚Äô is used in a few places and is explained later in the text (Pg.5).	I-Review	I-5	Review	20260
I think that It would be helpful if it is explained in more detail the first time it is mentioned.	I-Review	I-5	Review	20260
<sep> - I don‚Äôt understand the second sentence of the abstract.	I-Review	I-5	Review	20260
<sep> - Pg1: build a relationships -&gt; build relationships.	I-Review	I-5	Review	20260
<sep> - Pg2: I don‚Äôt understand what the authors mean by ‚Äòclone of Angry Birds.	I-Review	I-5	Review	20260
‚Äô	I-Review	I-5	Review	20260
- Pg3: is trained jointly or afterwards?	I-Review	I-5	Review	20260
<sep> - Pg4: was MSE the loss used for?	I-Review	I-5	Review	20260
<sep> - It would help adding sub-captions in Fig.6.	I-Review	I-5	Review	20260
<sep> <sep> We would like to thank the reviewer for their constructive comments and review.	O	O	Reply	20260
We would like to provide an answer to the questions raised in your review:	O	O	Reply	20260
<sep> ‚ÄúIt is not easy for me to understand the use-case of the proposed method.	O	O	Reply	20260
In which real-world scenarios we would have the exact motion equation, and why given that we know such an equation we would want to learn a mapping from the relative position to a trajectory‚Äù	O	O	Reply	20260
<sep> <sep> The use case of our method is the following: We know physics and we know the underlying physics formulas that apply when observing a physical action.	B-Reply	B-1	Reply	20260
What we don‚Äôt know is the required physics parameters of objects and the environment we observe, for example mass, friction, temperature, air pressure, air resistance, gravity, etc.	I-Reply	I-1	Reply	20260
So despite knowing the physics formulas that apply, we cannot predict consequences of actions.	I-Reply	I-1	Reply	20260
<sep> <sep> <sep> In the example we use in the paper, a playing agent has to predict the trajectory of the shot in a game that follows Newtonian Physics.	I-Reply	I-1	Reply	20260
The agent only has access to the images of the game and no access to the physics engine, that is, the agent knows the underlying physics formula of the trajectory, but does‚Äôt know the relevant physics parameters of the objects and the environment.	I-Reply	I-1	Reply	20260
Predicting a trajectory directly from observations in this case is a nontrivial task as it requires the agent to understand the relationship between the strength of a shot and it‚Äôs trajectory.	I-Reply	I-1	Reply	20260
While in the real world physics parameters like gravity are (roughly) known, in game worlds these can and do have arbitrary values.	I-Reply	I-1	Reply	20260
<sep> <sep> ‚ÄúIf I understand correctly, the trajectories (the input to InferNet) were generated with known G,V0, theta, and (the 3 latent variables of InferNet).	O	O	Reply	20260
It is not clear to me why the authors don‚Äôt use these for the MSE loss used to train InferNet (rather than using the projectile motion equation). ‚	O	O	Reply	20260
Äú	O	O	Reply	20260
<sep> <sep> The goal of our paper was to avoid using the known values and to test the ability of the network to discover such values from observations.	B-Reply	B-2	Reply	20260
As described above, the motivation for this approach is that typically these values are unknown when one has no direct access to the ‚Äúphysics engine‚Äù (as it is the case in the real world and in some games).	I-Reply	I-2	Reply	20260
<sep> <sep> <sep> ‚Äú- Is the ‚Äòprojectile motion equation‚Äô missing from Fig.2-right; is it used for inference?	O	O	Reply	20260
Is G from InferNet also input to RelateNet?‚Äù	O	O	Reply	20260
<sep> <sep> The goal of the RelateNet is to learn to predict the two values V0 and theta directly from the given in-game variables such as relative position of the bird.	B-Reply	B-4	Reply	20260
In order to train RelateNet we use the values V0 and theta that were predicted by InferNet from the observed trajectories.	I-Reply	I-4	Reply	20260
G predicted by InferNet is used as input to the RelateNet.	I-Reply	I-4	Reply	20260

This paper presents a method for predicting the trajectories of objects in video (or phone) games by learning the physical parameters underlying the movements.	O	O	Review	20260
To do so, the authors used some multi-layer perceptrons on the (x,y) trajectory in order to i) estimate the physical values of the equation (equation supposed to be known, here a parabolic trajectory); and then ii) predict the trajectories from new initial conditions.	O	O	Review	20260
<sep> <sep> General comment:	O	O	Review	20260
While the links between physics and machine learning is clearly interesting and trendy, I found the paper unclear, not well motivated and I think the work is not enough for a paper in ICLR.	B-Review	B-3	Review	20260
Yet, I think the authors did spend some time and this work might be suited for a workshop.	O	O	Review	20260
<sep> <sep> Positive aspects:	O	O	Review	20260
- the authors really tried to focus on games that are used today.	O	O	Review	20260
<sep> - the results are showing that they do learn the parameters they wanted, as the new trajectories are indeed working.	O	O	Review	20260
<sep> <sep> Remarks and questions:	O	O	Review	20260
- the writing of the paper is not enough to make it clear, and a lot of sentences are not readable.	B-Review	B-1	Review	20260
Starting at the second sentence of the abstract.	I-Review	I-1	Review	20260
Try to make small sentences, and add all the pronouns 'a', 'the', .... Avoid the too numerous 'and' and cut the sentences.	I-Review	I-1	Review	20260
<sep> - What is a shooting mechanism?	B-Review	B-2	Review	20260
Is it something scientifically defined?	I-Review	I-2	Review	20260
otherwise, explain better: the parabolic trajectory is I guess more explanatory of what you are doing.	I-Review	I-2	Review	20260
<sep> - What is the goal of your work?	B-Review	B-3	Review	20260
Estimating the parameters of an equation used in a game is not really interesting.. as we have to know the equation, it has to be simple, we have to extract the trajectory from the game... but there might be other related applications that could motivate this work.	I-Review	I-3	Review	20260
<sep> - Related work: I don't really see the novelty of your work.	B-Review	B-4	Review	20260
You are saying that the physical properties have to be learned from experience, but you are actually relying on a known equation, and just tuning the 3 parameters.	I-Review	I-4	Review	20260
Do games always follow the physical laws?	I-Review	I-4	Review	20260
From my knowledge, some games change the physical laws in order to be more pretty, ect.	I-Review	I-4	Review	20260
in that case, your method will not work?	I-Review	I-4	Review	20260
<sep> - More generally, can you explain the difference for you between physical laws and physical properties?	B-Review	B-5	Review	20260
<sep> - Explain what is 'MLP'; how many layers, what size, how did you defined it, ect.	B-Review	B-6	Review	20260
<sep> - in 3.1.1.	B-Review	B-7	Review	20260
you are spending quite a long time in explaining what an autoencoder is; I think you can go faster on this.	I-Review	I-7	Review	20260
<sep> - Why the RelateNet has 2 distinct MLPs while InferNet uses the same for inferring V0 and Theta?	B-Review	B-8	Review	20260
<sep> - How did you extract the trajectories, ect.	B-Review	B-9	Review	20260
from the games?	I-Review	I-9	Review	20260
<sep> - Figure 6: How come in the two last images, we see different starting points?	B-Review	B-10	Review	20260
<sep> - Table 1: can we have an idea of the errors in meters?	B-Review	B-11	Review	20260
and compared to the distance of the trajectory?	I-Review	I-11	Review	20260
<sep> <sep> Small remarks:	B-Review	B-12	Review	20260
- theta is not alpha.	I-Review	I-12	Review	20260
Please use a common notation.	I-Review	I-12	Review	20260
<sep> - Figure 5, 6.. : the legends are clearly not visible.	I-Review	I-12	Review	20260
they might not be useful, but in this case you have to spend time in changing the tick labels so that we can read them.	I-Review	I-12	Review	20260
<sep> - 'build a relationships': no 's'	I-Review	I-12	Review	20260
... a lot of  grammatical/ sentence problems	I-Review	I-12	Review	20260
<sep> <sep> We would like to thank the reviewer for their remarks and comments.	O	O	Reply	20260
We would like to provide an answer to the questions raised in your review:	O	O	Reply	20260
<sep> "- What is a shooting mechanism?	O	O	Reply	20260
Is it something scientifically defined?	O	O	Reply	20260
otherwise, explain better: the parabolic trajectory is I guess more explanatory of what you are doing."	O	O	Reply	20260
<sep> <sep> Shooting mechanism can be defined as any game object that launches another game object with some initial velocity and can be controlled by a player.	B-Reply	B-2	Reply	20260
<sep> <sep> ‚Äú- What is the goal of your work?	O	O	Reply	20260
Estimating the parameters of an equation used in a game is not really interesting.. as we have to know the equation, it has to be simple, we have to extract the trajectory from the game... but there might be other related applications that could motivate this work.	O	O	Reply	20260
‚Äù	O	O	Reply	20260
<sep> <sep> As described in the comment for reviewer #4, estimating the parameters despite knowing the equation is the essential task we face whenever we want to predict consequences of physical actions.	B-Reply	B-3	Reply	20260
The goal of our work is to learn to predict the trajectories of the shot given the observations.	I-Reply	I-3	Reply	20260
In order to achieve it, we have designed a network that learns physical properties from the observed trajectories without any insight on the values of these properties.	I-Reply	I-3	Reply	20260
In the concrete example we consider, such a module could then be combined with playing agents in order to play games that follow Newton‚Äôs physics and have a shooting mechanism that ‚Äúcreates‚Äù trajectories.	I-Reply	I-3	Reply	20260
<sep> <sep> "- Do games always follow the physical laws?	O	O	Reply	20260
From my knowledge, some games change the physical laws in order to be more pretty, ect.	O	O	Reply	20260
in that case, your method will not work?"	O	O	Reply	20260
<sep> <sep> In this work we are focusing on solving the trajectory prediction task in games that do follow Newton's laws of motion, the general solution for the cases where these laws do not apply is not a focus of this paper and is left to the future work.	B-Reply	B-4	Reply	20260
<sep> <sep> "- More generally, can you explain the difference for you between physical laws and physical properties?"	O	O	Reply	20260
<sep> <sep> Physical properties is something that can be measured by observation, physical law is something that was derived by scientific experiments and can be used to predict physical behavior if certain preconditions apply.	B-Reply	B-5	Reply	20260
<sep> <sep> "- Explain what is 'MLP'; how many layers, what size, how did you defined it, ect."	O	O	Reply	20260
<sep> <sep> 'MLP' or in another words multilayered perceptron is a feedforward artificial neural network.	B-Reply	B-6	Reply	20260
We provide the details on architecture of the used MLPs in Appendix.	I-Reply	I-6	Reply	20260
<sep> <sep> "- Why the RelateNet has 2 distinct MLPs while InferNet uses the same for inferring V0 and Theta?"	O	O	Reply	20260
<sep> <sep> By our experiments we have determined that using 2 distinct MLPs in RelateNet showed better results than using a single MLP as in InferNet.	B-Reply	B-8	Reply	20260
<sep> <sep> "- How did you extract the trajectories, ect.	O	O	Reply	20260
from the games?"	O	O	Reply	20260
<sep> <sep> The trajectories of objects were extracted directly from the physics engine of the game.	B-Reply	B-9	Reply	20260
In order to do so, we were tracking launched object throughout time starting from the moment in which the object was launched and until the moment in which object hits the ground.	I-Reply	I-9	Reply	20260
At each time step we were recording the position of a the launched object which resulted in a sequence of points.	I-Reply	I-9	Reply	20260
The resulted sequences were then padded with zeros or cut to the desired size.	I-Reply	I-9	Reply	20260
<sep> <sep> "- Figure 6: How come in the two last images, we see different starting points?"	O	O	Reply	20260
<sep> <sep> The goal of the Baseline Models 1 and 2 was to predict the trajectory of the launched object.	B-Reply	B-10	Reply	20260
The last two images on Figure 6 demonstrate the inability of the two baseline models to predict the correct position of the object on y-axis (when applied to the Basketball dataset with no further training) even at the first time step (starting point in the graph).	I-Reply	I-10	Reply	20260

The problem addressed by this paper is the estimation of trajectories of moving objects thrown / launched by a user, in particular in computer games like angry birds or basketball simulation games.	O	O	Review	20260
A deep neural network is trained on a small dataset of ~ 300 trajectories and estimates the underlying physical properties of the trajectory (initial position, direction and strength of initial force etc.).	O	O	Review	20260
A new variant of deep network is introduced, which is based on an encoder-decoder model, the decoder being a fully handcrafted module using known physics (projectile motion).	O	O	Review	20260
<sep> <sep> I have several objections, which can be summarized by the simplicity of the task (parabolic trajectories without any object/object or object/environment collisions / interactions), the interest of the task for the community (how does this generalize to other problems?),	O	O	Review	20260
and the writing and structuring of the paper.	O	O	Review	20260
I will detail these objections further in the rest of the review.	O	O	Review	20260
<sep> <sep> Learning physical interactions is a problem which has received considerable attention in the computer vision and ML communities.	B-Review	B-3	Review	20260
The problem is certainly interesting, but I think we should be clear on what kind of scientific knowledge we want to gain by studying a certain problem and by proposing solutions.	I-Review	I-3	Review	20260
The tasks studied by the community are mostly quite complex physical phenomena including multiple objects of different shapes and properties and which interact with each other.	I-Review	I-3	Review	20260
All these phenomena can be simulated with almost arbitrary precision with physics engines, and these engines are mostly also used for generating the data.	I-Review	I-3	Review	20260
In other words, the simulation itself is solved and is not the goal of this body of work.	I-Review	I-3	Review	20260
The goal is to learn differentiable models, which can be used as inductive bias in larger models targeting more general tasks in AI.	I-Review	I-3	Review	20260
<sep> <sep> Compared to this goal, the proposed goal is far too easy: learning projectile motion is very easy, as these trajectories can be described by simple functions with a small number of parameters, which also have a clear and interpretable meaning.	B-Review	B-1	Review	20260
The simplicity of the task is also further corroborated by the small number of samples used to estimate these parameters (in the order of 300).	I-Review	I-1	Review	20260
A further indication is the fact, that the decoder in the model is fully hardcoded.	I-Review	I-1	Review	20260
No noise modelling was even necessary, which further corroborates that a very simple problems is addressed.	I-Review	I-1	Review	20260
<sep> <sep> In order words, I am not really sure what kind of scientific problem is solved by this work, and how this knowledge can help us to solve other problems, harder problems.	I-Review	I-1	Review	20260
<sep> <sep> My second objection is with the written form of the paper.	B-Review	B-2	Review	20260
The paper is not well enough structured and written, many things are left unsaid.	I-Review	I-2	Review	20260
First of all, the problem has never been formally introduced, we don‚Äôt know exactly what needs to be estimated.	I-Review	I-2	Review	20260
What are the inputs, outputs?	I-Review	I-2	Review	20260
Is computer vision used anywhere?	I-Review	I-2	Review	20260
How are the positions of the objects determined if not with computer vision?	I-Review	I-2	Review	20260
How are the user forces gathered?	I-Review	I-2	Review	20260
What are ‚Äúin game variables‚Äù mentioned multiple times in the document?	I-Review	I-2	Review	20260
No notation has been introduced, no symbols have been introduced (or too late in the document).	I-Review	I-2	Review	20260
For instance, there is no notation for the latent space of the encoder-decoder model.	I-Review	I-2	Review	20260
<sep> <sep> The figures are not very helpful, as the labelling of the blocks and labels is very fuzzy.	B-Review	B-2	Review	20260
As an example, For InferNet, inputs and trajectories are ‚ÄúTrajectories‚Äù, so what is the difference?	I-Review	I-2	Review	20260
Of course we can guess that (inputs are measured trajectories, outputs are reconstructed trajectories), but we should not guess things when reading papers.	I-Review	I-2	Review	20260
<sep> <sep> The figure for encoder-decoder model is very confusing, as the different arrows have different functional meanings and we have no idea what they mean.	B-Review	B-2	Review	20260
The outputs of the encoder and the MLP both point to the latent space and at a first glance the reader might think that they are concatenated, which raises several questions.	I-Review	I-2	Review	20260
Reading the text, we infer that first a model is trained using on one of the arrows (the one coming from the encoder) and ignoring the other one, and then the MLP is learned to reconstruct the latent space using the other arrow (the one coming from the MLP), but this is absolutely impossible to understand looking at the figure, which does not make much sense.	I-Review	I-2	Review	20260
We can infer all this from the text around equations (1) to (3), which is itself quite fuzzy and difficult to understand, in spite of the simplicity of the underlying maths.	I-Review	I-2	Review	20260
<sep> <sep> The relationship of RelateNet and InferNet is not clear.	B-Review	B-2	Review	20260
While the task of InferNet is clear, the role of InferNet in the underlying problem is not clear and it has not been described how it interacts with RelateNet.	I-Review	I-2	Review	20260
<sep> <sep> It is unclear how the transfer between science birds and basketball has been performed and what exactly has been done there.	B-Review	B-2	Review	20260
<sep> <sep> As mentioned above, the role of ‚Äúin game variables‚Äù is unclear.	B-Review	B-2	Review	20260
What are those?	I-Review	I-2	Review	20260
I suggest to more clearly define their roles early in the document and use terms from well-defined fields like control (are they ‚Äúcontrol inputs‚Äù) or HCI (are they ‚Äúuser actions‚Äù?).	I-Review	I-2	Review	20260
<sep> <sep> In the evaluation section, we have baseline models BM1 and BM2, but they have never been introduced.	B-Review	B-2	Review	20260
We need to guess which of the models described in the paper correspond to these.	I-Review	I-2	Review	20260
<sep> <sep> The related work section is very short and mostly consists of an enumeration of references.	B-Review	B-2	Review	20260
The work should be properly described and related to the proposed work.	I-Review	I-2	Review	20260
How does the proposed work address topics which have not yet been solved by existing work?	I-Review	I-2	Review	20260
<sep> <sep> We would like to thank the reviewer for their review and comments.	B-Reply	B-2	Reply	20260
We have taken into account remarks on the figures and the structure of the paper and will fix them in our revision.	I-Reply	I-2	Reply	20260
<sep> <sep> <sep> ‚ÄúIn order words, I am not really sure what kind of scientific problem is solved by this work, and how this knowledge can help us to solve other problems, harder problems.	O	O	Reply	20260
‚Äù	O	O	Reply	20260
<sep> <sep> One of the goals of our paper was to design a network that would learn to predict the trajectory of a shot in games that follow Newton‚Äôs Physics when it has no direct access to the physics engine of the game.	B-Reply	B-1	Reply	20260
As an example task, we picked Science Birds - a clone of a popular game Angry Birds which requires player to shoot a bird from a slingshot.	I-Reply	I-1	Reply	20260
Predicting a trajectory directly from observations in this case is a non trivial task as it requires the agent to understand the relationship between the relative position of a bird and shot trajectory.	I-Reply	I-1	Reply	20260
Our method then can be combined with playing agents that would use trajectory prediction in making decisions.	I-Reply	I-1	Reply	20260
This is actually one of the problems agents face in the Angry Birds AI competition where they only get screenshots of the game but don‚Äôt have access to the physics engine and don‚Äôt know the physics parameters.	I-Reply	I-1	Reply	20260
<sep> <sep> <sep> Similar methods can be used for many other situations/problems where we know the physics equations that apply, but don‚Äôt know the required physics parameters of objects and the environment.	I-Reply	I-1	Reply	20260
As such, we believe that our work is important for solving these kinds of problems and also an important new approach.	I-Reply	I-1	Reply	20260
In our work we showed that rather than learning already known physics equations, we can learn the required physics parameters from the observations and use them successfully in predictions.	I-Reply	I-1	Reply	20260

This paper studies weight sharing in neural architecture search (NAS).	O	O	Review	483
It constructs a mini search space with 64 possible choices, and performs various comparisons and studies in an exhaustive way.	O	O	Review	483
Some of the observations are quite interesting, exploring the limitations of weight sharing.	O	O	Review	483
<sep> <sep> My biggest concern is the limited search space.	B-Review	B-1	Review	483
Unlike other NAS works that usually have search space size &gt; 10^10, this paper focuses on a very small search space (64 options in total).	I-Review	I-1	Review	483
Because the search space is so small, a small change in any search option might cause a big difference for the sampled model, which possibly lead to some of the instability observed in this paper (such as observation 3 in Section 3.2 and the implication "training a child model can easily perturb the rank of the previous mini-batch in section 4.1).	I-Review	I-1	Review	483
However, this might not be true if the search space is big, where changing a few search options may not affect the supernet significantly.	I-Review	I-1	Review	483
<sep> <sep> It would be great if the authors can perform similar study on a larger search space.	I-Review	I-1	Review	483
If evaluation for large search space is difficult, you may consider some pre-defined accuracy lookup tables (such as NAS-Bench-101: <a href="https://arxiv.org/abs/1902.09635)."	I-Review	I-1	Review	483
target="_blank" rel="nofollow">https://arxiv.org/abs/1902.09635).</a>	I-Review	I-1	Review	483
<sep> Thank you for your comments.	O	O	Reply	483
<sep> <sep> As far as I understand, your belief that our observations might not be true for larger search space is based on the hypothesis that a larger search space makes the hypernet robust and training a child model might not perturb the overall ranking by too much.	B-Reply	B-1	Reply	483
First of all, this is an educated guess that still requires further experiments or theoretical analysis.	I-Reply	I-1	Reply	483
Secondly, if larger search space were to be easier, it implies that weight sharing only works on large search space, but we found recently a paper submitted to ICLR (<a href="https://openreview.net/forum?id=SJx9ngStPH)" target="_blank" rel="nofollow">https://openreview.net/forum?id=SJx9ngStPH)</a> which has revealed the instability of weight sharing on large search space (Section 5.2).	I-Reply	I-1	Reply	483
<sep> <sep> We admit that our search space is limited and evaluation on a large search space is an experiment missing in our paper.	I-Reply	I-1	Reply	483
When developing this small search space, we follow a basic assumption is that smaller search space is easier to search, as intuitively, smaller search space is easier to optimize and very likely an easier problem for weight sharing.	I-Reply	I-1	Reply	483
If weight sharing doesn't even work on an easy problem, it doesn't make any sense it will work on a harder one.	I-Reply	I-1	Reply	483

First of all, I have to state that this is not my area of expertise.	O	O	Review	483
So, my review here is an educated guess.	O	O	Review	483
<sep> <sep> The paper is an empirical study that looks into the effect of weight sharing in neural network architecture search.	O	O	Review	483
The basic idea is that by sharing weights among multiple candidate architectures, the training process can be significantly improved.	O	O	Review	483
In the literature, there have been mixed results, either in favor of or against weight sharing.	O	O	Review	483
The question this paper aims to address is to determine if weight sharing is justifiable and to what extent.	O	O	Review	483
<sep> <sep> The primary subject investigated by the authors is to determine if the variance of the ranks generated by different runs of the algorithm are highly correlated with each other (e.g. using Kendall rank correlation score).	O	O	Review	483
Then, they compared such results with the ground truth (i.e. every child is trained independently).	O	O	Review	483
They found that the ranks generated by weight sharing are indeed highly correlated with each other, but there is much larger variance in the ranks when compared to the ground truth method.	O	O	Review	483
To understand why this is non-trivial: (1) on one hand, weight sharing speeds up the training process by providing an initial point close to a local minimum, but (2) the local minimum point may or may not  be good for the new architecture.	O	O	Review	483
Hence, one does not know apriori under what conditions would weight sharing be a good strategy.	O	O	Review	483
<sep> <sep> The authors also looked into variance of the rank within the same instance by examining how the rank changes with mini-batch epochs.	O	O	Review	483
They found that variance is large even within the same instance.	O	O	Review	483
<sep> <sep> My primary concern is that the paper is entirely empirical with little if any justification of the results.	B-Review	B-3	Review	483
In addition, it is based on a single architecture and a single dataset.	I-Review	I-3	Review	483
This would have been fine if the results were supported with explanation or theoretical justification.	I-Review	I-3	Review	483
Second, the ultimate goal is to improve the prediction accuracy, not the ranking accuracy.	I-Review	I-3	Review	483
These are not necessarily equivalent.	I-Review	I-3	Review	483
For instance, it is possible that the ranks have a high variance simply because many of the candidate architectures have nearly equivalent performance so the order within them becomes nearly random (and unimportant).	I-Review	I-3	Review	483
In fact, I think the results support this conclusion (see for example Figure 10).	I-Review	I-3	Review	483
Third, some of the highlighted observations are trivial.	I-Review	I-3	Review	483
For example, Observation 1, which states that "Two child models have (higher or lower) interference with each other when they share weights.	I-Review	I-3	Review	483
A child model‚Äôs validation accuracy highly depends on the child models it is jointly trained with."	I-Review	I-3	Review	483
I think this observation is trivial.	I-Review	I-3	Review	483
<sep> <sep> Some other comments:	O	O	Review	483
- I would appreciate it if the authors could explain briefly how "prefix sharing" works so that the paper is self-contained.	B-Review	B-1	Review	483
<sep> - The goal is to help improve the speed of neural architecture search.	B-Review	B-2	Review	483
The authors mention "hints for designing more efficient weight-sharing."	I-Review	I-2	Review	483
Please state those conclusions precisely and clearly.	I-Review	I-2	Review	483
I understand that the authors suggest similarity-based grouping.	I-Review	I-2	Review	483
So, please mention clearly what you recommend in the conclusion section.	I-Review	I-2	Review	483
<sep> <sep> <sep> ==========================	O	O	Review	483
#post rebuttal remarks	O	O	Review	483
<sep> Thanks for the response.	O	O	Review	483
Figure 10 was a typo from my end and I apologize for it.	O	O	Review	483
I actually meant figure 3.	O	O	Review	483
<sep> <sep> As I said in my review, having an empirical study is acceptable provided that it covers many datasets, not just a single one.	O	O	Review	483
Thank you for your detailed review.	O	O	Reply	483
<sep> <sep> Lack of theoretical foundation is actually an open problem in weight-sharing NAS.	B-Reply	B-3	Reply	483
This paper is an empirical study of weight sharing and it's not meant to be theoretical.	I-Reply	I-3	Reply	483
We've also included some explanation to phenomenons in our paper, but most of them are just hypothesis.	I-Reply	I-3	Reply	483
<sep> <sep> We don't agree that distinguishing performance-nearly-equivalent architectures is unimportant.	I-Reply	I-3	Reply	483
If there were to be many architectures sharing the "best accuracy", one could just do random search: they don't need all those fancy NAS algorithms.	I-Reply	I-3	Reply	483
It's true that we may not care about the overall rank, but only the top ones.	I-Reply	I-3	Reply	483
However, as shown Table 2, even the top ones have a very bad ranking of more than 10 in average: it's on average worse than 1/4 of the child models in search space.	I-Reply	I-3	Reply	483
In a large search space, it will become a candidate you will never try to train from scratch.	I-Reply	I-3	Reply	483
<sep> <sep> Also, I'm sure we don't have a Figure 10 in our paper.	I-Reply	I-3	Reply	483
<sep> <sep> This paper is supposed to inspire NAS researchers in future research, therefore we provide all these experiments and possible things to try.	I-Reply	I-3	Reply	483
We agree that writing a list in the conclusion section might be better.	I-Reply	I-3	Reply	483
<sep> <sep> We will elaborate the method of prefix sharing in our revision.	B-Reply	B-1	Reply	483

Many NAS methods rely on weight sharing.	O	O	Review	483
Notably in ENAS, a single weight tensor is used for all candidate operations each edge of a cell.	O	O	Review	483
In this paper, the authors take a small NAS search space (64 possible networks) and train each network separately to obtain their individual rankings.	O	O	Review	483
They then examine how this ranking correlates when  the same network is trained as part of a super-net with weight sharing, as in NAS algorithms.	O	O	Review	483
<sep> <sep> Given the prevalence of NAS algorithms, an examination of the potential pitfalls of weight sharing is very important and I commend the authors for that.	O	O	Review	483
There are a lack of typos and grammatical errors, which is nice too!	O	O	Review	483
<sep> <sep> I have two major issues with this paper however.	B-Review	B-3	Review	483
Firstly, the scope is limited; everything is based on looking at 64 convnets trained on CIFAR-10, this makes it tricky to make any broad statements about weight-sharing in NAS.	I-Review	I-3	Review	483
Secondly, the paper reads as a string of observations, and it is not clear what the takeaways are (it is hinted that one could reduce the search space for Figure 3, but this is not expanded on).	I-Review	I-3	Review	483
<sep> <sep> A few chronological comments:	O	O	Review	483
<sep> - "Population based algorithm () is another popular approach" ---&gt; "Population-based algorithms are another popular approach"	B-Review	B-4	Review	483
<sep> - "In this paper we try to answer" --&gt; A little confidence wouldn't hurt :)	B-Review	B-5	Review	483
<sep> - "Surprisingly".	B-Review	B-6	Review	483
I don't like the reader being told what is surprising/interesting etc.	I-Review	I-6	Review	483
but maybe that's just me.	I-Review	I-6	Review	483
<sep> <sep> - As mentioned above, more detail on search space pruning would be really nice.	B-Review	B-7	Review	483
For instance, are particular operations e.g. conv5x5 neglected.	I-Review	I-7	Review	483
<sep> <sep> - To clarify, when you have shared weights, but one candidate operation uses more parameters than another, do you just read off the weight tensor until you hit length?	B-Review	B-8	Review	483
e.g. if convA uses X params, and convB uses Y params, are the parameters for ConvA weight(1:X) and convB weight(1:Y)?	I-Review	I-8	Review	483
<sep> <sep> - Literature review is good.	O	O	Review	483
Figure 1 is nice and straightforward.	O	O	Review	483
<sep> <sep> - The figure and table captions could do with some more detail.	B-Review	B-9	Review	483
For instance, in Figure 2 the caption should contain the take-home point of the figure.	I-Review	I-9	Review	483
<sep> <sep> - "there are some statistic information" --&gt; "there is some statistical information"	B-Review	B-10	Review	483
<sep> - Figure 3 is nice.	B-Review	B-11	Review	483
It looks like you can't tell what's good, but you can tell what's bad.	I-Review	I-11	Review	483
A comparison of what architectures good v bad comprise off would be a nice addition.	I-Review	I-11	Review	483
<sep> <sep> - Figure 5 confused me, as there is a lot going on.	B-Review	B-12	Review	483
What do ordered and shuffled mean?	I-Review	I-12	Review	483
Is it just whether you are mixing up your minibatch selections? "	I-Review	I-12	Review	483
The curve has obvious periodicity with the length of 64 mini-batches i.e. the number of child model" doesn't make sense to me.	I-Review	I-12	Review	483
Could you elaborate?	I-Review	I-12	Review	483
<sep> <sep> - The accuracies in the plots look very low.	B-Review	B-13	Review	483
~80% for CIFAR-10 is really bad.	I-Review	I-13	Review	483
Am I missing something?	I-Review	I-13	Review	483
<sep> <sep> Pros	O	O	Review	483
------	O	O	Review	483
- Good topic with a few interesting observations	O	O	Review	483
- Relatively well-written	O	O	Review	483
<sep> Cons	O	O	Review	483
-------	O	O	Review	483
- Very limited scope.	B-Review	B-1	Review	483
Only 1 dataset and only 64 models	I-Review	I-1	Review	483
- The narrative is lacking, what are the key points that people using NAS should be aware of?	B-Review	B-2	Review	483
<sep> <sep> I recommend a weak rejection for this paper.	B-Review	B-3	Review	483
The topic is interesting, but I haven't been convinced through the limited scope of the experiments, or the arguments made what the real point is.	I-Review	I-3	Review	483
Should I stop weight sharing with NAS?	I-Review	I-3	Review	483
Should I prune my search space?	I-Review	I-3	Review	483
etc.	I-Review	I-3	Review	483
A few neat observations is nice, but there is a lack of cohesion.	I-Review	I-3	Review	483
Thank you for your detailed review.	O	O	Reply	483
The limited scope is selected based on the assumption that small search space is easier for NAS than a bigger one.	B-Reply	B-1	Reply	483
If you ever question about that, we could do some extra experiments to make that up.	I-Reply	I-1	Reply	483
However, I believe in this paper recently submitted (<a href="https://openreview.net/forum?id=SJx9ngStPH)," target="_blank" rel="nofollow">https://openreview.net/forum?id=SJx9ngStPH),</a> they have already discovered a similar instability in Section 5.2.	I-Reply	I-1	Reply	483
<sep> <sep> This paper is not meant to draw any conclusion, but to inspire future NAS researchers of things they could try.	B-Reply	B-2	Reply	483
I agree that we should make a list of everything we could think of in our conclusion section.	I-Reply	I-2	Reply	483
<sep> <sep> Here are chronological responses to your chronological comments.	O	O	Reply	483
<sep> <sep> - Thank you for pointing out all the grammar mistakes and literature issues.	B-Reply	B-10	Reply	483
Will fix in our revision.	I-Reply	I-10	Reply	483
<sep> <sep> - About search space, a basic idea we propose here is to reduce the search space, discarding the bottom-ranked child models and only train the top-half ones with weight sharing.	B-Reply	B-7	Reply	483
Do this over and over again until we find the top ones and train from scratch.	I-Reply	I-7	Reply	483
The method is only a proposal, requiring more experiments.	I-Reply	I-7	Reply	483
<sep> <sep> - Sharing conv weights follow the search space design of DARTS.	B-Reply	B-8	Reply	483
We don't share a superkernel among different types of convolutions.	I-Reply	I-8	Reply	483
<sep> <sep> - "what architectures good v bad comprise off" doesn't make sense to me.	B-Reply	B-11	Reply	483
Are you interested in what architectures they are from ground-truth-best to worst, i.e., the ground truth ranking of 64 architectures?	I-Reply	I-11	Reply	483
We will attach a table of all ground truth accuracies and ranks in Appendix.	I-Reply	I-11	Reply	483
<sep> <sep> - The meaning of "ordered" and "shuffled" corresponds to "different seeds" and "different orders (shuffle)" in Table 1.	B-Reply	B-12	Reply	483
Figure 5(a) shows a window of 128 mini-batches.	I-Reply	I-12	Reply	483
The pattern is repeated twice and the periodicity is 64 mini-batches.	I-Reply	I-12	Reply	483
Will make this clear in our revision.	I-Reply	I-12	Reply	483
<sep> <sep> - The low accuracies shown in this paper are due to the bad architecture design.	B-Reply	B-13	Reply	483
To simplify the network structure, we have removed the reduction cells.	I-Reply	I-13	Reply	483
We use fewer cells and fewer nodes than usual.	I-Reply	I-13	Reply	483
The networks are designed to be computationally efficient.	I-Reply	I-13	Reply	483

This paper aims at developing a better understanding of generalization error for increasingly prevalent non-convex learning problems.	O	O	Review	20236
For many such problems, the existing generalization bounds in the statistical learning theory literature are not very informative.	O	O	Review	20236
To address these issues, the paper explores algorithm-specific generalization bounds,  especially focusing on various types of noisy gradient methods.	O	O	Review	20236
<sep> <sep> The paper employs a framework that combines uniform stability and PAC-Bayesian theory to obtain generalization bound for the noisy gradient methods.	O	O	Review	20236
For gradient Langevin dynamic (GLD) and stochastic gradient Langevin dynamics (SGLD), using this Bayes-Stability framework, the paper obtains a generalization bound on the expected generalization error that scales with the expected empirical squared gradient norm.	O	O	Review	20236
As argued in the paper, this provides an improvement over the existing bounds in the literature.	O	O	Review	20236
Furthermore, this bound enables the treatment of the setting with noisy labels.	O	O	Review	20236
For this setting the expected empirical squared gradient norm along the optimization path is higher, leading to worse generalization bound.	O	O	Review	20236
<sep> <sep> The paper then extends their results to the setting where an regularization is added to the non-convex objective.	O	O	Review	20236
By using a new Log-Sobolev inequality for the parameter distribution at time t, the paper obtains new generalization bounds for continuous Langevin dynamic (CLD).	O	O	Review	20236
These bounds subsequently provide bounds for GLD as well.	O	O	Review	20236
<sep> <sep> The paper demonstrates the utility of their generalization bound via empirical evaluation on MNIST and CIFAR dataset.	O	O	Review	20236
The obtained generalization bounds are informative as they appear to capture the trend in the generalization error.	O	O	Review	20236
<sep> <sep> Overall, the paper is very well written with a clear comparison with the existing generalization bounds.	O	O	Review	20236
The results in the paper are interesting and novel.	B-Review	B-1	Review	20236
That said, the discussion in the introduction and abstract appears a bit misleading as it gives the impression that this is the first paper that combines the ideas from stability and PAC-Bayesian theory to obtain generalization bounds.	I-Review	I-1	Review	20236
This is not the case, e.g. see [1].	I-Review	I-1	Review	20236
<sep> As noted by the authors, some of the bounds obtained in this paper share similarities with one of the bounds in Mou et al  as all these bounds contain the expected empirical squared gradient norm.	B-Review	B-2	Review	20236
The bound in Mou et al holds with high probability and decays as, whereas the bounds in this paper are on expected generalization error and decay as.	I-Review	I-2	Review	20236
Could authors comment on extending their results to hold with high probability and how it would affect their bounds?	I-Review	I-2	Review	20236
<sep> <sep> [1] Rivasplata et al PAC-Bayes bounds for stable algorithms with instance-dependent priors.	O	O	Review	20236
<sep> <sep> <sep> ----------------------- Post author response -------------	O	O	Review	20236
<sep> Thank you for addressing my comments.	O	O	Review	20236
I have decided to keep my original score unchanged.	O	O	Review	20236
Thanks for your careful review and insightful comments!	O	O	Reply	20236
<sep> <sep> Regarding high-probability bounds, we note that our proof of Theorem 11 can be adapted to recover the previous bound of in (Mou et al 2018, Theorem 1), with the expected squared gradient norm term relaxed to, using the uniform stability framework.	B-Reply	B-2	Reply	20236
Then, applying the recent results of [Feldman and Vondrak, 2019, Theorem 1] gives a generalization error bound of that holds with high probability. (	I-Reply	I-2	Reply	20236
Here hides some polylog factors.)	I-Reply	I-2	Reply	20236
Since is typically at least linear in n, this means that the additional term will not be dominating.	I-Reply	I-2	Reply	20236
<sep> <sep> On the other hand, for our new bound, which is derived from Bayes-Stability instead of uniform stability, it remains unknown whether it can be translated into a high-probability bound following a similar approach.	I-Reply	I-2	Reply	20236
We believe that it is an interesting open problem to prove a similar high-probability bound (with a small overhead) for the Bayes-Stability framework.	I-Reply	I-2	Reply	20236
<sep> <sep> We will include the above discussion into the next version.	I-Reply	I-2	Reply	20236
<sep> <sep> Indeed, [Rivasplata et al] also combines ideas from PAC-Bayes and stability.	B-Reply	B-1	Reply	20236
While their stability is actually the hypothesis stability measured by the distance on the hypothesis space.	I-Reply	I-1	Reply	20236
And their work stduies the case when the returned hypothesis (model parameter) is randomized by a Gaussian perturbation (i.e., the posterior), which is different from our work.	I-Reply	I-1	Reply	20236
Thanks for pointing this out.	I-Reply	I-1	Reply	20236
In the next version, we will discuss their work and modify our descriptions in the introduction and abstract.	I-Reply	I-1	Reply	20236
<sep> <sep> -------------------------------------	O	O	Reply	20236
Reference	O	O	Reply	20236
<sep> PAC-Bayes bounds for stable algorithms with instance-dependent priors.	O	O	Reply	20236
Rivasplata et al	O	O	Reply	20236
<sep> High probability generalization bounds for uniformly stable algorithms with nearly optimal rate.	O	O	Reply	20236
Vitaly Feldman and Jan Vondrak.	O	O	Reply	20236
<sep> <sep> Sharper bounds for uniformly stable algorithms.	O	O	Reply	20236
Bousquet et al	O	O	Reply	20236
<sep> Generalization bounds for uniformly stable algorithms.	O	O	Reply	20236
Feldman et al	O	O	Reply	20236

In this paper, the authors provide new generalization analysis of (stochastic) gradient langevin dynamics in a nonconvex learning setting.	O	O	Review	20236
The results are largely based on and improves the analysis in Mou et al (2018).	O	O	Review	20236
In more details,  Theorem 11 improves the corresponding generalization bound in Mou et al (2018) by replacing the uniform Lipschitz constant by the expected empirical gradient norm, which can be smaller than the Lipschitz constant.	O	O	Review	20236
The authors also argue this can distinguish normal data from randomly labelled data with experiments.	O	O	Review	20236
The authors further studied the setting with an l_2 regularizer and derived improved result applicable to the case with infinite number of iterations, in which case the results in Mou et al (2018) can diverge.	O	O	Review	20236
These results are derived by a new bayes-stability method.	O	O	Review	20236
<sep> <sep> A drawback is that the results are only applicable to gradient methods in Section 4, i.e., using all examples in the gradient calculation.	B-Review	B-1	Review	20236
It would be interesting to see how the generalization bound would be for the stochastic counterparts.	I-Review	I-1	Review	20236
<sep> <sep> The authors assume \lambda&gt;1/2 in deriving (8).	B-Review	B-2	Review	20236
In practice, the regularization parameter should be set to be small enough to achieve a small test error.	I-Review	I-2	Review	20236
Therefore, eq (8) may not be quite interesting.	I-Review	I-2	Review	20236
<sep> <sep> ----------------------	O	O	Review	20236
After rebuttal:	O	O	Review	20236
<sep> I have read the authors' response.	O	O	Review	20236
I would like to keep my original score.	O	O	Review	20236
Thanks for your careful review and insightful comments.	O	O	Reply	20236
<sep> Indeed, the analysis can be extended to stochastic gradient (at the cost of an extra additive term) and the constant in the condition can be relaxed to any small constant by slightly changing the proof (for ease of calculation and convenience, we chose the constant in the original submission).	O	O	Reply	20236
Now, we explain the details.	O	O	Reply	20236
<sep> <sep> 1.Extending Theorem 15 to stochastic gradient: The key step is to apply Lemma 36 in Appendix B.3.	B-Reply	B-1	Reply	20236
By Lemma 36, we have, where is the constant in the 4th condition of Assumption 35.	I-Reply	I-1	Reply	20236
In the full gradient case, the 4th condition of Assumption 35 holds with.	I-Reply	I-1	Reply	20236
In the stochastic gradient case, it holds with.	I-Reply	I-1	Reply	20236
Hence, we need an extra additive term in the generalization bound (eq(8)), when applying to stochastic gradient settings.	I-Reply	I-1	Reply	20236
Here a batch of data are i.i.d.	I-Reply	I-1	Reply	20236
drawn from full dataset.	I-Reply	I-1	Reply	20236
Note that when batch size becomes larger, the extra term vanishes, and it matches the full gradient case bound (eq(8)).	I-Reply	I-1	Reply	20236
<sep> <sep> 2.Relax the condition: Thanks for you to point it out!	B-Reply	B-2	Reply	20236
Here we only need to slightly modify our original proof of  Theorem 15.	I-Reply	I-2	Reply	20236
In particular, we show that could be an arbitrary small positive number.	I-Reply	I-2	Reply	20236
Note that in the original proof of Theorem 15, is only used for satisfying the 2nd condition of Assumption 35 (hold with,, and m is required to be greater than 0 in this assumption, thus we set in our original proof).	I-Reply	I-2	Reply	20236
Note that the 2nd condition also holds with,, where could be any positive real number.	I-Reply	I-2	Reply	20236
Thus we only need to replace the statement "Assumption 35 holds with..." in page 26 with "Assumption 35 holds with" and change the upper bound of learning rate in Theorem 15 from to.	I-Reply	I-2	Reply	20236

This paper studies the generalization error bounds of stochastic gradient Langevin dynamics.	O	O	Review	20236
The convexity of the loss function is not assumed.	O	O	Review	20236
The author proposed "Bayes-stability" to derive generalization bound while taking the randomness of the algorithm into account.	O	O	Review	20236
The generalization bound proposed in this paper applies to some existing problem setups.	O	O	Review	20236
Also, the authors proposed the generalization bound of the continuous Langevin dynamics.	O	O	Review	20236
<sep> <sep> This is an interesting paper.	O	O	Review	20236
Overall, the readability is high.	O	O	Review	20236
The Bayes-stability is a significant contribution of this paper, and the theoretical analysis of the SGLD with non-Gaussian noise distribution will have a practical impact.	O	O	Review	20236
<sep> <sep> Some comments below:	O	O	Review	20236
- What is the function f of f(w,0)=0 above the equation (5)?	B-Review	B-1	Review	20236
Besides, the role of zero data point, i.e., f(w,0)=0, was not very clear.	I-Review	I-1	Review	20236
<sep> - In the numerical results (b) and (c) of Figure 1, the scale in the y-axis was very different.	B-Review	B-2	Review	20236
What made the generalization bound so loose?	I-Review	I-2	Review	20236
<sep> - In this paper, the developed theory was a general-purpose methodology.	B-Review	B-3	Review	20236
For deep neural networks, however, is there a meaningful insight obtained from the method developed in this paper?	I-Review	I-3	Review	20236
<sep> <sep> Thanks for your careful review and insightful comments.	O	O	Reply	20236
<sep> <sep> 1."What is the function of": Sorry for the typo.	B-Reply	B-1	Reply	20236
should be capital.	I-Reply	I-1	Reply	20236
The zero data point is a synthetic data point (just a symbol).	I-Reply	I-1	Reply	20236
It is defined as a zero constant function (i.e., for all).	I-Reply	I-1	Reply	20236
Note that we don't need to care about what the zero data point look like, because the only thing we use is its objective function's gradient (which is also zero) in our analysis.	I-Reply	I-1	Reply	20236
The zero data point is constructed for the convenience of defining the prior distribution.	I-Reply	I-1	Reply	20236

This paper presents a system to map natural language descriptions of scenes containing spatial relations to 3D visualizations of the corresponsing scene.	O	O	Review	699
The authors collect a dataset of different scenes containing objects of varying shapes and colors, along with several descriptions from different viewpoints.	O	O	Review	699
They train a model based on the Generative Query Network, to generate scenes conditioned on multiple text descriptions as input, along with associated camera angles.	O	O	Review	699
Empirical results using human evaluators demonstrate better performance compared to baselines and the authors perform a good analysis of the model, showing that it learns to ground the meaning of spatial words robustly.	O	O	Review	699
<sep> <sep> Pros:	O	O	Review	699
1.	O	O	Review	699
Well-executed paper, with convincing empirical results on the newly collected dataset.	O	O	Review	699
<sep> 2.	O	O	Review	699
Nice analysis to demonstrate that the model indeed learns good semantic representations for spatial language.	O	O	Review	699
<sep> <sep> Cons:	O	O	Review	699
1.	O	O	Review	699
The positioning of this paper with respect to recent work is disappointing.	B-Review	B-1	Review	699
In both the Introduction and Related Work sections, the authors talk about dated models for spatial reasoning in language (pre-2012).	I-Review	I-1	Review	699
There have been several pieces of work that have looked at learning multimodal representations for spatial reasoning.	I-Review	I-1	Review	699
These are a few examples:	I-Review	I-1	Review	699
a) Misra, Dipendra, John Langford, and Yoav Artzi. "	I-Review	I-1	Review	699
Mapping Instructions and Visual Observations to Actions with Reinforcement Learning."	I-Review	I-1	Review	699
Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing.	I-Review	I-1	Review	699
2017.	I-Review	I-1	Review	699
<sep> b) Michael Janner, Karthik Narasimhan, and Regina Barzilay. "	I-Review	I-1	Review	699
Representation Learning for Grounded Spatial Reasoning."	I-Review	I-1	Review	699
Transactions of the Association of Computational Linguistics 6 (2018): 49-61.	I-Review	I-1	Review	699
<sep> c) Paul, Rohan, et al "Grounding abstract spatial concepts for language interaction with robots."	I-Review	I-1	Review	699
Proceedings of the 26th International Joint Conference on Artificial Intelligence.	I-Review	I-1	Review	699
AAAI Press, 2017.	I-Review	I-1	Review	699
<sep> d) Ankit Goyal, Jian Wang, Jia Deng.	I-Review	I-1	Review	699
Think Visually: Question Answering through Virtual Imagery.	I-Review	I-1	Review	699
Annual Meeting of the Association for Computational Linguistics (ACL), 2018	I-Review	I-1	Review	699
<sep> Even though Gershman & Tenenbaum (2015) demonstrate weaknesses of a specific model, some of the above papers demonstrate models that can understand things like "A is in front of B" = "B is behind A".	I-Review	I-1	Review	699
A discussion of how this paper relates to some of this prior work, and an empirical comparison (if possible) would be good to have.	I-Review	I-1	Review	699
<sep> <sep> 2.	O	O	Review	699
The introduction reads a bit vague.	B-Review	B-2	Review	699
It would help to clearly state the task considered in this paper upfront i.e. generating 3D scenes from text descriptions at various viewpoints.	I-Review	I-2	Review	699
In the current form, it is hard to understand the task till one arrives at Section 3.	I-Review	I-2	Review	699
<sep> <sep> Other comments:	O	O	Review	699
1.	O	O	Review	699
What is the difference between the bar graphs of Figures 5 and 6?	B-Review	B-3	Review	699
Is the one on Figure 5 generated using the sentences (and their transforms) from Gershman & Tenenbaum?	I-Review	I-3	Review	699
If so, how do you handle unseen words that are not present in your training data?	I-Review	I-3	Review	699
<sep> 2.	O	O	Review	699
Would be helpful to clearly explain what the red and black arrows represent in Figure 7.	B-Review	B-4	Review	699
<sep> 3.	O	O	Review	699
How does the model handle noisy input text i.e. if the object descriptions (shape/color) are off or if some of the input text is incorrect (say a small fraction of the different viewpoints)?	B-Review	B-5	Review	699
<sep> <sep> ------	O	O	Review	699
Edit:	O	O	Review	699
Thank you for the author response.	O	O	Review	699
Even if you consider the story to be the same across literature (which in this case is not, since the more recent models handle spatial relations that the previous ones failed on), it's still worth doing due diligence to the recent work, especially so that the reader gets a better sense of how to position your work amongst these.	O	O	Review	699
Thank you for the thorough review and insightful comments.	O	O	Reply	699
To address each comment individually:	O	O	Reply	699
1.	O	O	Reply	699
Thank you for suggesting additional literature to consider.	B-Reply	B-1	Reply	699
We have updated the paper to incorporate more of this more recent work and have clarified the connection to our work.	I-Reply	I-1	Reply	699
While we acknowledge that some of those papers are worth discussing in the context of our work, the story remains unchanged, as these more recent papers ended up using the same simplifications or short-cuts when considering spatial relations that we already discussed in relation to earlier publications: spatial relations are either treated as absolute, well-defined metrics in discrete (block world) spaces, or in the continuous case of the robotics work, the complexity of real world data and relations is simplified through manually defined mappings onto symbolic, abstract factor graphs, which again then simplifies the aspect of spatial relations that we are focused on learning here.	I-Reply	I-1	Reply	699
<sep> 2.	O	O	Reply	699
We have added a section to the introduction to better introduce the task.	B-Reply	B-2	Reply	699
<sep> <sep> Comments:	O	O	Reply	699
1.	O	O	Reply	699
Figure 5 compares the similarities for a single sentence as encoded by the encoder.	B-Reply	B-3	Reply	699
Figure 6 on the other hand compares the similarity for the scene-level representation, after the aggregation step.	I-Reply	I-3	Reply	699
We were interested in studying the representations at the two stages, as the representation studied in the first is more directly comparable to classic NLP models, while the second integrates information from multiple perspectives.	I-Reply	I-3	Reply	699
This allows us to show that the spatial invariances in language are detected already at the encoder level, and are not due to the aggregation.	I-Reply	I-3	Reply	699
<sep> 2.	O	O	Reply	699
We have clarified this in the caption: black is the camera angle fed to the encoder to reconstruct, while red is the target camera angle.	B-Reply	B-4	Reply	699
<sep> 3.	O	O	Reply	699
This is a great question!	B-Reply	B-5	Reply	699
In fact this was the question we sought to address by collecting the natural language dataset, and we have observed that many human annotations are unusually written or employ rare words.	I-Reply	I-5	Reply	699
We can see that in spite of variation in specific descriptions, the integration over different captions confers extra robustness to the model and can still generate consistent scenes for this natural language setup, as evidenced by figure 3.	I-Reply	I-5	Reply	699

The main contributions of the work are the new datasets and the overall integration of previous modeling tools in such a way that the final architecture is able to encode semantic spatial relations from textual descriptions.	O	O	Review	699
This is demonstrated by an implementation that, given textual descriptions, is able to render images from novel viewpoints.	O	O	Review	699
In terms of these two contributions, as I explain below, I believe there is space to improve the datasets and the paper needs further analysis/comments about the merits of the proposed approach.	O	O	Review	699
So my current overall rating is below acceptance level.	O	O	Review	699
<sep> <sep> In terms of data, authors provide 2 new datasets: i) a large datasets (10M) with synthetic examples (images and descriptions) and ii) a small dataset (6k) with human textual descriptions corresponding to synthetic images.	O	O	Review	699
As the main evaluation method of the paper, the author include direct human evaluation of the resulting renderings (3 level qualitative evaluation: perfect-match/partial-match/no-match).	O	O	Review	699
I agree that, for this application, human evaluation is more adequate than comparing a pixel-level output with respect to a gold image.	B-Review	B-1	Review	699
In this sense, it is surprising that for the synthetic dataset the perfect match score of human evaluation for ground truth data is only 66%.	I-Review	I-1	Review	699
It will be good to increase this number providing a cleaning dataset.	I-Review	I-1	Review	699
<sep> <sep> Related to the previous comment, it will be good to provide a deeper analysis about the loss function used to train the model.	B-Review	B-2	Review	699
<sep> In terms of the input data, it is not clear how the authors decide about the 10 views for each scene.	B-Review	B-3	Review	699
<sep> <sep> In terms of the final model, if I understood correctly, the paper does not claim any contribution, they use a model presented in a previous work (actually information about the model is mostly included as a supplemental material).	B-Review	B-4	Review	699
If there are relevant contributions in terms of model integration and/or training scheme, it will be good to stress this in the text.	I-Review	I-4	Review	699
<sep> <sep> Writing is correct, however, authors incorporate important details about the dataset generation process as well as the underlying model in the supplemental material.	B-Review	B-5	Review	699
Given that there is a page limit, I believe the relevant parts of the paper should be self-contain.	I-Review	I-5	Review	699
Thank you for the thorough review and insightful comments.	O	O	Reply	699
<sep> <sep> > ‚ÄòIn this sense, it is surprising that for the synthetic dataset the perfect match score of human evaluation for ground truth data is only 66%.	O	O	Reply	699
It will be good to increase this number providing a cleaning dataset.	O	O	Reply	699
‚Äô For the synthetic dataset, the noise added by certain objects missing from the captions does not degrade the performance of the model - the model is *only* fed captions as input which means it can integrate the information of multiple captions to create a reconstruction of the scene, and it only reconstructs image pixels, which means it never sees that picture‚Äôs caption.	B-Reply	B-1	Reply	699
Therefore the imperfect match between pixels and text is an issue that only arises at [human] evaluation time.	I-Reply	I-1	Reply	699
Given the cost of cleaning up these captions, we believe the most practical course of action was to collect human evaluations with this mapping and keeping in mind that the gold truth sets an upper bound.	I-Reply	I-1	Reply	699
<sep> <sep> > ‚Äòdeeper analysis about the loss function used to train the model.	O	O	Reply	699
‚Äô We use the loss function from previous work by Eslami et al (2018)--.	B-Reply	B-2	Reply	699
We have added more details to the model section in the main text and also provide a detailed description in Appendix section A.2.	I-Reply	I-2	Reply	699
<sep> <sep> > ‚ÄòIn terms of the input data, it is not clear how the authors decide about the 10 views for each scene.	O	O	Reply	699
‚Äô For non-language related hyperparameters, we followed the choices in Eslami et al 2018.	B-Reply	B-3	Reply	699
Optimizing this hyperparameter choice is an interesting avenue to explore however we felt it was outside of the scope of this work.	I-Reply	I-3	Reply	699
<sep> <sep> > ‚ÄòIf there are relevant contributions in terms of model integration and/or training scheme, it will be good to stress this in the text.	O	O	Reply	699
‚Äô  We have updated the text to explain the novel aspects of the model, which is the integration of language inputs, as well as dataset generation as much as possible.	B-Reply	B-4	Reply	699
In the appendix you can also find a detailed description of the model setup, hyperparameters, and dataset generation which did not fit into the main text.	I-Reply	I-4	Reply	699

The authors present a large synthetic dataset for 3D scenes with templated descriptions.	O	O	Review	699
They then use the model of Eslami 2018 to this new domain.	O	O	Review	699
The previous work appears to already introduce all the necessary mechanisms for 3D generalization from multiple viewpoints, though this work embeds language instead of a scene in the process.	O	O	Review	699
Minor note: A bit more discussion on this distinction would be appreciated.	B-Review	B-1	Review	699
Also, it appears that the previous work includes many of the rendered scenes also present here, so the primary focus of this paper is on the use of a language encoder (not necessarily a trivial extension).	I-Review	I-1	Review	699
<sep> <sep> The model appears to perform well with synthetic data though very poorly with natural sentences.	O	O	Review	699
This may be in part due to the very small dataset size.	O	O	Review	699
It would be helpful to know how much of the performance gap is due to scaling issues (10M vs 5.6K) versus OOVs, new syntactic constructions, etc.	B-Review	B-2	Review	699
In particular, the results have ~two deltas of interest (NL vs SYN) and the gap in the upper bound from 0.66 to 0.91.	I-Review	I-2	Review	699
What do new models need to be able to handle to close these gaps?	I-Review	I-2	Review	699
<sep> <sep> Regarding the upper bound, there is some discussion that annotators might have had a strict definition of a perfect match.	O	O	Review	699
Were annotators asked about this?	B-Review	B-3	Review	699
The current examples (B.2), as the authors note, are more indicative of failings with the synthetic language than the human annotators.	I-Review	I-3	Review	699
This may again be motivation for collecting more natural language which would resolve some of the ambiguity and pragmatics of the synthetic dataset.	I-Review	I-3	Review	699
<sep> <sep> It would also be helpful to have some ablations included in this work.	B-Review	B-4	Review	699
The most obvious being the role of (number of scene perspectives).	I-Review	I-4	Review	699
How crucial is it that the model has access to 9 of 10 perspectives?	I-Review	I-4	Review	699
One would hope that given the limited set of objects and colors, the model would perform well with far fewer examples per scene, learning to generalize across examples.	O	O	Review	699
<sep> <sep> Since the primary contributions of the paper are a language dataset and a language encoder for the existing model of Eslami 2018, those should be discussed and ablated in the paper rather than relegated to the appendix.	B-Review	B-5	Review	699
<sep> <sep> Minor note:  the related work mentions grounding graphs which are core to work from Tellex and Roy, but omits existing fully neural end-to-end models in grounding (e.g. referring expressions work).	B-Review	B-6	Review	699
<sep> <sep> Thank you for the thorough review and insightful comments.	O	O	Reply	699
To address each comment individually:	O	O	Reply	699
<sep> > ‚ÄòA bit more discussion on this distinction would be appreciated.	O	O	Reply	699
Also, it appears that the previous work includes many of the rendered scenes also present here, so the primary focus of this paper is on the use of a language encoder (not necessarily a trivial extension).‚Äô Thank you for this suggestion.	B-Reply	B-1	Reply	699
We have modified the text to stress which aspects of this work are novel.	I-Reply	I-1	Reply	699
When it comes to the model aspect of the paper, the use of a language encoder is the main modification.	I-Reply	I-1	Reply	699
However, the primary focus of our paper is the analysis of the representations the model learns.	I-Reply	I-1	Reply	699
<sep> <sep> > ‚ÄòIt would be helpful to know how much of the performance gap is due to scaling issues (10M vs 5.6K) versus OOVs, new syntactic constructions, etc.	O	O	Reply	699
In particular, the results have ~two deltas of interest (NL vs SYN) and the gap in the upper bound from 0.66 to 0.91.	O	O	Reply	699
What do new models need to be able to handle to close these gaps?‚Äô Indeed the main obstacle with natural language is the small size of the dataset, which we can see on improvement from SLIM (NL) to SLIM (NL+SYN) in Figure 4, where we used additional synthetic data.	B-Reply	B-2	Reply	699
Investigating the further improvements additional natural language data might have would require further data collection which is costly, however, collecting a larger NL dataset or generating richer synthetic language would likely contribute towards closing the gap.	I-Reply	I-2	Reply	699
The gap in the upper bound (0.66 to 0.91) is an artifact of the task, and matching these numbers would mean the model has reached the human performance in interpreting the input descriptions.	I-Reply	I-2	Reply	699
<sep> > ‚ÄòWere annotators asked about this?	O	O	Reply	699
The current examples (B.2), as the authors note, are more indicative of failings with the synthetic language than the human annotators.	O	O	Reply	699
This may again be motivation for collecting more natural language which would resolve some of the ambiguity and pragmatics of the synthetic dataset.	O	O	Reply	699
‚Äò For the synthetic dataset, the noise added by certain objects missing from the captions does not degrade the performance of the model - the model is *only* fed captions as input which means it can integrate the information of multiple captions to create a reconstruction of the scene, and it only reconstructs image pixels, which means it never sees that picture‚Äôs caption.	B-Reply	B-3	Reply	699
Therefore the imperfect match between pixels and text is an issue that only arises at [human] evaluation time.	I-Reply	I-3	Reply	699
Given the cost of cleaning up these captions, we believe the most practical course of action was to collect human evaluations with this mapping and keeping in mind that the gold truth sets an upper bound.	I-Reply	I-3	Reply	699
<sep> <sep> > ‚ÄòIt would also be helpful to have some ablations included in this work.	O	O	Reply	699
The most obvious being the role of (number of scene perspectives).	O	O	Reply	699
How crucial is it that the model has access to 9 of 10 perspectives?‚Äô For non-language related hyperparameters, we followed the choices in Eslami et al 2018.	B-Reply	B-4	Reply	699
We choose to train by providing 9 input captions, but at test time we can control how many views of the scene the model gets or additionally sample them only from a restricted view of the room.	I-Reply	I-4	Reply	699
In figure 7 you can find the results of that investigation where in the top row we show the output of the model when it has access to only a single view of the scene, and bottom row where it has access to multiple views of the scene, but from a restricted set of angles.	I-Reply	I-4	Reply	699
We hope this analysis resolves your concerns but are happy to hear more specific suggestions as to further investigation.	I-Reply	I-4	Reply	699
<sep> <sep> > ‚ÄòSince the primary contributions of the paper are a language dataset and a language encoder for the existing model of Eslami 2018, those should be discussed and ablated in the paper rather than relegated to the appendix.	O	O	Reply	699
‚Äô Due to the page limitation we have provided a summary of the model changes and a description of the dataset, as the main focus of the current work is the representation analysis.	B-Reply	B-5	Reply	699
However we understand we could have provided more detail in the main text.	I-Reply	I-5	Reply	699
We have updated the text to describe the novel aspects of the model as well as dataset generation as much as possible.	I-Reply	I-5	Reply	699
If there is any concrete information you feel is missing in the main text which would improve the text we would be very happy to hear!	I-Reply	I-5	Reply	699
<sep> <sep> > ‚ÄòMinor note:  the related work mentions grounding graphs which are core to work from Tellex and Roy, but omits existing fully neural end-to-end models in grounding (e.g. referring expressions work).‚Äô Thank you for suggesting to include that line of work in our related works discussion.	B-Reply	B-6	Reply	699
We have made appropriate amendments to note the referring expressions literature and how this relates to our work.	I-Reply	I-6	Reply	699

<sep> The paper introduces a new encoding for cell structures to improve efficiency of neural architecture search methods.	O	O	Review	699
<sep> As a second contribution the paper proposes Bayesian optimization with an ensemble of neural networks as probabilistic model for the objective function.	O	O	Review	699
<sep> Both contributions combined show superior performance on the Nasbench101 benchmark as well as competitive performance on the DARTS search space.	O	O	Review	699
<sep> <sep> While the paper identifies an important problem - encoding of architectures - I do not think the paper is ready for acceptance.	O	O	Review	699
<sep> <sep> About the encodings:	O	O	Review	699
<sep> First, using different encodings to enable better architecture search has been investigated by others before.	B-Review	B-1	Review	699
<sep> For example, Ying et al also provided different encodings of the adjacency matrix for Nasbench101 besides the used binary encoding and it seems that different methods work well with different encodings.	I-Review	I-1	Review	699
<sep> Also in the work by Kandasamy et al they presented an encoding for architecture, such that Bayesian optimization can be applied.	I-Review	I-1	Review	699
<sep> <sep> Second, the encoding described in the paper lacks some intuition.	B-Review	B-1	Review	699
<sep> <sep> - How does enumerating all paths and encoding them as a binary vector convey more information than just using the adjacency matrix?	I-Review	I-1	Review	699
<sep> <sep> - Lead isomorphic graphs, which for example occur in Nasbench101, to the same encoding?	I-Review	I-1	Review	699
<sep> <sep> - It seems somewhat counter intuitive to use a large binary vector (more than 18000 dimensional vector for the DARTS space) as encoding for Bayesian optimization which is known to struggle with high dimensional input spaces.	I-Review	I-1	Review	699
<sep> <sep> <sep> About the Bayesian optimization strategy:	O	O	Review	699
<sep> The proposed probabilistic model for Bayesian optimization seems straight forward and simple.	B-Review	B-2	Review	699
Also here, previous work (Snoek et al, Springenberg et al Perrone et al)  already proposed to use neural networks and ,in order to be more convincing, the paper should include a comparison to these methods.	I-Review	I-2	Review	699
<sep> Furthermore, the paper should clarify how the diversity in the neural network ensemble is enforced.	B-Review	B-3	Review	699
Are the neural networks trained with different random initialization?	I-Review	I-3	Review	699
How does it compare to the method proposed by Lakshminarayanan et al which showed better performance for neural network ensembles based only on different random initialization?	I-Review	I-3	Review	699
<sep> <sep> <sep> Minor comments:	O	O	Review	699
<sep> <sep> - In the Nasbench101 paper other Bayesian optimization strategies (e.g SMAC, BOHB, TPE) showed strong performance.	B-Review	B-4	Review	699
The results would be more convincing if these methods are included in the comparison.	I-Review	I-4	Review	699
<sep> <sep> - Following the empirical protocol by Ying et al the results would be easier to parse if the Figure 3  could report the log test regret on the y-axis.	B-Review	B-5	Review	699
I am also missing a figure that shows the robustness of the method across independent runs.	I-Review	I-5	Review	699
<sep> <sep> - How are invalid architectures in the Nasbench101 (e.g architectures that violate the max edge constraint) treated in the experiments?	B-Review	B-6	Review	699
<sep> <sep> - I think the paper is missing the following references:	B-Review	B-7	Review	699
<sep> Simple and scalable predictive uncertainty estimation using deep ensembles	I-Review	I-7	Review	699
B Lakshminarayanan, A Pritzel, C Blundell	I-Review	I-7	Review	699
Advances in Neural Information Processing Systems, 6393-6395	I-Review	I-7	Review	699
<sep> Scalable hyperparameter transfer learning	I-Review	I-7	Review	699
V Perrone, R Jenatton, M Seeger, C Archambeau	I-Review	I-7	Review	699
Advances in Neural Information Processing Systems, 6845-6855	I-Review	I-7	Review	699
<sep> <sep> <sep> post rebuttal	O	O	Review	699
------------------	O	O	Review	699
<sep> <sep> I thank the authors for answering my questions regarding the path encoding and taking the time to improve the empirical evaluation of the paper.	O	O	Review	699
While I think that the paper has improved, I am afraid that the contributions of the paper are still not strong enough to reach the bar of acceptance because of the following reasons:	O	O	Review	699
<sep> - The path encoding is an interesting approach and seems to improve upon just using the adjacency matrix directly, it doesn't scale and, hence, it remain somewhat unclear how valuable it is in practice.	B-Review	B-1	Review	699
<sep> <sep> - More importantly, I am not convinced that the proposed neural network model represents a sufficient contribution.	B-Review	B-2	Review	699
After some discussion with the authors, they agree that existing BO methods based on neural networks could also be applied to this setting and even say that they may perform well with the path encoding.	I-Review	I-2	Review	699
However, they are not include them in the comparison and only promise to add them for the final evaluation.	I-Review	I-2	Review	699
I am concerned that if it turns out that other methods perform as well or even better, it would dramatically lower the contribution of the paper.	I-Review	I-2	Review	699
Thank you for your helpful comments.	O	O	Reply	699
We discuss the points below.	O	O	Reply	699
<sep> <sep> Replying to comments on the encoding:	O	O	Reply	699
<sep> First, we would like to point out the empirical effectiveness of our path encoding.	B-Reply	B-1	Reply	699
We show in Table 1, Figure 2, Figure 3, and Figure 4 that the difference between the adjacency matrix encoding (from the NASBench paper) and the path encoding has a huge effect on the performance of both the meta neural network and the NAS algorithm.	I-Reply	I-1	Reply	699
E.g., the NAS algorithm increases its efficiency by two orders of magnitude.	I-Reply	I-1	Reply	699
<sep> <sep> The downside of the adjacency matrix encoding is that it gives an arbitrary ordering to the nodes, and then gives a binary feature for an edge between node i and node j, for all i, j. Then a list of the operations at each node must also be included in the encoding.	I-Reply	I-1	Reply	699
This is a challenging data structure for a NAS algorithm to interpret.	I-Reply	I-1	Reply	699
The other encoding used by Ying et al is very similar to the adjacency matrix encoding, but the features of each edge are continuous.	I-Reply	I-1	Reply	699
Our path encoding is quite different.	I-Reply	I-1	Reply	699
We list all paths from the source to the sink in terms of the operations (Figure 1).	I-Reply	I-1	Reply	699
There is no arbitrary node ordering, therefore, isomorphic graphs are automatically mapped to the same encoding.	I-Reply	I-1	Reply	699
We will clarify these points in the final version of our paper.	I-Reply	I-1	Reply	699
<sep> <sep> Also, Kandasamy et al do not devise an encoding ‚Äî they devise a distance metric between neural architectures, which is used in a GP model.	I-Reply	I-1	Reply	699
<sep> <sep> We note that Bayesian optimization in general does not have a problem with high dimensions.	B-Reply	B-1	Reply	699
Bayesian optimization is most commonly set up with a GP model, which struggles with high dimensions.	I-Reply	I-1	Reply	699
We use a neural network model in Bayesian optimization, which is much more effective for high dimensional data.	I-Reply	I-1	Reply	699
<sep> <sep> <sep> Replying to the comments on Bayesian optimization:	O	O	Reply	699
<sep> Thank you for these suggestions.	B-Reply	B-2	Reply	699
We cannot directly compare our algorithm to the three papers you cited (Snoek et al, Springenberg et al Perrone et al), since they are methods for HPO rather than NAS.	I-Reply	I-2	Reply	699
HPO typically involves optimizing a set of discrete or real-valued parameters, while the search spaces for NAS are complex DAG structures.	I-Reply	I-2	Reply	699
Bayesian optimization has been used for HPO for years, but has only been applied to NAS last year.	I-Reply	I-2	Reply	699
Still, we agree that we should discuss these papers in more detail (we cited Snoek et al, but we will cite and discuss the others too).	I-Reply	I-2	Reply	699
<sep> <sep> Yes, in our neural network ensemble, the diversity is due to random initialization of the weights in the neural network and random order of the training data (same as Lakshminarayanan et al) We will emphasize this point in the final version of our paper.	B-Reply	B-3	Reply	699
<sep> <sep> <sep> Replying to minor comments:	O	O	Reply	699
<sep> As we discussed at the start of page 4 and in the Experiments section, we did not compare against BOHB, HB, etc.	B-Reply	B-4	Reply	699
because they are multi-fidelity NAS algorithms.	I-Reply	I-4	Reply	699
Our algorithm is a black-box algorithm, and we compared to other black-box algorithms on NASBench.	I-Reply	I-4	Reply	699
We mentioned a multi-fidelity version of our algorithm as exciting future work.	I-Reply	I-4	Reply	699
<sep> <sep> We will include log test regret in the next iteration of the paper (although in many search spaces we cannot compute log test regret because the best architecture is unknown, e.g. on the DARTS search space).	I-Reply	I-4	Reply	699
<sep> <sep> Please see Figure 3 for the error bars of our algorithm across different runs.	B-Reply	B-5	Reply	699
We also discuss the error across runs in the last paragraph on page 7.	I-Reply	I-5	Reply	699
<sep> <sep> We use the same random sampling method as in the original NASBench paper (rejection sampling).	B-Reply	B-6	Reply	699
Our mutation function also uses rejection sampling (again, similar to the original NASBench paper).	I-Reply	I-6	Reply	699
And just to clarify, we use the NASBench search space, so we reject cells with &gt;9 edges.	I-Reply	I-6	Reply	699
<sep> <sep> Thank you, we will include these references.	B-Reply	B-7	Reply	699
<sep> <sep> We would also like to point out our code release and our slightly updated results on the DARTS search space.	B-Reply	B-8	Reply	699
Our algorithm outperforms DARTS on average, and the best architecture achieves 2.57% test error on CIFAR-10.	I-Reply	I-8	Reply	699
Therefore, we achieve state-of-the-art performance on multiple search spaces.	I-Reply	I-8	Reply	699
Finally, we would like to emphasize that we carry out thorough and rigorous experiments, as we address every point on the NAS research checklist [Lindauer and Hutter, 2019].	I-Reply	I-8	Reply	699

This paper develop a path-based encoding scheme to featurize the neural architectures that are used to train the neural network model, and design a NAS algorithm that performs Bayesian optimization using a neural network model.	O	O	Review	699
The experiments show the priority of the proposed method.	O	O	Review	699
<sep> <sep> In general, this paper is easy to follow, but the contribution is limited.	B-Review	B-1	Review	699
The author did not give a clear explanation of why does this method work.	I-Review	I-1	Review	699
There are several problems that exist in the paper:	I-Review	I-1	Review	699
<sep> 1.	I-Review	I-1	Review	699
<tab>The paper introduced a path-based encoding scheme, which seems have nothing different from enumerating all possible paths.	I-Review	I-1	Review	699
Any additional operations should be clarified in the paper.	I-Review	I-1	Review	699
<sep> 2.	O	O	Review	699
<tab>The method retains new architectures with high UCB value.	B-Review	B-2	Review	699
However, the author did not prove that a higher UCB value leads to a better architecture.	I-Review	I-2	Review	699
Eq.(1) trained several different networks to predict the accuracy.	I-Review	I-2	Review	699
However, when using early stop stragegy, the intermediate accuracy is not convincing, and the new architecture selected based on UCB may not perform well when training with full epochs.	I-Review	I-2	Review	699
If early stop is not used, there is no need  to predict the accuracy with different networks.	I-Review	I-2	Review	699
<sep> 3.	O	O	Review	699
<tab>In my opinion, Algorithm 1 is a simplified traditional Evolutionary Algorithm, which only have mutation operation and do not have selection and crossover operation, and has limited novelty.	B-Review	B-3	Review	699
<sep> <sep> <sep> Thank you for your comments.	O	O	Reply	699
We discuss them below.	O	O	Reply	699
<sep> <sep> 1.	O	O	Reply	699
Yes, the path-based encoding scheme is enumerating all possible paths, with no additional operations.	B-Reply	B-1	Reply	699
As we show in Table 1 and Figures 2 and 4, using a path-based encoding is extremely effective for predicting the accuracy of neural architectures.	I-Reply	I-1	Reply	699
<sep> <sep> 2.	O	O	Reply	699
We do not optimize UCB to choose an architecture.	B-Reply	B-2	Reply	699
We are optimizing the validation accuracy and only use UCB as an acquisition function to choose subsequent queries.	I-Reply	I-2	Reply	699
This is the standard formulation for Bayesian optimization.	I-Reply	I-2	Reply	699
In Bayesian optimization literature, UCB is a well-known acquisition function that has been used for efficient global optimization.	I-Reply	I-2	Reply	699
In the NASBench experiments, there is no early stopping at all.	I-Reply	I-2	Reply	699
Every architecture is trained for 108 epochs.	I-Reply	I-2	Reply	699
In the DARTS experiments, every architecture is trained to 50 epochs (due to the large cost of training).	I-Reply	I-2	Reply	699
Then at the very end of our algorithm, we take the architecture with the best validation accuracy and train it to 600 epochs.	I-Reply	I-2	Reply	699
This method works well in practice.	I-Reply	I-2	Reply	699
<sep> <sep> 3.	O	O	Reply	699
Our method is completely different from an evolutionary algorithm.	B-Reply	B-3	Reply	699
Our algorithm follows a standard Bayesian optimization procedure, which is a different class of strategies.	I-Reply	I-3	Reply	699
In fact, we compared our algorithm to an evolutionary algorithm in Figure 2, and our algorithm performs much better.	I-Reply	I-3	Reply	699
The only similarity is that we use a mutation function to optimize the acquisition function.	I-Reply	I-3	Reply	699
Note that in the ablation study (Figure 3), we removed the mutation function (using random sampling instead), and our algorithm still significantly outperforms the evolutionary algorithm.	I-Reply	I-3	Reply	699
There is no overlap between the two algorithms other than the mutation function.	I-Reply	I-3	Reply	699
For example, our algorithm predicts the performance of unseen neural architectures, and there is no part of an evolutionary algorithm that makes predictions.	I-Reply	I-3	Reply	699

The paper considers the neural architecture search using Bayesian optimisation.	O	O	Review	699
The paper first propose a path-based encoding scheme to featurise the neural architectures.	O	O	Review	699
A path encoding of a cell is created by enumerating all possible paths from the input node to the output node.	O	O	Review	699
Then, they propose to train 5 neural networks and ensemble these networks to get the prediction (including the predictive value and uncertainty).	B-Review	B-2	Review	699
The paper optimises the acquisition function via a mutation procedure, where we randomly mutate the best architectures that we have trained so far, many times, and then select the architecture from this set which minimizes the acquisition function.	O	O	Review	699
<sep> <sep> While the writing is readable and the experiments seem promising, the reviewer thinks that the novelty and contribution of the paper are limited.	B-Review	B-1	Review	699
Particularly, using 5 neural networks for estimating the uncertainty is less convincing.	B-Review	B-2	Review	699
This is because it would have been better if we can train a Bayesian neural network to provide the uncertainty quantification directly.	I-Review	I-2	Review	699
<sep> <sep> <sep> Minor:	O	O	Review	699
Page 5: ‚Äúrandomly randomly‚Äù	O	O	Review	699
<sep> Thank you for your comments.	O	O	Reply	699
Your only specific complaint is that we did not use a Bayesian neural network, and we believe that this comment alone does not justify a poor rating.	B-Reply	B-2	Reply	699
We agree that using a Bayesian neural network may be an interesting alternative strategy.	I-Reply	I-2	Reply	699
However, our ensemble approach is well-justified as we explain below.	I-Reply	I-2	Reply	699
<sep> <sep> There have been a number of works that show the benefits of the ensembling approach to predictive uncertainty over using a classic Bayesian neural network.	I-Reply	I-2	Reply	699
For example, ensembles can be trained in parallel, use less memory, do not require approximate Bayesian inference algorithm (MCMC or variational inference) and in some cases have been shown empirically to provide better predictive uncertainty estimates [1], [2], [3]. Many of these papers have shown good performance using an ensemble of size five.	I-Reply	I-2	Reply	699
<sep> <sep> We would like to emphasize the novelty and contribution of our paper.	B-Reply	B-1	Reply	699
Using a path encoding to featurize neural architectures is a novel idea, which allows us to train a meta neural network to accurately predict the error of unseen neural architectures (Table 1, Figure 2, Figure 4).	I-Reply	I-1	Reply	699
When combined with Bayesian optimization, this creates a novel NAS algorithm that achieves state-of-the-art performance on the NASBench and DARTS search spaces.	I-Reply	I-1	Reply	699
We also carry out thorough and rigorous experiments, as we address every point on the NAS research checklist [Lindhaeur and Hutter, 2019].	I-Reply	I-1	Reply	699
<sep> [1] Lakshminarayanan et al Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles, 2017.	O	O	Reply	699
<sep> [2] Beluch et al, The power of ensembles for active learning in image classification, 2018.	O	O	Reply	699
<sep> [3] Choi et al, Ensemble of Deep Convolutional Neural Networks for Prognosis of Ischemic Stroke, 2017.	O	O	Reply	699

The paper proposes a straightforward method for end-to-end learning of active contours, based on predicting a dense field of 2D offsets, and then iteratively evolving the contour based on these offsets.	O	O	Review	699
A differentiable rendering formulation by Kato et al is employed to make the process of aligning a contour to a GT mask differentiable.	O	O	Review	699
<sep> <sep> The model shows rather compelling results on small datasets, and is very simple, with very strong parallels to active contours, which is a strength.	O	O	Review	699
The results improve those of DARNet, which to the best of my knowledge is the main published work in the space other than Curve-GCN.	B-Review	B-5	Review	699
One thing that would be helpful, is  to have an experiment on a large dataset, such as Cityscapes -- right now all the datasets are testing the model in only the small-data regime.	I-Review	I-5	Review	699
Perhaps in a supplement, it would also help to do ablation of how input image / dense deformation resolution affects the result quality -- the input can be subsampled by powers of 2 for the experiment.	I-Review	I-5	Review	699
<sep> <sep> As Amlan Kar helpfully points out, the work heavily overlaps with his approach "Fast Interactive Object Annotation with Curve-GCN", CVPR 2019, which is not cited or compared to.	O	O	Review	699
Curve-GCN similarly utilizes differential rendering (only a different variant) to match the GT masks.	O	O	Review	699
To me, the main difference wrt Curve-GCN is that explicit dense displacement fields are generated by the net and used directly for the iterative refinement steps, while Curve-GCN leverages implicit feature embeddings and uses GCN layers for their iterative updates.	O	O	Review	699
A second main difference is that Curve-GCN supports splines and interactive editing, while the proposed approach does not.	O	O	Review	699
Beyond these, there are multiple other differences that the authors point out, but those are more of a technical nature.	B-Review	B-1	Review	699
Unfortunately, without a more direct comparison, it is very difficult to evaluate the design choices in the two approaches, which I feel is necessary for proper understanding of the paper.	I-Review	I-1	Review	699
<sep> <sep> AFTER REBUTTAL: The authors made additions that covered my concerns, so I have switched my recommendation.	O	O	Review	699
<sep> <sep> A few more minor clarity / presentation issues.	O	O	Review	699
<sep> -- ‚ÄúThe recent learning-based approaches are either non-competitive or proven to be effective in the specific settings of building segmentation".	B-Review	B-2	Review	699
It's not exactly clear what the point is in the context.	I-Review	I-2	Review	699
Which "learning-based approaches"?	I-Review	I-2	Review	699
<sep> -- Typo 'backpropogation'.	B-Review	B-6	Review	699
<sep> -- A little better explanation of how a differentiable renderer of Kato works would have been helpful.	B-Review	B-3	Review	699
<sep> -- Figure 3 is not referenced in the text, takes a little bit of thought why it is relevant (helps explain Fig 1, but maybe better to show it prior to Fig 1).	B-Review	B-7	Review	699
<sep> -- In Eq 4 it‚Äôs not clear what F is.	B-Review	B-4	Review	699
(I see it is explained in Algorithm box, but that's much later)	I-Review	I-4	Review	699
<sep> <sep> <sep> <sep> <sep> <sep> We thank the reviewer for the comprehensive review.	O	O	Reply	699
<sep> <sep> We apologize for the typos in the previous draft.	B-Reply	B-6	Reply	699
These have been corrected.	I-Reply	I-6	Reply	699
<sep> <sep> To your comments:	O	O	Reply	699
<sep> Comparison to Curv-GCN: as noted by the reviewer, the differences between the methods are in the support of splines and working with an embedding space in Curve-GCN, vs. displacement map.	B-Reply	B-1	Reply	699
To emphasize: our method employs a single learned network that produces a displacement image in a single forward pass.	I-Reply	I-1	Reply	699
The CNN used by Curve-GCN predicts an embedding space of size 28x28 that is further processed by graph neural networks.	I-Reply	I-1	Reply	699
<sep> <sep> Following the review, we have conducted experiments on Cityscapes, which is the only public dataset available from Curve-GCN experiments (their code is not available).	B-Reply	B-5	Reply	699
In this dataset, our method obtains SOTA for 6/8 classes and SOTA, by a sizable margin that is larger than the difference between the performance of previous work, in the overall mean mIoU. We believe that this also directly addressed the reviewer‚Äôs comment regarding larger datasets.	I-Reply	I-5	Reply	699
<sep> <sep> All of our models are trained at the resolution of 64x64 pixels.	B-Reply	B-5	Reply	699
As noted in the original submission when discussing the Vaihingen dataset ‚Äúwe experiment with different resizing factors during training‚Äù.	I-Reply	I-5	Reply	699
Following the review, we share these results in Tab.5 of the revised submission.	I-Reply	I-5	Reply	699
As can be seen, there is a steep degradation in performance below 64x64, which we attribute to the lack of details.	I-Reply	I-5	Reply	699
When doubling the resolution to 128x128, the performance slightly degrades, however, that model could improve with further training epochs.	I-Reply	I-5	Reply	699
<sep> <sep> <sep> The recent learning-based approaches are either non-competitive or proven to be effective in the specific settings of building segmentation" ‚Äî we have clarified in the text that we mean learning-based active contour methods and have limited the scope of the claim.	B-Reply	B-2	Reply	699
<sep> <sep> We have added a paragraph regarding the use of a 3D renderer for 2D maps.	B-Reply	B-3	Reply	699
We simply fix the third coordinate and use the code of Kato as is.	I-Reply	I-3	Reply	699
<sep> <sep> The letter ‚ÄúF‚Äù (for faces) is defined at the beginning of the ‚ÄúMethod‚Äù section.	B-Reply	B-4	Reply	699
<sep> <sep> We believe that various issues raised by the reviewer were fully addressed in a way that considerably improved the manuscript.	O	O	Reply	699
With the CVPR deadline in a week, we would appreciate a timely response, in order for us to be able to plan our submission strategy.	O	O	Reply	699

This paper investigates an image segmentation technique that learns to evolve an active contour, constraining the segmentation prediction to be a polygon (with a predetermined number of vertices).	O	O	Review	699
The advantage of active contour methods is that some shapes (such as buildings) can naturally be represented as closed polygons, and learning to predict this representation can improve over pixelwise segmentation.	O	O	Review	699
<sep> <sep> The authors propose to learn an image-level displacement field to evolve the contour, and a neural mesh renderer to render the resulting mask for comparison with the ground truth mask.	O	O	Review	699
The performance compared to prior learning-based active contour methods is impressive.	O	O	Review	699
<sep> <sep> In section 4.3, there‚Äôs a reference to a ‚Äúgap in performance‚Äù between the proposed method and DARNet and a reference to a "low number of vertices," but a comparison between the two methods as the numbers of vertices is varied seems to only be present in Fig.6 -- it would be interesting to see an explanation of the discrepancy for the lower number of vertices seen in this figure.	B-Review	B-1	Review	699
<sep> <sep> Overall, due to the relative simplicity of the approach and impressive performance compared to prior learning-based approaches I recommend to accept.	O	O	Review	699
<sep> <sep> Post-rebuttal:  I maintain my recommendation.	O	O	Review	699
Thank you for the supportive review.	B-Reply	B-1	Reply	699
We are sorry for the reference mistakes, these are all fixed in the new revised version.	I-Reply	I-1	Reply	699
<sep> <sep> There was a typo in the caption of Fig.6 (Fig.7 in the revised version), which switched the association between the methods and the colors.	I-Reply	I-1	Reply	699
We believe that this mistake has led to the remark concerning this figure.	I-Reply	I-1	Reply	699

EDIT: The rating changed from '1: Reject' to '6: Weak accept' after the rebuttal.	O	O	Review	699
See below for my reasoning.	O	O	Review	699
<sep> <sep> The submission considers two-class image segmentation problems, where a closed-contour image region is to be specified as the 'object'/region of interest, vs. 'no-object'/background.	O	O	Review	699
The approach taken here is end-to-end learning with an active-contour type approach.	O	O	Review	699
The main loss, in contrast to other active contour approaches, contains a direct difference of the estimated polygon area vs. ground truth polygon area.	O	O	Review	699
<sep> <sep> The applied method seems conceptually quite simple (as admitted by the authors in Section 5), and the neural rendering approach seems quite neat, but both method presentation (Section 3) and evaluation (Section 4) seem incomplete and leave significant open questions.	B-Review	B-1	Review	699
<sep> <sep> One of my main concerns is related to the fact that the displacement field is static and, according to Figure 1 and Algorithm 1, is evaluated only once per image.	B-Review	B-2	Review	699
<sep> If the displacement field J is not conditioned on the current polygon shape (and this does not seem to be the case), then I am wondering why T iterations in the sampling/rendering part are necessary at all.	I-Review	I-2	Review	699
When only considering L_seg, the optimal solution should be found within one iteration, since the displacement field will be able to provide the optimal answer.	I-Review	I-2	Review	699
So maybe these iterations are only necessary when L_B and L_K are incorporated?	I-Review	I-2	Review	699
<sep> In any case, it is unclear why even L_seg is accumulated (using unweighted mean) over all T iterations before being backpropagated.	I-Review	I-2	Review	699
Does this mean that these iterations are not meant to yield shape improvements?	I-Review	I-2	Review	699
Why is ||M^t-M|| not evaluated per iteration, for the purpose of minimization?	I-Review	I-2	Review	699
<sep> It is also not sufficiently clear whether M^t in Equation 4 is a filled polygon mask, or if the mask is just related to the boundary (with a certain width).	I-Review	I-2	Review	699
In absence of explanatory image material, I am assuming the former.	I-Review	I-2	Review	699
<sep> Overall the method description remains weak, since obvious questions/concerns such as the above are not addressed.	I-Review	I-2	Review	699
<sep> <sep> The experimental results look good from a quantitative point of view, and indeed, the strongest baselines, e.g. DARNet, are outperformed significantly in many cases.	B-Review	B-3	Review	699
<sep> Section 4 mostly focuses on quantitative evaluation and lots of picture examples, but fails to give insight into particular behaviors, failure cases, etc.	I-Review	I-3	Review	699
<sep> The evaluation procedure is cast a bit into doubt by two things: 1) In Figure 4, the initializations (blue circles) between the DARNet method and the proposed method are very different in size.	I-Review	I-3	Review	699
I am wondering if this then still constitutes a fair comparison, and I have some doubts there.	I-Review	I-3	Review	699
2) In Figure 6, the proposed method consistently looks much worse than the DARNet baseline (and, in contrast to the baseline, completely fails for 4 vertices), unless the colors were swapped in the description.	I-Review	I-3	Review	699
<sep> <sep> Overall, I do not think the submission is in a good enough shape for acceptance.	O	O	Review	699
<sep> <sep> Minor remarks:	B-Review	B-4	Review	699
- The values for lambda_1 and lambda_2 seem to come out of thin air, and they also seem quite small.	I-Review	I-4	Review	699
It needs to be mentioned how they were determined.	I-Review	I-4	Review	699
<sep> - Data augmentation by rotation seems to be missing several values (between 270 and 260 degrees) and also not evenly spaced.	I-Review	I-4	Review	699
Is this a typo or on purpose?	I-Review	I-4	Review	699
In the latter case, an explanation is needed, since this seems weird.	I-Review	I-4	Review	699
<sep> - Section 4.3: There is no "Figure 4.2", I assume you mean Figure 6, which otherwise remains unreferenced.	I-Review	I-4	Review	699
<sep> - Section 4.3, Ablation Study: Don't use the word "derivatives" when you're talking about variations.	I-Review	I-4	Review	699
<sep> - Section 4.3, Ablation Study: "even without no auxiliary loss" -&gt; remove "no" or change "without" -&gt; "with"	I-Review	I-4	Review	699
<sep> -------------	O	O	Review	699
Post-rebuttal comments:	O	O	Review	699
<sep> I have read the revised version, as well as the other reviews and all authors' comments.	O	O	Review	699
The inclusion of an evaluation on a larger-size data set is highly appreciated, and seems to indeed validate the robustness of the method.	O	O	Review	699
Typos were fixed, including the switched color descriptions in Figure 7 (which should not have passed initial submission in the first place, if the text had been proofread properly).	O	O	Review	699
<sep> <sep> Several of the open questions (e.g. "Why is L_seg accumulated before backpropagation?", "	B-Review	B-1	Review	699
Why is the algorithm iterative if the displacement map is computed only once, if not for the other loss terms?", "	I-Review	I-1	Review	699
Choice of values for lambda_1, lambda_2", Initial diameter of initialization") have been somewhat addressed by the authors in the rebuttal comment, though not in great detail.	I-Review	I-1	Review	699
<sep> <sep> Based on the quality of the results across data sets, and because I believe that the timely publication of this rather simple method can benefit further research in this area, I have adjusted my score to a 'Weak accept'.	O	O	Review	699
That said, I still do not think it is a good manuscript, and my score should be seen as a massive benefit of the doubt toward the authors.	O	O	Review	699
<sep> <sep> Most importantly, above questions have NOT been adequately addressed in the actual revised text.	B-Review	B-4	Review	699
The authors claim they have "improved the manuscript considerably", but yet I see more reasoning for certain choices described in the comment here than in the actual manuscript.	I-Review	I-4	Review	699
Most of the changes are in Section 2 and the new Section 4.3, but not much relevant to my comments changed in Section 3.	I-Review	I-4	Review	699
<sep> <sep> For example, balloon and curvature losses aside, it is still not clear why an iterative approach would be helpful past the first iteration.	I-Review	I-4	Review	699
An ideal displacement map that is not conditioned on the polygon should point, for each pixel, straight to the closest contour pixel.	I-Review	I-4	Review	699
It is clear to me that this may not be what is being learned when multiple iterations are forced, yet it is not addressed why multiple iterations should be beneficial. (	I-Review	I-4	Review	699
I could see why they could be beneficial if the approach was conditioned on the polygon vertices, to avoid vertex collapsing, but it's not.)	I-Review	I-4	Review	699
<sep> <sep> A good submission preempts these kinds of questions by addressing them carefully.	O	O	Review	699
What seems crystal clear to the authors will not be crystal clear to every reader.	O	O	Review	699
The authors should be more careful to include their reasoning in the actual text, which I believe this is essential for proper, easy understanding of the paper.	O	O	Review	699
Thank you for the additional feedback and for upgrading the paper‚Äôs rating.	O	O	Reply	699
We appreciate the timely response and apologize for neglecting to proofread the submitted version more carefully.	O	O	Reply	699
<sep> <sep> Regarding the number of iterations.	B-Reply	B-2	Reply	699
In the original (and revised) submission, Section 4.4 "Number of Iterations‚Äù and Fig.8 (as numbered in the revised version), we experiment with different number of iterations.	I-Reply	I-2	Reply	699
We noticed that a single iteration is less beneficial across all datasets, while 2-3 iteration results in higher performance.	I-Reply	I-2	Reply	699
Nevertheless, as the reviewer hypothesised, a single iteration can already produce very good results, as can be seen from our experiments.	I-Reply	I-2	Reply	699
<sep> <sep> We have released a new revision, elaborating on two subjects: (i) The initial guess, and (ii) the effect of the number of iterations T.	I-Reply	I-2	Reply	699

The paper proposes to combine several smaller, pretrained RBMs into a larger model as a way to solve combinatorial optimization problems.	O	O	Review	1311
Results are presented on RBMs trained to implement binary addition, multiplication, and factorization, where the proposed approach is compared with the baseline of training a full model from scratch.	O	O	Review	1311
<sep> <sep> I found the paper confusing at times.	O	O	Review	1311
It is well-written from a syntactical and grammatical point of view, but some key concepts are stated without being explained, which gives the impression that the authors have a clear understanding of the material presented in the paper but communicate only part of the full picture to the reader.	O	O	Review	1311
<sep> <sep> For instance, there‚Äôs a brief exposition of the connection between Boltzmann machines and combinatorial optimization problems: the latter is mapped onto the former by expressing constraints as a fixed set of Boltzmann machine weights and biases, and low-energy states (i.e. more optimal solutions) are found by sampling from the model, which involves no training.	B-Review	B-1	Review	1311
What‚Äôs less clear to me is what kinds of combinatorial optimization problems can be mapped onto the RBM *training* problem.	I-Review	I-1	Review	1311
The paper states that the problem of training "large modules" is "equivalent to solving the optimization problem", but does not explain how.	B-Review	B-2	Review	1311
<sep> <sep> Similarly, the paper mentions that the "general approach to solving these combinatorial optimization problems is to recognize the atomic unit necessary to solve the problem", but at that point the reader has no concrete example of what combinatorial optimization problem would be mapped onto training and inference in RBMS.	B-Review	B-3	Review	1311
<sep> <sep> A concrete example is provided in the Experiments section: the authors propose to implement invertible (reversible?)	O	O	Review	1311
boolean logic circuits by combining smaller pre-trained RBMs which implement certain logical operations into larger circuits.	O	O	Review	1311
I have two issues with the chosen example: 1) the connection with combinatorial optimization is not clear to me, and 2) it‚Äôs not very well explained.	B-Review	B-4	Review	1311
As far as I understand, these reversible boolean logic operations are expressed as sampling a subset of the RBM‚Äôs inputs conditioned on another subset of its inputs.	I-Review	I-4	Review	1311
An example is presented in Figure 3 but is not expanded upon in the main text.	I-Review	I-4	Review	1311
I‚Äôd like the authors to validate my understanding:	I-Review	I-4	Review	1311
<sep> An RBM is trained to implement a complete binary adder circuit by having it model the joint distribution of the adder‚Äôs inputs and outputs [A, B, Cin, S, Cout] (A is the first input bit, B is the second input bit, Cin is the input carry bit, S is the output sum bit, and Cout is the output carry bit), where (I assume) the distribution over [A, B, Cin] is uniform, and where S and Cout follow deterministically from [A, B, Cin]. After training, the output of the circuit is computed from [A, B, Cin] by clamping [A, B, Cin] and sampling [S, Cout] given [A, B, Cin] using Gibbs sampling.	O	O	Review	1311
<sep> <sep> The alternative to this, which is examined in the paper, is to train individual XOR, AND, and OR gates in the same way and compose them into a complete binary adder circuit as prescribed by Section 3.	O	O	Review	1311
<sep> <sep> I think the paper has the potential to be a lot more transparent to the reader in explaining these concepts, which would avoid them spending quite a bit of time inferring meaning from figures.	O	O	Review	1311
<sep> <sep> I‚Äôm also confused by the presentation of the results.	B-Review	B-5	Review	1311
For instance, I don‚Äôt know what "log", "FA1", "FA2", etc.	I-Review	I-5	Review	1311
refer to in Figure 6.	I-Review	I-5	Review	1311
Also, Figure 6 is referenced in the text in the context of binary multiplication ("[...] is able to outperform a multiplier created just by training, as can be seen in Figure 6"), but presents results for addition and factorization only.	I-Review	I-5	Review	1311
<sep> <sep> The way I see it, implementing reversible boolean logic circuits using RBMs is an artificial problem, and the key idea of the paper -- which I find interesting -- is that in some cases it appears to be possible to combine RBMs trained for sub-problems into larger RBMs without needing to fine-tune the model.	B-Review	B-6	Review	1311
I think there are interesting large-scale applications of this, such as building an autoregressive RBM for image generation by training a smaller RBM on a more restricted inpainting task.	I-Review	I-6	Review	1311
The connection to combinatorial optimization, however, is much less clear to me.	I-Review	I-6	Review	1311
Thank you for your comments, we will be responding with specific comments to AnonReviewer4 here, and more general comments to the reviewer above.	O	O	Reply	1311
<sep> <sep> R4: ‚ÄúWhat‚Äôs less clear to me is what kinds of combinatorial optimization problems can be mapped onto the RBM *training* problem‚Äù	O	O	Reply	1311
<sep> The combination method we propose here can be applied to RBMs that are calculated by directly setting weights and by training individual sub units.	B-Reply	B-1	Reply	1311
We acknowledge there are pros and cons to both approaches; directly calculating the weights gives guarantees on probabilities and mixing rates, while training can produce a more compact, data, and computationally efficient model.	I-Reply	I-1	Reply	1311
Some algorithms will be more amenable to training, while others more amenable to directly calculating and setting weights, so we believe that this should be addressed on an algorithm by algorithm basis.	I-Reply	I-1	Reply	1311
We try to present one possible algorithm and a possible combination mechanism that we believe could work for others.	I-Reply	I-1	Reply	1311
<sep> R4: ‚ÄúThe paper states that the problem of training "large modules" is "equivalent to solving the optimization problem", but does not explain how.	O	O	Reply	1311
‚Äù	O	O	Reply	1311
<sep> Training a full module to solve an optimization problem in the context presented here involves supplying samples from a large portion of the subspace that we are trying to model.	B-Reply	B-2	Reply	1311
Based on the results we have seen, we only achieve good performance once we have samples from >30% of the subspace (depending on the problem).	I-Reply	I-2	Reply	1311
In addition, the RBMs perform significantly better when trained on the full space we are trying to model.	I-Reply	I-2	Reply	1311
We view this as the RBM creating an associative memory where it ‚Äúmemorizes‚Äù examples and recalls them afterward, and do not view this as a data and computationally efficient method of solving these problems.	I-Reply	I-2	Reply	1311
<sep> <sep> R4: An example is presented in Figure 3 but is not expanded upon in the main text.	O	O	Reply	1311
I‚Äôd like the authors to validate my understanding:	O	O	Reply	1311
An RBM is trained to implement a complete binary adder circuit by having it model the joint distribution of the adder‚Äôs inputs and outputs [A, B, Cin, S, Cout] (A is the first input bit, B is the second input bit, Cin is the input carry bit, S is the output sum bit, and Cout is the output carry bit), where (I assume) the distribution over [A, B, Cin] is uniform, and where S and Cout follow deterministically from [A, B, Cin]. After training, the output of the circuit is computed from [A, B, Cin] by clamping [A, B, Cin] and sampling [S, Cout] given [A, B, Cin] using Gibbs sampling.	B-Reply	B-4	Reply	1311
‚Äù	I-Reply	I-4	Reply	1311
<sep> Yes, your understanding is correct.	I-Reply	I-4	Reply	1311
We train on the joint density over inputs and outputs, and solving a problem amounts to clamping (conditioning) a subset of the units and sampling the remaining units via Gibbs Sampling.	I-Reply	I-4	Reply	1311
We have made an effort in the revision to make sure that this is more clear.	I-Reply	I-4	Reply	1311
In the case of solving factorization problem, we clamp some of the visible units to the integer we are trying to factor, and use gibbs sampling to get statistics for the remaining units conditioned on the output number.	I-Reply	I-4	Reply	1311
<sep> <sep> R4: I‚Äôm also confused by the presentation of the results.	O	O	Reply	1311
For instance, I don‚Äôt know what "log", "FA1", "FA2", etc.	O	O	Reply	1311
refer to in Figure 6.	O	O	Reply	1311
Also, Figure 6 is referenced in the text in the context of binary multiplication ("[...] is able to outperform a multiplier created just by training, as can be seen in Figure 6"), but presents results for addition and factorization only.	O	O	Reply	1311
<sep> <sep> We have presented results for addition and factorization in the main body of the paper, but refer to readers of the paper to the appendix where we have included a larger set of results.	B-Reply	B-5	Reply	1311
The results were omitted from the main body of the paper for the sake of brevity.	I-Reply	I-5	Reply	1311
The naming of units as ‚Äúlog‚Äù ‚ÄúFA1‚Äù, ‚ÄúFA2‚Äù, etc.	I-Reply	I-5	Reply	1311
are meant to represent the size of the base unit that was merged to create this larger unit, ‚Äúlog‚Äù referring to logical units (AND, XOR, etc.), ‚	I-Reply	I-5	Reply	1311
ÄúFA1‚Äù being 1 bit full adder, ‚ÄúFA2‚Äù being a 2 bit full adder, etc.	I-Reply	I-5	Reply	1311
we have made this clear in the figure caption.	I-Reply	I-5	Reply	1311
<sep> <sep> R4: The way I see it, implementing reversible boolean logic circuits using RBMs is an artificial problem, and the key idea of the paper -- which I find interesting -- is that in some cases it appears to be possible to combine RBMs trained for sub-problems into larger RBMs without needing to fine-tune the model.	O	O	Reply	1311
<sep> <sep> We also agree that there may be other applications to this type of merging of RBMs without further training, and we are working to look at those in greater detail.	B-Reply	B-6	Reply	1311
Invertible Boolean Logic provides a good test bed for this idea, and as explained above, we do believe it has a very intimate relationship with Boolean Satisfiability problems and other combinatorial optimization problems.	I-Reply	I-6	Reply	1311

The paper proposes learning Restricted Boltzmann Machines for solving small computational tasks (e.g., 1-bit addition) and composing those RBMs to form a more complex computational module (e.g., 16-bit addition).	O	O	Review	1311
The claim is that such an approach can be more data efficient than learning a single network to directly learn the more complex module.	O	O	Review	1311
Results are shown for addition and factoring tasks.	O	O	Review	1311
<sep> <sep> - The paper is somewhat easy to follow and the figures are helpful.	B-Review	B-1	Review	1311
But the overall organization and flow of ideas can be improved significantly.	I-Review	I-1	Review	1311
<sep> - The term "combinatorial optimization" is used in a confusing way -- addition would not usually be called a combinatorial optimization problem.	B-Review	B-2	Review	1311
<sep> - It would be good to understand what benefit does the stochasticity of RBMs provide.	B-Review	B-3	Review	1311
How do deterministic neural networks perform on the addition and factoring tasks?	I-Review	I-3	Review	1311
The choice of RBMs is not motivated well and without any comparisons to alternatives, it comes across as arbitrary.	I-Review	I-3	Review	1311
<sep> - That learning simple functions and composing them to compute more complex functions would be more data efficient than directly learning the complex functions does not seem very surprising.	B-Review	B-4	Review	1311
After all, the former approach gets a lot more knowledge about the target function built into it.	I-Review	I-4	Review	1311
It's good that the paper empirically confirms the intuition, but doesn't feel like a significant contribution on its own.	I-Review	I-4	Review	1311
<sep> - The paper would be stronger if it includes more complex tasks, e.g., TSP, and show that the same ideas can be applied to improve the learning a solver for such tasks.	B-Review	B-5	Review	1311
The current tasks and problem sizes are not very convincing, and the accuracy results are not very compelling.	I-Review	I-5	Review	1311
Thank you for your comments, we will be responding with specific comments to AnonReviewer3 here, and more general comments to the reviewer above.	O	O	Reply	1311
<sep> <sep> R3: ‚ÄúIt would be good to understand what benefit does the stochasticity of RBMs provide.	O	O	Reply	1311
‚Äù	O	O	Reply	1311
<sep> The stochasticity of the RBM provides a number of benefits over more deterministic methods.	B-Reply	B-3	Reply	1311
Firstly, the stochasticity allows for full sampling from the RBMs distribution, and has the ability to identify all possible modes in a multimodal distribution if sampled for long enough.	I-Reply	I-3	Reply	1311
As there are many possible solutions to a Boolean logic query (and integers can have many different factors), we note that the statistics that this method provides can give us a variety of answers to the queries, allowing the user to evaluate each individual solution based on its individual merit.	I-Reply	I-3	Reply	1311
<sep> <sep> R3: How do deterministic neural networks perform on the addition and factoring tasks?	O	O	Reply	1311
The choice of RBMs is not motivated well and without any comparisons to alternatives, it comes across as arbitrary.	O	O	Reply	1311
<sep> <sep> To the best of our knowledge, deterministic neural networks have not been well studied for the integer factorization problem.	B-Reply	B-3	Reply	1311
In [4] deterministic neural networks are used, but are able to factor smaller integers, on a more restricted problem, and are fully trained on the subset of all integers.	I-Reply	I-3	Reply	1311
We have cited this work in our related works section, and mentioned its impact.	I-Reply	I-3	Reply	1311
<sep> R3: That learning simple functions and composing them to compute more complex functions would be more data efficient than directly learning the complex functions does not seem very surprising.	O	O	Reply	1311
<sep> <sep> We agree that this method of composing simple functions to compute more complex ones is intuitive, and may not be very surprising, but we think that this helps data and model efficiency in a different manner than presented in previous papers.	B-Reply	B-4	Reply	1311
<sep> <sep> As far as scaling up the tasks and problem sizes, we are showing a method of combination here, and are scaling up the problem sizes continuously.	I-Reply	I-4	Reply	1311
We believe this combination method could be used for other things, and have presented it here as a proof of concept rather than a definitive survey with all possible uses.	I-Reply	I-4	Reply	1311

The paper introduces a new approach to combine small RBMs that are pretrained in order to obtain a large RBM with good performance.	O	O	Review	1311
This will bypass the need of training large RBMs and suggests to break them into smaller ones.	O	O	Review	1311
The paper then provides experimental evidence by applying the method on "invertible boolean logic".	O	O	Review	1311
MCMC is used to find the the solution to large RBM and compare it against the combined solutions of smaller RBMs.	O	O	Review	1311
<sep> <sep> <sep> The paper motivates the problem well, however, it is not well-written and at times it is hard to follow.	O	O	Review	1311
The details of the approach is not entirely clear and no theoritcal results are provided to support the approach.	B-Review	B-1	Review	1311
For instance, in the introduced approach, only an example of combination is provided in Figure 1.	I-Review	I-1	Review	1311
It is not clear how smaller RBMs (and their associated parameters) are combined to obtain the larger RBM model.	I-Review	I-1	Review	1311
From the experimental perspective, the experimental evidence on "invertible boolean logic" does not seem to be very convincing for validating the approach.	B-Review	B-2	Review	1311
Additionally, the details of the settings of the experiments are not fully discussed.	I-Review	I-2	Review	1311
For example, what are the atomic/smaller problems and associated RBMs?	I-Review	I-2	Review	1311
what is the larger problem and how is the corresponding RBM obtained?	B-Review	B-3	Review	1311
Overall, the paper seems to be a report consisting of a few interesting observations rather than introducing a solid and novel contribution with theoretical guarantees.	I-Review	I-3	Review	1311
<sep> <sep> Remark:	O	O	Review	1311
The term "Combinatorial optimization", which is used in the title and throughout the body of paper, sounds a bit confusing to the reviwer.	B-Review	B-4	Review	1311
This term is typically used in other contexts.	I-Review	I-4	Review	1311
<sep> <sep> Typos:	B-Review	B-5	Review	1311
** Page 2 -- Paragraph 2: "Therefore, methods than can exploit..."	I-Review	I-5	Review	1311
** Page 3 -- 2nd line of math: Super-scripts are missing for some entries of the matrices W^A and W^{A+B}	I-Review	I-5	Review	1311
** Page 5 -- Last paragraph: "...merged logical units is more likly to get get stuck in a ..."	I-Review	I-5	Review	1311
** Page 5 -- Last paragraph: "...and combining their distributions using the mulistart heuristic..."	I-Review	I-5	Review	1311
<sep> Thank you for your comments, we will be responding with specific comments to AnonReviewer3 here, and more general comments to the reviewer above.	O	O	Reply	1311
<sep> <sep> R2: For instance, in the introduced approach, only an example of combination is provided in Figure 1.	O	O	Reply	1311
It is not clear how smaller RBMs (and their associated parameters) are combined to obtain the larger RBM model.	O	O	Reply	1311
<sep> <sep> As far as explaining the method of combination, and the associated mathematical properties, we have tried to do this in greater detail in section 3 (Approach).	B-Reply	B-1	Reply	1311
We used Figure 1 and the combination matrices to show what exactly is happening when we combine the models, and how the models mathematically combine.	I-Reply	I-1	Reply	1311
In our revision we have made an effort to outline this in greater detail.	I-Reply	I-1	Reply	1311
<sep> R2: Overall, the paper seems to be a report consisting of a few interesting observations rather than introducing a solid and novel contribution with theoretical guarantees.	O	O	Reply	1311
<sep> <sep> In regards to the lack of theoretical guarantees, we have shown that the equilibrium distribution is what we expect it to be, and mathematically have shown that the final distribution of interest has the mode we expect it to.	B-Reply	B-3	Reply	1311
It has been shown in many texts that Gibbs Sampling converges to this equilibrium distribution at a geometric rate in Markov Random Fields.	I-Reply	I-3	Reply	1311
Finding the exact convergence rate involves calculation of the eigenstructure of the markov chain transition matrix, which is in general computationally intractable for RBMs of moderate size [1]. Given this, we have added an extra theorem to show how the upper bounds on convergence rate changes as we merge RBMs, this can be seen in Section 3.1 on ‚ÄúConvergence Rate and MCMC‚Äù.	I-Reply	I-3	Reply	1311
We show that the rate of convergence of the RBM is geometric in the number of sampling steps, and that the combined RBM will have a convergence rate bounded by the sum of the convergence rates of the individual RBMs.	I-Reply	I-3	Reply	1311
<sep> <sep> If we want to have further theoretical guarantees, we have the ability to exactly set model parameters, as mentioned in section 3.2 to get the exact distribution of interest, and to combine those RBMs with directly calculated parameters.	I-Reply	I-3	Reply	1311
As mentioned in that section, this is not a data efficient, or computationally efficient method which is why we chose to not pursue it.	I-Reply	I-3	Reply	1311
<sep> <sep> [1] Pierre.	O	O	Reply	1311
Bremaud.	O	O	Reply	1311
Markov Chains: Gibbs Fields, Monte Carlo Simulation, and Queues, volume 1.Springer New York, 1999.	O	O	Reply	1311
ISBN 9781441931313.	O	O	Reply	1311

Review of "A mechanism of ... deep learning"	O	O	Review	172
<sep> This paper studies the generalization performance and implicit regularization of deep learning.	O	O	Review	172
In particular, the authors propose a novel technique called "random walk analysis" to study the nonlinearity of the neural network with respect to the input data points.	O	O	Review	172
Moreover, the authors prove that for a class of 1-d continuously differentiable functions, SGD can achieve O(n^{-2}) generalization error bound.	O	O	Review	172
<sep> <sep> Overall this paper is well written and easy to follow.	O	O	Review	172
The linear approximation with respect to input parameter space is also interesting and seems to be useful in the generalization analysis.	O	O	Review	172
Besides, I have the following comments and concerns.	O	O	Review	172
<sep> <sep> 1.	B-Review	B-1	Review	172
I am a little bit confused by the definitions "Priori generalization estimates" and "posterior data distribution".	I-Review	I-1	Review	172
I would like to see clearer description in the introduction.	I-Review	I-1	Review	172
<sep> 2.	O	O	Review	172
I would like to see more discussion on Theorem 2 in the surrounding text, it is quite unclear to me why Theorem 2 is important and how it can be related to the "implicit regularization".	B-Review	B-2	Review	172
<sep> 3.	B-Review	B-3	Review	172
I do not see the proof of (6) in Section 3.2.	I-Review	I-3	Review	172
<sep> 4.	B-Review	B-4	Review	172
It seems that the generalization results in this paper are difficult to be generalized to high-dimension regimes.	I-Review	I-4	Review	172
For example, if you assume that each entry of the training data point is generated from the uniform distribution in the interval [0, v], the density of training sample would be \mu = n/(v^d), and the resulting generalization bound would be O(v^d/(n\delta)), which is extremely large.	I-Review	I-4	Review	172
<sep> 5.	B-Review	B-5	Review	172
It seems that the generalization results hold for any data distribution.	I-Review	I-5	Review	172
However, it is widely known that if the training data is randomly labeled, the neural network trained by SGD cannot achieve small population risk, which contradicts the result in Theorem 4.	I-Review	I-5	Review	172
<sep> <sep> <sep> ----------------------------	O	O	Review	172
After reading the authors' response, I still think that the generalization results in this paper are not significant and important, and how the theoretical results can be related to the implicit regularization.	B-Review	B-6	Review	172
Thus I would like to keep my score.	I-Review	I-6	Review	172
<sep> <sep> We appreciate your detailed reading of the paper and thoughtful comments.	O	O	Reply	172
We have responded to these below.	O	O	Reply	172
<sep> <sep> ## A5.	O	O	Reply	172
Contradiction(?)	O	O	Reply	172
between random label and Theorem 4	O	O	Reply	172
<sep> Certainly, the random label problem is important, but it does not conflict with Theorem 4.	B-Reply	B-5	Reply	172
<sep> <sep> The random label method is introduced to show that the Rademacher complexity of an over-parameterized neural network is very large, and it does not lead to poor generalization ability of neural networks (Zhang et al 2016).	I-Reply	I-5	Reply	172
<sep> <sep> In our setting, the target function is a-class function and is set independently of any other settings.	I-Reply	I-5	Reply	172
<sep> <sep> As is written in section 4, each data point and its label is sampled from.	I-Reply	I-5	Reply	172
Theorem 4 evaluates the difference between two functions - the target function and the neural network trained with the dataset.	I-Reply	I-5	Reply	172
<sep> <sep> Theorem 4 can be proven from Theorem 2, calculating the difference between and its piecewise linear interpolation between data points.	I-Reply	I-5	Reply	172
<sep> Then, we can understand neural networks almost straightly connect the output corresponding to the data point input.	I-Reply	I-5	Reply	172
<sep> <sep> When a random label dataset is given, the neural network converges to a piecewise linear function connecting its random label output corresponding to the input.	I-Reply	I-5	Reply	172
<sep> <sep> The generalization error must be high if the piecewise linear function connecting the neural network output corresponding to the random label dataset were not close to the true target function.	I-Reply	I-5	Reply	172
For short, to train with random label training data means not to sample it from true target function.	I-Reply	I-5	Reply	172

This paper studies the implicit regularization in deep learning under the over-parameterized setting.	O	O	Review	172
In specific, the authors study the neural network outputs and ‚Äúpre-activation values‚Äù on line segments connecting two training data inputs and characterize an implicit regularization based on it.	O	O	Review	172
I have the following concerns:	O	O	Review	172
<sep> First of all, it is not clear to me why Theorem 2 is relevant to ‚Äúimplicit regularization‚Äù.	B-Review	B-1	Review	172
To my knowledge, implicit regularization or implicit bias statements in prior works cited in this paper are all about the convergence to a specific solution for underdetermined problems.	I-Review	I-1	Review	172
For example, ‚Äúamong all solutions that fits the data, gradient descent converges to minimum distance solution to initialization (linear model square loss), maximum margin solution (linear model exponential loss), minimum nuclear norm solution (matrix sensing with small initialization)‚Äù.	I-Review	I-1	Review	172
In comparison, Theorem 2 just gives some bounds that holds for every sgd iteration.	I-Review	I-1	Review	172
I cannot see any connection between Theorem 2 and implicit regularization.	I-Review	I-1	Review	172
<sep> <sep> Moreover, the authors‚Äô claim ‚Äúthe implicit regularization in over-parameterized DNNs has not been identified‚Äù is not correct.	B-Review	B-2	Review	172
As the authors mentioned,  the neural network is close to its linear approximation model with respect to weight parameters at initialization.	I-Review	I-2	Review	172
Therefore the implicit bias of (stochastic) gradient descent for DNNs in the over-parameterized regime is essentially implicit bias of (stochastic) gradient descent for linear models (for square loss).	I-Review	I-2	Review	172
In Arora et al 2019b it has been proved that infinitely wide neural networks trained with gradient flow converges to the NTK-based kernel regression solution.	I-Review	I-2	Review	172
So at least for gradient flow with square loss, the implicit bias of DNNs has been well-studied.	I-Review	I-2	Review	172
In fact in a missed reference [2], essentially the implicit bias for both gradient descent and stochastic gradient descent has been studied.	I-Review	I-2	Review	172
The remark ‚Äúin most cases, the authors used GD to derive their results by the NTK analysis‚Äù is also not convincing.	I-Review	I-2	Review	172
Allen-Zhu et al 2018a,b, Allen-Zhu &amp; Li, 2019 and missed references [1,2,3,4] all studied SGD of over-parameterized neural networks, and some are not exactly in the so-called NTK regime.	I-Review	I-2	Review	172
The authors should also compare their generalization bounds with existing results for SGD (Allen-Zhu et al 2018a, Allen-Zhu &amp; Li, 2019) and [3].	I-Review	I-2	Review	172
<sep> Finally, Theorem 4 only considers one-dimensional models, which is not a very interesting problem setting.	B-Review	B-3	Review	172
Its proof might also be flawed.	I-Review	I-3	Review	172
In fact, the setting in Section 4 is not consistent with Theorem 1, since Theorem 1 requires that all inputs have unit norm and their last coordinate should be a constant.	I-Review	I-3	Review	172
For one dimensional case, this means all inputs must be the same scalar!	I-Review	I-3	Review	172
Even if we ignore the last coordinate assumption in Theorem 1, for 1D case all inputs are still reduced to +1 or -1‚Äôs.	I-Review	I-3	Review	172
<sep> <sep> <sep> [1] Difan Zou, Yuan Cao, Dongruo Zhou, Quanquan Gu, Stochastic Gradient Descent Optimizes Over-parameterized Deep ReLU Networks	O	O	Review	172
[2] Samet Oymak, Mahdi Soltanolkotabi, Overparameterized Nonlinear Learning: Gradient Descent Takes the Shortest Path?	O	O	Review	172
<sep> [3] Yuan Cao, Quanquan Gu, Generalization Bounds of Stochastic Gradient Descent for Wide and Deep Neural Networks	O	O	Review	172
[4] Difan Zou, Quanquan Gu, An Improved Analysis of Training Over-parameterized Deep Neural Networks	O	O	Review	172
<sep> <sep> <sep> <sep> <sep> We appreciate your detailed reading of the paper and thoughtful comments.	O	O	Reply	172
We have responded to these below.	O	O	Reply	172
<sep> <sep> &gt;&gt; In fact in a missed reference [2], essentially the implicit bias for both gradient descent and stochastic gradient descent has been studied.	O	O	Reply	172
The remark ‚Äúin most cases, the authors used GD to derive their results by the NTK analysis‚Äù is also not convincing...	O	O	Reply	172
<sep> <sep> Unfortunately, none of the papers you suggest show the relation between generalization and implicit regularization in over-parameterized DNN.	B-Reply	B-2	Reply	172
Especially, [2] focused on SGD convergence in various optimization problems.	I-Reply	I-2	Reply	172
<sep> <sep> They applied their results to one hidden layer neural networks and did not show generalization bounds as they said; "our results do not directly address generalization" ( in the Supplementary PDF p.14 line 30, <a href="http://proceedings.mlr.press/v97/oymak19a/oymak19a-supp.pdf" target="_blank" rel="nofollow">http://proceedings.mlr.press/v97/oymak19a/oymak19a-supp.pdf</a> ).	I-Reply	I-2	Reply	172
<sep> <sep> By contrast, our result shows that generalization bounds of DNN learned by SGD are proved by the piecewise linear interpolation between training data points.	I-Reply	I-2	Reply	172
We consider this idea itself is novel enough to submit the paper.	I-Reply	I-2	Reply	172
<sep> <sep> In order to explain clearly that DNN approximately convergent to piecewise linear interpolation between data points, we chose the one-dimensional regression problems.	I-Reply	I-2	Reply	172
Generalizing to high-dimension regimes could be achieved by applying formula (5) to prove that the empirical Rademacher complexity of DNNs is small.	I-Reply	I-2	Reply	172
<sep> <sep> Besides, none of the work has estimated generalization bounds by NTK for learning with STOCHASTIC GRADIENT DESCENT in the over-parameterized setting.	I-Reply	I-2	Reply	172
<sep> In the infinite width limit, the linear model of NTK does not hold about the information of the network structure.	I-Reply	I-2	Reply	172
In other words, for the NTK generalization bounds, we cannot investigate the effects of the number of neurons or the number of parameters.	I-Reply	I-2	Reply	172
<sep> <sep> <sep> &gt;&gt; Finally, Theorem 4 only considers one-dimensional models, which is not a very interesting problem setting...	O	O	Reply	172
<sep> <sep> As you point out, this part is certainly a little confusing, so we add some explanation to the Appendix.	B-Reply	B-3	Reply	172
<sep> <sep> Certainly, when we apply Theorem 1 to one-dimensional cases, simple preprocessing will be needed: It just consider a mapping (a half circle).	I-Reply	I-3	Reply	172
<sep> It is apparent that there exists a diffeomorphism from to.	I-Reply	I-3	Reply	172
Under this setting, the input from is the two-dimension space.	I-Reply	I-3	Reply	172
More precisely, the input needs another axis of coordinates to express the biases term.	I-Reply	I-3	Reply	172
This procedure is written in the subsection of Dataset and loss function in the paper p.4.	I-Reply	I-3	Reply	172
<sep> <sep> As a result, we deal with not the case of but the case of in Theorem 1.	I-Reply	I-3	Reply	172
<sep> <sep> In this paper, we show that the neural network is approximated by a piecewise linear interpolation between data points via SGD training and clarify the connection between the interpolation and generalization bounds.	I-Reply	I-3	Reply	172
<sep> <sep> To make clear the main points of the generalization bounds, we chose the one-dimensional regression task.	I-Reply	I-3	Reply	172
<sep> It is important to generalize to high-dimension regimes, but we leave this as a suggested direction for future research.	I-Reply	I-3	Reply	172

This paper suggests a new technique to analyze the implicit regularization caused by ReLU activations.	O	O	Review	172
They bound the generalization error by two terms: 1) one term that represents the distance between the trained network output and a piecewise linear function built based on the set of training points and 2) another term that represents the distance between the piecewise linear approximation and the desired target.	O	O	Review	172
The first term is bounded using a random walk type of analysis, which to the best of my knowledge is novel.	O	O	Review	172
<sep> I find this technique rather interesting and technically sound, although I do have a number of concerns and I'm at the moment more on the reject side, although I will re-consider my score if the authors can provide satisfactory answers.	O	O	Review	172
<sep> <sep> Generalization to more complex activation functions	O	O	Review	172
If I understand correctly, the interpolation technique between two points only works for ReLU functions.	B-Review	B-1	Review	172
If one were to try to generalize the analysis to more complex non-linear functions by using a more complex interpolation schemes, wouldn‚Äôt you then have a random walk in high-dimensions?	I-Review	I-1	Review	172
If so, wouldn‚Äôt that be a problem given the different properties of Brownian motion in high-dimensions?	I-Review	I-1	Review	172
<sep> <sep> Generalization to smooth activation functions	O	O	Review	172
Another question related to the previous one is whether one could hope to generalize the analysis to smooth activation functions.	B-Review	B-2	Review	172
I believe this is also a drawback of combinatorial techniques such as Hanin and Rolnick which have to rely on the discrete nature of the breakpoints.	I-Review	I-2	Review	172
<sep> <sep> Generalization bound is only derived for 1-d functions	O	O	Review	172
Theorem 2 is derived for each dimension independently while the generalization results in Theorem 4 are for 1-dimensional inputs.	B-Review	B-3	Review	172
Where is the difficulty in generalizing these results to higher dimensions?	I-Review	I-3	Review	172
<sep> <sep> Prior work on generalization of SGD	O	O	Review	172
I was really expecting a discussion about how the generalization bound derived in this paper compares to prior work, e.g.	B-Review	B-4	Review	172
Hardt, Moritz, Benjamin Recht, and Yoram Singer. "	I-Review	I-4	Review	172
Train faster, generalize better: Stability of stochastic gradient descent."	I-Review	I-4	Review	172
arXiv preprint arXiv:1509.01240 (2015).	I-Review	I-4	Review	172
<sep> Kuzborskij, Ilja, and Christoph H. Lampert. "	I-Review	I-4	Review	172
Data-dependent stability of stochastic gradient descent."	I-Review	I-4	Review	172
arXiv preprint arXiv:1703.01678 (2017).	I-Review	I-4	Review	172
<sep> Brutzkus, Alon, et al "Sgd learns over-parameterized networks that provably generalize on linearly separable data."	I-Review	I-4	Review	172
arXiv preprint arXiv:1710.10174 (2017).	I-Review	I-4	Review	172
<sep> And many others‚Ä¶	I-Review	I-4	Review	172
For instance the bound derived in Hardt et al is also of the order O(n^-2).	I-Review	I-4	Review	172
The bounds in Kuzborskij are also data-dependent and so are yours since your generalization bound depends on the density of the training points.	I-Review	I-4	Review	172
Can you comment on this?	I-Review	I-4	Review	172
What specific insights do we gain your analysis?	I-Review	I-4	Review	172
<sep> <sep> Noise SGD	O	O	Review	172
My understanding is that the authors assume that the noise of SGD is Gaussian.	B-Review	B-5	Review	172
Although this is commonly used when analyzing SGD, there is evidence that the noise is actually not Gaussian, see e.g.	I-Review	I-5	Review	172
Daneshmand, Hadi, et al "Escaping saddles with stochastic gradients."	I-Review	I-5	Review	172
arXiv preprint arXiv:1803.05999 (2018).	I-Review	I-5	Review	172
<sep> Simsekli, Umut, Levent Sagun, and Mert Gurbuzbalaban. "	I-Review	I-5	Review	172
A tail-index analysis of stochastic gradient noise in deep neural networks."	I-Review	I-5	Review	172
arXiv preprint arXiv:1901.06053 (2019).	I-Review	I-5	Review	172
<sep> I feel this is worth pointing out and one could perhaps also extend this analysis to Heavy-tail noise.	I-Review	I-5	Review	172
I would expect that the results would still hold in expectation but perhaps with a slightly worse probability.	I-Review	I-5	Review	172
<sep> <sep> Influence step size SGD	O	O	Review	172
Using larger step sizes in the SGD updates increase the influence of the noise.	B-Review	B-6	Review	172
I was expecting this to somehow be captured in your analysis but I fail to see where it appears.	I-Review	I-6	Review	172
Can you comment on this?	I-Review	I-6	Review	172
<sep> <sep> Proof Lemma 3	O	O	Review	172
The derivation of Eq.10 does not seem completely justified in the proof in the appendix.	B-Review	B-7	Review	172
The authors essentially prove that the length of the gradient gap is bounded by |S| but why is the coefficient \omega distributed according to a normal distribution.	I-Review	I-7	Review	172
It seems to me that you need the noise of SGD to be Gaussian for such statement to hold.	I-Review	I-7	Review	172
Can you confirm this?	I-Review	I-7	Review	172
If so, I think this needs to be clearly stated as an assumption since -- as pointed out above -- this is not necessarily true in practice.	I-Review	I-7	Review	172
<sep> <sep> Minor: proof Theorem 2	O	O	Review	172
It seems rather trivial but for completeness, you should write the proof of Eq. (6) in Theorem 2.	B-Review	B-8	Review	172
<sep> <sep> ‚ÄúA priori estimates‚Äù	O	O	Review	172
This is a terminology that is often used in the paper but never defined.	B-Review	B-9	Review	172
What do you mean by ‚Äúa priori‚Äù in this context?	I-Review	I-9	Review	172
<sep> <sep> Minor comment	O	O	Review	172
I would move footnote 3 directly in the main step.	B-Review	B-10	Review	172
I think it is important to point out that the steps of the random walk correspond to the breakpoints.	I-Review	I-10	Review	172
<sep> <sep> We appreciate your detailed reading of the paper and thoughtful comments.	O	O	Reply	172
We have responded to these below.	O	O	Reply	172
<sep> <sep> &gt;&gt;&gt; Proof Lemma 3	O	O	Reply	172
<sep> Let us explain that the coefficient is close to the initial value of the corresponding weight and is not a noise of SGD.	B-Reply	B-7	Reply	172
<sep> <sep> The following is the discussion about-th layer, and we drop the subscript for notational convenience.	I-Reply	I-7	Reply	172
<sep> is expressed as Eq. (44) in p.12.	I-Reply	I-7	Reply	172
<sep> <sep> We use to denote a weight matrix for-th layer after iterations of SGD.	I-Reply	I-7	Reply	172
In Eq. (46), we define the difference between and initial value as follows:	I-Reply	I-7	Reply	172
<sep> This is the weight change by SGD, and Theorem 1 guarantees that is small enough.	I-Reply	I-7	Reply	172
That is,, where is enough small related to the network width.	I-Reply	I-7	Reply	172
<sep> <sep> For notational convenience, let be.	I-Reply	I-7	Reply	172
We obtain the following upper bounds from Eq. (56).	I-Reply	I-7	Reply	172
58) and Eq. (	I-Reply	I-7	Reply	172
<sep> <sep> From the above, Eq. (44) can be expressed as follows:	I-Reply	I-7	Reply	172
<sep> Each weight value is initialized by He Normal, so.	I-Reply	I-7	Reply	172
Thus, because is Gaussian random value and is small enough, the sum of is `Gaussian random walk'.	I-Reply	I-7	Reply	172
<sep> <sep> From the above discussion, you can see that the coefficient is not a noise of SGD but the initial value of a weight.	I-Reply	I-7	Reply	172
<sep> <sep> <sep> &gt;&gt;&gt; proof Theorem 2	O	O	Reply	172
<sep> Thank you for your advice.	B-Reply	B-8	Reply	172
The output dimension of the last layer is while that of other layers is, so we prove Eq. (5).	I-Reply	I-8	Reply	172
6) by changing inequality in the proof of Eq. (	I-Reply	I-8	Reply	172
We already changed the paper, so please confirm.	I-Reply	I-8	Reply	172
<sep> <sep> <sep> &gt;&gt;&gt; ‚ÄúA priori estimates‚Äù	O	O	Reply	172
<sep> Thank you for your advice.	B-Reply	B-9	Reply	172
We have modified our paper to clarify what we wanted to convey by using the terminology "a priori estimates".	I-Reply	I-9	Reply	172
<sep> <sep> An a priori estimate is used in the theory of partial differential equations, but already used in machine theory for example:	I-Reply	I-9	Reply	172
Weinan E et al "A Priori Estimates for Two-layer Neural Networks", (arXiv:1810.06397).	I-Reply	I-9	Reply	172
<sep> <sep> A priori is Latin for "from before" and refers to the fact that the estimate for the solution of minimizing an objective function is derived before the solution is known to exist.	I-Reply	I-9	Reply	172
<sep> <sep> In other words, we show that in Theorem 2, the difference between the network output function and its linear interpolation is evaluated only from the amount of the weight change.	I-Reply	I-9	Reply	172
<sep> <sep> <sep> &gt;&gt;&gt;  footnote 3	O	O	Reply	172
<sep> Thank you for your advice.	B-Reply	B-10	Reply	172
We moved footnote 3 in the main step.	I-Reply	I-10	Reply	172
Please confirm.	I-Reply	I-10	Reply	172

This paper studies the adversarial robustness of neural networks by giving theoretical guarantees, providing statistical estimators and running experiments.	O	O	Review	20329
It is a lot of work and it is reasonably written.	B-Review	B-1	Review	20329
The problem is that a fair bit of it is quite basic: for example the measurability property is very much expected -- noone was doubting it, and the proof is more of a formality than a contribution.	I-Review	I-1	Review	20329
Similarly with the statistical sampling: the method seems to rely on i.i.d.	B-Review	B-2	Review	20329
sampling -- has this reviewer missed any important details?	I-Review	I-2	Review	20329
If not, then it's only the bounds that are a contribution, but the method is not.	I-Review	I-2	Review	20329
We would appreciate more specific description of the main contribution, without it we cannot recommend the acceptance of this paper.	I-Review	I-2	Review	20329
<sep> <sep> I am very grateful to the authors for their response.	O	O	Review	20329
I feel now that a main weakness of this paper may be that it puts too many results in one place.	B-Review	B-3	Review	20329
I would strongly suggest re-writing it, possibly into separate papers, to make the things pointed out in the response more clear and self-standing.	I-Review	I-3	Review	20329
Reviewer:  the measurability property is very much expected ‚Äì no one was doubting it, and the proof is more of a formality than a contribution.	O	O	Reply	20329
<sep> <sep> Response:	O	O	Reply	20329
<tab>We agree with the reviewer that measurability of global robustness for neural networks can be expected.	B-Reply	B-1	Reply	20329
<sep> Nevertheless, we argue that this has to be shown explicitly.	I-Reply	I-1	Reply	20329
In particular, we have to formally establish the measurably of and to guarantee that we are dealing with well defined random variables.	I-Reply	I-1	Reply	20329
Without this, we cannot guarantee the validity of the bounds in Theorem  1 and 2.	I-Reply	I-1	Reply	20329
For further details on this issue, see  Chapter 5 in [Richard M. Dudley.	I-Reply	I-1	Reply	20329
Uniform central limit theorems.	I-Reply	I-1	Reply	20329
No.	I-Reply	I-1	Reply	20329
63.	I-Reply	I-1	Reply	20329
Cambridge university press, 1999].	I-Reply	I-1	Reply	20329
<sep> Reviewer:  has  this  reviewer  missed  any  important  details?	O	O	Reply	20329
If  not,  then  it‚Äôs  only  the bounds that are a contribution, but the method is not.	O	O	Reply	20329
We would appreciate more specific description of the main contribution, without it we cannot recommend the acceptance of this paper.	O	O	Reply	20329
<sep> <sep> Response:	O	O	Reply	20329
<tab>While Chernoff bounds are well known, the main contribution of this paper lies in the development of a framework for the computation of global adversarial robustness with a-priori statistical guarantees (provided by the Chernoff's bound), which we use to investigate the robustness of different neural network architectures and training paradigms.	B-Reply	B-2	Reply	20329
This allow us to confirm and quantify previously reported results on the trade-off between generalisation accuracy and adversarial robustness of neural networks, demonstrated through a large-scale study.	I-Reply	I-2	Reply	20329
We then investigate the relationship between model capacity and model robustness in iterative magnitude pruning settings.	I-Reply	I-2	Reply	20329
We find that weight pruning does not increase robustness despite greatly reducing model capacity.	I-Reply	I-2	Reply	20329
Finally, we evaluate the robustness of Bayesian neural networks and compare it with their deterministic counterparts, which, to the best of our knowledge, had never been evaluated.	I-Reply	I-2	Reply	20329
Our finding that BNNs are more robust wrt gradient-based attacks, in our opinion, warrants further exploration into the use of BNN models in safety-critical scenarios.	I-Reply	I-2	Reply	20329

Summary:	O	O	Review	20329
<sep> The paper formally defines local and global adversarial robustness.	O	O	Review	20329
Following that, the paper investigates how to estimate local and global adversarial robustness using an estimator based on evaluating these quantities on the empirical distribution.	O	O	Review	20329
Using a Chernoff bound, the papers evaluate probabilistic bounds on the deviation of the estimated quantities from the true quantities.	O	O	Review	20329
Finally, simulations are provided to evaluate these bounds for examples.	O	O	Review	20329
<sep> <sep> Comments:	O	O	Review	20329
<sep> The authors' insistence on their contribution being proving measurability does not make sense -- of course everything is measurable!	B-Review	B-2	Review	20329
Furthermore, the formal definitions or local and global robustness are well-known, the bounds in Theorems 1 and 2 are not novel and highly unlikely to be tight.	I-Review	I-2	Review	20329
The redeeming aspect of the paper is the experiments, where the authors show that these bounds can actually be (approximately) calculated.	B-Review	B-3	Review	20329
However, I feel that merely experimental results with correct but not significant theoretical contributions does not meet the bar for acceptance.	I-Review	I-3	Review	20329
Reviewer: The authors‚Äô insistence on their contribution being proving measurability does not make sense ‚Äì of course everything is measurable!	O	O	Reply	20329
<sep> <sep> Response:	O	O	Reply	20329
<tab>We would like to disagree on this point.	B-Reply	B-1	Reply	20329
While it is true that the main contributions of the paper do not lie in the measurability proof, and that  measurability of the global robustness property for neural networks is expected, this has to be shown explicitly.	I-Reply	I-1	Reply	20329
It is not possible to substantiate the claim on statistical guarantees by any other means.	I-Reply	I-1	Reply	20329
In particular, we have to formally establish the measurability of and to ensure that we are dealing with well defined random variables.	I-Reply	I-1	Reply	20329
Without this, we cannot guarantee the validity of the bounds in Theorem  1 and 2.	I-Reply	I-1	Reply	20329
See for instance Chapter 5 in [Richard M. Dudley.	I-Reply	I-1	Reply	20329
Uniform central limit theorems.	I-Reply	I-1	Reply	20329
No.	I-Reply	I-1	Reply	20329
63.	I-Reply	I-1	Reply	20329
Cambridge university press, 1999].	I-Reply	I-1	Reply	20329
<sep> <sep> Reviewer: The  formal  definitions  of  local  and  global  robustness  are  well-known,  the bounds in Theorems 1 and 2 are not novel and highly unlikely to be tight.	O	O	Reply	20329
<sep> <sep> Response:	O	O	Reply	20329
<tab>We agree with the reviewer that definitions of local and global robustness are already known and used in practice.	B-Reply	B-2	Reply	20329
This is the reason why in this paper we propose a framework to study these quantities with statistical guarantees.	I-Reply	I-2	Reply	20329
In fact, although concentration inequalities and Chernoff bounds are well known techniques, these have been not been used before to establish global robustness.	I-Reply	I-2	Reply	20329
Moreover, Theorems 1 and 2 can be quite accurate in practice and the resulting number of samples required is generally under control.	I-Reply	I-2	Reply	20329
This is illustrated empirically in Figure 1 and discussed in Section 4.1  in  the  main  text.	I-Reply	I-2	Reply	20329
Moreover,  the  tightness  of  Chernoff  bounds  is  discussed  in  Chapter  4.1  in [Vapnik,  V. N. (1998).	I-Reply	I-2	Reply	20329
Statistical Learning Theory.	I-Reply	I-2	Reply	20329
Wiley-Interscience.],	I-Reply	I-2	Reply	20329
where it is shown that in case of Bernoulli random variables with probability of a half these bounds cannot be improved.	I-Reply	I-2	Reply	20329
<sep> <sep> <sep> Reviewer:  The  redeeming  aspect  of  the  paper  is  the  experiments,  where  the  authors show that these bounds can actually be (approximately) calculated.	O	O	Reply	20329
However, I feel that merely  experimental  results  with  correct  but  not  significant  theoretical  contributions does not meet the bar for acceptance.	O	O	Reply	20329
<sep> <sep> Response:	O	O	Reply	20329
<tab>We would like to stress that the main contribution of this paper lies in the development of a framework for the computation of global adversarial robustness with a-priori statistical guarantees.	B-Reply	B-3	Reply	20329
We first show that these bounds can be used for neural networks, and then we apply them to investigate the  robustness  of  different  neural  network  architectures  and  training  paradigms.	I-Reply	I-3	Reply	20329
This  allows  us  to confirm and quantify previously reported results on the trade-off between generalisation accuracy and adversarial robustness of neural networks.	I-Reply	I-3	Reply	20329
We then investigate the relationship between model capacity and model robustness in iterative magnitude pruning settings.	I-Reply	I-3	Reply	20329
We find that weight pruning does not increase  robustness  despite  greatly  reducing  model  capacity.	I-Reply	I-3	Reply	20329
Finally,  we  evaluate  the  robustness  of Bayesian neural networks and compare it with their deterministic counterpart, which, to the best of our knowledge, had never been evaluated.	I-Reply	I-3	Reply	20329
Our finding that BNNs are more robust wrt gradient based attacks,  in  our  opinion,  warrants  further  exploration  into  the  use  of  BNN  models  in  safety-critical scenarios.	I-Reply	I-3	Reply	20329

<sep> This paper tackles an issue imitation learning approaches face.	O	O	Review	547
More specifically, policies learned in this manner can often fail when they encounter new states not seen in demonstrations.	O	O	Review	547
The paper proposes a method for learning value functions that are more conservative on unseen states, which encourages the learned policies to stay within the distribution of training states.	O	O	Review	547
Theoretical results are derived to provide some support for the approach.	O	O	Review	547
A practical algorithm is also presented and experiments on continuous control tasks display the effectiveness of the method, with particularly good results on imitation learning followed by reinforcement learning.	O	O	Review	547
<sep> <sep> The proposed algorithm makes use of a natural intuition, that states visited by the expert probably have higher values, and the paper generally does a good job of supporting the approach through theory and experiments.	B-Review	B-1	Review	547
Although the experiments seem sound, certain experimental details are not completely clear.	I-Review	I-1	Review	547
The theory may also have some restrictive assumptions, limiting its significance.	I-Review	I-1	Review	547
<sep> Overall, I am divided about this paper.	O	O	Review	547
While this submission has the elements of a good paper and the presentation is great, certain concerns make me hesitant to recommend acceptance.	O	O	Review	547
I would be willing to increase my score if those points are addressed.	O	O	Review	547
<sep> <sep> Theory:	O	O	Review	547
1) My main concern is the applicability of the theorem, due to Assumption 4.2.	B-Review	B-2	Review	547
While the intuition is that there is an action that corrects the next state towards the demonstration states, the theoretical condition is more restrictive.	I-Review	I-2	Review	547
In particular, the following part (paraphrasing): "there exists an action a_cx that is close to a^bar and that makes a correction towards U".	I-Review	I-2	Review	547
This condition implies that there are correcting actions near any action a^bar, which sems unrealistic in most cases.	I-Review	I-2	Review	547
For example, in a driving task, say s^bar is a state such that moving back to U require the vehicle to move to the left.	I-Review	I-2	Review	547
Then, consider the action a^bar of steering towards the right (with some angle).	I-Review	I-2	Review	547
There could be no action near a^bar that makes the vehicle turn left towards U. Note that this is not necessarily a pathological situation as described in the text.	I-Review	I-2	Review	547
<sep> <sep> 2) Also concerning assumption 4.2, I do not see why s^bar' is included in the quantifier of the statement since it is not used afterwards; after "there exists an action..." no mention of s^bar' is made.	B-Review	B-3	Review	547
<sep> <sep> 3) The projection function may not be well-defined if there are multiple states that are closest to the one being projected.	B-Review	B-4	Review	547
<sep> <sep> 4) It could be said explicitly that the expert policy is assumed to be deterministic.	B-Review	B-5	Review	547
Currently, this is not said outright.	I-Review	I-5	Review	547
<sep> <sep> Experiments:	O	O	Review	547
1) It seems like VINS relies heavily on the assumption that the environment is deterministic to learn an effective model.	B-Review	B-6	Review	547
Was VINS tried in stochastic environments?	I-Review	I-6	Review	547
<sep> <sep> 2) Data augmentation is used for VINS.	B-Review	B-7	Review	547
This seems like an unfair advantage compared to the baseline competitors since sample efficiency is a key concern to reinforcement learning algorithms.	I-Review	I-7	Review	547
To make the comparisons fair, either it should be removed or the other algorithms should also receive additional data.	I-Review	I-7	Review	547
How is the performance of VINS without this addition?	I-Review	I-7	Review	547
<sep> <sep> 3) A description of how the hyperparameters were chosen and their final values would be needed for reproducibility.	B-Review	B-8	Review	547
Also, a discussion of the importance of the hyperparameters and their sensitivity would be informative.	I-Review	I-8	Review	547
For example, I was curious to know the value of \alpha in Algorithm 2 compared to the ranges the actions could take.	I-Review	I-8	Review	547
<sep> <sep> 4) I am not convinced that using Q functions would necessarily fail.	B-Review	B-9	Review	547
On p.6, the paragraph "can we learn conservatively-extrapolated Q-function" gives some reasoning why this could fail, that we may not want to penalize unseen actions.	I-Review	I-9	Review	547
This is in opposition to the BCQ algorithm [1], which explicitly tries to avoid unseen actions and still has good performance.	I-Review	I-9	Review	547
Trying a variant with Q(s,a) could be worthwhile.	I-Review	I-9	Review	547
<sep> I am not exactly sure if I understood Appendix A properly but, from my understanding, I do not think the argument made there necessarily invalidates using Q functions.	I-Review	I-9	Review	547
It seems to apply mostly to deterministic expert policies and also Q(s,a) could still have reasonable values due to function approximation (even if the particular action 'a' is not seen in demonstrations).	I-Review	I-9	Review	547
<sep> <sep> 5) Which RL algorithms were used for the imitation learning + RL set of experiments?	B-Review	B-10	Review	547
<sep> <sep> 6) For table 1, are the results also averaged over different sets of demonstrations?	B-Review	B-11	Review	547
<sep> <sep> 7) Are error bars one standard deviation or one standard error (divided by sqrt(n))?	B-Review	B-12	Review	547
<sep> <sep> 8) For figure 3, using RL without imitation learning would serve as a good additional baseline	B-Review	B-13	Review	547
<sep> 9) Ablation study: Trying no negative sampling with a perfect model could isolate the effect of negative sampling.	B-Review	B-14	Review	547
<sep> <sep> 10) Ablation study: What is the no behavior cloning and perfect model experiment trying to show?	B-Review	B-15	Review	547
<sep> <sep> 11) I think the name of the algorithm should be modified as "value iteration" refers to a specific dynamic programming algorithm for learning value functions, while the proposed algorithm does not resemble this at all.	B-Review	B-16	Review	547
<sep> <sep> Minor comments and typos (no impact on score):	B-Review	B-17	Review	547
- Using the cross-entropy method as in QTOpt [2] could be used to pick actions in a more refined manner.	I-Review	I-17	Review	547
<sep> - There is a large amount of blank space on p.8	I-Review	I-17	Review	547
- p.3 "At the test time" -&gt; "At test time"	I-Review	I-17	Review	547
- p.4 "entire states space" -&gt; "entire state space", "burned to warm up them" -&gt; "burned to warm them up"	I-Review	I-17	Review	547
- p.9  "option 2 by search the action uniformly."	I-Review	I-17	Review	547
-&gt; "option 2 to search the actions uniformly"	I-Review	I-17	Review	547
<sep> [1] "Off-Policy Deep Reinforcement Learning without Exploration" by Fujimoto et al	O	O	Review	547
[2] "QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation" by Kalashnikov et al	O	O	Review	547
<sep> Q5: ‚ÄúWhich RL algorithms were used for the imitation learning + RL set of experiments?‚Äù	O	O	Reply	547
<sep> We use a simple variant of model-based value iteration algorithm, the detailed description of which is deferred to Appendix C due to page limit.	B-Reply	B-10	Reply	547
We design this new algorithm so that we can use the value and the dynamics learned from VINS more easily.	I-Reply	I-10	Reply	547
(We also briefly mentioned it at the last paragraph of Section 5. )	I-Reply	I-10	Reply	547
<sep> <sep> Q6: ‚ÄúFor table 1, are the results also averaged over different sets of demonstrations? ‚	O	O	Reply	547
Äú	O	O	Reply	547
<sep> No, we only tried one set of demonstration following the setting in  [1].	B-Reply	B-11	Reply	547
<sep> Q7: ‚ÄúAre error bars one standard deviation or one standard error (divided by sqrt(n))?‚Äù	O	O	Reply	547
<sep> It‚Äôs one standard error.	B-Reply	B-12	Reply	547
We have made this more explicit in the revision.	I-Reply	I-12	Reply	547
<sep> <sep> Q8: ‚ÄúFor figure 3, using RL without imitation learning would serve as a good additional baseline ‚Äú	O	O	Reply	547
<sep> Thanks for the suggestion.	B-Reply	B-13	Reply	547
Our understanding is that for the sparse reward tasks, the best RL algorithms are HER [2] that we used to generate the expert policy.	I-Reply	I-13	Reply	547
As reported by Andrychowicz et al [2], Figure 3, these algorithms typically require 2 million steps to achieve near optimal success rate (e.g., 95%), whereas our algorithm needs about 100K.	I-Reply	I-13	Reply	547
<sep> Q9: ‚ÄúAblation study: Trying no negative sampling with a perfect model could isolate the effect of negative sampling. ‚	O	O	Reply	547
Äú	O	O	Reply	547
<sep> Thanks for the suggestions.	B-Reply	B-14	Reply	547
This is indeed a very useful ablation study in addition to those in Table 2.	I-Reply	I-14	Reply	547
We conducted the suggested experiment and found that indeed no negative sample (NS) with oracle mode is significantly worse than negative sample with oracle model as shown below.	I-Reply	I-14	Reply	547
<sep> (Here PickAndPlace-100 means that we have 100 trajectories in the demonstration.)	I-Reply	I-14	Reply	547
<sep> <sep> PickAndPlace-100:	I-Reply	I-14	Reply	547
Oracle model w/o NS: 47.2 +/- 1.9%; oracle model w/  NS: 76.3 +/- 1.4%	I-Reply	I-14	Reply	547
PickAndPlace-200:	I-Reply	I-14	Reply	547
Oracle model w/o NS: 74.3 +/- 1.0%; oracle model w/ NS: 87.0 +/- 0.7%	I-Reply	I-14	Reply	547
Push-100:	I-Reply	I-14	Reply	547
Oracle model w/o NS: 30.7 +/- 0.8%; oracle model w/ NS: 48.7 +/- 1.2%	I-Reply	I-14	Reply	547
Push-200:	I-Reply	I-14	Reply	547
Oracle model w/o NS: 41.3 +/- 0.8%; oracle model w/NS: 63.8 +/- 1.3%	I-Reply	I-14	Reply	547
(Please see Table 3 in Appendix E in the revision for a formal table.)	I-Reply	I-14	Reply	547
<sep> <sep> Q10: ‚ÄúAblation study: What is the no behavior cloning and perfect model experiment trying to show?‚Äù	O	O	Reply	547
<sep> By comparing VINS w/ perfect  w/o BC and VINS w/o BC, we can see how a better model improves the performance (even if BC is not used.)	B-Reply	B-15	Reply	547
In reality, it‚Äôs conceivable that the dynamics can be learned more accurately through other means (by using prior knowledge, or by collecting more data with random exploration, etc.),	I-Reply	I-15	Reply	547
and thus these experiments also suggest that our methods have a potential to perform better if the dynamics can be more accurate.	I-Reply	I-15	Reply	547
<sep> <sep> <sep> Q11: ‚ÄúI think the name of the algorithm should be modified as "value iteration" refers to a specific dynamic programming algorithm for learning value functions, while the proposed algorithm does not resemble this at all. ‚	O	O	Reply	547
Äú	O	O	Reply	547
<sep> Our algorithm VINS does learn value functions with iterative Bellman equation updates.	B-Reply	B-16	Reply	547
We note that in line 4 of Algorithm 2, when we minimize the part of the loss, we minimize the Bellman error.	I-Reply	I-16	Reply	547
In our view, this can be viewed as an approximate dynamic programming. (	I-Reply	I-16	Reply	547
But we are also happy to consider other names if the reviewer has some suggestions.)	I-Reply	I-16	Reply	547
<sep> <sep> Minor comments:	O	O	Reply	547
Thanks for pointing out the typos.	B-Reply	B-17	Reply	547
We‚Äôll fix them in the next version.	I-Reply	I-17	Reply	547
<sep> <sep> For QT-Opt: Thanks for your kind suggestion.	B-Reply	B-17	Reply	547
Yes, we agree that better optimization algorithms might result  in superior performance.	I-Reply	I-17	Reply	547
We will mention this as a potential extension of our algorithm.	I-Reply	I-17	Reply	547
<sep> <sep> [1] Overcoming Exploration in Reinforcement Learning with Demonstrations, Nair et al	O	O	Reply	547
[2] Hindsight Experience Replay, Andrychowicz et al	O	O	Reply	547

This work presents the value iteration with negative sampling (VINS) algorithm, a method for accelerating reinforcement learning using expert demonstrations.	O	O	Review	547
In addition to learning an expert policy through behavioral cloning, VINS learns an initial value function which is biased to assign smaller expected values to states not encountered during demonstrations.	O	O	Review	547
This is done by augmenting the demonstration data with states that have been randomly perturbed, and penalizing the value targets for these states by a factor proportional to their Euclidean distance to the original state.	O	O	Review	547
In addition to the policy and value function, VINS also learns a one-step dynamics model used to select actions against the learned value function.	O	O	Review	547
As the value function learned in VINS is only defined with respect to the current state, action values are estimated by sampling future states using the learned model, and computing the value of these sampled states.	O	O	Review	547
<sep> <sep> Empirical results on a set of robotic control tasks demonstrate that VINS requires significantly less interaction with the environment to learn a good policy than existing, state of the art approaches given the same set of demonstrations.	O	O	Review	547
While the paper presents a novel and highly effective approach, there are some apparent limitations to the algorithms which should be highlighted, and there is room for improvement in the empirical evaluations.	O	O	Review	547
<sep> <sep> It is unclear that VINS would generalize well beyond robotic control domains.	B-Review	B-1	Review	547
For one, its theoretical guarantees depend on the local reversibility of the dynamics, that is, for small deviations from the desired state, it is possible to return to that state in a single step.	B-Review	B-2	Review	547
This isn't too significant a restriction, as the ability to recover quickly from small mistakes would seem to be a necessary for any method to be able to provide similar guarantees about its behavior.	I-Review	I-2	Review	547
The bigger issue is the use of the Euclidean metric (or any fixed metric) in the definition of conservative extrapolation.	B-Review	B-1	Review	547
Basically, a state is said to be similar to the states observed during the demonstrations if it is close, under the Euclidean metric, to at least one demonstrated state.	I-Review	I-1	Review	547
This is a reasonable approach in robotic control tasks, where Euclidean distance is a good measure of how similar two configurations are to one another, but it would seem to be unsuitable for domains where the observation space consists of images or other high-dimensional representations.	I-Review	I-1	Review	547
In those cases, a useful notion of similarity would likely have to be learned from the data.	I-Review	I-1	Review	547
In such domains, one might imagine that the conservative value function would simply learn to distinguish between real observations, and those that have been perturbed by random noise, which would never be observed in the actual task.	I-Review	I-1	Review	547
<sep> <sep> While experimental results demonstrate a very significant advantage for VINS both in terms of sample complexity and final performance, results are presented for only two tasks, 'pick-and-place' and 'push', while VINS outperforms the alternatives on these tasks, it is worth noting that its initial performance (without additional environment interact) is not dramatically superior to pure behavioral cloning.	B-Review	B-3	Review	547
It would be helpful to see how well VINS compares against the alternatives for a much smaller number of demonstrations, say 5-20, a regime where we would expect initial performance to be poor.	I-Review	I-3	Review	547
We thank the anonymous reviewer 2 for the helpful comments.	O	O	Reply	547
The review noted that our method is ‚Äúa novel and highly effective approach‚Äù and ‚Äúhas a very significant advantage both in terms of sample complexity and final performance‚Äù.	O	O	Reply	547
The reviewer also has many constructive questions and comments which we will address below.	O	O	Reply	547
<sep> <sep> <sep> &gt; ‚ÄúFor one, its theoretical guarantees depend on the local reversibility of the dynamics, that is, for small deviations from the desired state, it is possible to return to that state in a single step.	O	O	Reply	547
This isn't too significant a restriction, as the ability to recover quickly from small mistakes would seem to be a necessary for any method to be able to provide similar guarantees about its behavior.	O	O	Reply	547
‚Äú	O	O	Reply	547
We agree with the reviewer on the point that the local-correctability is key to VINS and is suitable for robotic control problems.	B-Reply	B-2	Reply	547
<sep> <sep> &gt; ‚ÄúIt is unclear that VINS would generalize well beyond robotic control domains. ‚	O	O	Reply	547
Ä¶ The bigger issue is the use of the Euclidean metric (or any fixed metric) in the definition of conservative extrapolation.	O	O	Reply	547
‚Äù	O	O	Reply	547
We agree with the reviewer Euclidean metric are not applicable to certain situations such as pixel space.	B-Reply	B-1	Reply	547
We design the algorithm to learn self-correctable policies in the robotic control domain.	I-Reply	I-1	Reply	547
Indeed, we do not expect the technique can directly work in a pixel space as it is.	I-Reply	I-1	Reply	547
However, we believe that applying perturbation to the latent representation of images would be a very  promising and interesting direction for future work.	I-Reply	I-1	Reply	547
Concretely, it‚Äôs conceivable that the metric can be the Euclidean distance between the latent representations of the states. (	I-Reply	I-1	Reply	547
Our theory still applies to this metric, though the metric needs to be learnt.)	I-Reply	I-1	Reply	547
<sep> &gt; ‚ÄúIt would be helpful to see how well VINS compares against the alternatives for a much smaller number of demonstrations, say 5-20, a regime where we would expect initial performance to be poor.	O	O	Reply	547
‚Äù	O	O	Reply	547
<sep> Thanks for the suggestions.	B-Reply	B-3	Reply	547
For the Reach environment, we run our algorithm on 10 demonstration trajectories.	I-Reply	I-3	Reply	547
And the result is:	I-Reply	I-3	Reply	547
<sep> VINS = 99.3 +/- 0.1%, BC = 98.6 +/- 0.1%.	I-Reply	I-3	Reply	547
<sep> <sep> For Push and PickAndPlace environment, we found BC (and VINS) have very low success rate (below 20%) with less than 20 trajectories, and therefore we suspect the results are not very meaningful.	I-Reply	I-3	Reply	547
Thus, we conducted experiments on 40 demonstration trajectories.	I-Reply	I-3	Reply	547
The results are:	I-Reply	I-3	Reply	547
<sep> PickAndPlace-40: VINS = 40.0 +/- 0.9%, BC = 36.3 +/- 1.7%	I-Reply	I-3	Reply	547
Push-40: VINS = 26.5 +/- 0.6%, BC = 23.5 +/- 0.7%	I-Reply	I-3	Reply	547
<sep> (Please see Table 4 in Appendix E of the revision for a formal table.)	I-Reply	I-3	Reply	547

This work tried to address the covariate shift problem in imitation learning, which is due to the mismatch between training and test state distribution and may cause compounding errors.	B-Review	B-3	Review	547
<sep> <sep> The authors proposed the algorithm called value iteration with negative sampling (VINS) of which the main ideas can be summarized as follows.	O	O	Review	547
First, value iteration is used on expert trajectories with negative sampling.	O	O	Review	547
Specifically, the states that are randomly perturbed from expert‚Äôs states were used to enforce (4.1) and (4.2) in the submission (called *conservative extrapolation* requirements in the submission).	O	O	Review	547
By doing so, the state values outside the support of expert state visitation distribution become less than those inside the support.	O	O	Review	547
In the meantime, temporal-difference (TD) error was minimized to satisfy Bellman consistency among state values.	O	O	Review	547
The second main idea of this work is to use *self-correctable policy*, where the approximate dynamics and behavioral-cloning (BC) policy were used to select the action which is expected to give higher value at the successor states.	O	O	Review	547
<sep> <sep> To consolidate their ideas, the authors proved Theorem 4.4 showing that state visitation distribution of resultant policy is approximately close to that of an expert under a few assumptions.	O	O	Review	547
Empirically, they considered two experiments.	O	O	Review	547
In the first experiment, assuming that the environment simulation is not allowed, the performance of VINS was compared with that of BC over 5 tasks, and VINS achieved higher success rates.	O	O	Review	547
In the second experiment, assuming the simulation is allowed, VINS was compared with existing methods such as HER+BC, GAIL and Nair et al ‚Äò18 and shown to be much more sample-efficient compared to the selected baselines.	O	O	Review	547
<sep> <sep> Although the theoretical and empirical contributions of this work are clear to me when the environment simulation is not allowed (as shown in the first experiment in Table 1), I think the second experiment, which allows the environment simulation (as shown in Figure 3), is misleading, and this is why I vote weak reject for this work.	B-Review	B-1	Review	547
For instance, we can simply think about GAIL with BC initialization, but it seems to me that GAIL with random initialization was used in the second experiment (since authors mentioned GAIL in OpenAI baselines was used without hyperparameter tuning (<a href="https://github.com/openai/baselines/blob/master/baselines/gail/run_mujoco.py#L53))."	I-Review	I-1	Review	547
target="_blank" rel="nofollow">https://github.com/openai/baselines/blob/master/baselines/gail/run_mujoco.py#L53)).</a> In addition to it, there have been some recent works on the sample efficiency of imitation learning with environment simulation which are not included as baselines in this work:	I-Review	I-1	Review	547
<sep> [1] GMMIL (Kim and Park, 2018, ‚ÄúImitation Learning via Kernel Mean Embedding‚Äù) - cost learning with maximum mean discrepancy minimization leads to sample-efficient training	I-Review	I-1	Review	547
<sep> [2] BGAIL (Jeon et al, 2019, ‚ÄúBayesian Approach to Generative Adversarial Imitation Learning‚Äù) - Bayesian cost is helpful for sample-efficient imitation learning	I-Review	I-1	Review	547
<sep> [3] DAC (Kostrikov et al, 2019, ‚ÄúDiscriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning‚Äù) - Solving reward bias in imitation learning with simulation and using off-policy RL algorithm to enhance the sample efficiency	I-Review	I-1	Review	547
<sep> [4] Sasaki et al, 2019, ‚ÄúSample Efficient Imitation Learning for Continuous Control‚Äù - Bypassing cost learning and introducing off-policy RL to enhance the sample efficiency.	I-Review	I-1	Review	547
<sep> <sep> Especially, off-policy imitation learning methods [3], [4] are shown to be extremely sample-efficient compared to GAIL.	B-Review	B-2	Review	547
I think the authors should have compared the performance of VINS + RL with those baselines in the second experiment if they tried to emphasize the sample efficiency of VINS + RL.	I-Review	I-2	Review	547
Otherwise, they should have focused more on the initialization effect of VINS and BC.	I-Review	I-2	Review	547
For example, one can consider the convergence speed of GAIL to the expert performance when policies were initialized with either VINS or BC.	I-Review	I-2	Review	547
We thank the reviewer for the helpful comments.	O	O	Reply	547
The review noted that VINS ‚Äúachieved higher success rates‚Äù and is ‚Äúshown to be much more sample-efficient compared to the selected baselines‚Äù.	O	O	Reply	547
We have updated with the references that the reviewer kindly suggested, and added additional experiments in the revision.	O	O	Reply	547
We‚Äôll address the comments below.	O	O	Reply	547
<sep> <sep> ---  ‚ÄúAlthough the theoretical and empirical contributions of this work are clear to me when the environment simulation is not allowed (as shown in the first experiment in Table 1), I think the second experiment, which allows the environment simulation (as shown in Figure 3), is misleading, and this is why I vote weak reject for this work.	O	O	Reply	547
For instance, we can simply think about GAIL with BC initialization, but it seems to me that GAIL with random initialization was used in the second experiment (since authors mentioned GAIL in OpenAI baselines was used without hyperparameter tuning (<a href="https://github.com/openai/baselines/blob/master/baselines/gail/run_mujoco.py#L53))."	O	O	Reply	547
target="_blank" rel="nofollow">https://github.com/openai/baselines/blob/master/baselines/gail/run_mujoco.py#L53)).</a>	O	O	Reply	547
‚Äú	O	O	Reply	547
<sep> In the work of Sasaki et al, 2019 [4], section 5.3, the authors have empirically showed, somewhat surprisingly, that BC-initialized GAIL does work not better than BC itself.	B-Reply	B-1	Reply	547
We also run the experiment on our tasks and find out that the performance of BC initialized GAIL is also not better than vanilla GAIL.	I-Reply	I-1	Reply	547
Please see Figure 3 of the revision for the curve of BC+GAIL.	I-Reply	I-1	Reply	547
<sep> <sep> In general, we do think the baselines that we compare are a set of strong baselines for the manipulation tasks that we are working on.	I-Reply	I-1	Reply	547
We also note that because we are working with the setting where a sparse reward function is available when environment interaction is allowed, there are a broader set of RL algorithms to use with environment interactions beyond GAIL-related approaches.	I-Reply	I-1	Reply	547
We focus on the sparse reward setting because we believe that in many real-world robotic applications a sparse reward is available, and the main goal of imitation learning in this case is to improve the sample efficiency.	I-Reply	I-1	Reply	547
In this setting,  GAIL is apparently not very competitive (partly because it does not use the sparse reward).	I-Reply	I-1	Reply	547
This is also a reason why we are not centering  our work around comparing with GAIL (and its related work), because we are using more information than GAIL uses (and thus achieve better performance).	I-Reply	I-1	Reply	547
Instead, we focus more on comparing with the strong baselines reported in Nair et al	I-Reply	I-1	Reply	547
<sep> ---  ‚ÄúI think the authors should have compared the performance of VINS + RL with those baselines in the second experiment if they tried to emphasize the sample efficiency of VINS + RL.	O	O	Reply	547
Otherwise, they should have focused more on the initialization effect of VINS and BC.	O	O	Reply	547
For example, one can consider the convergence speed of GAIL to the expert performance when policies were initialized with either VINS or BC.	O	O	Reply	547
In addition to it, there have been some recent works on the sample efficiency of imitation learning with environment simulation which are not included as baselines in this work. ‚	O	O	Reply	547
Äù	O	O	Reply	547
<sep> Thanks for the suggestion of the references and baselines.	B-Reply	B-2	Reply	547
We have cited these papers.	I-Reply	I-2	Reply	547
Following the suggestion, we run the official code of  the DAC algorithm in [3] on our environments.	I-Reply	I-2	Reply	547
The result is formally reported in Figure 3 of the revision.	I-Reply	I-2	Reply	547
Unfortunately, DAC couldn‚Äôt get any non-trivial reward within 100K samples.	I-Reply	I-2	Reply	547
<sep> <sep> We would like to note that VINS cannot and perhaps should not be used to initialize GAIL because the strength of VINS is to provide a good initial value function.	I-Reply	I-2	Reply	547
If we only use the policy learned from VINS to initialize GAIL or other RL algorithms, then very likely it won‚Äôt be better than using BC to initialize them.	I-Reply	I-2	Reply	547
The strength of VINS is that it  provides a good value function and dynamics so that a value-based RL algorithm can be initialized with a good initialization of value function, Q-function, and policy.	I-Reply	I-2	Reply	547
Please see Appendix C for the precise RL algorithm we use, and how we make it compatible with VINS.	I-Reply	I-2	Reply	547
We cannot initialize the policy of a generic RL algorithm to see the benefit of VINS.	I-Reply	I-2	Reply	547
We consider this as the main contribution of VINS --- it allows us to fully initialize value-based RL algorithms.	I-Reply	I-2	Reply	547

The authors propose an approach for calibrated predictions under domain shift scenarios.	O	O	Review	801
The approach, that leverages (unlabeled) test samples allows for unsupervised post-processing calibration, even for off-the-shelf models for which the training data is not available.	O	O	Review	801
Experiments compare the proposed approach with existing calibration methods in shifted domains.	O	O	Review	801
<sep> <sep> Equation (5) is confusing.	B-Review	B-1	Review	801
If I understand correctly, the authors are simply making the point that q(x,y=k) can be written in terms of q(x,y\neq k) by weighting by the ratio of conditionals, which are available.	I-Review	I-1	Review	801
<sep> <sep> Sensitivity to noisy labels.	B-Review	B-2	Review	801
The experiment is reasonable and the results are convincing, however, the authors do not justify why accurate (manual) labels on the target set are not feasible in many applications.	I-Review	I-2	Review	801
The authors could point to a few examples for context.	I-Review	I-2	Review	801
<sep> <sep> The authors assume that q_s(y) = q_t(y), which seems restrictive in practice.	B-Review	B-3	Review	801
Though it does not impact my opinion of the proposed approach, it seems narrow to think of a practical situation where the space of covariates is changing but the class composition remains unchanged.	I-Review	I-3	Review	801
This is vaguely addressed in Section 6.	I-Review	I-3	Review	801
Perhaps it can be elaborated further.	I-Review	I-3	Review	801
<sep> <sep> I enjoyed reading the paper, the proposed reinterpretation of NLL in terms of a weighted average and its approximation based on weights that do not depend on the labels but the (assumed known) labels marginal is interesting and seems to yield good results.	O	O	Review	801
Thank you for your insightful comments, and we are happy that you find the paper interesting.	O	O	Reply	801
We address your concerns and add some parts to the paper accordingly:	O	O	Reply	801
<sep> Concerns:	O	O	Reply	801
1- Equation (5) is confusing.	O	O	Reply	801
<sep> <sep> We mean exactly the point that the reviewer mentioned.	B-Reply	B-1	Reply	801
As it was not clear in the text, we rewrite Eq.(5) explanation to make it more clear and precise.	I-Reply	I-1	Reply	801
<sep> <sep> 2- the authors do not justify why accurate (manual) labels on the target set are not feasible in many applications.	O	O	Reply	801
The authors could point to a few examples for context.	O	O	Reply	801
<sep> <sep> We add three examples of applications (Neuron cells classification taken by electron microscope, pathology images and skin disease classification) that have expensive labeling procedure with high risk of labeling noise to the introduction of the paper (Section 1) to make it clear why labeling even for few number of samples is not possible sometimes.	B-Reply	B-2	Reply	801
<sep> <sep> 3- The authors assume that, which seems restrictive in practice.	O	O	Reply	801
<sep> <sep> In domain shift, UTS is valid under Covariate Shift assumption for classification problem which means the test and training datasets are different in representation but keeps the same proportions of each class occurrence.	B-Reply	B-3	Reply	801
Covariate shift assumption is a common domain adaptation assumption that is valid for many classification problems.	I-Reply	I-3	Reply	801
For instance in medical image classification, it is very probable that the illumination, capturing noise, resolution, image size or viewpoint of the test images to be different from the training dataset.	I-Reply	I-3	Reply	801
In this case,  the representation of two domains is changed  that means but the probability of happening a class of object is staying the same which means.	I-Reply	I-3	Reply	801
<sep> In classification problems as the domain is discrete, UTS only needs to calculate empirically the number of occurrence of each class to the total number of samples in the training set which is equal to and use it as to calibrate the model.	I-Reply	I-3	Reply	801
<sep> <sep> Update to the paper:	O	O	Reply	801
We add one extra paragraph to Section 4.1 with the title of  "Validity of UTS in Practice" focusing on Covariate shift assumption in practice and how to calculate  to address this important concern.	B-Reply	B-3	Reply	801

The authors present an algorithm for postprocessing neural networks to ensure calibration under domain shift.	O	O	Review	801
Calibration under domain shift is an interesting challenge that has been receiving increasing attention and tackling this in an unsupervised manner is an interesting approach.	O	O	Review	801
However, I have 2 major concerns regarding the approach presented by the authors.	O	O	Review	801
What makes calibration under domain shift useful and appealing is that the model is then robust against any changes in the test distribution that can occur during the life cycle of a model.	O	O	Review	801
These often include erroneous/samples (corresponding to truly OOD samples), but also gradual domain shift, where the test distribution continuously moves away from the training distribution (e.g. due to a continuous drift in user behaviour/change in customer base) or unforeseen changes.	O	O	Review	801
My first major concern is regarding the requirements for UTS, which render this approach not very useful in many of these practical  applications: UTS first requires knowledge of and access to the test distribution; in addition it assumes that the distribution of the labels remains unaffected under domain shift.	O	O	Review	801
These assumptions are violated in the practical applications described above, in particular those where a gradual, continuous domain shift occurs - in this case, access to the test distribution is difficult since it changes continuously.	O	O	Review	801
On this note I also would have liked to see some analysis on how performance depends on the number of samples that are available from the test set, since in practice this might be substantially smaller than the full test set used.	O	O	Review	801
Furthermore, I find the assumption that the distribution of labels remains unchanged problematic (q_s(y) = q_t(y) and even q_s(y|x)=q_t(y|x)): once sufficiently out-of-domain, labels become meaningless and predictions for truly OOD samples should have maximum entropy.	O	O	Review	801
Even for small domain shifts in practical applications it is not clear why q_s(y|x)=q_t(y|x) should hold and it would have been useful to see a discussion and some robustness analysis on this.	O	O	Review	801
Finally,  the algorithm requires re-calibration whenever the test distribution changes, which in practice is  often not clear (and part of the reason why dealing with predictions under domain shift is so challenging).	O	O	Review	801
In addition to doubts on practical applicability, my second major concern is regarding the depth of the evaluation.	O	O	Review	801
First, while the authors present some comparisons to probabilistic methods, I am missing a crucial comparison to Evidential Deep Learning (Sensoy et al, NeurIPS 2018), which results in far superior performance than deep ensembles, SVI or dropout.	O	O	Review	801
Importantly, the comparisons to probabilistic approaches presented by the authors are very limited.	O	O	Review	801
The big advantage of those approaches is that, once trained, no further recalibration is necessary and well calibrated predictions can be made for any level of domain shift, whereas UTS requires a recalibration step for very level of domain shift.	O	O	Review	801
That is why I think it is crucial to not only show one arbitrarily picked level of domain shift for each dataset/perturbation, but calibration across all levels of domain shift, as for TS and TS-Target; since no recalibration is required for those probabilistic approaches	O	O	Review	801
this is very straight-forward and would be very informative - especially since e.g Figure 5 shows that UTS has only very minor advantages over TS in many settings.	O	O	Review	801
I appreciate that the authors report some performance in terms of ECE in the supplement, but I think it would be very informative to report performance in terms of ECE for all domain-shift experiments: The Brier score conflates accuracy with calibration (see eg the 2 component decomposition), whereas ECE directly quantifies calibration and is hence easier to interpret and arguably the more meaningful measure when quantifying calibration.	O	O	Review	801
Minor:  I find the manuscript lacks clarity.	O	O	Review	801
Aspects such as the definition of calibration as well as implications and interpretation of Proposition 1 should be described in more detail in the manuscript.	O	O	Review	801
Thank Reviewer #1 for thoroughly reading the paper, comments, and discussions, however, there are important points that it seems emerging concerns.	O	O	Reply	801
We try to clarify them by bringing detailed explanations one by one:	O	O	Reply	801

I've read the rebuttal and unfortunately, I'd like to keep my score as is.	B-Review	B-1	Review	801
I still think the assumption made in the paper is too limiting for most practical settings.	I-Review	I-1	Review	801
<sep> <sep> #########################	O	O	Review	801
<sep> The paper proposes an unsupervised calibration method in a domain adaptation setting.	O	O	Review	801
The approach is based on the well known temperature scaling and does not require labels for the calibration set.	O	O	Review	801
The problem of calibration under domain shift is an important problem in areas where uncertainty estimation is useful; the paper tackles this problem and relaxes the assumption of knowing the input distribution.	O	O	Review	801
The method does not rely on the labels in the calibration set but has a major limitation of knowing the task distribution which may not be true in many practical settings where uncertainty estimation is relevant (such as medical diagnostics).	O	O	Review	801
<sep> <sep> This assumption may not be a negative point for the paper as any domain adaptation problem needs at least some minimal assumptions; however,  the limits of the proposed method should be studied with respect to this assumption.	B-Review	B-1	Review	801
For instance, in the experiments how robust are the experiments with respect to the assumption of a known q(y)?	I-Review	I-1	Review	801
In the practical applications of the method in medical domain and self driving cars, q(y) is only known up to some approximation; so understanding the robustness of the method w.r.t.to this assumption is critical in real applications.	I-Review	I-1	Review	801
<sep> <sep> Also with the recent attention to calibration and uncertainty estimation in DL; I believe the acceptance bar for papers in this area has risen.	B-Review	B-2	Review	801
Unfortunately, most papers in this area rely on completely synthetic experiments which makes their impact limited.	I-Review	I-2	Review	801
I understand that ground truth uncertainty may not be available in some of these domains; however, other indirect metrics such as missclassification detection can be used.	I-Review	I-2	Review	801
There are also medical datasets available (e.g. Diabetic Retinopathy) that can be used for evaluation.	I-Review	I-2	Review	801
<sep> <sep> To summarize, the paper addresses an important problem of calibration under domain shift but it needs some more empirical work to show the real advantage and limitations of the proposed method in a practical setting.	B-Review	B-1	Review	801
Thank you for raising the important point of applicability of the methods in the field of machine learning, which we think it was our concern to propose  UTS, too.	B-Reply	B-1	Reply	801
<sep> The main advantage of UTS is ease of use and applicability in real scenarios.	I-Reply	I-1	Reply	801
However, in this paper, we dedicate the main part of the paper to discuss the UTS assumptions and its proof of robustness to the domain shift as UTS is a completely new idea and needs justification.	I-Reply	I-1	Reply	801
<sep> <sep> UTS is applicable to real scenarios as:	I-Reply	I-1	Reply	801
<sep> 1- the time complexity of UTS is O(1) which makes it really appealing for the application.	I-Reply	I-1	Reply	801
<sep> 2- it is a post-processing method, then it can be used to calibrate the model which is already trained toward the distribution of any new dataset.	I-Reply	I-1	Reply	801
<sep> 3- it does not need labels for the samples to calibrate the model which makes it really useful in many applications.	I-Reply	I-1	Reply	801
<sep> <sep> The main concern is about UTS assumption.	I-Reply	I-1	Reply	801
It needs to know to function properly.	I-Reply	I-1	Reply	801
Considering a K class classification problem, y is a discrete random variable.	I-Reply	I-1	Reply	801
Therefore, by having access to the samples from the training set, approximating is just by computing empirically the ratio of each class number of samples to the total number of samples in the training set.	I-Reply	I-1	Reply	801
As we consider Covariate shift assumption, then and simply we can approximate it for the test domain, too.	I-Reply	I-1	Reply	801
<sep> <sep> Covariate Shift assumption that we made UTS based on, is the most famous domain adaptation assumption that is valid in many applications.	B-Reply	B-2	Reply	801
When the training and test domains have a difference in representation distribution, the distribution shift scenario is categorized as Covariate Shift assumption.	I-Reply	I-2	Reply	801
In real scenarios, It is very common that we train a model on a dataset but when we want to apply the model on the test samples, they have different illumination, background, resolution or viewpoint from the training one.	I-Reply	I-2	Reply	801
This setting is categorized as covariate shift assumption.	I-Reply	I-2	Reply	801
In this case, test data keeps the same label distribution and only the representation of samples is changed based on the domain shift.	I-Reply	I-2	Reply	801
Even in medical applications, for instance in one region,  the rate of occurrence of different skin diseases is not changed but the condition in which the images are taken for skin disease detection could be changed from one healthcare center to the other.	I-Reply	I-2	Reply	801
This causes the classifier trained on skin images from one center to drop the accuracy during the test phase on the other center and we need the accurate certainty adjustment to let the system make a decision about when the output is trustworthy or not.	I-Reply	I-2	Reply	801
<sep> Update to the paper:	I-Reply	I-2	Reply	801
As it seems this explanation is missing in the paper, we add more details to the Section 1, Introduction and we add a new paragraph in Section 4.1 to explain about the validity of UTS assumptions in the paper.	I-Reply	I-2	Reply	801
<sep> <sep> We completely agree that it could be an interesting topic to see that UTS is how much robust to violating its assumptions in real situations.	I-Reply	I-2	Reply	801
However, in this paper, we only open the door to the concept of certainty adjustment for domain shift and this can be considered as the future work.	I-Reply	I-2	Reply	801

Summary:	O	O	Review	535
The manuscript extends the Neural Expectation Maximization framework by integrating an interaction function that allows asymmetric pairwise effects between objects.	O	O	Review	535
The network is demonstrated to learn compositional object representations which group together pixels, optimizing a predictive coding objective.	O	O	Review	535
The effectiveness of the approach is demonstrated on bouncing balls sequences and gameplay videos from Space Invaders.	O	O	Review	535
The proposed R-NEM model generalizes	O	O	Review	535
<sep> Review:	O	O	Review	535
Very interesting work and the proposed approach is well explained.	O	O	Review	535
The experimental section could be improved.	O	O	Review	535
<sep> I have a few questions/comments:	O	O	Review	535
1) Some limitations could have been discussed, e.g. how would the model perform on sequences involving more complicated deformations of objects than in the Space Invaders experiment?	B-Review	B-1	Review	535
As you always take the first frame of the 4-frame stacks in the data set, do the objects deform at all?	I-Review	I-1	Review	535
<sep> 2) It would have been interesting to vary K, e.g. study the behaviour for K in {1,5,10,25,50}. In Space Invaders the model would probably really group together separate objects.	B-Review	B-2	Review	535
What happens if you train with K=8 on sequences of 4 balls and then run on 8-ball sequences instead of providing (approximately) the right number of components both at training and test time (in the extrapolation experiment).	I-Review	I-2	Review	535
<sep> 3) One work that should be mentioned in the related work section is Michalski et al (2014), which also uses noise and predictive coding to model sequences of bouncing balls and NORBvideos.	B-Review	B-3	Review	535
Their model uses a factorization that also discovers relations between components of the frames, but in contrast to R-NEM the components overlap.	I-Review	I-3	Review	535
<sep> 4) A quantitative evaluation of the bouncing balls with curtain and Space Invaders experiments would be useful for comparison.	B-Review	B-4	Review	535
<sep> 5) I think the hyperparameters of the RNN and LSTM are missing from the manuscript.	B-Review	B-5	Review	535
Did you perform any hyperparameter optimization on these models?	I-Review	I-5	Review	535
<sep> 6) Stronger baselines would improve the experimental section, maybe Seo et al (2016).	B-Review	B-6	Review	535
Alternatively, you could train the model on Moving MNIST (Srivastava et al 2015) and compare with other published results.	I-Review	I-6	Review	535
<sep> <sep> I would consider increasing the score, if at least some of the above points are sufficiently addressed.	O	O	Review	535
<sep> <sep> References:	O	O	Review	535
Michalski, Vincent, Roland Memisevic, and Kishore Konda. "	O	O	Review	535
Modeling deep temporal dependencies with recurrent grammar cells""."	O	O	Review	535
In Advances in neural information processing systems, pp.1925-1933.	O	O	Review	535
2014.	O	O	Review	535
<sep> Seo, Youngjoo, Micha√´l Defferrard, Pierre Vandergheynst, and Xavier Bresson. "	O	O	Review	535
Structured sequence modeling with graph convolutional recurrent networks."	O	O	Review	535
arXiv preprint arXiv:1612.07659 (2016).	O	O	Review	535
<sep> Srivastava, Nitish, Elman Mansimov, and Ruslan Salakhudinov. "	O	O	Review	535
Unsupervised learning of video representations using lstms."	O	O	Review	535
In International Conference on Machine Learning, pp.843-852.	O	O	Review	535
2015.	O	O	Review	535
Thank you for the careful consideration of our paper and for the useful feedback.	O	O	Reply	535
Regarding your comments:	O	O	Reply	535
<sep> 1) We agree that adding a general discussion on the limitations of our approach is valuable (and currently lacking) and we intend to include this in the new draft.	B-Reply	B-1	Reply	535
In response to your specific examples: we expect the performance of R-NEM to be similar in regard to N-EM when confronted with high variability within an object class.	I-Reply	I-1	Reply	535
In N-EM when trained on sequences of moving MNIST digits (that highly vary, since each MNIST digit is unique) it is more difficult to group pixels into coherent objects (digits in this case) as all variation needs to be captured.	I-Reply	I-1	Reply	535
However, once pixels have been clustered to belong to an object, and its deformation is consistent/predictable R-NEM should be able to accurately capture it (as is for example the case for the occlusion experiment).	I-Reply	I-1	Reply	535
If it is not consistent/predictable as is for example the case in Atari due to randomness and deformation due to down-sampling, then R-NEM will continuously try to adjust its predictions as a function of feedback from the environment (eg.by means of the masked difference between prediction and reality that is fed into the system) .	I-Reply	I-1	Reply	535
<sep> <sep> 2) We have tried a range of values for K={4,5,6,7,8} on Atari, before settling onto K=4.	B-Reply	B-2	Reply	535
Since the Aliens move together they are mostly grouped together into a single component, which leaves only bullets / shields and the space-ship as remaining objects.	I-Reply	I-2	Reply	535
The bullets from the Aliens can not be predicted and so usually one of the alien columns takes care of it.	I-Reply	I-2	Reply	535
Bullets from the Spaceship can be predicted (as we feed in the action) and for this a remaining group does help.	I-Reply	I-2	Reply	535
It should be noted that (similar to N-EM) very large values of K > 9-10 cause instabilities during training as there may be too many components competing for the same pixel in the E-step.	I-Reply	I-2	Reply	535
We have therefore not explored extreme cases of K=25/50 further.	I-Reply	I-2	Reply	535
We are in the process of training R-NEM with K=8 on the balls 4 dataset to provide further insight into its behavior of 4-balls and 678-balls.	I-Reply	I-2	Reply	535
<sep> <sep> 3) Thank you, we‚Äôve missed this relevant work and will include it in the next draft.	B-Reply	B-3	Reply	535
<sep> <sep> 4) We are in the process of training RNN / LSTM models on the bouncing balls with curtain task to provide a quantitative evaluation.	B-Reply	B-4	Reply	535
With regard to a quantitative evaluation on Atari we feel that it would take an unjustified/disproportionate amount of effort and computational time to  provide a comparison that carries any value.	I-Reply	I-4	Reply	535
In particular, since we have not studied the performance of RNN / LSTM on this domain previously, we would need to perform a general search to ensure that our baseline isn‚Äôt just underfitted.	I-Reply	I-4	Reply	535
<sep> 5) We use the same encoder / decoder architecture for the LSTM / RNN variations, that also receive the difference between prediction from the previous timestep and current frame as input.	B-Reply	B-5	Reply	535
We use the same layer size also (250 units).	I-Reply	I-5	Reply	535
This is reported in the Appendix.	I-Reply	I-5	Reply	535
Some experiments that we ran but did not report involve adding more units (500) for the LSTM / RNN, for which we did not observe significant differences in performance.	I-Reply	I-5	Reply	535
Moreover, we experimented with an RHN, but were unable to improve upon the LSTM and therefore left it out of the final comparison.	I-Reply	I-5	Reply	535
We have tried several deeper/wider variations of the interaction function and settled on the smallest architecture that was able to achieve the reported performance.	I-Reply	I-5	Reply	535
This last observation is mentioned in the Appendix.	I-Reply	I-5	Reply	535
<sep> <sep> 6) We are happy to incorporate stronger baselines in our quantitative evaluation of R-NEM.	B-Reply	B-6	Reply	535
However we are unsure whether Seo et al (2016) / Srivastava et al 2015 (2015) are suitable.	I-Reply	I-6	Reply	535
Both approaches are encoder / decoder architectures that first encode a sequence of time-steps in an LSTM, to then use a (or multiple) decoder LSTMs initialized with the encoded state to reconstruct the input sequence in reverse, or predict future time-steps.	I-Reply	I-6	Reply	535
Since our model is trained with next-step prediction, this reduces the Decoder LSTM of such an approach to a simple feedforward decoder.	I-Reply	I-6	Reply	535
Moreover, we are only computing gradients from next-step prediction, eliminating the reverse decoder LSTM from such an approach such that the model is essentially reduced to a standard LSTM again that we do compare to.	I-Reply	I-6	Reply	535
In case of Seo et al (2016) the only addition would be to use a graph-convolutional LSTM in stead.	I-Reply	I-6	Reply	535
Neither of these seem much stronger than our LSTM baseline on the balls environments.	I-Reply	I-6	Reply	535
Instead we would like to propose to use PredNet (Lotter et al <a href="https://arxiv.org/pdf/1605.08104.pdf)" target="_blank" rel="nofollow">https://arxiv.org/pdf/1605.08104.pdf)</a> as an alternative to your suggestions.	I-Reply	I-6	Reply	535
In response to your suggestion to evaluate on the moving MNIST dataset we would like to point out that this dataset does involve any interactions between the digits and is unsuitable to evaluate the impact of our interaction function.	I-Reply	I-6	Reply	535

This was a pretty interesting read.	O	O	Review	535
Thanks.	O	O	Review	535
A few comments:	O	O	Review	535
<sep> One sentence that got me confused is this: ‚ÄúUnlike other work (Battaglia et al 2016) this function is not commutative and we opt for a clear separation between the focus object k and the context object i as in previous work (Chang et al 2016)‚Äù.	B-Review	B-1	Review	535
What exactly is not commutative?	I-Review	I-1	Review	535
The formulation seems completely align with the work of Battaglia et al, with the difference that one additionally has an attention on which edges should be considered (attention on effects).	I-Review	I-1	Review	535
What is the difference to Battaglia et al that this should highlight?	I-Review	I-1	Review	535
<sep> <sep> I don‚Äôt think is very explicit what k is in the experiments with bouncing balls.	B-Review	B-2	Review	535
Is it 5 in all of them ?	I-Review	I-2	Review	535
When running with 6-8 balls, how are balls grouped together to form just 5 objects?	I-Review	I-2	Review	535
<sep> <sep> Is there any chance of releasing the code/ data used in this experiments?	B-Review	B-3	Review	535
Thank you for the careful consideration of our paper and for the useful feedback.	O	O	Reply	535
Regarding your comments:	O	O	Reply	535
<sep> We were mistaken in that we thought that the interaction function in Battaglia et al 2016 was commutative in that it did not distinguish a sender and a receiver in computing interactions between objects.	B-Reply	B-1	Reply	535
However upon reviewing their work again it turns out that that segment (<a href="https://arxiv.org/pdf/1612.00222.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1612.00222.pdf</a> page 3 - bottom) only referred to the ordering of the arguments in the a-function.	I-Reply	I-1	Reply	535
We remove this part in the new draft.	I-Reply	I-1	Reply	535
<sep> <sep> The number of components is K=5 for the 4 balls experiment, K=8 for the 678 balls experiment, and K=5 for the occlusion experiment.	B-Reply	B-2	Reply	535
In general we observe (as is in line with the findings in the Neural Expectation Maximization paper) that increasing K benefits performance (independent of the number of balls) at training and at test time.	I-Reply	I-2	Reply	535
Very large values of K > 9-10 cause instabilities during training as there may be too many components competing for the same pixel in the E-step.	I-Reply	I-2	Reply	535
Choosing K < # objects hinders performance, as expected.	I-Reply	I-2	Reply	535
We are in the process of training R-NEM with K=8 on the balls 4 dataset to provide further insight into this.	I-Reply	I-2	Reply	535
<sep> <sep> Our current codebase is an adaptation of the code provided by the authors of the Neural Expectation Maximization paper (found here: <a href="https://github.com/sjoerdvansteenkiste/Neural-EM)."	B-Reply	B-3	Reply	535
target="_blank" rel="nofollow">https://github.com/sjoerdvansteenkiste/Neural-EM).</a> We will release our adaptation of this code including all datasets upon publication.	I-Reply	I-3	Reply	535

Summary	O	O	Review	535
---	O	O	Review	535
This work applies a representaion learning technique that segments entities to learn simple 2d intuitive physics without per-entity supervision.	O	O	Review	535
It adds a relational mechanism to Neural Expectation Maximization and shows that this mechanism provides a better simulation of bouncing balls in a synthetic environment.	O	O	Review	535
<sep> <sep> Neural Expectation Maximization (NEM) decomposes an image into K latent variables (vectors of reals) theta_k.	O	O	Review	535
A decoder network reconstructs K images from each of these latent variables and these K images are combined into a single reconstruction using pixel-wise mixture components that place more weight on pixels that match the ground truth.	O	O	Review	535
An encoder network f_enc() then updates the latent variables to better explain the reconstructions they produced.	O	O	Review	535
<sep> The neural nets are learned so that the latent variables reconstruct the image well when used by the mixture model and match a prior otherwise.	O	O	Review	535
Previously NEM has been shown to learn variables which represent individual objects (simple shapes) in a compositional manner, using one variable per object.	O	O	Review	535
<sep> <sep> Other recent neural models can learn to simulate simple 2d physics environments (balls bouncing around in a 2d plane).	O	O	Review	535
That work supervises the representation for each entity (ball) explicitly using states (e.g. position and velocity of balls) which are known from the physics simulator used to generate the training data.	O	O	Review	535
The key feature of these models is the use of a pairwise embedding of an object and its neighbors (message passing) to predict the object's next state in the simulation.	O	O	Review	535
<sep> <sep> This paper paper combines the two methods to create Relational Neural Expectation Maximization (R-NEM), allowing direct interaction at inference time between the latent variables that encode a scene.	O	O	Review	535
The encoder network from NEM can be seen as a recurrent network which takes one latent variable theta_k at time t and some input x to produce the next latent variable theta_k at time t+1.	O	O	Review	535
R-NEM adds a relational module which computes an embedding used as a third input to the recurrent encoder.	O	O	Review	535
Like previous relational models, this one uses a pairwise embedding of the object being updated (object k) and its neighbors.	O	O	Review	535
Unlike previous neural physics models, R-NEM uses a soft attention mechanism to determine which objects are neighbors and which are not.	O	O	Review	535
Also unlike previous neural models, this method does not require per-object supervision.	O	O	Review	535
<sep> <sep> Experiments show that R-NEM learns compositional representations that support intuitive physics more effectively than ablative baselines.	O	O	Review	535
These experiments	O	O	Review	535
show:	O	O	Review	535
1) R-NEM reconstructs images more accurately than baselines (RNN/LSTM) and NEM (without object interaction).	O	O	Review	535
<sep> 2) R-NEM is trained with 4 objects per image.	O	O	Review	535
It does a bit worse at reconstructing images with 6-8 objects per image, but still performs better than baselines.	O	O	Review	535
<sep> 3) A version of R-NEM without neighborhood attention in the relation module matches the performance of R-NEM using 4 objects and performs worse than R-NEM at 6-8 objects.	O	O	Review	535
<sep> 4) R-NEM learns representations which factorize into one latent variable per object as measured by the Adjusted Rand Index, which compares NEM's pixel clustering to a ground truth clustering with one cluster per object.	O	O	Review	535
<sep> 5) Qualitative and quantitative results show that R-NEM can simulate 2d ball physics for many time steps more effectively than an RNN and while only suffering gradual divergence from the ground truth simulation.	O	O	Review	535
<sep> <sep> Qualitative results show that the attentional mechanism attends to objects which are close to the context object together, acting like the heuristic neighborhood mechanism from previous work.	O	O	Review	535
<sep> <sep> Follow up experiments extend the basic setup significantly.	O	O	Review	535
One experiment shows that R-NEM demonstrates object permanence by correctly tracking a collision when one of the objects is completely occluded.	O	O	Review	535
Another experiment applies the method to the Space Invaders Atari game, showing that it treats columns of aliens as entities.	O	O	Review	535
This representation aligns with the game's goal.	O	O	Review	535
<sep> <sep> <sep> Strengths	O	O	Review	535
---	O	O	Review	535
<sep> The paper presents a clear, convincing, and well illustrated story.	O	O	Review	535
<sep> <sep> Weaknesses	O	O	Review	535
---	O	O	Review	535
<sep> * RNN-EM BCE results are missing from the simulation plot (right of figure 4).	B-Review	B-1	Review	535
<sep> <sep> Minor comments/concerns:	O	O	Review	535
<sep> * 2nd paragraph in section 4: Are parameters shared between these 3 MLPs (enc,emb,eff)?	B-Review	B-2	Review	535
I guess not, but this is ambiguous.	I-Review	I-2	Review	535
<sep> <sep> * When R-NEM is tested against 6-8 balls is K set to the number of balls plus 1?	B-Review	B-3	Review	535
How does performance vary with the number of objects?	I-Review	I-3	Review	535
<sep> <sep> * Previous methods report performance across simulations of a variety of physical phenomena (e.g., see "Visual Interaction Networks").	B-Review	B-4	Review	535
It seems that supervision isn't needed for bouncing ball physics, but I wonder if this is the case for other kinds of phenomena (e.g., springs in the VIN paper).	I-Review	I-4	Review	535
Can this method eliminate the need for per-entity supervision in this domain?	I-Review	I-4	Review	535
<sep> <sep> * A follow up to the previous comment: Could a supervised baseline that uses per-entity state supervision and neural message passsing (like the NPE from Chang et al) be included?	B-Review	B-5	Review	535
<sep> <sep> * It's a bit hard to qualitatively judge the quality of the simulations without videos to look at.	B-Review	B-6	Review	535
Could videos of simulations be uploaded (e.g., via anonymous google drive folder as in "Visual Interaction Networks")?	I-Review	I-6	Review	535
<sep> <sep> * This uses a neural message passing mechanism like those of Chang et al and Battaglia et al It would be nice to see a citation to neural message passing outside of the physics simulation domain (e.g. to "Neural Message Passing for Quantum Chemistry" by Gilmer et al in ICML17).	B-Review	B-7	Review	535
<sep> <sep> * Some work uses neighborhood attention coefficients for neural message passing.	B-Review	B-8	Review	535
It would be nice to see a citation included.	I-Review	I-8	Review	535
<sep> * See "Neighborhood Attention" in "One-Shot Imitation Learning" by Duan et al in NIPS17	B-Review	B-9	Review	535
* Also see "Programmable Agents" by Denil et al	B-Review	B-10	Review	535
<sep> <sep> Final Evaluation	O	O	Review	535
---	O	O	Review	535
<sep> This paper clearly advances the body of work on neural intuitive physics by incorporating NEM entity representation to allow for less supervision.	O	O	Review	535
Alternatively, it adds a message passing mechanism to the NEM entity representation technique.	O	O	Review	535
These are moderately novel contributions and there are only minor weaknesses, so this is a clear accept.	O	O	Review	535
Thank you for the careful consideration of our paper and for the useful feedback.	O	O	Reply	535
Regarding your comments:	O	O	Reply	535
<sep> - We will incorporate the RNN-EM BCE results in the simulation plot (right of figure 4).	B-Reply	B-1	Reply	535
<sep> - Videos of the performance of R-NEM (compared to the RNN) on all balls tasks are available at <a href="https://sites.google.com/view/r-nem-gifs/home" target="_blank" rel="nofollow">https://sites.google.com/view/r-nem-gifs/home</a>	B-Reply	B-6	Reply	535
- We will incorporate related work on neural message passing as you suggested	B-Reply	B-5	Reply	535
<sep> Indeed the parameters between the 3 MLPs (enc, emb, eff) are not shared and we will clarify this in the text.	B-Reply	B-2	Reply	535
<sep> <sep> When R-NEM is tested against 6-8 balls we set K to 8.	B-Reply	B-3	Reply	535
We have tried K=9 also and obtained similar results.	I-Reply	I-3	Reply	535
In general we observe (as is in line with the findings in the Neural Expectation Maximization paper) that increasing K benefits performance (independent of the number of balls) at training and at test time.	I-Reply	I-3	Reply	535
Very large values of K > 9-10 cause instabilities during training as there may be too many components competing for the same pixel in the E-step.	I-Reply	I-3	Reply	535
Choosing K < # objects hinders performance, as expected.	I-Reply	I-3	Reply	535
We are in the process of training R-NEM with K=8 on the balls 4 dataset to provide further insight into this.	I-Reply	I-3	Reply	535
<sep> <sep> We expect R-NEM to be able to fully eliminate the need for per-entity state supervision in various other domains that revolve around interactions between entities.	B-Reply	B-4	Reply	535
The interaction function incorporated in N-EM is not restricted to local interaction and therefore there is no apparent reason for it not to be able to handle springs.	I-Reply	I-4	Reply	535
<sep> <sep> Although we are happy to include a supervised baseline, we have not been able to come up yet with a fair comparison measure.	B-Reply	B-5	Reply	535
None of the supervised methods reconstructs in pixel-space and therefore comparing in terms of BCE would put R-NEM at a significant disadvantage.	I-Reply	I-5	Reply	535
Being unable to disentangle error due to poorly modeling physical dynamics (including interactions) from error due to poor visual reconstruction only allow for comparing to approaches that reconstruct in pixel-space.	I-Reply	I-5	Reply	535
We are currently looking into incorporating a stronger unsupervised baseline in the form of PredNet (<a href="https://arxiv.org/pdf/1605.08104.pdf)."	I-Reply	I-5	Reply	535
target="_blank" rel="nofollow">https://arxiv.org/pdf/1605.08104.pdf).</a>	I-Reply	I-5	Reply	535

This paper proposes a new embedding method for sentences that aims to preserve dilation invariance.	O	O	Review	535
Much of the methodology is justified by results for extremal point classification under particular assumptions, and then the authors try and encourage these assumptions to be met via penalty terms introduced in their embeddings/augmentation models.	O	O	Review	535
However, while the proposed methodology seems interesting/novel, it remains conceptually unclear why it should be superior to standard text classification methods (ie.exactly what assumptions are being exploited to improve performance and how exactly do those assumptions help should be made more explicit).	B-Review	B-1	Review	535
In particular, why is dilation invariance even a good idea?	I-Review	I-1	Review	535
<sep> <sep> Overall, I find the paper a bit mathematically dense in Secs 2.1-2.2, which would not be a bad thing if the math were necessary to justify why the proposed methodology works well, but it in this case seems mainly presented as background material (as if it were a prerequisite to understand the method itself, which it is certainly not).	B-Review	B-12	Review	535
<sep> <sep> Why not instead present an explicit theorem providing some statistical guarantees for the proposed methodology in Sec 3.1 based on the constant-along-rays result (which would be nice to have regardless), and then follow up the theorem with background math from 2.1-2.2 which is necessary to understand the proof?	B-Review	B-2	Review	535
<sep> <sep> As it is currently written the paper is a bit too dense in terminology, and opaque names like Hydra and Orthrus used to describe straightforward concepts that are essentially a neural classifier (of a particular form) and a seq2seq-based data augmentation procedure (which would be good to describe in language more familiar to the ML audience).	O	O	Review	535
In particular, the goals of Hydra and Orthrus should first be intuitively described before delving into their various components.	O	O	Review	535
<sep> <sep> - Why did the authors never evaluate the overall sentiment prediction performance of Orthrus + Hydra used together vs other classifiers + data augmentation strategies?	B-Review	B-3	Review	535
<sep> <sep> - If the goal of dilation invariance is to help the classifiers better generalize to out-of-distribution test sentences, then why not verify this happened, eg.by training on Yelp and testing on Amazon?	B-Review	B-4	Review	535
<sep> <sep> - The authors should better justify the assumption of Jalalzai et al, and why this is appropriate for the MLP classifier used later in the paper.	B-Review	B-5	Review	535
<sep> <sep> - This statement needs to be clarified and have citation: "Such classifier whose output solely depends on the angle Œò(x) of the considered input, with provable guarantees concerning the classification risk in out-of-sample regions scaling as the square root of the number of extreme points used at the training step"	B-Review	B-6	Review	535
<sep> - The authors should explain Equation (1) in English rather than referring to it so early on the paper (pg 1: "satisfying Equation 1").	B-Review	B-7	Review	535
I had no idea what this was supposed to mean as a first time reader.	I-Review	I-7	Review	535
<sep> <sep> - The way figure 4 is presented is a bit opaque and took me a while to understand (have to look closely at Fig 4a to see the columns are not monochromatic).	B-Review	B-8	Review	535
<sep> <sep> - "We also compare Hydra to a Vanilla Sequence to Sequence to demonstrate the validity of our approach" How "Vanilla Sequence to Sequence" (word 'model' is missing) is used for dataset augmentation needs to be clarified here.	B-Review	B-9	Review	535
<sep> <sep> - A figure demonstrating an example of the phenomenon explained in Sec 2.2 would be  helpful to aid reader's intuition.	B-Review	B-10	Review	535
<sep> - Typo: "eugmentation"	B-Review	B-11	Review	535
We thank AnonReviewer2 for spotting the typo.	O	O	Reply	535
<sep> <sep> ‚Ä¢ ‚ÄúIn particular, why is dilation invariance even a good idea?‚Äù	O	O	Reply	535
‚ûú The dilation invariance is a label invariance of the embeddings.	B-Reply	B-1	Reply	535
Such invariance, provided by the approach detailed in the paper, allows generating new text data based on labeled inputs while preserving the same label.	I-Reply	I-1	Reply	535
To the best of our knowledge, no other embedding provides a framework to generate new text data with a label preserving approach.	I-Reply	I-1	Reply	535
<sep> ‚Ä¢ ‚ÄúWhy not instead present an explicit theorem providing some statistical guarantees for the proposed methodology in Sec 3.1 based on the constant-along-rays result (which would be nice to have regardless), and then follow up the theorem with background math from 2.1-2.2 which is necessary to understand the proof?‚Äù	O	O	Reply	535
‚ûú  Following your suggestion we have added an explicit statement of the statistical guarantees that can be obtained with such constant-along-rays embeddings, citing theorem 1 of [1] in Section 2.1.	B-Reply	B-2	Reply	535
<sep> <sep> ‚Ä¢ ‚ÄúWhy did the authors never evaluate the overall sentiment prediction performance of Orthrus + Hydra used together vs other classifiers + data augmentation strategies?‚Äù	O	O	Reply	535
‚ûú We point out that the performance of Orthrus is compared to a MLP classifier on similar input (see Table 1 of the new version of the paper).	B-Reply	B-3	Reply	535
Hydra relies on the regularly varying representation provided by Orthrus.	I-Reply	I-3	Reply	535
Therefore, the performance of Hydra + Orthrus is compared to state-of-the-art methods in terms of data generation (see Table 2a and Table 2b).	I-Reply	I-3	Reply	535
<sep> <sep> ‚Ä¢ ‚ÄúIf the goal of dilation invariance is to help the classifiers better generalize to out-of-distribution test sentences, then why not verify this happened, eg.by training on Yelp and testing on Amazon?‚Äù	O	O	Reply	535
‚ûú Although there are works addressing learning a task on a given dataset and testing on a different dataset which relates to transfer learning, we make no claim that the regularly varying embedding allows to do this.	B-Reply	B-4	Reply	535
The added value of our approach is that it allows:	I-Reply	I-4	Reply	535
1.	I-Reply	I-4	Reply	535
Generalization for points which lie out of the envelope of the training inputs,	I-Reply	I-4	Reply	535
2.	I-Reply	I-4	Reply	535
A label preserving (text) data augmentation.	I-Reply	I-4	Reply	535
<sep> <sep> ‚Ä¢ ‚ÄúThe authors should better justify the assumption of Jalalzai et al, and why this is appropriate for the MLP classifier used later in the paper.	O	O	Reply	535
‚Äù	O	O	Reply	535
‚ûú Following your suggestion we now provide some intuition about the regular variation assumption of Jalalzai et al in Section 1 and Section 2.	B-Reply	B-5	Reply	535
In Section 3, we emphasize  that in the present work we do not assume that the original representation (from BERT) satisfies this assumption.	I-Reply	I-5	Reply	535
Instead we construct a new representation that does, via the GAN machinery with a target with the desired property.	I-Reply	I-5	Reply	535
Also we have added a few sentences concerning the advantage of using this representation for text document classification, namely the probability ratio between the two classes, conditionally on the input x, solely depend on the angle theta(x) above large radial thresholds, which allows to classify the most extreme test  points using information from a given fraction of the training set corresponding to inputs with largest norm.	I-Reply	I-5	Reply	535
<sep> <sep> ‚Ä¢ ‚ÄúThis statement needs to be clarified and have citation: ‚ÄúSuch classifier whose output solely depends on the angle Œò(x) of the considered input, with provable guarantees concerning the classification risk in out-of-sample regions scaling as the square root of the number of extreme points used at the training step‚Äù	O	O	Reply	535
‚ûú The information that helps to understand this statement is provided in Theorem 2 from [1]. But, indeed, it is not clear as it was explained and we clarified the paper accordingly, by adding the aforementioned theorem in Section 2.2.	B-Reply	B-6	Reply	535
<sep> ‚Ä¢ ‚ÄúThe authors should explain Equation (1) in English rather than referring to it so early on the paper (pg 1: "satisfying Equation 1").	O	O	Reply	535
I had no idea what this was supposed to mean as a first time reader.	O	O	Reply	535
‚Äù	O	O	Reply	535
‚ûú We have updated the paper accordingly and explain Equation (1) in the introduction as a homogeneity property above large radial thresholds.	B-Reply	B-7	Reply	535
<sep> <sep> ‚Ä¢ ‚ÄúA figure demonstrating an example of the phenomenon explained in Sec 2.2 would be helpful to aid reader's intuition.	O	O	Reply	535
‚Äù	O	O	Reply	535
‚ûú We have added  a figure (Figure 1) to illustrate the angular classifier in Sec 2.2.	B-Reply	B-10	Reply	535
<sep> <sep> ---	O	O	Reply	535
[1] Hamid Jalalzai, Stephan Cl√©mencon, and Anne Sabourin.	O	O	Reply	535
On binary classification in extreme regions.	O	O	Reply	535
In Advances in Neural Information Processing Systems, pp.3092‚Äì3100, 2018.	O	O	Reply	535

The paper explores learning dilation-invariant sentence representations, with a goal of improving downstream task performance on rare events.	O	O	Review	535
A pre-trained embedding is encoded as a latent variable Z, which is constrained to be multi-variate heavy tailed.	O	O	Review	535
Separate classifiers are trained on the head and tail of the distribution.	O	O	Review	535
Similarly, separate sentence generators are trained on the head and tail of the distribution, in order to allow data augmentation (creating diversity in the outputs by scaling the representation).	O	O	Review	535
While the high level motivation and algorithm is interesting, I found the paper very hard to follow, and the experiments are weak.	B-Review	B-9	Review	535
<sep> <sep> I have quite a few concerns:	O	O	Review	535
- The algorithm takes a sentence embedding from BERT as input.	B-Review	B-1	Review	535
BERT produces contextualized word representations, not sentence embeddings, so I don't know what the authors did here (the intro also claims that ELMo and GPT learn sentence embeddings, which is also confusing).	I-Review	I-1	Review	535
<sep> - The paper argues that with empirical risk minimization, "nothing guarantees that such classifiers perform satisfactorily	B-Review	B-2	Review	535
on the tails of the explanatory variables".	I-Review	I-2	Review	535
However, I could not follow what such guarantees the proposed method offers, if any.	I-Review	I-2	Review	535
<sep> - Experiment 4.1 is impossible to follow without reading the appendix.	B-Review	B-3	Review	535
This section should be expanded, or completely moved to the appendix.	I-Review	I-3	Review	535
<sep> - The authors claim without evidence that a baseline of a neural network trained on top of the "BERT embedding" is state-of-the-art for sentiment classification.	B-Review	B-4	Review	535
While there isn't enough information to know what was done, most state-of-the-art approaches involve fine-tuning BERT.	I-Review	I-4	Review	535
<sep> - No comparisons are made with any other work, despite the method attempting a very general and well studied problem of text classification.	B-Review	B-5	Review	535
<sep> - The submission claims that "Applying a dilation is equivalent to assess the generalization of classifiers outside	B-Review	B-6	Review	535
the envelope of both training and testing samples.".	I-Review	I-6	Review	535
It isn't obvious to me that dilation captures the variation in embeddings you'd get from out-of-domain training samples.	I-Review	I-6	Review	535
<sep> - The authors compare their data augmentation results to "backtranslation".	B-Review	B-7	Review	535
The citation for the method appears to be a class project, and in fact does round-trip translation for paraphrasing, and not back translation.	I-Review	I-7	Review	535
<sep> - No attempt is made to show if the data augmentation approach actually improves end task performance.	B-Review	B-8	Review	535
‚Ä¢ ‚ÄúThe algorithm takes a sentence embedding from BERT as input.	O	O	Reply	535
BERT produces contextualized word representations, not sentence embeddings, so I don't know what the authors did here (the intro also claims that ELMo and GPT learn sentence embeddings, which is also confusing).‚Äù	O	O	Reply	535
‚ûú AnonReviewer1 is right.	B-Reply	B-1	Reply	535
BERT produces contextualized word representation which can be applied to sentences (refer to the original paper).	I-Reply	I-1	Reply	535
In our implementation we use the [CLS] token as an embedding of the full sentence as done in the original paper on the glue benchmark for classification task.	I-Reply	I-1	Reply	535
We applied BERT on the sentences of the studied dataset as input for the algorithms we detail.	I-Reply	I-1	Reply	535
<sep> <sep> ‚Ä¢ ‚ÄúThe paper argues that with empirical risk minimization, "nothing guarantees that such classifiers perform satisfactorily on the tails of the explanatory variables".	O	O	Reply	535
However, I could not follow what such guarantees the proposed method offers, if any.	O	O	Reply	535
‚Äù	O	O	Reply	535
‚ûú Paper [1] precisely details why the tails deserve a specific treatment.	B-Reply	B-2	Reply	535
The mentioned paper also provides theoretical guarantees (theorem 2).	I-Reply	I-2	Reply	535
As advised by R2, we will explicitly state the results from [1] that are relevant for the present paper.	I-Reply	I-2	Reply	535
<sep> <sep> ‚Ä¢ ‚ÄúExperiment 4.1 is impossible to follow without reading the appendix.	O	O	Reply	535
This section should be expanded, or completely moved to the appendix."	O	O	Reply	535
<sep> ‚ûú Experiment 4.1 has been moved to the Appendix.	B-Reply	B-3	Reply	535
<sep> The authors claim without evidence that a baseline of a neural network trained on top of the "BERT embedding" is state-of-the-art for sentiment classification.	I-Reply	I-3	Reply	535
While there isn't enough information to know what was done, most state-of-the-art approaches involve fine-tuning BERT.‚Äù	I-Reply	I-3	Reply	535
<sep> ‚Ä¢ ‚ÄúNo comparisons are made with any other work, despite the method attempting a very general and well-studied problem of text classification.	O	O	Reply	535
‚Äù	O	O	Reply	535
‚ûú Our aim is to show that learning a regularly varying representation on top of a baseline representation (such as BERT) improves the classification performance of a standard classifier (such as MLP) compared to applying the same  standard classification algorithm (MLP) to the baseline representation.	B-Reply	B-4	Reply	535
Table 1 from the new version of the paper precisely gathers the experimental results with regards to this claim.	I-Reply	I-4	Reply	535
<sep> Our choice of BERT+MLP as baseline was merely guided by the state of the art approaches when we started working on this project.	I-Reply	I-4	Reply	535
<sep> <sep> ‚Ä¢ ‚Äú The submission claims that "Applying a dilation is equivalent to assess the generalization of classifiers outside the envelope of both training and testing samples.".	O	O	Reply	535
It isn't obvious to me that dilation captures the variation in embeddings you'd get from out-of-domain training samples.	O	O	Reply	535
‚Äù	O	O	Reply	535
‚ûú This sentence has been removed from the newest version for the sake of clarity.	B-Reply	B-6	Reply	535
<sep> <sep> ‚Ä¢ ‚ÄúThe authors compare their data augmentation results to "backtranslation".	O	O	Reply	535
The citation for the method appears to be a class project, and in fact does round-trip translation for paraphrasing, and not back translation.	O	O	Reply	535
‚Äù	O	O	Reply	535
‚ûú The author of the [2] used the word ‚Äúbacktranslation‚Äù along their article.	B-Reply	B-7	Reply	535
We will modify our paper and replace ‚Äúbacktranslation‚Äù with ‚Äúround-trip translation‚Äù.	I-Reply	I-7	Reply	535
<sep> <sep> ‚Ä¢ ‚ÄúNo attempt is made to show if the data augmentation approach actually improves end task performance.	O	O	Reply	535
‚Äù	O	O	Reply	535
‚ûú Please refer to the last experiment:  we observe that Hydra outperforms all other methods in terms of distinct 1 and distinct 2.	B-Reply	B-8	Reply	535
Table 1b shows that improvement in F1 score induced by dataset augmentation by Hydra beats all other methods and is only equaled by EDA.	I-Reply	I-8	Reply	535
<sep> <sep> ---	O	O	Reply	535
[1] Hamid Jalalzai, Stephan Cl√©mencon, and Anne Sabourin.	O	O	Reply	535
On binary classification in extreme regions.	O	O	Reply	535
In Advances in Neural Information Processing Systems, pp.3092‚Äì3100, 2018.	O	O	Reply	535
<sep> [2] Shleifer,S. ‚ÄúLow resource text classification with ulmfit and backtranslation‚Äù, arXiv preprint arXiv:1903.09244, 2019.	O	O	Reply	535

The paper presented two methods for augmenting sentiment classification from the perspective of applying the Extreme Value Theory (EVT), including:	O	O	Review	535
<sep> 1) A classification algorithm which has an adversarial classifier to enforce the intermediate representations of a neural network to be similar to one EVT distribution, logistic distribution;	O	O	Review	535
2) An encoder-decoder model that is able to generate grammatically coherent sentences with the same sentiment as the given input sentence.	O	O	Review	535
<sep> <sep> Questions:	O	O	Review	535
<sep> --	O	O	Review	535
1) the Fisher‚ÄìTippett‚ÄìGnedenko theorem states that it is possible that the maximum value of a set of iid samples converges to one of three plausible distributions, and the chosen logistic distribution falls into the Weibull distribution category.	O	O	Review	535
I have a couple concerns about this choice:	O	O	Review	535
<sep> 1.1) In order to show that the EVT indeed helps empirically in the way that an adversarial classifier enforces the inf-norm of vectors follow the Generalised Extreme Value (GEV) distribution, at least three plausible distributions from each form of the GEV distribution needs to be checked.	B-Review	B-1	Review	535
The logistic distribution is interesting, but the marginal improvement gained by enforcing the lengths of the produced vectors to follow the logistic distribution could be a result of hyper-param tuning, which shouldn't be a piece of supporting evidence.	I-Review	I-1	Review	535
<sep> <sep> 1.2) From the perspective of applying the EVT, recent successful work from the best of my knowledge is on Anomaly Detection [1], where the EVT enables the system to learn from samples in only one class and also adjust the threshold for detecting the abnormal behaviour of samples.	B-Review	B-2	Review	535
It is also theoretically grounded as the error variable of a logistic regression follows a Gumbel distribution which is one form of the GEV distribution, therefore, applying EVT for binary classification case makes sense.	I-Review	I-2	Review	535
<sep> <sep> 1.3) From the perspective of learning representations with structured priors, there exists an interesting work on decomposing vector representations into lengths and directions and enforcing lengths to follow a uniform distribution and directions a Von Mises‚ÄìFisher (vMF) distribution as in [2]. It would be interesting to see if the proposed method is indeed better than the way that structured priors are enforced in [2].	B-Review	B-3	Review	535
<sep> 1.4) Linguistically, given the distributional hypothesis, the length of learnt vectors tends to be highly correlated with the frequency information of available concepts and the direction of them matters more.	B-Review	B-4	Review	535
The argument is also presented by the paper.	I-Review	I-4	Review	535
However, in sentiment analysis, the length could contain the information about how strong the sentiment of the input sentence is, so I am not convinced that the proposed method would be applicable in fine-grained sentiment analysis, such as Stanford Sentiment Treebank [3].	I-Review	I-4	Review	535
<sep> <sep> --	O	O	Review	535
2) A soft approximation over the inf-norm of a set of iid samples is log-sum-exp function, and it is the cdf of softmax function, which is also theoretically grounded in EVT for classifications.	B-Review	B-5	Review	535
It could be a nicer story than the current one as the choice of the logistic distribution seems to be too intend.	I-Review	I-5	Review	535
<sep> <sep> <sep> --	O	O	Review	535
3) The construction of the two datasets seems to be very arbitrary given that there exists a large number of sentiment analysis datasets and many with lots of samples, I am not sure that the results on the chosen constructed two datasets are sufficient enough to support the claim.	B-Review	B-6	Review	535
<sep> <sep> 3.1) The size of the datasets is too small.	B-Review	B-7	Review	535
Given that, the marginal improvement against the NN baseline could be a result of a specific initialisation, which doesn't generalise to other random initialisations.	I-Review	I-7	Review	535
<sep> <sep> 3.2) The dimension of vector representations is also too small.	B-Review	B-8	Review	535
Normally, commonly used word embeddings are of 300 dimensions, and contextualised ones are of higher than 1200 dimensions.	I-Review	I-8	Review	535
The chosen 50 dimension could prevent the NN baseline model to perform well and IMO, it is helpful for picking a suitable logistic prior than it is in a very high dimensional space.	I-Review	I-8	Review	535
<sep> <sep> 3.3) There are many straightforward distributions that could be applied as a prior on the lengths of vector representations, e.g. the Rayleigh distribution in 2D and the Chi-squared distribution in higher-dimension.	B-Review	B-9	Review	535
Then again, the distribution gets flatter and becomes similar to a uniform distribution when the dim goes higher, which is a common issue.	I-Review	I-9	Review	535
It goes back to my concern or doubt on the usability of a prior on the norm of high dimensional vectors.	I-Review	I-9	Review	535
<sep> <sep> <sep> --	O	O	Review	535
4) I am still interested in seeing EVT being applied in various domains, but I'd be in favor of more justifiable approaches.	B-Review	B-10	Review	535
<sep> <sep> [1] Siffer, Alban, et al "Anomaly detection in streams with extreme value theory."	O	O	Review	535
Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.	O	O	Review	535
ACM, 2017.	O	O	Review	535
<sep> [2] Guu, Kelvin, et al "Generating sentences by editing prototypes."	O	O	Review	535
Transactions of the Association for Computational Linguistics 6 (2018): 437-450.	O	O	Review	535
<sep> [3] Socher, Richard, et al "Recursive deep models for semantic compositionality over a sentiment treebank."	O	O	Review	535
Proceedings of the 2013 conference on empirical methods in natural language processing.	O	O	Review	535
2013.	O	O	Review	535
We thank AnonReviewer3 for articles [1,2,3]. Though our framework is different, connections with these refs are worthy of attention and we now cite these papers in the introduction.	O	O	Reply	535
<sep> <sep> ‚Ä¢ ‚ÄúIn order to show that the EVT indeed helps empirically in the way that an adversarial classifier enforces the inf-norm of vectors follow the Generalised Extreme Value (GEV) [...] supporting evidence.	O	O	Reply	535
‚Äù	O	O	Reply	535
‚ûú    Selecting the logistic distribution is not the central point since we apply a standardization whose purpose is to place ourselves in the framework where the considered tail index is equal to 1.	B-Reply	B-1	Reply	535
<sep> ‚ÄúFrom the perspective of learning representations with structured priors, there exists an interesting work on decomposing vector representations into lengths [...].	O	O	Reply	535
It would be interesting to see if the proposed method is indeed better than the way that structured priors are enforced in [2].‚Äù	O	O	Reply	535
‚ûú We thank  AnonReviewer3 for mentioning article [2]. In the newest version  we mention that future work will implement a comparison with this work which we have not done yet due to time constraints.	B-Reply	B-3	Reply	535
<sep> <sep> ‚Ä¢ ‚ÄúLinguistically, given the distributional hypothesis, the length of learnt vectors tends to be highly correlated with the frequency information of available concepts and the direction of them matters more. [...]	O	O	Reply	535
would be applicable in fine-grained sentiment analysis, such as Stanford Sentiment Treebank [3].‚Äù	O	O	Reply	535
‚ûú We make no claim that the proposed method would be applicable in fine-grained sentiment analysis such as [3]. We would like to mention that the extreme values in [3] correspond to annotation labels with sharp and strong sentiment.	B-Reply	B-4	Reply	535
Such extremes are not the same as the extreme embeddings that we thoroughly study in this paper.	I-Reply	I-4	Reply	535
<sep> <sep> ‚Ä¢ ‚ÄúThe construction of the two datasets seems to be very arbitrary given that there exists a large number of sentiment analysis datasets and many with lots of samples, I am not sure that the results on the chosen constructed two datasets are sufficient enough to support the claim.	O	O	Reply	535
‚Äù	O	O	Reply	535
‚ûú The datasets are commonly used datasets for binary classification of text data (see [5, 6]).	B-Reply	B-6	Reply	535
What are the datasets that  AnonReviewer3 seems to have in mind?	I-Reply	I-6	Reply	535
<sep> <sep> ‚Ä¢ ‚ÄúThe size of the datasets is too small.	O	O	Reply	535
Given that, the marginal improvement against the NN baseline could be a result of a specific initialisation, which doesn't generalise to other random initialisations.	O	O	Reply	535
‚Äù	O	O	Reply	535
‚ûú The mentioned datasets are commonly used datasets for binary classification of text data.	B-Reply	B-7	Reply	535
We have tried different initializations and obtained similar results.	I-Reply	I-7	Reply	535
We do not report each initialization in this paper.	I-Reply	I-7	Reply	535
Concerning the sizes of datasets, we work with a limited amount of GPU time and we cannot go upscale in our experiments as R2 suggests.	I-Reply	I-7	Reply	535
We want to raise that we have more than 200 extreme samples thus the improvement on the extreme samples is far from marginal.	I-Reply	I-7	Reply	535
Note that the embeddings are not learnt from scratch: they are built to perform a classification task on top of (frozen) BERT embeddings, please refer to the GLUE benchmark (<a href="https://gluebenchmark.com/)" target="_blank" rel="nofollow">https://gluebenchmark.com/)</a> for similar system.	I-Reply	I-7	Reply	535
<sep> <sep> ‚Ä¢ ‚ÄúThe dimension of vector representations is also too small. [...]	O	O	Reply	535
it is in a very high dimensional space.	O	O	Reply	535
‚Äù	O	O	Reply	535
‚ûú In the original BERT paper, the size of the embedding used is 768.	B-Reply	B-8	Reply	535
The size of the learnt embedding in the present work  is a hyperparameter which varies from 10 to 768.	I-Reply	I-8	Reply	535
the value 50 was automatically chosen by cross-validation.	I-Reply	I-8	Reply	535
We now mention this fact in the additional experiment settings for real data section in the Appendix.	I-Reply	I-8	Reply	535
<sep> <sep> ‚Ä¢ ‚ÄúThere are many straightforward distributions [...] a prior on the norm of high dimensional vectors.	O	O	Reply	535
‚Äù	O	O	Reply	535
‚ûú As mentioned earlier in our response, In this paper, we do not use an explicit prior on the radius; Instead our target (=prior) is a multivariate extreme value distribution called the Logistic distribution in the EVT setting.	B-Reply	B-9	Reply	535
It happens that the radial component of this distribution is heavy tailed but this constraint does not need to appear (and does not) in our algorithm.	I-Reply	I-9	Reply	535
<sep> <sep> ---	O	O	Reply	535
[1] Siffer, Alban, et al "Anomaly detection in streams with extreme value theory."	O	O	Reply	535
Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.	O	O	Reply	535
ACM, 2017.	O	O	Reply	535
<sep> [2] Guu, Kelvin, et al "Generating sentences by editing prototypes."	O	O	Reply	535
Transactions of the Association for Computational Linguistics 6 (2018): 437-450.	O	O	Reply	535
<sep> [3] Socher, Richard, et al "Recursive deep models for semantic compositionality over a sentiment treebank."	O	O	Reply	535
Proceedings of the 2013 conference on empirical methods in natural language processing.	O	O	Reply	535
2013.	O	O	Reply	535
<sep> [4] Hamid Jalalzai, Stephan Cl√©mencon, and Anne Sabourin.	O	O	Reply	535
On binary classification in extreme regions.	O	O	Reply	535
In Advances in Neural Information Processing Systems, pp.3092‚Äì3100, 2018.	O	O	Reply	535
<sep> [5] Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016).	O	O	Reply	535
Deep learning.	O	O	Reply	535
MIT press.	O	O	Reply	535
<sep> [6] R Stewart, S Ermon, Label-free supervision of neural networks with physics and domain knowledge, In Thirty-First AAAI Conference on Artificial Intelligence, 2017.	O	O	Reply	535

The authors propose in this paper a variant of Deep SVDD which brings semi-supervision to this model.	O	O	Review	20515
The paper is well written and contains a thorough experimental evaluation (even disregarding the supplementary material).	O	O	Review	20515
As far as I know, the proposed method is new and improve anomaly detection.	O	O	Review	20515
The modification of Deep SVDD are in a way minimalistic, but they do the job.	O	O	Review	20515
<sep> <sep> The only negative aspects, in my opinion, is the "information-theoretic view" which is close to hand waving.	B-Review	B-1	Review	20515
The authors are indeed 1) disregarding the regularization term 2) considering an upper bound of the entropy 3) pretending the results on the pre-trained NN hold after post training.	I-Review	I-1	Review	20515
Putting everything together, I do not see how this reasoning could accepted.	I-Review	I-1	Review	20515
In fact, its extension to Deep SVDD is even more problematic as the discussion in the paper contradicts the reasoning.	I-Review	I-1	Review	20515
The authors emphasize the fact that anomalies should not fulfill the clustering assumption (which is indeed an important remark).	I-Review	I-1	Review	20515
But then the distribution of phi(x,W) cannot be approximated by a Gaussian for anomalies and thus the bound on the entropy is not valid.	I-Review	I-1	Review	20515
<sep> <sep> I strongly recommend to remove this part of the paper and to derive Deep SAD from Deep SVDD from heuristics consideration (which is fine!).	B-Review	B-2	Review	20515
This will provide an opportunity to remove the cute sentence "We are happy to now introduce Deep SAD".	I-Review	I-2	Review	20515
We understand your concerns with the "information-theoretic view," nonetheless we think the framework should remain and is of interest to the ML community for a few reasons:	O	O	Reply	20515
<sep> - Previous theoretical work on anomaly detection [1,2] often assumed that the anomalous distribution is unconcentrated (analogously high-entropy or not clustered) and it is reasonable that this intuition would extend to deep anomaly detection.	B-Reply	B-1	Reply	20515
Our framework introduces and explores the idea of using a training objective to incorporate this assumption.	I-Reply	I-1	Reply	20515
This presents an avenue for future work.	I-Reply	I-1	Reply	20515
For example, in our paper we use high-variance as a proxy for distribution not being clustered.	I-Reply	I-1	Reply	20515
Can we find a better loss to enforce anomalies to be unclustered?	I-Reply	I-1	Reply	20515
Further future work could study the detection performance under the information-theoretic rate-distortion curve [3] or derive novel methods from using other non-parametric estimators for mutual information (e.g. [4]) based on our framework.	I-Reply	I-1	Reply	20515
<sep> <sep> - Other recent work on deep anomaly detection utilizing self-supervised classification have incorporated the use of anomalies during training in a similar way, albeit without theoretical justification [5]. In these methods normal samples are trained to minimize a classification loss.	B-Reply	B-1	Reply	20515
On the other hand anomalous samples are trained so that the softmax output distribution has high entropy, not for misclassification.	I-Reply	I-1	Reply	20515
This results in a network where the softmax output from normal samples are concentrated around at the corners of the probability simplex, and anomalous samples are diffusely spread around the center.	I-Reply	I-1	Reply	20515
Our information-theoretic framework offers a potential explanation for why such an objective is natural and connects it to our method.	I-Reply	I-1	Reply	20515
<sep> <sep> - The Gaussianity assumption for used in Eq. (6) is merely a choice of convenience in order to obtain a simple derivation, but is not necessary to derive the claim that the entropy is minimized by minimizing the empirical variance.	B-Reply	B-1	Reply	20515
To see this, note that the upper bound in Eq. (5) is a log determinant of covariance, which is a sum of the log eigenvalues of.	I-Reply	I-1	Reply	20515
These eigenvalues are variances obtained by projecting the data on certain orthonormal basis vectors.	I-Reply	I-1	Reply	20515
By Cauchy-Schwarz inequality, each of these projected variances are upper bounded by the scalar variance since.	I-Reply	I-1	Reply	20515
<sep> We will add a complete derivation of this claim to the appendix.	I-Reply	I-1	Reply	20515
<sep> <sep> - Reviewer 2 expressed interest in our framework, so we are reluctant to remove it completely.	O	O	Reply	20515
<sep> <sep> In a final version of the paper we will elaborate on the connection to previous work, with a focus on future work.	B-Reply	B-2	Reply	20515
We will also de-emphasize this framework as a way to derive our method, treating it instead as a possible interpretation for why our loss is somewhat "natural," e.g. why it makes sense to concentrate the nominal samples and let the anomalies be diffuse.	I-Reply	I-2	Reply	20515
We will also remove our "cute sentence."	I-Reply	I-2	Reply	20515
<sep> <sep> <sep> [1] Steinwart, I., Hush, D., and Scovel, C. A Classification Framework for Anomaly Detection.	O	O	Reply	20515
Journal of Machine Learning Research, 6(Feb):211‚Äì232, 2005.	O	O	Reply	20515
<sep> [2] Sch√∂lkopf, B. et al Estimating the Support of a High-Dimensional Distribution.	O	O	Reply	20515
Neural computation, 13(7):1443‚Äì1471, 2001.	O	O	Reply	20515
<sep> [3] Alemi, A. et al Fixing a broken ELBO.	O	O	Reply	20515
In ICML, volume 80, pages 159‚Äì168, 2018.	O	O	Reply	20515
<sep> [4] Hjelm, R. D. et al Learning Deep Representations by Mutual Information Estimation and Maximization.	O	O	Reply	20515
In ICLR, 2019.	O	O	Reply	20515
<sep> [5] Hendrycks, D. Mazeika, M., and Dietterich, T. G. Deep Anomaly Detection with Outlier Exposure.	O	O	Reply	20515
In ICLR, 2019.	O	O	Reply	20515

[Summary]	O	O	Review	20515
The paper proposes an abnormal detection (AD) framework under general settings where 1) unlabeled data, 2) labeled positive (normal) data, and 3) labeled negative (abnormal) data are available (with the last two optional), denoted as semi-supervised AD.	O	O	Review	20515
Starting from the assumption that abnormal data are sampled from background unpredicted distribution, rather than ‚Äúcluster‚Äù assumption, it is argued that conventional discriminative formulation is not applicable.	O	O	Review	20515
Motivated by the recent deep AD methods (e.g., deep SVDD), the paper proposes to approach semi-supervised AD from the information theoretic perspective where 1) mutual information between raw data and learnt representation should be maximized (infomax principle), 2) entropy of labeled positive data should be minimized (‚Äúcompactness‚Äù constraint), and 3) enrtropy of labeled negative data should be maximized to reflect the uncertainty assumption of anomaly.	O	O	Review	20515
The solution is implemented by the encoder of a pre-trained autoencoder that is further fine tuned to enforce entropy assumption on all types of training data.	O	O	Review	20515
Extensive experiments on benchmarks suggests promising results on the proposed framework versus other state-of-the-arts.	O	O	Review	20515
<sep> <sep> [Comments]	O	O	Review	20515
The paper is well written and easy to follow (the presentation is especially pleasant to read).	O	O	Review	20515
The problem is well defined and of interest to the community under fairly general and practical conditions.	O	O	Review	20515
Despite the fact that the implementation is only marginally tweaked from previous work (deep SVDD), the theoretical motivation, nevertheless, is sound and well justified, and the empirical evaluation is extensive to reveal the behaviors of the proposed method.	B-Review	B-1	Review	20515
It would be better if complexity analysis can also be provided for all concerning methods.	I-Review	I-1	Review	20515
Overall, the value of the paper is worth circulation in the community.	O	O	Review	20515
<sep> <sep> [Area to improve]	O	O	Review	20515
The manuscript could be further improved by exploring the training process more.	B-Review	B-2	Review	20515
In the current format, the solution follows the strategy of deep SVDD that learns the model in two separate stages: pre-training the autoencoder, and then fitting the encoder to enforce compactness and entropy minimization/maximization.	I-Review	I-2	Review	20515
What if these are implemented in an end-to-end fashion?	I-Review	I-2	Review	20515
Will this help to achieve a better result?	I-Review	I-2	Review	20515
<sep> We have performed experiments without pre-training as well as incorporating end-to-end autoencoder training.	B-Reply	B-2	Reply	20515
Our method consistently performs worse without pre-training.	I-Reply	I-2	Reply	20515
With an end-to-end autoencoder we achieve performance approximately as good as presented in this paper, provided one uses a training regimen which first emphasizes and then de-emphasizes the autoencoder loss, which is essentially pre-training.	I-Reply	I-2	Reply	20515
We will include these points in our final draft.	I-Reply	I-2	Reply	20515

This work uses sequence-to-sequence and memory network neural nets to learn a	O	O	Review	1527
network that not only predicts a label, but also predicts nearest neighbors and	O	O	Review	1527
their label.	O	O	Review	1527
The intuition is that by training on a related but harder task,	O	O	Review	1527
the network is forced to learn not just about sampled points but about the	O	O	Review	1527
behavior in regions around the actual training examples.	O	O	Review	1527
<sep> <sep> Their work shows that imposing these additional requirements on the model does	O	O	Review	1527
result in better performance on unseen data, where only the label of the unseen	O	O	Review	1527
data point is required as output.	O	O	Review	1527
They show that learning more about the	O	O	Review	1527
global {feature,label} distribution improves F1 scores, and suggest that their	O	O	Review	1527
methods can be used as an example generator for datasets with class imbalance.	O	O	Review	1527
<sep> <sep> The writing was clear.	B-Review	B-1	Review	1527
I had only 1 misunderstanding that cause me trouble,	I-Review	I-1	Review	1527
namely the first sentence of "Classification", where I might put the word	I-Review	I-1	Review	1527
'benchmark' up front rather than at the end of this somewhat long sentence.	I-Review	I-1	Review	1527
<sep> By the time 'knn benchmark' appeared some paragraphs later, I realized I	I-Review	I-1	Review	1527
had missed something, and had to backtrack.	I-Review	I-1	Review	1527
<sep> <sep> Figs 1--3 are only viewable on screen with fairly extreme magnification.	B-Review	B-2	Review	1527
I	I-Review	I-2	Review	1527
found different viewers varied in legibility at these extreme zoom settings.	I-Review	I-2	Review	1527
<sep> However, when expanded so y-axis numbers could be deciphered, it turned out	I-Review	I-2	Review	1527
that actual improvements in F1 score were rather modest.	I-Review	I-2	Review	1527
<sep> <sep> For 4 datasets, their F1 scores of their best method, V2VSLS, improved by ~ 1.5	B-Review	B-3	Review	1527
to 6%.	I-Review	I-3	Review	1527
They found that their methods were less affected by out-of-core	I-Review	I-3	Review	1527
computation than the benchmark kNN F1 scores.	I-Review	I-3	Review	1527
<sep> <sep> I did have some questions about the problem formulation.	B-Review	B-4	Review	1527
I did not really	I-Review	I-4	Review	1527
understand why the models wanted to reproduce the exact ordering of the	I-Review	I-4	Review	1527
nearest neighbors, other than this is easy to formulate.	I-Review	I-4	Review	1527
This makes sense	I-Review	I-4	Review	1527
for n.n.	I-Review	I-4	Review	1527
label sequences, where further points might be in some neighboring	I-Review	I-4	Review	1527
class.	I-Review	I-4	Review	1527
But for predicting the feature vectors of n.n.,	I-Review	I-4	Review	1527
it seems that the	I-Review	I-4	Review	1527
exact order is not robust, in the sense very small distance changes can cause	I-Review	I-4	Review	1527
abrupt shifts in the target nearest-neghbor ordering.	I-Review	I-4	Review	1527
Is there some way	I-Review	I-4	Review	1527
for me to understand why this does not pose a problem?	I-Review	I-4	Review	1527
Or is there perhaps	I-Review	I-4	Review	1527
a way to make the loss function a bit less dependent on the precise order	I-Review	I-4	Review	1527
of the generated feature vector sequence?	I-Review	I-4	Review	1527
<sep> <sep> In the computational experiments, with the choice of datasets, it was often	B-Review	B-5	Review	1527
hard for me to judge how much different aspects of their 4 network structures	I-Review	I-5	Review	1527
were really being excercised.	I-Review	I-5	Review	1527
The main issue is the all problems used only	I-Review	I-5	Review	1527
2--3 classes.	I-Review	I-5	Review	1527
I could not guess what fraction of data points had actual label	I-Review	I-5	Review	1527
changes within the 5 n.n..  For many datasets, "same class" might be a pretty	I-Review	I-5	Review	1527
good predictor of nearest neighbor label.	I-Review	I-5	Review	1527
<sep> <sep> Alternatively, one can consider the other extreme, of very many classes.	B-Review	B-6	Review	1527
<sep> Does it still make sense to try to predict the order of nearest neighbor labels in	I-Review	I-6	Review	1527
such a setting?	I-Review	I-6	Review	1527
<sep> <sep> The authors provide evidence of some performance improvement, but I would	B-Review	B-7	Review	1527
encourage them to provide some intuition about what the networks are actually	I-Review	I-7	Review	1527
learning.	I-Review	I-7	Review	1527
Some of this can be done with their existing data.	I-Review	I-7	Review	1527
<sep> <sep> For example, on average, what are the distances from predicted feature vectors	B-Review	B-8	Review	1527
to the actual nn feature vectors?	I-Review	I-8	Review	1527
If the feature sequence is typically badly	I-Review	I-8	Review	1527
predicted, then this might allow the authors to propose that the network is	I-Review	I-8	Review	1527
*actually* learning some simpler features of the the distributions underlying	I-Review	I-8	Review	1527
an actual {feature,label} sequence.	I-Review	I-8	Review	1527
This might allow simplified training losses,	I-Review	I-8	Review	1527
based, on things like direction and distance to same-label cluster center,	I-Review	I-8	Review	1527
direction+distance to average same-class nn.s, direction and distance to	I-Review	I-8	Review	1527
closest differently labeled cluster, etc.	I-Review	I-8	Review	1527
Or does their data suggest that	I-Review	I-8	Review	1527
their models are actually learning the precise nearest neighbor ordering?	I-Review	I-8	Review	1527
<sep> <sep> Such considerations might be able to improve the OOC training, since	B-Review	B-9	Review	1527
"global" aspects of the distribution features (like "cluster center")	I-Review	I-9	Review	1527
remain approx.	I-Review	I-9	Review	1527
valid as training batches changes.	I-Review	I-9	Review	1527
<sep> <sep> The other question I had was with the oversampling proposition.	B-Review	B-10	Review	1527
The extent	I-Review	I-10	Review	1527
of class imbalance in the datasets is not described.	I-Review	I-10	Review	1527
Perhaps it belongs in	I-Review	I-10	Review	1527
Table 1.	I-Review	I-10	Review	1527
Their approach seems a lot of work for modest gains usually available	I-Review	I-10	Review	1527
with oversampling.	I-Review	I-10	Review	1527
Can the authors provide any guideline for how many members a	I-Review	I-10	Review	1527
minority class should have before using their sequence-to-sequence technique?	I-Review	I-10	Review	1527
<sep> <sep> Pros: they improve generalization to unseen data.	O	O	Review	1527
<sep> Cons: their models are considerably more complex, and they do not analyze their	B-Review	B-11	Review	1527
data in enough detail to suggest whether their complexity is necessary, or perhaps	I-Review	I-11	Review	1527
could be reduced.	I-Review	I-11	Review	1527
Figures are too small (many unreadable in printed copy).	I-Review	I-11	Review	1527
<sep> Datasets have very few classes and the extent to which nearest neighbors are	I-Review	I-11	Review	1527
of different class not reported.	I-Review	I-11	Review	1527
<sep> <sep> Thank you very much for the comments.	B-Reply	B-4	Reply	1527
For the issue of ordering of nearest neighbors, we postulate that this is because when predicting the label of a sample, the model tries to predict k probability distributions and mimic ‚Äúmajority voting.	I-Reply	I-4	Reply	1527
‚Äù For example, for a sample x, the predicted label sequence is, say, [2,1,1,1,2], the final predicted label would very likely be the same if the predicted label sequence is [1,2,1,1,2], due to ‚Äúmajority voting.	I-Reply	I-4	Reply	1527
‚Äù An order is quite natural ‚Äì based on the distance from the sample.	I-Reply	I-4	Reply	1527
In summary, while there is no direct order, the order based on the distance makes sense in our opinion.	I-Reply	I-4	Reply	1527
To get a better handle on the order, we are currently conducting an experiment where we swap some elements in the order.	I-Reply	I-4	Reply	1527
We will post here the findings as soon as we have them.	I-Reply	I-4	Reply	1527
<sep> <sep> [UPDATE] We have tried to swap the 1st and the 3rd element in the order, and the results only have a tiny difference.	I-Reply	I-4	Reply	1527
The results are shown below (4 datasets):	I-Reply	I-4	Reply	1527
V2VSLS: 92.07/94.97/86.24/69.87	I-Reply	I-4	Reply	1527
Swapped: 91.79/94.56/85.99/69.42	I-Reply	I-4	Reply	1527
These numbers are based on the average of five runs.	I-Reply	I-4	Reply	1527
The results suggest that the order of nearest neighbors does not have a big impact.	I-Reply	I-4	Reply	1527
Note also that in our loss function there is a KL divergence term between the ground truth label and the final predicted label with a high weight.	I-Reply	I-4	Reply	1527
<sep> <sep> [UPDATE] We have also implemented the algorithm from Wang et al (2017), which also utilized the nearest neighbors to make predictions.	I-Reply	I-4	Reply	1527
The comparison is shown below (4 datasets):	I-Reply	I-4	Reply	1527
V2VSLS: 92.07/94.97/86.24/69.87	I-Reply	I-4	Reply	1527
Memory Network: 79.36/77.98/75.17/61.83	I-Reply	I-4	Reply	1527
Wang: 64.18/69.64/54.29/52.18	I-Reply	I-4	Reply	1527
In the implementation of Wang, we have fine-tuned the hyperparameters: K, I, Learning rate.	I-Reply	I-4	Reply	1527
The optimizer used is Adam.	I-Reply	I-4	Reply	1527
These numbers are based on the average of five runs.	I-Reply	I-4	Reply	1527
There is a gap between our models and Wang‚Äôs model, and we were unable to further improve the Wang's model.	I-Reply	I-4	Reply	1527
<sep> <sep> Regarding your suggestion of changing the loss function to be less dependent on the order of the feature vector sequence, we have actually tried to change the sum of MSE losses (Sum (X^T_i ‚Äì X^P_i)^2) to the MSE loss between every X^P_i and the average feature vector (Sum (X^T_i)/k) or the feature vector X itself.	B-Reply	B-4	Reply	1527
The experiments have showed that our current loss function outperforms these options.	I-Reply	I-4	Reply	1527
<sep> <sep> Regarding the second issue of how many members a minority class should have before using the seq2seq technique, the minority class proportions for our four datasets vary from approximately 3% to 30% (thanks for the note - we will include such information in Table 1), and our proposed seq2seq technique works well in this range.	B-Reply	B-10	Reply	1527
Since its performance is more stable than other oversampling techniques, we suggest trying this model in the oversampling task as long as the minority class consists of less than 30% of all samples.	I-Reply	I-10	Reply	1527

I had a hard time understanding this paper.	O	O	Review	1527
The approach is clearly about combining kNN with neural networks, but it wasn‚Äôt clear how it is done.	O	O	Review	1527
After reading the whole paper, my guess is that kNN is done on raw data first, and then its results are used for training a neural network.	O	O	Review	1527
In particular, a network is trained to predict the labels of neighboring samples, which are obtained by kNN beforehand.	O	O	Review	1527
A simple figure explaining it in the introduction would be very helpful since the idea is not that complex.	B-Review	B-1	Review	1527
<sep> <sep> Also, the authors also fail to give an adequate explanation on why the method works.	B-Review	B-2	Review	1527
The only reason I can think of is that this regularization forces the model to detect if a sample near a class boundary.	I-Review	I-2	Review	1527
This is because when a sample is far from boundaries and surrounded by samples of the same class, the model would simply predict that class label.	I-Review	I-2	Review	1527
The same is true when predicting out-of-sample vectors because the average position of K'th neighbor is likely to overlap with the input sample due to the randomness of sampling.	I-Review	I-2	Review	1527
<sep> <sep> I don‚Äôt really see why a memory-based model is introduced.	B-Review	B-3	Review	1527
The external memory is used for holding random samples.	I-Review	I-3	Review	1527
It is not clear how the model can use such random samples for making predictions.	I-Review	I-3	Review	1527
Also, the authors give no explanation to why it should help.	I-Review	I-3	Review	1527
The results also don‚Äôt show the benefit of a memory-based model.	I-Review	I-3	Review	1527
Maybe the authors should look into models that output a set instead of a sequence since neighbors are more like a set in their structure.	I-Review	I-3	Review	1527
<sep> <sep> The experimental results show clear improvements over basic baselines, so the method is doing some regularization.	B-Review	B-4	Review	1527
However, I'm not very familiar with datasets used here and their state-of-art.	I-Review	I-4	Review	1527
They are relatively low dimensional compared to usual datasets used in deep learning.	I-Review	I-4	Review	1527
It is not clear if the method can scale to high dimensional data such as images.	I-Review	I-4	Review	1527
The vanilla neural network is not really a strong baseline here.	I-Review	I-4	Review	1527
Since the authors proposed a regularization technique, it should be compared with other regularization techniques in neural networks.	I-Review	I-4	Review	1527
<sep> <sep> Pros:	O	O	Review	1527
- a simple idea	O	O	Review	1527
- encouraging experimental results	O	O	Review	1527
<sep> Cons:	O	O	Review	1527
- confusing read	B-Review	B-5	Review	1527
- no clear intuition is given	B-Review	B-6	Review	1527
- restricted to low-dimensional datasets	B-Review	B-4	Review	1527
- strong baselines needed	B-Review	B-4	Review	1527
- the plots are too small to see (impossible to see when printed)	B-Review	B-7	Review	1527
<sep> Other comments:	O	O	Review	1527
- The authors are using the term "feature vector" to refer to a data point.	B-Review	B-8	Review	1527
However, in the context of neural networks, "feature vector" often means a hidden representation of a neural network.	I-Review	I-8	Review	1527
<sep> - why repeat "randomly draw B samples" R times?	B-Review	B-9	Review	1527
why not directly sample RxB samples?	I-Review	I-9	Review	1527
<sep> - "it is quite implausible that only affine ..." any evidence to support this?	B-Review	B-10	Review	1527
<sep> - The model is not really "sequence-to-sequence" since the input is not a sequence.	B-Review	B-11	Review	1527
<sep> <sep> Thank you very much for the comments.	O	O	Reply	1527
Your understanding is correct ‚Äì kNN is done on raw data first, then the results are used for training a neural network.	B-Reply	B-2	Reply	1527
Regarding the reason of why the method works, we postulate that this is because the model is forced to learn more than just the final label of a sample; it also needs to learn its nearest feature vectors.	I-Reply	I-2	Reply	1527
The idea is similar to an autoencoder, which is able to compress and then recover the data.	I-Reply	I-2	Reply	1527
By projecting the data to a lower dimensional space, the model is forced to learn the most representative information of inputs, so that the compressed information can be used to recover the original data.	I-Reply	I-2	Reply	1527
If the model is forced to reconstruct more complex information from compressed information, it is expected that it needs to work harder and thus to produce more exact predictions.	I-Reply	I-2	Reply	1527
<sep> <sep> Regarding the reason why we consider a memory network, the structure of a vanilla memory network fits perfectly with our original thought: after each hop of a memory network, the network outputs a label or a feature vector.	B-Reply	B-3	Reply	1527
This is very similar to the sequence to sequence concept.	I-Reply	I-3	Reply	1527
However, experiments show that the memory network family does not perform well ‚Äì the sequence to sequence family works much better.	I-Reply	I-3	Reply	1527
We wanted to assess whether those different structures would improve the performance, and unfortunately, they do not perform well.	I-Reply	I-3	Reply	1527
We are reporting these results in order for other researchers not to spend time on such attempts.	I-Reply	I-3	Reply	1527
<sep> <sep> Regarding  the comment about baseline models, we have fine-tuned the vanilla neural network with dropout regularization.	B-Reply	B-4	Reply	1527
The baseline result in the paper already includes this regularization.	I-Reply	I-4	Reply	1527
We have also tried the L1/L2 regularization, but dropout outperforms them on the baseline neural network model.	I-Reply	I-4	Reply	1527
<sep> <sep> For the point ‚Äòthe model is not really a sequence to sequence model since the input is not a sequence,‚Äô we can in fact regard the input as the sequence of length 1, and then the seq2seq model can be applied in this situation.	B-Reply	B-11	Reply	1527
<sep> <sep> For the point ‚Äò"it is quite implausible that only affine ..." any evidence to support this,‚Äô for example the two linking rings are not easy to separate if we only use affine transformation etc.	B-Reply	B-10	Reply	1527
<sep> <sep> Regarding ‚Äòwhy repeat "randomly draw B samples" R times?	O	O	Reply	1527
why not directly sample RxB samples,‚Äô our assumption is that at most B samples can fit to computer memory (and thus RxB cannot).	B-Reply	B-9	Reply	1527
Randomly drawing B samples R times fixes this problem.	I-Reply	I-9	Reply	1527
<sep> <sep> [UPDATE] To get a better handle on the order of nearest neighbors, we have tried to arbitrarily swap the 1st and the 3rd element in the order, and the results only have a tiny difference.	B-Reply	B-12	Reply	1527
The results are shown below (4 datasets):	I-Reply	I-12	Reply	1527
V2VSLS: 92.07/94.97/86.24/69.87	I-Reply	I-12	Reply	1527
Swapped: 91.79/94.56/85.99/69.42	I-Reply	I-12	Reply	1527
These numbers are based on the average of five runs.	I-Reply	I-12	Reply	1527
The results suggest that the order of nearest neighbors does not have a big impact.	I-Reply	I-12	Reply	1527
Note also that in our loss function there is a KL divergence term between the ground truth label and the final predicted label with a high weight.	I-Reply	I-12	Reply	1527
<sep> <sep> [UPDATE] We have also implemented the algorithm from Wang et al (2017), which also utilized the nearest neighbors to make predictions.	B-Reply	B-13	Reply	1527
The comparison is shown below (4 datasets):	I-Reply	I-13	Reply	1527
V2VSLS: 92.07/94.97/86.24/69.87	I-Reply	I-13	Reply	1527
Memory Network: 79.36/77.98/75.17/61.83	I-Reply	I-13	Reply	1527
Wang: 64.18/69.64/54.29/52.18	I-Reply	I-13	Reply	1527
In the implementation of Wang, we have fine-tuned the hyperparameters: K, I, Learning rate.	I-Reply	I-13	Reply	1527
The optimizer used is Adam.	I-Reply	I-13	Reply	1527
These numbers are based on the average of five runs.	I-Reply	I-13	Reply	1527
There is a gap between our models and Wang‚Äôs model, and we were unable to further improve the Wang's model.	I-Reply	I-13	Reply	1527

To exploit the near neighbor/manifold features, this paper proposes to combine k-nearest neighbors of each training data point into the neural network models.	O	O	Review	1527
Specifically, the authors propose two families of models built on the popular sequence to sequence neural network models and memory network models, which mimic the k-nearest neighbors model in model learning.	O	O	Review	1527
Besides, the final label of the classification task will be learned, a sequence of nearest neighbor labels and a sequence of out-of-sample feature vectors (for oversampling) will be also learned in the same time, similar with the multi-task approaches.	O	O	Review	1527
Since the proposed models are based k-nearest neighbor calculations, which is time-consuming, they also design an algorithm for the ‚Äòout-of-core‚Äô situation, say load a small portion of data each time to approximately calculate the neighbors.	O	O	Review	1527
Experiments show that some proposed models work better than baselines in classification and oversampling.	O	O	Review	1527
<sep> Strong points:	O	O	Review	1527
(1) As similar with the multi-task setting, the proposed model can output some side useful results, such as oversampling vectors.	O	O	Review	1527
<sep> (2) The proposed models work well on the ‚Äòout-of-core‚Äô situation, which shows that the models are robust.	O	O	Review	1527
<sep> Concerns or suggestions:	O	O	Review	1527
(1) The training data is just one data point, it is not a sequence of data.	B-Review	B-1	Review	1527
So the idea to model it in a sequence to sequence setting does not make sense.	I-Review	I-1	Review	1527
<sep> (2) K-nearest neighbors are a set but not a sequence.	B-Review	B-2	Review	1527
To model them as a sequence is also strange.	I-Review	I-2	Review	1527
The i-th nearest neighbor does not necessarily dependent on the i-1-th nearest neighbor.	I-Review	I-2	Review	1527
For example, we consider the one-dimensional case, the focus data may lie between its first and second nearest neighbors.	I-Review	I-2	Review	1527
In this case, there is no clear sequence dependence from the second neighbor to the first neighbor.	I-Review	I-2	Review	1527
<sep> (3) The experiments are not sufficient.	B-Review	B-3	Review	1527
They only compare with some weak baselines, such as KNN.	I-Review	I-3	Review	1527
As the classification task, there are many state-of-the-art models.	I-Review	I-3	Review	1527
Besides of these standard classification models, we strongly suggest comparing with the previous method, Wang et al (2017), which also proposes to combine the k-nearest neighbors into memory network models.	I-Review	I-3	Review	1527
I am surprised that the authors did not compare with this very related work.	I-Review	I-3	Review	1527
In my opinion, the idea of utilizing nearest neighbors as external memory in Wang et al (2017) makes more senses.	I-Review	I-3	Review	1527
<sep> (4) The experimental results of some proposed sub-models (key parts of final models) are even worse than the basic kNN model.	B-Review	B-4	Review	1527
I should say that the results are not good enough to support the proposed methods.	I-Review	I-4	Review	1527
Thank you very much for the comments.	O	O	Reply	1527
Regarding the first point, we can regard the input as the sequence of length 1, and then the seq2seq model can be applied in this situation.	O	O	Reply	1527
<sep> <sep> Regarding the second point, an order is quite natural ‚Äì based on the distance from the sample.	B-Reply	B-2	Reply	1527
In summary, while there is no direct order, the order based on the distance makes sense in our opinion.	I-Reply	I-2	Reply	1527
When predicting the label of a sample, the model tries to predict probability distributions and mimic ‚Äúmajority voting.	I-Reply	I-2	Reply	1527
‚Äù We have also tried changing the loss function to be less (or not) dependent on the order of the feature vector sequence: we tried changing the sum of MSE losses (Sum (X^T_i ‚Äì X^P_i)^2) to the MSE loss between every X^P_i and the average feature vector (Sum (X^T_i)/k) or the feature vector X itself.	I-Reply	I-2	Reply	1527
The experiments show that our current loss function (dependent sequence) outperforms these options (independent or less dependent sequence).	I-Reply	I-2	Reply	1527
To get a better handle on the order, we are currently conducting an experiment where we swap some elements in the order.	I-Reply	I-2	Reply	1527
We will post here the findings as soon as we have them.	I-Reply	I-2	Reply	1527
<sep> <sep> [UPDATE] To get a better handle on the order of nearest neighbors, we have tried to arbitrarily swap the 1st and the 3rd element in the order, and the results only have a tiny difference.	B-Reply	B-2	Reply	1527
The results are shown below (4 datasets):	I-Reply	I-2	Reply	1527
V2VSLS: 92.07/94.97/86.24/69.87	I-Reply	I-2	Reply	1527
Swapped: 91.79/94.56/85.99/69.42	I-Reply	I-2	Reply	1527
These numbers are based on the average of five runs.	I-Reply	I-2	Reply	1527
The results suggest that the order of nearest neighbors does not have a big impact.	I-Reply	I-2	Reply	1527
Note also that in our loss function there is a KL divergence term between the ground truth label and the final predicted label with a high weight.	I-Reply	I-2	Reply	1527
<sep> <sep> Regarding the third point, in our results, our model outperforms a fine-tuned neural network (with regularization, using the Adam optimization algorithm, etc.),	B-Reply	B-3	Reply	1527
random forest, XGBoosting etc.,	I-Reply	I-3	Reply	1527
which we consider as the state-of-the-art general classifiers.	I-Reply	I-3	Reply	1527
For example, XGBoosting is a frequent winner in many Kaggle competitions.	I-Reply	I-3	Reply	1527
<sep> <sep> [UPDATE] We have also implemented the algorithm from Wang et al (2017), which also utilized the nearest neighbors to make predictions.	B-Reply	B-3	Reply	1527
The comparison is shown below (4 datasets):	I-Reply	I-3	Reply	1527
V2VSLS: 92.07/94.97/86.24/69.87	I-Reply	I-3	Reply	1527
Memory Network: 79.36/77.98/75.17/61.83	I-Reply	I-3	Reply	1527
Wang: 64.18/69.64/54.29/52.18	I-Reply	I-3	Reply	1527
In the implementation of Wang, we have fine-tuned the hyperparameters: K, I, Learning rate.	I-Reply	I-3	Reply	1527
The optimizer used is Adam.	I-Reply	I-3	Reply	1527
These numbers are based on the average of five runs.	I-Reply	I-3	Reply	1527
There is a gap between our models and Wang‚Äôs model, and we were unable to further improve the Wang's model.	I-Reply	I-3	Reply	1527
<sep> <sep> Regarding the fourth point, I assume you were referring to the memory networks models and V2VS.	B-Reply	B-4	Reply	1527
That is correct ‚Äì we wanted to assess whether those different structures would improve the performance, and unfortunately, they do not perform well.	I-Reply	I-4	Reply	1527
We are reporting these results in order for other researchers not to spend time on such attempts.	I-Reply	I-4	Reply	1527
However, the V2VSLS performance is excellent, and therefore V2VSLS is the main method our work suggests.	I-Reply	I-4	Reply	1527

The work proposes a structure that mimics progressive nets.	O	O	Review	1523
Maybe the main difference from progressive nets is that backwards connection from the new features to the old features in layer 2 are not 0 out.	B-Review	B-1	Review	1523
This could cause interference, however is solved by using the task ID to not evaluate those new features when going back to a previous task.	I-Review	I-1	Review	1523
I think this is a technical detail, that does not provide any explicit advantage or disadvantage over progressive nets.	I-Review	I-1	Review	1523
<sep> <sep> Employing GANs/VAE to predict task id also can be seen as not an ideal choice.	B-Review	B-2	Review	1523
In particular the GAN network will suffer from catastrophic forgetting, which is solved (if I understood correctly) by training the GAN with data from all tasks.	I-Review	I-2	Review	1523
Which makes one wonder, if we can affort to access data from all tasks to learn the GAN then why not the classification model too !?	I-Review	I-2	Review	1523
<sep> <sep> I think an alternative might be something like the Forget Me Not Process published and used in the original work with EWC.	B-Review	B-3	Review	1523
<sep> <sep> Unfortunately due to presence of these previous works, lack of more thorough comparison with other existing approaches, the work should not be accepted to ICLR.	B-Review	B-4	Review	1523
Thank you for the comments and feedbacks.	O	O	Reply	1523
<sep> <sep> We think there was a misunderstanding.	B-Reply	B-1	Reply	1523
Gradients to the old features are 0 out to make sure they do not ruin the trained parameters.	I-Reply	I-1	Reply	1523
<sep> In the progressive network, each feature is summarized by an additional adapter and passed to the next task network.	I-Reply	I-1	Reply	1523
Therefore, it is not a typical form of CNN.	I-Reply	I-1	Reply	1523
Meanwhile, our HCnet takes the form of a regular CNN and just expands the number of filters so that the new information is learned by those additional filters.	I-Reply	I-1	Reply	1523
That is why we compared our method to the Packnet.	I-Reply	I-1	Reply	1523
Packnet also divides its capacity into several pieces but has no ability to add more tasks once the network is trained and pruned.	I-Reply	I-1	Reply	1523
What we wanted to present in this paper was (1) we can retain the properties of the Packnet (2) without using any pruning process which makes the packnet unexpandable, (3) in a typical form of CNN so that it can be easily used in various applications.	I-Reply	I-1	Reply	1523
<sep> <sep> In the case of the GAN/VAE, We do not use the whole datasets for the generative model.	B-Reply	B-2	Reply	1523
If there are three tasks, the H-Net also has three generative models.	I-Reply	I-2	Reply	1523
Each generative model is trained only using each task data.	I-Reply	I-2	Reply	1523
Then, the binary classifier use the three generators for training.	I-Reply	I-2	Reply	1523

Summary	O	O	Review	1523
This paper proposes an extension of Progressive Networks [Rusu et al NIPS 2016] (unfortunately, not cited) where the task id is not given at test time.	O	O	Review	1523
This is inferred by a battery of classifiers trained on data produced by generative models trained on task specific data.	O	O	Review	1523
<sep> The authors argue strong connections to similar mechanisms in the human brain and demonstrate this method on a stream of 2 or 3 vision tasks.	B-Review	B-1	Review	1523
However, the interpretation of these results is dubious.	I-Review	I-1	Review	1523
<sep> <sep> Novelty: given prior work on Progressive Nets and other methods using generative models for continual learning, novelty is limited.	B-Review	B-2	Review	1523
<sep> <sep> Relevance: the motivation and aim of this work is certainly relevant for ICLR.	O	O	Review	1523
<sep> <sep> Clarity: the paper is overall clear, although it needs a bit of rewriting to improve fluency (see for instance sec.3.4.1).	B-Review	B-3	Review	1523
<sep> <sep> References: the authors should definitely cite Progressive Networks and their extension "Progress and Compress" (Schwarz ICML 2018), as their approach is an extension of the former with the only difference that the task id is inferred at test time by using a battery of binary classifiers.	B-Review	B-4	Review	1523
<sep> <sep> Empirical validation: The empirical validation is limited because of:	B-Review	B-5	Review	1523
a) lack of comparison to Progressive Nets,	I-Review	I-5	Review	1523
b) lack of simple baselines (e.g., how about replacing H-Net with an inference process like task_id = argmin_i=1..T loss(C-Net, task = i) ),	B-Review	B-5	Review	1523
c) unclear interpretation of the provided results (how can the accuracy on MNIST be 100%?	B-Review	B-5	Review	1523
are the authors reporting training accuracy?)	I-Review	I-5	Review	1523
<sep> d) very limited number of tasks considered (up to 3)	B-Review	B-5	Review	1523
<sep> General comments	O	O	Review	1523
Major drawbacks of the proposed approach are: 1) training on new tasks can never improve performance on past tasks (unlike other methods like GEM (Lopez-Paz et al NIPS 2017), 2) the number of parameters grow linearly with the number of tasks (an issue addressed by the Progress and Compress paper above), and 3) the overall approach is not efficient as it requires lots of data from each task in order to train the generative models.	B-Review	B-6	Review	1523
<sep> Finally, I think all the connections and inspiration from how the human brain works should be toned down.	B-Review	B-7	Review	1523
Statements like "the C-Net corresponds to the human cortex..." should be at the very least rephrased appropriately.	I-Review	I-7	Review	1523
Thank you for the comments and feedbacks.	O	O	Reply	1523
<sep> <sep> We agree that the citation of Progressive networks should be included in this paper.	B-Reply	B-5	Reply	1523
However, What we meant in this paper was that  our method can allocate each task parameters to each part of the model and that is what the Packnet does.	I-Reply	I-5	Reply	1523
We simply wanted to show that given the same number of parameters, additional pruning process and filter mask of Packnet are not necessary.	I-Reply	I-5	Reply	1523
Also, progressive network includes additional adaptor modules in each layer and is difficult to say which setting would contain the exactly equal capacity of our model.	I-Reply	I-5	Reply	1523
These are the reasons why we presented a comparison with the Packnet.	I-Reply	I-5	Reply	1523
<sep> <sep> (a) We agree that the citation of Progressive networks should be included in this paper.	O	O	Reply	1523
However, What we meant in this paper was that  our method can allocate each task parameters to each part of the model and that is what the Packnet does.	O	O	Reply	1523
We simply wanted to show that given the same number of parameters, additional pruning process and filter mask of Packnet are not necessary.	O	O	Reply	1523
Also, progressive network includes additional adaptor modules in each layer and is difficult to say which setting would contain the exactly equal capacity of our model.	O	O	Reply	1523
These are the reasons why we presented a comparison with the Packnet.	O	O	Reply	1523
<sep> (b) We agree that your suggestion is reasonable.	B-Reply	B-5	Reply	1523
<sep> (c) The results are evaluated in the validation data of each dataset.	B-Reply	B-5	Reply	1523
Separating Mnist from SVHN is obviously an easy task for the Hnet and we wrote the details in the 'Hnet' section.	I-Reply	I-5	Reply	1523
<sep> <sep> (d) With the lack of time and resources, we evaluated our method on three tasks.	B-Reply	B-5	Reply	1523
We can try more tasks in the future but we think that this won't change the aspects of our experiments.	I-Reply	I-5	Reply	1523
<sep> <sep> (1) Instead of improving the old tasks performance we have chosen to 'not degrading' the performance.	B-Reply	B-6	Reply	1523
This point can samely applied to the Packnet.	I-Reply	I-6	Reply	1523
<sep> (2) Given the same parameter, we can allocate the model's capacity to each task and 'also' can expand the network if needed, which is impossible for the Packnet.	B-Reply	B-6	Reply	1523
<sep> (3) The Hnet is trained with each dataset in return for the ability to know where the data comes from.	B-Reply	B-6	Reply	1523
We think that whether this approach is efficient or not is a subjective problem.	I-Reply	I-6	Reply	1523
In the previous works such as Progressive networks, LwF and Packnet, they just left this problem as a future work and we just suggested a baseline method for it.	I-Reply	I-6	Reply	1523
<sep> (4) We admit that the expression about the human brain may be too exagerated.	B-Reply	B-7	Reply	1523

The key idea of this paper is to expand the network for training on new tasks which is termed as C-Net, and train an additional generative model which is used for predicting task id (which is called H-Net), and use the task id for selecting weights from the C-Net.	O	O	Review	1523
<sep> <sep> Pros:	O	O	Review	1523
1.	O	O	Review	1523
It is relatively easy to understand the paper.	O	O	Review	1523
<sep> 2.	O	O	Review	1523
The originality of this paper lies in the usage of generative model to predict task id (H-Net).	O	O	Review	1523
To my knowledge has not been proposed before.	O	O	Review	1523
<sep> 3.	O	O	Review	1523
In contrast to previous works in multi-task learning, which assumes task id is available both during training and inference, this work tries to remove the need of task id during inference, which makes it closer to the general definition of continual learning.	O	O	Review	1523
<sep> <sep> Cons:	O	O	Review	1523
1.	B-Review	B-1	Review	1523
Expanding the network for new tasks is not a novel contribution of this paper, it has already been proposed in previous works on multi-task learning.	I-Review	I-1	Review	1523
Doing expansion on all of the layers does not qualify for a major contribution in my opinion.	I-Review	I-1	Review	1523
<sep> 2.	O	O	Review	1523
The experimental comparison is not very fair in my opinion,	B-Review	B-2	Review	1523
a. Comparing accuracy of C-Net to other methods is not very useful.	I-Review	I-2	Review	1523
Because this methods expands the network for every new task, while other methods (EWC, LwF) has limited to no expansion in the network.	I-Review	I-2	Review	1523
Given that the single network result is far from state of the art (table 3), I suppose model size could contribute to the accuracy boost.	I-Review	I-2	Review	1523
<sep> b. It is not explicitly stated in the paper whether the output neurons are shared between tasks or an individual set of output neurons are used for different tasks, but from the rest of the paper I suppose disjoint neurons are used.	B-Review	B-2	Review	1523
Then the comparison between EWC and this work is not fair because EWC shares the output neurons among tasks.	I-Review	I-2	Review	1523
<sep> This is not to blame this paper for not making fair comparison, since given different assumptions between methods (availability of task id, shared output neurons etc.),	I-Review	I-2	Review	1523
it is usually difficult to fairly compare between continual learning methods.	I-Review	I-2	Review	1523
This problem is raised in another submission <a href="https://openreview.net/forum?id=ByGVui0ctm."	I-Review	I-2	Review	1523
target="_blank" rel="nofollow">https://openreview.net/forum?id=ByGVui0ctm.</a> The point here is that the accuracy of C-Net is not a good measure of how good this method is.	I-Review	I-2	Review	1523
<sep> 3.	O	O	Review	1523
I disagree with the point that MNIST and SVHN are similar, they have very different distributions and are very easy to tell apart with a model.	B-Review	B-3	Review	1523
One concern is that the generative H-Net may fail to work once the distributions of the tasks overlap to some extent.	I-Review	I-3	Review	1523
e.g. cifar10 vs cifar100.	I-Review	I-3	Review	1523
<sep> <sep> As a conclusion, the key contribution of this work is using generative model to determine task id which removes the need for task id during inference.	O	O	Review	1523
It is relatively insufficient for publication on ICLR.	O	O	Review	1523
Thank you for the comments and feedbacks.	O	O	Reply	1523
<sep> <sep> 1.	O	O	Reply	1523
The major comparison in this paper was between the Packnet and ours.	B-Reply	B-1	Reply	1523
We wanted to emphasize that our model can avoid catastrophic forgetting and 'also' can expand if needed.	I-Reply	I-1	Reply	1523
We agree that we should have been careful in writing the contribution.	I-Reply	I-1	Reply	1523
<sep> <sep> 2. (	O	O	Reply	1523
a) Maybe there was a misunderstanding in this part.	B-Reply	B-2	Reply	1523
The overall architectures are the same in all experimental settings(EWC, LwF, Packnet and ours).	I-Reply	I-2	Reply	1523
So we are not giving more capacity to our network but efficiently distributing the capacity to each task just like the Packnet.	I-Reply	I-2	Reply	1523
In other words, we do not expand the c-net capacity compared to the baseline network.	I-Reply	I-2	Reply	1523
<sep> As we are not using the full Imagenet dataset, we believe that the result in Table 3 may be different with the full dataset result.	I-Reply	I-2	Reply	1523
We assumed that Resnet-50 is enough to show the properties of our method.	I-Reply	I-2	Reply	1523
<sep> <sep> (b) We agree with your opinion about EWC and we are willing to remove it from the paper.	B-Reply	B-2	Reply	1523
Except that, we want the readers understand that our method has the same or better performance with the Packnet.	I-Reply	I-2	Reply	1523
Even so, our method does not need masks in all filters and has flexibility.	I-Reply	I-2	Reply	1523
<sep> <sep> 3.	O	O	Reply	1523
We agree with your opinion and that is what we noted in the limitation section.	B-Reply	B-3	Reply	1523

This paper proposes a "gamma principle" for stochastic updates in deep neural network optimization.	O	O	Review	20467
First, the authors propose if Eq. (2) is satisfied then convergence is guaranteed (Thm.	O	O	Review	20467
1).	O	O	Review	20467
Second, they use experimental results of Alexnet and Resnet-18 on cifar10/100 to show that Eq. (2) is satisfied by SGD, SGD with momentum, and Adam, with different activations and tricks like batch normalization, skip connection.	O	O	Review	20467
<sep> <sep> Pros:	O	O	Review	20467
1.	O	O	Review	20467
This paper is well written and the presentation is clear.	O	O	Review	20467
<sep> 2.	O	O	Review	20467
The experiments are extensive.	O	O	Review	20467
<sep> <sep> Cons:	O	O	Review	20467
1.	O	O	Review	20467
Before Eq. (2), it is assumed that over-parameterized NNs are used as \theta.	B-Review	B-1	Review	20467
But there is no quantization how many parameters are enough?	I-Review	I-1	Review	20467
Are the Alexnet/Resnet-18 in experiments enough over-parameterized and how can we tell that?	I-Review	I-1	Review	20467
Some quantitative conditions should be provided to show what kind of models this principle hold.	I-Review	I-1	Review	20467
<sep> <sep> 2.	B-Review	B-2	Review	20467
The connection between Eq. (2) and Thm.	I-Review	I-2	Review	20467
1 is too obvious and the gamma is just to characterize the progress of each update.	I-Review	I-2	Review	20467
Of course, large progress corresponds to fast convergence.	I-Review	I-2	Review	20467
Eq. (2) is a strong assumption rather than a theoretical contribution.	I-Review	I-2	Review	20467
<sep> <sep> 3.	O	O	Review	20467
Experiments are used to show that Eq. (2) is a "principle".	B-Review	B-3	Review	20467
However, the experiments are problematic as follows.	I-Review	I-3	Review	20467
<sep> First, "we set \theta^* to be the network parameters produced in the last training iteration", then how do we make sure \theta in the last training iteration is \theta^*, even if the loss is close to (but not exactly) zero?	I-Review	I-3	Review	20467
For this point, I suggest using a teacher-student setting, where the optimal \theta^* is already known.	I-Review	I-3	Review	20467
<sep> Second, using \theta in the last training iteration makes the experiments show the following simple fact, that methods/tricks/activations with faster convergence to certain parameter will have larger every update progress to that parameter, which is, of course, true and does not reveal an optimization principle of deep learning.	B-Review	B-4	Review	20467
<sep> Third, it is difficult to claim that this is a principle for general deep learning by using experiments on two datasets.	B-Review	B-5	Review	20467
<sep> <sep> Overall, I found the theory not inspiring and experiments not convincing.	O	O	Review	20467
<sep> <sep> ========Update=========	O	O	Review	20467
Thanks for the rebuttal.	O	O	Review	20467
<sep> I have read it and using teacher-student setting is an improvement to resolve my question with respect to \theta^*.	O	O	Review	20467
However I would maintain my rating since	O	O	Review	20467
1) the theoretical contribution is actually marginal;	B-Review	B-2	Review	20467
2) the argument that this "gamma principle" holds for over-parameterized NNs is vague in the sense (and the author did not resolve my concern of this) that for what kinds of over-parameterized NNs this would work and for what kinds of NNs it does not hold.	B-Review	B-3	Review	20467
In particular, mentioning other theory work of over-parameterized NNs is not enough, because usually in these work, the numbers of parameters in NNs are poly(n), like O(n^4), O(n^6), where n is number of training data.	I-Review	I-3	Review	20467
There is an obvious gap between poly(n) and the number of parameters in experiments.	I-Review	I-3	Review	20467
From this perspective, the experiments cannot verify the claim that this "principle" holds for over-parameterized NNs that mentioned by authors in the rebuttal.	I-Review	I-3	Review	20467
<sep> 3) experiments on two datasets are not enough to claim this is a general "principle".	B-Review	B-5	Review	20467
<sep> Considering this claim is for general over-parameterized NN optimization, I think it lacks of specifying types of NNs for which this claim would hold (of course it cannot hold for any NNs, but it possibly can hold for some NNs, and what are these NNs?),	I-Review	I-5	Review	20467
and experiments are not enough to show the generality of this claim.	I-Review	I-5	Review	20467
We thank the reviewer for providing valuable feedback.	O	O	Reply	20467
Below is our point-to-point response.	O	O	Reply	20467
Any further comment is very welcome.	O	O	Reply	20467
<sep> <sep> 1).	O	O	Reply	20467
Before Eq. (2), ...	O	O	Reply	20467
A: In our experiments, we found that all the neural network models can be trained to achieve 1e-4 total loss, which is very close to the global minimum.	B-Reply	B-1	Reply	20467
We think this justifies that these models are over-parameterized.	I-Reply	I-1	Reply	20467
On the other hand, we think a quantitative bound for over-parameterization can be obtained by following other theoretical works, e.g., Gradient Descent Finds Global Minima of Deep Neural Networks.	I-Reply	I-1	Reply	20467
We leave this part of development for future study.	I-Reply	I-1	Reply	20467
<sep> <sep> 2).	O	O	Reply	20467
The connection between Eq. (2) ...	O	O	Reply	20467
A: We agree that fast convergence must correspond to large progress.	B-Reply	B-2	Reply	20467
However, the key point here is to quantify such progress to characterize the effects of different deep learning training techniques.	I-Reply	I-2	Reply	20467
We want to show that the proposed simple principle can quantify these effects and match the empirical observations well.	I-Reply	I-2	Reply	20467
We have pointed out in the paper that there are other existing optimization principles that guarantee convergence in nonconvex machine learning, but they do not match the experimental observations in training deep networks under various training techniques.	I-Reply	I-2	Reply	20467
<sep> 3).	O	O	Reply	20467
Experiments are used to show ...	O	O	Reply	20467
A: We thank the reviewer for providing valuable feedback.	B-Reply	B-3	Reply	20467
We appreciate the suggestion to use the teacher-student setting to guarantee the existence of a common global minimizer.	I-Reply	I-3	Reply	20467
Based on your suggestion, we plan to use a teacher-student setting in our experiments where the optimal \theta* is already known.	I-Reply	I-3	Reply	20467
Please find the details in our general response.	I-Reply	I-3	Reply	20467
<sep> <sep> 4) Second, using \theta ...	O	O	Reply	20467
A: We want to point out that \gamma along does not correspond to the per-step progress, which actually corresponds to the last term in eq(4) in the appendix.	B-Reply	B-4	Reply	20467
In that term, the loss gap, in general, varies in the optimization process and therefore the per-step progress is not a constant.	I-Reply	I-4	Reply	20467
Under the proposed principle, we showed that the \gamma fully determines the convergence speed and is verified in the experiments.	I-Reply	I-4	Reply	20467
<sep> <sep> 5) Third, it is difficult to claim ...	O	O	Reply	20467
A: We plan to do experiments on more large and complex datasets (e.g. ImageNet dataset).	B-Reply	B-5	Reply	20467

Summary:	O	O	Review	20467
<sep> This paper proposes an optimization principle that is called \gamma-optimization principle for stochastic algorithms (SA) in nonconvex and over-parametrized optimization.	O	O	Review	20467
The author(s) provide convergence results under this ‚Äú\gamma-optimization principle‚Äù assumption.	O	O	Review	20467
Numerical experiments are conducted on classification datasets CIFAR-10 and CIFAR-100 for Alexnet and Resnet-18 with different activation functions.	O	O	Review	20467
<sep> <sep> Comments:	O	O	Review	20467
<sep> 1) Could you please explain how you could achieve the value of \theta* (common global minimizer for the loss on all individual component functions)?	B-Review	B-1	Review	20467
It is unclear to me how you could obtain it.	I-Review	I-1	Review	20467
<sep> <sep> 2) You have not mentioned the loss function that you are using for your numerical experiments.	B-Review	B-2	Review	20467
From my view, you are using softmax cross-entropy loss for classification problems (CIFAR-10, CIFAR-100).	I-Review	I-2	Review	20467
Can you show that Fact 1 is true for softmax cross-entropy loss?	I-Review	I-2	Review	20467
I wonder how you could train the total loss to achieve zero for this loss.	I-Review	I-2	Review	20467
<sep> <sep> 3) Fact 1 with over-parameterized model could be true if the loss, for example, is mean square (for regression problems).	B-Review	B-3	Review	20467
Therefore, I would suggest you to consider other numerical examples rather than classification problems.	I-Review	I-3	Review	20467
If not, the numerical part is not very consistent with the theoretical part.	I-Review	I-3	Review	20467
<sep> <sep> 4) The assumption that the author(s) use in the paper, that is, \gamma-optimization principle in Definition 1, is indeed strong and not reasonable.	B-Review	B-4	Review	20467
You simply assume what you want in order to achieve the convergence result.	I-Review	I-4	Review	20467
It is not easy to verify this assumption since you include \theta* unless it has only a unique solution.	I-Review	I-4	Review	20467
Note that the learning rate (eta) and gamma are very sensitive here and it is not clear how to determine these values.	I-Review	I-4	Review	20467
<sep> <sep> 5) There is related work that you may need to consider: Vaswani et al 2019, "Fast and Faster Convergence of SGD for Over-Parameterized Models (and an Accelerated Perceptron)" in AISTATS 2019.	B-Review	B-5	Review	20467
<sep> <sep> I think the paper still needs lots of work to be ready.	I-Review	I-5	Review	20467
Theoretical result is not strong and the numerical experiments are not convincing.	I-Review	I-5	Review	20467
I do not support the publication for this paper at the current state.	I-Review	I-5	Review	20467
<sep> <sep> Minor:	B-Review	B-6	Review	20467
1) I am not really why you have a question mark (?)	I-Review	I-6	Review	20467
in the title.	I-Review	I-6	Review	20467
<sep> <sep> We thank the reviewer for providing valuable feedback.	O	O	Reply	20467
Below is our point-to-point response.	O	O	Reply	20467
Any further comment is very welcome.	O	O	Reply	20467
<sep> <sep> 1) Could you please explain ...	O	O	Reply	20467
A: We assume the (neural network) model has enough expressive power to interpolate all the training data samples.	B-Reply	B-1	Reply	20467
In our experiments, we used the non-negative cross-entropy loss function and train the total loss for a sufficient number of epochs to achieve a small value (1e-4).	I-Reply	I-1	Reply	20467
In this case, we empirically found that the model \theta produced in the last training iteration achieves small loss on all the data samples, and therefore we choose it as an approximation of the \theta*.	I-Reply	I-1	Reply	20467
<sep> 2) &amp; 3) You have not mentioned the loss function that ...	O	O	Reply	20467
A: We thank the reviewer for providing valuable suggestions.	B-Reply	B-3	Reply	20467
We use the cross-entropy loss in the experiments.	I-Reply	I-3	Reply	20467
We understand that an exact minimum cannot be achieved for this loss and use the last training iteration to serve as an approximation.	I-Reply	I-3	Reply	20467
To fix this issue, we will adopt the MSE loss under the teacher-student setting to guarantee the existence of a known common global minimum (Please see our general response).	I-Reply	I-3	Reply	20467
<sep> <sep> 4) The assumption that the author(s) use in the paper...	O	O	Reply	20467
A: In general, one can propose many different optimization conditions that guarantee convergence in nonconvex optimization, e.g., the regularity condition in (Zhang et al 2017b) for nonconvex phase retrieval, star-convex condition in (Zhou et al 2019) for deep learning.	B-Reply	B-4	Reply	20467
However, these conditions cannot characterize the effects of the deep learning training techniques explored in this paper.	I-Reply	I-4	Reply	20467
What we empirically found is that the proposed \gamma-principle well characterizes these effects in terms of the value \gamma.	I-Reply	I-4	Reply	20467
Regarding the concern on the minimizer \theta*, we will adopt the teacher-student setting to bridge the gap between our theory and experiments.	I-Reply	I-4	Reply	20467
<sep> <sep> 5) There is related work that you may...	O	O	Reply	20467
A: We thank the reviewer for recommending this paper on stochastic optimization theory.	B-Reply	B-5	Reply	20467
We will cite  and discuss it in the related works.	I-Reply	I-5	Reply	20467
<sep> Minor: we will use a more informative title in the revision.	B-Reply	B-6	Reply	20467

The paper proposes a density score, which is defined based on a density or some other score such as Fr√©chet Inception Distance (FID).	O	O	Review	464
<sep> <sep> While the given problem is an important one, there are some substantial problems with the proposed approach:	O	O	Review	464
1) The paper does not mention the limitations of the FID which, as described in (Shmelkov et al, ECCV 2018.	B-Review	B-1	Review	464
How good is my GAN?),	I-Review	I-1	Review	464
are: i) it is based on the pre-trained Inception network and therefore does not exactly match the distributions over the data in other datasets; and ii) crude approximation of the scores by Gaussian distributions.	I-Review	I-1	Review	464
Overall, this score is empirical and aims at circumventing the subjective analysis and it should be better reflected in the paper.	I-Review	I-1	Review	464
<sep> 2) The justification of the normal density based index (Section 2) seems weak.	B-Review	B-2	Review	464
While it is obvious that this score could be used, is it possible to make the empirical assessment?	I-Review	I-2	Review	464
E.g. compare between two scores on an extensive amount of data.	I-Review	I-2	Review	464
<sep> 3) In addition to the previous comment, there is a substantial problem in the experimental results that all the observations are qualitative and based only on a few images.	B-Review	B-3	Review	464
Further analysis of the realism index on the real images which are not included into the training dataset could improve the analysis.	I-Review	I-3	Review	464
<sep> 4) Following up on the previous comment, the experiments on the real images may need the values from the latent space corresponding to the real images.	B-Review	B-4	Review	464
Currently, the model has been mostly assessed using DCGAN (with the assessment of VAE in Figure 4 but only for FID score), while it is stated after equation (1) that 'This case covers both GAN-like and AE-like models.'	I-Review	I-4	Review	464
This might be used for the assessment of the realism index on real images as stated before.	I-Review	I-4	Review	464
If the proposed model were assessed with variational auto-encoders (VAE) and flow based models, it would make it possible to transform between the latent representation and the data themselves.	I-Review	I-4	Review	464
From another perspective, experimental results on different types of models (VAE-type, flow based type such as GLOW) for different types of interpolation are needed for the sake of experimental completeness.	I-Review	I-4	Review	464
It would help emphasise the limitations of the method and difference in interpolation results in different models.	I-Review	I-4	Review	464
4) In the optimisation section, the following statement is made: 'However, to accelerate the process of minimisation, we alternate the gradient step with the following one: first choose two random numbers i &lt; j from the set {0, . . . ,	B-Review	B-5	Review	464
k} and then consider the linear interpolation between xi and xj given with...'.	I-Review	I-5	Review	464
Could the authors elaborate on why does this acceleration happen?	I-Review	I-5	Review	464
It might be necessary to give some references on the experimental results or at least provide some line of support for this phrase.	I-Review	I-5	Review	464
<sep> ***	O	O	Review	464
The following comments are not as critical but fall into the category of ‚Äònice to have':	O	O	Review	464
5) Although the reviewer is aware that there were some experiments in the appendix on the value \epsilon, it might be a good idea to have more studies on the influence of this regularisation parameter for other datasets rather than just MNIST	B-Review	B-6	Review	464
6)  While figure 1 appears in the beginning of the paper, on page two, it is discussed on page seven, in the experimental section.	B-Review	B-7	Review	464
Placing the figures closer to the narrative would improve the reading experience.	I-Review	I-7	Review	464
Thank you for your very detailed comments and suggestions!	O	O	Reply	464
Below we review each individual point that you made.	O	O	Reply	464
<sep> <sep> 1) We agree that the FID score clearly has many limitations, and we are happy to expand the discussion about them in the paper.	B-Reply	B-1	Reply	464
However, the focus of our work is not to discuss the pros and cons of FID score, but to present a new interpolation technique that could be based on an arbitrary score.	I-Reply	I-1	Reply	464
It should be noted that despite the fact that FID score is empirical, its application as the realism score in our method still gives reasonable results.	I-Reply	I-1	Reply	464
Exchanging FID score with a better realism measure would likely further improve the performance.	I-Reply	I-1	Reply	464
The main issue with the measures GAN-train and GAN-test proposed by Shmelkov et al is that they require a separate classification model, optimized either using the GAN training set (GAN-train) or examples generated from the GAN (GAN-test).	I-Reply	I-1	Reply	464
Therefore, they are suitable for datasets with a clear classification task (and would be problematic, for instance, for the Celeb-A dataset), while our realism index can be used for any dataset.	I-Reply	I-1	Reply	464
We agree that designing a good realism measure is a challenging problem, and we will update the paper to address your concerns.	I-Reply	I-1	Reply	464
<sep> <sep> 2) Our paper includes a theoretical derivation of the approximation of the realism index in the case of the normal distribution (6), which we believe gives a strong basis for the method.	B-Reply	B-2	Reply	464
The key point of this derivation is to discuss the properties of the proposed index.	I-Reply	I-2	Reply	464
It demonstrates that the proposed realism index exhibits the expected behavior for high dimensional normal density:	I-Reply	I-2	Reply	464
- As it is well known, almost all points generated from the standard normal density in R^D lie inside the sphere S(0,D^¬Ω).	I-Reply	I-2	Reply	464
Thus points outside of this sphere can be considered unrealistic, while those inside can be obtained by random sampling.	I-Reply	I-2	Reply	464
<sep> - By examining equation (6), we directly see that our realism density based index correctly identifies the latent points that lay inside the sphere S(0,D^¬Ω) as having an index approximately 1, and points outside sphere as having index approximately 0.	I-Reply	I-2	Reply	464
<sep> - Observe, that this behavior is not recognized by the density itself, which has no clear ‚Äòborder/change‚Äô at the sphere S(0,D^¬Ω).	I-Reply	I-2	Reply	464
<sep> <sep> We would like to thank the reviewer for pointing out that we have not explained the above reasoning in the paper clearly enough, and we shall improve it in the updated version of the paper.	I-Reply	I-2	Reply	464
We would also like to add that this theoretical formula was needed only for the justification of the method, and therefore was never used in experiments.	I-Reply	I-2	Reply	464
<sep> <sep> 3 &amp; 4) The reviewer is right in noticing that most of our experiments have been performed using DCGAN, therefore the notion of ‚Äúlatent codes of real images‚Äù is not feasible.	B-Reply	B-4	Reply	464
We did assess the method on an AE-based model; note that it was a Wasserstein Autoencoder (Figure 4), not a Variational Autoencoder, and the paths were optimized using the density-based realism index, not the FID-based.	I-Reply	I-4	Reply	464
We chose WAE over VAE, as our preliminary experiments suggested it yields lower reconstruction error.	I-Reply	I-4	Reply	464
<sep> <sep> On the other hand, one problem with GLOW is that it does not lead to a completely valid generative model, in the sense that the samples are not generated from the distribution which is learned during the training (the authors in GLOW use the concept of temperature, which results in sampling from the normal density with covariance smaller then identity, while they train the model using standard normal density).	I-Reply	I-4	Reply	464
For this reason we did not perform any experiments with this architecture.	I-Reply	I-4	Reply	464
<sep> <sep> In our preliminary experiments we have used some real data points in the VAE-type model.	I-Reply	I-4	Reply	464
However, we did not observe any difference in the methods behavior in comparison to the sample-points interpolations, and therefore we did not proceed with making further experiments in this direction.	I-Reply	I-4	Reply	464
<sep> <sep> 4') We use the optimization described in section 'Optimisation procedure' to reduce the number of necessary iterations in our method.	B-Reply	B-5	Reply	464
This is particularly evident for a DCGAN with semicircle prior (see Fig.1).	I-Reply	I-5	Reply	464
In the initial phase of optimizing the linear interpolation, the value of the gradient for the middle points (located in the middle of the interpolation curve) can be extremely small due to the diminishing density.	I-Reply	I-5	Reply	464
As a consequence, this part of the curve converges slower than the points lying closer to the ends of the curve.	I-Reply	I-5	Reply	464
Our experiments for this model show that we can get the same result without using the described acceleration, but with up to 3 times more iterations.	I-Reply	I-5	Reply	464
This procedure is only crucial for the semicircle prior; for the other experiments there is no significant impact on the number of iterations.	I-Reply	I-5	Reply	464
<sep> <sep> We would like to thank the reviewer for drawing our attention to explaining the motivation behind this optimization more clearly; we will update the paper accordingly.	O	O	Reply	464

This paper introduced a linear interpolation method that could be applied to the latent space of a generative model.	O	O	Review	464
With their method, interpolating instances generated by those generative models all maintain high quality in terms of the realism index they proposed.	O	O	Review	464
<sep> <sep> This paper first introduced the quantity realism index, which is a measure of how well a generated instance in the latent space is fitted to the ground truth manifold of the data space.	O	O	Review	464
The definition of realism index is the probability measure of the sublevel set of some f (f:latent -&gt; R+) function threshold by the f(z) for some z. f(z) could be the density function of feature in the latent space.	O	O	Review	464
<sep> <sep> There are two types of realism index which has analytic form introduced in this paper.	O	O	Review	464
The one based on normal density.	O	O	Review	464
Another is based on Frechet inception distance.	O	O	Review	464
If the density of latent feature is normal, normal density based index is used and it could be approximated with a analytic form; while if the density is not accessible, then f is the gaussian density of certain transformation of features in the latent space.	O	O	Review	464
<sep> <sep> If an arbitrary f is used, a kernel density estimator is used to estimate the density of log(f).	O	O	Review	464
After the realism index is introduced, the optimal interpolation  is the one has the highest cumulative realism index along the interpolation curve.	O	O	Review	464
<sep> <sep> To optimize, a linear interpolation is used as initialization.	O	O	Review	464
All the intermediate results are updated iteratively.	O	O	Review	464
<sep> <sep> Results show better interpolation than linear ones.	B-Review	B-1	Review	464
But not many baselines are available.	I-Review	I-1	Review	464
<sep> <sep> Overall, I think the problem is very interesting and important.	O	O	Review	464
The results seem reasonable although only beating an obviously flawed baseline.	O	O	Review	464
<sep> <sep> Typo in Equation (3): w-&gt;s?	B-Review	B-2	Review	464
<sep> <sep> -----------------	O	O	Review	464
<sep> After reading rebuttal and other reviews, I agree that quantitative results is crucially missing especially when the proposed method involves proposing an optimization method to find the best geodesic.	B-Review	B-3	Review	464
I think the authors should find a reasonable model that can at least show the proposed geodesic is better than a linear interpolation in the accumulated realism score.	I-Review	I-3	Review	464
Also some quantitative evaluation of the proposed optimization scheme will be very helpful.	I-Review	I-3	Review	464
Thank you for reviewing our work!	B-Reply	B-2	Reply	464
We believe that Equation (3) is correct, although the notation used there was not explained clearly enough.	I-Reply	I-2	Reply	464
The letter ‚Äúw‚Äù in this Equation is only used to define the set over which we are integrating.	I-Reply	I-2	Reply	464
We are grateful to the reviewer for pointing out this issue, and we will update the paper to address it.	I-Reply	I-2	Reply	464

This paper proposed to address a compound problem where missing data and distribution shift are both at play.	O	O	Review	464
The paper goes on to describe some heuristic methods that resemble the gradient reversal methods due to Ganin et al for handling both problems.	O	O	Review	464
<sep> <sep> The novel part of the paper over DANNs is the joint, end-to-end training of latent representations for missing data, &nbsp;While it is sloppy with terminology, the paper is overall reasonably easy to follow although it might mislea a novice reader and sufficient details are provided to replicate their results.	O	O	Review	464
<sep> The major problem here is the problem appears to be underspecified, and its not clear under what conditions if any the proposed methods are valid.	B-Review	B-1	Review	464
Moreover it‚Äôs not clear to what extent the experimental results should ameliorate these concerns.	I-Review	I-1	Review	464
<sep> <sep> If the data is not missing at random then there is presumably confounding.	B-Review	B-2	Review	464
The authors dance around this topic, just asserting that they are handling non-stochastic missing data but do not say precisely what is assumed about the relationship between the observed and missing data.	I-Review	I-2	Review	464
<sep> <sep> In short the paper addresses an under-specified problem with a heuristic technique based upon domain-adversarial nets which have recently been shown have a number of fundamental flaws.	B-Review	B-3	Review	464
It's never made clear under what assumptions this proposed procedure is valid and the paper misrepresents the prior work on lable shift, including the theoretically sound work, e.g.:	I-Review	I-3	Review	464
<sep> "we assume covariate shift as in most UDA papers e.g. Ben-David et al (2010); Ganin &amp; Lempitsky (2015).‚Äù	I-Review	I-3	Review	464
&gt;&gt;&gt;  Ben-David 2010 is not about covariate shift ‚Ä¶.	I-Review	I-3	Review	464
<sep> Some minor thoughts:	B-Review	B-4	Review	464
<sep> ‚Äúsome components of the target data are systematically absent‚Äù	I-Review	I-4	Review	464
&gt;&gt;&gt; <tab>Not clear what ‚Äúcomponent‚Äù means at this point	I-Review	I-4	Review	464
<sep> ‚ÄúWe propose a way to impute non-stochastic missing data‚Äù	I-Review	I-4	Review	464
&gt;&gt;&gt; <tab>What does this mean?	I-Review	I-4	Review	464
Is non-stochastic, not missing at random?	I-Review	I-4	Review	464
What is the pattern of missing-ness conditioned on?	I-Review	I-4	Review	464
What assumption, if any, is made?	I-Review	I-4	Review	464
<sep> <sep> ‚ÄúThis key property allows us to handle non-stochastic missing data,‚Äù	I-Review	I-4	Review	464
&gt;&gt;&gt; <tab>again what precisely does this mean?	I-Review	I-4	Review	464
<sep> <sep> ‚ÄúConsider that x has two components (x_1, x_2)‚Ä¶‚Äù	I-Review	I-4	Review	464
&gt;&gt;&gt;<tab>sloppy  notation:	I-Review	I-4	Review	464
<tab>‚ÄúSource features‚Äù x_s = (x_S1, x_S2) are always available	I-Review	I-4	Review	464
<sep> <sep> I read the author's reply but do not believe that the responses are satisfactory.	O	O	Review	464
The authors do not address the primary concerns clearly and do not point to specific improvements in the draft that might cause me to change my mind.	O	O	Review	464
<sep> <sep> <sep> Thank you for your review.	O	O	Reply	464
We have taken note of your comments and try to provide detailed answers to the points you raised:	O	O	Reply	464
<sep> A) Problem specification:	O	O	Reply	464
All the data considered in the paper are vectors.	B-Reply	B-1	Reply	464
Let be a complete data vector and a binary mask indicating which entries of are missing (1 for missing and 0 for observed).	I-Reply	I-1	Reply	464
Given a dataset, we define the missingness indicator matrix as where is the number of instances.	I-Reply	I-1	Reply	464
In the following, we remove index for clarity.	I-Reply	I-1	Reply	464
The hypotheses are the following:	I-Reply	I-1	Reply	464
<sep> 1.	I-Reply	I-1	Reply	464
Source domain data are fully observed.	I-Reply	I-1	Reply	464
<sep> <sep> 2.	O	O	Reply	464
Target domain data are partially observed and the missingness pattern is fixed: the indicator mask is the same for all the target domain data.	B-Reply	B-1	Reply	464
In the paper when one refers to "non-stochastic missing data" we mean that the mask pattern is fixed for all target domain data.	I-Reply	I-1	Reply	464
For simplicity, we have used the notations (source) and (target) with and corresponding to the mask positions with 0 value, i.e. features observed on both domains, and and corresponding to mask positions with value 1, i.e. missing features for the target domain.	I-Reply	I-1	Reply	464
<sep> Please see the discussion below on the classical terminology used for missing data (item "Rubin's theory for missing data").	I-Reply	I-1	Reply	464
<sep> <sep> 3.	B-Reply	B-1	Reply	464
and contain some information not present in and.	I-Reply	I-1	Reply	464
This means that the feature values and cannot be predicted directly (e.g. through a regressor) from the features and respectively.	I-Reply	I-1	Reply	464
<sep> <sep> 4.	O	O	Reply	464
The distribution of features conditioned on the features could be inferred provided that we have some supervision for training the conditional distribution model; this is typically the case if for some observation, one also observes, however such a supervision is not available for our problem.	B-Reply	B-1	Reply	464
This is where adaptation comes into play.	I-Reply	I-1	Reply	464
For inferring the conditional probability, the model  makes use of the source domain information for which this supervision is available while adapting to the target domain.	I-Reply	I-1	Reply	464
Note that the model operates in a latent space and not in the original one.	I-Reply	I-1	Reply	464
It does not attempt to reconstruct the true conditional distribution of, but a conditional distribution in a latent space for a projection of denoted in the paper.	I-Reply	I-1	Reply	464
<sep> <sep> 5.	O	O	Reply	464
Finally, we make the typical covariate shift assumption seen in several UDA papers, such as DANN [Ganin2015] to address an unsupervised classification adaptation setting.	B-Reply	B-1	Reply	464
<sep> <sep> These hypotheses map to several real world problems as mentioned in this paper and the methods introduced show important improvement on our datasets based on these specifications.	I-Reply	I-1	Reply	464
<sep> <sep> * Rubin's theory for missing data:	O	O	Reply	464
<sep> The foundations of missing data theory were established by Rubin [Rubin1976] and his colleagues [Little2014]. We briefly introduce this formalism in order to put in evidence the specificity and originality of our problem.	B-Reply	B-2	Reply	464
Rubin distinguishes between a missingness pattern, which describes which values are missing and observed in the data and the missingness mechanism, which represents the statistical relationship between the probability of missing data and the data variables.	I-Reply	I-2	Reply	464
Let define as above a pattern of missing data; the missingness mechanism is characterized by the conditional distribution of given, where denotes a vector of unknown parameters describing the relationship between the and variables.	I-Reply	I-2	Reply	464
is known as the mechanism of missing data and provides the basis for distinguishing between three categories of missing data problems: Missing Completely at Random - MCAR ), Missing At Random - MAR  with being the observed features), and Missing Not At Random - MNAR that covers all the other cases.	I-Reply	I-2	Reply	464
<sep> <sep> Our missingness mechanism trivially corresponds to MCAR on the target domain.	I-Reply	I-2	Reply	464
However, the key idea behind Rubin's theory is that missingness is a variable with a probability distribution.	I-Reply	I-2	Reply	464
In our case, the missingness pattern is deterministic, not stochastic.	I-Reply	I-2	Reply	464
The problem is then more difficult than classical MCAR problems and does not lead for example to classical maximum likelihood solutions exploited in the literature.	I-Reply	I-2	Reply	464

*Summary.*	O	O	Review	464
The paper presents and addresses the problem of performing domain adaptation when the target domain is systematically (i.e., not the result of a stochastic process) missing subsets of the data.	O	O	Review	464
The issue is motivated by applications where one modality of data becomes unavailable in the target domain (e.g., when deciding which ads to serve to new users, the predictor may have access to behavior across other websites but not on a specific merchant's website).	O	O	Review	464
The proposed method learns to map source and target data to a latent space where the representations for the source and target are aligned, the missing components of the target can be inferred, and classification can be performed successfully.	O	O	Review	464
These are achieved by adversarial/optimal transport loss on source and target features, a mean-squared error and adversarial loss on latent generation/imputation, and a cross entropy loss on source label prediction, respectively.	O	O	Review	464
Experiments are performed on digits and click-through rate (CTR) prediction and include a thorough set of baselines/oracles for comparison.	O	O	Review	464
<sep> <sep> *Review.*	O	O	Review	464
While the problem statement is novel, I am unconvinced that the advertising experiment includes both a domain adaptation and imputation problem.	B-Review	B-1	Review	464
I describe this in detail below.	I-Review	I-1	Review	464
For this reason, I am giving the paper a weak reject.	I-Review	I-1	Review	464
<sep> <sep> *Questions that impacted rating.*	I-Review	I-1	Review	464
<sep> 1.	I-Review	I-1	Review	464
Ads experiment: From my understanding, the source domain is the traffic of users who have interacted with (clicked through to?)	I-Review	I-1	Review	464
a specific partner and the target domain is the traffic of the users who have not interacted with that specific partner.	I-Review	I-1	Review	464
The data that needs to be imputed is the click through rate for target users with that specific partner.	I-Review	I-1	Review	464
In this case, it is not obvious to me why there is a domain shift between these two groups of users.	I-Review	I-1	Review	464
This would imply that the traffic of source users and target users is different for other partners.	I-Review	I-1	Review	464
I don't see why this would need to be true.	I-Review	I-1	Review	464
Could the authors provide an explanation as to why this is the case (e.g., by showing that CTRs differ with other (partner, publisher) pairs between source and target).	I-Review	I-1	Review	464
From my understanding, Table 5 only shows CTR averaged across all users in each domain, but does not show that the CTRs differ between source and target users for contexts/(partner, publisher) pairs (i.e., the results in table 5 could be due to the fact that the prior distribution over context is different for source and target users).	I-Review	I-1	Review	464
<sep> <sep> *Additional notes.	O	O	Review	464
Immaterial to rating.*	O	O	Review	464
<sep> 1.	B-Review	B-2	Review	464
I personally felt that the motivation for UDA vs imputation in the first paragraph was a bit muddled.	I-Review	I-2	Review	464
I think sticking to one example would make the motivation more clear to the reader.	I-Review	I-2	Review	464
E.g., explain the prediction problem for medical imaging (which I assume is disease diagnosis, but it is not stated explicitly), describe how some medical imaging may be missing for certain patients (imputation), then explain that there may be noise across different medical imaging systems (UDA), then list the other applications where this arises with citations (e.g., These phenomena have also been documented in advertising applications [1], ...).	I-Review	I-2	Review	464
<sep> 2.	B-Review	B-3	Review	464
I was surprised by the difference between Adaptation-Partial and the other two train/test conditions in Figure 2 when p=30%.	I-Review	I-3	Review	464
Out of curiosity, do the authors have an explanation for this discrepancy?	I-Review	I-3	Review	464
I would have predicted that, if most of the information necessary for prediction was available in the remaining 70% of the image that the performance of these cases would be very similar.	I-Review	I-3	Review	464
I think it would be helpful to see the accuracy on the source domain and the labeled target domain to better understand that result.	I-Review	I-3	Review	464
Thanks a lot for your feedback and your recommendations.	O	O	Reply	464
We provide below a detailed response.	O	O	Reply	464
<sep> <sep> A) Joint domain shift and missing data hypothesis for the ads experiments:	O	O	Reply	464
We do agree that this is not obvious.	B-Reply	B-1	Reply	464
As mentioned in the paper, the ads problem was our initial motivation for this work and our formulation of the problem comes from preliminary exploratory data analyses performed on ads datasets.	I-Reply	I-1	Reply	464
We have added in Appendix E in the new paper version, distribution plots (Figure 6) and mean values (Table 6) for the different observed features used in the ads-kaggle dataset for the source and target domains.	I-Reply	I-1	Reply	464
This shows that there is indeed a domain shift between the two domains.	I-Reply	I-1	Reply	464
The same conclusion holds for the ads-real dataset.	I-Reply	I-1	Reply	464
More details are provided below.	I-Reply	I-1	Reply	464
<sep> Your description of the problem in the detailed comments (*Questions that impacted rating.*)	I-Reply	I-1	Reply	464
is basically right.	I-Reply	I-1	Reply	464
We figured out however that we might not have been precise enough in the text and we provide below more details clarifying the experimental setting.	I-Reply	I-1	Reply	464
<sep> <sep> The source dataset is composed of all user-partner pairs for which the user visited the partner and the target dataset is composed of all the user-partner pairs for which the user never visited this partner.	I-Reply	I-1	Reply	464
A key point here is that there are several partners (and of course users) per domain, and this was probably not clear enough from the text.	I-Reply	I-1	Reply	464
Typically we could expect thousands of partners depending on the size of an ads company's partner portfolio.	I-Reply	I-1	Reply	464
For the source domain, we have available complete data (mean statistics on all visited partners + traces on a specific ad partner for a user-partner pair) and for the target domain only partial data (mean statistics but no partner specific traces for a user-partner pair).	I-Reply	I-1	Reply	464
<sep> Regarding domain shift, in Figure 6 Appendix E, we plot the normalized feature distributions for the source (blue plots) and target (red plots) domains.	I-Reply	I-1	Reply	464
While some features have a similar distribution for the source and target domains, many have completely different distributions indicating a clear domain shift.	I-Reply	I-1	Reply	464
This is synthesized in Table 6 Appendix E, giving the mean values for all the features for the two domains.	I-Reply	I-1	Reply	464
We notice that feature 5 is missing on the target.	I-Reply	I-1	Reply	464
<sep> <sep> This shift was initially a surprising finding for us too.	I-Reply	I-1	Reply	464
Our hypothesis is that the source domain includes users with a higher overall activity both for visiting partner websites and for interacting with the websites.	I-Reply	I-1	Reply	464
Target domain includes users that are probably less active.	I-Reply	I-1	Reply	464
This is confirmed by the mean value of the features in the two domains in Table 6 Appendix E: feature distributions from users in the source domain tend to have higher mean values than features in the target domain.	I-Reply	I-1	Reply	464
These features typically measure click, visit and sale activities which is consistent with the above hypothesis.	I-Reply	I-1	Reply	464

The submission describes an approach for unsupervised domain adaptation in a setting where some parts of the target data are missing.	O	O	Review	464
<sep> <sep> Both UDA approaches as well as data completion approaches have a sizable research history, as laid out in the related work section (Section 5).	O	O	Review	464
The novelty here comes from the properties that a) domain adaptation and data imputation are handled in a joint manner, b) the missing data in the target domain is non-stochastic, and c) imputation is performed in a latent space.	O	O	Review	464
This maps to a fairly specific, but realistic enough set of real-world problems; the authors give an image recognition as well as an advertising prediction related problem as experimental examples.	O	O	Review	464
<sep> <sep> The submission is overall well written and easy to understand.	O	O	Review	464
I'd rate the novelty as medium (smart combination of existing methods), but the exemplary experimental evaluation elevates it to more than a systems paper.	O	O	Review	464
<sep> <sep> The method is described clearly in Section 3, and the joint training makes sense.	B-Review	B-1	Review	464
I notice that not all hyperparameters ({lambda_adv, lambda_mse}, {lambda_1, lambda_2, lambda_3}) are truly needed.	I-Review	I-1	Review	464
lambda_adv and lambda_1 could be canonically set to 1 for such a loss minimization problem, so why are the extraneous parameters included?	I-Review	I-1	Review	464
<sep> <sep> In addition to Section 3, the experimental evaluation on two very different data sets in Section 4 is highly detailed and describes the insights clearly, both qualitatively and quantitatively.	O	O	Review	464
I'm happy that mean standard deviations are reported on an acceptable experiment sample set size.	O	O	Review	464
<sep> Regarding the different approaches: I'm wondering whether the higher performance of the ADV approach over OT (or the parameter hunger of OT over ADV) is only due to the tuning of the network architectures, or whether this is due to the approximations described in B.1.	B-Review	B-2	Review	464
<sep> The ablation study in Section 4.4 is interesting w.r.t.the trade-off it shows between stable, consistent, "average" results from an MSE loss term, vs. high-variance (and on average better) results when a choice of mode is forced using an adversarial loss term.	O	O	Review	464
<sep> <sep> Minor comments:	O	O	Review	464
- In Table 2, I am not sure what the first row ('Naive') refers to.	B-Review	B-3	Review	464
As far as I can tell, it is not referenced in the text.	I-Review	I-3	Review	464
<sep> - I would move Section 5 (related work) to right after the introduction, as is common in conference papers and makes for smoother reading.	B-Review	B-4	Review	464
<sep> - Section 5.2: type "impainting" -&gt; "inpainting"	B-Review	B-5	Review	464
- Appendix, section 'Pre-processing': It seems to me that there is a clear assumption made that the target set is balanced, since training happens with a balanced source set.	B-Review	B-6	Review	464
Is this realistic in practical scenarios?	I-Review	I-6	Review	464
There is work on DA with unequal class distributions between domains.	I-Review	I-6	Review	464
<sep> <sep> In summary, I can clearly recommend this submission for publication.	O	O	Review	464
We gratefully thank the reviewer for acknowledging the effort put in the experimental evaluation, for pointing out typos and advise on the structure of the paper.	O	O	Reply	464
<sep> <sep> * Indeed as the reviewer notices, not all hyperparameters are used in practise in the experimental section.	B-Reply	B-1	Reply	464
During initial tests, we experimented with different values of the hyperparameters and finally only tuned in the experiments.	I-Reply	I-1	Reply	464
We kept the initial formulation to indicate that the other parameters could also be tuned further and might yield improved classification performance.	I-Reply	I-1	Reply	464
We have added a sentence clarifying this in the revised version in Section 4.1.	I-Reply	I-1	Reply	464
<sep> <sep> * OT vs ADV: in preliminary tests, we figured out that the NN architectures used for mapping data onto the latent space had usually a much higher influence on the performance than the choice of the alignment method itself.	B-Reply	B-2	Reply	464
In order to provide a fair comparison and also because our goal was to show the effectiveness of the proposed mechanism rather than reaching the best possible performance, we decided to use NN architectures with similar complexity for both models.	I-Reply	I-2	Reply	464
The OT models used in [Damodaran2018] indeed require an order of magnitude more parameters than the ADV models [Ganin2015] to reach similar performance.	I-Reply	I-2	Reply	464
Concerning the approximation, the OT model in [Damodaran2018] uses an alignment on the joint (X,Y) distributions while we are only aligning the X distributions.	I-Reply	I-2	Reply	464
Hence, our approach is equivalent to a primal Wasserstein version of the domain adaptation method proposed in [Shen 2018]. In our tests, aligning on the joint distribution did not perform better than aligning only on the marginal.	I-Reply	I-2	Reply	464
Then, our most plausible explanation is still that the difference of performance is due to tuning.	I-Reply	I-2	Reply	464
<sep> <sep> * The Naive model is referenced in the Baselines paragraph (in the revised version it figures in Section 5.1) .	B-Reply	B-3	Reply	464
This model refers to the likelihood computed using as a prediction the mean CTR on the training set and is a typical baseline used on advertising problems.	I-Reply	I-3	Reply	464
<sep> <sep> * We have moved the related works to Section 2 in the revised paper upon the reviewer's recommendation and corrected the typo.	B-Reply	B-5	Reply	464
<sep> <sep> * Indeed there is in practise no guarantee that the target domain will be balanced and usually it is not.	B-Reply	B-6	Reply	464
However, dealing with both domain shift and label shift is more complex and requires additional mechanisms.	I-Reply	I-6	Reply	464
Most work up to now only considered one of the two hypothesis (either domain or label shift).	I-Reply	I-6	Reply	464
Recent work such as [Zhao2019], [Wu2019] has started to examine more complex settings and it is of course of strong practical interest.	I-Reply	I-6	Reply	464
We have also started analyzing joint domain shift and unequal class distributions.	I-Reply	I-6	Reply	464
<sep> <sep> [Ganin2015] Yaroslav Ganin et al  Unsupervised Domain Adaptation by Backpropagation.	O	O	Reply	464
2015	O	O	Reply	464
[Damodaran2018] Bharath Bhushan Damodaran et al DeepJDOT : Deep Joint Distribution Optimal Transport for Unsupervised Domain Adaptation.	O	O	Reply	464
2018	O	O	Reply	464
[Zhao2019] Han Zhao et al  On learning invariant representation for domain adaptation.	O	O	Reply	464
ICML 2019	O	O	Reply	464
[Wu2019] Yifan  Wu et al   Domain  adaptation  with asymmetrically-relaxed distribution alignment.	O	O	Reply	464
ICML 2019	O	O	Reply	464
[Shen2018] Shen Ji et al Wasserstein Distance Guided Representation Learning for Domain Adaptation, AAAI 2018	O	O	Reply	464

I agree with R1, the workshop format is too small to efficiently describe an idea.	O	O	Review	130
<sep> <sep> This is what I understand: let's assume a young child is playing with toys from 2 different brands.	B-Review	B-1	Review	130
The toys include several pieces of different  types (10 MNIST classes).	I-Review	I-1	Review	130
The aim is to learn to put the same brand types into same buckets.	I-Review	I-1	Review	130
We want a bucket to have the same time of toy of the same brand (purity, all block type t of brand j is in bucket b) also the object types are the same for 2 brands in the bucket (association, all block type t of both brands is in bucket b).	I-Review	I-1	Review	130
The ultimate goal (future work) is to learn association between diffferent streams (e.g. what parents say when the child holds a lego).	I-Review	I-1	Review	130
<sep> <sep> This work models this problem with a MLP to first induce a feature vector z^{1,2} for 2 streams.	B-Review	B-2	Review	130
A pseudo-class \hat{z^{1,2}} is predicted using these feature vectors.	I-Review	I-2	Review	130
In the M-step the parameters are updated so that the distribution defined by  \hat{z^{1,2}} matches the target distribution \phi.	I-Review	I-2	Review	130
<sep> <sep> two issues I observed:	O	O	Review	130
1) they do not provide any information about how they evaluated other clustering algorithms.	B-Review	B-3	Review	130
If they are fed with raw pixels, I don't think the comparison would be fair because there is no featurization of raw fixels where the proposed model have this power.	I-Review	I-3	Review	130
Comparison on a single layer MLP autoencoder's hidden features or output of PCA would be more fair.	I-Review	I-3	Review	130
<sep> 2) The experiments are almost oracle type.	B-Review	B-4	Review	130
The model knows the number of classes and the target distribution.	I-Review	I-4	Review	130
I am not sure if other clustering algorithms make use of target distribution information.	I-Review	I-4	Review	130
In a real life scenario, none of these assumptions are true.	I-Review	I-4	Review	130
An early attempt in that direction would make this work acceptable for workshop publication.	I-Review	I-4	Review	130
<sep> Thank you for your time.	O	O	Reply	130
Hopefully, our responses have addressed your concerns	O	O	Reply	130
> This is what I understand: let's assume a young child is playing with toys from 2 different brands.	O	O	Reply	130
The toys include several pieces of different  types (10 MNIST classes).	O	O	Reply	130
<sep> >The aim is to learn to put the same brand types into same buckets.	O	O	Reply	130
We want a bucket to have the same time of toy of the same brand (purity, all block type t of brand j is in	O	O	Reply	130
>bucket b) also the object types are the same for 2 brands in the bucket (association, all block type t of both brands is in bucket b).	O	O	Reply	130
The ultimate goal (future work) is to	O	O	Reply	130
>learn association between diffferent streams (e.g. what parents say when the child holds a lego).	O	O	Reply	130
<sep> The analogy is correct.	B-Reply	B-1	Reply	130
<sep> <sep> >This work models this problem with a MLP to first induce a feature vector z^{1,2} for 2 streams.	O	O	Reply	130
A pseudo-class \hat{z^{1,2}} is predicted using these feature vectors.	O	O	Reply	130
In the M-step the parameters are updated so that the distribution defined by  \hat{z^{1,2}} matches the target distribution \phi.	O	O	Reply	130
<sep> We want to point out that the model has two MLPs	B-Reply	B-2	Reply	130
<sep> <sep> >two issues I observed:	O	O	Reply	130
>1) they do not provide any information about how they evaluated other clustering algorithms.	O	O	Reply	130
If they are fed with raw pixels, I don't think the comparison would be fair	O	O	Reply	130
>because there is no featurization of raw fixels where the proposed model have this power.	O	O	Reply	130
Comparison on a single layer MLP autoencoder's hidden features or output of PCA	O	O	Reply	130
>would be more fair.	O	O	Reply	130
<sep> <sep> The reported resuls of both clustering algorithms is based on raw pixels.	B-Reply	B-3	Reply	130
We have evaluated the same datasets using pca (64, 128, 256), and the results are quite similar to Table 1.	I-Reply	I-3	Reply	130
Moreover, these results are similar to Jenckel, et al, where they did not find any improve between raw pixels vs pca for character recognition in Historical documents.	I-Reply	I-3	Reply	130
<sep> 1) MNIST input 1, input 2	I-Reply	I-3	Reply	130
* pca - 64: 64.1 (std:1.8), 63.9 (std:3.2)	I-Reply	I-3	Reply	130
* pca - 128: 63.5 (std:2.3), 63.6 (std:2.1)	I-Reply	I-3	Reply	130
* pca - 256: 63.6 (std:2.4), 63.4 (std:3.3)	I-Reply	I-3	Reply	130
2) Rotated MNIST input 1, input 2	I-Reply	I-3	Reply	130
* pca - 64: 63.9 (std:2.2), 63.3 (std:3.2)	I-Reply	I-3	Reply	130
* pca - 128: 63.7 (std:3.8), 61.6 (std:2.8)	I-Reply	I-3	Reply	130
* pca - 256: 65.1 (std:2.4), 63.9 (std:1.6)	I-Reply	I-3	Reply	130
3) Inverted MNIST input 1, input 2	I-Reply	I-3	Reply	130
* pca - 64: 64.9 (std:2.8), 64.1 (std:3.3)	I-Reply	I-3	Reply	130
* pca - 128: 64.6 (std:2.0), 64.2 (std:3.3)	I-Reply	I-3	Reply	130
* pca - 256: 65.1 (std:1.7), 63.5 (std:2.8)	I-Reply	I-3	Reply	130
4) Random Rotated MNIST input 1, input 2	I-Reply	I-3	Reply	130
* pca - 64: 64.4 (std:1.7), 14.9 (std:0.4)	I-Reply	I-3	Reply	130
* pca - 128: 63.9 (std:1.9), 14.8 (std:0.3)	I-Reply	I-3	Reply	130
* pca - 256: 65.5 (std:2.2), 14.9 (std:0.5)	I-Reply	I-3	Reply	130
<sep> [1] Jenckel, et al (2016).	O	O	Reply	130
Clustering Benchmark for Characters in Historical Documents.	O	O	Reply	130
Workshop on Document Analysis Systems, DAS16.	O	O	Reply	130
<sep> <sep> >2) The experiments are almost oracle type.	O	O	Reply	130
The model knows the number of classes and the target distribution.	O	O	Reply	130
I am not sure if other clustering algorithms make use of target	O	O	Reply	130
>distribution information.	O	O	Reply	130
In a real life scenario, none of these assumptions are true.	O	O	Reply	130
An early attempt in that direction would make this work acceptable for workshop	O	O	Reply	130
>publication.	O	O	Reply	130
<sep> We agree that the experiments are the ideal case, where the number of classes and the statistical distribution is known.	B-Reply	B-4	Reply	130
However, our model can be extended where the task is not constrained to the number of classes (which are defined by the language-linguistic).	I-Reply	I-4	Reply	130
For example, the classes in MNIST (one, two, three, ... zero) constraint that the input sample	I-Reply	I-4	Reply	130
can only be in those ten buckets (supervised tasks).	I-Reply	I-4	Reply	130
In contrast, our association task inspired by the symbol grounding problem is not constrained to the number of classes because we are only interested in learning two elements are the same based on their correlation.	I-Reply	I-4	Reply	130
With this in mind, our model only requires changing the size of the vectors z^{1}, z^{2}, and \phi for learning the association.	I-Reply	I-4	Reply	130

I can honestly say that despite several readings, I have no idea what this paper is actually about.	B-Review	B-1	Review	130
I believe the problem is relating two objects, despite not having a label that classifies the two objects as being of the same class.	I-Review	I-1	Review	130
From there, my comprehension goes downhill: EM algorithm mixed with pseudo-classes and a weighting scheme.	I-Review	I-1	Review	130
Networks using the output from another network as the targets of other networks.	I-Review	I-1	Review	130
Target uniform statistical distributions.	I-Review	I-1	Review	130
Why a weighting scheme?	I-Review	I-1	Review	130
What's going on?	I-Review	I-1	Review	130
<sep> <sep> I acknowledge that perhaps the workshop format is too small, and therefor limits too severely the required space to explain an idea.	B-Review	B-2	Review	130
Perhaps.	I-Review	I-2	Review	130
But I can safely say that almost nobody will glean any insight from this manuscript in the time that a reasonable person is willing to give a manuscript.	I-Review	I-2	Review	130
I would say that if the authors are confident of this work, they should write up a longer manuscript (or return to a longer one) that takes the time and space necessary to more effectively motivate the problem, and introduce the parts of the architecture, again with motivation, so that the reader has a chance of understanding the manuscript.	I-Review	I-2	Review	130
<sep> <sep> We thank the reviewer for the time.	O	O	Reply	130
Unfortunately, given the strict limit of 3 pages, it is challenging to give more information about the motivation and the elements of our model.	O	O	Reply	130
Hopefully, our responses have addressed your concerns.	O	O	Reply	130
<sep> <sep> * The presented task is to learn the association between two disjoint input streams where both streams represent the same unknown class.	B-Reply	B-1	Reply	130
This task is motivated by the Symbol Grounding Problem, which is the binding of abstract concepts with the real world via sensory input, such as visual system.	I-Reply	I-1	Reply	130
More formally, our task is defined by two disjoint input streams x^(1) and x^(2)  that represent the same unlabeled class.	I-Reply	I-1	Reply	130
The goal is to learn the association by classifying both with the same pseudo-class c^(1) = c^(2).	I-Reply	I-1	Reply	130
<sep> <sep> * Our training rule relies on matching a statistical distribution and a mini-batch of output vectors of MLPs as an alternative loss function that does not require classes.	B-Reply	B-1	Reply	130
With this in mind, we have introduced a new learning parameter (weighting vectors) that modifies the raw output vectors (z) based on the statistical constraint (\phi).	I-Reply	I-1	Reply	130
In addition, the weighting vectors help to classify the input samples.	I-Reply	I-1	Reply	130
As a result, the pseudo-classes -obtained in the classification step in Equation 4- change during training and similar elements are grouped together (Figure 1, 2, and 3).	I-Reply	I-1	Reply	130
<sep> <sep> * Motivated by the association learning between both streams.	B-Reply	B-1	Reply	130
We have proposed to use the pseudo-classes of one network as a target of the other network, and vice versa.	I-Reply	I-1	Reply	130
It can be seen in Figure 1, 2 and 3, each row in the first and second columns (MLP^(1) and MLP^(2)) represents a pseudo class (index) between 0-9.	I-Reply	I-1	Reply	130
After the model is trained, both networks agree on classifying similar input samples (or digits) with the same index.	I-Reply	I-1	Reply	130
<sep> <sep> * In summary, the two previous components are used in an EM-approach.	B-Reply	B-1	Reply	130
- Initial step: all input samples x(1) and x(2) have random pseudo-classes c(1) and c(2), where histogram of pseudo-classes is similar to the desired statistical distribution	I-Reply	I-1	Reply	130
-  E-step classifies the output vectors based on the weighting vectors (Equation 4)  and approximates the current statistical distribution of the mini-batch (Equation 3).	I-Reply	I-1	Reply	130
Note that the pseudo-classes are assigned to the samples after a number of iterations.	I-Reply	I-1	Reply	130
In other words, the updated of the pseudo-classes is not online.	I-Reply	I-1	Reply	130
<sep> - M-step updates the weighting vectors (\gamma^(1), \gamma^(2)) and the parameters of the networks (\theta^(1),\theta^(2))	I-Reply	I-1	Reply	130
<sep> We have updated our paper in order to clarify more the model and still keeping the page limit.	B-Reply	B-2	Reply	130

This paper studies the problem of part segmentation in objects represented as a point cloud.	O	O	Review	130
The main novelty is in the fact that the proposed method uses a bottom-up iterative merging framework inspired by perceptual grouping and finds that it transfers better to unseen categories.	B-Review	B-7	Review	130
In zero-shot transfer experiments, the proposed method performs better than all four other baselines compared; but is worse than Mo et al (2019) in known categories.	B-Review	B-1	Review	130
<sep> <sep> The paper hypothesizes that top-down approaches do not generalizes well to new categories because they end up overfitting to the global context.	O	O	Review	130
While this is reasonable, I find that the experiments are not sufficient to validate this claim (please see questions below).	B-Review	B-6	Review	130
Evaluation on unseen object categories is an underexplored topic, and the paper is generally well written.	I-Review	I-6	Review	130
I think the submission can be an above-threshold paper if the questions are addressed.	I-Review	I-6	Review	130
<sep> <sep> - I‚Äôd like to see some evidence for the claim that classic segmentation methods "can perform much better for unseen object classes" (last paragraph of page 1), and see how the proposed method compares to those baselines.	B-Review	B-2	Review	130
<sep> <sep> - If my understanding of Table 3 is correct, "PartNet-InsSeg" (Mo et al 2019) is a top-down approach yet it performs better than SGPN which is a bottom-up grouping method (as summarized on page 7) in novel categories.	B-Review	B-3	Review	130
If so, can it be explained in a way that is consistent with the paper's findings?	I-Review	I-3	Review	130
<sep> <sep> - Table 4 shows some ablation study in an attempt to justify the proposed design, but I think it should be more thorough.	B-Review	B-4	Review	130
e.g. it is not immediately obvious why the authors did not included a baseline that consists only of the rectification module with a termination threshold (seems like the most basic design that doesn't have the large-part bias or explicitly require a termination module).	I-Review	I-4	Review	130
<sep> <sep> <sep> <sep> Typos:	O	O	Review	130
<sep> psilon-greedy   (page 6 paragraph 2)	B-Review	B-5	Review	130
backpropogation  (page 6 under training losses)	I-Review	I-5	Review	130
In consequences (page 5 under termination network)	I-Review	I-5	Review	130
epilson  (page 5, under network training)	I-Review	I-5	Review	130
We thank Reviewer #2 for the feedback and suggestions.	O	O	Reply	130
The suggestions are helpful, and we are open to further discussions.	O	O	Reply	130
<sep> <sep> From the comments, we infer that Reviewer #2 assumes our claim to be that top-down approaches perform worse than bottom-up approaches in terms of generalization abilities.	B-Reply	B-7	Reply	130
This is not exactly our view.	I-Reply	I-7	Reply	130
Here, we precisely lay out our argument: Using features with the global context may hurt part segmentation performance in unseen categories.	I-Reply	I-7	Reply	130
In most top-down pipelines and some bottom-up pipelines, the features extracted for each point to be fed to the classifier would include the global context.	I-Reply	I-7	Reply	130
This point will be further discussed when addressing specific concerns.	I-Reply	I-7	Reply	130
<sep> <sep> <sep> [Regarding ‚ÄúPartNet-InsSeg‚Äù outperforms ‚ÄúSGPN‚Äù in novel categories]	O	O	Reply	130
Both ‚ÄúPartNet-InsSeg‚Äù (top-down) and the ‚ÄúSGPN‚Äù (bottom-up) involve global context to learn point features and make decisions, thus give inferior segmentation results on unseen categories.	B-Reply	B-3	Reply	130
This is consistent with our conclusions.	I-Reply	I-3	Reply	130
We are happy to make this point crystally clear in the revised version.	I-Reply	I-3	Reply	130
<sep> <sep> <sep> <sep> [Regarding the performance of the tradition segmentation methods and the proposed method]	O	O	Reply	130
WCseg is one of the most feasible traditional segmentation methods, whose results are provided in Table 1.	B-Reply	B-2	Reply	130
Compared to the learning-based methods, It champions 6 out of 21 unseen categories.	I-Reply	I-2	Reply	130
Also, we have added more qualitative results to Appendix C.3, which demonstrates the performance of both the traditional segmentation method and the proposed method.	I-Reply	I-2	Reply	130
<sep> <sep> <sep> <sep> [Regarding the ablation studies]	O	O	Reply	130
Thanks for pointing this out, and we made the ablation studies more thorough in revision, including the effects of involving more context on both seen and unseen categories, more components analysis, and qualitative results of the rectification module.	B-Reply	B-4	Reply	130
Please refer to Appendix B for details.	I-Reply	I-4	Reply	130
<sep> <sep> Since the policy scores sum to one overall pairs of sub-parts, there is no explicit signal from the policy network whether the pair should be grouped.	I-Reply	I-4	Reply	130
We therefore introduce the termination module to verify whether we should group the pair of sub-parts, selected based on the score from the policy module.	I-Reply	I-4	Reply	130
We noticed that the name of ‚Äútermination module‚Äù may have confused reviewers, so we would rename it as ‚Äúverification module‚Äù.	I-Reply	I-4	Reply	130
Also, there is indeed a cascaded structure where the termination module will focus on the samples selected by the policy module.	I-Reply	I-4	Reply	130
This serves as a kind of hard example mining and complements the policy module, which needs to recognize so many samples.	I-Reply	I-4	Reply	130
We will make the related descriptions clearer in revision.	I-Reply	I-4	Reply	130
<sep> <sep> <sep> <sep> [Regarding the proposed method performs worse than Mo et al (2019) in seen categories]	O	O	Reply	130
With involved limited context only for seen categories, our proposed method further improves the performance in seen categories.	B-Reply	B-1	Reply	130
Please refer to Table 1,6 for new results and Appendix B.1 for details.	I-Reply	I-1	Reply	130

This paper proposes a method for part segmentation in object pointclouds.	O	O	Review	130
The method is to (1) break the object into superpixel-like subparts (without semantic meaning yet), then (2) score pairs of parts on their mergeability, (3) greedily merge the best pair, and repeat.	O	O	Review	130
The scoring has a unary component (called a "purity" module), and a pairwise component (called a "rectification" module); the unary component determines if the joined pointcloud of two sub-parts appears part-like, and the pairwise component determines if the features of the two sub-parts appear compatible.	O	O	Review	130
These components are implemented as pointnets/MLPs.	O	O	Review	130
Finally there is a termination module, which sigmoid-scores part pairs on whether they should actually merge (and the algorithm continue), or not (and we stop).	O	O	Review	130
The purity and termination modules are trained supervised, to mimic intersection-like and mergeability scores, and the rectification module with a "reward" which is another mergeability score (coming from GT and the purity module).	O	O	Review	130
<sep> <sep> The method is interesting for being (1) iterative, and (2) driven by purely local cues.	O	O	Review	130
The iterative approach, with small networks doing the work, is a nice relief from the giant-network baselines (such as PartNet-InsSeg) that take the entire pointcloud as input and produce all instance segmentations directly.	O	O	Review	130
Also, whereas most works try to maximize the amount of contextual input to the learning modules, this work makes the (almost certainly correct) observation that the smaller the contextual input, the smaller the risk for overfitting.	O	O	Review	130
This is a bit like making the approach "convolutional", in the sense that the same few parameters are used repeatedly over space (and in this case, also repeated over scale).	O	O	Review	130
The design of the local modules makes sense, although I would prefer they be called unary/pairwise instead of purity/rectification, and the RL training procedure looks reasonable also.	O	O	Review	130
<sep> <sep> I am not totally clear on how the termination module actually comes into play.	B-Review	B-1	Review	130
From the name, it sounds like this network would output 1 when the algorithm should terminate, but in its usage, it seems to output 1 when the best-scored pair should be merged.	I-Review	I-1	Review	130
So then, does the algorithm terminate when this module decides to NOT merge the best-scored pair?	I-Review	I-1	Review	130
This sounds like it bears great risk of early stopping.	I-Review	I-1	Review	130
I would appreciate some clarification on this.	I-Review	I-1	Review	130
<sep> <sep> The abstract says that locality "guarantees the generalizability to novel categories".	B-Review	B-2	Review	130
This is an overstatement, since "guarantees" implies some theoretical proof, and also since the paper's own results (in Table 1 and 3) indicate that cross-category generalization is far from addressed, and depends partly on the categories used in training (shown in Table 2).	I-Review	I-2	Review	130
<sep> <sep> I assume that this method has (or at least can have) far fewer parameters than the baselines, since the components never need to learn broad contextual priors.	B-Review	B-3	Review	130
Can the authors clarify and elaborate on this please?	I-Review	I-3	Review	130
If you can show that your method has far fewer parameters than the baselines, it would improve the paper I think.	I-Review	I-3	Review	130
<sep> <sep> Can the authors please provide some statistics on the earliest stage of the method, where superpixel-like parts are proposed?	B-Review	B-4	Review	130
How many proposals, and how many pairs does this make, and how slowly do the main modules proceed through these pairs?	I-Review	I-4	Review	130
<sep> <sep> Is there a missing step that makes the part selection non-random?	B-Review	B-5	Review	130
It seems like many of the pairs can be rejected outright early on, such as ones whose centroids exceed some distance threshold in 3D.	I-Review	I-5	Review	130
We greatly appreciate Reviewer #1 for the analysis, which precisely states the contributions of this paper.	O	O	Reply	130
We have added more details and made descriptions clearer in revision.	O	O	Reply	130
<sep> <sep> Here are the answers to the questions and concerns:	O	O	Reply	130
<sep> <sep> [Regarding the naming of modules, especially the ‚Äútermination module‚Äù]	O	O	Reply	130
Thanks for pointing this out.	B-Reply	B-1	Reply	130
After reading the comments from all reviewers, we also feel that renaming some modules may help to clarify confusion.	I-Reply	I-1	Reply	130
<sep> <sep> Since the policy scores sum to one overall pairs of sub-parts, there is no explicit signal from the policy network whether the pair should be grouped.	I-Reply	I-1	Reply	130
We therefore introduce the termination module to verify whether we should group the pair of sub-parts, selected based on the score from the policy module.	I-Reply	I-1	Reply	130
In fact, this module will verify pairs of merge candidates ranked by their scores from the policy module.	I-Reply	I-1	Reply	130
The first pair that passes the verification will be grouped.	I-Reply	I-1	Reply	130
Only if no pairs pass the verification the whole algorithm will terminate.	I-Reply	I-1	Reply	130
Based on the functionality, we would rename this module as ‚Äúverification module‚Äù.	I-Reply	I-1	Reply	130
The verification module complements the policy module, which needs to recognize so many samples.	I-Reply	I-1	Reply	130
The pipeline thus can be viewed as a kind of hard example mining.	I-Reply	I-1	Reply	130
We have made the related descriptions clearer in both Section 4.1 and Appendix C.1.	I-Reply	I-1	Reply	130
<sep> <sep> Currently, we named the modules according to their functionalities.	I-Reply	I-1	Reply	130
We thanks for the suggestion and will seriously consider using unary/pairwise(binary) naming the purity/rectification modules which indicate the type of information input into the module.	I-Reply	I-1	Reply	130
<sep> <sep> <sep> <sep> [Regarding the overstatement]	O	O	Reply	130
Thanks for the suggestion.	B-Reply	B-2	Reply	130
We have articulated this statement more precisely in revision.	I-Reply	I-2	Reply	130
The phrase ‚Äúguarantees the generalizability‚Äù is replaced by a milder one ‚Äúencourages the generalizability‚Äù.	I-Reply	I-2	Reply	130
<sep> <sep> <sep> <sep> [Regarding the proposed model has fewer parameters than baselines]	O	O	Reply	130
Thanks for pointing this out.	B-Reply	B-3	Reply	130
The number of parameters for different methods is listed below:	I-Reply	I-3	Reply	130
<sep> --------------------------	I-Reply	I-3	Reply	130
PartNet: 1.93e+06	I-Reply	I-3	Reply	130
SGPN:   1.55e+06	I-Reply	I-3	Reply	130
GSPN: 14.80e+06 (Shape Proposal Net: 13.86e+06)	I-Reply	I-3	Reply	130
Our:       0.64e+06	I-Reply	I-3	Reply	130
--------------------------	I-Reply	I-3	Reply	130
<sep> Currently, our model does have fewer parameters than compared learning methods.	I-Reply	I-3	Reply	130
But, we would like to point out that it will slightly degrade the performance on both seen and unseen categories if half the width of the model.	I-Reply	I-3	Reply	130
Our intuition is that the intermediate sub-parts generated during the grouping process may have various patterns and are irregular.	I-Reply	I-3	Reply	130
This increases the burden of models to recognize, and we widen the network can alleviate this situation.	I-Reply	I-3	Reply	130
This intuition is also one of the motivations why we introduce the RL to learn to select the pairs.	I-Reply	I-3	Reply	130
We want to use the policy network to help form more regular intermediate sub-parts during the grouping process.	I-Reply	I-3	Reply	130
The size-equal rule learned by our policy network is a positive signal on this point.	I-Reply	I-3	Reply	130
Please also refer to Appendix B.3 and see some related qualitative results.	I-Reply	I-3	Reply	130
<sep> <sep> Besides, the input for our modules is not the whole shape point cloud, but sampling points of sub-parts from the shape.	I-Reply	I-3	Reply	130
In our experiments, the size of input point clouds for our method is 1024, while for compared baselines are 10000.	I-Reply	I-3	Reply	130
So the proposed method has advantages in GPU memory cost.	I-Reply	I-3	Reply	130
<sep> <sep> <sep> <sep> [Regarding more statistics on the earliest stage of the method]	O	O	Reply	130
Thanks for pointing this out, and we have added more details and statistics in Appendix A and C.1.	B-Reply	B-4	Reply	130
<sep> <sep> When we train on Chair and test on Chair of the level-3 annotation, the average number of initial proposals on is 124 and the average number of pairs for the initial pool is 658.	I-Reply	I-4	Reply	130
The number of valid pairs will decrease quickly as the grouping process going, and we usually have a total of 137 iterations.	I-Reply	I-4	Reply	130
When employing the model on 1080Ti, it will cost 3s for processing one shape.	I-Reply	I-4	Reply	130
<sep> <sep> <sep> <sep> [Regarding the part selection]	O	O	Reply	130
Yes, we adopted similarly mentioned conditions that two sub-parts of a pair are constrained to be close to each other at the early grouping stage.	B-Reply	B-5	Reply	130
Please refer to Appendix C.1 to see more implementation details.	I-Reply	I-5	Reply	130

This paper describes a method for segmenting 3D point clouds of objects into component parts, with a focus on generalizing part groupings to novel object categories unseen during training.	O	O	Review	130
In order to improve generalization, the paper argues for limiting the influence of global context, and therefore seeks to build compact parts in a bottom-up fashion by iterative merging of superpixel-like point subsets.	O	O	Review	130
This is achieved by defining a RL merge policy, using merge and termination scores formed by a combination of explicitly trained part purity (each part should comprise one true part), and policy-trained pair comparison network.	O	O	Review	130
The system is evaluated using PartNet, using three categories for training and the rest for testing, showing strong performance relative to baselines.	O	O	Review	130
<sep> <sep> The system is described well, and shows good performance on a nicely motivated task.	O	O	Review	130
A few more ablations would have been nice to see (in questions below), as might more qualitative results.	O	O	Review	130
Overall, the method is presented and evaluated convincingly.	O	O	Review	130
<sep> <sep> <sep> Questions:	O	O	Review	130
<sep> *  What is the effect of the purity score regression?	B-Review	B-1	Review	130
Since the policy network is trained using a pair-comparison module anyway, what happens if the explicit purity score supervision is removed?	I-Review	I-1	Review	130
<sep> <sep> * What if the "rectifier" module is made larger (with or without purity module), e.g. the same size as the termination network?	B-Review	B-2	Review	130
Does this improve or overfit to the training categories?	I-Review	I-2	Review	130
<sep> <sep> * Sec 5.3 mentions "segmentation levels for different categories may not share consistent part granularity ....  Thus, ... we train three networks corresponding to three levels of segmentation for training categories".	B-Review	B-3	Review	130
While it makes sense to have three networks for the three levels (each have different termination points, and perhaps even merge paths), I don't see how this follows from the levels being inconsistent between categories.	I-Review	I-3	Review	130
In fact, it seems just the opposite, that if the levels are inconsistent, this could pose a problem when a part at one level for one category is "missing" from the other category, due to level numbers not coinciding.	I-Review	I-3	Review	130
Or, is this actually not a problem because on the three training categories selected, the levels are in fact consistent?	I-Review	I-3	Review	130
<sep> <sep> * Can termination be integrated into the policy network or policy itself?	B-Review	B-4	Review	130
<sep> <sep> A couple typos I noticed:	B-Review	B-5	Review	130
<sep> p.5 "In consequences," --&gt; "As a consequence,"	I-Review	I-5	Review	130
p.11 "in-balanced" --&gt; "unbalanced"	I-Review	I-5	Review	130
<sep> We thank Reviewer #3 for the comments and suggestions.	O	O	Reply	130
The suggestions are helpful in further improving our work.	O	O	Reply	130
<sep> <sep> Here are the answers to the questions and concerns:	O	O	Reply	130
<sep> <sep> [Regarding the purity score and the purity module]	O	O	Reply	130
Similar to the objectness score used in object detection, the purity score serves as the partness score to measure the quality of the sub-part.	B-Reply	B-1	Reply	130
The purity score is higher, the sub-part is more likely to only cover one part in ground-truth.	I-Reply	I-1	Reply	130
We will use this score to measure the quality of our initial sub-part proposals and remove the low-quality subparts to form our initial sub-parts pool.	I-Reply	I-1	Reply	130
We add more related descriptions in Appendix A and C.1.	I-Reply	I-1	Reply	130
<sep> <sep> For the policy network, we use the purity module to process unary information and the rectification module to process binary information.	I-Reply	I-1	Reply	130
While the purity score as a unary term could be learned through the policy gradient, we observe that we can give direct supervision, which is effective.	I-Reply	I-1	Reply	130
In revision, we add related ablation results in Appendix B.2 and justify that the purity module helps to learn the policy.	I-Reply	I-1	Reply	130
<sep> <sep> <sep> <sep> [Regarding making the rectification module larger]	O	O	Reply	130
Larger networks have larger capacities but higher risks to overfit to training data.	B-Reply	B-2	Reply	130
Since our approach purely exploits local context, larger networks may have less impact on the overfitting issue for our method compared to those baselines with inputting the global context.	I-Reply	I-2	Reply	130
We enlarge the rectification module and gain improvements in seen categories.	I-Reply	I-2	Reply	130
For the unseen categories which have similar part patterns with the training categories, we obtain some improvements.	I-Reply	I-2	Reply	130
But, for the unseen categories (e.g. scissors) which have relatively large different part patterns with the training categories (chair, storage furniture, lamp), we observe inconsistent improvements or declinations.	I-Reply	I-2	Reply	130
Thanks for the suggestion.	I-Reply	I-2	Reply	130
We will study this point thoroughly, and include it in revision.	I-Reply	I-2	Reply	130
<sep> <sep> Please also refer to Appendix B.1 to see the related ablation studies about the effects of involving more context on both seen and unseen categories.	I-Reply	I-2	Reply	130
<sep> <sep> <sep> <sep> [Regarding the levels being inconsistent between categories]	O	O	Reply	130
Thanks for pointing this out.	B-Reply	B-3	Reply	130
The mentioned statements are not clear, and we have fixed it in revision.	I-Reply	I-3	Reply	130
The segmentation levels for different categories may not share consistent part granularity, which is the reason that we gather together the part proposals predicted by networks at all three levels as a joint pool of proposals for evaluation on unseen categories.	I-Reply	I-3	Reply	130
The levels of different categories may not correspond exactly; however, the joint part proposals can cover multiple levels of parts for unseen categories.	I-Reply	I-3	Reply	130
Our three training categories have several thousands of models per category, thus providing a large variety of parts at different granularities for learning.	I-Reply	I-3	Reply	130
<sep> <sep> <sep> <sep> [Regarding integrating the termination module into the policy module]	O	O	Reply	130
In our pipeline, we will use the policy network to pick the pair of sub-parts and use the termination network to determine whether we should group the pair.	B-Reply	B-4	Reply	130
The termination module is the basic building block of our pipeline.	I-Reply	I-4	Reply	130
We noticed that the name of ‚Äútermination module‚Äù may have confused readers, so we would rename it as ‚Äúverification module‚Äù and made related descriptions clearer in revision.	I-Reply	I-4	Reply	130
Also, we would like to point out that the termination module will focus on the samples selected by the policy module.	I-Reply	I-4	Reply	130
This cascade structure serves as a kind of hard example mining and will improve the performance.	I-Reply	I-4	Reply	130

This manuscript presents a number of algorithmic techniques to reduce the computational and space complexity of Transformer, a powerful and very popular deep learning model for natural language processing (NLP).	B-Review	B-2	Review	130
Although Transformer has revolutionized the field of NLP, many small groups cannot make a full use of it due to lack of necessary computational resources.	I-Review	I-2	Review	130
As such, it is very important to improve the space and computational complexity of this popular deep model.	I-Review	I-2	Review	130
The techniques presented in this manuscript seem to be very reasonable and the experimental results also indicate that they are effective.	O	O	Review	130
My major concern is that the authors shall present more detailed experimental results.	B-Review	B-1	Review	130
In addition to bits per dim, it will also better if the authors can evaluate the performance in terms of other metrics.	I-Review	I-1	Review	130
We thank the reviewer for feedback and comments on our paper.	O	O	Reply	130
We have updated the paper to address some concerns and we‚Äôre working on preparing additional experiments and results to more thoroughly characterize the behavior of the proposed method, which will address all other questions.	O	O	Reply	130
<sep> <sep> We posted a revised version of the paper with updated results figures.	B-Reply	B-3	Reply	130
In particular, we‚Äôve completed the curves and updated our illustration of the wall clock time used by different attention methods.	I-Reply	I-3	Reply	130
This makes it clearer at what length the LSH attention starts saving time compared to full attention and at which number of hashes (Figure 5).	I-Reply	I-3	Reply	130
<sep> <sep> As for the question on metrics: we will expand the results to include machine translation in the final version (we didn‚Äôt do this initially since sequences are quite short in translation datasets and as such don‚Äôt make for ideal targets for the Reformer).	B-Reply	B-1	Reply	130
We did not get the complete results yet, but we started training a Reformer language model on concatenated English-then-German sentence pairs and we do not observe any major difference compared to a regular Transformer LM.	I-Reply	I-1	Reply	130
We are also putting together and tuning a more conventional encoder-decoder approach that uses the Reformer architecture and we will include a comparison of BLEU between such Reformer and the Transformer in the final version of our paper.	I-Reply	I-1	Reply	130
<sep> <sep> We are also happy to report that, with further tuning, a 12-layer Reformer model can achieve 1.05 bits/dim on the enwik8 test set.	I-Reply	I-1	Reply	130
In terms of other metrics, this corresponds to 77.8% byte-level accuracy.	I-Reply	I-1	Reply	130

This paper presents a method to make Transformer models more efficient in time and memory.	O	O	Review	130
The proposed approach consists mainly of three main operations:	O	O	Review	130
- Using reversible layers (inspired from RevNets) in order to prevent the need of storing the activations of all layers to be reused for back propagation;	O	O	Review	130
- Using locality sensitive hashing to approximate the costly softmax(QK^T) computation in the full dot-product attention;	O	O	Review	130
- Chunking the feed-forward layers computations to reduce their cost.	O	O	Review	130
<sep> This approach is first applied to a toy dataset to analyze its complexity, then tested on enwik8 language modelling task and imagenet-64 image generation task for ablation study and performance assessment.	O	O	Review	130
<sep> <sep> The problem approached by the paper is interesting and the proposed approach is novel to the best of my knowledge.	O	O	Review	130
The paper is well structured and clearly written a part from some small typos (see minor comments below).	O	O	Review	130
<sep> While the analysis of complexity is sound and convincing, and the fact of being able to train larger Reformers is very interesting, I have some questions and concerns about the approach and experiments.	O	O	Review	130
<sep> - Effect of reversible layers: It is clear for the experiment of Imagenet64 that the effect is negligible, but the experiment on enwik8 in the paper seems unfinished.	B-Review	B-1	Review	130
Did the authors manage to finish the training, and does it confirm the observation?	I-Review	I-1	Review	130
<sep> - Sharing QK: I am a bit confused about the effect and usefulness of this operation.	B-Review	B-2	Review	130
Can the authors comment on why it is needed for LSH attention?	I-Review	I-2	Review	130
It seems to me that the same operations can be achieved with different Q and K. Indeed, doing so, the authors slightly reduce the capacity of the model.	I-Review	I-2	Review	130
The observed non-significantly decreased performance can be an effect of using only 3-layers.	I-Review	I-2	Review	130
This may explain why the results reported for larger models in figure 5 show higher bpc than similar size state of the art models.	I-Review	I-2	Review	130
<sep> - Time per iterations: Can the authors report the time per iteration for the larger hash rounds (8 and 16) that are closer to full attention?	B-Review	B-3	Review	130
For the highest reported number (4), from a quick and not precise look at figure 4, it seems that the performance achieved by the proposed method after 140k iterations is achieved by the full attention after ~40k iterations.	I-Review	I-3	Review	130
The gain in time per iteration for this particular number of hash rounds can be lost by the loss in performance.	I-Review	I-3	Review	130
<sep> - Can the authors detail how they chose the hyperparameters of their approach?	B-Review	B-4	Review	130
e.g. the size of hash buckets, the distribution used to generate the random matrix R ..	I-Review	I-4	Review	130
- The reported results can be made stronger by reporting average/error bars across several trial to show consistency.	B-Review	B-5	Review	130
<sep> <sep> Minor: typos:	B-Review	B-6	Review	130
Dimension of matrix R [d_k, d_b/2] -&gt; [d_k, b/2]	I-Review	I-6	Review	130
Last paragraph of page 6: state of these art -&gt; state of the art	I-Review	I-6	Review	130
<sep> ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî	O	O	Review	130
After rebuttal:	O	O	Review	130
I have read the authors answer, and found they addressed my concerns.	O	O	Review	130
I'm therefore increasing my score.	O	O	Review	130
We thank the reviewer for thoughtful feedback on our paper.	O	O	Reply	130
We have posted an update to address some of the comments, which we detail below.	O	O	Reply	130
<sep> <sep> 1.	O	O	Reply	130
Effect of reversible layers	O	O	Reply	130
<sep> We updated the figures in the paper to cover longer training durations.	B-Reply	B-1	Reply	130
As expected, reversible layers perform the same as regular Transformer layers on enwik8.	I-Reply	I-1	Reply	130
<sep> <sep> 2.	O	O	Reply	130
Sharing QK	O	O	Reply	130
<sep> This operation is needed so that we can batch LSH attention on current hardware.	B-Reply	B-2	Reply	130
Absent any hardware requirements, we could do unshared LSH attention as illustrated in Figure 2(b).	I-Reply	I-2	Reply	130
Each hash bucket in the unshared condition may contain a different number of queries, a different number of keys, and moreover there is no relationship between the number of queries and the number of keys.	I-Reply	I-2	Reply	130
Computing one bucket at a time would be too slow, and it‚Äôs unclear how to batch buckets of highly variable sizes.	I-Reply	I-2	Reply	130
With shared-QK, as in Figure 2(c-d), we can batch effectively because the entries we want to calculate cluster near the main diagonal (after sorting).	I-Reply	I-2	Reply	130
Let us stress though that this is purely a speed optimization which we did due to the realities of current hardware architectures.	I-Reply	I-2	Reply	130
It works, but one could indeed hope that one day it will not be necessary.	I-Reply	I-2	Reply	130
<sep> <sep> 3.	O	O	Reply	130
Enwik8 results	O	O	Reply	130
<sep> We‚Äôre happy to report that, with further tuning, our 12-layer model reaches 1.05 bits/dim on enwik8.	B-Reply	B-1	Reply	130
Adjusting optimizer settings and dropout played a big role in improving perplexity for this task.	I-Reply	I-1	Reply	130
<sep> <sep> 3.	O	O	Reply	130
Time per iterations	O	O	Reply	130
<sep> Thank you for your suggestion.	O	O	Reply	130
We‚Äôve updated the right part of Figure 5 to sweep over a larger range of hash numbers and sequence lengths.	B-Reply	B-3	Reply	130
Although full attention is fast for short sequences, its O(n^2) scaling makes it rather slow at long sequence lengths, even when compared to the 8-hash LSH variant.	I-Reply	I-3	Reply	130
<sep> <sep> 4.	O	O	Reply	130
Hyperparameters	O	O	Reply	130
<sep> The random matrix R has i.i.d.	B-Reply	B-4	Reply	130
unit Gaussian entries, following Andoni et al (<a href="https://arxiv.org/pdf/1509.02897.pdf;" target="_blank" rel="nofollow">https://arxiv.org/pdf/1509.02897.pdf;</a> page 4).	I-Reply	I-4	Reply	130
The number of hash buckets was chosen such that each bucket would have 64 entries on average.	I-Reply	I-4	Reply	130
Making the hash buckets smaller hurts accuracy, whereas increasing it doesn‚Äôt seem to do much other than making the model slower.	I-Reply	I-4	Reply	130
<sep> <sep> 5.	O	O	Reply	130
Variance between runs.	O	O	Reply	130
<sep> <sep> Thank you for your pointing this out.	B-Reply	B-5	Reply	130
For now, we can report that the variance between runs, at convergence, is minimal: we see no variance when rounding to two decimal points.	I-Reply	I-5	Reply	130

This paper presents an attempt to reduce the memory complexity of Transformers.	O	O	Review	130
The authors call their model the Reformer.	O	O	Review	130
It presents a LSH based self-attention mechanism, along with reversible adaptation of Transformers.	O	O	Review	130
The Locality sensitive hashing scheme reduces complexity from L^2 to L which is pretty neat.	O	O	Review	130
<sep> <sep> Tackling the quadratic complexity of self-attention is indeed an important and nice direction.	O	O	Review	130
I think the LSH based attention quite novel and is a natural solution to reducing the complexity of the self-attention module.	O	O	Review	130
However, I think the technical description could be improved as the current form is quite confusing and difficult to parse.	B-Review	B-1	Review	130
<sep> <sep> The experiments are a little on the weaker side.	B-Review	B-2	Review	130
Authors presented results on imagenet, enwiki and a synthetic task.	I-Review	I-2	Review	130
I am mainly concerned if the Reformer works on tasks such as machine translation or other NLP tasks.	I-Review	I-2	Review	130
The paper does not present much evidence that the effectiveness of LSH is broad and versatile.	I-Review	I-2	Review	130
<sep> <sep> My current vote is a weak accept, based on some preliminary understanding and the general novelty of the idea.	O	O	Review	130
<sep> <sep> I do have some questions/issues/comments:	O	O	Review	130
<sep> 1) Given that there is some form of QK sorting, how is it possible to mask the future?	B-Review	B-3	Review	130
Is this because tokens are sorted within buckets?	I-Review	I-3	Review	130
<sep> 2) Can the authors clarify what "Causal masking on the Transformer is typically implemented to allow a position i to attend to itself."	B-Review	B-4	Review	130
mean?	I-Review	I-4	Review	130
<sep> 3) I'm a little confused about how the sorting is being done.	B-Review	B-5	Review	130
Can this be done in an end-to-end differentiable manner?	I-Review	I-5	Review	130
<sep> 4) Can the authors present some results on other tasks?	B-Review	B-7	Review	130
While neat, I think other tasks (e.g., MT or QA) can be investigated to further ascertain that the LSH attention works well.	I-Review	I-7	Review	130
Current experimental results are not too convincing.	I-Review	I-7	Review	130
<sep> <sep> Thank you for your feedback and questions regarding the paper, which we address one-by-one below.	O	O	Reply	130
We‚Äôre updated the technical sections of the paper to increase clarity; please let us know if there are still any sections that you find difficult to parse.	O	O	Reply	130
<sep> <sep> 1.	O	O	Reply	130
How is causal masking implemented?	O	O	Reply	130
<sep> <sep> To mask out attention to the future, we associate each query/key vector with a position index, where the position indices are then sorted using the same permutation as the QK sort.	B-Reply	B-4	Reply	130
Position indices are compared for each query-key dot product, and the attention probability is masked to zero if the query comes before the key.	I-Reply	I-4	Reply	130
<sep> <sep> 2.	O	O	Reply	130
Attention-in-place	O	O	Reply	130
<sep> Thank you for pointing out that this was unclear.	B-Reply	B-1	Reply	130
We have updated the paper to elaborate on this point.	I-Reply	I-1	Reply	130
<sep> <sep> In a typical Transformer implementation, positions can attend to themselves.	I-Reply	I-1	Reply	130
There is a dot product between the query vector at position i and the key vector at position i; if this dot product is high then the value vector at position i will contribute to the output of the attention layer.	I-Reply	I-1	Reply	130
This behavior isn‚Äôt very useful because local information is already propagated through the residual connections, but standard attention can learn to drive this attention probability to zero by making q_i and k_i orthogonal.	I-Reply	I-1	Reply	130
Shared-QK attention, on the other hand, can‚Äôt reduce this weight because the query and the key are the same vector.	I-Reply	I-1	Reply	130
To address this issue, we don‚Äôt allow attention-in-place for the Reformer.	I-Reply	I-1	Reply	130
<sep> <sep> 3.	O	O	Reply	130
Backprop through LSH attention, and sorting.	O	O	Reply	130
<sep> <sep> We use sorting as an implementation for allowing items that map to the same hash bucket to attend to each other.	B-Reply	B-7	Reply	130
Similar items get mapped to the same hash bucket with high probability, which allows similar item pairs to participate in both the forward and backward passes.	I-Reply	I-7	Reply	130
Each hash bucket may contain a certain number of unrelated items, in which case there will be a gradient signal that either up-weighs or down-weighs attention to these items.	I-Reply	I-7	Reply	130
<sep> <sep> We don‚Äôt differentiate through the hash bucket assignment procedure, or the choice of what order to sort the items into.	I-Reply	I-7	Reply	130
Rather, these operations take query/key vectors as input where LSH maps nearby vectors to the same bucket with high probability.	I-Reply	I-7	Reply	130
Therefore, the sorting re-adjusts any time parameter updates to cause relevant vector pairs to have higher dot product, and ‚Äúunhelpful‚Äù vector pairs to have lower dot products.	I-Reply	I-7	Reply	130
<sep> <sep> 4.	O	O	Reply	130
Additional tasks.	O	O	Reply	130
<sep> <sep> Thank you for your recommendation that we evaluate on other tasks.	O	O	Reply	130
Prompted by your recommendation we started working on applying the Reformer to machine translation (we didn‚Äôt do that before since sequences are short in translation data-sets so it was not a prime target for Reformer).	B-Reply	B-6	Reply	130
Thus far we have trained a decoder-only Reformer on concatenated English-then-German sentence pairs, and we do not observe any difference compared to a regular Transformer LM.	I-Reply	I-6	Reply	130
We‚Äôre in the process of constructing and tuning a more standard encoder-decoder approach that likewise uses the Reformer architecture.	I-Reply	I-6	Reply	130
In the final version of our paper, we‚Äôll report BLEU numbers and comparisons for English-German translation -- the current runs make us believe that they will be the same as for Transformer.	I-Reply	I-6	Reply	130

Pretty interesting paper attempting to learn discrete linguistic units via vector quantization of visually grounded, speech related features.	O	O	Review	20518
I think this is a worthwhile contribution.	O	O	Review	20518
My main complaint is that the exposition is a bit diffuse and fails to crystallize the essence of the work.	B-Review	B-1	Review	20518
In particular, the claim is that the novelty is from the use of a "discriminative, multi-modal grounding objective".	I-Review	I-1	Review	20518
Reading the work, this seems to be the triplet loss described in Section 3.5.	B-Review	B-2	Review	20518
Is that the novel objective?	I-Review	I-2	Review	20518
In my my the really interesting aspect that should be stressed is the visual grounding -- I encourage the authors to highlight that aspect more directly.	I-Review	I-2	Review	20518
I fear that essential and interesting point is somewhat diluted in the detailed exposition of results.	I-Review	I-2	Review	20518
Detailed response to Reviewer #3:	O	O	Reply	20518
<sep> Q3.1: My main complaint is that the exposition is a bit diffuse and fails to crystallize the essence of the work.	O	O	Reply	20518
In particular, the claim is that the novelty is from the use of a "discriminative, multi-modal grounding objective".	O	O	Reply	20518
Reading the work, this seems to be the triplet loss described in Section 3.5.	O	O	Reply	20518
Is that the novel objective?	O	O	Reply	20518
<sep> <sep> A3.1: We apologize for the confusion about the novelty.	B-Reply	B-1	Reply	20518
We did not mean to say the triplet loss is a novel objective for visual grounding.	I-Reply	I-1	Reply	20518
Instead, our novelty is learning discrete linguistic units through visual grounding, rather than through reconstruction (e.g., VQ-VAE).	I-Reply	I-1	Reply	20518
The triplet loss is simply the specific way that we implement the visual grounding.	I-Reply	I-1	Reply	20518
<sep> <sep> Q3.2: In my my the really interesting aspect that should be stressed is the visual grounding -- I encourage the authors to highlight that aspect more directly.	O	O	Reply	20518
I fear that essential and interesting point is somewhat diluted in the detailed exposition of results.	O	O	Reply	20518
<sep> <sep> A3.2: We thank you for the suggestion and we fully agree.	B-Reply	B-2	Reply	20518
We will revise the abstract and introduction to better highlight discrete speech unit learning via visual grounding as the core contribution.	I-Reply	I-2	Reply	20518

This paper attempts to learn discrete speech units in a hierarchical (phone and word) fashion by incorporating multiple vector quantization layers into the audio encoder branch of a model that visually grounds speech segments with accompanying images.	O	O	Review	20518
<sep> <sep> The model has been tested and compared against two algorithms and implementations that set the SOTA on the Zero Speech 2019 challenge (further improving one of them in the process, it seems), and outperforms these significantly using the ABX metric, so the proposed method seems to perform well (the model is using additional supervision, though).	O	O	Review	20518
In addition, this is an interesting and timely research problem with implications far beyond the core machine learning setup.	O	O	Review	20518
The hierarchical setup, and the finding that successful learning here depends on the curriculum, is intriguing indeed.	O	O	Review	20518
The paper is a pleasure to read and provides a rich set of results and analyses.	O	O	Review	20518
<sep> <sep> A few remarks:	O	O	Review	20518
- It is probably worth explaining how the ABX test is performed, i.e. that features are extracted from some layer of a model, and then a time alignment is performed to get the score - this is in the text somehow, but i had to read it multiple times.	B-Review	B-1	Review	20518
<sep> - Did you try other architectures like 5 layers (rather than 4) in Figure 2	B-Review	B-2	Review	20518
- Figure 2 is a bit hard to interpret.	B-Review	B-3	Review	20518
Maybe plot log of ABX error rate or something, to pull apart the different layers?	I-Review	I-3	Review	20518
<sep> - Could you explain the difference between cold-start and warm-start?	B-Review	B-4	Review	20518
One is adding the discretization to a pre-trained model, the other is training from the start?	I-Review	I-4	Review	20518
<sep> - When you measure ABX at layer 2 and 3, in a model trained with quantization, do you measure ABX on the features before or after quantization?	B-Review	B-5	Review	20518
does it make a difference?	I-Review	I-5	Review	20518
<sep> - Table 7: some of the top word hypothesis pairs make sense acoustically (building-buildings, red-bed, ...), some could be neighboring words (large-car, ...), but some are just weird (people-computer) - any intuition as to what is going on?	B-Review	B-6	Review	20518
Detailed response to Reviewer #2:	O	O	Reply	20518
<sep> Q2.1: It is probably worth explaining how the ABX test is performed, i.e. that features are extracted from some layer of a model, and then a time alignment is performed to get the score - this is in the text somehow, but i had to read it multiple times.	O	O	Reply	20518
<sep> <sep> A2.1: Thank you for this suggestion - we will include a few sentences describing in detail how the ABX score is computed.	B-Reply	B-1	Reply	20518
<sep> <sep> Q2.2: Did you try other architectures like 5 layers (rather than 4) in Figure 2	O	O	Reply	20518
<sep> A2.2: We apologize that the legend in Figure 2 is slightly misleading, because ‚Äúlayer‚Äù in this context actually refers to the output of a residual block.	B-Reply	B-2	Reply	20518
The total number of convolutional layers in the model is 17 (because each residual block contains 4 convolutions, and there is 1 initial convolutional layer before the 4 residual blocks), but we only probe the representations between consecutive blocks.	I-Reply	I-2	Reply	20518
<sep> <sep> Q2.3: Figure 2 is a bit hard to interpret.	O	O	Reply	20518
Maybe plot log of ABX error rate or something, to pull apart the different layers?	O	O	Reply	20518
<sep> <sep> A2.3: We agree that the figure would be more clearly interpretable on a log scale and will make this adjustment.	B-Reply	B-3	Reply	20518
We will also make the legend more specific to highlight the fact that in the middle sub-figure the red curve represents a quantized output, and in the right sub-figure the brown curve represents a quantized output (whereas all outputs are continuous in the leftmost sub-figure)	I-Reply	I-3	Reply	20518
<sep> Q2.4: Could you explain the difference between cold-start and warm-start?	O	O	Reply	20518
One is adding the discretization to a pre-trained model, the other is training from the start?	O	O	Reply	20518
<sep> <sep> A2.4: A warm-start model just means that training starts from an initial model that can either be continuous or discretized - in other words, a warm-start model is pre-trained, except for any new quantization layers that are inserted (which are randomly initialized).	B-Reply	B-4	Reply	20518
In contrast, a cold-start model is trained from a random initialization.	I-Reply	I-4	Reply	20518
<sep> <sep> Q2.5: When you measure ABX at layer 2 and 3, in a model trained with quantization, do you measure ABX on the features before or after quantization?	O	O	Reply	20518
does it make a difference?	O	O	Reply	20518
<sep> <sep> A2.5: In these cases, we measure ABX on the features after quantization in the paper.	B-Reply	B-5	Reply	20518
Here we provide additional ABX results on the features before quantization.	I-Reply	I-5	Reply	20518
<sep> <sep> For model ‚Äú{2}‚Äù in Table 1, ABX at layer 2 is 10.73% before quantization and 12.33% after quantization.	I-Reply	I-5	Reply	20518
For model ‚Äú{3}‚Äù in Table 1, ABX at layer 3 is 32.24% before quantization and 38.21% after quantization.	I-Reply	I-5	Reply	20518
In general, quantization does hurt the ABX performance, but comes with the benefit of far greater information compression (in terms of bitrate) over non-quantized representations.	I-Reply	I-5	Reply	20518
Additionally, it should also be noticed that for non-quantized model, the ABX at layer 2 is 11.35%, which is worse than the pre-quantized feature in a quantized model.	I-Reply	I-5	Reply	20518
This can imply that the inductive bias that encourages features to be close to one of the codes also improves the quality of the learned continuous representations.	I-Reply	I-5	Reply	20518
<sep> <sep> Q2.6: Table 7: some of the top word hypothesis pairs make sense acoustically (building-buildings, red-bed, ...), some could be neighboring words (large-car, ...), but some are just weird (people-computer) - any intuition as to what is going on?	O	O	Reply	20518
<sep> <sep> A2.6: Table 7 represents the performance of the VQ3 layer in a model that did not learn to make this layer function as a word detector.	B-Reply	B-6	Reply	20518
Therefore, we expect very few of the codebook vectors shown in Table 7 to accurately detect words.	I-Reply	I-6	Reply	20518
We included this table primarily as a point of contrast to Table 6, which shows a model whose VQ3 layer did learn to function as a word detector (and thus has many more codes with a large F1 score for specific words).	I-Reply	I-6	Reply	20518
We wanted to draw this contrast because the only difference between the models corresponding to Table 6 vs. Table 7 is the training curriculum.	I-Reply	I-6	Reply	20518
In the case of (people-computer) in Table 7, code #924 was one of only a handful of codebook entries that learned to behave as a reliable word detector, for the word ‚Äúpeople‚Äù with an F1 score of 76.6. ‚	I-Reply	I-6	Reply	20518
ÄúComputer‚Äù is simply the word with the second highest F1 score when code #924 is treated as a detector for that word - but it is a very poor detector for ‚Äúcomputer,‚Äù with an F1 score of only 2.3.	I-Reply	I-6	Reply	20518

Overview:	O	O	Review	20518
<sep> The paper proposes a method to learn discrete linguistic units in a low-resource setting using speech paired with images (no labels).	B-Review	B-5	Review	20518
The visual grounding signal is different from other recent work, where a reconstruction objective was used to learn discrete representations in unsupervised neural networks.	O	O	Review	20518
In contrast to other work, a hierarchy of discretization layers are also considered, and the paper shows that, with appropriate initialization, higher discrete layers capture word-like units while lower layers capture phoneme-like units.	O	O	Review	20518
<sep> <sep> Strengths:	O	O	Review	20518
<sep> The paper is extremely well-written with a clear motivation (Section 1).	O	O	Review	20518
The approach is novel.	O	O	Review	20518
But I think the paper's biggest strength is in its very thorough experimental investigation.	O	O	Review	20518
Their approach is compared to other very recent speech discretization methods on the same data using the same (ABX) evaluation metric.	O	O	Review	20518
But the work goes further in that it systematically attempts to actually understand what types of structures are captured in the intermediate discrete layers, and it is able to answer this question convincingly.	O	O	Review	20518
Finally, very good results on standard benchmarks are achieved.	O	O	Review	20518
<sep> <sep> Weaknesses:	O	O	Review	20518
<sep> Although I think the paper is very well-motivated, my first criticism is that discretization itself is not motivated: why is it necessary to have a model with discrete intermediate layers?	B-Review	B-1	Review	20518
Does this give us something other than interpretability (which we obtain due to the sparse bottleneck)?	I-Review	I-1	Review	20518
In the detailed questions below, I also specifically ask whether, for instance, the downstream speech-image task actually benefits from including discrete layers.	I-Review	I-1	Review	20518
<sep> <sep> My second point is that it is unclear why word-like units only appear when the higher-level discrete layers are trained from scratch; as soon as warm-starting is used, the higher level layers capture phoneme-like units (Table 1).	B-Review	B-2	Review	20518
Is it possible to answer/speculate why this is the case?	I-Review	I-2	Review	20518
<sep> <sep> Overall assessment:	O	O	Review	20518
<sep> The paper presents a new approach with a thorough experimental investigation.	O	O	Review	20518
I therefore assign an "accept".	O	O	Review	20518
The weaknesses above asks for additional motivation and some speculation.	O	O	Review	20518
<sep> <sep> Questions, suggestions, typos, grammar and style:	O	O	Review	20518
<sep> - Section 3.3: It maybe makes less sense for the end-task, but did the authors consider discretization on the image side of the network?	B-Review	B-3	Review	20518
This could maybe lead to parts of objects being composed to form larger objects (in analogy to the speech network).	I-Review	I-3	Review	20518
<sep> - Section 3.3, par.	B-Review	B-4	Review	20518
3: "with the intention that they should capture discrete word-like and sub-word-like units" -&gt; "with the intention that they should capture discrete *sub-word-like and word-like units*" (easier to read with first part of sentence)	I-Review	I-4	Review	20518
- Section 3.3: The more standard VQ-VAE adds a commitment loss and a loss for updating the embeddings; was this used or considered at all, or is this all captured through the exponential moving average method?	B-Review	B-5	Review	20518
<sep> - Section 3.4: "with same VQ layers" -&gt; "with *the* same VQ layers"	B-Review	B-6	Review	20518
- Section 3.5: Can you briefly outline the motivation for adding the two losses (so that it is not required to read the previous work).	B-Review	B-7	Review	20518
<sep> - Section 4.1: Following from the first weakness listed above, the caption under Figure 2 states that the non-discrete model achieves a speech-image retrieval R@10 of 0.735.	B-Review	B-8	Review	20518
This is lower than some of the best scores achieved in Table 1.	I-Review	I-8	Review	20518
Can this be taken as evidence that discretization actually improves the downstream task?	I-Review	I-8	Review	20518
If so, it would be worth highlighting the point more; if there is some other reason, that would also be worth knowing.	I-Review	I-8	Review	20518
<sep> - Figure 1: Did the authors ever consider putting discrete layers right at the top of the speech component, just before the pooling layer?	B-Review	B-9	Review	20518
Would this more consistently lead to word-like units?	I-Review	I-9	Review	20518
<sep> <sep> Detailed response to Reviewer #1 (part 1 of 2):	O	O	Reply	20518
<sep> Q1.1: why is it necessary to have a model with discrete intermediate layers?	O	O	Reply	20518
Does this give us something other than interpretability (which we obtain due to the sparse bottleneck)?	O	O	Reply	20518
In the detailed questions below, I also specifically ask whether, for instance, the downstream speech-image task actually benefits from including discrete layers.	O	O	Reply	20518
<sep> <sep> A1.1:	O	O	Reply	20518
We agree that interpretability is an important benefit of quantization, and also believe that there are other compelling reasons for learning discrete speech representations.	B-Reply	B-1	Reply	20518
<sep> <sep> All known human languages employ a finite inventory of phonemes, where a phoneme is defined as the minimal perceptive unit whose modification (insertion, deletion, substitution) changes the meaning of the underlying word it belongs to.	I-Reply	I-1	Reply	20518
The sentences ‚ÄúThey bit them‚Äù and ‚ÄúThey bet them‚Äù differ by only one phoneme (/I/ vs. /e/ in the middle word), but as a result they take on completely different meanings.	I-Reply	I-1	Reply	20518
Evidence has been found that human perception of phonemes is categorical in nature: for example, gradually interpolating between the acoustic realizations of two different phonemes reveals a sharp decision threshold in human judgements of the underlying phoneme identity [1].	I-Reply	I-1	Reply	20518
<sep> From the perspective of one-shot or few-shot learning, discretization makes sense because the principle of compositionality could be leveraged to reduce the sample complexity of learning new words.	I-Reply	I-1	Reply	20518
From a bottom-up standpoint, maintaining an inventory of sub-word building blocks enables new words to be expressed in terms of a sequence of units already known to the model.	I-Reply	I-1	Reply	20518
From a top-down perspective, segmentation and grammatical parsing of the words surrounding a new word form enable a learner to more quickly grasp the meaning of the word.	I-Reply	I-1	Reply	20518
Ultimately, we would like to extend this work into the realm of acquiring higher-level linguistic structure, such as syntax and grammar, directly from the speech waveform (as human children are able to do).	I-Reply	I-1	Reply	20518
These systems inherently operate on token sequences, and so it seems reasonable that some sort of discrete inductive bias should be baked into the model.	I-Reply	I-1	Reply	20518
<sep> <sep> Finally, learning discrete representations of speech audio opens the door to applying NLP techniques such as BERT directly to the speech signal.	I-Reply	I-1	Reply	20518
This was explored in another ICLR 2020 submission, with impressive results on supervised speech recognition (<a href="https://openreview.net/forum?id=rylwJxrYDS)" target="_blank" rel="nofollow">https://openreview.net/forum?id=rylwJxrYDS)</a>	I-Reply	I-1	Reply	20518
<sep> [1] Lisker, Leigh, and Arthur S. Abramson. "	O	O	Reply	20518
The voicing dimension: Some experiments in comparative phonetics."	O	O	Reply	20518
In Proceedings of the 6th international congress of phonetic sciences, pp.563-567.	O	O	Reply	20518
Academia Prague, 1970.	O	O	Reply	20518
<sep> <sep> Q1.2: Section 3.3: It maybe makes less sense for the end-task, but did the authors consider discretization on the image side of the network?	O	O	Reply	20518
This could maybe lead to parts of objects being composed to form larger objects (in analogy to the speech network).	O	O	Reply	20518
<sep> <sep> A1.2: We have not experimented with adding VQ layers in the image model, but we agree with the reviewer that it may also lead to a similar hierarchical compositionality in the image network, and further improves the visual grounding performance because of better generalization, as observed when adding VQ layers to the audio network (as noted in Q1.6).	B-Reply	B-3	Reply	20518
We will leave it as future work here.	I-Reply	I-3	Reply	20518
<sep> <sep> Q1.3: - Section 3.3: The more standard VQ-VAE adds a commitment loss and a loss for updating the embeddings; was this used or considered at all, or is this all captured through the exponential moving average method?	O	O	Reply	20518
<sep> <sep> A1.3: We only experimented with exponential moving average (EMA) for updating the codebook, which is introduced in the original VQ-VAE paper and works well for our model.	B-Reply	B-5	Reply	20518
We believe that our model should also work with the gradient-based update.	I-Reply	I-5	Reply	20518
<sep> <sep> Q1.4: - Section 3.5: Can you briefly outline the motivation for adding the two losses (so that it is not required to read the previous work).	O	O	Reply	20518
<sep> <sep> A1.4: Yes, we will add the motivation for adding the losses to the text.	B-Reply	B-7	Reply	20518
It was shown in Harwath et al (2019) that the addition of the second loss term (semi-hard negative mining) performed much better than the standard triplet loss, and the authors noted that using only the semi-hard negative mining term by itself led to unstable training.	I-Reply	I-7	Reply	20518
<sep> <sep> Q1.5:- Figure 1: Did the authors ever consider putting discrete layers right at the top of the speech component, just before the pooling layer?	O	O	Reply	20518
Would this more consistently lead to word-like units?	O	O	Reply	20518
<sep> <sep> A1.5: We did not consider adding a discrete layer because we hypothesize that the final layer could be capturing linguistic units larger than words, such as phrases (which would require a much larger codebook), or semantic equivalence classes of multiple different words/phrases with synonymous/similar meanings.	B-Reply	B-9	Reply	20518

This paper presents a M-product based temporal GCNs to handle dynamic graphs.	O	O	Review	20523
Experiments on four real datasets are performed to verify the effectiveness of the proposed model.	O	O	Review	20523
<sep> <sep> Overall, I think this paper make a few contributions to advocate tensor M-product.	O	O	Review	20523
However, there are several big issues as listed below.	O	O	Review	20523
Given the current status, I could not accept the paper.	O	O	Review	20523
<sep> <sep> Pros:	O	O	Review	20523
<sep> 1, The generalization brought by M-product seems to be general as it includes quite a few graph convolution elements for 3D tensors in a natural way.	O	O	Review	20523
<sep> <sep> 2, The experimental setup is reasonable.	O	O	Review	20523
Datasets are collected from practical problems and of moderately large scale.	O	O	Review	20523
<sep> <sep> 3, The paper is clearly written and easy to follow.	O	O	Review	20523
<sep> <sep> Cons &amp; Questions:	O	O	Review	20523
<sep> 1, My first concern is that M-product formulation does not bring any new insights as people have already used some of the key elements in practice for a long time.	B-Review	B-1	Review	20523
For example, the M-transform is just applying 1x1 convolution to multi-channel image.	I-Review	I-1	Review	20523
Slice-wise matrix multiplication is also common in practice.	I-Review	I-1	Review	20523
<sep> <sep> 2, Moreover, I think there are several challenges in the M-product formulation which prevent the technique from being practical.	O	O	Review	20523
<sep> <sep> (1) Sharing M such that frontal slices of the transformed signal are the same, i.e., each row of M share the same vector, limits the model capacity significantly.	B-Review	B-2	Review	20523
If there is no sharing mechanism, then the model learned on one sequence of graphs could not be applied to another sequence of graphs given two sequences have different lengths.	I-Review	I-2	Review	20523
<sep> <sep> (2) If you learn M from data, how could you ensure that M is invertible?	B-Review	B-3	Review	20523
In the paragraph before section 4.1, an edge classification formulation is proposed where the inverse M-transform is abandoned.	I-Review	I-3	Review	20523
However, if in practice, you do not need the inverse transform, then do those theoretical properties still hold and what is the meaning of introducing such M-product formulation?	I-Review	I-3	Review	20523
<sep> <sep> 3, A few temporal GCN baselines are neither compared or discussed, e.g., [1].	B-Review	B-4	Review	20523
<sep> 4, Could you explain why all the other GCN variants performs significantly worse with a symmetrized adjacency matrix compared to using the asymmetric one?	B-Review	B-5	Review	20523
<sep> <sep> [1] Li, Y., Yu, R., Shahabi, C. and Liu, Y., 2017.	O	O	Review	20523
Diffusion convolutional recurrent neural network: Data-driven traffic forecasting.	O	O	Review	20523
arXiv preprint arXiv:1707.01926.	O	O	Review	20523
<sep> <sep> ======================================================================================================	O	O	Review	20523
<sep> After I read authors' reply and other reviewers' comments, I would like to keep my original rating as the issues have not been properly addressed.	O	O	Review	20523
I agree with the Reviewer #4 that the theoretical results are a bit artificial and trivial.	O	O	Review	20523
Thank you for reading our paper and providing feedback.	O	O	Reply	20523
<sep> <sep> - Different elements of our method have indeed been used before.	B-Reply	B-1	Reply	20523
However, to the best of our knowledge, they have not been used together in the way that we do.	I-Reply	I-1	Reply	20523
Moreover, the framework we use brings together these various ideas into a principled approach with a sound theoretical foundation.	I-Reply	I-1	Reply	20523
<sep> <sep> - The only limitation on M is that it is invertible; the rows don't have to be the same.	B-Reply	B-2	Reply	20523
Indeed, our proposed M has rows that are different; see Fig.4 in our paper.	I-Reply	I-2	Reply	20523
<sep> <sep> - If we learn M from data, we can impose various constraints to ensure that M is invertible (e.g., that M is diagonally dominant).	B-Reply	B-3	Reply	20523
We chose the specific form of the model for p(m,n,t) since it roughly corresponds to temporal mixing of the separate adjacency graphs and then applying a standard GCN to each of the new mixed adjacency graphs.	I-Reply	I-3	Reply	20523
We thought this simplicity was appealing as it makes the model more interpretable.	I-Reply	I-3	Reply	20523
<sep> <sep> - The paper [Li et al 2017] considers a setting in which both the nodes and edges remain fixed over time.	B-Reply	B-4	Reply	20523
In our paper, the edges change over time.	I-Reply	I-4	Reply	20523
So the method by [Li et al 2017] is not applicable, which is why we don't compare to it.	I-Reply	I-4	Reply	20523
<sep> <sep> - Intuitively, it seems natural that performance decreases as the adjacency matrices are symmetrized, since this destroys information about directionality on the graph.	B-Reply	B-5	Reply	20523
It could be that direction of a relationship is more important in the bitcoin datasets, which are more negatively impacted by symmetrization, than the Reddit and chess datasets.	I-Reply	I-5	Reply	20523
<sep> <sep> [Li et al 2017] Li, Y., Yu, R., Shahabi, C. and Liu, Y., 2017.	O	O	Reply	20523
Diffusion convolutional recurrent neural network: Data-driven traffic forecasting.	O	O	Reply	20523
arXiv preprint arXiv:1707.01926.	O	O	Reply	20523

Summary: this work uses tensor methods to improve graph convolution for dynamic graph, where the nodes are fixed and the edges are changing.	O	O	Review	20523
Specifically, it uses the M-product technique to develop the operations of sequence of matrices that analog to these operations of matrices.	O	O	Review	20523
In the M-product notations, everything seems to be as neat as matrix operations.	O	O	Review	20523
The works also shows decent supremacy on edge classification tasks.	O	O	Review	20523
<sep> <sep> <sep> Comments: this paper is mathematically interesting.	B-Review	B-1	Review	20523
It is well-written in general, but the definitions are dense and hard to follow.	I-Review	I-1	Review	20523
<sep> <sep> It will be better to give some examples of M-product.	B-Review	B-2	Review	20523
For example, what these operations will be if we choose M to be the identity matrix?	I-Review	I-2	Review	20523
<sep> <sep> M-transfer is a tensor contraction, right?	B-Review	B-3	Review	20523
<sep> <sep> It seems if you do the operations of the sequence of matrix, there is no need to do iterations like RNN.	B-Review	B-4	Review	20523
I am interested in how this will influence the runtime and memory cost.	I-Review	I-4	Review	20523
<sep> <sep> The M matrix is defined as a lower triangle matrix such as (A \times M)_::t depends on A^(1:t).	B-Review	B-5	Review	20523
Is it possible to formulate M such that (A \times M)_::t will depend heavily on A^(t), and less on the farther matices?	I-Review	I-5	Review	20523
such that we encode some Markov property?	I-Review	I-5	Review	20523
<sep> <sep> Does there exist some condition when this method will be equivalent to RNN?	B-Review	B-6	Review	20523
<sep> <sep> <sep> Decision: I feel this work novel and interesting in general.	O	O	Review	20523
I would like to weakly accept it.	O	O	Review	20523
<sep> <sep> Thank you for reading our paper and providing feedback.	O	O	Reply	20523
<sep> <sep> - Giving concrete examples of M is a good idea.	B-Reply	B-2	Reply	20523
We will include further examples of concrete choices of M (such as M = identity) and discuss what these mean.	I-Reply	I-2	Reply	20523
This discussion will be added to the appendix.	I-Reply	I-2	Reply	20523
<sep> <sep> - The M-transform wouldn't typically be called a tensor contraction since it does not completely collapse any dimensions or change the size of any dimension of the three-dimensional tensor (since M is square).	B-Reply	B-3	Reply	20523
The computation done in the M-transform is typically called a mode-3 tensor-times-matrix (TTM) product in the tensor literature.	I-Reply	I-3	Reply	20523
<sep> <sep> - Our hope is that our tensor approach will capture time dynamics and therefore eliminate the need for other time modeling like RNNs.	B-Reply	B-4	Reply	20523
However, you could also use elements (e.g. the M-transform) of our method as a preprocessing step before applying models incorporating RNN to it.	I-Reply	I-4	Reply	20523
This may increase performance, and is an area for future exploration.	I-Reply	I-4	Reply	20523
Depending on how M is chosen, the cost could potentially be reduced compared a model which incorporates an RNN.	I-Reply	I-4	Reply	20523
This all depends on how the different models are parameterized.	I-Reply	I-4	Reply	20523
<sep> <sep> - It is indeed possible to encode some notion of a Markov property by varying the bandwidth and weight of the matrix M. For example, the magnitude of the elements in each row of M could decrease exponentially as we move to the left of the main diagonal.	B-Reply	B-5	Reply	20523
This would, in a sense, encode that data further in the past is much less important than more current data.	I-Reply	I-5	Reply	20523
<sep> <sep> - This is a great question.	B-Reply	B-6	Reply	20523
It seems more likely that they are not equivalent, except for possibly in a very trivial case.	I-Reply	I-6	Reply	20523
However, there may be ways to adapt our method by adding more components that make them more similar and even equivalent.	I-Reply	I-6	Reply	20523
This is an interesting direction for future research.	I-Reply	I-6	Reply	20523

This paper introduces a deep reasoning networks for de-mixing overlapping patterns with some logic constraints.	O	O	Review	10141
There are two applications considered in the paper: de-mixing overlapping hand-written digits and inferring crystal structures of materials from X-ray diffraction data.	O	O	Review	10141
The experiments indicate the proposed method work pretty well on these tasks.	O	O	Review	10141
<sep> <sep> I like the general idea of this paper, since it has the flavor of combining deep learning with logic rules, although I feel weird to view the generative decoder as thinking fast and the reasoning modules as thinking slow.	B-Review	B-1	Review	10141
The notion of thinking fast and slow in the model does not well match the intuition given in the first paragraph of the introduction.	I-Review	I-1	Review	10141
The so-called reasoning module is essentially some contraints (i.e., regualrization losses) and a training data sampler.	I-Review	I-1	Review	10141
It is far away from the concept of (symbolic or logic) reasoning.	I-Review	I-1	Review	10141
There is not too much reasoning happening here.	I-Review	I-1	Review	10141
The way the paper relaxes the discrete logic constraints to continuous and differentiable objective that can be jointly optimized by SGD is interesting, which is similar to [Harnessing deep neural networks with logic rules, ACL 2016]. The carefully designed training data sampler that samples data according to a constraint graph also resembles GraphRNN, as the authors have mentioned in the paper.	I-Review	I-1	Review	10141
I feel the combination of these techniques is definitely interesting but also somehow incremental.	I-Review	I-1	Review	10141
I am not a big fan of some big claims in the paper.	I-Review	I-1	Review	10141
The reasoning modules are not what I expect.	I-Review	I-1	Review	10141
<sep> <sep> For the experiments, I think the authors do a good job presenting these experimental details and evaluations.	O	O	Review	10141
These experiments are interesting and also show some advantages of the propose method.	O	O	Review	10141
However, some baselines are also doing pretty well, indicating that the task is not difficult in general.	B-Review	B-2	Review	10141
Thank you for your review.	O	O	Reply	10141
Yes, we "stand on the shoulders of giants," but what makes our framework novel (not incremental) is the unique combination of ideas to deal with challenging unsupervised or weakly-supervised pattern de-mixing problems.	B-Reply	B-1	Reply	10141
<sep> <sep> "It is far away from the concept of (symbolic or logic) reasoning.	O	O	Reply	10141
‚Äù We disagree with this comment (see e.g, <a href="https://en.wikipedia.org/wiki/Reasoning_system)."	O	O	Reply	10141
target="_blank" rel="nofollow">https://en.wikipedia.org/wiki/Reasoning_system).</a> Reasoning system: given a set of axioms and rules, an inference procedure computes what follows.	B-Reply	B-1	Reply	10141
For example, in standard Sudoku, the inference procedure finds the values for missing cells.	I-Reply	I-1	Reply	10141
In logic, the axioms and rules can be written using propositional logic and the inference engine can be e.g., resolution or resolution and search, etc.	I-Reply	I-1	Reply	10141
Another example of a reasoning system is a constraint solver.	I-Reply	I-1	Reply	10141
In our case, we show how to encode the problem as a constraint optimization problem, encoding the Sudoku (and phase mapping ) rules using entropy-based functions and then use Lagrangian relaxation, and constraint-aware SGD to do the reasoning.	I-Reply	I-1	Reply	10141
In the appendix, we show that DRNets can solve standard Sudokus to further illustrate how DRNets can infer (‚Äúreason about‚Äù) the missing values.	I-Reply	I-1	Reply	10141
But DRNets also reason about Sudoku rules (and thermodynamic rules) to make sense of the noise input patterns.	I-Reply	I-1	Reply	10141
A typical logical reasoning system cannot reason about noisy data: in contrast, the strength of deep reasoning is to be able to make sense of noisy patterns.	I-Reply	I-1	Reply	10141
That is a key novelty of our approach ‚Äì we combine pattern recognition using deep learning with explicit constraint reasoning about rules, encoded through entropy-based functions and Lagrangian relaxation plus constraint-aware SGD.	I-Reply	I-1	Reply	10141
This combination of so many ideas makes our framework very powerful.	I-Reply	I-1	Reply	10141
<sep> <sep> "Harnessing deep neural networks with logic rules, ACL 2016" also utilizes logic rules to enhance deep learning.	O	O	Reply	10141
Good point.	O	O	Reply	10141
However, their framework is totally different from ours.	B-Reply	B-1	Reply	10141
We didn't compare with them because their framework is only applicable to **supervised** settings, where they have massive labeled data points as their main supervision, which diminishes the role of logic rules.	I-Reply	I-1	Reply	10141
In their experiments, the logic rules only increase their performance by less than 0.5%.	I-Reply	I-1	Reply	10141
Again, note that in contrast we are mainly interested in	I-Reply	I-1	Reply	10141
unsupervised/weakly-supervised settings for which we do not have labels for the mixtures, but we have only prototypes or idealized versions of what the digits or (phases) look like - for example, for the phase mapping not only do we only have unlabeled mixture data we also	I-Reply	I-1	Reply	10141
only have a few data points (&lt;500).	I-Reply	I-1	Reply	10141
The MNIST is not a good representative of these challenges since we can generate a large number of Sudokus (10,000).	I-Reply	I-1	Reply	10141
Also, in the MNIST we deal with 10 digits while in the phase mapping we can have possibly hundreds of pure phases (e.g., 159 for Al-Fe-Li).	I-Reply	I-1	Reply	10141
Furthermore, in the MNIST setting, we assume that there are always two overlapping digits: in the phase mapping, we do not know a priori how many phases are overlapped, which increases the combinatorial complexity of the problem and makes it even more important that the system could reason about the underlying thermodynamic rules.	I-Reply	I-1	Reply	10141
<sep> <sep> Thanks for appreciating our experiments.	O	O	Reply	10141
<sep> <sep> ‚ÄúHowever, some baselines are also doing pretty well, indicating that the task is not difficult in general‚Äù: The baselines actually perform poorly in both tasks: In Multi-MNIST-Sudoku, the baselines could only recover less than 70% overlapping Sudokus even with the supervision of labeled data points (which DRNets don‚Äôt have).	B-Reply	B-2	Reply	10141
In contrast, DRNets (with the supervision of the rules) recover 100% Sudoku puzzles without any labeled data.	I-Reply	I-2	Reply	10141
The difference in crystal-structure phase mapping is even more significant.	I-Reply	I-2	Reply	10141
For the Al-Fe-Li system, the phase diagram (Fig.7) recovered by baselines are far from the ground-truth while DRNets perfectly recovered it.	I-Reply	I-2	Reply	10141
For the Bi-Cu-V system, none of the baselines could generate a meaningful solution (the phases discovered by both IAFD and NMF-k are far from real phases (huge phase-fidelity loss); the solutions from both IAFD and NMF-k break the thermodynamic rules) and as far as we know DRNet is the first model that can solve this system.	I-Reply	I-2	Reply	10141
<sep> <sep> "I am not a big fan of some big claims in the paper."	B-Reply	B-1	Reply	10141
We understand your comment.	I-Reply	I-1	Reply	10141
But at the same time, there are advantages of seeing the "big picture".	I-Reply	I-1	Reply	10141
In fact, thinking of this framework as a general reasoning framework expanded our horizons and was very helpful for the students and senior researchers to have a broader perspective of its possibilities.	I-Reply	I-1	Reply	10141
For example, that led to the phase mapping application and we are now applying it to other problems in seemingly different domains such as species distributions for which there is prior knowledge about constraints on the species interactions and other settings.	I-Reply	I-1	Reply	10141
<sep> <sep> Thanks again, please let us know if you have additional questions.	O	O	Reply	10141

This work proposes a framework for solving de-mixing problems.	O	O	Review	10141
The hard constraints from human inputs about a specific problem are relaxed into continuous constraints (the "slow" reasoning part), and a reconstruction loss measures the fitness of the inferred labels with the observations (the "fast" pattern recognition part).	O	O	Review	10141
Due to the relaxation inference becomes an optimization problem, and on a Sudoku task and a crystal-structure-phase-mapping recovery task (both de-mixing tasks), the proposed method gets very good performance (100% for all Sudoku tasks including one in the appendix).	O	O	Review	10141
<sep> <sep> Pros:	O	O	Review	10141
1.	O	O	Review	10141
The method works well for the two demixing tasks.	O	O	Review	10141
<sep> 2.	O	O	Review	10141
It "led to the discovery of a new material that is important for solar fuels technology"	O	O	Review	10141
<sep> Cons:	O	O	Review	10141
1.	O	O	Review	10141
The generative decoder seems to be pretrained on both tasks instead of learned (correct me if I misunderstood), and I'm not sure if this approach can work in cases where we don't have access to such a generative decoder, so branding the approach "deep reasoning network" might be an overclaim.	B-Review	B-1	Review	10141
<sep> 2.	O	O	Review	10141
No reasonable baselines are used: The supervised baseline in Sudoku does not use those handcrafted constraints at all.	B-Review	B-2	Review	10141
Given pretrained decoders, a reasonable baseline would be randomized optimization methods such as simulated annealing, which might also solve the two tasks listed here.	I-Review	I-2	Review	10141
<sep> 3.	O	O	Review	10141
This paper proposes a deep reasoning framework with relaxation and continuous optimization, but it is unclear whether this can solve general reasoning problems such as multi-hop QA or some NP-hard integer programming problems.	B-Review	B-3	Review	10141
<sep> <sep> Questions:	O	O	Review	10141
1.	O	O	Review	10141
In algorithm 1, how are the penalty weights and thresholds adjusted?	B-Review	B-4	Review	10141
<sep> 2.	B-Review	B-5	Review	10141
How to determine whether a run needs to restart?	I-Review	I-5	Review	10141
<sep> <sep> Overall this work points an interesting direction of combining reasoning and pattern recognition in the same network and the proposal works well on two de-mixing problems.	B-Review	B-1	Review	10141
However, I am not convinced that the proposed solution can generalize to tasks other than the tasks proposed here, and the usage of pretrained generative decoders undermines the significance of this work.	I-Review	I-1	Review	10141
Therefore, I am inclined to reject this paper.	O	O	Review	10141
<sep> <sep> <sep> ---updates after reading authors' rebuttal----	O	O	Review	10141
Thanks for revising the paper and addressing my concerns!	O	O	Review	10141
However, my concern Con #2 has not been fully addressed.	B-Review	B-2	Review	10141
I think a reasonable baseline (at least for Sudoku) is simulated annealing, such as in <a href="https://www.researchgate.net/publication/220704743_Sudoku_Using_Parallel_Simulated_Annealing."	I-Review	I-2	Review	10141
target="_blank" rel="nofollow">https://www.researchgate.net/publication/220704743_Sudoku_Using_Parallel_Simulated_Annealing.</a> I believe that with restarts those baselines would also solve the Sudoku problem.	I-Review	I-2	Review	10141
<sep> <sep> Another concern I still have is the claim of "reasoning", and I'd suggest to narrow down the claim to be only on pattern de-mixing, since the reasoning part seems to be writing down continuous constraints from the discrete constraints (same as the concern in review #3).	B-Review	B-1	Review	10141
Although the proposed approach can solve some NP-C integer programming problems, it is unclear based on the experiments here whether it can work for general reasoning tasks (e.g., DROP <a href="https://allennlp.org/drop" target="_blank" rel="nofollow">https://allennlp.org/drop</a> or listops <a href="https://arxiv.org/pdf/1804.06028.pdf)" target="_blank" rel="nofollow">https://arxiv.org/pdf/1804.06028.pdf)</a> without writing new rules manually.	I-Review	I-1	Review	10141
<sep> <sep> Besides, after reading Reviewer 3's comments, I also feel it unsuitable to train DRNet (generalization) on test set for 25 epochs even though you made it explicit in the revised paper.	B-Review	B-6	Review	10141
I'd recommend removing that experiment since it doesn't change this work that much.	I-Review	I-6	Review	10141
<sep> <sep> ‚ÄúPros:	O	O	Reply	10141
1.	O	O	Reply	10141
The method works well for the two de-mixing tasks.	O	O	Reply	10141
<sep> 2.	O	O	Reply	10141
It "led to the discovery of a new material that is important for solar fuels technology"	O	O	Reply	10141
<sep> These are not small achievements :-)!	O	O	Reply	10141
<sep> Con#1: The generative decoders are either a pre-trained or a parametric model (GMM), which is learned/obtained using prior knowledge.	B-Reply	B-1	Reply	10141
For example, we assume that we have prototypes of single hand-written digits in Multi-MNIST-Sudoku and we have the ICDD database to provide pure phase patterns.	I-Reply	I-1	Reply	10141
Note  DRNets target unsupervised/weakly-supervised pattern de-mixing tasks, where we don‚Äôt have ground-truth labels for the de-mixed patterns.	I-Reply	I-1	Reply	10141
Therefore, without any prior knowledge of what single patterns may look like, the de-mixing tasks are ill-posed and intractable.	I-Reply	I-1	Reply	10141
Indeed, such prior knowledge is necessary even for human experts to solve those tasks.	I-Reply	I-1	Reply	10141
Thus, having access to the prior knowledge of possible single patterns, which can be used to build the generative decoder, is a very practical and reasonable assumption for unsupervised/weakly-supervised de-mixing tasks.	I-Reply	I-1	Reply	10141
<sep> <sep> Please see the explanation to reviewer#2 about DRNets‚Äô reasoning system.	I-Reply	I-1	Reply	10141
<sep> Con#2: The Multi-MNIST-Sudoku experiment is just a simplified example of the challenging task ‚Äî crystal-structure phase mapping.	B-Reply	B-2	Reply	10141
Our comparison is to show how we can boost pure deep learning models by incorporating prior knowledge such as rules and constraints.	I-Reply	I-2	Reply	10141
We compared our unsupervised methods with state-of-the-art supervised approaches.	I-Reply	I-2	Reply	10141
Thus, the baseline models have label supervision while DRNets ‚Äúreason‚Äù about rules.	I-Reply	I-2	Reply	10141
We thought that it was a fair comparison.	I-Reply	I-2	Reply	10141
Moreover,  we also tried your suggestion of using Sudoku rules for ResNet and CapsuleNet.	I-Reply	I-2	Reply	10141
Specifically, we did a local search for the top-2 most likely digits (one from 1-4 and another one from 5-8) for each Sudoku of the two overlapping Sudokus and try to satisfy Sudoku rules with minimal modification compared with the original prediction.	I-Reply	I-2	Reply	10141
The process took about 3 hours (we can't try top-3, it takes too long) for each model and increased their Sudoku accuracy from 68.5% -&gt; 88.3% (ResNet) and 50.9% -&gt; 57.8% (CapsuleNet).	I-Reply	I-2	Reply	10141
Though imposing Sudoku rules for these baselines could improve their performance, the barrier between the deep learning model and the post-process reasoning (local search) makes their performance far from DRNets' 100% accuracy.	I-Reply	I-2	Reply	10141
This further confirmed the advantage of combining deep learning and logical reasoning seamlessly and we are happy to include this in our paper.	I-Reply	I-2	Reply	10141
Thanks for the great suggestion.	I-Reply	I-2	Reply	10141
<sep> For crystal-structure phase mapping, we have compared our model with the state-of-the-art approaches in this area, i.e., NMF-k and IAFD, where IAFD has directly incorporated all constraints as we have and NMF-k incorporated those constraints indirectly.	I-Reply	I-2	Reply	10141
Therefore, these two models are the best baselines we can have so far.	I-Reply	I-2	Reply	10141
<sep> Q1: We initialize penalty weights and thresholds for penalty functions using hyper-parameters.	B-Reply	B-4	Reply	10141
During training, we check the satisfiability of constraints after several epochs and increase the penalty for violated constraints.	I-Reply	I-4	Reply	10141
This mechanism is mainly designed for Crystal-Structure Phase Mapping because DRNets can already achieve perfect performance for Multi-MNIST-Sudoku with fixed weights.	I-Reply	I-4	Reply	10141
For example, the threshold c of k-sparsity is initialized as logk, which is the entropy of the case that the probability mass is evenly distributed among k entities.	I-Reply	I-4	Reply	10141
Thus, it could be the case that there are more than k entities, but their probability mass is not evenly distributed.	I-Reply	I-4	Reply	10141
Hence, we check the satisfiability of k-sparsity constraint: if the entropy is already below the current threshold (logk) and there are still more than k entities with probability mass more than epsilon (0.01), we decrease the threshold c to keep enforcing the model to minimize the entropy to reach the k-sparsity.	I-Reply	I-4	Reply	10141
<sep> Q2:	O	O	Reply	10141
Since DRNets directly incorporate logical constraints, we can check whether those constraints are satisfied at the end of a run.	B-Reply	B-5	Reply	10141
For the instances violating constraints, we re-run the algorithm again.	I-Reply	I-5	Reply	10141
<sep> <sep> Con#3 and ‚ÄúI am not convinced that the proposed solution can generalize to tasks other than the tasks proposed here‚Äù:	I-Reply	I-5	Reply	10141
Indeed, the DRNet framework is general and we do have some results for pure NP-C problems such as original Sudoku (9x9)  and 3-SAT problems.	I-Reply	I-5	Reply	10141
Please check the appendix, where we show that DRNets outperform existing state-of-the-art deep learning methods for those pure NP-C problems.	I-Reply	I-5	Reply	10141
For example, DRNets solve 3-SAT, 100 literals and 430 clauses, which is above the capability of existing deep learning methods.	I-Reply	I-5	Reply	10141
Note, however,  DRNets are mainly meant for problems that require combining the pattern recognition and logical reasoning instead of pure reasoning problems.	I-Reply	I-5	Reply	10141
<sep> <sep> DRNets are relevant to other scientific tasks and even other domains.	I-Reply	I-5	Reply	10141
Also, as you recognize, our results are very good for these tasks, leading even to new discoveries.	I-Reply	I-5	Reply	10141
We hope you re-consider our score.	O	O	Reply	10141
Thanks!	O	O	Reply	10141

This paper proposes a new encoder-decoder framework that combines prior knowledge-based regularization and constrained reconstruction for unsupervised and weakly-supervised classification in structure rich scenarios.	O	O	Review	10141
This framework injects prior knowledge in the form of relaxed constraints that act as regularization during the training of the encoder network.	O	O	Review	10141
Some of the constraints concern sets of training examples.	O	O	Review	10141
In this case, the paper proposes corresponding sampling schemes.	O	O	Review	10141
Three experiments demonstrate the efficacy of the model.	O	O	Review	10141
The first is a synthetically created 4x4 Sudoku made of overlaid MNIST digits.	O	O	Review	10141
The other two are based on predicting crystal structures from x-ray diffraction measurements.	O	O	Review	10141
Here, the first experiment is on simulated data for the Al-Li-Fe oxide system, while the other is performed on real measurements for the Bi-Cu-V oxide system.	O	O	Review	10141
<sep> <sep> Overall, I believe that the proposed framework could be a significant contribution to the fields of representation learning and constrained optimization.	O	O	Review	10141
However, the paper exhibits serious shortcomings, which require revision.	O	O	Review	10141
<sep> <sep> First, the positive aspects of the paper:	O	O	Review	10141
‚Ä¢<tab>The framework is simple yet ingenious.	O	O	Review	10141
It makes intelligent use of constraints in the form of regularization to guide the training of the encoder.	O	O	Review	10141
Furthermore, it enables the direct design of the latent representation through the use of (pre-trained) generative models for constrained reconstruction of data points.	O	O	Review	10141
<sep> ‚Ä¢<tab>The proposed entropy-based method for relaxation of discrete constraints is intuitive and potentially adaptable for further constraints.	O	O	Review	10141
<sep> ‚Ä¢<tab>The experiments presented in this paper are well chosen.	O	O	Review	10141
They demonstrate the contribution of the model to both general CV data as well as a specialized domain, where it can solve both simulated and real scenarios.	O	O	Review	10141
<sep> ‚Ä¢<tab>The paper provides an extensive literature survey, which makes it easy to embed the presented work in the proper context.	O	O	Review	10141
However, I propose to remove the paragraph titled ‚ÄúOther less closely related work‚Äù as the connection to the current work is not clear, and the space could be used more effectively (see below).	O	O	Review	10141
<sep> <sep> Unfortunately, this paper has a couple of major flaws:	O	O	Review	10141
‚Ä¢<tab>The results for DRNets (Generalization) on the MNIST Sudoku are compromised because the model trained on the test set for 25 epochs after being trained on the training set.	B-Review	B-1	Review	10141
Honestly, I was baffled to read the following sentence in the appendix: ‚ÄúNote that, during the test, instead of predicting the overlapping digits directly as other networks, we further optimize DRNets on the test set for 25 epochs to achieve a better result.	I-Review	I-1	Review	10141
‚Äù What is more, the main paper does not even mention this fact!	I-Review	I-1	Review	10141
<sep> ‚Ä¢<tab>Although this paper relies on empirical verification of its proposition, the experimental results are almost impossible to interpret with just the information provided in the paper.	B-Review	B-2	Review	10141
Both experiments are poorly described, and even after reading the appendix several times, some serious detective work was necessary to piece together what happened in the experiments.	I-Review	I-2	Review	10141
The XRD experiments are especially hard to decipher, even with a physics background.	I-Review	I-2	Review	10141
Many vital components remain shrouded in mystery: What is a composition graph, and how are the paths sampled from it?	I-Review	I-2	Review	10141
How does the restart method, which is part of the results, work?	I-Review	I-2	Review	10141
Why are only six phases shown in the phase concentration visualizations if there were 159 possible phases?	I-Review	I-2	Review	10141
Are these the first six, a random subset, or were the other phases not realized?	I-Review	I-2	Review	10141
<sep> ‚Ä¢<tab>The paper introduces the constraint-aware SGD algorithm to incorporate batching rules into the training of the encoder.	B-Review	B-3	Review	10141
On pages 2 and 6 and in Algorithm 1, I found the statement that the weights for each constrained are updated dynamically.	I-Review	I-3	Review	10141
However, that is where the information on the dynamic update method ends.	I-Review	I-3	Review	10141
Nowhere in the paper or the appendix did I find an explanation of how this is done.	I-Review	I-3	Review	10141
As this mechanism is a critical component of the proposed framework, the absence of an explanation is a significant oversight.	I-Review	I-3	Review	10141
<sep> Other remarks:	O	O	Review	10141
‚Ä¢<tab>In the context of global constraints, the paper talks about a constraint graph.	B-Review	B-4	Review	10141
If I understand the creation of this graph correctly, this graph has several connected components in which every element connects to every other element.	I-Review	I-4	Review	10141
As such, this seems to be a collection of sets rather than a real graph.	I-Review	I-4	Review	10141
This is especially confusing in the case of XRD, where all data points are in the same global constraint, leading to a fully connected ‚Äúgraph‚Äù.	I-Review	I-4	Review	10141
<sep> ‚Ä¢<tab>Although I appreciate the reference to Kahneman‚Äôs model of the mind, I suggest to remove the first two paragraphs from the introduction and use the space to motivate the de-mixing problem instead.	B-Review	B-5	Review	10141
While it is a compelling (but not novel) observation, the analogy to system 1 and system 2 does not benefit the proposed work in the slightest.	I-Review	I-5	Review	10141
<sep> ‚Ä¢<tab>In general, I fail to see the connection between reasoning and the proposed work.	B-Review	B-6	Review	10141
The model itself is an encoder-decoder network that cannot reason.	I-Review	I-6	Review	10141
It does not discover any new rules during training.	I-Review	I-6	Review	10141
All the reasoning has to be done manually beforehand to be then incorporated in the form of constraints.	I-Review	I-6	Review	10141
To clarify, I do believe that there is value in the presented work, but not necessarily in the way, it is advertised.	I-Review	I-6	Review	10141
<sep> <sep> Thank you so much for appreciating our work!	O	O	Reply	10141
<sep> <sep> Indeed, we also included the performance of DRNets on some pure NP-C problems including original Sudoku problems and 3-SAT problems.	B-Reply	B-1	Reply	10141
You can check them in the last two pages of the appendix.	I-Reply	I-1	Reply	10141
<sep> <sep> Thank you for pointing out the "redundant" part of the related work.	B-Reply	B-5	Reply	10141
We will consider erasing that paragraph to save space for other content.	I-Reply	I-5	Reply	10141
<sep> <sep> 1.	B-Reply	B-1	Reply	10141
Thank you for pointing out the confusion of the "generalization mode" of DRNets.	I-Reply	I-1	Reply	10141
In fact, DRNets mainly target on "solving" unsupervised pattern de-mixing tasks, instead of generalization.	I-Reply	I-1	Reply	10141
Because in real tasks, such as crystal-structure phase mapping, we only have hundreds of data points, which is not enough to do any generalization.	I-Reply	I-1	Reply	10141
<sep> However, in Multi-MNIST-Sudoku, we found that by solving enough instances together, the network naturally could generalize to unseen instances.	I-Reply	I-1	Reply	10141
This phenomenon resembles a "self-learning" process, where we can actually learn a model without labels if we have enough unlabeled data points.	I-Reply	I-1	Reply	10141
Therefore, we think it is interesting to show this phenomenon in our paper.	I-Reply	I-1	Reply	10141
However, limited by space, we are sorry that we didn't address this properly.	I-Reply	I-1	Reply	10141
We do extra 25-optimization steps for improving the generalization performance on unseen instances, which increases the one-shot Sudoku accuracy from 50.5% to 75.7%.	I-Reply	I-1	Reply	10141
We use the validation set for determining the best # of extra optimizations.	I-Reply	I-1	Reply	10141
We will clarify this in the paper.	I-Reply	I-1	Reply	10141
<sep> <sep> 2.	O	O	Reply	10141
We do appreciate that you read our paper thoroughly.	B-Reply	B-2	Reply	10141
To be honest, the crystal-structure phase mapping is a real-world task, which includes a lot of domain knowledge and details.	I-Reply	I-2	Reply	10141
Therefore, we proposed this Multi-MNIST-Sudoku task as a glimpse of the crystal-structure phase mapping.	I-Reply	I-2	Reply	10141
We are sorry for the confusing terminology in our description and we will include more details of this experiment to make it reproducible for other readers.	I-Reply	I-2	Reply	10141
In fact, we have organized our code as well as the dataset into a runnable package, and we will release it with a document for people to fully understand our code.	I-Reply	I-2	Reply	10141
<sep> <sep> For your specific questions:	O	O	Reply	10141
(1) composition graph: Each XRD data point is associated with a 3-dimensional vector, denoting the percentage of 3 elements at that point (e.g., [a% of Li, b% of Fe, c% of Al]).	B-Reply	B-2	Reply	10141
Then you can locate each data point into the triangular system (note that, the vector is a probability distribution so that there are only 2 degrees of freedom and it can be plotted in a 2-D triangle.)	I-Reply	I-2	Reply	10141
Visually, we will have a composition graph like the triangle plot in Fig.10 (appendix).	I-Reply	I-2	Reply	10141
After locating each data point into the 2-D triangle as vertices, we did a Delaunay triangulation over those points to build edges among vertices.	I-Reply	I-2	Reply	10141
Finally, we did a Breadth-First Search on this graph to sample paths.	I-Reply	I-2	Reply	10141
<sep> <sep> (2) restart mechanism for Multi-MNIST: Since DRNets directly incorporate logical constraints, we can check whether those constraints are satisfied at the end of a run.	B-Reply	B-2	Reply	10141
If not, for instances with violated constraints, we re-run the algorithm again on them.	I-Reply	I-2	Reply	10141
We didn‚Äôt restart for crystal-structure phase mapping.	I-Reply	I-2	Reply	10141
<sep> <sep> (3) 6 phases out of 159 possible phases: Though there are 159 possible pure phases for the Al-Fe-Li-O system, only 6 of them appear and there are 15 mixtures of those 6 pure phases exist in this system.	B-Reply	B-2	Reply	10141
For the Bi-Cu-V-O system, there are 13 pure phases and 19 different mixtures.	I-Reply	I-2	Reply	10141
Note that, each XRD data point is like a cell in the Multi-MNIST-Sudoku (with mixed pure phases) and each pure phase is like a digit.	I-Reply	I-2	Reply	10141
For Multi-MNIST-Sudoku, we know a priori that there are exact 2 digits in each cell but the number of mixed pure phases in each XRD is from 1 to 3.	I-Reply	I-2	Reply	10141
Moreover, the number of possible candidate phases is way more than possible digits (e.g., 159 vs 10), which is the reason why this task is so challenging.	I-Reply	I-2	Reply	10141
We will make this point more clear in our final version.	I-Reply	I-2	Reply	10141
<sep> <sep> 3.	O	O	Reply	10141
Dynamic update of penalty weights: please check similar response to reviewer #1(Q1)	B-Reply	B-3	Reply	10141
<sep> 4.	O	O	Reply	10141
The constraint graph shows how data points are linked through different constraints.	B-Reply	B-4	Reply	10141
Yes, you can think of it as a collection of sets when we can batch each maximal connected component together.	I-Reply	I-4	Reply	10141
When it comes to the case of XRD, the graph is fully-connected due to global constraints.	I-Reply	I-4	Reply	10141
Therefore, we no longer batch the maximal connected component together but sample a path in this graph to reason about a local structure of those global constraints.	I-Reply	I-4	Reply	10141
Though the constraint graph is a fully-connected graph, we prefer to sample paths in the composition graph, given it is easier to reason about those thermodynamic rules on a path of composition graph.	I-Reply	I-4	Reply	10141
<sep> <sep> 5.	B-Reply	B-6	Reply	10141
The reasoning does happen in DRNets: See comments to reviewer #2	I-Reply	I-6	Reply	10141
<sep> Thanks again!	O	O	Reply	10141
We believe this framework is indeed quite ‚Äúingenious :-)!‚Äù expandable for other constraints and domains, very relevant for scientific unsupervised tasks with rich prior-knowledge.	O	O	Reply	10141
We will improve the description of our problem domains and we hope you champion this paper!	O	O	Reply	10141

The paper introduces a new method for training GANs with discrete data.	O	O	Review	501
To this end, the output of the discriminator is interpreted as importance weight and REINFORCE-like updates are used to train the generator.	O	O	Review	501
Despite making interesting connections between different ideas in GAN training, I found the paper to be disorganized and hard to read.	O	O	Review	501
My main concern is the fact that the paper does not make any comparison with other methods for handling of discrete data in GANs.	O	O	Review	501
In particular, (Gulrajani et al‚Äô17) show that it is possible to train Wasserstein GANs without sampling one-hot vectors for discrete variables during the training.	O	O	Review	501
Is there a reason to use REINFORCE-like updates when such a direct approach works?	O	O	Review	501
Minor:	O	O	Review	501
complex conjugate => convex conjugate	O	O	Review	501
We would like to kindly remind the reviewer of our revision.	O	O	Reply	501
The complete revision list is provided in the main thread (titled, "Revision available").	O	O	Reply	501

Thanks for the feedback and for clarifying the 1) algorithm and the assumptions in the multivariate case 2) comparison to RL based methods 3) connection to estimating importance sampling weights using GAN discriminator.	O	O	Review	501
I think the paper contribution is now more clear and strengthened with additional convincing experiments and I am increasing my score to 7.	O	O	Review	501
The paper would still benefit from doing the experiment with importance weights by pixel , rather then a global one as done in the paper now.	O	O	Review	501
I encourage the authors to still do the experiment, see if there is any benefit.	O	O	Review	501
==== Original Review =====	O	O	Review	501
Summary of the paper:	O	O	Review	501
The paper presents a method based on importance sampling and reinforcement learning to learn discrete generators in the GAN framework.	O	O	Review	501
The GAN uses an  f-divergence cost function for  training the discriminator.	O	O	Review	501
The generator is trained to minimize the KL distance between the  discrete generator q_{\theta}(x|z), and the importance weight discrete real distribution estimator w(x|z)q(\theta|z).	O	O	Review	501
where w(x|z) is estimated in turn using the discriminator.	O	O	Review	501
The methodology is also extended to the continuous case.	O	O	Review	501
Experiments are conducted on quantized image generation, and text generation.	O	O	Review	501
Quality:	O	O	Review	501
the paper is overall well written and supported with reasonable experiments.	O	O	Review	501
Clarity:	O	O	Review	501
The paper has a lot of typos that make sometimes the paper harder to follow:	O	O	Review	501
- page (2) Eq 3 max , min should be min, max if we want to keep working with f-divergence	O	O	Review	501
- Definition 2.1 \mathbb{Q}_{\theta} --> \mathbb{Q}	O	O	Review	501
- page 5 the definition of \tilde{w}(x^{(m})) in the normalization it is missing \tilde{w}	O	O	Review	501
- Equation (10) \nabla_{\theta}\log(x|z) --> \nabla_{\theta}\log(x^{(m)}|z)	O	O	Review	501
- In algorithm 1, again missing indices in the update of theta  --> \nabla_{\theta}\log(x^{(m|n)}|z^{n})	O	O	Review	501
Originality:	O	O	Review	501
The main ingredients of the paper are well known and already used in the literature (Reinforce for discrete GAN with Disc as a reward for e.g GAN for image captioning Dai et al).	O	O	Review	501
The perspective from importance sampling coming from f-divergence for discrete GAN has some novelty although the foundations of this work relate also to previous work:	O	O	Review	501
- Estimating ratios using the discriminator is well known for e.g learning implicit models , Mohamed et al	O	O	Review	501
- The relation of  importance sampling to  reinforce is also well known" On a Connection between Importance Sampling and the Likelihood Ratio Policy Gradient," Tang and Abbeel.	O	O	Review	501
General Review:	O	O	Review	501
- when the generator is producing only *one* discrete distribution the theory is presented in Section 2.3.	O	O	Review	501
When we move to experiments, for image generation for example, we need to have a generator that produces a distribution by pixel.	O	O	Review	501
It would be important for 1) understanding the work 2) the reproducibility of the work to parallel algorithm 1 and have it *in the paper*, for this 'multi discrete distribution ' generation case.	O	O	Review	501
If we have N pixels    \log(p(x_1,...x_N|z))= \Pi_i g_{\theta}(x_i|z) (this should be mentioned in the paper if it is the case ), it would be instructive to comment on the assumptions on independence/conditional dependence of this model, also to state clearly how the generator is updated in this case and what are importance sampling weights.	O	O	Review	501
- Would it make sense in this N pixel discrete case generation to have also the discriminator produce N probabilities of real and fake as in PixelGAN in Isola et al?	O	O	Review	501
then see in this case what are the importance sampling weights this would parallel the instantaneous reward in RL?	O	O	Review	501
We would like to kindly remind the reviewer of our revision.	O	O	Reply	501
The complete revision list is provided in the main thread (titled, "Revision available").	O	O	Reply	501

Thank you for the feedback, and I have read the revision.	O	O	Review	501
<sep> <sep> I would say the revised version has more convincing experimental results (although I'm not sure about the NLP part).	O	O	Review	501
The authors have also addressed my concerns on variance reduction, although it's still mysterious to me that the density ratio estimation method seems to work very well even at the begining stage.	O	O	Review	501
<sep> <sep> Also developing GAN approaches for discrete variables is an important and unsolved problem.	O	O	Review	501
<sep> <sep> Considering all of the above, I would like to raise the rating to 7, but lower my confidence to 3 (as I'm not an expert for NLP which is the main task for discrete generative models).	O	O	Review	501
<sep> <sep> ==== original review ====	O	O	Review	501
<sep> Thank you for an interesting read.	O	O	Review	501
<sep> <sep> My understanding of the paper is that:	O	O	Review	501
<sep> 1.	O	O	Review	501
the paper proposes a density-ratio estimator via the f-gan approach;	O	O	Review	501
2.	O	O	Review	501
the paper proposes a training criterion that matches the generator's distribution to a self-normalised importance sampling (SIS) estimation of the data distribution;	O	O	Review	501
3.	O	O	Review	501
in order to reduce the variance of the REINFORCE gradient, the paper seeks out to do matching between conditionals instead.	O	O	Review	501
<sep> <sep> There are a few things that I expect to see explanations, which are not included in the current version:	O	O	Review	501
<sep> 1.	B-Review	B-1	Review	501
Can you justify your variance reduction technique either empirically or experimentally?	I-Review	I-1	Review	501
Because your method requires sampling multiple x for a single given z, then in the same wall-clock time I should be able to obtain more samples for the vanilla version eq (8).	I-Review	I-1	Review	501
How do they compare?	I-Review	I-1	Review	501
<sep> <sep> 2.	O	O	Review	501
Why your density ratio estimation methods work in high dimensions, even when at the beginning p and q are so different?	B-Review	B-2	Review	501
<sep> <sep> 3.	O	O	Review	501
It's better to include some quantitative metrics for the image and NLP experiments rather than just showing the readers images and sentences!	B-Review	B-3	Review	501
<sep> <sep> 4.	O	O	Review	501
Over-optimising generators is like solving a max-min problem instead.	B-Review	B-4	Review	501
You showed your method is more robust in this case, can you explain it from the objective you use, e.g. the convex/concavity of your approach in general?	I-Review	I-4	Review	501
<sep> <sep> Typo: eq (3) should be min max I believe?	B-Review	B-5	Review	501
<sep> <sep> BTW I'm not an expert of NLP so I won't say anything about the quality of the NLP experiment.	O	O	Review	501
Following your concerns, we have added a section to the Appendix that introduces an experiment comparing the estimated GAN-distance during training across models trained by the variance-reducing method (eq 10) and models trained by estimating beta (eqs 7, 8) using Monte Carlo.	B-Reply	B-1	Reply	501
From these experiments, we are able to make the following conclusions: a) more samples from the conditional in training achieves lower GAN-divergence (2 JSD - 2log4) and b) eq 10 consistently achieves lower GAN-divergence than using MC estimate of beta from eq 8.	I-Reply	I-1	Reply	501
Next, we added your insight regarding the convex/concavity of using the square error loss in the continuous case (see next to last paragraph, page 6, starting with ‚ÄúThis objective can be seen‚Äù).	I-Reply	I-1	Reply	501
<sep> <sep> Next, rather than using Inception score, which has not been used for quantitative experiments with discrete data, we trained new discriminators with higher capacities to estimate the Wasserstein distance or f-divergences between the MNIST training set and the discrete generated samples (keeping the generators fixed).	B-Reply	B-2	Reply	501
Our results show that BGAN outperforms WGAN-GP consistently across *all metrics*, including the Wasserstein distance.	I-Reply	I-2	Reply	501
Though we cannot say with absolutely certainty, it is very likely that this is because, while WGAN-GP is able to generate samples that visually resemble the target dataset, using the softmax outputs hurts the generator‚Äôs ability to model a truly discrete distribution.	I-Reply	I-2	Reply	501
Please refer to the Appendix, section 7.1 for details.	I-Reply	I-2	Reply	501
<sep> <sep> We attempted some experiments to illuminate why BGAN works using importance sampling, especially at the beginning of training when we know the distribution overlap will be small.	B-Reply	B-3	Reply	501
However, at this time, we do not have any results that would paint a particularly clear picture to the reader.	I-Reply	I-3	Reply	501
For instance, when looking at the effective sample size over the first epoch, we found this quantity fluctuates rapidly at the beginning of training, until converging to a reasonable value (about 90%).	I-Reply	I-3	Reply	501
We expect that the effective sample size might be highly variable in the beginning of training as the unnormalized weights as very low, but not uniform.	I-Reply	I-3	Reply	501
However, this is still speculation, and we believe that more time and care is needed to make any conclusions in the text.	I-Reply	I-3	Reply	501

This paper proposes a clever and sensible approach to using the structure learned by the auxiliary variational method to accelerate random-walk MCMC.	O	O	Review	501
The idea is to learn a low-dimensional latent space that explains much of the variation in the original parameter space, then do random-walk sampling in that space (while also updating a state variable in the original state, which is necessary to ensure correctness).	O	O	Review	501
<sep> <sep> I like this idea and think the paper merits acceptance, although there are some important unanswered questions.	O	O	Review	501
For example:	O	O	Review	501
- How does the method work on higher-dimensional target distributions?	B-Review	B-1	Review	501
I would think it would be hard for a low-dimensional auxiliary space to have high mutual information with a much higher-dimensional space.	I-Review	I-1	Review	501
In principle neural networks can do all sorts of crazy things, but phenomena like VAEs with low-dimensional latent spaces generating blurry samples make me suspect that auxiliary dimension should be important.	I-Review	I-1	Review	501
<sep> - How does the method work with hierarchical models, heavy-tailed models, etc.?	B-Review	B-2	Review	501
Rings, MoGs, and flat logistic regressions are already pretty easy targets.	I-Review	I-2	Review	501
<sep> - Is it really so valuable to not need gradients?	B-Review	B-3	Review	501
High-quality automatic differentiation systems are widely available, and variational inference on discrete parameters with neural nets remains a pretty hard problem in general.	I-Review	I-3	Review	501
<sep> <sep> Some other comments:	O	O	Review	501
<sep> * It‚Äôs probably worth citing Ranganath et al (2015; ‚ÄúHierarchical Variational Models‚Äù), who combine the auxiliary variational method with modern stochastic VI.	B-Review	B-4	Review	501
Also, I wonder if there are connections to approximate Bayesian computation (ABC).	I-Review	I-4	Review	501
<sep> <sep> * I think you could prove the validity of the procedure in section 2.1 more succinctly by interpreting it as alternating a Gibbs sampling update for ‚Äúa‚Äù with a Metropolis-Hastings update for ‚Äúx‚Äù.	B-Review	B-4	Review	501
If we treat ‚Äúa‚Äù as an auxiliary variable such that	I-Review	I-4	Review	501
p(a | x) = \tilde q(a | x)	I-Review	I-4	Review	501
p(x | a) \propto p(x) \tilde q(a | x)	I-Review	I-4	Review	501
then the equation (2) is the correct M-H acceptance probability for the proposal	I-Review	I-4	Review	501
\tilde q(a‚Äô, x‚Äô) = Œ¥(a‚Äô-a) \tilde q(x‚Äô | a).	I-Review	I-4	Review	501
<sep> Alternating between this proposal and a Gibbs update for ‚Äúa‚Äù yields the mixture proposal in section 2.1.	I-Review	I-4	Review	501
<sep> <sep> * It‚Äôs also possibly worth noting that this procedure will have a strictly lower acceptance rate than the ideal procedure of using the marginal	B-Review	B-4	Review	501
\tilde q(x‚Äô|x)	I-Review	I-4	Review	501
as a M-H proposal directly.	I-Review	I-4	Review	501
Unfortunately that marginal density usually can‚Äôt be computed, which makes this ideal procedure impractical.	I-Review	I-4	Review	501
It might be interesting to try to say something about how large this gap is for the proposed method.	I-Review	I-4	Review	501
<sep> <sep> * "We choose not to investigate burn-in since AVS is initialized by the variational distribution and therefore has negligible if any burn-in time.	B-Review	B-4	Review	501
‚Äù This claim seems unjustified to me.	I-Review	I-4	Review	501
It‚Äôs only true insofar as the variational distribution is an excellent approximation to the posterior (in which case why use MCMC at all?).	I-Review	I-4	Review	501
It‚Äôs easy to find examples where an MCMC chain initialized with a sample from a variational distribution takes quite a while to burn in.	I-Review	I-4	Review	501
Thank you for your review and well considered comments.	O	O	Reply	501
<sep> <sep> > Review: This paper proposes a clever and sensible approach to using the structure learned by the auxiliary variational method to accelerate random-walk MCMC.	O	O	Reply	501
The idea is to learn a low-dimensional latent space that explains much of the variation in the original parameter space, then do random-walk sampling in that space (while also updating a state variable in the original state, which is necessary to ensure correctness).	O	O	Reply	501
<sep> <sep> > I like this idea and think the paper merits acceptance, although there are some important unanswered questions.	O	O	Reply	501
For example:	O	O	Reply	501
<sep> <sep> > How does the method work on higher-dimensional target distributions?	O	O	Reply	501
I would think it would be hard for a low-dimensional auxiliary space to have high mutual information with a much higher-dimensional space.	O	O	Reply	501
In principle neural networks can do all sorts of crazy things, but phenomena like VAEs with low-dimensional latent spaces generating blurry samples make me suspect that auxiliary dimension should be important.	O	O	Reply	501
<sep> <sep> This is an interesting question and one we think it is hard to give a definitive answer to.	B-Reply	B-1	Reply	501
The degree to which we can benefit from learning low dimensional structure will depend significantly on the choice of target distribution.	I-Reply	I-1	Reply	501
It is easy to construct very high dimensional distributions with low dimensional parametrisations and in these cases it is likely the method will work well but it's unclear how many of the posteriors typically encountered in real world Bayesian inference actually have this structure.	I-Reply	I-1	Reply	501
In practice, we have found the method to perform reasonably well on problems up till 10's of dimensions, which would cover quite a wide range of statistical applications.	I-Reply	I-1	Reply	501
However, we were not able to get our method (or any of the other neural adaptive samplers tested) to sample reliably from the posterior of a relatively small neural network.	I-Reply	I-1	Reply	501
<sep> <sep> We would argue that the blurry images often produced by VAEs are more to do with the training objective than the ability of neural nets to discover low-dimensional structure.	I-Reply	I-1	Reply	501
This is evidenced by the fact that otherwise identical models, when trained with an adversarial objective are able to produce very sharp images.	I-Reply	I-1	Reply	501
<sep> <sep> >  How does the method work with hierarchical models, heavy-tailed models, etc.?	O	O	Reply	501
Rings, MoGs, and flat logistic regressions are already pretty easy targets.	O	O	Reply	501
<sep> <sep> This is a fair point and we will try to add one or two more experiments and update the paper.	B-Reply	B-2	Reply	501
<sep> <sep> > Is it really so valuable to not need gradients?	O	O	Reply	501
High-quality automatic differentiation systems are widely available, and variational inference on discrete parameters with neural nets remains a pretty hard problem in general.	O	O	Reply	501
<sep> <sep> We take your point but would still argue that the ability to avoid gradient computations could be of benefit, especially in the large data regime.	B-Reply	B-3	Reply	501
<sep> <sep> Though automatic differentiation eases the implementation burden, it doesn't do away with the computational difficulty of calculating gradients which for most Bayesian inference will scale linearly in the size of the data-set and for exact HMC will need to be calculated multiple times per iteration (sometimes even hundreds oft times).	I-Reply	I-3	Reply	501
It's exactly for this reason that methods such as Stochastic Gradient HMC have been introduced but these methods are derived for continuous time and are not exact in practice.	I-Reply	I-3	Reply	501
<sep> <sep> Furthermore, whilst it's true that discrete neural variational inference (NVI) remains challenging it is an area of very active ongoing research and this method opens up the possibility to translate progress in NVI immediately to MCMC.	I-Reply	I-3	Reply	501
<sep> <sep> > Some other comments:	O	O	Reply	501
<sep> >* It‚Äôs probably worth citing Ranganath et al (2015; ‚ÄúHierarchical Variational Models‚Äù), who combine the auxiliary variational method with modern stochastic VI.	O	O	Reply	501
Also, I wonder if there are connections to approximate Bayesian computation (ABC).	O	O	Reply	501
<sep> <sep> Thanks for this pointer, we were not aware of this paper and it does indeed use many of the same ingredients.	O	O	Reply	501
We will add this reference.	O	O	Reply	501

In my opinion, the paper contains very interesting novel ideas.	B-Review	B-1	Review	501
<sep> However, some parts needs a future clarification and the state-of-the-art must be improved.	I-Review	I-1	Review	501
<sep> <sep> - First of all,  Sections 2.3.1 or 2.3.2 can be improved and clarified.	I-Review	I-1	Review	501
For instance, I believe you can create a unique section with title " Choice of Proposal density " and then schematically describe each proposal from the simplest to the more sophisticated one.	I-Review	I-1	Review	501
<sep> <sep> - At the beginning of Section 2, please devote more sentence to explain why extending the space and apply the variational inference is good for finding a suitable good proposal density.	B-Review	B-2	Review	501
<sep> <sep> - Related  to Section 2 ( theMixture Proposal MCMC contribution), the authors should discuss (in the introduction and also in the related works section) the Multiple Try Metropolis schemes with correlated candidates where, for instance, a path of candidates is generated and one of them is selected and tested with MH-type acceptance probability, in a proper way.	B-Review	B-3	Review	501
This is more general that your scheme but very related.	I-Review	I-3	Review	501
Please see	I-Review	I-3	Review	501
<sep> Qin, Z.S., Liu, J.S., 2001.	I-Review	I-3	Review	501
Multi-point Metropolis method with application to hybrid Monte Carlo.	I-Review	I-3	Review	501
Journal of Computational Physics 172, 827‚Äì840.	I-Review	I-3	Review	501
<sep> <sep> L. Martino, V. P. Del Olmo, J. Read, "A multi-point Metropolis scheme with generic weight functions", Statistics and Probability Letters, Volume 82, Issue 7, Pages: 1445-1453, 2012.	I-Review	I-3	Review	501
<sep> <sep> L. Martino, "A Review of Multiple Try MCMC algorithms for Signal Processing", Digital Signal Processing, Volume 75, Pages: 134-152, 2018.	I-Review	I-3	Review	501
<sep> <sep> - Related again with the state-of-the-art description, the references regarding  Adaptive Mixture Metropolis methods are completely missed.	B-Review	B-4	Review	501
If I have properly understood, you also adapt a mixture via variational inference.	I-Review	I-4	Review	501
Please, in Section 4, consider the different works that considers an adapting mixture proposal for a  Metropolis-type algorithm,	I-Review	I-4	Review	501
<sep> P. Giordani and R. Kohn, ‚ÄúAdaptive independent Metropolis-Hastings by fast estimation of mixtures of normals,‚Äù Journal of Computational and Graphical Statistics, vol.19, no.	O	O	Review	501
2, pp.243‚Äì259, September 2010.	O	O	Review	501
<sep> <sep> Tran, M.-N., M. K. Pitt, and R. Kohn.	O	O	Review	501
Adaptive Metropolis‚ÄìHastings sampling using reversible dependent mixture proposals.	O	O	Review	501
Statistics and Computing, 26, 1‚Äì21, 2014.	O	O	Review	501
<sep> <sep> D. Luengo, L. Martino, "Fully Adaptive Gaussian Mixture Metropolis-Hastings Algorithm", IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), Vancouver (Canada), 2013.	O	O	Review	501
<sep> <sep> Roberts, G. O. and J. S. Rosenthal (2009).	O	O	Review	501
Examples of adaptive MCMC.	O	O	Review	501
Journal of Computational and Graphical Statistics 18, 349‚Äì367.	O	O	Review	501
<sep> <sep> <sep> <sep> Thank you for your review and well considered comments.	O	O	Reply	501
<sep> <sep> > Review: In my opinion, the paper contains very interesting novel ideas.	O	O	Reply	501
<sep> > However, some parts needs a future clarification and the state-of-the-art must be improved.	O	O	Reply	501
<sep> <sep> <sep> > First of all,  Sections 2.3.1 or 2.3.2 can be improved and clarified.	O	O	Reply	501
For instance, I believe you can create a unique section with title " Choice of Proposal density " and then schematically describe each proposal from the simplest to the more sophisticated one.	O	O	Reply	501
<sep> <sep> Thanks for the feedback.	B-Reply	B-1	Reply	501
As we edit the paper to include other changes we'll bear this in mind.	I-Reply	I-1	Reply	501
We'd hoped this was what we had done already but will try to make it clearer.	I-Reply	I-1	Reply	501
<sep> <sep> > At the beginning of Section 2, please devote more sentence to explain why extending the space and apply the variational inference is good for finding a suitable good proposal density.	O	O	Reply	501
<sep> <sep> We believe that this was made clear in sections 2.3.1 and 2.3.2.	B-Reply	B-2	Reply	501
In particular the discussion immediately following equation (9) tries to make this point.	I-Reply	I-2	Reply	501
However, we can add a further sentence emphasising this at the start of section 2 as well.	I-Reply	I-2	Reply	501
<sep> <sep> > Related  to Section 2 ( theMixture Proposal MCMC contribution), the authors should discuss (in the introduction and also in the related works section) the Multiple Try Metropolis schemes with correlated candidates were, for instance, a path of candidates is generated and one of them is selected and tested with MH-type acceptance probability, in a proper way.	O	O	Reply	501
This is more general that your scheme but very related.	O	O	Reply	501
Please see	O	O	Reply	501
<sep> > Qin, Z.S., Liu, J.S., 2001.	O	O	Reply	501
Multi-point Metropolis method with application to hybrid Monte Carlo.	O	O	Reply	501
Journal of Computational Physics 172, 827‚Äì840.	O	O	Reply	501
<sep> <sep> > L. Martino, V. P. Del Olmo, J. Read, "A multi-point Metropolis scheme with generic weight functions", Statistics and Probability Letters, Volume 82, Issue 7, Pages: 1445-1453, 2012.	O	O	Reply	501
<sep> <sep> >L. Martino, "A Review of Multiple Try MCMC algorithms for Signal Processing", Digital Signal Processing, Volume 75, Pages: 134-152, 2018.	O	O	Reply	501
<sep> <sep> Thanks for the pointers to these papers.	B-Reply	B-3	Reply	501
We are aware of Multiple Try Metropolis (MTM) but many of the references you provided below were new to us.	I-Reply	I-3	Reply	501
Whilst we acknowledge that MTM is a powerful tool in the MCMC arsenal, we felt that it was quite different to our method and really offers an orthogonal direction for improvement.	I-Reply	I-3	Reply	501
We don't attempt a thorough review of the state-of-the-art in MCMC, which we feel is beyond the scope here, but instead try to focus our discussion on other neural adaptive samplers such as L2HMC and A-NICE-MCMC.	I-Reply	I-3	Reply	501
<sep> <sep> <sep> > related again with the state-of-the-art description, the references regarding  Adaptive Mixture Metropolis methods are completely missed.	O	O	Reply	501
If I have properly understood, you also adapt a mixture via variational inference.	O	O	Reply	501
Please, in Section 4, consider the different works that considers an adapting mixture proposal for a  Metropolis-type algorithm,	O	O	Reply	501
<sep> Thanks for the pointers to these papers.	B-Reply	B-4	Reply	501
These were mostly new to us and do seem very related.	I-Reply	I-4	Reply	501
After reading the papers more closely we will try to include them in our references.	I-Reply	I-4	Reply	501
<sep> <sep> >P. Giordani and R. Kohn, ‚ÄúAdaptive independent Metropolis-Hastings by fast estimation of mixtures of normals,‚Äù Journal of Computational and Graphical Statistics, vol.19, no.	O	O	Reply	501
2, pp.243‚Äì259, September 2010.	O	O	Reply	501
<sep> <sep> >Tran, M.-N., M. K. Pitt, and R. Kohn.	O	O	Reply	501
Adaptive Metropolis‚ÄìHastings sampling using reversible dependent mixture proposals.	O	O	Reply	501
Statistics and Computing, 26, 1‚Äì21, 2014.	O	O	Reply	501
<sep> <sep> >D. Luengo, L. Martino, "Fully Adaptive Gaussian Mixture Metropolis-Hastings Algorithm", IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), Vancouver (Canada), 2013.	O	O	Reply	501
<sep> <sep> >Roberts, G. O. and J. S. Rosenthal (2009).	O	O	Reply	501
Examples of adaptive MCMC.	O	O	Reply	501
Journal of Computational and Graphical Statistics 18, 349‚Äì367	O	O	Reply	501

This paper proposes an auxiliary variable MCMC scheme involving variational inference for efficient MCMC.	B-Review	B-1	Review	501
Given a target distribution p(x), the authors introduce an auxiliary variable a, and learn conditional distributions p(a|x) and q(a|x) by minimizing the KL divergence between p(x)p(a|x) and q(a)q(x|a), with q(a) something simple (the authors use Gaussian).	I-Review	I-1	Review	501
A MH proposal step involves simulating x givea the current MCMC sample x (from p(a|x), taking a step in A-space, and then returning back to the X space (using q(x|a)).	I-Review	I-1	Review	501
The authors show how to calculate the acceptance probability.	I-Review	I-1	Review	501
<sep> <sep> I think the idea is nice and useful (I'm surprised people haven't thought of this before), though I think the paper presents this in a less clear way (as an extension of ideas from Agakov and Barber's "Auxiliary variational method").	I-Review	I-1	Review	501
While this is correct and perhaps more general, in my mind it slightly obscures the main idea, as well as the strong ties with variational autoencoders: express a complex distribution as a (learnt) transformation of a simple distribution (this is the actual approach taken in the experiments).	I-Review	I-1	Review	501
<sep> <sep> The motivation of the approach is that the nonlinear encoding network can transform the complex p(x) into a simpler q(a).	B-Review	B-2	Review	501
<sep> For this reason, I think an important baseline is the independent MH sampler from equation 8 (I think this essentially uses a trained VAE generative model as a proposal distribution).	I-Review	I-2	Review	501
The authors talk about how producing independent proposals can be sub-optimal, yet it seems to me that if the encoder and decoder neural networks are powerful enough, this should do a good job.	I-Review	I-2	Review	501
I think excluding this baseline hurts the paper a bit.	I-Review	I-2	Review	501
<sep> <sep> The proof of correctness while correct is a bit unclear, can perhaps be simplified if you view the MCMC algorithm as operating on an augmented space (x,a,x') with stationary distribution p(x)q(a|x)q(x'|a) (writing writing q for \tilde(q)).	B-Review	B-3	Review	501
This clearly has the right distribution over x. Each MCMC iteration starts with x and proceeds as follow:	I-Review	I-3	Review	501
1) Given x, sample a and x' from q(a|x) and q(x'|a)	I-Review	I-3	Review	501
2) Make a deterministic proposal on the augmented space to swap (x,x').	I-Review	I-3	Review	501
The acceptance probability is now equation 2.	I-Review	I-3	Review	501
<sep> 3) Discard a,x'.	I-Review	I-3	Review	501
<sep> <sep> In figure 4, the authors use HMC as an "improved MCMC algorithm", yet this is not an algorithm that deals with multimodality well.	B-Review	B-4	Review	501
More useful would be to include some tempering algorithm like serial or parallel tempering.	I-Review	I-4	Review	501
<sep> <sep> While I like the idea, I unfortunately don't think the experiments are very convincing (and the authors barely discuss their results).	B-Review	B-5	Review	501
Other than mixture of Gaussians, HMC (which involves no training) appears to be superior.	I-Review	I-5	Review	501
With some tempering, I expect it to outperform the proposed method for the MoG case	I-Review	I-5	Review	501
<sep> Table 2 left: since HMC involves no training, does this mean that, taking training time into account, HMC is 5-6 orders of magnitude more efficient.	B-Review	B-6	Review	501
L?ke I mentioned earlier, these results need more discussion.	I-Review	I-6	Review	501
<sep> <sep> It would also help to provide absolute training and run times, so the reader can better understand whether the proposed method of ANICE is better.	B-Review	B-7	Review	501
<sep> <sep> Figure 3: why don't the authors also plot the histogram of values in the auxiliary space, p(a).	B-Review	B-8	Review	501
It would be interesting to see how Gaussian this is (this is what variational inference is trying to achieve).	I-Review	I-8	Review	501
Also, does Figure 3(a) mean that conditioned on x, p(a|x) is basically a delta function?	I-Review	I-8	Review	501
This would suggest that the encoder is basically learning a deterministic transformation to a simpler low-dimensional space?	I-Review	I-8	Review	501
There is some work in this direction in the statistics literature, e.g.	I-Review	I-8	Review	501
"Variable transformation to obtain geometric ergodicity in the random-walk Metropolis algorithm"	I-Review	I-8	Review	501
<sep> The authors some refers to the distribution of a|x as q(a|x) sometimes (in section 2.1) and sometimes as p(a|x) which is a bit confusing.	B-Review	B-9	Review	501
<sep> <sep> Figure 2: the labels are wrong.	B-Review	B-10	Review	501
Thank you for your review and well considered comments.	O	O	Reply	501
<sep> <sep> >This paper proposes an auxiliary variable MCMC scheme involving variational inference for efficient MCMC.	O	O	Reply	501
Given a target distribution p(x), the authors introduce an auxiliary variable a, and learn conditional distributions p(a|x) and q(a|x) by minimizing the KL divergence between p(x)p(a|x) and q(a)q(x|a), with q(a) something simple (the authors use Gaussian).	O	O	Reply	501
A MH proposal step involves simulating x givea the current MCMC sample x (from p(a|x), taking a step in A-space, and then returning back to the X space (using q(x|a)).	O	O	Reply	501
The authors show how to calculate the acceptance probability.	O	O	Reply	501
<sep> <sep> >I think the idea is nice and useful (I'm surprised people haven't thought of this before), though I think the paper presents this in a less clear way (as an extension of ideas from Agakov and Barber's "Auxiliary variational method").	O	O	Reply	501
While this is correct and perhaps more general, in my mind it slightly obscures the main idea, as well as the strong ties with variational autoencoders: express a complex distribution as a (learnt) transformation of a simple distribution (this is the actual approach taken in the experiments).	O	O	Reply	501
<sep> <sep> We did consider presenting the exposition in this way but in the end decided to err on the side of generality.	B-Reply	B-1	Reply	501
Ultimately, we think that there are really two main ideas in the paper: 1) A quite general framework for construction of MH proposals that can exploit structure 2) A VAE-inspired black-box instantiation of that structure.	I-Reply	I-1	Reply	501
<sep> <sep> Though we primarily investigated the neural-net version of our sampler, we do think that there are likely other ways to construct valid samplers that may be more efficient on a problem specific basis and wanted to expose this possibility to the research community.	I-Reply	I-1	Reply	501
<sep> <sep> <sep> >The motivation of the approach is that the nonlinear encoding network can transform the complex p(x) into a simpler q(a).	O	O	Reply	501
<sep> >For this reason, I think an important baseline is the independent MH sampler from equation 8 (I think this essentially uses a trained VAE generative model as a proposal distribution).	O	O	Reply	501
The authors talk about how producing independent proposals can be sub-optimal, yet it seems to me that if the encoder and decoder neural networks are powerful enough, this should do a good job.	O	O	Reply	501
I think excluding this baseline hurts the paper a bit.	O	O	Reply	501
<sep> <sep> We think this is a fair point and will run this experiment and update the results.	B-Reply	B-2	Reply	501
<sep> <sep> >The proof of correctness while correct is a bit unclear, can perhaps be simplified if you view the MCMC algorithm as operating on an augmented space (x,a,x') with stationary distribution p(x)q(a|x)q(x'|a) (writing writing q for \tilde(q)).	O	O	Reply	501
This clearly has the right distribution over x. Each MCMC iteration starts with x and proceeds as follow:	O	O	Reply	501
>  1) Given x, sample a and x' from q(a|x) and q(x'|a)	O	O	Reply	501
>  2) Make a deterministic proposal on the augmented space to swap (x,x').	O	O	Reply	501
The acceptance probability is now equation 2.	O	O	Reply	501
<sep> >  3) Discard a,x'.	O	O	Reply	501
<sep> <sep> This point was also made by another reviewer who suggested a slightly different approach that was also valid.	B-Reply	B-3	Reply	501
As we said to them, we agree that there are perhaps more direct proofs of our method.	I-Reply	I-3	Reply	501
However, rigorously handling deterministic proposals in Metropolis Hastings is quite an advanced topic and we feel that our proof whilst algebraically more involved is conceptually simpler.	I-Reply	I-3	Reply	501
Unless the reviewers feel very strongly on this point, the authors would prefer to maintain the proof as is.	I-Reply	I-3	Reply	501
<sep> <sep> <sep> >In figure 4, the authors use HMC as an "improved MCMC algorithm", yet this is not an algorithm that deals with multimodality well.	O	O	Reply	501
More useful would be to include some tempering algorithm like serial or parallel tempering.	O	O	Reply	501
<sep> <sep> In retrospect the inclusion of HMC here is maybe a little distracting.	B-Reply	B-4	Reply	501
The point was not to demonstrate superiority over advanced methods but simply to demonstrate the ability of our sampler to find low dimensional structure when we know it is present.	I-Reply	I-4	Reply	501
Perhaps the main reason we chose to include this example though, was because the inability of HMC to mix between modes was a key problem investigated in the L2HMC paper, which we benchmark against.	I-Reply	I-4	Reply	501
The authors would happily remove this example if the reviewer feels it adds little.	I-Reply	I-4	Reply	501

I. Summary of the paper	O	O	Review	501
<sep> This paper describes a principled strategy for searching for the most	O	O	Review	501
suitable neural network architecture out of a particular class of	O	O	Review	501
architectures.	O	O	Review	501
Specifically, the problem is framed as an optimisation	O	O	Review	501
problem over a set of directed acyclic graphs (DAGs) that correspond to	O	O	Review	501
potential network architectures.	O	O	Review	501
By optimising the edge weights of this	O	O	Review	501
representation, a suitable architecture can be generated.	O	O	Review	501
<sep> In addition to the aforementioned optimisation scheme, the paper also	O	O	Review	501
presents a regularisation that results in *sparse* networks, i.e.	O	O	Review	501
networks with a smaller number of edges.	O	O	Review	501
Multiple experiments on	O	O	Review	501
'tuning' existing architectures on several data sets conclude the paper.	O	O	Review	501
<sep> <sep> II.	O	O	Review	501
Summary of the review	O	O	Review	501
<sep> This paper discusses a highly relevant subject, namely how to select	O	O	Review	501
neural network architectures in a principled manner.	O	O	Review	501
While the presented	O	O	Review	501
work already goes into a good direction, I cannot give it my endorsement	O	O	Review	501
for acceptance because of the following reasons:	O	O	Review	501
<sep> - The paper is lacking clarity: concepts could be explained somewhat	B-Review	B-11	Review	501
better, and the paper is suffering from language/grammar issues that	I-Review	I-11	Review	501
make it harder to understand the contents.	I-Review	I-11	Review	501
<sep> <sep> - Lack of experimental or theoretical depth: the proposed method is	B-Review	B-12	Review	501
presented as-is; no theoretical analysis of its behaviour is	I-Review	I-12	Review	501
performed; while this is not necessarily a problem, as there are	I-Review	I-12	Review	501
several empirical experiments, the experimental section is not	I-Review	I-12	Review	501
sufficiently detailed: for example, no limitations of the method are	I-Review	I-12	Review	501
being discussed and the presented results are not state-of-the-art	I-Review	I-12	Review	501
accuracies.	I-Review	I-12	Review	501
<sep> <sep> Nevertheless, I want to point out that this paper has the potential to	I-Review	I-12	Review	501
become an important contribution to the community; it is absolutely	I-Review	I-12	Review	501
clear that more principled approaches are required to select network	I-Review	I-12	Review	501
architectures.	I-Review	I-12	Review	501
<sep> <sep> In the following, I will comment on the individual aspects in more	O	O	Review	501
detail.	O	O	Review	501
<sep> <sep> III.	O	O	Review	501
Detailed comments (clarity)	O	O	Review	501
<sep> - The abstract could be improved in terms of its logical flow.	B-Review	B-13	Review	501
Instead	I-Review	I-13	Review	501
of trying to introduce new terminology (macro/micro etc.)	I-Review	I-13	Review	501
here, the	I-Review	I-13	Review	501
abstract should rather state directly that this paper frames network	I-Review	I-13	Review	501
architecture selection as an optimisation problem over DAGs.	I-Review	I-13	Review	501
<sep> <sep> - The use of topology is slightly non-standard here.	B-Review	B-1	Review	501
What is the meaning	I-Review	I-1	Review	501
behind the 'macro' and 'micro' operations?	I-Review	I-1	Review	501
This should be explained	I-Review	I-1	Review	501
somewhat better.	I-Review	I-1	Review	501
<sep> <sep> - Figure 1 should be extended to show an example of how the depicted	B-Review	B-14	Review	501
graphs are described through the terminology mentioned in the paper.	I-Review	I-14	Review	501
<sep> For example, individual edges or nodes could be highlighted and	I-Review	I-14	Review	501
referred to in the text to make the 'mapping' clearer.	I-Review	I-14	Review	501
<sep> <sep> - I do not understand how operations such as *addition* are represented	B-Review	B-15	Review	501
in the DAG.	I-Review	I-15	Review	501
Ideally, this should also be elucidated by a figure.	I-Review	I-15	Review	501
<sep> <sep> - When discussing 'intervals' of residual connections, I am assuming	B-Review	B-2	Review	501
that the paper refers to how many layers are skipped?	I-Review	I-2	Review	501
If so, this	I-Review	I-2	Review	501
should be mentioned and defined explicitly.	I-Review	I-2	Review	501
<sep> <sep> - The term 'searching space' should be replaced by 'search space', as	B-Review	B-16	Review	501
the latter is more standard usage.	I-Review	I-16	Review	501
<sep> <sep> - I do not understand why the optimisation of the topology can decrease	B-Review	B-3	Review	501
the computational burden, as claimed on p. 2.	I-Review	I-3	Review	501
The optimisation process	I-Review	I-3	Review	501
still has to be performed, just like the training of the network,	I-Review	I-3	Review	501
correct?	I-Review	I-3	Review	501
Am I misunderstanding this?	I-Review	I-3	Review	501
<sep> <sep> - The caption of Figure 2 could be extended; does a single node type	B-Review	B-17	Review	501
mean that the complete network only consists of nodes of that type?	I-Review	I-17	Review	501
<sep> Moreover, accuracies/errors should be shown in addition to the loss	I-Review	I-17	Review	501
curves.	I-Review	I-17	Review	501
<sep> <sep> - The term 'dense connection' is vague; I think the paper should use	B-Review	B-18	Review	501
'densely-connected graph' here.	I-Review	I-18	Review	501
<sep> <sep> - The sentence 'Among these nodes, [...]' refers to the *whole* network,	B-Review	B-19	Review	501
and not to the way the output tensor is processed.	I-Review	I-19	Review	501
Am I	I-Review	I-19	Review	501
understanding this correctly?	I-Review	I-19	Review	501
<sep> <sep> - I do not understand the initial sentences in Section 2.2; what is the	B-Review	B-20	Review	501
meaning of 'cell' in this case?	I-Review	I-20	Review	501
<sep> <sep> - The term 'topological structures' should be renamed to '(sub)graphs'	O	O	Review	501
in order to improve clarity.	O	O	Review	501
<sep> <sep> - I do not understand the comment on sparsity in Section 2.4.	B-Review	B-4	Review	501
How are	I-Review	I-4	Review	501
'moderate sparsity' and Figure 2 connected?	I-Review	I-4	Review	501
<sep> <sep> - In the algorithm, I would use 'Sparsity Type' instead of 'Sparse Type'	O	O	Review	501
to refer to the parameter.	O	O	Review	501
<sep> <sep> - What does 'Complete' (without) mean in Table 3?	B-Review	B-5	Review	501
<sep> <sep> - The footnote below Table 3 is not referenced anywhere in the text or	O	O	Review	501
in the table.	O	O	Review	501
<sep> <sep> - In Figure 3, are the adjacency matrices consistent?	B-Review	B-6	Review	501
What happens if	I-Review	I-6	Review	501
the training process is repeated?	I-Review	I-6	Review	501
It would be highly interesting to	I-Review	I-6	Review	501
show 'averaged' matrices over multiple runs.	I-Review	I-6	Review	501
<sep> <sep> IV.	O	O	Review	501
Detailed comments (experiments &amp; theory)	O	O	Review	501
<sep> - A theoretical analysis of the proposed method would be interesting.	O	O	Review	501
<sep> Does the optimisation always converge?	O	O	Review	501
Are minima unique?	O	O	Review	501
What is the	O	O	Review	501
computational complexity?	O	O	Review	501
<sep> <sep> At least some of these aspects should be discussed.	O	O	Review	501
<sep> <sep> - The limitations of the proposed method are not explained.	B-Review	B-8	Review	501
For example,	I-Review	I-8	Review	501
what is the meaning of the sentence on p. 2 about 'excluding the	I-Review	I-8	Review	501
influence of the mixture of different layers/nodes'?	I-Review	I-8	Review	501
<sep> <sep> It is my understanding that the proposed method can only change the	I-Review	I-8	Review	501
*connections* between blocks of a network, but not the type of layers.	I-Review	I-8	Review	501
<sep> Is this correct?	I-Review	I-8	Review	501
If so, it would be a major limitation that should be	I-Review	I-8	Review	501
mentioned explicitly.	I-Review	I-8	Review	501
<sep> <sep> - Another limitation that is not discussed is the scaling to very deep	B-Review	B-9	Review	501
networks.	I-Review	I-9	Review	501
How problematic is it to model all potential connections in	I-Review	I-9	Review	501
such a network?	I-Review	I-9	Review	501
Are there limits to the current optimisation scheme?	I-Review	I-9	Review	501
<sep> This needs to be assessed in the experimental section.	I-Review	I-9	Review	501
<sep> <sep> - For all experimental tables, standard deviations and means should be	O	O	Review	501
provided.	O	O	Review	501
This is necessary in order to assess the stability of the	O	O	Review	501
proposed method, because there are multiple sources of stochasticity:	O	O	Review	501
one arising from the optimisation procedure, the other one arising	O	O	Review	501
from the training of the network itself.	O	O	Review	501
<sep> <sep> - The results reported for the experiments are somewhat behind the	O	O	Review	501
state-of-the-art in terms of accuracy values.	O	O	Review	501
This should be stated	O	O	Review	501
more clearly; I assume that it is caused by limitations of the	O	O	Review	501
proposed method, which prohibit an application to very recent	O	O	Review	501
architectures.	O	O	Review	501
Is this correct?	O	O	Review	501
If so, it should at least be	O	O	Review	501
mentioned.	O	O	Review	501
<sep> <sep> - The claim that nodes at the start of a topological ordering contribute	B-Review	B-7	Review	501
more to specific stages needs to be (empirically) proven.	I-Review	I-7	Review	501
<sep> <sep> V. Style issues	B-Review	B-10	Review	501
<sep> The paper is not easy to read because of several non-standard phrases or	I-Review	I-10	Review	501
expressions.	I-Review	I-10	Review	501
<sep> <sep> - The phrase 'in topology' is often added to a sentence where it does	I-Review	I-10	Review	501
not entirely make sense.	I-Review	I-10	Review	501
For example, '[The] architecture can be	I-Review	I-10	Review	501
expressed as a directed acyclic graph (DAG) in topology'.	I-Review	I-10	Review	501
I do not	I-Review	I-10	Review	501
see the necessity of adding 'in topology' here.	I-Review	I-10	Review	501
There are other places	I-Review	I-10	Review	501
at well from which I would remove this phrase.	I-Review	I-10	Review	501
<sep> <sep> - 'effective networks' --&gt; 'effective network architectures'	I-Review	I-10	Review	501
<sep> - 'largely affects' --&gt; 'largely affect'	I-Review	I-10	Review	501
<sep> - 'Motivated by which' --&gt; 'Motivated by this'	I-Review	I-10	Review	501
<sep> - 'innovative method' --&gt; 'method' (or 'novel method')	I-Review	I-10	Review	501
<sep> - 'as a complete graph, through' --&gt; 'as a complete graph, and through'	I-Review	I-10	Review	501
<sep> - 'auxiliary sparsity constraint' --&gt; 'an auxiliary sparsity constraint'	I-Review	I-10	Review	501
<sep> - 'named as TopoNet' --&gt; 'called TopoNet'	I-Review	I-10	Review	501
<sep> - 'At initial periods' --&gt; 'Previously' (I am not sure I understand	I-Review	I-10	Review	501
this correctly)	I-Review	I-10	Review	501
<sep> - 'red signs' --&gt; 'red arrows'	I-Review	I-10	Review	501
<sep> - 'for its topology' --&gt; 'in terms of its topology' (?)	I-Review	I-10	Review	501
<sep> <sep> - 'both combining' --&gt; 'both a combination' (?)	I-Review	I-10	Review	501
<sep> <sep> - 'number of interval' --&gt; 'number of intervals'	I-Review	I-10	Review	501
<sep> - 'straight connected' --&gt; 'directly connected'	I-Review	I-10	Review	501
<sep> - 'conduct transformation' --&gt; 'performs a transformation'	I-Review	I-10	Review	501
<sep> - What is the meaning of the phrase 'These may cover the influence	I-Review	I-10	Review	501
[...]'?	I-Review	I-10	Review	501
Is this a reference to limitations of existing networks?	I-Review	I-10	Review	501
<sep> <sep> - 'opted from' --&gt; 'chosen from'	I-Review	I-10	Review	501
<sep> - 'Following two simple design rules' --&gt; 'We follow two simple design	I-Review	I-10	Review	501
rules'	I-Review	I-10	Review	501
<sep> - '1000-dimension' --&gt; -dimensional'	I-Review	I-10	Review	501
<sep> - 'We raise two ways' --&gt; 'We describe two ways'	I-Review	I-10	Review	501
<sep> - 'consited' --&gt; 'consisted' / 'consists'	I-Review	I-10	Review	501
<sep> - 'deepen the depth' --&gt; 'increase the depth'	I-Review	I-10	Review	501
<sep> - 'origin' --&gt; 'original'	I-Review	I-10	Review	501
<sep> - 'promotions' --&gt; 'improvements'	I-Review	I-10	Review	501
<sep> - 'can make more profit' --&gt; 'can be useful to improve performance' (I	I-Review	I-10	Review	501
am guessing this from the context)	I-Review	I-10	Review	501
<sep> - 'sparseness on representation' --&gt; 'sparsity'	I-Review	I-10	Review	501
<sep> - 'Adaptive one' --&gt; 'The adaptive one'	I-Review	I-10	Review	501
<sep> - 'At the fore' --&gt; 'At the beginning/start'	I-Review	I-10	Review	501
<sep> - I do not understand the sentence about the 'free lunch'.	I-Review	I-10	Review	501
Does it refer	I-Review	I-10	Review	501
to the fact that some connections can still be removed from the	I-Review	I-10	Review	501
network without decreasing accuracy?	I-Review	I-10	Review	501
<sep> <sep> - 'less computation costs' --&gt; 'lower computation costs'	I-Review	I-10	Review	501
<sep> - 'shortcut offers' --&gt; 'shortcuts offer'	I-Review	I-10	Review	501
<sep> - 'benefits optimization' --&gt; 'benefit optimization'	I-Review	I-10	Review	501
<sep> - 'feasible way to the optimization' --&gt; 'feasible way for the optimization'	I-Review	I-10	Review	501
<sep> - Some references in the bibliography are not capitalised consistently	I-Review	I-10	Review	501
We thank the reviewer for the detailed review and suggestions.	O	O	Reply	501
<sep> Q1: What is the meaning behind the 'macro' and 'micro' operations?	O	O	Reply	501
<sep> A1: In our paper, micro operations denote stacked conv, bn, or activation modules in a layer.	B-Reply	B-1	Reply	501
Macro one is used to represent connections between layers.	I-Reply	I-1	Reply	501
This representation is also used in other literature [1,2].	I-Reply	I-1	Reply	501
<sep> Q2: ... 'intervals' of residual connections‚Ä¶?	O	O	Reply	501
<sep> A2: Yes.	B-Reply	B-2	Reply	501
The number of interval represents the number of layers that make up a residual block.	I-Reply	I-2	Reply	501
<sep> <sep> Q3: ‚Ä¶ can decrease the computational burden ‚Ä¶	O	O	Reply	501
A3: Different from sample-based search method, in our method, the topology and parameters of neural networks are optimized jointly, resulting in small computation cost.	B-Reply	B-3	Reply	501
The proposed weights in edges have little effect on total params and FLOPs.	I-Reply	I-3	Reply	501
So we claimed this does not introduce additional computing burdens.	I-Reply	I-3	Reply	501
<sep> <sep> Q4: In Fig.2, ...single node type mean ... consists of nodes of that type?	O	O	Reply	501
And the relationship between 'moderate sparsity' and Fig.2?	O	O	Reply	501
<sep> A4: Yes.	B-Reply	B-4	Reply	501
And top-1 accuracies are shown in labels in the upper right.	I-Reply	I-4	Reply	501
As given in p. 2, denser networks can achieve higher performance in most cases, e.g. SepConv with interval of 1 (top-1 80.12%) and MBOP with interval of 1 (top-1 81.10%).	I-Reply	I-4	Reply	501
For Conv operation, the best results of 80.79% is achieved when interval is 2.	I-Reply	I-4	Reply	501
These indicate moderate sparsity may benefit the optimization and generalization.	I-Reply	I-4	Reply	501
So we introduce L1 regularization.	I-Reply	I-4	Reply	501
<sep> <sep> Q5: What does 'Complete' (without \alpha) mean in Table 3?	O	O	Reply	501
<sep> A5: This means the topology is fixed to complete graph without learnable weights.	B-Reply	B-5	Reply	501
It is a baseline which reveals the importance of learnable weights of edges and sparsity constrains.	I-Reply	I-5	Reply	501
<sep> <sep> Q6ÔºöIn Fig.3, are the adjacency matrices consistent?	O	O	Reply	501
Does the optimization always converge?	O	O	Reply	501
Are minima unique?	O	O	Reply	501
For all experimental tables, standard deviations and means should be provided.	O	O	Reply	501
<sep> A6ÔºöWe do multiple runs and give the results in Fig.6.	B-Reply	B-6	Reply	501
5 and Fig.	I-Reply	I-6	Reply	501
We provide standard deviations and means in Table 4.	I-Reply	I-6	Reply	501
For experiments in Table 2 and 3, more structures are compared with our optimization method.	I-Reply	I-6	Reply	501
In Fig.5, the matrices optimized from multiple runs have high similarity, where weights on the diagonal are larger, and connections on the off-diagonal are relatively sparse.	I-Reply	I-6	Reply	501
This indicates nodes with adjacent topological orderings have more information interactions.	I-Reply	I-6	Reply	501
Besides, some essential long-range connections are built as input to intermediate layers.	I-Reply	I-6	Reply	501
For the final output, many nodes have their contributions.	I-Reply	I-6	Reply	501
It is hard to prove the unique of minima in neural networks.	I-Reply	I-6	Reply	501
Despite the similarities, there are some minor differences between optimized topologies through multiple runs.	I-Reply	I-6	Reply	501
But the final performances of them are similar.	I-Reply	I-6	Reply	501
We infer that there is more than one local minima in the search space.	I-Reply	I-6	Reply	501
<sep> <sep> Q7: The claim that nodes at the start of a topological ordering contribute more to specific stages needs to be (empirically) proven.	O	O	Reply	501
<sep> A7: Thanks for your attention.	B-Reply	B-7	Reply	501
Since the topology is represented by a directed acyclic graph, for a node with topological ordering of i, the generated can be only received by node (where).	I-Reply	I-7	Reply	501
This causes that features generated by front nodes can participate in feature aggregation as a downstream input.	I-Reply	I-7	Reply	501
It makes the front nodes contribute more.	I-Reply	I-7	Reply	501
<sep> <sep> Q8: It is my understanding that the proposed method can only change the *connections* between blocks of a network, but not the type of layers.	O	O	Reply	501
Is this correct?	O	O	Reply	501
<sep> A8: Yes.	B-Reply	B-8	Reply	501
Our optimization is conducted under the same type of layers.	I-Reply	I-8	Reply	501
It provides a convenient and fair platform to compare the effects caused by topology changes.	I-Reply	I-8	Reply	501
When extending to multiple type of layers, more factors will affect the optimization process, such as the topological orderings and number of params/FLOPs of different types of layers.	I-Reply	I-8	Reply	501
They are certainly interesting open questions and can serve as future work.	I-Reply	I-8	Reply	501
To some extent, our experiments of graph damage can also be a preliminary exploration.	I-Reply	I-8	Reply	501
<sep> <sep> Q9: Scaling to very deep networks and the reason why behind the state-of-the-art networks?	O	O	Reply	501
<sep> A9: We further conduct experiments on networks with more layers on CIFAR-100 and ImageNet.	B-Reply	B-9	Reply	501
<sep> It can be seen that our optimization method is depth-friendly.	I-Reply	I-9	Reply	501
<sep> <sep> Network (CIFAR-100)<tab>origin<tab>optimized<tab>gain	I-Reply	I-9	Reply	501
ResNet-20<tab><tab><tab>69.01<tab><tab>0.90	I-Reply	I-9	Reply	501
ResNet-32<tab><tab><tab>72.07<tab><tab>1.37	I-Reply	I-9	Reply	501
ResNet-44<tab><tab><tab>73.73<tab><tab>1.87	I-Reply	I-9	Reply	501
ResNet-56<tab><tab><tab>75.22<tab><tab>1.68	I-Reply	I-9	Reply	501
ResNet-110<tab><tab><tab>76.31<tab><tab>2.23	I-Reply	I-9	Reply	501
<sep> Network (ImageNet)<tab>depth<tab>origin<tab>optimized<tab>gain	I-Reply	I-9	Reply	501
MobileNet-1.0<tab><tab>53<tab><tab>72.62<tab><tab>0.24	I-Reply	I-9	Reply	501
MobileNet-1.0-2N<tab>104<tab><tab>75.93<tab><tab>0.47	I-Reply	I-9	Reply	501
MobileNet-1.0-4N<tab>206<tab><tab>77.33<tab><tab>0.54	I-Reply	I-9	Reply	501
MobileNet-1.0-6N<tab>308<tab><tab>77.61<tab><tab>0.75	I-Reply	I-9	Reply	501
A11: Style issues are corrected in the paper.	B-Reply	B-10	Reply	501
Thank you for your careful proofreading.	I-Reply	I-10	Reply	501
<sep> [1] Atwood J, Towsley D. Diffusion-convolutional neural networks.	O	O	Reply	501
NIPS.	O	O	Reply	501
2016.	O	O	Reply	501
<sep> [2] P√©rez-R√∫a J M, Baccouche M, Pateux S. Efficient progressive neural architecture search.	O	O	Reply	501
arXiv preprint arXiv:1808.00391, 2018.	O	O	Reply	501

-------------------------      Update after rebuttal    ---------------------------	O	O	Review	501
<sep> <sep> Thank you for addressing my concerns.	O	O	Review	501
I feel the rebuttal did improve the paper, e.g., the significance of results can be evaluated better now.	O	O	Review	501
I still like the overall idea of the paper as optimizing connectivity patterns in architectures has so far mostly been ignored while it is actually straight-forward to do (as shown in this work).	O	O	Review	501
I increased my score accordingly.	O	O	Review	501
However, the novelty and significance of this work is still limited in my option and therefore I do not argue heavily in favor of accepting this submission.	B-Review	B-1	Review	501
<sep> <sep> <sep> --------------------------------------------------------------------------------------------------------------------------------------------------	O	O	Review	501
<sep> <sep> <sep> <sep> The authors propose a method for learning the connections/ connectivity pattern (dubbed: the topology; meaning which layer is directly connected to which other layer) in neural networks.	O	O	Review	501
They do so by weighting connections between layers (e.g., by weighting skip connections) with a real valued parameter.	O	O	Review	501
This real-valued parameterization of the connections is then optimized by gradient descent along with the weights of neural networks.	O	O	Review	501
The authors also propose L1 regularization on the connectivity parameters to induce sparsity.	O	O	Review	501
The proposed method is evaluated by optimizing the topology for ResNets, MobileNetsV2 and their proposed ‚ÄúTopoNets‚Äù.	O	O	Review	501
<sep> Originality and significance.	O	O	Review	501
The manuscript addresses an interesting problem: while there has been lots of work on manually designing better architectures as well as automated design (a.k.a.	O	O	Review	501
neural architecture search, NAS), there is little work on optimizing the overall topology (meaning the connectivity patterns between layers).	O	O	Review	501
Most prior work solely focuses on search for blocks or cells and then stacking these cells in a pre-defined, not-optimized manner.	B-Review	B-1	Review	501
However, there has been some work also including this in architecture search (e.g., [1,2,3]), and especially the work [4] seems very related but is not discussed.	I-Review	I-1	Review	501
The authors of [4] propose, very similar to this submission, a gradient-based optimization of the connections (in a different way though).	I-Review	I-1	Review	501
The proposed method for optimizing the topology is also very similar to DARTS, simply applied to the connectivity pattern rather than on the operations-level.	I-Review	I-1	Review	501
However, here the topology is optimized along with the network‚Äôs weights on the training data rather than the bi-level optimization from DARTS, where the architectural parameters are optimized on the validation data instead (which is very reasonable as one usually considers the architecture as a hyperparameter).	I-Review	I-1	Review	501
I wonder if this has also been considered/tested by the authors of this paper as I would consider the topology to be a hyperparameter which should not be optimized on training but rather validation data.	I-Review	I-1	Review	501
Knowing [4] and DARTS, the proposed method seems to be rather incremental and straightforward rather than ground breaking.	I-Review	I-1	Review	501
While the proposed method allows for more flexible topologies, it introduces different ‚Äústages‚Äù for their TopoNets, which are actually a similar concept as blocks or cells from the NAS literature.	B-Review	B-2	Review	501
This again does not allow connections between arbitrary layers (but rather only between layers in the same stage; to the best of my understanding).	I-Review	I-2	Review	501
Empirical results show rather small improvements and their significance is unclear (see next paragraph).	I-Review	I-2	Review	501
<sep> Clarity and quality.	O	O	Review	501
The paper is mostly well written, well motivated and easy to follow.	O	O	Review	501
The mathematical formalism is a little vague at some points (e.g., in Section 2.1.,	B-Review	B-3	Review	501
the notation G is used for defining a graph and later in Equation (2) as a function computing feature maps in networks).	I-Review	I-3	Review	501
While the literature on manual design of architectures is thoroughly reviewed, there is missing related work in the context of neural architecture search, as already discussed above.	B-Review	B-4	Review	501
The quality of the results is questionable as differences in accuracies are in almost all experiment rather small (e.g., tuning MobileNetsV2 on Imagenet: 72.62% (original) Top-1 accuracy vs. 72.84% (optimized) and it seems that the authors do only report results for a single run of experiments.	B-Review	B-5	Review	501
In order to assess if the differences are actually statistically significant, the authors would need to report several runs and would need to state, e.g., means and standard deviations.	I-Review	I-5	Review	501
<sep> <sep> Overall, the authors address an interesting problem, which seems to have fallen into oblivion in current NAS literature: while researcher optimize cells, which are then stacked to build the final model, not many researcher look into connectivity patterns / topology on the macro level, meaning connections across cells and how cells should be stacked.	O	O	Review	501
This paper addresses this problem to some extent.	O	O	Review	501
However, the proposed optimization method is, in my opinion, rather incremental (with respect to DARTS and [4]) and therefore of limited novelty and significance.	B-Review	B-1	Review	501
It is currently hard to assess the empirical results due to rather small improvements and the lack of repeated runs of experiments.	B-Review	B-2	Review	501
Mainly for these two reasons, I do not recommend the paper for acceptance.	O	O	Review	501
<sep> <sep> <sep> <sep> [1] Esteban Real, Sherry Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon Suematsu, Quoc V. Le, and Alex Kurakin.	O	O	Review	501
Large-scale evolution of image classifiers.	O	O	Review	501
ICML, 2017.	O	O	Review	501
<sep> [2] Thomas Elsken, Jan Hendrik Metzen, and Frank Hutter.	O	O	Review	501
Efficient multi-objective neural architecture search via lamarckian evolution.	O	O	Review	501
ICLR, 2019.	O	O	Review	501
<sep> [3] Hieu Pham, Melody Y. Guan, Barret Zoph, Quoc V. Le, and Jeff Dean.	O	O	Review	501
Efficient neural architecture search via parameter sharing.	O	O	Review	501
ICML, 2018	O	O	Review	501
[4] Karim Ahmed and Lorenzo Torresani.	O	O	Review	501
Maskconnect: Connectivity learning by gradient descent.	O	O	Review	501
ECCV, 2018	O	O	Review	501
<sep> <sep> <sep> We thank the reviewer for detailed review.	O	O	Reply	501
<sep> <sep> A1: Differences with MaskConnect and DARTS.	O	O	Reply	501
<sep> MaskConnect treated original residual networks as being connected only to the immediately preceding module.	B-Reply	B-1	Reply	501
However, in our proposed topological view, due to the existing of identity mappings, each residual block has already built densely-connected links with all preceding modules.	I-Reply	I-1	Reply	501
We tried to explain the reason why ResNet work from a new perspective.	I-Reply	I-1	Reply	501
Additionally, MaskConnect learned to connect each module to K previous modules, where the connections are binary of {0,1}. Fig.2 in their paper proposed that a very low or very high K yields lower accuracy, which results in the need to select the appropriate hyperparameter for different networks with different depths.	I-Reply	I-1	Reply	501
In our method, we do not set a fixed in-degree for different layers/nodes.	I-Reply	I-1	Reply	501
Instead, a complete graph is built and the connections between nodes are continuous.	I-Reply	I-1	Reply	501
The number of in-degree and the importance of connections are learned adaptively and motivated by task-related loss and sparsity constrains.	I-Reply	I-1	Reply	501
<sep> <sep> Different from DARTS, we define a type-consistent search space to explore the topology-induced impact.	I-Reply	I-1	Reply	501
Due to memory limitation, DARTS can only search blocks in small datasets, and repeated the learned block to form networks for larger datasets.	I-Reply	I-1	Reply	501
This suffers from the transfer gap.	I-Reply	I-1	Reply	501
Our optimization is directly applied to target tasks, e.g. classification, recognition and detection, which guarantees the consistency of search and application.	I-Reply	I-1	Reply	501
<sep> <sep> A2: Whether to adopt alternative optimization strategies.	O	O	Reply	501
<sep> There is no theoretical analysis can prove that alternative optimization is better than simultaneous one.	B-Reply	B-2	Reply	501
DARTS claimed alternative training can ease overfitting in CIFAR-10.	I-Reply	I-2	Reply	501
But we tested these two types in ImageNet.	I-Reply	I-2	Reply	501
The top-1 accuracy difference is within in multiple runs.	I-Reply	I-2	Reply	501
To ensure the consistency of optimization objective, we finally selected the simultaneous one.	I-Reply	I-2	Reply	501
To further verify the relationship between and.	I-Reply	I-2	Reply	501
We test the stand-alone accuracies for different topologies during optimization and give the results in Fig.6.	I-Reply	I-2	Reply	501
<sep> The expression ability of topology itself increases with the optimization process on the validation set.	I-Reply	I-2	Reply	501
Joint training does not lead to structural overfitting on the training set.	I-Reply	I-2	Reply	501
<sep> <sep> A3: About cross-stage optimization.	O	O	Reply	501
<sep> Extending optional connections to different stages can expand the search space.	B-Reply	B-2	Reply	501
But additional transformations are needed to bridge the changes of channels and feature maps for each node with other stages.	I-Reply	I-2	Reply	501
This contradicts our definition that the down-sample operation is performed by the first node in topological ordering.	I-Reply	I-2	Reply	501
However, this is an interesting and open question in the future work.	I-Reply	I-2	Reply	501
<sep> <sep> A4: Mathematical formalism correction.	O	O	Reply	501
<sep> We use to denote the mapping function computing feature maps of.	B-Reply	B-3	Reply	501
<sep> <sep> A5: Some missing related work is added.	B-Reply	B-4	Reply	501
<sep> <sep> A6: Improvements of our proposed optimization method through multiple runs.	O	O	Reply	501
<sep> We provide standard deviations and means in Table 4 through multiple runs.	B-Reply	B-5	Reply	501
We further apply our method to different networks in more dataset.	I-Reply	I-5	Reply	501
The improvements are given in Table 2, and Table 3.	I-Reply	I-5	Reply	501
This shows that the improvements of our method increase with the depth of networks.	I-Reply	I-5	Reply	501
<sep> <sep> Network (CIFAR-100)<tab>origin<tab>optimized<tab>gain	I-Reply	I-5	Reply	501
ResNet-20<tab><tab><tab>69.01<tab><tab>0.90	I-Reply	I-5	Reply	501
ResNet-32<tab><tab><tab>72.07<tab><tab>1.37	I-Reply	I-5	Reply	501
ResNet-44<tab><tab><tab>73.73<tab><tab>1.87	I-Reply	I-5	Reply	501
ResNet-56<tab><tab><tab>75.22<tab><tab>1.68	I-Reply	I-5	Reply	501
ResNet-110<tab><tab><tab>76.31<tab><tab>2.23	I-Reply	I-5	Reply	501
<sep> Network (ImageNet)<tab>depth<tab>origin<tab>optimized<tab>gain	I-Reply	I-5	Reply	501
MobileNet-1.0<tab><tab>53<tab><tab>72.62<tab><tab>0.24	I-Reply	I-5	Reply	501
MobileNet-1.0-2N<tab>104<tab><tab>75.93<tab><tab>0.47	I-Reply	I-5	Reply	501
MobileNet-1.0-4N<tab>206<tab><tab>77.33<tab><tab>0.54	I-Reply	I-5	Reply	501
MobileNet-1.0-6N<tab>308<tab><tab>77.61<tab><tab>0.75	I-Reply	I-5	Reply	501

*UPDATE* I have read the other reviews, authors' comments and the revised version of the manuscript.	O	O	Review	501
I have modified my rating to accept.	O	O	Review	501
The updated version, with variance across runs reported, comparison to randomly wired networks, and clearer writing, is substantially better.	O	O	Review	501
The core idea is simple to understand in retrospect, and could lead to more follow-up work in the vein of DenseNets and DART (with a more constrained search space).	O	O	Review	501
<sep> <sep> The paper proposes a refinement of the idea behind DenseNets -- rather than summing over all previous layers' outputs, sum a weighted combination instead where the weights are learned.	O	O	Review	501
This idea can be extended to search through the space of all possible residual connections, which they call TopoNet.	O	O	Review	501
This is practically achieved by enforcing a sparsity constraint on the learned weights.	O	O	Review	501
There is an additional nuance when enforcing the sparsity constraint: downstream layers have many more incoming residual connections, and may need an appropriately scaled sparsity penalty.	O	O	Review	501
<sep> <sep> It may help to clarify in the text that weights can be positive or negative (the current motivation from the point of view of residuals at different intervals suggests all the weights should be non-negative).	O	O	Review	501
<sep> Table 3 is baffling.	B-Review	B-1	Review	501
Were the initial edge values (column 2) chosen so as to make the number of params and FLOPS somewhat comparable across different rows?	I-Review	I-1	Review	501
How were these initial edge values set (seems very specific for N_3 to go from 46 to 103 when residual interval goes from 4 to 2, etc.)?	I-Review	I-1	Review	501
The comment that number of params and FLOPS changes are negligible is puzzling; clearly Random, p=0.01 should use much fewer FLOPS than Random, p=0.99.	I-Review	I-1	Review	501
<sep> Without additional information behind the numbers for the baselines in Table 3, it is unclear if TopoNets indeed give an improvement over the baselines (Random and Residual).	B-Review	B-2	Review	501
<sep> The text will also benefit from a careful elaboration of the differences in the Random baselines in the paper vs. the Xie et al approach of trying random architectures.	B-Review	B-3	Review	501
We thank the reviewers for your attention to the details.	O	O	Reply	501
<sep> <sep> A1: Parameters and FLOPs in Table 3.	O	O	Reply	501
<sep> We are sorry for not clarifying the changes of params and FLOPs among different topologies.	B-Reply	B-1	Reply	501
In Table3, for fair comparison, the generated random graph is required to have at least one input and output edge for each node.	I-Reply	I-1	Reply	501
Otherwise, the graph will be regenerated until the condition is met.	I-Reply	I-1	Reply	501
Under this setting, different networks share similar params and FLOPs of convolution operations, and the only difference is the number of edges.	I-Reply	I-1	Reply	501
This ensures that the improvement is not the result of additional computation but topology changes.	I-Reply	I-1	Reply	501
Without this constrain, nodes without input or output edges can be removed, resulting in fewer params and FLOPs.	I-Reply	I-1	Reply	501
As shown in Sect.	I-Reply	I-1	Reply	501
3.2.3, the removal of nodes for optimized topologies is used to acceleration.	I-Reply	I-1	Reply	501
<sep> <sep> A2: Comparation with random architectures.	O	O	Reply	501
<sep> Since [1] has not released their codes, we conduct comparisons using TopoNet through replacing graphs to form networks.	B-Reply	B-3	Reply	501
The three graph generators (ER, BA, WS) are performed using NetworkX [2] with the best configs in their paper.	I-Reply	I-3	Reply	501
For fair comparison, we do not adopt droppath and dropout for all experiments.	I-Reply	I-3	Reply	501
The results are given as follows using 5 repeat runs.	I-Reply	I-3	Reply	501
These results and Table 3 further prove the effectiveness of our optimization method over random and residual baselines.	I-Reply	I-3	Reply	501
<sep> <sep> Topology(ImageNet)<tab>Top-1 Acc(%)	I-Reply	I-3	Reply	501
<sep> ER (P=0.2)<tab><tab><tab>77.76¬±0.23	I-Reply	I-3	Reply	501
BA (M=5)<tab><tab><tab>78.08+0.17	I-Reply	I-3	Reply	501
WS (K=4, P=0.75)<tab><tab>78.19¬±0.25	I-Reply	I-3	Reply	501
our method<tab><tab><tab>78.60¬±0.06	I-Reply	I-3	Reply	501
<sep> [1] Xie, Saining, et al "Exploring randomly wired neural networks for image recognition."	O	O	Reply	501
ICCV, 2019	O	O	Reply	501
[2] <a href="https://networkx.github.io/documentation/stable/tutorial.html" target="_blank" rel="nofollow">https://networkx.github.io/documentation/stable/tutorial.html</a>	O	O	Reply	501

The authors proposed a method to optimize the topology of neural networks in a soft fashion.	O	O	Review	501
The main idea is to formulate the network as a complete graph (or a sequence of complete subgraphs), and to optimize the relative importance of each edge using gradient descent.	O	O	Review	501
The overall approach is similar to differentiable architecture search, except that (1) the continuous architecture is optimized wrt the training set (instead of the validation set), and (2) the learned architecture is never discretized at the end of training.	O	O	Review	501
<sep> <sep> The paper is well-organized and easy to follow.	O	O	Review	501
The authors have also conducted controlled experiments to convincingly show that the method is leading to improvement.	O	O	Review	501
<sep> <sep> I'm a bit concerned about the technical novelty, however, as the approach can be viewed as an application of (a simplified version of) differentiable NAS to a search space analogous to the one used in [1]. In fact, the notion of soft topology has already been introduced in this prior work (Figure 2 in [1]: "The aggregation is done by weighted sum with learnable positive weights w0, w1, w2"), which was also optimized using gradient descent.	B-Review	B-1	Review	501
A difference between this work and [1] is that whether the underlying graph is complete or randomly generated, but such a distinction is minor (we can always get densely connected random graphs by adjusting the hyperparameters of the graph generator).	I-Review	I-1	Review	501
<sep> <sep> In addition, I'm not sure whether the learned continuous \alpha can be conveniently referred to as "topology".	B-Review	B-2	Review	501
Note the mathematical definition of topology is discrete by nature.	I-Review	I-2	Review	501
I believe the authors would need to either revise this terminology (e.g., by referring to it as ‚Äúsoft topology‚Äù, as a generalized definition of hard topology), or provide a way to induce discrete subgraphs from the continuous architecture.	I-Review	I-2	Review	501
Sparsity regularization alone may not be sufficient as the non-zero \alpha's are still real-valued.	I-Review	I-2	Review	501
<sep> <sep> Minor issue:	B-Review	B-3	Review	501
I like Figure 1 a lot.	I-Review	I-3	Review	501
However, it seems the equivalence between the 3rd and the 4th sub-figures in Figure 1 can only be established for ResNet-V2 blocks, where there is no ReLU after each addition.	I-Review	I-3	Review	501
It is not immediately obvious how this analysis can generalize to ResNet-V1 blocks (which still offers reasonably good empirical performance).	I-Review	I-3	Review	501
<sep> <sep> [1] Xie, Saining, et al "Exploring randomly wired neural networks for image recognition."	O	O	Review	501
arXiv preprint arXiv:1904.01569 (2019).	O	O	Review	501
We thank the reviewer for the valuable feedback.	O	O	Reply	501
In the following, we attempt to address the reviewer's concerns:	O	O	Reply	501
<sep> A1: About the differences with randomly wired neural networks.	O	O	Reply	501
<sep> What we are trying to explore is completely different with Randomly Wired Networks.	B-Reply	B-1	Reply	501
<sep> Randomly wired networks claimed that random graphs generated by well-defined graph generators are good enough.	I-Reply	I-1	Reply	501
To its credit, it provides a good platform to explore more flexible network architectures.	I-Reply	I-1	Reply	501
However, its performance is largely affected by randomness as shown in Fig.3 in their paper.	I-Reply	I-1	Reply	501
For the same generator, performances range from 72.6 to 73.4 (ER), 70.7 to 73.2 (BA) and 72.1 to 73.8 (WS).	I-Reply	I-1	Reply	501
So hyperparameters of generators need to be searched by trial-and-error.	I-Reply	I-1	Reply	501
Particularly, their experiments with ER generators indicate denseness leads to performance degradation, e.g. 72.6(P=0.8), 72.7(P=0.6), 72.8(P=0.4), 73.4(P=0.2).	I-Reply	I-1	Reply	501
We also tested ER(P=1.0) (noted Complete with in Tab.3) in our paper, resulting in 0.40 lower than our optimization method.	I-Reply	I-1	Reply	501
These limit the search space in larger ones.	I-Reply	I-1	Reply	501
<sep> <sep> Starting from the residual connection, we point a new topological view to find the reasons for its success.	I-Reply	I-1	Reply	501
It inspires for dense and important connections.	I-Reply	I-1	Reply	501
Furthermore, we analyze the influence of different topologies on optimization process, including not just random, but also residual and complete ones.	I-Reply	I-1	Reply	501
Searching from the complete graph with sparsity constrain proves topology can be optimized rather than randomly wired.	I-Reply	I-1	Reply	501
Our methods also compatible with existing networks.	I-Reply	I-1	Reply	501
<sep> <sep> We also perform comparision with randomly wired networks as shown in Response to Review #3 A2.	I-Reply	I-1	Reply	501
<sep> <sep> Topology(ImageNet)<tab>Top-1 Acc(%)	I-Reply	I-1	Reply	501
<sep> ER (P=0.2)<tab><tab><tab>77.76¬±0.23	I-Reply	I-1	Reply	501
BA (M=5)<tab><tab><tab>78.08+0.17	I-Reply	I-1	Reply	501
WS (K=4, P=0.75)<tab><tab>78.19¬±0.25	I-Reply	I-1	Reply	501
our method<tab><tab><tab>78.60¬±0.06	I-Reply	I-1	Reply	501
<sep> A2: The definition of topology.	O	O	Reply	501
<sep> Our definition of topology is consistent with weighted graph in which a number (the weight) is assigned to each edge.	B-Reply	B-2	Reply	501
<sep> <sep> A3: The generalization of the proposed topological view.	O	O	Reply	501
<sep> Thank you for your attention to our proposed perspective.	B-Reply	B-3	Reply	501
The topological view can be used to represent ResNet, ResNeXt, MobileNet-V2 and other networks with residual connections.	I-Reply	I-3	Reply	501
When there is ReLU after addition such as ResNet-V1, it can be merged into the subsequent node with a form of ReLU/Conv/BN, and the edges should conduct additional inplace ReLU.	I-Reply	I-3	Reply	501
This transformation is equivalent to original expression, and does not change  the properties of a densely-connect network.	I-Reply	I-3	Reply	501

The paper proposes a new way of transferring knowledge.	O	O	Review	176
<sep> I like the idea of transferring attention maps instead of activations.	O	O	Review	176
<sep> However, the experiments don‚Äôt show a big improvement compared with knowledge distillation alone and I think more experiments are required in IMAGENET section.	B-Review	B-1	Review	176
<sep> I would consider updating the score if the authors extend the last section 4.2.2.	O	O	Review	176
Dear Reviewer,	O	O	Reply	176
<sep> Below is our answer:	O	O	Reply	176
<sep> Q: However, the experiments don‚Äôt show a big improvement compared with knowledge distillation alone and I think more experiments are required in IMAGENET section.	O	O	Reply	176
<sep> A: We‚Äôve updated the paper with an ImageNet experiment where we used two attention losses and trained  from scratch, and got 1.1%/0.8% top1/top5 accuracy improvement over baseline ResNet-18, ~30% reduction in error difference between teacher and student.	B-Reply	B-1	Reply	176
We think that this is a remarkable result, considering our very limited computational resources (8 GPUs), and are sure it could be easily further improved by using more AT losses, tuning hyperparameters, or using more powerful teachers.	I-Reply	I-1	Reply	176
<sep> We are currently running experiments with:	I-Reply	I-1	Reply	176
1.	I-Reply	I-1	Reply	176
<tab>All four AT losses, one for each group of residual blocks;	I-Reply	I-1	Reply	176
2.	I-Reply	I-1	Reply	176
<tab>KD baseline;	I-Reply	I-1	Reply	176
and will update the paper as soon as we get the results.	I-Reply	I-1	Reply	176
<sep> <sep> Thanks.	O	O	Reply	176

The paper presented a modified knowledge distillation framework that minimizes the difference of the sum of statistics across the a feature map between the teacher and the student network.	O	O	Review	176
The authors empirically demonstrated the proposed methods outperform the fitnet style distillation baseline.	O	O	Review	176
<sep> <sep> Pros:	O	O	Review	176
+ The author evaluated the proposed methods on various computer vision dataset	O	O	Review	176
+ The paper is in general well-written	O	O	Review	176
<sep> Cons:	O	O	Review	176
- The method seems to be limited to the convolutional architecture	B-Review	B-1	Review	176
- The attention terminology is misleading in the paper.	B-Review	B-2	Review	176
The proposed method really just try to distill the summed squared(or other statistics e.g. summed lp norm) of  activations in a hidden feature map.	I-Review	I-2	Review	176
<sep> - The gradient-based attention transfer seems out-of-place.	B-Review	B-3	Review	176
The proposed gradient-based methods are never compared directly to nor are used jointly with the "attention-based" transfer.	I-Review	I-3	Review	176
It seems like a parallel idea added to the paper that does not seem to add much value.	I-Review	I-3	Review	176
<sep> - It is also not clear how the induced 2-norms in eq.(2) is computed.	B-Review	B-4	Review	176
Q is a matrix \in \mathbb{R}^{H \times W}  whose induced 2-norm is its largest singular value.	I-Review	I-4	Review	176
It seems computationally expensive to compute such cost function.	I-Review	I-4	Review	176
Is it possible the authors really mean the Frobenius norm?	I-Review	I-4	Review	176
<sep> <sep> Overall, the proposed distillation method works well in practice but the paper has some organization issues and unclear notation.	O	O	Review	176
<sep> Dear Reviewer,	O	O	Reply	176
<sep> Below are our answers:	O	O	Reply	176
<sep> Q: The method seems to be limited to the convolutional architecture	O	O	Reply	176
A: Fist, we would like to note that our method can be directly applied even to non convolutional  architectures (such as MLPs) given that our definitions of attention are also valid for such architectures.	B-Reply	B-1	Reply	176
We‚Äôre also currently looking into applying attention transfer for recurrent neural networks in NLP tasks.	I-Reply	I-1	Reply	176
Independently of the above, we consider that the convolutional architecture is one of the most important and widely used type of network architectures (with a really huge impact on several fields).	I-Reply	I-1	Reply	176
<sep> <sep> Q: The attention terminology is misleading in the paper.	O	O	Reply	176
The proposed method really just try to distill the summed squared(or other statistics e.g. summed lp norm) of  activations in a hidden feature map.	O	O	Reply	176
<sep> A: We respectfully disagree with this statement.	B-Reply	B-2	Reply	176
In our view a spatial attention map is supposed to indicate how important each spatial location of the input layer (or of an intermediate layer) is w.r.t.the output computed by the network (in other words, roughly how much focus the network puts per spatial location).	I-Reply	I-2	Reply	176
Here we provide two simple ways of defining such an attention map, an activation based one and a gradient based one.	I-Reply	I-2	Reply	176
<sep> <sep> Q: The gradient-based attention transfer seems out-of-place.	O	O	Reply	176
The proposed gradient-based methods are never compared directly to nor are used jointly with the "attention-based" transfer.	O	O	Reply	176
It seems like a parallel idea added to the paper that does not seem to add much value.	O	O	Reply	176
<sep> A: A main contribution of this work is the idea that attention transfer can be very useful for improving the performance of a network.	B-Reply	B-3	Reply	176
We therefore wanted to show that this is indeed true even when using different ways for defining attention, which is why we included results for both activation based and gradient based attention.	I-Reply	I-3	Reply	176
Nevertheless we agree that it will be useful to compare the  two methods under the same conditions, and, to that end, we are going to update the paper with new experiments.	I-Reply	I-3	Reply	176
<sep> <sep> Q: It is also not clear how the induced 2-norms in eq.(2) is computed.	O	O	Reply	176
Q is a matrix \in \mathbb{R}^{H \times W}  whose induced 2-norm is its largest singular value.	O	O	Reply	176
It seems computationally expensive to compute such cost function.	O	O	Reply	176
Is it possible the authors really mean the Frobenius norm?	O	O	Reply	176
<sep> A: Sorry for the confusion, it is indeed a Frobenius norm.	B-Reply	B-4	Reply	176
Essentially, in eq. (2)  we consider that all attention maps are in vectorized form, in which case the standard norm notation for vectors applies.	I-Reply	I-4	Reply	176
We have updated the paper respectively.	I-Reply	I-4	Reply	176
<sep> <sep> Thanks.	O	O	Reply	176

This paper proposes to investigate attention transfers between a teacher and a student network.	O	O	Review	176
<sep> <sep> Attention transfer is performed by minimising the l2 distance between the teacher/student attention maps at different layers, in addition to minimising the classification loss and optionally a knowledge distillation term.	O	O	Review	176
<sep> Authors define several activation based attentions (sum of absolute feature values raise at the power p or max of values raised at the power p).	O	O	Review	176
They also propose a gradient based attention (derivative of the Loss w.r.t.inputs).	O	O	Review	176
<sep> <sep> They evaluate their approaches on several datasets (CIFAR, Cub/Scene, Imagenet) showing that attention transfers  does help improving the student network test performance.	O	O	Review	176
However, the student networks performs worst than the teacher, even with attention.	O	O	Review	176
<sep> <sep> Few remarks/questions:	O	O	Review	176
- in section 3 authors  claim that networks with higher accuracy have a higher spatial correlation between the object and the attention map.	B-Review	B-1	Review	176
While Figure 4 is compelling, it would be nice to have quantitative results showing that as well.	I-Review	I-1	Review	176
<sep> - how did you choose the hyperparameter values, it would be nice to see what is the impact of.	B-Review	B-2	Review	176
<sep> - it would be nice to report teacher train and validation loss in Figure 7 b)	B-Review	B-3	Review	176
- from the experiments, it is not clear what at the pros/cons of the different attention maps	B-Review	B-4	Review	176
- AT does not lead to better result than the teacher.	B-Review	B-5	Review	176
However, the student networks have less parameters.	I-Review	I-5	Review	176
It would be interesting to characterise the corresponding speed-up.	I-Review	I-5	Review	176
If you keep the same architecture between the student and the teacher, is there any benefit to the attention transfer?	I-Review	I-5	Review	176
<sep> <sep> In summary:	O	O	Review	176
Pros:	O	O	Review	176
- Clearly written and well motivated.	O	O	Review	176
<sep> - Consistent improvement of the student with attention compared to the student alone.	O	O	Review	176
<sep> Cons:	O	O	Review	176
- Students have worst performances than the teacher models.	B-Review	B-8	Review	176
<sep> - It is not clear which attention to use in which case?	B-Review	B-7	Review	176
<sep> - Somewhat incremental novelty relatively to Fitnet	B-Review	B-6	Review	176
<sep> Dear Reviewer,	O	O	Reply	176
<sep> Below are our answers:	O	O	Reply	176
<sep> Q: in section 3 authors claim that networks with higher accuracy have a higher spatial correlation between the object and the attention map.	O	O	Reply	176
While Figure 4 is compelling, it would be nice to have quantitative results showing that as well.	O	O	Reply	176
<sep> A: Thanks for the suggestion.	B-Reply	B-1	Reply	176
We are going to try to look into how to do that for the VOC or COCO dataset.	I-Reply	I-1	Reply	176
However, it should be noted that this is in fact a not so trivial task (e.g., due to the need of bounding box or segmentation mask annotations, due to the need to deal with overlapping objects etc.)	I-Reply	I-1	Reply	176
<sep> <sep> Q: how did you choose the hyperparameter values, it would be nice to see what is the impact of.	O	O	Reply	176
<sep> A: We found our method to be quite stable with respect to different values of beta, i.e. in all our experiments we observed that there‚Äôs typically a wide range of values which give improvements close to optimal;	B-Reply	B-2	Reply	176
<sep> Q: it would be nice to report teacher train and validation loss in Figure 7 b)	O	O	Reply	176
A: Thanks, we are going to add this;	B-Reply	B-3	Reply	176
<sep> Q: from the experiments, it is not clear what at the pros/cons of the different attention maps	O	O	Reply	176
A: We are currently running attention transfer experiments using grad-based and activation-based attention maps under the same conditions, and going to update the paper as soon as we have the results;	B-Reply	B-4	Reply	176
<sep> Q: AT does not lead to better result than the teacher.	O	O	Reply	176
However, the student networks have less parameters.	O	O	Reply	176
It would be interesting to characterise the corresponding speed-up.	O	O	Reply	176
If you keep the same architecture between the student and the teacher, is there any benefit to the attention transfer?	O	O	Reply	176
<sep> A: The baselines we choose have very different numbers of parameters, thus making it very difficult for student to have better or even the same accuracy as teacher, as network performance largely depends on this number.	B-Reply	B-5	Reply	176
This was shown in a number of recent works, including our Wide ResNet paper.	I-Reply	I-5	Reply	176
It can be shown though that AT leads to drastic improvements in speed and number of parameters needed to achieve the same accuracy.	I-Reply	I-5	Reply	176
For example, to achieve 7.5% on CIFAR-10 one would need a ResNet with 300k (e.g. WRN-16-1.3) parameters, whereas AT+KD achieves it with only 160k parameters, resulting in about 2x less parameters and a much more efficient network;	I-Reply	I-5	Reply	176
Q: Somewhat incremental novelty relatively to Fitnet	O	O	Reply	176
A: We would like to note that one main goal/contribution of this work is to convey the idea that the use of attention transfer during training can be an important factor for improving a network‚Äôs performance.	B-Reply	B-6	Reply	176
In a case like this, the student is forced to mimic only a small ‚Äúsummary‚Äù of the teacher‚Äôs data, as opposed to FitNets that try to mimic the full activation maps.	I-Reply	I-6	Reply	176
Yet we show that our method achieves much better results, which we consider as a very interesting finding.	I-Reply	I-6	Reply	176
<sep> Thanks.	O	O	Reply	176

The paper describes a VAE-based approach to semi-supervised learning	O	O	Review	176
of dependency parsing.	O	O	Review	176
The encoder in the VAE is a neural edge-factored	O	O	Review	176
parser allowing inference using Eisner's dynamic programming algorithms.	O	O	Review	176
<sep> The decoder generates sentences left-to-right, at each point conditioning	O	O	Review	176
on head-modifier dependencies specified by the tree.	O	O	Review	176
A key technical	O	O	Review	176
step is to develop a method for "differentiable" sampling/parsing,	O	O	Review	176
using a modification of the dynamic program, and the Gumbel-max trick.	O	O	Review	176
<sep> <sep> I thought this was an excellent paper - very clear, an important	O	O	Review	176
problem, a very useful set of techniques and results.	O	O	Review	176
I would strongly	O	O	Review	176
recommend acceptance.	O	O	Review	176
<sep> <sep> Some comments:	O	O	Review	176
<sep> * I do wonder how well this approach would work with orders of magnitude	B-Review	B-1	Review	176
more unlabeled data.	I-Review	I-1	Review	176
The amount of unlabeled data used is quite small.	I-Review	I-1	Review	176
<sep> <sep> * Similarly, I wonder how well the approach works as the amount of	B-Review	B-2	Review	176
unlabeled data is decreased (or increased, for that matter).	I-Review	I-2	Review	176
It should	I-Review	I-2	Review	176
be possible to provide graphs showing this.	I-Review	I-2	Review	176
<sep> <sep> * Are there natural generalizations to multi-lingual data, for example	B-Review	B-3	Review	176
settings where supervised data is only available for languages other	I-Review	I-3	Review	176
than the language of interest?	I-Review	I-3	Review	176
<sep> <sep> * It would be interesting to see an analysis of accuracy improvements	B-Review	B-4	Review	176
on different dependency labels.	I-Review	I-4	Review	176
The "root" case is in some sense just	I-Review	I-4	Review	176
one of the labels (nsubj, dobj, prep, etc.)	I-Review	I-4	Review	176
that could be analyzed.	I-Review	I-4	Review	176
<sep> <sep> * I wonder also if this method would be particularly helpful in	B-Review	B-5	Review	176
domain transfer, for example from Wall Street Journal text to	I-Review	I-5	Review	176
Wikipedia or Web data in general.	I-Review	I-5	Review	176
The improvements could be more	I-Review	I-5	Review	176
dramatic in this case - that kind of effect has been seen with	I-Review	I-5	Review	176
ELMO for example.	I-Review	I-5	Review	176
Many thanks for the positive feedback and suggestions.	O	O	Reply	176
<sep> <sep> >  Varying amounts of unlabeled data	O	O	Reply	176
<sep> We will do our best to include these results in a subsequent revision.	B-Reply	B-1	Reply	176
Using more unlabeled data is harder for Swedish and French, as we would need to re-tokenize in the form consistent with our labeled data.	I-Reply	I-1	Reply	176
<sep> <sep> <sep> > Are there natural generalizations to multi-lingual data  for example settings where supervised data is only available for languages other than the language of interest?	O	O	Reply	176
<sep> <sep> This is a very interesting direction.	B-Reply	B-3	Reply	176
We hope that using ‚Äòunlabeled‚Äô and ‚Äòlabeled‚Äô terms in the objective would make the multilingual model capture correspondences between surface regularities and the underlying syntax, for a given language.	I-Reply	I-3	Reply	176
This should be especially helpful in the suggested one-shot learning scenario, where only unlabeled term will present for the target language.	I-Reply	I-3	Reply	176
We suspect that part-of-speech tags (not currently used in our model) would be needed to facilitate learning the cross-lingual correspondences.	I-Reply	I-3	Reply	176
<sep> <sep> <sep> > I wonder also if this method would be particularly helpful in domain transfer	O	O	Reply	176
<sep> Yes, we would like to look into this in the future work.	B-Reply	B-5	Reply	176
<sep> <sep> <sep> > It would be interesting to see an analysis of accuracy improvementson different dependency labels.	O	O	Reply	176
<sep> <sep> We performed analysis on English, there are some interesting cases:	B-Reply	B-4	Reply	176
1.	I-Reply	I-4	Reply	176
Multi-word expressions: the recall / precision scores of the semi-supervised model are 90.70 / 84.78 while the one of the supervised model are 75.58 / 81.25.	I-Reply	I-4	Reply	176
We suspect that the reason is that MWEs are relatively infrequent.	I-Reply	I-4	Reply	176
<sep> 2.	O	O	Reply	176
Adverbial modifiers: we observe an increase in precision without compromising on recall: 87.32 / 87.51 versus 87.27 / 85.95.	B-Reply	B-4	Reply	176
<sep> 3.	O	O	Reply	176
Appositional modifiers: we also observe a significant increase for the recall in this  category: 81.39 / 81.03 versus 77.49 / 80.27	B-Reply	B-4	Reply	176
We included the results in the new version of the paper.	O	O	Reply	176

[Summary]	O	O	Review	176
This paper proposes to do semi-supervised learning , via a generative model, of an arc-factored dependency parser by using  amortized variational inference.	O	O	Review	176
The parse tree is the latent variable, the parser is the encoder that maps a sentence to a distribution over parse-trees, and the decoder is a generative model that maps a parse tree to a distribution over sentences.	O	O	Review	176
<sep> [Pros]	O	O	Review	176
Semi-supervised learning for dependency parsing is both important and difficult and this paper presents a novel approach using variational auto-encoders.	O	O	Review	176
And the semi-supervised learning method in this paper gives a small but non-zero improvement over a reasonably strong baseline.	O	O	Review	176
<sep> <sep> [Cons]	O	O	Review	176
1.	O	O	Review	176
My main concern with this paper currently are the "explanations" provided in the paper which are quite hand-wavy.	B-Review	B-1	Review	176
E.g. the authors state that using a KL term in semi-supervised learning is exactly opposite to the "low density separation assumption".	I-Review	I-1	Review	176
And therefore they set the KL term to be zero.	I-Review	I-1	Review	176
One has to wonder that why is the "low density separation assumption" so critical for dependency parsing only?	I-Review	I-1	Review	176
VAEs have been used with a prior for semi-supervised learning before, why didn't this assumption affect those models ?	I-Review	I-1	Review	176
<sep> <sep> A better explanation will have been that since the authors first trained the parser in a supervised fashion, therefore their inference network already represents a "good" distribution over parses, even though this distribution is specified only upto sampling but not in a mathematically closed form.	I-Review	I-1	Review	176
Finally, setting the KL divergence between the posterior of the inference network and the prior to be zero is the same as dynamically specifying the prior to be the same as the inference network's distribution.	I-Review	I-1	Review	176
<sep> 2.	O	O	Review	176
A number of important details are missing in the submitted version of the paper which the authors addressed in their reply to my public comment.	B-Review	B-2	Review	176
<sep> <sep> 3.	O	O	Review	176
The current paper does not contain any comparison to self-training which is a natural baseline for this work.	B-Review	B-3	Review	176
The authors replied to my comment saying that self-training requires a number of heuristics but it's not clear to me how much more difficult can these heuristics be than the tuning required for training their VAE.	I-Review	I-3	Review	176
Thank you for your suggestions and the positive feedback.	O	O	Reply	176
<sep> <sep> > hand-wavy explanations	O	O	Reply	176
<sep> We toned down our speculation, and incorporated your suggestions.	B-Reply	B-1	Reply	176
Please let us know if you think, we could improve this further.	I-Reply	I-1	Reply	176
<sep> <sep> >  A number of important details are missing in the submitted version of the paper which the authors addressed in their reply to my public comment.	O	O	Reply	176
<sep> <sep> <sep> The submission has now been updated, reflecting what we described in our public comment.	B-Reply	B-2	Reply	176

This paper proposed a variational autoencoder-based method for semi-supervised dependency parsing.	O	O	Review	176
Given an input sentence s, an LSTM-based encoder generates a sentence embedding z, and a NN of Kiperwasser & Goldberg (2016) generates a dependency structure T. Gradients over the tree encoder are approximated by (1) adding a perturbation matrix over the weight matrix and (2) relax dynamic programming-based parsing algorithm to a differentiable format.	O	O	Review	176
The decoder combines standard LSTM and Graph Convolutional Network to generate the input sentence from z and T. The authors evaluated the proposed method on three languages, using 10% of the original training data as labeled and the rest as unlabeled data.	O	O	Review	176
<sep> <sep> Pros	O	O	Review	176
1.	O	O	Review	176
I like the idea of this sentence->tree->sentence autoencoder for semi-supervised parsing.	O	O	Review	176
The authors proposed a novel and nice way to tackle key challenges in gradient computation.	O	O	Review	176
VAE involves marginalization over all possible dependency trees, which is computationally infeasible, and the proposed method used a Gumbel-Max trick to approximate it.	O	O	Review	176
The tree inference procedure involves non-differentiable structured prediction, and the authors used a peaked-softmax method to address the issue.	O	O	Review	176
The whole model is fully differentiable and can be thus trained end to end.	O	O	Review	176
<sep> <sep> 2.	O	O	Review	176
The direction of semi-supervised parsing is useful and promising, not only for resource-poor languages, but also for popular languages like English.	O	O	Review	176
A successful research on this direction could be potentially helpful for lots of future work.	O	O	Review	176
<sep> <sep> Cons, and suggestions on experiments	O	O	Review	176
My main concerns are around experiments.	O	O	Review	176
Overall I think they are not strong enough to demonstrate that this paper has sufficient contribution to semi-supervised parsing.	O	O	Review	176
Below are details.	O	O	Review	176
<sep> <sep> 1.	O	O	Review	176
The current version only used 10% of original training data as labeled and the rest as unlabeled data.	B-Review	B-1	Review	176
This makes the reported numbers way below existing state-of-the-art performance.	I-Review	I-1	Review	176
For example, the SOTA UAS on English PTB has been >95%.	I-Review	I-1	Review	176
Ideally, the authors should be able to train a competitive supervised parser on full training data (English or other languages), and get huge amount of unlabeled data from other sources (e.g. News) to further push up the performance.	I-Review	I-1	Review	176
The current setting makes it hard to justify how useful the proposed method could be in practice.	I-Review	I-1	Review	176
<sep> <sep> 2.	O	O	Review	176
The best numbers from the proposed model is lower than baseline (Kipperwasser & Goldberg) on English, and only marginally better on Swedish.	B-Review	B-2	Review	176
This probably means the supervised baseline is weak, and it's hard to tell if the gains from VAE will retain if applied to a stronger supervised.	I-Review	I-2	Review	176
<sep> <sep> 3.	O	O	Review	176
A performance curve with different amount of labeled and unlabeled data would be useful to better understand the impact of semi-supervised learning.	B-Review	B-3	Review	176
<sep> <sep> 4.	O	O	Review	176
What's the impact of perturbation?	B-Review	B-4	Review	176
One could simply use T=Eisner(W) as approximation.	I-Review	I-4	Review	176
Did you observe any significant benefits from sampling?	I-Review	I-4	Review	176
<sep> <sep> Other questions	O	O	Review	176
1.	O	O	Review	176
What's the impact of keeping the tree constraint on dependencies during backpropagation?	B-Review	B-5	Review	176
Have you tried removing the tree constraint like previous work?	I-Review	I-5	Review	176
<sep> <sep> 2.	O	O	Review	176
Are sentence embedding and trees generated from two separate LSTM encoders?	B-Review	B-6	Review	176
Are there any parameter sharing between the two?	I-Review	I-6	Review	176
<sep> <sep> <sep> Thank you for your comments and for finding the method novel and interesting.	O	O	Reply	176
<sep> <sep> We would like first to clarify that we are not making claiming that our method is appropriate in the high resource scenario (i.e. full in-domain English PTB parsing).	B-Reply	B-1	Reply	176
However, large datasets are available only for a few languages, so the lower resource setting we study here is important and common.	I-Reply	I-1	Reply	176
We use a sufficiently strong baseline (e.g., already using external word embeddings) and obtain improvements across all 3 languages.	I-Reply	I-1	Reply	176
Interestingly, we observe that there are certain phenomena which our semi-supervised parser captures considerably more accurately than the baseline model (e.g., long distance dependencies and multi-word expression, see reply to R1).	I-Reply	I-1	Reply	176
Very few studies have been done for semi-supervised structured prediction with  neural generative models, especially for the more challenging parsing task, so we think these results are interesting.	I-Reply	I-1	Reply	176
<sep> <sep> We also think that our differentiable perturb-and-parse operator is interesting on its own, and has other potential applications.	B-Reply	B-1	Reply	176
For example, it could be used in the context of latent structure induction, where there is no supervision (i.e. no treebank).	I-Reply	I-1	Reply	176
Our sampling technique has properties which are different from those of previously proposed latent induction methods:	I-Reply	I-1	Reply	176
- unlike structured attention [4], we sample global structures rather than compute marginals (e.g., we preserve higher-order statistics)	I-Reply	I-1	Reply	176
- unlike SPIGOT [2], we can impose tree constraints directly rather than compute an approximation	I-Reply	I-1	Reply	176
- unlike us, [3] relies on sparse distributions so that marginalization is feasible.	I-Reply	I-1	Reply	176
While sparse distributions have many interesting properties, they yield flat areas in the optimization landscape that can be difficult to escape from.	I-Reply	I-1	Reply	176
<sep> - unlike sampling with shift-reduce parsing models,  we do not seem to have issues with bias which was argued to negatively affect its results [1].	I-Reply	I-1	Reply	176
<sep> <sep> > A performance curve with different amount of labeled and unlabeled data	O	O	Reply	176
<sep> We will do our best to include these results in a subsequent revision.	B-Reply	B-3	Reply	176
Using more unlabeled data is harder for Swedish and French, as we would need to re-tokenize in the form consistent with our labeled data.	I-Reply	I-3	Reply	176
<sep> <sep> <sep> > What's the impact of perturbation?	O	O	Reply	176
<sep> <sep> In our experiments, using sampling is beneficial so that improvements are consistent across languages.	B-Reply	B-4	Reply	176
For example, UAS results in French for the model that does not us sentence embeddings are as follows:	I-Reply	I-4	Reply	176
- supervised: 84.09	I-Reply	I-4	Reply	176
- semi-supervised without sampling: 84.27	I-Reply	I-4	Reply	176
- semi-supervised with sampling: 84.69	I-Reply	I-4	Reply	176
<sep> <sep> > What's the impact of keeping the tree constraint on dependencies during backpropagation?	O	O	Reply	176
<sep> <sep> We thought that the main motivation for dropping the constraint in previous work (e.g., SPIGOT) was efficiency.	B-Reply	B-5	Reply	176
Since it does not seriously affect computation cost in our approach, we have not experimented with dropping it.	I-Reply	I-5	Reply	176
<sep> <sep> <sep> >  Are sentence embedding and trees generated from two separate LSTM encoders?	O	O	Reply	176
<sep> <sep> Yes.	B-Reply	B-6	Reply	176
There are no shared parameters in our model: the LSTM of the parser, the LSTM generating the sentence embeddings and the decoder are all separate.	I-Reply	I-6	Reply	176
Introducing parameter sharing would likely be beneficial.	I-Reply	I-6	Reply	176
However, our set-up is more controlled, as we can make sure that the improvements are due to modeling latent syntactic structure rather than getting better word representations (i.e. from using the multi-task learning objective).	I-Reply	I-6	Reply	176
<sep> <sep> <sep> <sep> [1] Andrew Drozdov and Samuel Bowman, The Coadaptation Problem when Learning How and What to Compose (2nd Workshop on Representation Learning for NLP, 2017)	O	O	Reply	176
[2] Hao Peng, Sam Thomson and Noah Smith, Backpropagating through Structured Argmax using a SPIGOT (ACL 2018)	O	O	Reply	176
[3] Vlad Niculae, Andr√© Martins and Claire Cardie, Towards Dynamic Computation Graphs via Sparse Latent Structure (EMNLP 2018)	O	O	Reply	176
[5] Yoon Kim, Carl Denton, Luong Hoang and Alexander Rush, Structured Attention Networks (ICLR 2017)	O	O	Reply	176

Strong paper in the direction of a more biologically plausible solution for the weight transport problem, where the forward and the backward weights need to be aligned.	O	O	Review	176
Earlier work for feedback alignment has included methods such as hard-coding sign symmetry.	O	O	Review	176
In this method, the authors show that a piece-wise linear model of the feedback as a function of the input given to a neuron can estimate the causal effect of a spike on downstream neurons.	O	O	Review	176
The authors propose a learning rule based on regression discontinuity design (RDD) and show that this leads to stronger alignment of weights (especially in earlier layers) compared to previous methods.	O	O	Review	176
The causal effect is measured directly from the discontinuity introduced while spiking - the difference between the outputs of the estimated piece-wise linear model at the point of discontinuity is used as the feedback.	O	O	Review	176
Compared to feedback alignment, RDD-based pre-training demonstrates stronger alignment between forward and backward weights and better performance on CIFAR-10 and Fashion-MNIST datasets.	O	O	Review	176
Overall, the paper is very well written and addresses an important problem.	O	O	Review	176
The theoretical foundation, to my knowledge, is well studied.	O	O	Review	176
Thank you for your comments!	O	O	Reply	176

summary	O	O	Review	176
<sep> This paper considers the "weight transport problem" which is the problem of ensuring that the feedforward weights is the same as the feedback weights in the spiking NN model of computation.	O	O	Review	176
This paper proposes a novel learning method for the feedback weights which depends on accurately estimating the causal effect of any spiking neuron on the other neurons deeper in the network.	O	O	Review	176
Additionally, they show that this method also minimizes a natural cost function.	O	O	Review	176
They run many experiments on FashionMNIST and CIFAR-10 to validate this and also show that for deeper networks this approaches the accuracy levels of GD-based algorithms.	O	O	Review	176
<sep> <sep> <sep> <sep> comments	O	O	Review	176
<sep> Overall I find this paper to be well-written and _accessible_ to someone who is not familiar with the biologically plausible learning algorithms.	O	O	Review	176
To overcome the massive computational burden, they employ a novel experimental setup.	O	O	Review	176
In particular, they use a separate non-spiking neural network to train the feedforward weights and use the spiking neurons only for alignment of weights.	O	O	Review	176
They have experimental evidence to show that this method is a legitimate workaround.	O	O	Review	176
I find their experimental setup and the results convincing to the best of my knowledge.	O	O	Review	176
The experimental results indeed show the claim that the proposed algorithm has the properties stated earlier (i.e., learns the feedback weights correctly and that using this to train deep neural nets provide better performance than weight alignment procedure).	B-Review	B-2	Review	176
I must warn that I am not an expert in this area and thus, might miss some subtleties.	I-Review	I-2	Review	176
Given this, it is also unclear to me why this problem is important and thus, would leave the judgement of this to other reviewers.	I-Review	I-2	Review	176
Here I will score only based on the technical merit of the method used to solve the problem.	I-Review	I-2	Review	176
<sep> <sep> I had one minor comment on the arrangement of the writing of the paper.	B-Review	B-1	Review	176
Section 4 starts off with "Results" but the earlier sub-sections are not really about the results.	I-Review	I-1	Review	176
I would split section 4 as methodology/algorithm and include the everything until section 4.4.	I-Review	I-1	Review	176
From sub section 4.5 onwards are the actual results.	I-Review	I-1	Review	176
<sep> <sep> <sep> overall decision	O	O	Review	176
<sep> Without commenting on the importance of this problem, I think this paper merits an acceptance based on the technical content.	O	O	Review	176
The paper provides convincing experiments to test the properties the author claim the new algorithm has.	O	O	Review	176
"I had one minor comment on the arrangement of the writing of the paper.	O	O	Reply	176
Section 4 starts off with "Results" but the earlier sub-sections are not really about the results.	O	O	Reply	176
I would split section 4 as methodology/algorithm and include the everything until section 4.4.	O	O	Reply	176
From sub section 4.5 onwards are the actual results."	O	O	Reply	176
<sep> <sep> Yes, we see your point.	B-Reply	B-1	Reply	176
We have split the materials into methods/results as requested.	I-Reply	I-1	Reply	176

The paper introduces a training mechanism for spiking neural nets that employs a causal inference technique, called RDD, for adjustment of backward spiking weights.	O	O	Review	176
This technique induces the backward influence strengths to be reciprocal to the forward ones, bringing desirable symmetry properties.	O	O	Review	176
<sep> <sep> Pros:	O	O	Review	176
* The relationship between causal inference and biologically plausible learning is very interesting.	O	O	Review	176
This relationship is also important and impactful for the machine learning community, as we are on the quest of new deep learning technologies.	O	O	Review	176
<sep> <sep> * Application of the RDD method to spiking neural net training is novel.	O	O	Review	176
The reciprocal relationship of the causal effect to the synaptic strength is a very intuitive and elegant solution to the weight transport problem.	O	O	Review	176
<sep> <sep> Cons:	O	O	Review	176
* From the reported results, it is not possible to decide whether RDD really outperforms Feedback Alignment (FA).	B-Review	B-1	Review	176
The comparison is performed on only two data sets and each algorithm is better on one.	B-Review	B-6	Review	176
Could the authors report results on at least two more data sets (however small or simple) during the rebuttal?	I-Review	I-6	Review	176
<sep> <sep> * Fig and Table 1 report the same outcome.	B-Review	B-2	Review	176
One of the two need to be removed.	I-Review	I-2	Review	176
<sep> <sep> Further Questions:	O	O	Review	176
* The Conv Net illustrated in Fig 2 panel A shares its weights with the biologically plausible net on panel B. Further, these two nets communicate for pre-training.	B-Review	B-3	Review	176
How does the paper then isolate the contribution of the biologically plausible net to the prediction accuracy from the vanilla ConvNet?	I-Review	I-3	Review	176
What would happen if we trained only the LIF net without a contact with the conv net?	I-Review	I-3	Review	176
<sep> <sep> * Eq.1 proposes induction of symmetry to solve the weight transform.	B-Review	B-4	Review	176
At the extreme, this regularizer would make W and Y identical, boiling down to  a vanilla artificial neural net, which the ML community already knows wella nd performs with excellence.	I-Review	I-4	Review	176
Would not having the biologically  implausible artificial neural model as the extreme solution contradict with the goal of biologically plausible learning?	I-Review	I-4	Review	176
This would in the end make one conclude that the biological brain only performs a broken gradient descent.	I-Review	I-4	Review	176
<sep> <sep> Overall, this is a decent piece of work with some potential.	O	O	Review	176
My initial vote is a weak reject, as I  am at present missing sufficient evidence that the improved symmetry properties introduced by the causal inference scheme also brings an accuracy improvement over the vanilla feedback alignment method.	B-Review	B-1	Review	176
I am open to improve to an accept if this evidence is provided and my aforementioned concerns primarily on the role of ConvNet are properly addressed during rebuttal.	O	O	Review	176
<sep> <sep> <sep> --	O	O	Review	176
Post-rebuttal: My only major concern was the lack of sufficient empirical evidence to support the idea.	B-Review	B-5	Review	176
The updated version of the manuscript has properly addressed this issue by reporting results on additional data sets.	I-Review	I-5	Review	176
The authors have also given enlightening clarifications to some of the open points I have raised earlier.	I-Review	I-5	Review	176
Hence, I'm happy to increase my score.	O	O	Review	176
"From the reported results, it is not possible to decide whether RDD really outperforms Feedback Alignment (FA).	O	O	Reply	176
The comparison is performed on only two data sets and each algorithm is better on one."	O	O	Reply	176
<sep> We are afraid that we must have been unclear in the original submission, so thank you for raising this.	B-Reply	B-1	Reply	176
To clarify, RDD performs better than FA on all of the datasets we have investigated to date.	I-Reply	I-1	Reply	176
<sep> <sep> "Could the authors report results on at least two more data sets (however small or simple) during the rebuttal?"	O	O	Reply	176
<sep> <sep> This is a very valid request, and we are happy to oblige.	B-Reply	B-6	Reply	176
We have no also tested on the SVHN and VOC datasets.	I-Reply	I-6	Reply	176
RDD outperforms FA on both datasets (see updated Figure 5).	I-Reply	I-6	Reply	176
<sep> <sep> "Fig and Table 1 report the same outcome.	O	O	Reply	176
One of the two need to be removed."	O	O	Reply	176
<sep> <sep> Fair point, we have removed Table 1, and provide both training and testing results in Figure 5 now.	B-Reply	B-2	Reply	176
<sep> <sep> "The Conv Net illustrated in Fig 2 panel A shares its weights with the biologically plausible net on panel B. Further, these two nets communicate for pre-training.	O	O	Reply	176
How does the paper then isolate the contribution of the biologically plausible net to the prediction accuracy from the vanilla ConvNet?	O	O	Reply	176
What would happen if we trained only the LIF net without a contact with the conv net?"	O	O	Reply	176
<sep> <sep> We now see that we were insufficiently clear in the original submission, so again, thank you for raising this.	B-Reply	B-3	Reply	176
The interaction between the ConvNet and the LIF net is as follows: the two networks share weights, but the ConvNet is used for training the feedforward weights and measuring accuracy, while the LIF net is only for training the feedback weights.	I-Reply	I-3	Reply	176
More specifically, on each epoch, we train the feedforward weights with the ConvNet, using the current setting of the feedback weights.	I-Reply	I-3	Reply	176
This means that the transpose of the feedforward weights in the usual gradient update term is replaced with the current feedback weights.	I-Reply	I-3	Reply	176
Then, we transfer the new feedforward weights from the ConvNet to the LIF net, and we train only the feedback weights.	I-Reply	I-3	Reply	176
This continues: the feedback weights of the ConvNet are set to the new values from the LIF net, and so on.	I-Reply	I-3	Reply	176
Thus, the LIF net is not learning to categorize the images, it is only learning the feedback weights, which get used by the ConvNet for the feedforward training.	I-Reply	I-3	Reply	176
We have clarified this in the text and Figure 2A. We do this because our goal in this paper is simply to test the RDD algorithm's ability to learn good feedback weights, not to test the ability of an LIF net to perform categorization.	I-Reply	I-3	Reply	176
<sep> <sep> "Eq.1 proposes induction of symmetry to solve the weight transform.	O	O	Reply	176
At the extreme, this regularizer would make W and Y identical, boiling down to  a vanilla artificial neural net, which the ML community already knows well and performs with excellence.	O	O	Reply	176
Would not having the biologically  implausible artificial neural model as the extreme solution contradict with the goal of biologically plausible learning?	O	O	Reply	176
This would in the end make one conclude that the biological brain only performs a broken gradient descent."	O	O	Reply	176
<sep> <sep> The reviewer is correct that the symmetric alignment cost function would only be zero when perfect symmetry in weights is achieved.	B-Reply	B-4	Reply	176
The reviewer is also correct that this would indicate that biological networks were approximating gradient descent.	I-Reply	I-4	Reply	176
However, that is part of the point of this exercise.	I-Reply	I-4	Reply	176
To date, no one has demonstrated how one can achieve efficient credit assignment in large networks without at least a good correlation with the true gradient.	I-Reply	I-4	Reply	176
To be clear, we hypothesize that the brain may in fact have a means of estimating gradients, and that this would be achieved, in part, by ensuring symmetry between feedforward and feedback pathways.	I-Reply	I-4	Reply	176
That may not be a "broken" gradient descent, in so far as there can be regularizing advantages to not always perfectly following the gradient.	I-Reply	I-4	Reply	176
If the reviewer is interested in this perspective, they can read more in our recent review on the topic: Richards, et al Nature Neuroscience 22, no.	I-Reply	I-4	Reply	176
11 (2019): 1761-1770.	I-Reply	I-4	Reply	176

This paper applies the Gumbel-softmax to optimizing task-specific routing in deep multi-task learning.	O	O	Review	20282
Experiments demonstrate improvements of the method over no sharing or full sharing, and it is used to achieve s-o-t-a results in the Omniglot MTL benchmark.	O	O	Review	20282
<sep> <sep> Although the end results are good, and the approach is well-motivated, I am leaning to reject, because the experiments have not made clear when the method works and how it behaves.	O	O	Review	20282
The improvements over the full-sharing baselines appear fairly small, and in the analysis it appears the model is mainly discarding unneeded pooling layers.	B-Review	B-3	Review	20282
Is there some real task-specific routing that the method is able to take advantage of?	I-Review	I-1	Review	20282
Maybe an experiment where full-sharing is detrimental, i.e., because there are some highly unrelated tasks, would help to highlight how the approach selects appropriate module subsets for each task.	I-Review	I-1	Review	20282
E.g., what are the routing patterns in Section 6.1 that are the same within each pair of MNIST tasks, but different across task pairs?	B-Review	B-2	Review	20282
Is there a way to visualize differences between routing of different Omniglot tasks?	I-Review	I-2	Review	20282
<sep> <sep> Similarly, the experiment in Section 2 is interesting, but the conclusion that negative transfer exists is not novel.	B-Review	B-4	Review	20282
Is there a way to include the Gumbel approach in these synthetic experiments to show that it addresses this issue?	I-Review	I-4	Review	20282
E.g., something like the result in A.3 could be promoted to Section 2.	I-Review	I-4	Review	20282
More compelling synthetic datasets could be generated by the method in A.1.	I-Review	I-4	Review	20282
for the case where tasks are somewhat related, in which case we can actually see if how the sharing occurs.	I-Review	I-4	Review	20282
Could Gumbel see a bigger boost in these synthetic experiments if training data were limited and generalization was tested instead of training loss?	I-Review	I-4	Review	20282
<sep> <sep> We thank the reviewer for the valuable comments.	O	O	Reply	20282
We are open to any further suggestions for improving our paper.	O	O	Reply	20282
Our responses to specific comments are provided below.	O	O	Reply	20282
<sep> <sep> 1) Routing patterns for Omniglot	O	O	Reply	20282
<sep> For the Omniglot experiment, it was indeed the case that discarding unwanted pooling layers was one of the clearest trends learned by our method.	B-Reply	B-2	Reply	20282
However, as pointed out in the paper, there were still important differences in allocation patterns corresponding to different tasks.	I-Reply	I-2	Reply	20282
Specifically, we grouped the tasks based on the pattern (i.e. the concatenation of all binary routing matrices), and we found around 10 groups on average, while the number of tasks was 20.	I-Reply	I-2	Reply	20282
Notice that differences in patterns may result in arbitrarily large differences in outputs.	I-Reply	I-2	Reply	20282
<sep> <sep> 2) Routing patterns for MNIST	O	O	Reply	20282
<sep> In the case of no budget penalty, the routing commonly converged to the pattern of the following form: one pair of MNIST tasks would use all components (12 components, since there were 3 layers of 4 components each), while the other pair would use all but one component (11 components).	B-Reply	B-1	Reply	20282
Since MNIST and MNIST-rot are still highly related, this shows that the model preferred almost full sharing, except for dropping a single connection to allow for processing the first pair of tasks differently than the second.	I-Reply	I-1	Reply	20282
<sep> <sep> With budget penalty enabled, each pair would usually use three out of four components in each layer, exactly matching the budget of 75% active connections.	I-Reply	I-1	Reply	20282
Note that the resulting accuracy was the same with and without the budget penalty.	I-Reply	I-1	Reply	20282
<sep> <sep> 3) Magnitude of gains on Omniglot over the full-sharing baseline	O	O	Reply	20282
<sep> Even though the improvement on top of full sharing for Omniglot is not very large, full sharing is actually a pretty strong baseline; even stronger than previous SotA based on a sparse Mixture-of-Experts (P. Ramachandran et al, ICLR 2019).	B-Reply	B-3	Reply	20282
Our interpretation of this result is that in the case of limited data (Omniglot has very few samples per class), it is hard to learn task-specific routing without incurring an accuracy drop due to optimization difficulties.	I-Reply	I-3	Reply	20282
Since our routing method managed to learn task-conditioned routing and improve the accuracy, while the methods from previous works did not, we consider our Omniglot result to be a strong one.	I-Reply	I-3	Reply	20282
<sep> <sep> 4) Other comments	O	O	Reply	20282
<sep> We are happy to move the result from Appendix A.3 to Section 2, if that helps the paper.	B-Reply	B-4	Reply	20282
<sep> <sep> Also, the reviewer proposed considering the case of limited data and generalization.	I-Reply	I-4	Reply	20282
However, note that Omniglot might already be seen as such a case, and our experiments show that Gumbel-Matrix routing does produce solutions that generalize well.	I-Reply	I-4	Reply	20282

In many ways this work is well presented.	B-Review	B-1	Review	20282
However, I have major concerns regarding the novelty of the proposed method and the theoretical rationale for the key design choices.	I-Review	I-1	Review	20282
Although the authors do cite and discuss (Rosenbaum et al 2019), what is very much not clear to me is how the Gumbel-Matrix Routing proposed in this work differs from past work using the Gumbel Softmax within routing networks.	I-Review	I-1	Review	20282
It seems like past work even focused on using only the task for routing, so it is not clear to me how the approach here is really novel in comparison.	I-Review	I-1	Review	20282
Even if there is some distinction I am missing, the high level idea is clearly not that new.	I-Review	I-1	Review	20282
Additionally, there is not much theoretical discussion about what the Gumbel Softmax adds to routing networks.	I-Review	I-1	Review	20282
<sep> <sep> The bias/variance tradeoff of Gumbel Softmax / RELAX / REINFORCE was already highlighted in (Rosenbaum et al 2019).	B-Review	B-2	Review	20282
Can the performance of the model on the settings tested be attributed to this tradeoff?	I-Review	I-2	Review	20282
If so, would a RELAX model perform even better?	I-Review	I-2	Review	20282
Moreover, there is not much discussion of important implications of using the Gumbel Softmax trick in the context of routing.	I-Review	I-2	Review	20282
First, as the authors acknowledge, but don't really elaborate on, using the Gumbel Softmax means we must backprop through every possible routing choice in each layer.	I-Review	I-2	Review	20282
As a result, the Gumbel approach results in a large scaling of computation with the number of modules, limiting the applicability to more ambitious settings.	I-Review	I-2	Review	20282
Moreover, while a clear motivation of this work is eliminating interference between tasks, it is not really explained how Gumbel Softmax does this and how it compares to hard routing decisions in this respect.	I-Review	I-2	Review	20282
During backprop, the computation it very similar to mixtures of experts models, and should contain more interference than hard routing.	I-Review	I-2	Review	20282
Can you explicitly show that the shape of the Gumbel distribution results in less interference between modules during learning than the standard mixtures of experts softmax approach?	I-Review	I-2	Review	20282
<sep> <sep> Furthermore, (Rosenbaum et al 2019) found that a number of RL based models outperform Gumbel Softmax when routing on multi-task settings of CIFAR-100 and the Stanford Corpus of Implicatives.	B-Review	B-3	Review	20282
The authors do not provide any explanation for why this approach did not succeed in their settings.	I-Review	I-3	Review	20282
This also leads me to doubt how impressive the results presented here are as there is really not any apples to apples comparison with the same architecture and different routing decisions.	I-Review	I-3	Review	20282
In Tables 1 and 2 the best baseline is full sharing.	I-Review	I-3	Review	20282
This indicates to me that the performance difference with other cited baselines has to do with different architecture choices and not changes in the routing policy itself.	I-Review	I-3	Review	20282
The experiments can be much improved by discussing why past approaches to Gumbel based routing have failed and by thoroughly comparing to other methods for just the routing decisions with the same base architecture as done in prior work.	I-Review	I-3	Review	20282
Unfortunately, in its current form, there is not enough context provided for the community to understand the implications of the proposed approach in the submitted draft even though it achieves good performance.	I-Review	I-3	Review	20282
We thank the reviewer for the valuable comments.	O	O	Reply	20282
Our responses to specific comments are provided below.	O	O	Reply	20282
<sep> <sep> 1) Novelty of our method	O	O	Reply	20282
<sep> We agree that the Gumbel trick and the Gumbel-Softmax routing method is not new.	B-Reply	B-1	Reply	20282
In this work, we propose a new method for multi-task learning and not a new routing method.	I-Reply	I-1	Reply	20282
<sep> <sep> While Gumbel-based routing has been already applied to multi-task learning, we claim that our formulation (in its full form) is novel for the following reasons:	I-Reply	I-1	Reply	20282
- We learn flexible parameter sharing among tasks by learning binary allocation matrices indicating how each component is allocated to each task.	I-Reply	I-1	Reply	20282
This is in contrast to previous works, which typically consider routing with a sequence of decisions ‚Äúwhere to route‚Äù.	I-Reply	I-1	Reply	20282
We argue that our formulation is more natural for multi-task learning, as it provides an explicit way to control parameter sharing between tasks (depending on their relatedness).	I-Reply	I-1	Reply	20282
Right now we condition on the task id, but in the future we envision conditioning on task embeddings, which can better capture the relatedness of the tasks.	I-Reply	I-1	Reply	20282
<sep> - Moreover, we also introduced ways to regularize our method such as the budget penalty (see Section 4.4) that promotes sparsity of the allocation solution.	I-Reply	I-1	Reply	20282
<sep> <sep> Since the proposed method is a new method for multi-task learning (and not a new routing method), we argue that evaluating different routing solvers (such as REINFORCE or RELAX) goes beyond the scope of this work.	I-Reply	I-1	Reply	20282
However, it is a very interesting direction and it will definitely be the focus of our future work.	I-Reply	I-1	Reply	20282
As per reviewer‚Äôs suggestion, this may further improve the results.	I-Reply	I-1	Reply	20282
<sep> <sep> 2) Hard vs soft routing decisions	O	O	Reply	20282
<sep> Please note that our method does use hard decisions, since we use the Straight-Through variant of the Gumbel-Softmax trick (the original Gumbel-Softmax paper introduces both the soft variant, and the Straight-Through variant).	B-Reply	B-2	Reply	20282
If a connection is sampled to be inactive, the corresponding component will not contribute to the output and therefore will not get gradients.	I-Reply	I-2	Reply	20282
It will only be used to compute the gradient for the per-connection routing probability.	I-Reply	I-2	Reply	20282
<sep> <sep> 3) Comparing apples to apples	O	O	Reply	20282
<sep> We believe that the Omniglot experiment is an apples-to-apples comparison, since we re-used the same architecture that achieved the previous SotA (‚ÄúDiversity and Depth in Per-Example Routing Models‚Äù, ICLR 2019).	B-Reply	B-3	Reply	20282
We made sure that we reproduced all the details by contacting the authors of that prior work; we also used the same regularization strategies and the same optimizer.	I-Reply	I-3	Reply	20282
The only difference is the routing method.	I-Reply	I-3	Reply	20282
<sep> <sep> 4) Scalability	O	O	Reply	20282
<sep> It is indeed the case that due to the use of Gumbel-Softmax, the backward pass needs to activate all of the components of the model.	B-Reply	B-3	Reply	20282
Hence, the training phase of our method is more expensive than for other sparse baselines (such as the sparsely-gated mixture-of-experts).	I-Reply	I-3	Reply	20282
<sep> However, it is important to note that inference phase of our method is pretty scalable, since it uses hard decisions (and the budget penalty promotes even sparser solutions).	I-Reply	I-3	Reply	20282
Therefore, we argue that our method is practical for many multi-task learning applications.	I-Reply	I-3	Reply	20282

The paper proposes to learn the routing matrix in routing networks for multi-task learning (MTL) using the gumbel softmax trick for binary random variables.	O	O	Review	20282
It makes the model amenable for training the network and the routing matrix simultaneously, which is a relatively easier and unified training procedure compared to the original routing networks.	O	O	Review	20282
The gumbel softmax trick technique is pretty standard.	O	O	Review	20282
The proposed method is evaluated on two MTL datasets with comparisons to baselines on one of them.	O	O	Review	20282
<sep> <sep> In terms of methodology, using gumbel trick for learning routing matrix seems new to my knowledge.	O	O	Review	20282
Although the trick has been applied to other problems and is used in a standard way.	O	O	Review	20282
I like the idea of using this trick to make the learning of routing network unified under optimization compared to the learning in the original routing network.	O	O	Review	20282
<sep> <sep> However, the experiments seem not extensive enough to demonstrate its superiority and efficiency.	B-Review	B-1	Review	20282
The method is only compared with other state of the art methods on one dataset.	I-Review	I-1	Review	20282
More experiments on various datasets and neural network architectures will be more convincing to me.	B-Review	B-4	Review	20282
I am also interested in how does the sparsity of the different routing models compare to each other?	I-Review	I-4	Review	20282
It would be unfair if some models trade performance for sparsity compared to the method proposed in this paper.	I-Review	I-4	Review	20282
Also it would be interesting to see how the learned routing matrix pattern could say something about the relatedness of different tasks.	I-Review	I-4	Review	20282
<sep> Regarding "full sharing", is it different tasks trained together with the same network?	B-Review	B-2	Review	20282
<sep> And another minor question for the experiments on MNIST, what are the accuracies for single task learning using same architecture?	B-Review	B-3	Review	20282
<sep> <sep> Overall, I find the idea of using gumbel trick for learning routing networks interesting.	O	O	Review	20282
However, I feel the experiments are not sufficient and I would encourage the authors to conduct more experiments and comparisons.	B-Review	B-1	Review	20282
<sep> <sep> We thank the reviewer for valuable comments and suggestions.	O	O	Reply	20282
Our responses to specific points are provided below.	O	O	Reply	20282
<sep> <sep> 1) Extensiveness of experiments	O	O	Reply	20282
<sep> While our method is compared with the SotA only on Omniglot, we also included several other experiments (MNIST, synthetic data), which were aimed at better understanding the behavior of our approach.	B-Reply	B-1	Reply	20282
We believe that these three lines of experiments together paint a relatively broad and convincing picture.	I-Reply	I-1	Reply	20282
<sep> <sep> 2) Sparsity of different routing methods	O	O	Reply	20282
<sep> We can control the sparsity level learned by our method by using the budget penalty, similarly to how it can be controlled in the sparse Mixture-of-Experts paper (P. Ramachandran et al, ICLR 2019) by varying the value of 'k'.	B-Reply	B-4	Reply	20282
<sep> <sep> For Omniglot, we do not use the budget penalty, so the learned solution is indeed not very sparse.	I-Reply	I-4	Reply	20282
The previous SotA based on a Mixture-of-Experts imposed a sparsity level of activating approximately 60% of connections, which is again not very sparse, although on average a little more than the solutions found by our method.	I-Reply	I-4	Reply	20282
However, note that this prior work did not mean to trade-off sparsity for accuracy, and neither did we; the other results reported for Omniglot are not sparse and not even based on routing.	I-Reply	I-4	Reply	20282
Therefore, results that we list in our paper (Table 2) include a variety of methods, none of which tried to trade-off accuracy for anything.	I-Reply	I-4	Reply	20282
We believe this constitutes a fair comparison.	I-Reply	I-4	Reply	20282
<sep> <sep> 3) Definition of different static sharing patterns	B-Reply	B-2	Reply	20282
<sep> ‚ÄúFull sharing‚Äù essentially means the shared bottom pattern i.e., all tasks share the same bottom layers and the latter are followed by task-specific heads.	I-Reply	I-2	Reply	20282
In our allocation matrix view, this corresponds to setting the matrix to be all ones (i.e. every task uses every component).	I-Reply	I-2	Reply	20282
<sep> <sep> ‚ÄúNo sharing‚Äù means that the network is divided, with each task getting to train a separate set of parameters.	I-Reply	I-2	Reply	20282
In particular, the reviewer asked about the single-task training for MNIST: the non-sharing pattern is essentially that, since each task gets to independently train 1/4 of the network.	I-Reply	I-2	Reply	20282

This paper focuses on deep reinforcement learning methods and discusses the presence of inductive biases in the existingRL algorithm.	O	O	Review	1522
Specifically, they discuss biases that take the form of domain knowledge or hyper-parameter tuning.	O	O	Review	1522
The authors state that such biases rise the tradeoff between generality and performance wherein strong biases can lead to efficient performance but deteriorate generalization across domains.	O	O	Review	1522
Further, it motivates that most inductive biases has a cost associated to it and hence it is important to study and analyze the effect of such biases.	O	O	Review	1522
<sep> <sep> To support their insights, the authors investigate the performance of well known actor-critic model in the Atari environment after replacing domain specific heuristics with the adaptive components.	O	O	Review	1522
The author considers two ways of injecting biases: i) sculpting agents objective and ii) sculpting agent's environment.	O	O	Review	1522
They show empirical evidence that replacing carefully designed heuristics to induce biases with more adaptive counterparts preserves performance and generalizes without additional fine tuning.	O	O	Review	1522
<sep> <sep> The paper focuses on an important concept and problem of inductive biases in deep reinforcement learning techniques.	O	O	Review	1522
<sep> Analysis of such biases and methods to use them judiciously is an interesting future direction.	O	O	Review	1522
The paper covers a lot of related work in terms of various algorithms and corresponding biases.	O	O	Review	1522
<sep> However, this paper only discusses such concepts at high level and provides short empirical evidences in a single environment to support their arguments.	B-Review	B-1	Review	1522
Further, both the heuristics used in practice and the adaptive counterparts that the paper uses to replace those heuristics are all available in existing approaches and there is no novel contribution in that direction too.	I-Review	I-1	Review	1522
<sep> Finally, the adaptive methods based on parallel environment and RNNs have several limitation, as per author's own admission.	B-Review	B-2	Review	1522
<sep> <sep> Overall, the paper does not have any novel technical contributions or theoretical analysis on the effect of such inductive biases which makes it very weak.	B-Review	B-3	Review	1522
Further, there is nothing surprising about the author's claims and many of the outcomes from the analysis are expected.	B-Review	B-4	Review	1522
The authors are recommended to consider this task more rigorously and provide stronger and concrete analysis on the effects of inductive biases on variety of algorithms and variety of environments.	I-Review	I-4	Review	1522
<sep> <sep> <sep> <sep> <sep> In addition to 3 grid-world domains (designed specifically to highlight specific properties of the inductive biases considered in the paper), we also provide extensive experiments at scale on 57 Atari games and 28 continuous control tasks.	B-Reply	B-3	Reply	1522
This is a larger set of non-trivial environments than in the vast majority of deep RL papers.	I-Reply	I-3	Reply	1522
Perhaps the reviewer interpreted the Atari experiments (on 57 games) as having been run on a single Atari game?	I-Reply	I-3	Reply	1522

This paper contains various numerical experiments to see the effects of some heuristics in reinforcement learning.	O	O	Review	1522
Those heuristics include reward clipping, discounting for effective learning, repeating actions, and different network structures.	O	O	Review	1522
However, since the training algorithms also greatly affect the performance of RL agents, it seems hard to draw any quantitive conclusions from this paper.	O	O	Review	1522
<sep> <sep> Detailed comments:	O	O	Review	1522
<sep> 1.	B-Review	B-1	Review	1522
It seems that actor-critic algorithms are defined for RL with function approximation.	I-Review	I-1	Review	1522
What is the tabular A2C algorithm?	I-Review	I-1	Review	1522
A reference in Section 3.1 would be better.	I-Review	I-1	Review	1522
<sep> <sep> 2.	O	O	Review	1522
This paper claims to study the "inductive biases", which is not clearly defined.	B-Review	B-2	Review	1522
How to quantify those biases and how to measure "generality"?	I-Review	I-2	Review	1522
<sep> <sep> 3.	O	O	Review	1522
Are there any quantitive conclusions that can be drawn from the experiments?	B-Review	B-3	Review	1522
<sep> <sep> 4.	O	O	Review	1522
Since the performance of RL agents also relies on initialization and the training algorithms.	B-Review	B-4	Review	1522
There are a lot of tricks of optimization for deep learning.	I-Review	I-4	Review	1522
How to measure the "inductive biases" by ruling out the effects of training algorithms?	I-Review	I-4	Review	1522
<sep> <sep> Some of the questions raised by the reviewer suggest that there may have been a misunderstanding of the term ‚Äúinductive bias‚Äù, possibly interpreted as referring to some form of statistical bias. ‚	B-Reply	B-2	Reply	1522
ÄúInductive Bias‚Äù is a well defined concept from the Machine Learning and Neuroscience literature and refers to the set of assumptions that go into a learning system (such as domain knowledge and heuristics).	I-Reply	I-2	Reply	1522
In the context of this paper we define and classify the various types of inductive biases under consideration in Section 2.	I-Reply	I-2	Reply	1522
<sep> <sep> Regarding how to measure "generality": in this paper we propose to measure the "generality" of an RL algorithm as the degree to which such algorithm can be ported to a different domain from the one it was proposed for, without forcing the practitioner to revisit the inductive biases that were incorporated in the original agent.	B-Reply	B-2	Reply	1522
Our experiments on Continuous Control show that adaptive solutions perform better in this respect than other heuristic inductive biases.	I-Reply	I-2	Reply	1522
<sep> <sep> As always, the Actor-Critic update in equation 2 of Section1 subsumes the tabular case, which can be seen by noting that in a tabular representation the gradient would only update the corresponding entry in the table.	B-Reply	B-1	Reply	1522

The paper presents and evaluates different common inductive biases in Deep RL.	O	O	Review	1522
These are systematically evaluated on different experimental settings.	O	O	Review	1522
<sep> <sep> The paper is easy to read and the authors explain well the setting and their findings.	O	O	Review	1522
The comparison and evaluations is well conducted and valuable contribution to the literature.	B-Review	B-1	Review	1522
I would have liked some more details on the motivating example in section 3.1, maybe with a figure supporting the explanation of the example.	I-Review	I-1	Review	1522
We thank the reviewer for the many positive comments.	O	O	Reply	1522
<sep> We will add a figure for each of the 3 motivating examples in the Appendix, thanks for the suggestion!	B-Reply	B-1	Reply	1522

This paper asks what is the role of pooling in the success story of CNNs applied to computer vision.	O	O	Review	982
<sep> Through several experimental setups, the authors conclude that, indeed, pooling is neither necessary nor sufficient to achieve deformation stability, and that its effect is essentially recovered during training.	O	O	Review	982
<sep> <sep> The paper is well-written, it is clear, and appears to be readily reproducible.	O	O	Review	982
It addresses an interesting and important question at the interface between signal processing and CNNs.	O	O	Review	982
<sep> <sep> That said, the paper does not produce any clear novel results.	B-Review	B-1	Review	982
It does not provide any theoretical result, nor any new algorithm.	I-Review	I-1	Review	982
Its contributions consist of three empirical studies, demonstrating that (i) the benefits of pooling in terms of deformation stability can be achieved through supervised learning the filters instead (sec 3), (ii) the mechanism to obtain stability through learning essentially consists on reducing the bandwidth of (some) filters (sec4), and (iii) that this mechanism is data-dependent (sec 5).	I-Review	I-1	Review	982
None of these studies strike the reviewer as particularly revealing.	I-Review	I-1	Review	982
Moreover, the reviewer felt that the authors could have built on those findings to ask (and hopefully answer) a few interesting questions, such as:	O	O	Review	982
-- Nowhere in the paper there is a discussion about critical Nyquist sampling and the need to reduce the bandwidth of a signal prior to downsampling it in order to avoid aliasing.	B-Review	B-2	Review	982
Average pooling provably does it, and learnt filters do it provided they indeed become bandlimited.	I-Review	I-2	Review	982
What are the links between deformation stability and the ability to avoid aliasing?	I-Review	I-2	Review	982
<sep> -- How many lowpass antialiasing filters are needed per layer to provide sufficient stability?	B-Review	B-3	Review	982
<sep> -- Also, the authors should relate this study with similar works that do the same in speech (e.g. <a href="https://www.isca-speech.org/archive/Interspeech_2018/abstracts/1371.html)."	B-Review	B-4	Review	982
target="_blank" rel="nofollow">https://www.isca-speech.org/archive/Interspeech_2018/abstracts/1371.html).</a>	I-Review	I-4	Review	982
<sep> In conclusion, my impression is that this paper requires a major iteration before it can be of widespread interest to the community.	O	O	Review	982
I encourage the authors to think about the above points.	O	O	Review	982
<sep> <sep> <sep> Thank you for your kind feedback about the writing and the importance of the question being addressed.	O	O	Reply	982
<sep> <sep> While we agree the results are not particularly surprising in retrospect, reading the literature on pooling, we have not seen learned smooth filters as a proposed mechanism for deformation stability and thought that these results may be of interest to the community trying to understand convolutional networks and deformation stability.	B-Reply	B-1	Reply	982
<sep> <sep> Further, we believe this work gives us an important bit of information on the topic of building inductive biases into architecture.	B-Reply	B-1	Reply	982
Our work shows that a common architectural decision (pooling), long believed to be helpful in conferring a particular inductive bias (stability to deformation) was not actually necessary and that the inductive bias built in was being ‚Äúoverridden‚Äù by the learning process.	I-Reply	I-1	Reply	982
<sep> <sep> Thank you for suggesting we discuss aliasing.	B-Reply	B-2	Reply	982
This indeed looks like an important direction in which to expand this work.	I-Reply	I-2	Reply	982
Also, thank you for pointing out the reference ‚ÄúImpact of Aliasing on Deep CNN-Based End-to-End Acoustic Models‚Äù, we were unaware of this work and it seems very relevant.	I-Reply	I-2	Reply	982

It is often argued that one of the roles of pooling is to increase the stability of neural networks to	O	O	Review	982
deformations.	O	O	Review	982
This paper presents empirical evidence to contest this assertion, or at least qualify it.	O	O	Review	982
<sep> <sep> I appreciate empirical studies that question some of the widely accepted dogmas of deep learning.	O	O	Review	982
<sep> From this point of view, the present paper is certainly interesting.	O	O	Review	982
<sep> <sep> Unfortunately, the actual evidence presented is quite weak, and insufficient to draw far reaching	B-Review	B-1	Review	982
conclusions.	I-Review	I-1	Review	982
An obvious objection is the authors only consider two datasets, and a very small number of	I-Review	I-1	Review	982
more or less standard pooling methodologies.	I-Review	I-1	Review	982
The effect of pooling is evaluated in terms of cosine	I-Review	I-1	Review	982
similarlity, which is not necessarily a good proxy for the actual performance of a network.	I-Review	I-1	Review	982
<sep> <sep> A more serious issue is that they seem to very readily jump to unwarranted conclusions.	B-Review	B-2	Review	982
For example,	I-Review	I-2	Review	982
the fact that stability to deformations (by which I necessarily mean the specific type of deformations	I-Review	I-2	Review	982
that they consider) tends to decrease in the middle layers of neural networks during training does not	I-Review	I-2	Review	982
mean that starting with a neural network with less stability would be better.	I-Review	I-2	Review	982
Maybe some kind of	I-Review	I-2	Review	982
spontaneous coarse-to-fine optimization is going on in the network.	I-Review	I-2	Review	982
Similarly, it is obvious that smoother	I-Review	I-2	Review	982
filters are going to lead to more stable representations.	I-Review	I-2	Review	982
However, they might be less good at discriminative	I-Review	I-2	Review	982
tasks.	I-Review	I-2	Review	982
Just because smoother filters are more stable does not automatically mean that they are more desirable.	I-Review	I-2	Review	982
<sep> <sep> Stability to deformations is an important but subtle topic in computer vision.	B-Review	B-3	Review	982
For starters, it is difficult	I-Review	I-3	Review	982
to define what kind of deformations one wants to be insensitive to in the first place.	I-Review	I-3	Review	982
A useful model would	I-Review	I-3	Review	982
likely incorporate some notion of deformations at multiple different length scales.	I-Review	I-3	Review	982
<sep> <sep> Just showing that one network is better than another wrt some arbitrarily defined simple class of deformations	B-Review	B-4	Review	982
with no reference to actual recognition performance, speed of training, or interpretation of the nature of	I-Review	I-4	Review	982
the deformations and the learned filters is not very convincing.	I-Review	I-4	Review	982
I would particularly like to emphasize the	I-Review	I-4	Review	982
last point.	I-Review	I-4	Review	982
I would really like to understand what pooling actually does, not just at the level of "if you	I-Review	I-4	Review	982
turn it off, then cosine similarity will decrease by this much or that much."	I-Review	I-4	Review	982
Thank you for your encouraging words regarding empirical studies that question some of the widely accepted dogmas of deep learning!	O	O	Reply	982
<sep> <sep> We wish to clarify a few points and ask of you to clarify some of your comments if possible:	O	O	Reply	982
<sep> ‚ÄúJust because smoother filters are more stable does not automatically mean that they are more desirable.	O	O	Reply	982
‚Äù	O	O	Reply	982
It seems that you concluded that we were claiming that more stability is always a desirable property.	B-Reply	B-2	Reply	982
We have not asserted this and in fact have highlighted that often stability is *reduced* over the course of training.	I-Reply	I-2	Reply	982
Further, as our title suggests, it is important not only to have ‚Äúmore deformation stability‚Äù but rather the ‚Äúappropriate deformation stability‚Äù.	I-Reply	I-2	Reply	982
<sep> In future we will try to make it clearer as to what we are asserting, and if you have any suggestions on how to improve this aspect we would greatly appreciate it.	I-Reply	I-2	Reply	982
<sep> <sep> ‚ÄúJust showing that one network is better than another wrt some arbitrarily defined simple class of deformations with no reference to actual recognition performance, speed of training, or interpretation of the nature of the deformations and the learned filters is not very convincing.	O	O	Reply	982
‚Äù	O	O	Reply	982
Could you please clarify what you meant by this sentence.	B-Reply	B-4	Reply	982
It is not clear what you think we are trying to convince you of when you say ‚Äúthis is not very convincing‚Äù.	I-Reply	I-4	Reply	982
<sep> You assert that class of deformations is arbitrary.	I-Reply	I-4	Reply	982
We spend the first few paragraphs of section 2.1 justifying the study of these deformations.	I-Reply	I-4	Reply	982
It would be helpful for us if you could explain why this class of deformations still arbitrary to you.	I-Reply	I-4	Reply	982
<sep> <sep> ‚ÄúI would really like to understand what pooling actually does.	O	O	Reply	982
‚Äù It would be really helpful to us if you could expand on this and clarify what you are asking here.	B-Reply	B-4	Reply	982

The work does an analysis of impact of different pooling strategies on image classification with deformations.	O	O	Review	982
It shows different pooling strategies reach to similar levels of deformation stability after sufficient training.	O	O	Review	982
It also offers an alternative technique with smoothness filters with to CNNs more stable.	O	O	Review	982
<sep> Pros:	O	O	Review	982
The paper considers a wide variety of pooling strategies and deformation techniques for evaluation.	O	O	Review	982
Fair experiments with conclusion of similar stability of different pool layers after training is very evident.	O	O	Review	982
<sep> Cons:	O	O	Review	982
i) Results on CIFAR 10 show pooling has little effect but is it unnecessary for harder problems as well?	B-Review	B-2	Review	982
What about human pose datasets where deformation is inherent?	I-Review	I-2	Review	982
<sep> iii) Although, the results presented on smoother filter initialization are interesting, but these results are not compared in a one to one setting to different pooling methods, convolutions or residual networks.	B-Review	B-5	Review	982
<sep> <sep> This paper tries to argue that pooling is unnecessary for deformation invariance, as title suggests, and proposes initialization based on smooth filters as an alternative.	B-Review	B-1	Review	982
Results are presented on CIFAR 10 to show the same, albeit on a trained network.	O	O	Review	982
However, CIFAR 10 is not a difficult dataset and the level of cosine sensitivity (shown as same with and without pooling) could very well be a steady state for the specific classification task.	B-Review	B-3	Review	982
Imagenet dataset doesn't seem to show ablative studies.	O	O	Review	982
So this little evidence is insufficient to conclude that pooling is unnecessary.	O	O	Review	982
Also as mentioned in the conclusion of the paper, the effect of pooling through the course of training would add more weight.	B-Review	B-4	Review	982
Thank you for your kind feedback.	O	O	Reply	982
<sep> <sep> ‚ÄúThis paper tries to argue that pooling is unnecessary for deformation invariance.	O	O	Reply	982
‚Äù	O	O	Reply	982
Perhaps we should have made this clearer in our writing, but our claim is not that pooling is *never* necessary.	B-Reply	B-1	Reply	982
Instead, our claim is that pooling is not *always* necessary and that there is an alternative mechanism that can lead to stability to deformation, namely smooth filters.	I-Reply	I-1	Reply	982
Further, we show that on very commonly studied tasks, this mechanism is at play.	I-Reply	I-1	Reply	982
Perhaps our choice of title lead to some confusion, but we were trying to say pooling is ‚Äúnot necessary‚Äù by which we meant ‚Äúnot required‚Äù rather than ‚Äúuneccessary‚Äù which seems to imply ‚Äúnever helpful‚Äù.	I-Reply	I-1	Reply	982
We believe these are the common uses of these terms but perhaps we should have chosen a different title or made our assertion clearer.	I-Reply	I-1	Reply	982
<sep> <sep> ‚ÄúResults on CIFAR 10 show pooling has little effect but is it unnecessary for harder problems as well?	O	O	Reply	982
What about human pose datasets where deformation is inherent?‚Äù	O	O	Reply	982
Thank you for this suggestion, this indeed is an interesting question.	B-Reply	B-2	Reply	982
However, at the same time, we do not believe this question needs to be answered to establish our main point in this paper.	I-Reply	I-2	Reply	982
Our point is NOT that pooling is never helpful.	I-Reply	I-2	Reply	982
Our point is that for tasks that benefit from deformation stability, it is possible to learn to be stable to deformation by learning smooth filters.	I-Reply	I-2	Reply	982
We also show that this mechanism is at play on two of the most commonly studied computer vision tasks in machine learning.	I-Reply	I-2	Reply	982
<sep> <sep> ‚Äúthe level of cosine sensitivity (shown as same with and without pooling) could very well be a steady state for the specific classification task.	O	O	Reply	982
‚Äù	O	O	Reply	982
It would be very helpful to us if you could expand on this statement.	B-Reply	B-3	Reply	982
Are you claiming that perhaps deformation stability is merely correlated with good performance at the end of training rather than causing it?	I-Reply	I-3	Reply	982
<sep> <sep> ‚ÄúAlso as mentioned in the conclusion of the paper, the effect of pooling through the course of training would add more weight.	O	O	Reply	982
‚Äù	O	O	Reply	982
Thank you for the encouragement to pursue this line of work!	B-Reply	B-4	Reply	982

SUMMARY	B-Review	B-4	Review	596
This paper studies the expressive power of deep neural networks under various related measures of expressivity.	O	O	Review	596
<sep> It discusses how these measures relate to the `trajectory length', which is shown to depend exponentially on the depth of the network, in expectation (at least experimentally, at an intuitive level, or theoretically under certain assumptions).	O	O	Review	596
<sep> The paper also emphasises the importance of the weights in the earlier layers of the network, as these have a larger influence on the represented classes of functions, and demonstrates this in an experimental setting.	O	O	Review	596
<sep> <sep> PROS	O	O	Review	596
The paper further advances on topics related to the expressive power of feedforward neural networks with piecewise linear activation functions, in particular elaborating on the relations between various points of view.	O	O	Review	596
<sep> <sep> CONS	O	O	Review	596
The paper further advances and elaborates on interesting topics, but to my appraisal it does not contribute significantly new aspects to the discussion.	O	O	Review	596
<sep> <sep> COMMENTS	O	O	Review	596
- The paper is a bit long (especially the appendix) and seems to have been written a bit in a rush.	B-Review	B-1	Review	596
<sep> Overall the main points are presented clearly, but the results and conclusions could be clearer about the assumptions / experimental vs theoretical nature.	I-Review	I-1	Review	596
<sep> The connection to previous works could also be clearer.	I-Review	I-1	Review	596
<sep> <sep> - On page 2 one finds the statement ``Furthermore, architectures are often compared via ‚Äòhardcoded‚Äô weight values -- a specific function that can be represented efficiently by one architecture is shown to only be inefficiently approximated by another.''	B-Review	B-2	Review	596
<sep> <sep> This is partially true, but it neglects important parts of the discussion conducted in the cited papers.	O	O	Review	596
<sep> In particular, the paper [Montufar, Pascanu, Cho, Bengio 2014] discusses not one hard coded function, but classes of functions with a given number of linear regions.	O	O	Review	596
<sep> That paper shows that deep networks generically* produce functions with at least a given number of linear regions, while shallow networks never do.	O	O	Review	596
<sep> * Generically meaning that, after fixing the number of parameters, any function represented by the network, for parameter values form an open, positive -measure, neighbourhood, belongs to the class of functions which have at least a certain number of linear regions.	O	O	Review	596
<sep> In particular, such statements can be directly interpreted in terms of networks with random weights.	O	O	Review	596
<sep> <sep> - One of the measures for expressivity discussed in the present paper is the number of Dichotomies.	B-Review	B-3	Review	596
In statistical learning theory, this notion is used to define the VC-dimension.	I-Review	I-3	Review	596
In that context, a high value is associated with a high statistical complexity, meaning that picking a good hypothesis requires more data.	I-Review	I-3	Review	596
<sep> <sep> - On page 2 one finds the statement ``We discover and prove the underlying reason for this ‚Äì all three measures are directly proportional to a fourth quantity, trajectory length.''	B-Review	B-4	Review	596
<sep> The expected trajectory length increasing exponentially with depth can be interpreted as the increase (or decrease) in the scale by a composition of the form a*...*a x, which scales the inputs by a^d.	I-Review	I-4	Review	596
Such a scaling by itself certainly is not an underlying cause for an increase in the number of dichotomies or activation patterns or transitions.	I-Review	I-4	Review	596
Here it seems that at least the assumptions on the considered types of trajectories also play an important role.	I-Review	I-4	Review	596
<sep> This is probably related to another observation from page 4: ``if the variance of the bias is comparatively too large... then we no longer see exponential growth.''	I-Review	I-4	Review	596
<sep> <sep> OTHER SPECIFIC COMMENTS	O	O	Review	596
In Theorem 1	O	O	Review	596
- Here it would be good to be more specific about ``random neural network'', i.e., fixed connectivity structure with random weights, and also about the kind of one-dimensional trajectory, i.e., finite in length, closed, differentiable almost everywhere, etc.	B-Review	B-5	Review	596
<sep> <sep> - The notation ``g \geq O(f)'' used in the theorem reads literally as |g| \geq \leq k |f| for some k>0, for large enough arguments.	B-Review	B-6	Review	596
It could also be read as g being not smaller than some function that is bounded above by f, which holds for instance whenever g\geq 0.	I-Review	I-6	Review	596
<sep> For expressing asymptotic lower bounds one can use the notation \Omega (see <a href="https://en.wikipedia.org/wiki/Big_O_notation)."	I-Review	I-6	Review	596
target="_blank" rel="nofollow">https://en.wikipedia.org/wiki/Big_O_notation).</a>	I-Review	I-6	Review	596
<sep> - It would be helpful to mention that the expectation is being taken with respect to the network weights and that these are normally distributed with variance \sigma.	B-Review	B-7	Review	596
<sep> <sep> - Theorem 2.	B-Review	B-8	Review	596
Here it would be good to be more specific about the kind of sign transitions.	I-Review	I-8	Review	596
Is this about transitions at any units of the network, or about sign transitions at the scalar output of the entire network.	I-Review	I-8	Review	596
<sep> <sep> - Theorem 3 is quite trivial.	B-Review	B-9	Review	596
<sep> The bijection between transitions and activation patterns is not clear.	I-Review	I-9	Review	596
<sep> Take a regular n-gon in the plane and a circle that crosses each edge twice.	I-Review	I-9	Review	596
<sep> This makes 2n transitions but only n+1 activation patterns.	I-Review	I-9	Review	596
<sep> <sep> - Theorem 4.	B-Review	B-10	Review	596
<sep> Where is the proof of this statement?	I-Review	I-10	Review	596
<sep> How does this relate to the simple fact that each activation pattern corresponds to the vector indicating the units that are `active'?	I-Review	I-10	Review	596
<sep> <sep> <sep> MINOR COMMENTS	B-Review	B-11	Review	596
- The names of the theorems (e.g. ``Bound on ...'' in Theorem 1) could be separated more clearly from the statements, for instance using bold font, a dot, or parentheses.	I-Review	I-11	Review	596
<sep> - On page 4, in Latex one can use \gg for the `much larger' symbol.	I-Review	I-11	Review	596
<sep> - On page 4, explain the notation \delta z_\orth.	I-Review	I-11	Review	596
- On page 4, explain that ``latent image'' refers to the image in the last layer.	I-Review	I-11	Review	596
<sep> - Why are there no error bars in Figure 2?	I-Review	I-11	Review	596
- On page 5 explain that the hyperplane is in the last hidden layer.	I-Review	I-11	Review	596
<sep> - On page 5, ``is transitioning for any input''.	I-Review	I-11	Review	596
This is not clearly stated, since a transition takes place at a point in a trajectory of inputs, not for a single input.	I-Review	I-11	Review	596
<sep> - The y-axis labels in Figure 1 (c) and (d) are too small.	I-Review	I-11	Review	596
<sep> - Why are there no error bars in Figure 1 (a) and (b)?	I-Review	I-11	Review	596
The caption could at least mention that shown are the averages over experiments.	I-Review	I-11	Review	596
<sep> - In Figure 4 (b) the curves are occluded by the labels.	I-Review	I-11	Review	596
<sep> - The numbering of results is confusing.	I-Review	I-11	Review	596
In the Appendix some numbers are repeated with the main part and some are missing.	I-Review	I-11	Review	596
<sep> - On page 19.	I-Review	I-11	Review	596
Theorem 6.	I-Review	I-11	Review	596
As far as I remember Stanley also provides an elementary proof of case with hyperplanes in general position.	I-Review	I-11	Review	596
Many other works also provide elementary proofs using the same induction arguments in what is known as the sweep hyperplane method.	I-Review	I-11	Review	596
<sep> <sep> <sep> Thank you for your careful reading, and specific feedback!	O	O	Reply	596
We are working to improve the paper based on your suggestions.	O	O	Reply	596
Some responses to specific points follow below:	O	O	Reply	596
<sep> ***"In particular, the paper [Montufar, Pascanu, Cho, Bengio 2014] discusses not one hard coded function, but classes of functions with a given number of linear regions.	O	O	Reply	596
<sep> That paper shows that deep networks generically* produce functions with at least a given number of linear regions, while shallow networks never do. "	O	O	Reply	596
<sep> <sep> This is untrue.	O	O	Reply	596
In [Montufar et al, 2014], in Lemma 2 they put a lower bound on the *maximum* number of linear regions that can be achieved by adjusting weights.	O	O	Reply	596
They also discuss in the text how weights can be perturbed, even for a network with an exponential number of linear regions, without changing the number of linear regions.	O	O	Reply	596
Nowhere do they establish bounds on the expected number of linear regions for generic weights.	O	O	Reply	596
<sep> <sep> <sep> ***"One of the measures for expressivity discussed in the present paper is the number of Dichotomies.	O	O	Reply	596
In statistical learning theory, this notion is used to define the VC-dimension.	O	O	Reply	596
In that context, a high value is associated with a high statistical complexity, meaning that picking a good hypothesis requires more data."	O	O	Reply	596
<sep> <sep> Thank you for the connection.	O	O	Reply	596
We actually discuss this in Appendix D.1, and will improve the reference to this discussion in the text.	O	O	Reply	596
As you note, the literature on VC dimension typically takes a negative view of complexity, and treats it as a measure of how badly a class of functions could overfit to the training data.	O	O	Reply	596
In this paper we take an opposite perspective, and instead treat complexity as a measure of how powerful and flexible a class of functions is, which is a view adopted from the combinatorial literature on the Sauer-Shelah lemma.	O	O	Reply	596
<sep> <sep> <sep> ***"On page 2 one finds the statement ``We discover and prove the underlying reason for this ‚Äì all three measures are directly proportional to a fourth quantity, trajectory length.''	O	O	Reply	596
<sep> The expected trajectory length increasing exponentially with depth can be interpreted as the increase (or decrease) in the scale by a composition of the form a*...*a x, which scales the inputs by a^d.	O	O	Reply	596
Such a scaling by itself certainly is not an underlying cause for an increase in the number of dichotomies or activation patterns or transitions.	O	O	Reply	596
Here it seems that at least the assumptions on the considered types of trajectories also play an important role.	O	O	Reply	596
<sep> This is probably related to another observation from page 4: ``if the variance of the bias is comparatively too large... then we no longer see exponential growth.''"	O	O	Reply	596
<sep> <sep> Interpreting the increase in trajectory length as the result of a composition a*a*a..*x is important, but only part of the whole picture.	B-Reply	B-4	Reply	596
As we examine hard tanh, there is another  competing factor, which is whether neurons are saturated or not -- if neurons are saturated, then we cannot expect a perturbation to experience exponential growth and hence the trajectory itself will not grow.	I-Reply	I-4	Reply	596
<sep> <sep> From the outset, it is unclear which of these will win out.	I-Reply	I-4	Reply	596
But it turns out that even with saturation effects, the composition effects are enough to cause trajectory growth.	I-Reply	I-4	Reply	596
<sep> <sep> The reviewer is correct in that the increase of transitions is not due to this alone -- it also has to do with autocorrelation length, which also decreases exponentially (explored further in <a href="https://arxiv.org/abs/1606.05340)."	I-Reply	I-4	Reply	596
target="_blank" rel="nofollow">https://arxiv.org/abs/1606.05340).</a> The only (mild) condition we need on the trajectory for this to be true is that the tangent vector must have a perpendicular component to the current point. (	I-Reply	I-4	Reply	596
So for the proof to go through, it can't be a line from the origin.)	I-Reply	I-4	Reply	596
<sep> <sep> <sep> ***"In Theorem 1	O	O	Reply	596
- Here it would be good to be more specific about ``random neural network'', i.e., fixed connectivity structure with random weights, and also about the kind of one-dimensional trajectory, i.e., finite in length, closed, differentiable almost everywhere, etc.	O	O	Reply	596
<sep> - The notation ``g \geq O(f)'' used in the theorem reads literally as |g| \geq \leq k |f| for some k>0, for large enough arguments.	O	O	Reply	596
It could also be read as g being not smaller than some function that is bounded above by f, which holds for instance whenever g\geq 0.	O	O	Reply	596
<sep> For expressing asymptotic lower bounds one can use the notation \Omega (see <a href="https://en.wikipedia.org/wiki/Big_O_notation)."	O	O	Reply	596
target="_blank" rel="nofollow">https://en.wikipedia.org/wiki/Big_O_notation).</a>	O	O	Reply	596
- It would be helpful to mention that the expectation is being taken with respect to the network weights and that these are normally distributed with variance \sigma."	O	O	Reply	596
<sep> <sep> Thank you for these suggestions!	B-Reply	B-5	Reply	596
We are making all of these changes (differentiable everywhere is not required.)	I-Reply	I-5	Reply	596
<sep> <sep> <sep> ***"- Theorem 2.	O	O	Reply	596
Here it would be good to be more specific about the kind of sign transitions.	O	O	Reply	596
Is this about transitions at any units of the network, or about sign transitions at the scalar output of the entire network. "	O	O	Reply	596
<sep> <sep> The theorem as stated is for the expected number of transition of the readout neuron in an n-layer network.	B-Reply	B-8	Reply	596
The same relationship holds for any neuron in the network, as a function of that neuron's depth.	I-Reply	I-8	Reply	596
We are clarifying this in the text.	I-Reply	I-8	Reply	596
<sep> <sep> <sep> ***"- Theorem 3 is quite trivial. "	O	O	Reply	596
<sep> Note that Theorem 3 states that activation patterns of the *entire network* subdivide input space into convex polytopes!	B-Reply	B-9	Reply	596
See Figure 3 for an illustration of this.	I-Reply	I-9	Reply	596
We have found in conversation that our colleagues find it obvious that a single layer in a deep network subdivides the layer immediately below into convex polytopes, but are typically surprised to discover that the pattern of activity across all layers of the network subdivides input space into convex polytopes.	I-Reply	I-9	Reply	596
<sep> <sep> <sep> ***"The bijection between transitions and activation patterns is not clear.	O	O	Reply	596
<sep> Take a regular n-gon in the plane and a circle that crosses each edge twice.	B-Reply	B-9	Reply	596
<sep> This makes 2n transitions but only n+1 activation patterns."	I-Reply	I-9	Reply	596
<sep> <sep> This was stated and proved as only true for affine trajectories in the appendix but we will clarify this further in the text -- thank you for pointing it out!	B-Reply	B-9	Reply	596
<sep> <sep> <sep> ***"- Theorem 4.	O	O	Reply	596
<sep> Where is the proof of this statement?	B-Reply	B-10	Reply	596
<sep> How does this relate to the simple fact that each activation pattern corresponds to the vector indicating the units that are `active'? "	I-Reply	I-10	Reply	596
<sep> <sep> The proof of theorem 4 follows after the proof of theorem 6 in the appendix -- apologies that this was not more clearly marked before, but theorem 4 follows readily from the proof of theorem 3 and the statement of theorem 6.	I-Reply	I-10	Reply	596
<sep> <sep> This theorem gives an asymptotically tight bound on how many such unique vectors we can expect from a real neural network.	I-Reply	I-10	Reply	596
The naive bound would be 2^(number of neurons) - so in our case, 2^(kn + m).	I-Reply	I-10	Reply	596
But all of these combinations are not possible.	I-Reply	I-10	Reply	596
E.g. if we trace a line in our input space and look at the on off pattern of the first hidden layer, each unit can only switch from on to off (or vice versa), *once*. So we get k different patterns, not 2^k.	I-Reply	I-10	Reply	596
<sep> <sep> <sep> MINOR COMMENTS	O	O	Reply	596
"On page 19.	B-Reply	B-11	Reply	596
Theorem 6.	I-Reply	I-11	Reply	596
As far as I remember Stanley also provides an elementary proof of case with hyperplanes in general position.	I-Reply	I-11	Reply	596
Many other works also provide elementary proofs using the same induction arguments in what is known as the sweep hyperplane method."	I-Reply	I-11	Reply	596
<sep> <sep> Stanley's proof method uses intersection posets to prove Zaslavsky's theorem a special case of which gives the bound in general position.	I-Reply	I-11	Reply	596
At the time of writing, the authors were unable to find an elementary proof of this theorem.	I-Reply	I-11	Reply	596
<sep> <sep> <sep> We will make all the other changes you suggest in MINOR COMMENTS.	I-Reply	I-11	Reply	596
Thank you again for your careful reading and actionable suggestions!	O	O	Reply	596

This paper presents 'Multimodal Factorization model' that factorizes representations into shared multimodal discriminative factors and modality specific generative factors.	O	O	Review	596
This work applies 'Wassertein Auto-Encoders' by Tolstikhin et al (with proofs that this setup works in the multimodal case) for handling factorized joint distributions over the multimodal space.	B-Review	B-1	Review	596
Can this method be considered as a generalization of the wasserstein autoencoder based method with a broader application? -	I-Review	I-1	Review	596
the authors should discuss this more broadly in the paper.	I-Review	I-1	Review	596
<sep> <sep> Pros:	O	O	Review	596
- There has been many recent work in the area of disentangling joint representations for improving generative auto-encoding architectures using VAEs, GANs, WAE and some variants of these.	O	O	Review	596
This work falls in this category with many interesting experiments showing SOTA generation and discrimination results on several tasks.	O	O	Review	596
<sep> - This work is practical due to its robustness to noisy and/or missing data for one or more of the modalities in a multimodal machine learning classification (or generation) problem.	O	O	Review	596
Application of this technique for continuous multimodal time series data modeling and prediction for high accuracy requirement applications is very promising.	O	O	Review	596
<sep> - The methods seems to be easily portable to other tasks.	O	O	Review	596
The authors say that they will make the code available to other researchers.	O	O	Review	596
<sep> <sep> Cons:	O	O	Review	596
- Some more comparison to other disentangling approaches such as beta-VAE, InfoGAN and partitioned VAE methods would have been useful for understanding the advantages and disadvantages of this techniques. (	B-Review	B-2	Review	596
The authors do add a note about comparison with partitioned VAE method in the Appendix)	I-Review	I-2	Review	596
- For generation and classification tasks, the authors have chosen the tasks for digit recognition and sentiment analysis - I wonder if the results would hold for other types of multimodal tasks.	B-Review	B-3	Review	596
<sep> <sep> Overall the paper is very well-written with many experiments to support the claims.	O	O	Review	596
Thank you for your positive comments and suggestions for improvement.	O	O	Reply	596
We address your comments and questions below.	O	O	Reply	596
<sep> <sep> [Regarding generalization of the Wasserstein autoencoder] Inspired by Wasserstein autoencoders, we generalize the definition of Wasserstein distance from marginal to joint distributions.	B-Reply	B-1	Reply	596
This generalization enables us to perform structured prediction for multimodal learning.	I-Reply	I-1	Reply	596
We believe the generalization can not only be used in multimodal learning but can also be applied in other domains.	I-Reply	I-1	Reply	596
Will include this discussion in the revised manuscript.	I-Reply	I-1	Reply	596
<sep> <sep> [Comparisons to additional baselines] Thank you for suggesting these additional baselines.	B-Reply	B-2	Reply	596
For the beta-VAE model, we set the choice of the prior matching discrepancy as the KL-divergence and set beta large enough to encourage disentanglement of the latent variables.	I-Reply	I-2	Reply	596
We train a beta-VAE to model multimodal data using the same factorization as proposed in our model (i.e. modality-specific generative factors and a multimodal discriminative factor).	I-Reply	I-2	Reply	596
To provide a fair comparison to our discriminative model, we fine tune by training a classifier on top of the multimodal discriminative factor Z_y to the label.	I-Reply	I-2	Reply	596
We perform experiments on 4 multimodal datasets.	I-Reply	I-2	Reply	596
These experimental results have been added to section I of the appendix.	I-Reply	I-2	Reply	596
MFM outperforms beta-VAE across these datasets and metrics:	I-Reply	I-2	Reply	596
- 9.5% improvement on CMU-MOSI	I-Reply	I-2	Reply	596
- 25.1% improvement on ICT-MMMO	I-Reply	I-2	Reply	596
- 14.1% improvement on YouTube	I-Reply	I-2	Reply	596
- 35.9% improvement on MOUD	I-Reply	I-2	Reply	596
<sep> We have also provided additional experimental results that compare our model with partitioned VAE (Hsu and Glass, 2018) in section H of the appendix.	I-Reply	I-2	Reply	596
In summary, we obtain:	I-Reply	I-2	Reply	596
- 3.9% improvement on CMU-MOSI	I-Reply	I-2	Reply	596
- 4.9% improvement on ICT-MMMO	I-Reply	I-2	Reply	596
- 3.1% improvement on YouTube	I-Reply	I-2	Reply	596
- 24.4% improvement on MOUD	I-Reply	I-2	Reply	596
<sep> [Other multimodal tasks] We obtain improved results for 3 types of multimodal tasks: multimodal sentiment analysis (CMU-MOSI, ICT-MMMO, YouTube, MOUD datasets), emotion recognition (IEMOCAP dataset) and personality traits prediction (POM dataset).	B-Reply	B-3	Reply	596
These results are presented in Table 1 (see page 5).	I-Reply	I-3	Reply	596
Our multimodal factorization model can also be combined with many of the existing discriminative models.	I-Reply	I-3	Reply	596
In future work we will explore applications of multimodal factorization to various additional tasks, such as Video QA, Image retrieval, etc.	I-Reply	I-3	Reply	596
We will also release the code so that our model can be adapted to other multimodal tasks.	I-Reply	I-3	Reply	596

Multimodality learning is an important topic in multimedia and human computer interaction.	O	O	Review	596
How to efficiently leverage the additional information cross multimodality is the key to the task.	O	O	Review	596
Authors proposed the Bayesian latent variable model to factorize the multimodality representation into multimodal discriminative factors and modality-specific generating factors, which is interesting.	O	O	Review	596
Approximate inference is also proposed to learn this model via a generalised mean-field assumption.	O	O	Review	596
<sep> <sep> The technical quality of the paper is sound and significant, The problem to solve in this paper is also well motivated and important.	O	O	Review	596
In general, this is a well-written paper,	O	O	Review	596
<sep> I have a few minor questions which requires authors for further elaboration.	O	O	Review	596
<sep> 1.	B-Review	B-1	Review	596
If I understand it correctly, in the current work, the feature Xs are continuous.	I-Review	I-1	Review	596
Does the approach apply to categorical or binary features?	I-Review	I-1	Review	596
<sep> <sep> 2.	O	O	Review	596
In equation(4), MMD is used.	B-Review	B-2	Review	596
How to solve the computation complexity problem since the complexity of MMD is O(n^2)?	I-Review	I-2	Review	596
It is true that the batch size should be small?	B-Review	B-3	Review	596
How to select the hyper-parameters of kernels?	B-Review	B-4	Review	596
<sep> <sep> Thank you for your positive comments and suggestions for improvement.	O	O	Reply	596
We address your comments and questions below.	O	O	Reply	596
<sep> <sep> [Categorical or binary features] Yes, the encoders and decoders can be flexibly chosen for continuous or categorical features (e.g. for text, we can use discrete word tokens, represented as one-hot vectors, and train an embedding layer for task-specific word embeddings.)	B-Reply	B-1	Reply	596
To model categorical or binary features, we can also choose the suitable distance metric designed for them, for example, Jaccard distance.	I-Reply	I-1	Reply	596
<sep> <sep> [MMD computational complexity] In this work, we adopt the unbiased MMD estimator which has a computational complexity of O(n^2).	B-Reply	B-2	Reply	596
The complexity can be reduced if we choose a block, linear, or incomplete MMD estimator [1]. For example, if we use a linear MMD estimator, the computation time required is O(n), and in the batch setting, it is O(b) where b is the batch size.	I-Reply	I-2	Reply	596
<sep> <sep> [Batchsize] We found that a batchsize of 32, 64 or 128 works well in our experiments.	B-Reply	B-3	Reply	596
<sep> <sep> [Hyperparameters] As suggested by WAE, we first set our RBF kernel bandwidth to be sqrt(d), where d is the dimension of latent variables in WAE.	B-Reply	B-4	Reply	596
Using cross-validation, we also found that setting the bandwidth to 1.0 works well across the datasets we considered.	I-Reply	I-4	Reply	596
<sep> <sep> [1] Makoto Yamada, Denny Wu, Yao-Hung Hubert Tsai, Ichiro Takeuchi, Ruslan Salakhutdinov, Kenji Fukumizu, 2018.	O	O	Reply	596
Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator, <a href="https://arxiv.org/pdf/1802.06226.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1802.06226.pdf</a>	O	O	Reply	596

The authors splitted the features of multimodal representations to "common" (multimodal discriminative) and "specific" (modality-specific generative) factors.	O	O	Review	596
In this framework, their MFM can capture more detailed features.	O	O	Review	596
<sep> <sep> Pros:	O	O	Review	596
(*) Learning the feature representations from two perspectives.	O	O	Review	596
<sep> <sep> (*) Even missing one modality, MFM can still achieve acceptable performance.	O	O	Review	596
<sep> <sep> (*) Using mutual information and gradient-based method to interpret their method.	O	O	Review	596
<sep> <sep> Cons:	O	O	Review	596
(*) The work has some similarity to Hsu & Glass (2018), but the comparison between this work is only on CMU-MOSI.	B-Review	B-1	Review	596
<sep> <sep> (*) In Table.	B-Review	B-2	Review	596
3, it shows that language is the most informative feature for prediction.	I-Review	I-2	Review	596
However, in Table.	I-Review	I-2	Review	596
2, it can be seen that if audio is missing, the result it the worse compared to the other two cases.	I-Review	I-2	Review	596
It seems the interpretation is not convincing to me.	I-Review	I-2	Review	596
Can you give us more explanation about this phenomenon?	I-Review	I-2	Review	596
<sep> <sep> Comments:	O	O	Review	596
(*) The details of SVHN-MNIST experiment are missing.	B-Review	B-3	Review	596
Appendix B gave some information about models but specified the targeted datasets.	I-Review	I-3	Review	596
<sep> <sep> (*) The appendix is not clear, e.g. In Appendix B, it is said "subsection 3.3" but there is no section 3.3.	B-Review	B-4	Review	596
<sep> <sep> <sep> Thank you for your positive comments and suggestions for improvement.	O	O	Reply	596
We address your comments and questions below.	O	O	Reply	596
<sep> <sep> [Comparison with  Hsu & Glass (2018)] We have performed additional experiments between our model and Hsu & Glass (2018) on 3 more multimodal datasets.	B-Reply	B-1	Reply	596
Our proposed MFM model consistently outperforms the model proposed in Hsu & Glass (2018).	I-Reply	I-1	Reply	596
In terms of sentiment classification accuracy, we obtain:	I-Reply	I-1	Reply	596
- 3.9% improvement on CMU-MOSI	I-Reply	I-1	Reply	596
- 4.9% improvement on ICT-MMMO	I-Reply	I-1	Reply	596
- 3.1% improvement on YouTube	I-Reply	I-1	Reply	596
- 24.4% improvement on MOUD	I-Reply	I-1	Reply	596
For more details, please refer to full results in appendix H. We would like to emphasize that our present work started in February, and was performed independently and in parallel to the arXiv submission by Hsu & Glass (2018) in July.	I-Reply	I-1	Reply	596
<sep> <sep> We also highlight a few key differences: 1) we use an MMD prior matching discrepancy derived from an extension of WAE from marginal to joint distributions over multimodal data and labels, 2) we train a single network architecture to learn factorized representations, 3) we use a generative-discriminative objective function, and 4) we perform experiments over 6 large-scale multimodal datasets across 3 multimodal tasks.	I-Reply	I-1	Reply	596
For more details, please refer to appendix section H.	I-Reply	I-1	Reply	596
<sep> [Language and audio] There seems to be some misunderstanding regarding Table 2: we note that having a missing audio modality does not lead to worse prediction performance.	B-Reply	B-2	Reply	596
Instead, label prediction performance (Y prediction) suffers the most when the language modality is missing.	I-Reply	I-2	Reply	596
<sep> Results in terms of binary classification accuracy (see Table 2):	I-Reply	I-2	Reply	596
- Language missing: 62.0%	I-Reply	I-2	Reply	596
- Audio missing: 74.3%	I-Reply	I-2	Reply	596
- Visual missing: 74.6%	I-Reply	I-2	Reply	596
- All present: 78.1%	I-Reply	I-2	Reply	596
Similar results hold for other metrics as well.	I-Reply	I-2	Reply	596
Discriminative performance is most affected when the language modality is missing, which is consistent with prior work which indicates that language is most informative in multimodal setting (Zadeh et al 2017).	I-Reply	I-2	Reply	596
On the other hand, sentiment prediction is more robust to missing acoustic and visual features.	I-Reply	I-2	Reply	596
<sep> <sep> [SVHN-MNIST experiments] We will release the code along with the appropriate dataset preprocessing details to avoid any ambiguity.	B-Reply	B-3	Reply	596
Some details are provided in subsection 3.1, multimodal image datasets: Specifically, SVHN and MNIST are images with different styles but the same labels (digits 0 ‚àº 9).	I-Reply	I-3	Reply	596
We randomly pair 100,000 SVHN and MNIST images that have the same label, creating a multimodal dataset which we call SVHN+MNIST.	I-Reply	I-3	Reply	596
80,000 pairs are used for training and the rest for testing.	I-Reply	I-3	Reply	596
To show that MFM is able to learn improved multimodal representations, we provided both classification and generation results on SVHN+MNIST in Figure 2.	I-Reply	I-3	Reply	596
We use convolution layers to learn the latent codes from images and deconvolution layers to generate images from the latent codes.	I-Reply	I-3	Reply	596
We have updated the paper with more details (appendix section E).	I-Reply	I-3	Reply	596
<sep> <sep> [Appendix] We apologize for the typo.	B-Reply	B-4	Reply	596
The baselines models referred to are in subsection 3.2, paragraph 3 (prediction on multimodal time series datasets).	I-Reply	I-4	Reply	596
We have updated the paper.	I-Reply	I-4	Reply	596

-- define cascade errors when you first use the phrase	B-Review	B-1	Review	596
-- basic english grammar could be fixed but is not interfering with understanding	B-Review	B-2	Review	596
-- what is the early stopping criterion in Alg 1?	B-Review	B-3	Review	596
<sep> -- did you try any other values for the initial threshold and decay factor?	B-Review	B-4	Review	596
<sep> -- At the end of Section 4.1 DROP: ", but not the same." -	B-Review	B-5	Review	596
I can't parse what this last clause is supposed to mean.	I-Review	I-5	Review	596
<sep> --the diff sum example in table 2 is confusing; the program appears to sum up the numbers but the result is a subtraction without a sum operation in it.	B-Review	B-6	Review	596
Would be clearer to show the sum in the result line as well rather than distribute the subtraction.	I-Review	I-6	Review	596
Also, shouldn't it be diff(9, sum(10, 12))?	I-Review	I-6	Review	596
<sep> -- I think you should pull at least some commentary about the constant used in Table 3 from Appendix B and include it in the main paper (or at least mention Appendix B is the place to look).	B-Review	B-7	Review	596
Can you add a table in an appendix showing the complete list of operators used?	I-Review	I-7	Review	596
<sep> -- Nice results in Table 4 on the dev set.	B-Review	B-8	Review	596
Are there Test set results as well?	I-Review	I-8	Review	596
<sep> -- The organization of the Baselines 4.3 section and the Results 4.4 is confusing.	B-Review	B-9	Review	596
For example, you mention that you test different variants of NeRd, operator variants, and mathqa, but then the results are not mentioned for these experiments until the next page.	I-Review	I-9	Review	596
I found myself immediately looking for the numbers/results when you introduce the experiment.	I-Review	I-9	Review	596
I would pair your experiment description with the results rather than grouping all experiment descriptions and then grouping all results, especially when the order of the experiment descriptions does not match the order of the results presented.	I-Review	I-9	Review	596
For example, in baselines you discuss training variants and then operators.	I-Review	I-9	Review	596
Then in Results you discuss operators before variants.	I-Review	I-9	Review	596
It is too disconnected and makes the reader jump around a bunch.	I-Review	I-9	Review	596
Same goes for the drop baselines where you mention a bunch of models, and I would prefer the Results/discussion paired with each one, rather than having to wait for it down below.	I-Review	I-9	Review	596
<sep> -- Overall it seems like a solid work; good empirical results showing improvements of each purported contribution.	B-Review	B-10	Review	596
The model itself is a relatively simple construction of basic component, but the combination with the DSL is intuitive and makes sense.	I-Review	I-10	Review	596
I don't think the novelty in model here is the main selling point anyways; the training variants and the demonstration of how well a DSL approach can do combined with previously introduced methods.	I-Review	I-10	Review	596
<sep> -- I find the model description to be slightly unclear.	B-Review	B-11	Review	596
In Fig 1 for example there is an arrow that connects passage to compositional programs.	I-Review	I-11	Review	596
What does that arrow represent?	I-Review	I-11	Review	596
I think you should elaborate on how the attention over the encoded text interacts with the attention over previously generated tokens.	I-Review	I-11	Review	596
Equations would make this far more explicit as is I am left with a lot of questions on how to implement your model.	I-Review	I-11	Review	596
Maybe you can add to your appendix?	I-Review	I-11	Review	596
Or release your code?	I-Review	I-11	Review	596
That is mentioned either.	I-Review	I-11	Review	596
Thanks for your constructive feedback!	O	O	Reply	596
We have incorporated your comments in our revision, and we respond to your questions below:	O	O	Reply	596
<sep> -- define cascade errors when you first use the phrase	O	O	Reply	596
<sep> We use "cascade error" to refer to errors caused by the previous phase in a pipeline.	B-Reply	B-1	Reply	596
In our case, we use this term to refer to the errors caused by data preprocessing for semantic parsing approaches, which parses the text into structured representations using tools such as SRL.	I-Reply	I-1	Reply	596
We revised the paper to add a description in the introduction, where we first use this phrase.	I-Reply	I-1	Reply	596
<sep> <sep> -- basic english grammar could be fixed but is not interfering with understanding	O	O	Reply	596
We have done another round of proof-reading and updated the paper accordingly.	B-Reply	B-2	Reply	596
<sep> <sep> -- what is the early stopping criterion in Alg 1?	O	O	Reply	596
<sep> We perform early stopping when both exact match and F1 scores on the development set do not improve for two consecutive training iterations.	B-Reply	B-3	Reply	596
We have updated Appendix D.2 to make this point clearer.	I-Reply	I-3	Reply	596
<sep> <sep> -- did you try any other values for the initial threshold and decay factor?	O	O	Reply	596
<sep> We have also tried other values for the initial threshold and decay factor, and we found that the specific values do not matter much for the final results as long as they are in a good range.	B-Reply	B-4	Reply	596
Specifically, values in [0.2, 0.5] work well for both the initial threshold and decay factor (we tried 1/5, 1/4, 1/3, 1/2 within this range).	I-Reply	I-4	Reply	596
Values larger than 0.5 will slow down training, and values smaller than 0.2 will decrease the quality of the final model.	I-Reply	I-4	Reply	596
<sep> <sep> -- At the end of Section 4.1 DROP: ", but not the same." -	O	O	Reply	596
I can't parse what this last clause is supposed to mean.	O	O	Reply	596
<sep> <sep> We have rephrased the sentence to be "F1 score, which gives partial credits to a prediction that is not exactly the same as the ground truth, but overlaps with it‚Äù.	B-Reply	B-5	Reply	596
For example, if the ground truth is "Barrack Obama", and the prediction is "Obama", the exact match score will be zero, while the F1 score is larger than zero.	I-Reply	I-5	Reply	596
<sep> <sep> --the diff sum example in table 2 is confusing.	O	O	Reply	596
<sep> <sep> Thanks for catching the problem!	O	O	Reply	596
It is indeed a typo.	B-Reply	B-6	Reply	596
We have fixed it in the revision, and modified the explanation accordingly to make it clearer.	I-Reply	I-6	Reply	596
<sep> <sep> -- Discussion of the complete operator and constant lists.	O	O	Reply	596
<sep> <sep> For DROP, we have included the complete constant list in Appendix B. Note that MathQA covers a wide range of mathematical questions, and in their public dataset, they released the complete lists with 58 operators and 23 constants, which could be too long to include in the paper.	B-Reply	B-7	Reply	596
Therefore, we added a description in Appendix B, and refer to their paper and public dataset for complete details.	I-Reply	I-7	Reply	596
<sep> <sep> -- Nice results in Table 4 on the dev set.	O	O	Reply	596
Are there Test set results as well?	O	O	Reply	596
<sep> <sep> Due to time constraint, we only evaluated locally on dev set at the time of submission.	B-Reply	B-8	Reply	596
We submitted to the DROP server later, and the test result is better (+1.18% on F1 and +1.37% on Exact Match) than other baselines.	I-Reply	I-8	Reply	596
<sep> <sep> -- The organization of the Baselines 4.3 section and the Results 4.4 is confusing...	O	O	Reply	596
<sep> Thanks for the suggestions!	B-Reply	B-9	Reply	596
We swapped the descriptions of operator variants and training variants in Section 4.3, so that the order in Section 4.3 matches the order in Section 4.4 now.	I-Reply	I-9	Reply	596
The main reason why we did not pair the descriptions with results is for paper space arrangement.	I-Reply	I-9	Reply	596
Given that our paper has several tables of different sizes, separating them out is sometimes sub-optimal in terms of space usage.	I-Reply	I-9	Reply	596
Therefore, we tentatively keep the section organization as it is in this revision; however, in our camera ready version, we will try to re-organize these two sections if it looks better.	I-Reply	I-9	Reply	596
<sep> <sep> -- Overall it seems like a solid work; good empirical results showing improvements of each purported contribution...	O	O	Reply	596
<sep> Thanks for appreciating our work!	B-Reply	B-10	Reply	596
We agree that the neural architecture of each component in our model, i.e., BERT as the encoder and an LSTM with attention as the program decoder, is not our main contribution.	I-Reply	I-10	Reply	596
Instead, as pointed out by Reviewer 2, the key novelty is "This paper presents a semantic parser that operates over passages of text instead of a structured data source.	I-Reply	I-10	Reply	596
This is the first time anyone has demonstrated such a semantic parser".	I-Reply	I-10	Reply	596
To achieve this, we made several technical contributions to address the challenges in designing such a model, for example, the introduction of span selection operators so that compositional reasoning can be applied over text.	I-Reply	I-10	Reply	596
<sep> <sep> -- I find the model description to be slightly unclear...	O	O	Reply	596
<sep> The arrow means that the program can directly select spans from the passage by calling the PASSAGE_SPAN operator with the indices of start and end token; on the contrary, existing neural semantic parsers require an additional structured parser.	B-Reply	B-11	Reply	596
We have written the detailed equations in Appendix C, including the attention mechanism.	I-Reply	I-11	Reply	596
We will open source our code with our camera ready version.	I-Reply	I-11	Reply	596

This paper discusses an extended DSL language for answering complex questions from text and adding data augmentation as well as weak supervision for training an encoder/decoder model where the encoder is a language model and decoder a program synthesis machine generating instructions using the DSL.	O	O	Review	596
They show interesting results on two datasets requiring symbolic reasoning for answering the questions.	O	O	Review	596
<sep> <sep> Overall, I like the paper and I think it contains simple extensions to previous methods referenced in the paper enabling them to work well on these datasets.	O	O	Review	596
<sep> <sep> A few comments:	O	O	Review	596
<sep> 1 - Would be interesting to see the performance of the weak supervision on these datasets.	B-Review	B-1	Review	596
In other words, if the heuristics are designed to provide noisy instruction sets for training, we need to see the performance of those on these datasets to determine if the models are generalising beyond those heuristics or they perform at the same level which then may mean we don't need the model.	I-Review	I-1	Review	596
<sep> <sep> 2 - From Tab 4, it seems the largest improvements are due to span-selection cases as a result of adding span operators to the DSL.	B-Review	B-2	Review	596
A deep dive on this would be a great insight (in addition to performance improvement statements on page 7).	I-Review	I-2	Review	596
<sep> <sep> 3 - Since the span and value operators require indices to the text location, could you please clarify in the text how that is done?	B-Review	B-3	Review	596
Do LSTMs output the indices or are you selecting from a preselection spans as part of preprocessing?	I-Review	I-3	Review	596
<sep> <sep> <sep> Thank you for your valuable comments, and we are glad that you like our paper!	O	O	Reply	596
About your comments:	O	O	Reply	596
<sep> 1.	O	O	Reply	596
The heuristics used to obtain training data augmentations from weak supervision all rely on access to the ground truth answer, so they cannot be directly applied for prediction given just questions and passages.	B-Reply	B-1	Reply	596
In other words, the heuristics are only applicable during training, so at the inference time, the model has to generalize to answer unseen questions.	I-Reply	I-1	Reply	596
<sep> <sep> 2.	O	O	Reply	596
The span selection operators are key components in the DSL because (1) they can be used to answer the single span and multiple span questions; (2) they can support higher level reasoning such as counting and sorting.	B-Reply	B-2	Reply	596
<sep> <sep> For the significant improvement on multiple-span questions, we hypothesize that it is because the same PASSAGE_SPAN operators are used in both single-span, multiple-span as well as counting and sorting questions; i.e., multiple-span questions are answered by calling PASSAGE_SPAN a few times, and counting also calls PASSAGE_SPAN to find the spans to count.	I-Reply	I-2	Reply	596
Therefore, the model obtains more training signals to learn how to use such operators.	I-Reply	I-2	Reply	596
<sep> <sep> 3.	B-Reply	B-3	Reply	596
We extended Appendix C to provide the full details of how the programs are generated.	I-Reply	I-3	Reply	596
Specifically, the program generation process is similar to the pointer network [Vinyals et al, 2015], where we compute the attention weights over all valid possible program tokens at each timestep, and select the one with the highest prediction probability.	I-Reply	I-3	Reply	596
<sep> <sep> Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. "	O	O	Reply	596
Pointer networks."	O	O	Reply	596
Advances in Neural Information Processing Systems.	O	O	Reply	596
2015.	O	O	Reply	596

This paper presents a semantic parser that operates over passages of text instead of a structured data source.	O	O	Review	596
This is the first time anyone has demonstrated such a semantic parser (Siva Reddy and several others have essentially used unstructured text as an information source for a semantic parser, similar to OpenIE methods, but this is qualitatively different).	O	O	Review	596
The key insight is to let the semantic parser point to locations in the text that can be used in further symbolic operations.	O	O	Review	596
This is excellent work, and it should definitely be accepted.	O	O	Review	596
I have a ton of questions about this method, but they are good questions.	O	O	Review	596
The rest of this review focuses on things that I thought could be more clear, or that raise new questions, and might sound negative.	O	O	Review	596
Please understand them, however, in terms of my overall score and what I said above.	O	O	Review	596
<sep> <sep> The three claimed contributions are (1) better numbers, (2) better compositionality / domain applicability, and (3) better interpretability.	B-Review	B-1	Review	596
<sep> <sep> (2) and (3) sound a bit like overclaiming in the introduction to me, as there isn't a whole lot of nested composition in the language used by NeRd, and the BERT calculator in principle is almost as compositional and interpretable (also, e.g., NAQANet can add and subtract an arbitrary number of numbers, also, and it tells you which ones they are, just as NeRd does).	I-Review	I-1	Review	596
Later in the paper the specifics of those claims are made more clear, and while they are justified, they are very narrow claims.	I-Review	I-1	Review	596
To me, someone who is intimately familiar with this research area, the key contributions (the things that I learned) are (1) using passage-span and key-value predicates actually works, (2) how much difference hard EM and thresholding make, and (3) the data augmentation in this work is pretty clever.	I-Review	I-1	Review	596
(2) was intuitively clear to me after seeing Dasigi's iterative search paper and Min's hard EM paper, but the difference in results presented here is pretty striking.	I-Review	I-1	Review	596
<sep> <sep> Compositionality:	O	O	Review	596
<sep> The authors claim that their method is compositional and domain agnostic, while all previous methods had hand-crafted modules for specific question types.	B-Review	B-2	Review	596
However, I see little reason to believe there's much of a difference here.	I-Review	I-2	Review	596
You also defined operations that are tailored to the dataset, and are basically identical to the operations that others have used.	I-Review	I-2	Review	596
I see no evidence that NeRd actually generalizes to program types that are beyond what is captured by other methods.	I-Review	I-2	Review	596
It's possible that this happens, but there is no evaluation that discusses this, and from all of the examples I'm led to believe that this is basically also just learning a few program templates, the same ones learned by previous methods.	I-Review	I-2	Review	596
With the weak supervision that you have, are you actually able to find more complex programs during your search?	I-Review	I-2	Review	596
Some kind of demonstration of actual compositionality on the more complex questions in DROP would make a very strong argument for your claims; without that, they ring a little hollow.	I-Review	I-2	Review	596
<sep> <sep> Interpretability:	O	O	Review	596
<sep> The use of passage-span as a predicate is really interesting, and it raises a lot of questions.	B-Review	B-3	Review	596
This predicate lets the model shortcut any interpretable reasoning and do operations entirely inside the encoder/parser.	I-Review	I-3	Review	596
For example, your first example in table 2 ostensibly requires filtering the numbers in the passage to those that are percentages associated with groups, then filtering them again to those where the percentage is larger than 16, then returning the associated groups.	I-Review	I-3	Review	596
But your method jumps straight to returning a set of passage spans.	I-Review	I-3	Review	596
This is hardly interpretable.	I-Review	I-3	Review	596
(In fairness, no prior method provides interpretable reasoning for this kind of operation either.)	I-Review	I-3	Review	596
But the fact that you have this predicate lets the model do these filters and greater-than comparisons inside the network in an opaque way, while also getting interpretable operations for some questions (table 5 is further confirmation of this, and of the fact that you probably are not capturing many of more the complex, compositional questions in DROP).	I-Review	I-3	Review	596
But how does the network decide which to do?	I-Review	I-3	Review	596
Any argmax or max question, and many count questions, could be answered by passage-span alone.	I-Review	I-3	Review	596
With only weak supervision, and with the parser having the ability to shortcut these more interpretable operations, how often are you actually getting the interpretable one, and what's causing the model to choose it?	I-Review	I-3	Review	596
<sep> <sep> Similarly, how often does an argmax or a max operation actually operate on the full set that you would expect it to?	B-Review	B-3	Review	596
Or does it just do the argmax internal to the network, and output only one item as an argument to the argmax?	I-Review	I-3	Review	596
If the later, this again hurts your claims of better interpretability over prior methods, as the logic is just as opaque as before.	I-Review	I-3	Review	596
This also seems like a really hard search problem in how you've set up your DSL - what would make your search over programs actually select all of the correct arguments?	I-Review	I-3	Review	596
Because you're selecting passage spans directly instead of performing some kind of matching operation, you have to have your search select all of the appropriate spans for this to be "interpretable", and not just hiding the logic inside of the network.	I-Review	I-3	Review	596
But that seems like a totally intractable search.	I-Review	I-3	Review	596
You found a clever way to get around this for count questions (even though that still implicitly hides a bunch of filtering logic, as noted above), but I don't know how to make it work for maxes and argmaxes.	I-Review	I-3	Review	596
<sep> <sep> Another question raised by the passage-span predicate: the more you use bare passage-span programs for training, the more the network learns to put all of its compositional reasoning inside, in an opaque way, instead of giving you interpretable compositionality.	B-Review	B-3	Review	596
At one extreme, you end up with something like NABERT (or even less compositional), where basically everything is inside the network.	I-Review	I-3	Review	596
At the other extreme, where you don't have passage-span, you are left with a crippled semantic parser that can't handle most of the questions.	I-Review	I-3	Review	596
But using the predicate introduces tension in the model between interpretability and flexibility.	I-Review	I-3	Review	596
How do we resolve this tension?	I-Review	I-3	Review	596
(This isn't something I expect your paper to address, it's just a really interesting and important question raised by your work.)	I-Review	I-3	Review	596
<sep> <sep> Parser:	O	O	Review	596
<sep> Prior work has found benefit in using runtime constraints on parser outputs, or grammar-based decoding.	B-Review	B-4	Review	596
It looks like you are doing neither of those, yet you're able to output specific token indices and number indices in your programs.	I-Review	I-4	Review	596
Are you really not doing anything special to handle those?	I-Review	I-4	Review	596
How does the decoder know token indices?	I-Review	I-4	Review	596
I feel like something must be missing here, or a simple LSTM decoder is more magical than I thought.	I-Review	I-4	Review	596
<sep> <sep> Evaluation:	O	O	Review	596
<sep> Why only show results on DROP dev, and not on the test set?	B-Review	B-5	Review	596
It's possible that your higher numbers are because you were better able to overfit to the dev set, which you presumably used during training.	I-Review	I-5	Review	596
(I don't think that that's likely, but it's a concern that would be easily avoided by evaluating on test.)	I-Review	I-5	Review	596
Thanks for appreciating our work and your insightful comments!	O	O	Reply	596
We respond to your questions below in terms of Contributions, Compositionality, Interpretability, Parser details and Evaluation.	O	O	Reply	596
<sep> <sep> Clarifications on contributions	O	O	Reply	596
<sep> (1) We would like to clarify that we did not claim the the model is fully interpretable, solves all the compositional questions in DROP, or requires no domain-specific languages.	B-Reply	B-1	Reply	596
Instead, we are arguing that NeRd is *better* than previous methods in these dimensions, so we scoped all the claims in comparison with previous methods in the paper.	I-Reply	I-1	Reply	596
<sep> <sep> (2) We would like to emphasize that the claims, especially the ones on compositionality and easier domain adaptation, are supported by considering *both the experiments on DROP and MathQA*. We have demonstrated that the semantic parsing approach can be applied over text to achieve good performance on DROP, but due to the challenges of searching for highly compositional programs on DROP (more on this in "Compositionality" discussion), the ability of NeRd to generate highly compositional programs are better demonstrated on MathQA.	B-Reply	B-1	Reply	596
And easier domain adaptation is shown by the fact that we applied the same architecture to MathQA using the DSL released by the author of MathQA without any further efforts in DSL or architecture design.	I-Reply	I-1	Reply	596
<sep> <sep> (3) We would like to point out some important differences with previous methods:	O	O	Reply	596
<sep> 1.	O	O	Reply	596
NeRd, which operates over text, is similar to other semantic parsers in that it has the expressive power to generate compositional programs by recursively calling the operators, and uses a single program decoder, e.g., LSTM in our evaluation, to answer different types of questions.	B-Reply	B-1	Reply	596
In contrast, previous methods on DROP rely on designing specialized neural modules to answer different types of questions, and more importantly, those modules cannot be applied recursively or compositionally.	I-Reply	I-1	Reply	596
<sep> <sep> Let‚Äôs take arithmetic as an example, and show how previous approaches would require specialized neural modules to handle it.	I-Reply	I-1	Reply	596
BERT with calculator has to introduce an operator "Sum3" that selects three arguments to support summing up 3 numbers, and extending that approach to handle numerical operations with an arbitrary number of arguments would require creating an exponential number of operators like "Sum4", "Sum2Diff1", etc; on the other hand, these operations can be naturally handled by recursively calling "Sum" and/or "Diff" a few times with a model that supports generating compositional programs such as NeRd.	I-Reply	I-1	Reply	596
MTMSN designs a specialized ‚Äúnegation‚Äù module, which predicts whether a number should be subtracted from 100 to handle negation questions in percentage calculation, e.g., ‚ÄúHow many percent were not German‚Äù, because this type of questions appear frequently in the DROP dataset.	I-Reply	I-1	Reply	596
As you pointed out, NAQANet can add or subtract arbitrary number of numbers by performing a 3-class classification for each number in the passage, representing plus, minus or zero; this design choice is also applied in several subsequent approaches on DROP, e.g., NABERT and MTMSN.	I-Reply	I-1	Reply	596
However, if the questions require more math operators,like in MathQA, this approach cannot easily support complex computations interleaving different types of operators, e.g., ((1+2)*(3-5)+5^2/6), while such questions can be naturally supported by the compositional programs generated by NeRd in our MathQA experiments.	I-Reply	I-1	Reply	596
<sep> <sep> In a word, we agree that if we solely focus on the performance, all these different approaches work reasonably well for arithmetic questions in DROP since they are specially designed for it; however, none of them can be directly adapted to MathQA, which requires highly compositional arithmetic reasoning and a much larger set of operators.	I-Reply	I-1	Reply	596
By providing the model with the capability of generating compositional programs, it is easier to adapt NeRd to other domains than other methods compared in our work.	I-Reply	I-1	Reply	596
These compositional programs are already commonly used in semantic parsing to naturally support complex reasoning without designing specialized neural modules for different types of questions.	I-Reply	I-1	Reply	596
Our contribution, as you noted, is to show that we can apply them to unstructured input as well, i.e., text, to achieve the same adaptability and compositionality.	I-Reply	I-1	Reply	596

In this paper, the authors provide a new neural-net model of logical formulae.	O	O	Review	229
The key feature of the model is that it gathers information about a given formula by traversing its parse tree top-down.	O	O	Review	229
One neural net of the model traverses the parse tree of the formula from the root all the down toward the leaves, and generates vectors for the leaves of the tree.	O	O	Review	229
Then, another RNN-based neural net collects these generated vectors, and answers a query asked for the formula, such as logical entailment.	O	O	Review	229
When experimented with Evans et al's data set for logical entailment queries, the authors' model outperforms existing models that encode formulae by traversing their parse trees bottom-up.	O	O	Review	229
<sep> <sep> I found the idea of traversing a parse tree of a formula top-down and converting it to a vector very interesting.	O	O	Review	229
It is also good to know that the idea leads to a competitive model for at least one dataset.	O	O	Review	229
<sep> <sep> However, I am hesitant to be a strong supporter for this paper.	O	O	Review	229
I feel that the cons and pros of the model and its design decisions are not fully analyzed or explained in the paper; when reading this paper, I wanted to learn a rule of thumb for deciding when (and why if so) a top-down model of logical formulae works better than a bottom-up model.	B-Review	B-1	Review	229
I understand that what I ask for is very difficult to answer, but experiments with more datasets and different types of queries (such as satisfiability) might have made me happier.	I-Review	I-1	Review	229
<sep> <sep> Here are some minor comments.	B-Review	B-2	Review	229
<sep> <sep> * Abstract: I couldn't quite understand your point about atoms.	I-Review	I-2	Review	229
According to Figure 1, there is a neural net for each propositional symbol, and this means that your model tracks information about which occurrences of propositional symbols are about the same one.	I-Review	I-2	Review	229
Is your point about the insensitivity of your model to a specific name given to each symbol?	I-Review	I-2	Review	229
<sep> <sep> * p1: this future ===> this feature	I-Review	I-2	Review	229
<sep> * p2: these constrains ===> these constraints	I-Review	I-2	Review	229
<sep> * p2: recursively build model ===> recursively built model	I-Review	I-2	Review	229
<sep> * p2: Change the font of R in the codomain of ci.	I-Review	I-2	Review	229
<sep> <sep> * p3: p1 at the position of ===> p1 is at the position of	I-Review	I-2	Review	229
<sep> Thank you for your comments.	O	O	Reply	229
Indeed, the question why and when a top-down model outperforms a bottom-up model is crucial.	B-Reply	B-1	Reply	229
However, as you have pointed out, it is likely a difficult question to answer.	I-Reply	I-1	Reply	229
A new Section 3.1 was added to a revised version of the paper, where the inner working of the model is briefly analyzed.	I-Reply	I-1	Reply	229
A top-down model was also tested on formulae from another dataset.	I-Reply	I-1	Reply	229
Although the results are hard to compare directly, it seems that the model does not exploit just one particular dataset.	I-Reply	I-1	Reply	229
Similarly, we can reformulate a TAUT-problem as a SAT-problem by taking the negation of formula.	I-Reply	I-1	Reply	229
The results remain similar on the dataset from Evans et al however, this is hardly surprising, because the problem remains essentially the same from the point of view of a top-down approach.	I-Reply	I-1	Reply	229
<sep> <sep> All your minor comments were incorporated into a revised version of the paper.	B-Reply	B-2	Reply	229

Cons	O	O	Review	229
<sep> 1.	O	O	Review	229
<tab>There is no study of the representations developed by the model, which is unfortunate because this is a conference on learning representations and because there is little light shed on how the network achieves its rather high level of performance.	B-Review	B-1	Review	229
<sep> 2.	O	O	Review	229
<tab>It seems less generally useful to have such a special-purpose network for computing global properties like tautologicality than to have a network that produces actual vector encodings of propositions, as typical of the bottom-up tree-structured models.	B-Review	B-2	Review	229
<sep> <sep> Pros	O	O	Review	229
<sep> 3.	O	O	Review	229
<tab>The paper is quite clear.	O	O	Review	229
<sep> 4.	O	O	Review	229
<tab>The problem is important.	O	O	Review	229
<sep> 5.	O	O	Review	229
<tab>The paper pursues the familiar path of a tree-structured network isomorphic to the parse tree of a propositional-calculus formula, but with the original twist of passing information top-down rather than bottom-up.	O	O	Review	229
<sep> 6.	O	O	Review	229
<tab>The results are impressively strong.	O	O	Review	229
In particular, it improves by 10% absolute over the special-purpose and highly performant PossibleWorldNet on the most difficult category of problems, the ‚Äòmassive‚Äô category, achieving 83.6% accuracy.	O	O	Review	229
<sep> <sep> Pro/Con mix	O	O	Review	229
<sep> 7.	O	O	Review	229
<tab>Although the paper did not provide much insight into what was going on in the network to allow it to perform well (point 1 in ‚ÄòCons‚Äô), I was able to convince myself I could understand a way the architecture *could* succeed (whether this possible approach matches the actual processing in the model I have no way of assessing).	B-Review	B-3	Review	229
In brief, the vector that is passed down the network can be thought of as a list of truth values across multiple possible worlds of the tree node at which the vector resides.	I-Review	I-3	Review	229
To search for a counterexample to tautologicalhood, the original input vector to the root node could be the zero (false) vector.	I-Review	I-3	Review	229
If the kth value in the vector at a parent node labeled ‚Äòor‚Äô is 0 (the disjunction is false in world k) then in the two children the kth value must also be 0.	I-Review	I-3	Review	229
If the kth value of the vector at an XOR node is 0, the kth value of the two children must both be 0 or both be 1; actually these values need not reside in position k so the children could both have value 0 at some position i and both have value 1 at another position j. Then in the RNN-Var component of the network, which checks for consistency across multiple tokens of the same proposition variable, each position k in all vectors for the same variable can be checked for equality, producing a value 1 in the output vector if all have value 1, producing 0 if all have value 0, and producing value -1 if the values do not all agree.	I-Review	I-3	Review	229
Then RNN-All checks across all vectors for proposition variable types to see if there‚Äôs a position k in which no value -1 occurs; if so, the values of the variable vectors at position k give the truth values for all variables such that the overall proposition has the desired value 0: a counterexample exists.	I-Review	I-3	Review	229
If no such position k exists, the proposition is a tautology.	I-Review	I-3	Review	229
This seems roughly right, at least.	I-Review	I-3	Review	229
Thank you for your comments.	O	O	Reply	229
A new Section 3.1 was added to a revised version of the paper, where the inner working of the model is briefly discussed.	B-Reply	B-4	Reply	229
Although it is definitely far from being conclusive, it, hopefully, sheds some light on the model.	I-Reply	I-4	Reply	229
<sep> <sep> Your description (point 7) of how the model can possible work corresponds to the idea behind the model as described in Section 2 and discussed in new Section 3.1.	B-Reply	B-3	Reply	229
An interesting point in your text is that values may change their positions in lists of truth values.	I-Reply	I-3	Reply	229
In fact, something like that can actually happen, but so far, it is really unclear how to do this, because such changes have to be (almost) consistent through the whole model.	I-Reply	I-3	Reply	229
Moreover, to make things even more complicated, different atoms occur at different levels (their depth) in a formula.	I-Reply	I-3	Reply	229
<sep> <sep> You are right (point 2) that the model, in its current form, cannot produce suitable vector encodings of propositions.	B-Reply	B-2	Reply	229
For example, the model is invariant to the renaming of atoms.	I-Reply	I-2	Reply	229
However, for formulae where this is no longer an issue, e.g., sentences in FOL, it is possible to imagine such interpretations even using a top-down approach.	I-Reply	I-2	Reply	229

In this paper the authors propose a neural model that, given a logical formula as input, predicts whether the formula is a tautology or not.	O	O	Review	229
Showing that a formula is a tautology is important because if we can classify a formula A -> B as a tautology then we can say that B is a logical consequence of A. The structure of the formula is a feedforward neural network built in a top-down manner.	O	O	Review	229
The leaves of this network are vectors (each of them represents a particular occurrence of an atom) which, after the construction of the formula, are processed by some recurrent neural networks.	O	O	Review	229
<sep> <sep> The proposed approach seems interesting.	B-Review	B-1	Review	229
However, my main doubt concerns the model.	I-Review	I-1	Review	229
It seems to outperform the state-of-the-art, but the authors do not give any explanations why.	I-Review	I-1	Review	229
There is no theoretical or intuitive explanation of why the model works.	I-Review	I-1	Review	229
Why we need RNNs and not feedforward NNs?	I-Review	I-1	Review	229
I think this is an big issue.	I-Review	I-1	Review	229
<sep> In conclusion, I think that the paper is a bit borderline.	O	O	Review	229
The model should be better explained.	O	O	Review	229
However, I think that the approach is compelling and, after a minor revision, the paper could be considered for acceptance.	O	O	Review	229
<sep> <sep> [Minor comments]	O	O	Review	229
Page 4.	B-Review	B-2	Review	229
<sep> ‚ÄúThe dataset contains train (99876 pairs)‚Äù, pairs of what?	I-Review	I-2	Review	229
<sep> <sep> Page 5.	B-Review	B-3	Review	229
<sep> What is the measure of the values reported in Table 1?	I-Review	I-3	Review	229
Precision?	I-Review	I-3	Review	229
<sep> <sep> Thank you, reviewer 1, for your review.	O	O	Reply	229
I appreciate and understand your position regarding the lack of explanation for the model's performance.	B-Reply	B-1	Reply	229
However, our field is primarily empirical, and it is common for engineering-oriented papers to produce such results which will only be properly understood and explained by further work.	I-Reply	I-1	Reply	229
The literature is rife with examples, from GANs to regularization tricks for RNNs.	I-Reply	I-1	Reply	229
You must ask yourself: are the results sufficiently believable?	I-Reply	I-1	Reply	229
is the study conducted rigorously?	I-Reply	I-1	Reply	229
and have the authors attempted to explain and discuss them to a reasonable extent?	I-Reply	I-1	Reply	229
Please read the author response, revisions to the paper, and be prepared to reconsider your assessment or provide further justification as to why you stand by your current score, if that is what you choose to do.	I-Reply	I-1	Reply	229

This paper addresses the question of how to utilize physical interactions to answer questions about physical outcomes.	O	O	Review	234
This question falls into a popular stream in ML community -- understanding physics.	O	O	Review	234
The paper moved a step further and worked on experimental setups where there is no prior about the physical properties/rules and it uses a deep reinforcement learning (DRL) technique to address the problem.	O	O	Review	234
My overall opinion about this paper is: an interesting attempt and idea, yet without a clear contribution.	O	O	Review	234
<sep> <sep> The experimental setups are quite interesting.	O	O	Review	234
The goal is to figure out which blocks are heavier or which blocks are glued together -- only by pushing and pulling objects around without any prior.	O	O	Review	234
The paper also shows reasonable performances on each task with detailed scenarios.	O	O	Review	234
<sep> <sep> While these experiments and results are interesting, the contribution is unclear.	O	O	Review	234
My main question is: does this result bring us any new insight?	B-Review	B-1	Review	234
While the scenarios are interesting and focused on physical experiments, this is not any more different (potentially easier) than learning from playing games (e.g. Atari).	I-Review	I-1	Review	234
In other words, are the tasks really different from other typical popular DRL tasks?	I-Review	I-1	Review	234
To this end, I would have been more excited if authors showed some more new insights or experiments on learned representations and etc.	O	O	Review	234
Currently, the paper only discusses the factual outcome.	O	O	Review	234
For example, it describes the experimental setup and how much performances an agent could achieve.	O	O	Review	234
The authors could probably dissect the learned representations further, or discuss how the experimental results are linked to the human behavior or physical properties/laws.	O	O	Review	234
<sep> <sep> I am very in-between for my overall rating.	O	O	Review	234
I think the paper could have a deeper analysis.	O	O	Review	234
I however recommend the acceptance because of its merit of the idea.	O	O	Review	234
<sep> <sep> <sep> <sep> The followings are some detailed questions (not directly impacting my overall rating):	O	O	Review	234
(1) Page 2 "we assume that the agent has no prior knowledge about the physical properties of objects, or the laws of physics, and hence must interact with the objects in order to learn to answer questions about these properties.":	B-Review	B-2	Review	234
why does one "must" interact with objects in order to learn about the properties?	I-Review	I-2	Review	234
Can't we also learn through observation?	I-Review	I-2	Review	234
<sep> <sep> (2) Figure 1right is missing a Y-axis label.	B-Review	B-7	Review	234
<sep> <sep> (3) Page 3: A relating to bandit is interesting, but the formal approach is all based on DRL.	B-Review	B-8	Review	234
<sep> <sep> (4) Page 5 "which makes distinguishing between the two heaviest blocks very difficult": I am a bit confused why having a small mass gap makes the task harder (unless it's really close to 0).	B-Review	B-3	Review	234
Shouldn't a machine be possible to distinguish even a pixel difference of speed?	I-Review	I-3	Review	234
If not, isn't this just because of the network architecture?	I-Review	I-3	Review	234
<sep> <sep> (5) Page 5 "Since the agents exhibit similar performance using pixels and features we conduct the remaining experiments in this section using feature observations, since these agents are substantially faster to train.":	O	O	Review	234
How about at least showing a correlation of performances at the instance level (rather than average performances)?	B-Review	B-6	Review	234
Even so, I think this is a bit of big conclusion.	I-Review	I-6	Review	234
<sep> <sep> (6) Throughout the papers, I felt that many conclusions (e.g. difficulty and etc) are based on a particularly chosen training distribution.	B-Review	B-4	Review	234
For example, how does an agent really know when the instance is any more difficult?	I-Review	I-4	Review	234
Doesn't this really depend on the empirically learned distribution of training samples (i.e. P(m_3 | m_1, m_2), where m_i indicates masses of object 1, 2, and 3)?	I-Review	I-4	Review	234
In other words, does what's hard/easy matter much unless this is more thoroughly tested over various types of distributions?	I-Review	I-4	Review	234
<sep> <sep> (7) Any baseline approach?	B-Review	B-5	Review	234
Thank you for your feedback.	O	O	Reply	234
<sep> <sep> With regards to the desire for more analysis of the learned representations, we have added some experiments comparing the learned policies to a randomized baselines.	B-Reply	B-1	Reply	234
These experiments show that when using the learned interaction policies agents are more accurate and often take less time to produce correct outputs as compared to randomized interactions.	I-Reply	I-1	Reply	234
<sep> <sep> We would also draw your attention, particularly for the which is heavier environment, to the experiments where we examine episode length as a function of difficulty.	B-Reply	B-1	Reply	234
These are intended to show that the learned representations include information both about the prior distribution of masses (the population level experiment) as well as information the agent's state of knowledge about the mass gap for individual instances.	I-Reply	I-1	Reply	234
We assess this by measuring the behavior of the agent, but the behavior is wholly determined by the representations.	I-Reply	I-1	Reply	234
<sep> <sep> > "why does one "must" interact with objects in order to learn about the properties?	O	O	Reply	234
Can't we also learn through observation?"	O	O	Reply	234
<sep> <sep> This is intended as a descriptive statement about our particular environments, not as a principle of how learning must happen in a general setting.	B-Reply	B-2	Reply	234
Our environments are designed so that mere passive observation is not sufficient to perform better than chance, and therefore agents "must" interact with the environment in order to learn.	I-Reply	I-2	Reply	234
In real world settings appearance will often provide strong clues as to physical properties, but for this paper we have deliberately removed such clues from our environments.	I-Reply	I-2	Reply	234
<sep> <sep> > I am a bit confused why having a small mass gap makes the task harder (unless it's really close to 0).	O	O	Reply	234
Shouldn't a machine be possible to distinguish even a pixel difference of speed?	O	O	Reply	234
If not, isn't this just because of the network architecture?	O	O	Reply	234
<sep> <sep> <sep> The mass gap is frequently quite small in the more difficult settings (see Figure 1 (right)), when this is not the case the task is reliably solved perfectly.	B-Reply	B-3	Reply	234
It is possible a different architecture or more training would allow the agents to achieve perfect performance on the more difficult settings as well; however, as we argue in our reply to Reviewer 6, achieving perfect performance on this task is not really the point, and the value of doing so is questionable.	I-Reply	I-3	Reply	234
<sep> <sep> > "For example, how does an agent really know when the instance is any more difficult?	O	O	Reply	234
Doesn't this really depend on the empirically learned distribution of training samples (i.e. P(m_3 | m_1, m_2), where m_i indicates masses of object 1, 2, and 3)?"	O	O	Reply	234
<sep> <sep> The agent is not told explicitly about the difficulty of any instance.	B-Reply	B-4	Reply	234
It must come to know which instances are difficult through interaction, and the purpose of the experiments on the which is heavier environment are intended to show that the agent does in fact come to know this.	I-Reply	I-4	Reply	234
The reason for including both population and instance level experiments is to show that what is learned goes beyond simply the conditional distributions of masses: in the instance level experiments the conditional distributions you mention are fixed and we still see behavior that adapts to the difficulty of the individual instances.	I-Reply	I-4	Reply	234
<sep> <sep> > Any baseline approach?	O	O	Reply	234
<sep> <sep> We have added baseline comparisons for both environments.	B-Reply	B-5	Reply	234
Please see the updated version of the paper.	I-Reply	I-5	Reply	234

This paper investigates the question of gathering information (answering question)	O	O	Review	234
through direct interaction with the environment.	O	O	Review	234
In that sense, it is closely	O	O	Review	234
related to "active learning" in supervised learning, or to the fundamental	O	O	Review	234
problem of exploration-exploitation in RL.	O	O	Review	234
The authors consider a specific	O	O	Review	234
instance of this problem in a physics domain and learn	O	O	Review	234
information-seeking policies using recent deep RL methods.	O	O	Review	234
<sep> <sep> The paper is mostly empirical and explores the effect of changing the	O	O	Review	234
cost of information (via the discount factor) on the structure of the learned	O	O	Review	234
policies.	O	O	Review	234
It also shows that general-purpose deep policy gradient methods are	O	O	Review	234
sufficient powerful to learn such tasks.	O	O	Review	234
The proposed environment is, to my knowledge,	O	O	Review	234
novel as well the task formulation in section 2. (	O	O	Review	234
And it would be very valuable to the	O	O	Review	234
the community if the environment would be open-sourced)	O	O	Review	234
<sep> The expression "latent structure/dynamics" is used throughout the text and the connection	B-Review	B-1	Review	234
with bandits is mentioned in section 4.	I-Review	I-1	Review	234
It therefore seems that authors aspire	I-Review	I-1	Review	234
for more generality with their approach but the paper doesn't quite fully ground	I-Review	I-1	Review	234
the proposed approach formally in any existing framework nor does it provide a	I-Review	I-1	Review	234
new one completely.	I-Review	I-1	Review	234
<sep> <sep> For example: how does your approach formalize the concept of "questions" and "answers" ?	B-Review	B-2	Review	234
<sep> What makes a question "difficult" ?	I-Review	I-2	Review	234
How do you quantify "difficulty" ?	I-Review	I-2	Review	234
<sep> How do you define the "cost of information"?	I-Review	I-2	Review	234
What are its units (bits, scalar reward), its semantics ?	I-Review	I-2	Review	234
<sep> Do you you have an MDP or a POMDP ?	I-Review	I-2	Review	234
What kind of MDP do you consider ?	I-Review	I-2	Review	234
<sep> How do you define your discounted MDP ?	I-Review	I-2	Review	234
What is the state and action spaces ?	I-Review	I-2	Review	234
<sep> Some important problem structure under the "interaction/labeling/reward"	I-Review	I-2	Review	234
paragraph of section 2 would be worth expressing directly in your definition	I-Review	I-2	Review	234
of the MDP: labeling actions can only occur during the "labeling phase" and that the transition	I-Review	I-2	Review	234
and reward functions have a specific structure (positive/negative, lead to absorbing state).	I-Review	I-2	Review	234
<sep> The notion of "phase" could perhaps be implemented by considering an augmented state space :	I-Review	I-2	Review	234
<sep> Thank you for your suggestions to improve the precision of the paper.	O	O	Reply	234
In particular, our intent when describing the the Which is Heavier environment as a "latent bandit" seems to have caused quite a bit of confusion and this is connected to our imprecise formulation of our "question answering" framework which you identified earlier.	B-Reply	B-1	Reply	234
We will attempt to make these ideas more precise as we continue to update the paper.	I-Reply	I-1	Reply	234

This paper purports to investigate the ability of RL agents to perform ‚Äòphysics experiments‚Äô in an environment, to infer physical properties about the objects in that environment.	O	O	Review	234
The problem is very well motivated; indeed, inferring the physical properties of objects is a crucial skill for intelligent agents, and there has been relatively little work in this direction, particularly in deep RL.	O	O	Review	234
The paper is also well-written.	O	O	Review	234
<sep> <sep> As there are no architectural or theoretical contributions of the paper (and none are claimed), the main novelty comes in the task application ‚Äì using a recurrent A3C model for two tasks that simulate an agent interacting with an environment to infer physical properties of objects.	O	O	Review	234
More specifically, two tasks are considered ‚Äì moving blocks to determine their mass, and poking towers such that they fall to determine the number of rigid bodies they are composed of.	O	O	Review	234
These of course represent a very limited cross-section of the prerequisite abilities for an agent to understand physics.	B-Review	B-1	Review	234
This in itself is not a bad thing, but since there is no comparison of different (simpler) RL agents on the tasks, it is difficult to determine if the tasks selected are challenging.	I-Review	I-1	Review	234
As mentioned in the pre-review question, the ‚ÄòWhich is Heavier‚Äô task seems quite easy due to the actuator set-up, and the fact that the model simply must learn to take the difference between successive block positions (which are directly encoded as features in most experiments).	I-Review	I-1	Review	234
Thus, it is not particularly surprising that the RL agent can solve the proposed tasks.	I-Review	I-1	Review	234
<sep> <sep> The main claim beyond solving two proposed tasks related to physics simulation is that ‚Äúthe agents learn different strategies for these tasks that balance the cost of gathering information against the cost of making mistakes‚Äù.	O	O	Review	234
The ‚Äòcost of gathering information‚Äô is implemented by multiplying the reward with a value of gamma < 1.	O	O	Review	234
This is somewhat interesting behaviour, but is hardly surprising given the problem setup.	O	O	Review	234
<sep> <sep> One item the authors highlight is that their approach of learning about physical object properties through interaction is different from many previous approaches, which use visual cues.	O	O	Review	234
However, the authors also note that this in itself is not novel, and has been explored in other work (e.g. Agrawal et al (2016)).	B-Review	B-2	Review	234
I think it‚Äôs crucial for the authors to discuss these approaches in more detail (potentially along with removing some other, less relevant information from the related work section), and specifically highlight why the proposed tasks in this paper are interesting compared to, for example, learning to move objects towards certain end positions by poking them.	I-Review	I-2	Review	234
<sep> <sep> To discern the level of contribution of the paper, one must ask the following questions:	B-Review	B-3	Review	234
<sep> 1)<tab>how much do these two tasks contribute (above previous work) to the goal of having agents learn the properties of objects by interaction; and	I-Review	I-3	Review	234
2)<tab>how much do the results of the RL agent on these tasks contribute to our understanding of agents that interact with their environment to learn physical properties of objects?	I-Review	I-3	Review	234
<sep> <sep> It is difficult to know exactly, but due to the concerns outlined above, I am not convinced that the answers to (1) or (2) are ‚Äúto a significant extent‚Äù.	I-Review	I-3	Review	234
In particular, for (1), since the proposed agent is able to essentially solve both tasks, it is not clear that the tasks can be used to benchmark more advanced agents (e.g. it can‚Äôt be used as a set of bAbI-like tasks).	I-Review	I-3	Review	234
<sep> <sep> Another possible concern, as pointed out by Reviewer 3, is that the description of the model is extremely concise.	B-Review	B-4	Review	234
It would be nice to have, for example, a diagram illustrating the inputs and outputs to the model at each time step, to ease replication.	I-Review	I-4	Review	234
<sep> <sep> Overall, it is important to make progress towards agents that can learn to discover physical properties of their environment, and the paper contributes in this direction.	O	O	Review	234
However, the technical contributions of this paper are rather limited ‚Äì thus, it is not clear to what extent the paper pushes forward research in this direction beyond previous work that is mentioned.	B-Review	B-1	Review	234
It would be nice, for example, to have some discussion about the future of agents that learn physics from interaction (speculation on more difficult versions of the tasks in this paper), and how the proposed approach fits into that picture.	I-Review	I-1	Review	234
<sep> ---------------	O	O	Review	234
EDIT: score updated, see comments below	O	O	Review	234
<sep> I should clarify - I would be willing to modify the review if the authors address the following issues:	O	O	Reply	234
<sep> 1) More thorough comparison to the approaches taken in other papers for agents learning physical properties of their environment (e.g. Agrawal et al (2016) and others).	B-Reply	B-1	Reply	234
Why is the approach in this paper measuring something different (in an interesting way) than previous approaches?	I-Reply	I-1	Reply	234
The current related work section has significant breadth, but needs more depth in this area.	I-Reply	I-1	Reply	234
<sep> 2) Similarly, the authors argue that the 'Which is Heavier' task becomes more challenging as the mass gap decreases.	B-Reply	B-3	Reply	234
If the authors want to argue that this is an interesting axis of difficulty, they should explain why in more detail.	I-Reply	I-3	Reply	234
For example, it is unlikely that humans would be able to tell two blocks apart if their mass gap was extremely small -- why is this necessary for artificial agents?	I-Reply	I-3	Reply	234
Shouldn't we focus on one of the many other areas of physics understanding where humans outperform RL agents?	I-Reply	I-3	Reply	234
More discussion of the general direction of physics-learning agents (and how this paper fits in) would greatly benefit the paper.	I-Reply	I-3	Reply	234
<sep> 3) Comparison of some simpler RL baselines on the tasks considered.	B-Reply	B-3	Reply	234

This paper presents interesting experimental findings that state-of-the-art deep reinforcement learning methods enable agent learning of latent (physical) properties in its environment.	O	O	Review	234
The paper formulates the problem of an agent labeling environmental properties after interacting with the environment based on its actions, and applies the deep reinforcement learning model to evaluate whether such learning is possible.	O	O	Review	234
The approach jointly learns the convolutional layers for pixel-based perception and its later layers for learning actions based on reinforcement signals.	O	O	Review	234
<sep> <sep> We have a mixed opinion about this paper.	O	O	Review	234
The paper is written clearly and presents interesting experimental findings.	O	O	Review	234
It introduces and formulates a problem potentially important for many robotics applications.	O	O	Review	234
Simultaneously, the paper suffers from lacking algorithmic contributions and missing (some of) crucial experiments to confirm its true benefits.	O	O	Review	234
<sep> <sep> Pros:	O	O	Review	234
<sep> + This paper introduces a new problem of learning latent properties in the agent's environment.	O	O	Review	234
<sep> <sep> + The paper presents a framework to appropriately combine existing tools to address the formulated problem.	O	O	Review	234
<sep> <sep> + The paper tries reinforcement learning with image inputs and fist-like actuator actions.	O	O	Review	234
This will lead to its direct application to robots.	O	O	Review	234
<sep> <sep> Cons:	O	O	Review	234
<sep> - Lacking algorithmic contribution: this paper applies existing tools/methods to solve the problem rather than developing something new or extending them.	B-Review	B-1	Review	234
The approach essentially is training LSTMs with convolutional layers using the previous Asynchronous Advantage Actor Critic.	I-Review	I-1	Review	234
<sep> <sep> - In the Towers experiment, the results of probably the most important setting, "Fist Pixels", are missing.	B-Review	B-3	Review	234
This setting receiving pixel inputs and using the Fist actuator in a continuous space is the setting closest to real-world robots, and thus is very important to confirm whether the proposed approach will be directly applicable to real-world robots.	I-Review	I-3	Review	234
However, Figure 5 is missing the results with this setting.	I-Review	I-3	Review	234
Is there any reason behind this?	I-Review	I-3	Review	234
<sep> <sep> - The paper lacks its comparison to any baseline methods.	B-Review	B-2	Review	234
Without explicit baselines, it is difficult to see what the agent is really learning and what aspect of the proposed approach is benefitting the task.	I-Review	I-2	Review	234
For instance, in the Towers task, how would an agent randomly pushing/hitting the tower (using 'Fist') a number of times and then passively observing its consequence to produce a label perform compared to this approach?	I-Review	I-2	Review	234
That is, how would an approach with a fixed action policy (but with everything else) perform compared to the full deep reinforcement learning version?	I-Review	I-2	Review	234
Thank you for your balanced feedback.	O	O	Reply	234
<sep> <sep> In addition to the specific issues addressed below, please also see our general reply which addresses the importance and positioning of this paper in spite of not not offering an algorithmic contribution.	O	O	Reply	234
<sep> <sep> To address your concern over the lack of the Fist Pixels setting for the Towers environment, we have conducted the experiment you requested.	B-Reply	B-1	Reply	234
We have added the corresponding plots to the paper which show that the agents are also able to learn in this setting.	I-Reply	I-1	Reply	234
We have also modified the "Waiting for information" experiment to use the Fist Pixels agent (replacing the Fist Features agent we used for this experiment in the original version of the paper).	I-Reply	I-1	Reply	234
Thank you for this suggestion to improve the paper.	I-Reply	I-1	Reply	234
<sep> <sep> Your suggestion to compare against baselines that use a fixed (randomized) policy is a good one.	B-Reply	B-2	Reply	234
We have added experiments on both environments comparing the performance of our agents using learned vs randomized interaction policies (see the updated paper for full details).	I-Reply	I-2	Reply	234
These experiments show that when using the learned interaction policies agents are more accurate and often take less time to produce correct outputs as compared to randomized interactions.	I-Reply	I-2	Reply	234

This paper studies an optimistic variant of AMSGrad algorithm, where an estimate of the future gradient is incorporated into the optimization problem.	O	O	Review	20469
The main claim is that when we have good enough (distance from the ground truth is small) estimate of the unknown gradient, the proposed algorithm will enjoy lower regret.	B-Review	B-4	Review	20469
Theoretical results are provided and experiments are conducted to compare the proposed algorithm with baselines.	I-Review	I-4	Review	20469
The idea seems to be not very novel since the optimistic optimization techniques are borrowed directly from the online optimization field, while it is still interesting to see this kind of work and to see its comparison with existing algorithms in experiments.	I-Review	I-4	Review	20469
However, the comparison seems to be not fair both in theory and experiments.	I-Review	I-4	Review	20469
<sep> <sep> In the second paragraph of Section 2.1, you use to denote an estimate of the loss function.	B-Review	B-5	Review	20469
But later (In the third equation) you use to denote the guess of gradient vector.	I-Review	I-5	Review	20469
The notation is reloaded without any description, which makes the presentation confusing.	I-Review	I-5	Review	20469
<sep> <sep> In addition, at the end of this paragraph, you mentioned that even when is far away from, the regret of an optimistic algorithm is just a constant factor of non-optimistic one.	B-Review	B-6	Review	20469
This seems not rigorous since it is true only when the divergence of from is in constant order.	I-Review	I-6	Review	20469
<sep> <sep> Can you explain why in line 8 of Algorithm 2, you use to update instead of?	B-Review	B-1	Review	20469
A discussion about these choices should be added to the description of algorithm.	I-Review	I-1	Review	20469
<sep> <sep> In the first equation on page 5, the second term on the R.H.S. of the first equation misses a factor of.	B-Review	B-7	Review	20469
Moreover, the second equation should be inequality.	I-Review	I-7	Review	20469
<sep> <sep> In the comparison of equation (2) and (3), I think it should be pointed out that when the gradient has a sparse structure, the regret of the optimistic-AMSGrad in (2) seems to be worse than that of the original AMSGrad.	B-Review	B-2	Review	20469
<sep> <sep> The optimistic algorithm seems to cost more computation in order to estimate the unknown gradient in advance.	B-Review	B-8	Review	20469
In the experiment part, you used the last few iterations to estimate the guess of gradient in the next step.	I-Review	I-8	Review	20469
But it seems that the comparison with is not consistent in many plots since I expected a larger will lead to more accurate estimate.	I-Review	I-8	Review	20469
<sep> <sep> The experiment results seem to be not convincing.	B-Review	B-3	Review	20469
In particular, in Fig.1,2 and others, the training loss of AMSGrad is far away from zero, which implies that the algorithm is not fully optimized.	I-Review	I-3	Review	20469
Therefore, it is hard to draw any meaningful conclusion from the current experiments.	I-Review	I-3	Review	20469
<sep> <sep> In footnote 1, ‚Äúhad been known‚Äù -&gt; ‚Äúhad known‚Äù	B-Review	B-9	Review	20469
<sep> ====after rebuttal	O	O	Review	20469
The authors did not provide satisfying response neither submit any revision to address the questions.	O	O	Review	20469
I will keep my rating.	O	O	Review	20469
Thanks for your valuable suggestions on improving the paper.	O	O	Reply	20469
<sep> 1)<tab>For Algorithm2, the update is based on the standard optimistic updating strategy using the ‚Äúhalf-gradient‚Äù.	B-Reply	B-1	Reply	20469
<sep> 2)<tab>For the experiments, the results of r=3,5,10 not giving a very consistent pattern is partly because that the starting iteration of using the optimistic step is also different (at iteration 3,5,10 respectively, for collecting enough gradients).	B-Reply	B-3	Reply	20469
This brings uncertainty since early start may be either good or bad, depending on different datasets.	I-Reply	I-3	Reply	20469
However, we can see that the test performance is very similar, so we suggest setting r around 5 as a good choice in practice.	I-Reply	I-3	Reply	20469
<sep> <sep> The goal of OPTIMISTIC-AMSGRAD is to improve the sample efficiency: using same number of samples (for example, fixed number of epochs), OPT-AMSGRAD can converge much faster than AMSGRAD and achieve better performance.	B-Reply	B-2	Reply	20469
Furthermore, the test accuracy has become stable in Figure 1,2 and 3, which indicates that OPT-AMSGRAD is better than AMSGRAD in testing phase.	I-Reply	I-2	Reply	20469
For the training loss plots, we try to emphasize the acceleration effect of OPT-AMSGRAD.	I-Reply	I-2	Reply	20469

This paper proposes an online optimization method called Optimistic-AMSGrad, which combines two existing methods: (i) AMSGrad (Reddi et al 2018) and (ii) optimistic online learning where the prediction step is done with the extrapolation algorithm by Scieur et al 2016.	O	O	Review	20469
The authors do a good job of presenting the method (by introducing the background in proper order), the paper seems self-contained and cites the relevant literature.	O	O	Review	20469
The regret analysis of the proposed algorithm is provided, where the obtained regret can be smaller than AMSGrad depending on whether or not the guess of the gradient and the gradient are close.	O	O	Review	20469
<sep> <sep> In my opinion the boundedness assumption (footnote 2) is quite important here, and should be mentioned in the main text.	B-Review	B-6	Review	20469
<sep> <sep> It is not clear how the different ways of accelerations combined in this method interact when the guess is not good.	B-Review	B-3	Review	20469
In other words, if the guess is not good this method could be slower then AMSGrad.	I-Review	I-3	Review	20469
Moreover, AMSGrad has stability property allowed from the ratio between 1st and 2nd moment estimate.	I-Review	I-3	Review	20469
In Optimistic-AMSGrad if m_t is bad, obtaining next w_{t+1} (line 9) would include ratio between outdated/bad 1st mom.	I-Review	I-3	Review	20469
estimate and new 2nd-moment estimate.	I-Review	I-3	Review	20469
In short, the method‚Äôs stability and outperformance might rely on the selection of the algorithm for gradient prediction.	I-Review	I-3	Review	20469
<sep> <sep> In my understanding, extragradient has clear advantages in games, as if considering simple bilinear examples it is the only method that converges.	O	O	Review	20469
However, for a single objective, its advantages are not clear to me (after reading the paper).	B-Review	B-1	Review	20469
Thus, I think it would be useful if the authors could provide comparison over *wall clock time* as well as long-run comparisons when the compared methods converge (it would be interesting to see if Optimistic-AMSGrad obtains better final train/test accuracy?).	I-Review	I-1	Review	20469
In many of the experiments where Opt-AMSGrad outperforms, the accuracy of the baseline still goes up--whereas the latter is computationally cheaper, so it is not clear from the provided results why a practitioner should use this method.	I-Review	I-1	Review	20469
<sep> Moreover, the experimental results would be much more convincing if the authors do multiple runs using different seeds and present mean and standard deviation of the methods.	B-Review	B-2	Review	20469
<sep> In the context of games, using more computationally demanding optimizers makes sense as training is unstable.	B-Review	B-4	Review	20469
In this case, after reading the paper, it is not clear to me what is the problem that the proposed method solves (or its advantages).	I-Review	I-4	Review	20469
Indeed, its advantage depends on how good the guess of g_{t+1} is.	I-Review	I-4	Review	20469
However, the extra-computation cost to obtain a good guess needs to be justified, or proven empirically that gets better performances faster (wall-clock time), or final ones.	I-Review	I-4	Review	20469
<sep> <sep> In summary: (i)  the paper is well-presented and provides hyperparameter sensitivity results; (ii) the paper is very interesting, but (imo) it should leave clearer message why one should use this method; (iii) the proposed method has tighter regret, but only in some (data-dependent) cases and combines existing methods, limiting novelty.	O	O	Review	20469
Hence, given the pros and cons, I am not confident recommending acceptance, and I think improved experimental results (error bars &amp; wall-clock, see above) would make the results more significant.	O	O	Review	20469
<sep> <sep> <sep> --- Minor ---	B-Review	B-5	Review	20469
- Alg.2: maybe add input hyperparameter r to optimistic-AMSGrad and a line between lines 8-9 that calls function which obtains the guess m_{t+1} (r should be passed to it).	I-Review	I-5	Review	20469
It would make it more clear that your algorithm has parameter r (sec.	I-Review	I-5	Review	20469
D.2)	I-Review	I-5	Review	20469
- I could be wrong, but in my opinion, using \theta as first moment est.	I-Review	I-5	Review	20469
is slightly confusing, as it is normally used to denote parameters; similarly, the authors could use hat/prime on top of a variable to denote the ‚Äòguess‚Äô of that same variable, making it easier to follow.	I-Review	I-5	Review	20469
<sep> - maybe add init of \theta_0 in alg1&amp;2	I-Review	I-5	Review	20469
- if I am correct amsgrad also does bias correction of the initial values of 1st and 2nd moment estimates; if that‚Äôs the case it could be useful adding a note that this is omitted for clarity if a reader implements it	I-Review	I-5	Review	20469
- pg2: we just would like -&gt; we would like	I-Review	I-5	Review	20469
<sep> Thanks for your valuable feedback and suggestions.	O	O	Reply	20469
<sep> 1)<tab>Yes, the quality of the guess is very important in OPT-AMSGRAD.	B-Reply	B-1	Reply	20469
As a first attempt, we try to use RMPE and empirically find it effective.	I-Reply	I-1	Reply	20469
More research towards this direction is surely meaningful and interesting.	I-Reply	I-1	Reply	20469
<sep> 2)<tab>Our results are all averaged over 5 trials.	B-Reply	B-2	Reply	20469
We apologize that we did not mention it in the submission.	I-Reply	I-2	Reply	20469
The benefit of ‚Äúoptimistic + online learning‚Äù is the improved sample efficiency, which means that with same number of samples used (e.g. fixed number of epochs), the OPT-AMSGRAD converges faster than the baseline, which could be seen from the experiments.	I-Reply	I-2	Reply	20469
In addition, we find that OPT-AMSGRAD is able to provide better test accuracy as well.	I-Reply	I-2	Reply	20469
The extra cost mainly comes from computing one more gradient in each step.	I-Reply	I-2	Reply	20469
We will provide some more detailed explanation on the computational cost.	I-Reply	I-2	Reply	20469

Summary:	O	O	Review	20469
<sep> <sep> This work proposed a new variant of AMSGrad called Optimistic-AMSGrad, which makes use of the ideas from Optimistic Online learning.	O	O	Review	20469
The authors showed that Optimistic-AMSGrad enjoys lower regret compared with AMSgrad in online learning.	O	O	Review	20469
Experiment results backup their theory.	O	O	Review	20469
<sep> <sep> Pros:	O	O	Review	20469
<sep> This work proposed a new variant of AMSGrad called Optimistic-AMSGrad.	O	O	Review	20469
In the paper the authors showed that by predicting the future gradient using m_t, the regret of Optimistic-AMSGrad can be lowered from \sum |g_t| to \sum |g_t - m_t|, which improves AMSGrad directly.	O	O	Review	20469
The authors also gave a practical way to compute m_t based on history information with the underlying assumption on input x_t.	O	O	Review	20469
The authors provided detailed experiment results to backup their theory.	O	O	Review	20469
<sep> Cons:	O	O	Review	20469
<sep> - There is no discussion about the choice of parameters.	B-Review	B-1	Review	20469
From equation 2, Corollary 1, it seems that to set \beta_2 = 1 achieves the best regret, which implies that to keep v_t unchanged achieves the best result.	I-Review	I-1	Review	20469
That sounds a bit strange because it suggests that the coordinate correction is useless.	I-Review	I-1	Review	20469
I recommend the authors to add some explanation for their corollary here.	I-Review	I-1	Review	20469
<sep> - The intuition behind Algorithm 3 should be demonstrated more clear.	B-Review	B-2	Review	20469
Right now I do not understand how the correlation between x_t affects the prediction of m_t.	I-Review	I-2	Review	20469
The authors should add more explanation in Section 3.	I-Review	I-2	Review	20469
<sep> - The experiment results are not well aligned with theoretical results, since the authors considered convex loss in their proof, while the optimization on neural network is a highly non-convex task.	B-Review	B-3	Review	20469
I suggest the authors add some simple convex examples to demonstrate the superiority of Optimistic-AMSGrad.	I-Review	I-3	Review	20469
<sep> <sep> Thanks for your valuable suggestions.	O	O	Reply	20469
<sep> 1)<tab>The assumption  is mainly for the ease of analysis.	B-Reply	B-1	Reply	20469
This assumption is also adopted in	I-Reply	I-1	Reply	20469
Manzil Zaheer, Sashank Reddi, Devendra Sachan, Satyen Kale, and Sanjiv Kumar.	I-Reply	I-1	Reply	20469
Adaptive methods for nonconvex optimization, NeurIPS 2018	I-Reply	I-1	Reply	20469
2)<tab>We use the RMPE algorithm (Algorithm 3) as a straightforward application for gradient prediction, so we did not include more detailed explanation on it.	B-Reply	B-2	Reply	20469
We will definitely add some given more space.	I-Reply	I-2	Reply	20469

The paper introduces a new intrinsic reward for MARL, representing the causal influence of an agent‚Äôs action on another agent counterfactually.	O	O	Review	670
The authors show this causal influence reward is related to maximising the mutual information between the agents‚Äô actions.	O	O	Review	670
The behaviour of agents using this reward is tested in a set of social dilemmas, where it leads to increased cooperation and communication protocols, especially if given an explicit communication channel.	O	O	Review	670
As opposed to related work, the authors also equip the agents with an internal Model of Other Agents that predicts the actions of other agents and simulates counterfactuals.	O	O	Review	670
This allows the method to run in a decentralized fashion and without access to other agents‚Äô reward functions.	O	O	Review	670
<sep> <sep> The paper proposes a very interesting approach.	O	O	Review	670
I‚Äôm not a MARL expert, so I focused more on the the causal aspects.	O	O	Review	670
The paper seems generally well-organized and well-written, although I‚Äôm a bit confused about the some of the causal modelling decisions and assumptions.	O	O	Review	670
This confusion and  some potential errors, which I describe in detail below, are the reason for my borderline decision, despite liking the paper otherwise.	O	O	Review	670
<sep> First, I‚Äôm a bit confused about the utility of the Section 2.1 model (Figure 1), mostly because of the temporal and multiple agents aspects that seem to be dealt with (‚Äúmore‚Äù) correctly in the MOA model.	B-Review	B-1	Review	670
Specifically in Figure 1, one would need to assume that there is only one agent A influencing agent B at the same time (and agent B does not influence anything else).	I-Review	I-1	Review	670
For example, there is no other agent C which actions also influence agent B, and no agent D that is influenced by agent B, otherwise the backdoor-criterion would not work, unless you add also the action of agent C to the conditioning set (or its state).	I-Review	I-1	Review	670
Importantly, adding the actions of all agents, also a potential agent D that is downstream of B would be incorrect.	I-Review	I-1	Review	670
So in this model there is some kind of same time interaction and there seems to be the need for a causal graph that is known a priori.	I-Review	I-1	Review	670
These problems should disappear if one assumes that only the time t-1 actions can influence the time t actions, as in the MOA model.	I-Review	I-1	Review	670
I assume the idea of the Figure 1 model was to show a relationship with mutual information, but for me specifically it was quite confusing.	I-Review	I-1	Review	670
<sep> <sep> I was much less confused by the MOA causal graph represented in Figure 4, although I suspect there are quite some interactions missing (for example s_t^A causes u_t^A similarly to the green background?	B-Review	B-2	Review	670
s_t causes s_{t+1} (which btw in this case should probably be split in two nodes, one s_{t+1} and one s_{t+1}^B?).	I-Review	I-2	Review	670
Possibly one could also add the previous time step for agent B (with u_{t+1}^B influenced by u_t^B I would assume?).	I-Review	I-2	Review	670
As far as I can see there is no need to condition on a_t^B in this case to see the influence of a_t^A on a_{t+1}^B, u_t^A and s_t^A should be enough?	I-Review	I-2	Review	670
<sep> <sep> Minor details:	O	O	Review	670
Is there possibly a log missing in Eq.2?	B-Review	B-3	Review	670
<sep> <sep> Thanks for your feedback - we are glad that you found the paper interesting, and we hope to be able to clear up any confusion surrounding the causal modeling.	O	O	Reply	670
<sep> <sep> You are correct that the first method of implementing the causal influence reward described in section 2.1 has the important limitation that agents cannot mutually influence each other.	B-Reply	B-1	Reply	670
However, we believe we have handled the conditioning correctly to satisfy the back door criterion, by imposing a sequential ordering on agents‚Äô actions.	I-Reply	I-1	Reply	670
We allow only a fixed number of agents to be influencers, and the rest are influencees.	I-Reply	I-1	Reply	670
Only an influencer gets the causal influence reward, and only an influencee can be influenced.	I-Reply	I-1	Reply	670
At each timestep, the influencers choose their actions first, and these actions are then given as input to the influencees.	I-Reply	I-1	Reply	670
Let‚Äôs say that agent A and B are influencers, and C is an influencee.	I-Reply	I-1	Reply	670
Then C receives both a^A_t and a^B_t as input.	I-Reply	I-1	Reply	670
When computing the causal influence of A on C, we also add a^B_t to the conditioning set, as you describe.	I-Reply	I-1	Reply	670
However, we do not condition on actions downstream of C, as you mention.	I-Reply	I-1	Reply	670
You are correct that in this model the causal graph does need to be known a priori, and in that sense it is more limited.	I-Reply	I-1	Reply	670
We only introduced this initial model as a proof-of-concept, and retained it in the paper because it is associated with some of the interesting qualitative results we present in Section 4.1.	I-Reply	I-1	Reply	670
We will modify the paper to include a more detailed description of the sequential nature of agents‚Äô actions in order to reduce confusion in the future.	I-Reply	I-1	Reply	670
However, you are correct that the MOA approach is likely to be more effective in practice, and we would like to emphasize the success of this approach, and the communication results in Section 4.2, as more important contributions.	I-Reply	I-1	Reply	670
<sep> <sep> You are right that we are missing an arrow from s_t -> s_{t+1}, and the partially observed states s^B_{t+1} in Figure 4; we will add these to the Figure and update it in the next revision.	B-Reply	B-2	Reply	670
You are also correct that we do not need to condition on a_t^B, but we do allow the model to use a_t^B when making its predictions about a_{t+1}^B, so we have shown this as shaded in the Figure.	I-Reply	I-2	Reply	670
<sep> We don‚Äôt believe there is a missing log in equation 2; the log is absorbed into the KL term.	B-Reply	B-3	Reply	670

INTRINSIC SOCIAL MOTIVATION VIA CAUSAL INFLUENCE IN MULTI-AGENT RL	O	O	Review	670
<sep> Main Idea: The authors consider adding a reward term to standard MARL which is the mutual information between its actions and the actions of others.	O	O	Review	670
They show that adding this intrinsic social motivation can lead to increased cooperation in several social dilemmas.	O	O	Review	670
<sep> <sep> Strong Points:	O	O	Review	670
-<tab>This paper is a novel extension of ideas from single agent RL to multi agent RL, there are clear benefits from doing reward shaping in the right way to make deep RL work better.	O	O	Review	670
<sep> -<tab>The paper focuses on cooperative environments which is an underfocused area in RL right now	O	O	Review	670
Weak Points:	O	O	Review	670
-<tab>There is missing discussion of a lot of literature.	B-Review	B-1	Review	670
The causal influence term can be thought of as a form of reward shaping.	I-Review	I-1	Review	670
There is little discussion on the (large) literature on reward shaping to get MARL to exhibit good behavior.	I-Review	I-1	Review	670
<sep> -<tab>The results feel quite thin.	B-Review	B-2	Review	670
Related to the point above: the theory of different types of reward shaping (e.g. optimistic Q-learning, prosociality, etc‚Ä¶) are well understood.	I-Review	I-2	Review	670
It is not clear to me under what conditions the authors‚Äô proposed augmentation to the reward function will lead to better or worse outcomes.	I-Review	I-2	Review	670
The experiments in this paper are quite simple and only span a small set of environments so it would be good to have at least some formal theory.	I-Review	I-2	Review	670
<sep> -<tab>Social dilemmas don‚Äôt seem like the best application.	B-Review	B-3	Review	670
The authors define the social dilemma as: ‚ÄúFor each individual agent, ‚Äòdefecting‚Äô i.e. non-cooperative behavior has the highest payoff.	I-Review	I-3	Review	670
‚Äù With the intrinsic motivation, agents learn to cooperate.	I-Review	I-3	Review	670
This is good, however, if we‚Äôre thinking about situations where agents aren‚Äôt trained together and have their own rewards (the authors‚Äô example: ‚Äúautonomous vehicles are likely to be produced by a wide variety of organizations and institutions with mixed motivations‚Äù) then won‚Äôt these agents be exploited by rational agents?	I-Review	I-3	Review	670
Other solutions to this problem (e.g. recent papers on tit-for-tat by Lerer & Peysakhovich or LOLA by Foerster et al construct agents where defectors get explicitly punished and so don‚Äôt want to try exploiting).	I-Review	I-3	Review	670
Is there something I am missing here?	I-Review	I-3	Review	670
Do the agents learn to punish non-cooperators (if no, isn‚Äôt it rational at that point to just not cooperate and won‚Äôt self-driving cars trained via this method get exploited by others)?	I-Review	I-3	Review	670
<sep> -<tab>Relate to the point(s) above: a better environment for application here seems to be coordination games/‚ÄùStag Hunt‚Äù games where it is known that MARL converges to poor equilibria and many other methods e.g. optimistic Q-learning or prosociality have been invented to make things work better.	B-Review	B-4	Review	670
Perhaps the method proposed here will work better than these (and it has the appealing property that it does not require the ability to observe the other agents' rewards as e.g. prosociality does)	I-Review	I-4	Review	670
-<tab>This paper contains some quite grandiose language connecting the proposed reward shaping to ‚Äúhow humans learn‚Äù (example: It may also have correlates in human cognition; experiments show that newborn infants are sensitive to correspondences between their own actions and the actions of other people, and use this to coordinate their behavior with others) it‚Äôs unclear to me that humans experience extra reward for their actions having high mutual information (and/or causal information with others).	B-Review	B-5	Review	670
While it‚Äôs fine to argue some of these points at a high level I would suggest scrubbing the text of the gratuitous references to this.	I-Review	I-5	Review	670
<sep> <sep> Nits:	O	O	Review	670
‚ÄúCrawford & Sobel (1982) find that once agents‚Äô interests diverge by a finite amount, no communication is to be expected.	O	O	Review	670
‚Äù ‚Äì this is an awkward phrasing of the Crawford and Sobel result (it can be read as ‚Äúif interests diverge by any epsilon there can be no communication‚Äù).	O	O	Review	670
The CS result is that information revealed in communication (in equilibrium) is proportional to amount of common interest.	O	O	Review	670
Thank you for pointing out the connection to related work on reward shaping.	O	O	Reply	670
We initially understood reward shaping to be specific to a given environment, and would argue that intrinsic motivation is designed to be a more general mechanism that works across environments, and thus focused on related work in intrinsic motivation.	B-Reply	B-1	Reply	670
However, at your suggestion we have begun looking for related work in the reward shaping literature (such as [4-5]) and after reading these works in detail, will include references to them in an updated version of the text.	I-Reply	I-1	Reply	670
We are happy to include other specific papers that you can recommend.	I-Reply	I-1	Reply	670
<sep> <sep> You raise an interesting question about whether the influence reward, if used to train autonomous vehicles, could lead to vehicles being exploited for information.	B-Reply	B-3	Reply	670
The example of autonomous driving was mainly meant to illustrate the benefit of decentralized training.	I-Reply	I-3	Reply	670
Obviously the problem of cars driving in the real world is much more complex than the simulations tested here, and so we cannot make claims about whether the influence reward could generalize to this setting.	I-Reply	I-3	Reply	670
However, it is interesting to consider the question of the degree to which the desire to influence may lead to being exploited.	I-Reply	I-3	Reply	670
Since the agents balance both influence and environmental reward based on a hyperparameter, this can be tuned to ensure influence does not override the drive for environmental reward.	I-Reply	I-3	Reply	670
We hypothesize that sharing information is actually a relatively cheap way to influence another agent, without sacrificing much in terms of one‚Äôs own environmental reward; this may protect agents from being unduly exploited.	I-Reply	I-3	Reply	670
However, we should emphasize that we think the approach of training agents with influence goes well beyond the application of autonomous vehicles.	I-Reply	I-3	Reply	670
As we have shown in the paper, influence can be an effective way to train agents to learn to communicate with each other, and could thus be valuable whenever meaningful communication is desired.	I-Reply	I-3	Reply	670
We think that this could be an important and novel contribution to the emergent communication community.	I-Reply	I-3	Reply	670
<sep> <sep> [1] Edward Hughes, Joel Z Leibo, Matthew G Phillips, Karl Tuyls, Edgar A Duenez-Guzman, Antonio Garcƒ±a Castaneda, Iain Dunning, Tina Zhu, Kevin R McKee, Raphael Koster, et al Inequity aversion improves cooperation in intertemporal social dilemmas.	O	O	Reply	670
In Advances in neural information processing systems (NIPS), Montreal, Canada, 2018.	O	O	Reply	670
<sep> <sep> [2] Joel Z Leibo, Vinicius Zambaldi, Marc Lanctot, Janusz Marecki, and Thore Graepel.	O	O	Reply	670
Multi-agent reinforcement learning in sequential social dilemmas.	O	O	Reply	670
In Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems, pp.464‚Äì473.	O	O	Reply	670
International Foundation for Autonomous Agents and Multiagent Systems, 2017.	O	O	Reply	670
<sep> <sep> [3] Devlin, S., Yliniemi, L., Kudenko, D., & Tumer, K. (2014, May).	O	O	Reply	670
Potential-based difference rewards for multiagent reinforcement learning.	O	O	Reply	670
In Proceedings of the 2014 international conference on Autonomous agents and multi-agent systems (pp.165-172).	O	O	Reply	670
International Foundation for Autonomous Agents and Multiagent Systems.	O	O	Reply	670
<sep> <sep> [4] Devlin, S., Yliniemi, L., Kudenko, D., & Tumer, K. (2014, May).	O	O	Reply	670
Potential-based difference rewards for multiagent reinforcement learning.	O	O	Reply	670
In Proceedings of the 2014 international conference on Autonomous agents and multi-agent systems (pp.165-172).	O	O	Reply	670
International Foundation for Autonomous Agents and Multiagent Systems.	O	O	Reply	670
<sep> <sep> [5] Peysakhovich, A., & Lerer, A. (2018, July).	O	O	Reply	670
Prosocial learning agents solve generalized stag hunts better than selfish ones.	O	O	Reply	670
In Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems (pp.2043-2044).	O	O	Reply	670
International Foundation for Autonomous Agents and Multiagent Systems.	O	O	Reply	670

This paper proposes an approach to model social influence in a scenario-independent manner by instantiating the concept of intrinsic motivation and combine various human abilities as part of a reinforcement learning function in order to improve the agent's operation in social dilemma scenarios.	O	O	Review	670
<sep> <sep> Agents are operationalised as convolutional neural network, linear layers and LSTM.	O	O	Review	670
Using these base mechanisms, different abilities (communication, models of other agents (MOA)), their causal influence is inferred based on counterfactual actions.	O	O	Review	670
The architecture is explored across two different sequential social dilemmas.	O	O	Review	670
<sep> <sep> The architecture is described in sufficient detail, with particular focus on the isolation of causal influence for communication and MOA influence.	O	O	Review	670
The experimental evaluation is described in sufficient detail, given the low complexity of the scenarios.	O	O	Review	670
While the agents with communicative ability and MOA show superior performance, a few results warrant clarification.	O	O	Review	670
<sep> <sep> Figure 6a) highlights the performance of influencers in contrast to a visible actions baseline.	B-Review	B-1	Review	670
This specific scenarios shows the necessity to run experiments for larger number of runs, since it appears that action observations may actually outperform influencer performance beyond 3 steps.	I-Review	I-1	Review	670
Please clarify what is happening in this specific case, and secondly, justify your choice of steps used in the experimental evaluation.	I-Review	I-1	Review	670
<sep> <sep> Another results that requires clarification is Figure 6f), which is not sufficiently discussed in the text, yet provides interesting patterns between the MOA baseline performance decaying abruptly at around 3 steps, with the influence MOA variant only peaking after that.	B-Review	B-2	Review	670
Please clarify the observation.	I-Review	I-2	Review	670
Also, could you draw conclusions or directions for a combination of the different approaches to maximise the performance (more generally, beyond this specific observation)?	I-Review	I-2	Review	670
<sep> <sep> A valuable discussion is the exemplification of specific agent behaviour on Page 7.	O	O	Review	670
While it clarifies the signalling of resources in this specific case, it also shows shortcomings of the model's realism.	B-Review	B-3	Review	670
How would the model perform if agents had limited resources and would die upon depletion (e.g. the de facto altruistic influencer in this scenario - since it only performs two distinct actions)?	I-Review	I-3	Review	670
The extent of generalisability should be considered in the discussion.	I-Review	I-3	Review	670
<sep> <sep> In general, the paper motivates and discusses the underlying work in great detail and is written in an accessible manner (minor comment: the acronym LSTM is not explicitly introduced).	B-Review	B-4	Review	670
The quality of presentation is good.	O	O	Review	670
Thanks for your questions about the results in Figure 6.	O	O	Reply	670
With regards to Figure 6a, we set the limit of 3e8 steps for the first two experiments a priori, and did not change it based on the results of the experiments, to ensure we did not bias the results.	B-Reply	B-1	Reply	670
While it does appear that the visible actions baseline may reach the performance of the influence model in this experiment, we consider the initial centralized controller experiments to be a simple proof-of-concept.	I-Reply	I-1	Reply	670
In practice, one would most likely always prefer to use the MOA method for computing influence, since it provides the important benefit that agents do not need to observe each others‚Äô reward or require training with a centralized controller in order to compute influence.	I-Reply	I-1	Reply	670
As is evident in Figures 6c, 13e, and 14e, the MOA method reliably and clearly outperforms all baselines in the Cleanup game.	I-Reply	I-1	Reply	670
<sep> <sep> With regard to Figure 6f, because multi-agent training is highly stochastic and non-stationary, as agents learn to adapt to each other it can change the dynamics of the environment such that formerly effective strategies no longer result in high reward.	B-Reply	B-2	Reply	670
For example, in Harvest, as agents get more proficient at collecting apples efficiently, they may actually deplete the apples faster, thus paradoxically lowering overall reward.	I-Reply	I-2	Reply	670
As noted in Section 6.4 of the Appendix, if one agent fails to learn to collect apples, it actually makes Harvest easier for the other agents, since the apples are less easily exhausted.	I-Reply	I-2	Reply	670
However, if this agent then begins to collect apples they will quickly be exhausted.	I-Reply	I-2	Reply	670
Figure 6f shows some of these unstable dynamics for a single hyperparameter setting with 5 random seeds in Harvest.	I-Reply	I-2	Reply	670
However, Figure 14f in the Appendix plots the same game using 5 hyperparameter settings with 5 seeds each, giving a more stable training curve.	I-Reply	I-2	Reply	670
<sep> <sep> You make an excellent point about the fact that agents must balance their own self-interest with the intrinsic reward of influencing others.	B-Reply	B-3	Reply	670
We actually hypothesize that the reason the agent in the example on page 7 learned to communicate was because communication is the cheapest way to obtain influence while still pursuing its own environment reward.	I-Reply	I-3	Reply	670
In terms of generalizing to new tasks, it is straightforward to tune the parameter which trades off the environment and influence rewards to suit a new task.	I-Reply	I-3	Reply	670
We will add further discussion about this trade off to in an updated version of the paper.	I-Reply	I-3	Reply	670
<sep> <sep> We have also added text introducing the acronym LSTM - thanks for pointing that out.	B-Reply	B-4	Reply	670

This paper proposed a learning to learn (L2L) framework for zeroth-order (ZO) optimization, and demonstrated its effectiveness on black-box adversarial example generation.	O	O	Review	670
The approach is novel since L2L provides a new perspective to zeroth-order optimization.	O	O	Review	670
<sep> <sep> However, I have some concerns about the current version.	O	O	Review	670
<sep> <sep> 1) The knowledge that one should use to train UpdateRNN and  QueryRNN is not clear.	B-Review	B-1	Review	670
A clear presentation is required	I-Review	I-1	Review	670
<sep> 2) Please clarify the optimization variables in (4).	B-Review	B-2	Review	670
In general, the problem is not clearly defined.	I-Review	I-2	Review	670
<sep> <sep> 3) Eq.5 is a query-expensive gradient estimate.	B-Review	B-3	Review	670
Will it make training extremely expensive?	I-Review	I-3	Review	670
<sep> <sep> 4) The computation and query complexity are unclear during training and testing.	B-Review	B-4	Review	670
<sep> <sep> 5) Pros and cons of L2L?	B-Review	B-5	Review	670
It seems that training a L2L network is not easy.	I-Review	I-5	Review	670
Does its advantage exist only when inference?	I-Review	I-5	Review	670
A better discussion should be made.	I-Review	I-5	Review	670
<sep> <sep> ########## post-feedback #######	O	O	Review	670
Thanks for the response.	B-Review	B-5	Review	670
In the pros of L2L, the authors mentioned "The learned optimizer is trained on a small subset of optimization problems and apply in a wide range of problems in similar classes."	I-Review	I-5	Review	670
In the setting of attack generation, does it mean that there exists an attack transferbility from a small group of training images to a large group of testing images?	I-Review	I-5	Review	670
Is the transferbility a requirement for applying L2L in design of attacks.	I-Review	I-5	Review	670
Please try to make these points clearer in the revised version.	I-Review	I-5	Review	670
I keep my decision 'weak accept'.	I-Review	I-5	Review	670
Thank you for your comments and suggestions!	O	O	Reply	670
Here are our responses to your questions.	O	O	Reply	670
<sep> <sep> Q1: The knowledge that one should use to train UpdateRNN and QueryRNN is not clear.	O	O	Reply	670
A clear presentation is required	O	O	Reply	670
<sep> The performance of the RNN optimizer is measured by that of the optimizee whose parameter updates are proposed by the RNN optimizer.	B-Reply	B-1	Reply	670
Thus, we can use the optimizee loss function as part of the objective function (as described in equation (4)) to directly train the parameters of both the UpdateRNN and the QueryRNN, which can be done by truncated BPTT.	I-Reply	I-1	Reply	670
Note that we use zeroth-order optimization method for training the optimizer if the gradients of the optimizee are not available in the training stage either (as described in Section 3.3), the only knowledge we need to train the optimizer is function values rather than explicit gradients of the optimizee.	I-Reply	I-1	Reply	670
So our method can be applied as long as the function values of the optimizee are available.	I-Reply	I-1	Reply	670
<sep> <sep> <sep> Q2: Please clarify the optimization variables in (4).	O	O	Reply	670
In general, the problem is not clearly defined.	O	O	Reply	670
<sep> <sep> Sorry for the confusion.	B-Reply	B-2	Reply	670
To define the objective function (4) more clearly, we rewrite the optimizee‚Äôs parameters \theta_t as \theta_t(\phi) since \theta_t is updated by the RNN optimizer as in equation (2) and thus determined by the RNN optimizer‚Äôs parameters \phi.	I-Reply	I-2	Reply	670
In a slight abuse of notation, we can also rewrite the predicted covariance matrix \Sigma_t as \Sigma_t(\phi) since it is proposed by the QueryRNN as in equation (3).	I-Reply	I-2	Reply	670
The exact optimization variables in equation (4) are the RNN optimizer‚Äôs parameters \phi which include the parameters of both the UpdateRNN and the QueryRNN.	I-Reply	I-2	Reply	670
We have revised Section 3.2 in the paper to make it more clear.	I-Reply	I-2	Reply	670
<sep> <sep> <sep> Q3: Eq.5 is a query-expensive gradient estimate.	O	O	Reply	670
Will it make training extremely expensive?	O	O	Reply	670
<sep> <sep> For problems of high dimensions, the coordinatewise ZO gradient estimator in equation (5) does require function queries linearly scale with the problem dimension.	B-Reply	B-3	Reply	670
But this estimator can be computed in parallel, the computational overhead would be released a lot.	I-Reply	I-3	Reply	670
We have experimented with the MNIST attack task (the problem dimension is 784) to estimate the computation overhead.	I-Reply	I-3	Reply	670
We compare two methods:	I-Reply	I-3	Reply	670
1) use equation (5) to approximate the optimizee gradient.	I-Reply	I-3	Reply	670
<sep> 2) assume the gradient of the optimizee model is available at training time and use traditional backpropagation (note that this assumption is made in Chen et al (2017b) but is usually not the case, so we only use this method as the baseline for comparison).	I-Reply	I-3	Reply	670
<sep> We find that the training time of 1) is about twice that of 2), which is acceptable.	I-Reply	I-3	Reply	670
Moreover, potentially there could be several approaches to further reduce training time, such as sampling d'&lt;d dimensions to estimate the gradient in equation (5) at each iteration.	I-Reply	I-3	Reply	670
<sep> <sep> <sep> Q4: The computation and query complexity are unclear during training and testing.	O	O	Reply	670
<sep> <sep> In the training stage, at each step of the forward pass, the optimizer uses equation (1) to obtain ZO gradient estimator whose query complexity is O(q) where q is the query number.	B-Reply	B-4	Reply	670
In the backward pass, to backpropagate through the optimizee model, we apply coordinatewise ZO gradient estimator in equation (5) to approximate its gradient and its query complexity is O(d) where d is the problem dimension.	I-Reply	I-4	Reply	670
Thus, for each step of the training stage, the total query complexity is O(q+d).	I-Reply	I-4	Reply	670
If the gradient of the optimizee is available during training (which is the assumption made in Chen et al (2017b)), we can use direct backpropagation instead of gradient estimation to train the zeroth-order optimizer, so the query complexity reduces to O(q).	I-Reply	I-4	Reply	670
Note that both equation (1) and (5) can be computed in parallel to reduce computation time.	I-Reply	I-4	Reply	670
<sep> <sep> In the testing stage (when using the optimizer to solve a given optimization problem), we only need to compute equation (1) for the forward pass.	I-Reply	I-4	Reply	670
So for each step, the total query complexity is O(q).	I-Reply	I-4	Reply	670
This is the same with other hand-designed ZO optimizers.	I-Reply	I-4	Reply	670
<sep> <sep> For the computation complexity, most of the ZO optimizers (including the proposed one) have time complexity proportional to the number of queries, so the same observations will hold also for computation complexity.	I-Reply	I-4	Reply	670

This paper proposed a novel learning to learn framework based on zeroth-order optimization.	O	O	Review	670
Specifically, the framework consists of three parts: (1) UpdateRNN for learning the parameter update rules (2) Guided gradient estimation and search (3) QueryRNN that dynamically adapts the Gaussian sampling rules for covariance estimation in (2).	O	O	Review	670
<sep> <sep> Experimental results on generating adversarial examples from black-box machine learning models as well as a binary classification problem demonstrate improved performance over several existing baselines, such as better query efficiency or faster empirical convergence in the loss function.	O	O	Review	670
An ablation study is also conducted to study the effect of each component in the proposed framework.	O	O	Review	670
<sep> <sep> Overall, this paper is pleasant to read and well-motivated.	O	O	Review	670
The applications are of practical importance.	O	O	Review	670
Given that the empirical results suggest faster convergence than the compared methods, it will be great if the authors can also discuss how to prove the improved convergence in theory.	B-Review	B-1	Review	670
<sep> <sep> *** Post-rebuttal comments	O	O	Review	670
I thank the authors for the clarification.	O	O	Review	670
<sep> ***	O	O	Review	670
Thank you for the suggestion!	O	O	Reply	670
In fact, this is still an open problem for the learning to learn community.	B-Reply	B-1	Reply	670
Even in the first-order case, none of the existing work is able to provide an improved convergence rate (or even the same convergence rate) for learned optimizers, compared to the hand-designed ones.	I-Reply	I-1	Reply	670
This is an interesting future direction that we are currently pursuing.	I-Reply	I-1	Reply	670
In our future work, we aim to prove the improved convergence in theory and we have added more discussion in the conclusion part.	I-Reply	I-1	Reply	670

The paper proposes a zeroth-order optimization framework that employs an RNN to modulate the sampling used to estimate gradients and a second RNN that models the parameter update.	O	O	Review	670
More specifically, query directions are sampled from a Gaussian distribution with a diagonal covariance whose evolution is determined by an RNN (QueryRNN).	O	O	Review	670
The resulting gradient estimates are used by an RNN (UpdateRNN) that learns the parameter update rule.	O	O	Review	670
This framework has the stated advantage that, unlike existing work in ZO optimization, it does not rely upon hand-designed strategies to reduce the variance common to ZO gradient estimators.	O	O	Review	670
The paper evaluates the proposed framework on MNIST and CFAR tasks, as well as a synthetic binary classification task.	O	O	Review	670
The results demonstrate faster convergence compared to baseline zeroth-order optimization algorithms, while ablations indicate the contributions of the different model components.	O	O	Review	670
<sep> <sep> The primary contribution of the proposed method is the inclusion of a second network that learns to adapt the covariance of the Gaussian from which  query directions are sampled.	O	O	Review	670
The use of an RNN to model the parameter update rule is borrowed from previous work.	O	O	Review	670
The ablation studies show that the adaptive sampling strategy noticeably improves convergence as does the inclusion of the RNN update (the contribution of UpdateRNN is more significant in one ablation study, while the contribution of QueryRNN is greater in the other).	O	O	Review	670
<sep> <sep> Given that a stated advantage of QueryRNN is reducing variance, it would be beneficial to compare against baselines such as Liu et al 2018a,b and/or Guo et al 2016 which similarly seek to reduce variance.	B-Review	B-1	Review	670
<sep> <sep> The paper includes a large number of typos (e.g., CIFAR--&gt;CIAFR) and grammatical errors, but is otherwise clear.	B-Review	B-2	Review	670
<sep> <sep> ADDITIONAL COMMENTS/QUESTIONS	O	O	Review	670
<sep> * The related work discussion would benefit from a discussion of how Liu et al 2018 and Guo et al 2016 reduce variance	B-Review	B-3	Review	670
<sep> * The computational complexity of the proposed method as compared to the baselines is unclear as is the scalability with dimensionality.	B-Review	B-4	Review	670
At various points, the paper comments that other methods scale poorly with the dimensionality of the query space, which is true of the proposed method unless the operations are parallelized.	I-Review	I-4	Review	670
Is this not possible with the baseline methods?	I-Review	I-4	Review	670
<sep> <sep> * The paper makes hand wavy claims to the fact that modulating the diagonal covariance matrix allows the method to focus on certain subspaces.	B-Review	B-5	Review	670
It would be helpful to make these claims more formal, particularly in light of the fact that the mean does not change.	I-Review	I-5	Review	670
<sep> <sep> * The method relies upon a bit of a hack that samples from a standard Gaussian at random times.	B-Review	B-6	Review	670
How important is this to performance?	I-Review	I-6	Review	670
How sensitive is convergence to the frequency with which standard Gaussian sampling is used?	I-Review	I-6	Review	670
<sep> <sep> * The discussion of Eqn.	B-Review	B-7	Review	670
5 as it relates to Eqn.	I-Review	I-7	Review	670
1 is unclear.	I-Review	I-7	Review	670
<sep> <sep> <sep> UPDATE AFTER AUTHOR RESPONSE	O	O	Review	670
<sep> I appreciate the authors' thorough response, which resolved my primary questions/concerns, including comparisons to existing variance reduction methods (which should be incorporated into the main paper).	O	O	Review	670
Thank you for your comments and suggestions!	O	O	Reply	670
Here are our responses to your questions.	O	O	Reply	670
<sep> <sep> Your first and third questions are both about existing variance reduced methods for zeroth-order optimization.	O	O	Reply	670
We make response to these two questions together.	O	O	Reply	670
<sep> <sep> Q1: Given that a stated advantage of QueryRNN is reducing variance, it would be beneficial to compare against baselines such as Liu et al 2018a,b and/or Guo et al 2016 which similarly seek to reduce variance.	O	O	Reply	670
<sep> <sep> Q3: The related work discussion would benefit from a discussion of how Liu et al 2018 and Guo et al 2016 reduce variance	O	O	Reply	670
<sep> About related work: ZO-SVRG (Liu et al2018b) reduced the variance of random samples by dividing optimization steps into several epochs and maintaining a snapshot point at each epoch whose gradient was estimated using a larger or the full batch.	B-Reply	B-3	Reply	670
And the snapshot point served as a reference in building a modified stochastic gradient estimate at each inner iteration.	I-Reply	I-3	Reply	670
ZO-SZVR-G (Liu et al2018a) adopted a similar strategy and extended it to reduce the variance of both random samples and random query directions.	I-Reply	I-3	Reply	670
AsyDSZOVR (Gu et al 2016) applied a similar variance reduction method in the asynchronous zeroth-order optimization setting.	I-Reply	I-3	Reply	670
We have added this discussion to the related work part.	I-Reply	I-3	Reply	670
<sep> <sep> Comparison with existing methods: Since ZO-SZVR-G is the extension of ZO-SVRG and AsyDSZOVR applies in a different optimization setting (asynchronous zeroth-order optimization), we only compare ZO-SZVR-G with our proposed method.	I-Reply	I-3	Reply	670
We have conducted experiments on MNIST attack task which have been included in Appendix C.4.	I-Reply	I-3	Reply	670
The main result is that ZO-SZVR-G converges faster than ZO-SGD because of reduced variance but leads to higher final loss values, whereas our QueryRNN brings about improvements both in terms of convergence rate and final loss.	I-Reply	I-3	Reply	670
Since ZO-SZVR-G requires extra queries to reduce variance at each iteration and each epoch, we also plot the training loss against query number and observe that ZO-SZVR-G needs more queries than ZO-SGD and our method.	I-Reply	I-3	Reply	670
<sep> <sep> <sep> Q2: The paper includes a large number of typos (e.g., CIFAR--&gt;CIAFR) and grammatical errors, but is otherwise clear.	O	O	Reply	670
<sep> <sep> We are sorry for our mistakes and have corrected them in the revised version.	B-Reply	B-2	Reply	670
<sep> <sep> <sep> Q4: The computational complexity of the proposed method as compared to the baselines is unclear as is the scalability with dimensionality.	O	O	Reply	670
At various points, the paper comments that other methods scale poorly with the dimensionality of the query space, which is true of the proposed method unless the operations are parallelized.	O	O	Reply	670
Is this not possible with the baseline methods?	O	O	Reply	670
<sep> <sep> Sorry for the confusion.	B-Reply	B-4	Reply	670
For ZO optimizers it‚Äôs common to compare the number of queries (or the number of iterations in our experiments because the number of queries is the same at each iteration) required to obtain a certain objective function value, so ‚Äúscalability‚Äù here mainly indicates the number of queries.	I-Reply	I-4	Reply	670
In all the comparisons, our method can reduce the number of queries over existing optimizers.	I-Reply	I-4	Reply	670
Also, we plot the number of queries with respect to dimensionality in Appendix C.1 to illustrate the effectiveness of the QueryRNN in terms of scalability with problem dimensions.	I-Reply	I-4	Reply	670
<sep> <sep> For the parallelization of equation (5), it is only for accelerating training rather than improving the scalability of our method.	B-Reply	B-7	Reply	670
In the comparisons of our method with baseline methods, all methods use the same number of queries at each iteration and we plot the loss against the query (or iteration) number, so the parallelization does nothing to the comparison.	I-Reply	I-7	Reply	670

POST-REBUTTAL FEEDBACK	O	O	Review	20420
<sep> Thanks for your response.	O	O	Review	20420
<sep> <sep> The justifications provided in the response have not convinced me to improve my score.	B-Review	B-10	Review	20420
They are at times hard to understand: For example, the authors have claimed that while their design choice is not reasonable, it is less unreasonable than the other.	I-Review	I-10	Review	20420
<sep> <sep> SUMMARY OF REVIEW	O	O	Review	20420
<sep> The authors have proposed the use of a neural surrogate model in place of the GP posterior mean and a weighted Reptile algorithm to meta-learn the initial weights of the neural surrogate model.	O	O	Review	20420
This approach appears interesting.	O	O	Review	20420
However, there seems to be multiple highly restrictive (at times impractical) assumptions in this work that are atypical of the BO setting adopted by other meta BO algorithms and not discussed, as detailed below.	O	O	Review	20420
Justifications are required.	O	O	Review	20420
<sep> <sep> Clarifications are also needed with regards to how they exactly run their algorithm in the experiments and whether the prior/initial information from related problems/meta tasks provided to the tested algorithms is fair.	O	O	Review	20420
<sep> <sep> <sep> <sep> DETAILED COMMENTS	O	O	Review	20420
<sep> The authors say that "We still use the variance in Eq. (4) to measure uncertainty, because the estimation uncertainty should be independent in individual problems."	B-Review	B-1	Review	20420
This does not seem to hold true.	I-Review	I-1	Review	20420
If a meta task or train set is indeed correlated (or provides information) to the new problem, the posterior variance/uncertainty at a point depends on the observations in the meta task or train set near to this point (see, for example,	I-Review	I-1	Review	20420
Feurer et al (2018)).	I-Review	I-1	Review	20420
Can the authors discuss the implications of such an assumption in their work?	I-Review	I-1	Review	20420
<sep> <sep> Q and Q_i have always been referred to as problems.	B-Review	B-2	Review	20420
In Algorithm 3, Q is suddenly referred to as meta train set.	I-Review	I-2	Review	20420
On page 4, you have said that x^*_i is the minimizer of i-th problem Q_i(x) in meta train set.	I-Review	I-2	Review	20420
Based on these information, I assume that the authors consider x^*_i as the global minimizer and that x^*_i is known in order to compute the rewards.	I-Review	I-2	Review	20420
Can the authors discuss why is this a reasonable assumption?	I-Review	I-2	Review	20420
<sep> <sep> In their proposed weight Reptile algorithm (Algorithm 3), the authors have also assumed access to the black-box functions of the related problems or meta tasks, which is not typical of other meta BO works that only require the existing observations or datasets of the related problems/meta tasks.	B-Review	B-9	Review	20420
As a result, compared with the existing meta BO algorithms, their proposed weighted Reptile is considerably more expensive due to the need to additionally evaluate the black-box functions of the related problems or meta tasks many times during execution.	I-Review	I-9	Review	20420
Can the authors discuss the practical implications of such an assumption and how it affects the types of problems/applications that can be considered by this work?	I-Review	I-9	Review	20420
<sep> <sep> The authors have not provided any justification for their choice of reward on page 4.	B-Review	B-10	Review	20420
If the black-box function is indeed complex and highly varying, the distance between points may not work well at all.	I-Review	I-10	Review	20420
Can the authors provide a justification and discuss the practical implications and limitations with such a choice?	I-Review	I-10	Review	20420
<sep> <sep> Isn't it more natural to consider a single Bayesian neural network instead of using a neural network for the mean and a GP for the variance?	B-Review	B-11	Review	20420
<sep> <sep> For the experiments, it would be good to see two other variants of the proposed algorithm to understand the individual contributions of the neural surrogate model and weighted Reptile algorithm: one without neural surrogate model and the other with simply the use of neural surrogate model.	B-Review	B-3	Review	20420
<sep> <sep> Can the authors explain in greater detail how they run their algorithms (Algorithms 2 and 3) in the experiments?	B-Review	B-12	Review	20420
For example, the authors say that "WRA-N starts with learned initial surrogate model".	I-Review	I-12	Review	20420
I assume that WRA-N refers to Algorithm 3 based on its acronym.	I-Review	I-12	Review	20420
Isn't the learned initial surrogate model the output of WRA-N in the first place?	I-Review	I-12	Review	20420
Also, the graphs in Fig.2 seem to show iteration 1 to 13 in NOE (Algorithm 2).	I-Review	I-12	Review	20420
However, Algorithm 3 accepts N_T = 13 and executes NOE for N_T = 13 (and not 1, 2, or 3, ...) for each problem in each epoch.	I-Review	I-12	Review	20420
How do the authors generate the plot of WRA-N for iterations 1 to 12?	I-Review	I-12	Review	20420
<sep> What seems to make more sense to me is that the authors in fact run Algorithm 2 instead of Algorithm 3 for each experiment and they initialize w in Algorithm 2 to the output of Algorithm 3.	B-Review	B-4	Review	20420
In any case, a clarification is needed here.	I-Review	I-4	Review	20420
<sep> <sep> It is not clear to me whether the initial/prior information from related problems/meta tasks provided to WRA-N, TST-R, AND TSR-M is fair.	B-Review	B-13	Review	20420
Can the authors provide a justification?	I-Review	I-13	Review	20420
<sep> <sep> To clarify, for each related problem/function, only N_T number of datapoints are used to train a corresponding neural network with 1 hidden layer of 15 hidden units?	B-Review	B-5	Review	20420
<sep> <sep> The authors say that "Since TST-R needs base models for combination, we sample 20 points from uniform distribution in (‚àí10, 10) to construct base models."	B-Review	B-6	Review	20420
Is this sampling procedure the same as that in (Wistuba et al 2016)?	I-Review	I-6	Review	20420
<sep> <sep> Can the authors explain the comparable performance of WRA-N and TST-R in Fig.5?	B-Review	B-7	Review	20420
Why are the error bars missing?	I-Review	I-7	Review	20420
<sep> <sep> How does the proposed approach compare with that of Feurer et al (2018)?	B-Review	B-8	Review	20420
<sep> <sep> <sep> <sep> Minor issues	B-Review	B-14	Review	20420
<sep> Page 1, 3: adapt well to new tasks.	I-Review	I-14	Review	20420
<sep> Page 2: The author says "depends on a GP-based surrogate model fitting function values without learnable parameters".	I-Review	I-14	Review	20420
This is not true: The GP hyperparameters need to be learned and they adapt to new problems.	I-Review	I-14	Review	20420
<sep> Page 4: descent order?	I-Review	I-14	Review	20420
<sep> Pages 4, 5: Why is there an input x to Q_i?	I-Review	I-14	Review	20420
<sep> Algorithm 2: t^* should be at the superscript of x.	I-Review	I-14	Review	20420
Equation 7: What is N?	I-Review	I-14	Review	20420
<sep> Page 5: Does it make a difference in the performance when delta is set to 0?	I-Review	I-14	Review	20420
<sep> Page 5: well define meta-features?	I-Review	I-14	Review	20420
Thanks for your review,	O	O	Reply	20420
1 Feurer et al (2018) used linear combination of variance of related problems.	B-Reply	B-1	Reply	20420
It is not reasonable,  first as the variance of  related problems is not determinate as it depends on sampling points.	I-Reply	I-1	Reply	20420
Thus different sampling points can cause different variance, then cause different surface in new problem.	I-Reply	I-1	Reply	20420
Second, in related problems, lower variance means lower uncertainty, then should this lower uncertainty bring to new problem?	I-Reply	I-1	Reply	20420
If so, then in new problems, the variance of points sampled in related problems are low and the variance of points not sampled in related problems are high.	I-Reply	I-1	Reply	20420
It is absurd.	I-Reply	I-1	Reply	20420
<sep> 2 Knowing accurate global minimizer is acctually hard, however, we can use global minimizer of surrogate model.	B-Reply	B-2	Reply	20420
In other words, when meeting a problem, we sampled some points on it and construct a surrrogate model, then using this global minimizer to substitute.	I-Reply	I-2	Reply	20420
<sep> 3 Actually, when tuning hyper-parameters for neural networks, we may have tuned several similar (in structure )networks.	B-Reply	B-2	Reply	20420
Then these knowledge can be used to new tuning process.	I-Reply	I-2	Reply	20420
<sep> 4 May be global minimizer is not a reasonable setting.	B-Reply	B-2	Reply	20420
However, using function value is more unreasonable.	I-Reply	I-2	Reply	20420
Our aim is to finding global minimizer of objective function, thus using distance of global minimizer seems no problem.	I-Reply	I-2	Reply	20420
<sep> 5  'For the experiments, it would be good to see two other variants of the proposed algorithm to understand the individual contributions of the neural surrogate model and weighted Reptile algorithm: one without neural surrogate model and the other with simply the use of neural surrogate model.'	O	O	Reply	20420
<sep> I can give you the comparation about initialization on ablation study (on problem of synthetic function):	B-Reply	B-3	Reply	20420
initialization    |2.1|1.2|  0  |-0.8|-1.1|-1.2|-1.3|-1.4|-1.4|-1.4	I-Reply	I-3	Reply	20420
after training  |0.1|  0 |-0.7|-1.2|-2.4|-3.5|-4.1|-4.8|-5.0|-5.9	I-Reply	I-3	Reply	20420
But how to use WRA without neural surrogate model?	I-Reply	I-3	Reply	20420
WRA is a training method to train neural surroagte models.	I-Reply	I-3	Reply	20420
Without  neural surrogate model, what should WRA learn?	I-Reply	I-3	Reply	20420
<sep> 6 'What seems to make more sense to me is that the authors in fact run Algorithm 2 instead of Algorithm 3 for each experiment and they initialize w in Algorithm 2 to the output of Algorithm 3.'	O	O	Reply	20420
You are right, we do not write clearly.	B-Reply	B-4	Reply	20420
We actually use Alg 2 to get  iterations 1 to 12 and its initialization is got by Alg 3.	I-Reply	I-4	Reply	20420
<sep> 7 'To clarify, for each related problem/function, only N_T number of datapoints are used to train a corresponding neural network with 1 hidden layer of 15 hidden units?'	O	O	Reply	20420
We actually use neural network with 1 hidden layer of 15 hidden units.	B-Reply	B-5	Reply	20420
<sep> 8   'sample 20 points from uniform distribution in (‚àí10, 10)' is the same as Feurer et al (2018) who has compared TST-R.	B-Reply	B-6	Reply	20420
9 TST-R based on linear combination of related problems, thus related problems determine the performance of TST-R. The comparable performance in SVM problem may beacuse this data set is suitable to TST-R. However, other datasets are not so suitable.	B-Reply	B-7	Reply	20420
<sep> 10  I can give you the comparation about Feurer et al (2018) on ablation study (on problem of synthetic function):	B-Reply	B-8	Reply	20420
Feurer et al (2018)   |0.1|  0 |-1.7|-1.7|-1.7|-1.7|-1.7|-2.0|-2.0|-2.1	I-Reply	I-8	Reply	20420
WRA-N                        |0.1|  0 |-1.9|-2.7|-2.8|-2.8|-3.5|-4.1|-4.4|-5.0	I-Reply	I-8	Reply	20420

Summary of the paper:	O	O	Review	20420
The authors propose a meta-learning approach for BO.	O	O	Review	20420
The method consists in using a NN as the predictive mean of the model used to guide the search in BO.	O	O	Review	20420
This NN is initialized cleverly so that its solutions is close to the actual solution to the problem by using related optimization tasks.	O	O	Review	20420
The proposed method is validated on several experiments.	O	O	Review	20420
<sep> <sep> Detailed comments:	O	O	Review	20420
<sep> The writing of the paper needs to be improved.	B-Review	B-9	Review	20420
It has awkward sentences like "Bayesian optimization iteratively samples new point by".	I-Review	I-9	Review	20420
<sep> <sep> The intro on Bayesian optimization has to be improved, it explain very poorly this technique.	B-Review	B-10	Review	20420
<sep> <sep> The description of the MAML method is not clear.	B-Review	B-11	Review	20420
The same for the reptile algorithm.	I-Review	I-11	Review	20420
<sep> <sep> Eq. (3) is wrong.	B-Review	B-12	Review	20420
It does not take into account that the mean of the GP is different from 0.	I-Review	I-12	Review	20420
<sep> <sep> It seems the authors replace the mean of the GP predictive distribution with the output of a neural network.	B-Review	B-13	Review	20420
This is strange and not very well justified.	I-Review	I-13	Review	20420
I would have expected that they use the output of the NN as the GP prior mean, to then compute the GP posterior mean.	I-Review	I-13	Review	20420
<sep> <sep> In the related problems the actual objective is unknown.	B-Review	B-1	Review	20420
How is that difficulty addressed?	I-Review	I-1	Review	20420
<sep> <sep> In Section 3.1, why do not you standardize the output values to have zero mean and unit deviation instead of using the ranking?	B-Review	B-2	Review	20420
<sep> <sep> How are the hyper-parameters of the GP tuned?	B-Review	B-3	Review	20420
It seems GP based method will fail, essentially, because the authors do not consider the posterior distribution of the GP and change the mean of the predictive distribution to be the NN output.	I-Review	I-3	Review	20420
<sep> <sep> There are no error bars for WRA-N in the experiments.	B-Review	B-4	Review	20420
Does this means that only one realization has been carried out?	I-Review	I-4	Review	20420
If so, this is insufficient to extract any conclusion.	I-Review	I-4	Review	20420
The results can be simply obtained by chance.	I-Review	I-4	Review	20420
The authors should consider several repetitions with different random seeds or different problems.	I-Review	I-4	Review	20420
<sep> <sep> The experiments in section 4.1 are non realistic, since the actual shape of the objective function is known beforehand.	B-Review	B-5	Review	20420
<sep> <sep> In section 4.2 it is not clear what relation are between the train / test functions.	B-Review	B-6	Review	20420
Therefore, it is not possible to understand why the proposed approach works better.	I-Review	I-6	Review	20420
<sep> <sep> The experiments need another baseline to compare with.	B-Review	B-7	Review	20420
Namely, the same method in which the NN is randomly initialized.	I-Review	I-7	Review	20420
This will allow to check that the meta-learning procedure is useful.	I-Review	I-7	Review	20420
Currently, it can be the case that the improvements are simply due to using a different model for optimization.	I-Review	I-7	Review	20420
<sep> <sep> Summing up, I think that:	B-Review	B-8	Review	20420
<sep> (1) This paper needs further improvement in the writing.	I-Review	I-8	Review	20420
<sep> <sep> (2) The experimental section is questionable since there are missing methods in the comparison and no error bars in the experiments.	I-Review	I-8	Review	20420
<sep> <sep> Therefore I believe that this paper is still at an early stage and not ready for publication.	O	O	Review	20420
<sep> <sep> Thanks for your review,	O	O	Reply	20420
1 ‚ÄòIn the related problems the actual objective is unknown.	O	O	Reply	20420
How is that difficulty addressed?',	B-Reply	B-1	Reply	20420
We don't need real objective,  just a few number of sampling points.	I-Reply	I-1	Reply	20420
<sep> 2 You can standardize data in  train set but how to standardize data in test set?	B-Reply	B-2	Reply	20420
We only observe few points, standardize is not valid.	I-Reply	I-2	Reply	20420
<sep> 3 ‚ÄòHow are the hyper-parameters of the GP tuned?	O	O	Reply	20420
It seems GP based method will fail, essentially, because the authors do not consider the posterior distribution of the GP and change the mean of the predictive distribution to be the NN output‚Äô I cannot understand what you are talking about.	B-Reply	B-3	Reply	20420
<sep> 4 The randomness of bayesian optimization comes from the randomly sampled initial points.	B-Reply	B-4	Reply	20420
WRA-N doesn't have error bar as it is determinate as we sampled first point by minimizing neural surrogate model.	I-Reply	I-4	Reply	20420
5 'experiments in section 4.1 are non realistic' , we propose a warm starting bayesian 'optimization' method.	B-Reply	B-5	Reply	20420
I don't think it is questionable to optimize a synthetic function.	I-Reply	I-5	Reply	20420
Futhermore, the rest of 3 experiments are real problems.	I-Reply	I-5	Reply	20420
<sep> 6 CEC2017 consists of several test functions, which are used to test efficiency of evolutionary algorithms, just like image-net.	B-Reply	B-6	Reply	20420
And DE is a traditional method using on this dataset.	I-Reply	I-6	Reply	20420
When using an algorithm, hyper-parameters cannot be sensitive (there is a small gap of hyper-parameters between different functions).	I-Reply	I-6	Reply	20420
Thus we set a part of funcitons in CEC2017 to train and others to test.	I-Reply	I-6	Reply	20420
<sep> 7 I can give you the comparation about initialization on ablation study (on problem of synthetic function):	B-Reply	B-7	Reply	20420
initialization    |2.1|1.2|  0  |-0.8|-1.1|-1.2|-1.3|-1.4|-1.4|-1.4	I-Reply	I-7	Reply	20420
after training  |0.1|  0 |-1.9|-2.7|-2.8|-2.8|-3.5|-4.1|-4.4|-5.0	I-Reply	I-7	Reply	20420

Learning from past experience to quickly adapt to a new task has been an important and fast-growing issue in machine learning.	O	O	Review	20420
Such technique facilitates Bayesian optimization as well, warm-starting Bayesian optimization.	O	O	Review	20420
Recently a few methods have been developed along this direction, from designing handcrafted meta-features to learning meta-features.	O	O	Review	20420
The current paper takes a similar step, learning neural surrogate model from related tasks to warm-start Bayesian optimization.	O	O	Review	20420
The main idea is to replace the mean function of GP by neural surrogate model, so that parameterized models are used for meta-training, in the framework of RETILE.	O	O	Review	20420
An idea of weighted REPTILE is another contribution in this paper, where parameter updates are done with weighs defined by rewards.	O	O	Review	20420
<sep> <sep> ---Strength---	O	O	Review	20420
<sep> - Learning initialization for a surrogate model to warm-start Bayesian optimization is a sound approach.	O	O	Review	20420
<sep> <sep> ---Weakness---	O	O	Review	20420
<sep> - While mean function of GP is replaced by a neural surrogate model, the posterior variance of GP should be calculated.	B-Review	B-1	Review	20420
In other words, GP regression should be run in addition to updating the neural surrogate model.	I-Review	I-1	Review	20420
One can use the conditional neural process (instead of GP regression).	I-Review	I-1	Review	20420
Have a look at the ICML18 paper: Marta Garnelo et al (2018), "Conditional neural processes," ICML.	I-Review	I-1	Review	20420
<sep> <sep> ---Comments---	O	O	Review	20420
<sep> - You can also learn an initial mean function of GP.	B-Review	B-2	Review	20420
Any comparison?	I-Review	I-2	Review	20420
<sep> - There is also interesting work on meta Bayesian optimization: Zi Wang et al (2018), "Regret bounds for meta Bayesian optimization," NeurIPS.	B-Review	B-3	Review	20420
<sep> - Ranking loss is used to train neural surrogate models.	B-Review	B-4	Review	20420
It is not clear why minimizing ranking loss makes sense in this case.	I-Review	I-4	Review	20420
It will be different from the mean function of GP regression, so it is not clear what is the behavior of the acquisition function constructed by the neural surrogate model as the posterior variance of GP.	I-Review	I-4	Review	20420
<sep> <sep> Thanks for your review,	O	O	Reply	20420
I have read the paper you mentioned in ICML 2018  Marta Garnelo et al (2018).	B-Reply	B-1	Reply	20420
It seems that this paper learned a conditional process.	I-Reply	I-1	Reply	20420
However, it seems learning a process based on several functions in training set, which means that it needs much sampling points to train.	I-Reply	I-1	Reply	20420
In real problems, we can only sample few points on related problems.	I-Reply	I-1	Reply	20420
Thus this work cannot be used here.	I-Reply	I-1	Reply	20420
<sep> <sep> Ranking loss aims to eliminate the scale problem in real problems.	B-Reply	B-4	Reply	20420
Though we can standardize data in train set, we cannot standandize data in test set.	I-Reply	I-4	Reply	20420

The paper proposes a new generative model based on the Generative Adversarial Network (GAN).	O	O	Review	18
The method disentangles the content and the view of objects without view supervision.	O	O	Review	18
The proposed Generative Multi-View (GMV) model can be considered to be an extension of the traditional GAN, where the GMV takes the content latent  vector and the view latent vector as input.	O	O	Review	18
In addition, the GMV is trained to generate a pair of objects that share the content but with different views.	O	O	Review	18
In this way, the GMV successfully models the content and the view of the objects without using view labels.	O	O	Review	18
The paper also extends GMV into a conditional generative model that takes an input image and generates different views of the object in the input image.	O	O	Review	18
Experiments are conducted on four different datasets to show the generative ability of the proposed method.	O	O	Review	18
<sep> <sep> Positives:	O	O	Review	18
- The proposed method is novel in disentangling the content and the view of objects in a GAN and training the GAN with pairs of objects.	O	O	Review	18
By using pairs that share the content but with different views, the model can be trained successfully without using view labels.	O	O	Review	18
<sep> <sep> - The experimental results on the four datasets show that the proposed network is able to model the context and the view of objects when generating images of these objects.	O	O	Review	18
<sep> <sep> Negatives:	O	O	Review	18
- The paper only shows comparison between the proposed method and several baselines: DCGAN and CGAN.	B-Review	B-1	Review	18
There is no comparison with methods that also disentangle the content from the view such as Mathieu et al 2016.	I-Review	I-1	Review	18
<sep> <sep> - For the comparison with CGAN in Figure 7, it would be better to show the results of C-GMV and CGAN on the same input images.	B-Review	B-2	Review	18
Then it is easier for the readers to see the differences in the results from the two methods.	I-Review	I-2	Review	18
We thank the reviewer for the comments and feedback.	O	O	Reply	18
We apologize for the late reply due to the number of additional experiments that have been made to improve the quality of the paper.	O	O	Reply	18
<sep> <sep> The first concern of the reviewer is about the lack of comparisons with other techniques.	B-Reply	B-1	Reply	18
We updated the paper with results obtained on the same tasks with the approach by Mathieu et al 2016 which is the closest to ours.	I-Reply	I-1	Reply	18
Note that we were able to obtain comparable quality of outputs using the Mathieu et al model by carefully testing many different neural networks architectures, the ones being provided in the open-source implementation, provided by the authors being inefficient on our problems.	I-Reply	I-1	Reply	18
The quality of the generated samples of the different models (GMV, CMGV, GANx, CGAN and Mathieu et al) have been evaluated in terms of quality of the outputs, and in terms of diversity of the generated samples, showing the superiority of our model w.r.t these baselines (new section 5.3, pages 11 to 13 of the new version)	I-Reply	I-1	Reply	18
<sep> We have also taken care to illustrate samples of the different models based on the same input images to allow for a better qualitative comparison  (Figure 8)	B-Reply	B-2	Reply	18

This paper firstly proposes a GAN architecture that aim at decomposing the underlying distribution of a particular class into "content" and "view".	O	O	Review	18
The content can be seen as an intrinsic instantiation of the class that is independent of certain types of variation (eg viewpoint), and a view is the observation of the object under a particular variation.	O	O	Review	18
The authors additionally propose a second conditional GAN that learns to generate different views given a specific content.	O	O	Review	18
<sep> <sep> I find the idea of separating content and view interesting and I like the GMV and CGMV architectures.	B-Review	B-1	Review	18
Not relying on manual attribute/class annotation for the views is also positive.	I-Review	I-1	Review	18
The approach seems to work well for a relatively clean setup such as the chair dataset, but for the other datasets the separation is not so apparent.	I-Review	I-1	Review	18
For example, in figure 5, what does each column represent in terms of view?	I-Review	I-1	Review	18
It seems that it depends heavily on the content.	I-Review	I-1	Review	18
That raises the question of how useful it is to have such a separation between content and views; for some datasets their diversity can be a bottleneck for this partition, making the interpretation of views difficult.	I-Review	I-1	Review	18
<sep> <sep> A missing (supervised) reference that considers also the separation of content and views.	B-Review	B-2	Review	18
<sep> [A] Learning to generate chairs with convolutional neural networks, Alexey Dosovitskiy, Jost Tobias Springenberg, Thomas Brox, CVPR 15	I-Review	I-2	Review	18
<sep> Q:Figure 5, you mean "all images in a column were generated with the same view vector"	B-Review	B-3	Review	18
Q: Why on Figure 7 you use different examples for CGAN?	I-Review	I-3	Review	18
We thank the reviewer for the comments and feedback.	O	O	Reply	18
We apologize for the late reply due to the large number of experiments that have been made to improve the quality of the paper.	O	O	Reply	18
<sep> <sep> As far as we understand, the main concern is about the fact that the interpretation of the notion of view can be difficult depending on the nature of the dataset.	B-Reply	B-1	Reply	18
We agree on that point.	I-Reply	I-1	Reply	18
Indeed, what we call ‚Äòcontent‚Äô in this paper corresponds to the invariant factors contained in a set of images representing a same object, the view corresponding to the remaining ‚Äòchanging‚Äô factors.	I-Reply	I-1	Reply	18
This is the assumption also made for the IBFA and CCA based approaches (see next review).	I-Reply	I-1	Reply	18
We have added a discussion on this point in the paper in the literature review section.	I-Reply	I-1	Reply	18
Note also  that the more difficult interpretation of views in our work is the counterpart of  the increased ability of the method to deal with various datasets.	I-Reply	I-1	Reply	18
<sep> <sep> Concerning the suggested reference, our related work is focused on  models that are not based on view supervision.	B-Reply	B-2	Reply	18
<sep> <sep> Note that we have added a large additional experimental section that objectively evaluates the quality of the generated samples of the different models (GMV, CMGV, GANx, CGAN and Mathieu et al) in terms of quality of the outputs, and in terms of diversity of the generated samples, showing the superiority of our model w.r.t these baselines (new section 5.3, pages 11 to 13 of the new version)	B-Reply	B-3	Reply	18

The paper proposes a GAN-based method for image generation that attempts to separate latent variables describing fixed "content" of objects from latent variables describing properties of "view" (all dynamic properties such as lighting, viewpoint, accessories, etc).	O	O	Review	18
The model is further extended for conditional generation and demonstrated on a range of image benchmark data sets.	O	O	Review	18
<sep> <sep> The core idea is to train the model on pairs of images corresponding to the same content but varying in views, using adversarial training to discriminate such examples from generated pairs.	B-Review	B-1	Review	18
This is a reasonable procedure and it seems to work well, but also conceptually quite straightforward -- this is quite likely how most people working in the field would solve this problem, standard GAN techniques are used for training the generator and discriminator, and the network architecture is directly borrowed from Radford et al (2015) and not even explained at all in the paper.	I-Review	I-1	Review	18
The conditional variant is less obvious, requiring two kinds of negative images, and again the proposed approach seems technically sound.	I-Review	I-1	Review	18
<sep> <sep> Given the simplicity of the algorithmic choices, the potential novelty of the paper lies more in the problem formulation itself, which considers the question of separating two sets of latent variables from each other in setups where one of them (the "view") can vary from pair to pair in arbitrary manner and no attributes characterising the view are provided.	B-Review	B-2	Review	18
This is an interesting problem setup, but not novel as such and unfortunately the paper does not do a very good job in putting it into the right context.	I-Review	I-2	Review	18
The work is contrasted only against recent GAN-based image generation literature (where covariates for the views are often included) and the aspects related to multi-view learning are described only at the level of general intuition, instead of relating to the existing literature on the topic.	I-Review	I-2	Review	18
The only relevant work cited from this angle is Mathieu et al (2016), but even that is dismissed lightly by saying it is worse in generative tasks.	I-Review	I-2	Review	18
How about the differences (theoretical and empirical) between the proposed approach and theirs in disentangling the latent variables?	I-Review	I-2	Review	18
One would expect to see more discussion on this, given the importance of this property as motivation for the method.	I-Review	I-2	Review	18
<sep> <sep> The generative story using three sets of latent variables, one shared, to describe a pair of objects corresponds to inter-battery factor analysis (IBFA) and is hence very closely related to canonical correlation analysis as well (Tucker "An inter-battery method of factor analysis", Psychometrika, 1958; Klami et al "Bayesian canonical correlation analysis", JMLR, 2013).	B-Review	B-3	Review	18
Linear CCA naturally would not be sufficient for generative modeling and its non-linear variants (e.g. Wang et al "Deep variational canonical correlation analysis", arXiv:1610.03454, 2016; Damianou et al "Manifold relevance determination", ICML, 2012) would not produce visually pleasing generative samples either, but the relationship is so close that these models have even been used for analysing setups identical to yours (e.g. Li et al "Cross-pose face recognition by canonical correlation analysis", arXiv:1507.08076, 2015) but with goals other than generation.	I-Review	I-3	Review	18
Consequently, the reader would expect to learn something about the relationship between the proposed method and the earlier literature building on the same latent variable formulation.	I-Review	I-3	Review	18
A particularly interesting question would be whether the proposed model actually is a direct GAN-based extension of IBFA, and if not then how does it differ.	I-Review	I-3	Review	18
Use of adversarial training to encourage separation of latent variables is clearly a reasonable idea and quite likely does better job than the earlier solutions (typically based on some sort of group-sparsity assumption in shared-private factorisation) with the possible or even likely exception of Mathieu at al. (	I-Review	I-3	Review	18
2016), and aspects like this should be explicitly discussed to extend the contribution from pure image generation to multi-view literature in general.	I-Review	I-3	Review	18
<sep> <sep> The empirical experiments are somewhat non-informative, relying heavily on visual comparisons and only satisfying the minimum requirement of demonstrating that the method does its job.	B-Review	B-4	Review	18
The results look aesthetically more pleasing than the baselines, but the reader does not learn much about how the method actually behaves in practice; when does it break down, how sensitive it is to various choices (network structure, learning algorithm, amount of data,  how well the content and view can be disentangled from each other, etc.).	I-Review	I-4	Review	18
In other words, the evaluation is a bit lazy somewhat in the same sense as the writing and treatment of related work; the authors implemented the model and ran it on a collection of public data sets, but did not venture further into scientific reporting of the merits and limitations of the approach.	I-Review	I-4	Review	18
<sep> <sep> Finally, Table 1 seems to have some min/max values the wrong way around.	B-Review	B-5	Review	18
<sep> <sep> <sep> Revision of the review in light of the author response:	O	O	Review	18
The authors have adequately addressed my main remarks, and while doing so have improved both the positioning of the paper amongst relevant literature and the somewhat limited empirical comparisons.	O	O	Review	18
In particular, the authors now discuss alternative multi-view generative models not based on GANs and the revised paper includes considerably extended set of numerical comparisons that better illustrate the advantage over earlier techniques.	O	O	Review	18
I have increased my preliminary rating to account for these improvements.	O	O	Review	18
We thank the reviewer for the comments and feedback.	O	O	Reply	18
We apologize for the late reply due to the large number of experiments that have been made to improve the quality of the paper.	O	O	Reply	18
<sep> <sep> Concerning the fact that our generative model is ‚Äúconceptually quite straightforward‚Äù, we would like to emphasis that the proposed paper is as far as we know the first paper to evaluate this idea of using a discriminator on pairs of outputs for the multiview problem, this discriminator being in charge of telling is the two outputs correspond to the same object.	B-Reply	B-1	Reply	18
<sep> <sep> We acknowledge the reviewer for pointing us this extensive literature on IBFA and on similar ideas in CCA and non linear variants of CCA.	B-Reply	B-3	Reply	18
Of course our method is clearly related to this literature and we added this related work on the state if the art section.	I-Reply	I-3	Reply	18
As suggested by the reviewer the assumption made by our method is very similar to the one made with IBFA models.	I-Reply	I-3	Reply	18
The main difference being in the way the models are learned: by using ‚Äòstrong‚Äò regularization and particular factorization functions in the IBFA literature, or by using a discriminator in our case.	I-Reply	I-3	Reply	18
Note also that most experiments in the IBFA literature are based on datasets where a limited finite number of possible views is provided while our model is evaluated on complex datasets with multiple possible views, without any available view supervision.	I-Reply	I-3	Reply	18
A detailed discussion on this point has been added in Section 6.	I-Reply	I-3	Reply	18
<sep> <sep> About Radford architecture.	B-Reply	B-1	Reply	18
Yes we do reuse the architecture in [Radford et al 2015] for the DCGAN architecture because the core idea of the paper is elsewhere, as it was the case for [Mathieu et al 2016]. Actually the main features of our method, its ability to learn from data whose views are not aligned between objects and which are unlabeled comes from our particular learning scheme and the way we build pairs of examples.	I-Reply	I-1	Reply	18
This is why we focus the presentation of our method on this particular way of constructing training examples for our models.	I-Reply	I-1	Reply	18
<sep> <sep> Please consider  that we have added a large additional experimental section that objectively evaluates the quality of the generated samples of the different models (GMV, CMGV, GANx, CGAN and Mathieu et al) in terms of quality of the outputs, and in terms of diversity of the generated samples, showing the superiority of our model w.r.t these baselines (new section 5.3, pages 11 to 13 of the new version)	B-Reply	B-4	Reply	18

This paper proposes a generative model for scalable sequential object-oriented representation.	O	O	Review	18
The paper proposes several improvements based on the method SQAIR (Kosiorek et al 2018b), (1) modeling the background and foreground dynamics separately; (2) parallelizing the propagation-discovery process by introducing the propose-reject model which reducing the time complexity.	O	O	Review	18
Finally, the proposed model can deal with orders of magnitude more objects than previous methods, and can model more complex scenes with complex background.	O	O	Review	18
<sep> <sep> Accept.	O	O	Review	18
<sep> The paper is clearly written and the experimental results are well organized.	O	O	Review	18
The results in the paper may be useful for unsupervised multi-objects tracking .I have one concern here,	O	O	Review	18
Ôºà1ÔºâAs argued in the paper, previous methods are difficult to deal with the nearly a hundred objects situation and there is no direct comparison for these methods.	B-Review	B-1	Review	18
So has the author compared the method SCALOR with previous methods in few objects setting?	I-Review	I-1	Review	18
Does the technical improvements of the method benefit in the few objects setting?	I-Review	I-1	Review	18
Thank you for the suggestion.	O	O	Reply	18
Yes, in the revision, we will add two additional experiments in a ‚ÄúVery Low Density (VLD)‚Äù setting, containing up to 4 objects, in which SQAIR works properly, and several different metrics to compare our method to SQAIR quantitatively.	B-Reply	B-1	Reply	18
As we show quantitatively, our method can outperform SQAIR even in those settings, leading to more accurate and consistent bounding boxes.	I-Reply	I-1	Reply	18

I thank the authors for the detailed rebuttal, as well as for the updates to the text and several new experiments in the revised version of the paper.	O	O	Review	18
Most of my comments are addressed well.	O	O	Review	18
I am happy to improve my rating and recommend to accept the paper.	O	O	Review	18
<sep> <sep> ---	O	O	Review	18
<sep> The paper proposes an approach for unsupervised detection and tracking of objects in videos.	O	O	Review	18
The method continues the "Attend, Infer, Repear" (AIR) and Sequential AIR (SQAIR) line of work, but improves on these previous approaches in terms of scalability and can thus be applied to scenes with tens of objects.	O	O	Review	18
The scalability is obtained by replacing, wherever possible, sequential processing of objects by parallel processing.	O	O	Review	18
Experiments are performed on three datasets: moving DSprites, moving MNIST, and the real-world "Crowded Grand Central Station" dataset.	O	O	Review	18
The method seems to work in all cases, as confirmed by quantitative evaluation on the first two datasets and a qualitative evaluation on all three.	O	O	Review	18
<sep> <sep> I recommend rejecting the paper in its current state.	O	O	Review	18
On one hand, the results look quite good, and the method seems to indeed scale well to many objects.	O	O	Review	18
On the other hand, novelty is limited and the experiments are limited in that there are no comparisons with relevant baselines and no clear experiments showing the specific impact of the architectural modifications proposed in this paper.	B-Review	B-1	Review	18
Moreover, the paper is over 9 pages, which, as far as I remember, requires the reviewers apply "higher standards".	B-Review	B-2	Review	18
Overall, I would like the authors to comment on my concerns (below) and may reconsider my rating after that.	I-Review	I-2	Review	18
<sep> <sep> Pros:	O	O	Review	18
1) Relatively clear presentation.	O	O	Review	18
<sep> 2) Judging from the extensive qualitative results and the (limited) quantitative evaluation, the method seems to work.	O	O	Review	18
<sep> 3) I appreciate the additoinal results on generalization and parallel disovery in the appendix.	O	O	Review	18
<sep> <sep> Cons:	O	O	Review	18
1) Novelty of the work seems quite limited.	B-Review	B-1	Review	18
The main contribution is in improving the efficiency of object detection/tracking by parallelizing the computation, without much conceptual innovation.	I-Review	I-1	Review	18
This might be a sufficient contribution (in the end, efficiency is very important for actually applying methods in practice), but then a thorough evaluation of the method would be expected (see further comments about it further).	I-Review	I-1	Review	18
Moreover, the previously published SPAIR method by Crawford and Pineau seems very relevant and related, but is not compared against and is only briefly commented upon, despite the code for that method seems to be available online.	I-Review	I-1	Review	18
I would like the authors to clarify the relation to SPAIR and preferably provide an experimental comparison.	I-Review	I-1	Review	18
<sep> <sep> 2) The experiments are restricted.	O	O	Review	18
While there are quite many qualitative results, several issues remain:	O	O	Review	18
2a) No baseline results are reported.	B-Review	B-3	Review	18
It is thus impossible to judge if the method indeed improves upon related prior works.	I-Review	I-3	Review	18
In particular, comparisons to SQAIR and SPAIR would be very useful.	I-Review	I-3	Review	18
If possible, it would be useful to provide even more baselines, for instance some traditional tracking methods.	I-Review	I-3	Review	18
Comparisons can be both in terms of tracking/reconstruction performanc, as well as in terms of computational efficiency.	I-Review	I-3	Review	18
Both can be measured as functions of the number of objects in the scene.	I-Review	I-3	Review	18
<sep> 2b) There are few quantitative resutls.	B-Review	B-4	Review	18
In experiments 2-4 of section 5.1 it seems it would be fairly easy to introduce some, in particular, one could compare how do these more difficult settings compare to the "default" one.	I-Review	I-4	Review	18
In section 5.2 given that the ground truth tracks are not available, evaluating tracking is challenging, but one could still compare NLL/reconstruction with appropriate baselines.	I-Review	I-4	Review	18
The provided comparison to a vanilla VAE in therms of NLL is actually somewhat confusing - not sure what it tells the reader; moreover, I would actually expect the NLL of the proposed structured model to be better.	I-Review	I-4	Review	18
Why is it not?	I-Review	I-4	Review	18
<sep> 2c) Since the paper is largely about tracking objects through videos, it would be very usefuly to include a supplementary video with qualitative results.	B-Review	B-5	Review	18
<sep> <sep> 3) (minor) Some issues with the presentation:	B-Review	B-6	Review	18
3a) I found the method description at times confusing and incomplete.	I-Review	I-6	Review	18
For instance, it is quite unclear which exactly architectures are used for different components.	I-Review	I-6	Review	18
The details can perhaps bee looked up in the SQAIR paper, but it would still be useful to summarize most crucial points in the supplementary material to make the paper more self-contained.	I-Review	I-6	Review	18
<sep> 3b) The use of \citet vs \citep is often incorrect.	I-Review	I-6	Review	18
\citet should be used when the author names are a part of the text, while \ciptp if the paper is cited in passing, for instance: "Smith et al (2010) have shown that snow is white."	I-Review	I-6	Review	18
vs "It is known that snow is white (Smith et al 2010)."	I-Review	I-6	Review	18
<sep> 3c) Calling AIR a "seminal work in the field of object detection" is not quite correct - object detection is a well-established task in computer vision, and AIR is not really considered a seminal work in that field.	I-Review	I-6	Review	18
It is a great paper, but not really in object detection.	I-Review	I-6	Review	18
The review text states that ‚Äúthe method seems to work‚Äù based on the qualitative results and the limited quantitative evaluation.	O	O	Reply	18
This raises a discussion about the contribution of this paper.	O	O	Reply	18
<sep> <sep> Regarding the quantitative comparison, our response is two-fold.	O	O	Reply	18
<sep> <sep> ** Novelty.	O	O	Reply	18
R1 claims ‚ÄúThe main contribution is in improving the efficiency of object detection/tracking by parallelizing the computation without much conceptual innovation.	O	O	Reply	18
‚Äù	O	O	Reply	18
<sep> Although at first glance, one might assume that the parallelization may be a simple adaptation, we are not simply implementing a parallelization of a sequential model whose parallelization is already straightforward.	B-Reply	B-1	Reply	18
Instead, we *identify the specific reasons that enable a parallelization* and then actually *make it work* with our own new observations, investigations, analysis, and experiments.	I-Reply	I-1	Reply	18
This is not a minor contribution because, in the SPAIR paper, the authors actually state that the sequential computation (within an image) is crucial to obtain the desired results.	I-Reply	I-1	Reply	18
Thus, given this previous state of the art, it is not trivial to devise a parallel algorithm without substantial conceptual innovation.	I-Reply	I-1	Reply	18
Specifically, through our analysis and investigation, we first observe that an efficient parallelization that does not degrade the results is actually feasible, contrary to what was previously believed.	I-Reply	I-1	Reply	18
Our new findings include (1) that in (physical) spatial space, two objects cannot exist in the same position, and, hence, the relation and interference from other objects should not be severe; (2) that considering the bottom-up encoding conditioning on the input image, each object should know what is happening in its immediate surroundings and thus should not need to communicate; and (3) that in the temporal general setting, the past behavior (trajectory) of an object ought to provide strong signals for the inference of an object‚Äôs latent in the future time step. (	I-Reply	I-1	Reply	18
We will clarify these points more thoroughly in the revision.)	I-Reply	I-1	Reply	18
Based on this reasoning, questioning the conclusion in the SPAIR paper, we propose our novel parallelization approach and show empirically that our insights and reasoning are correct, as R1 agrees that ‚Äúthe method seems to work.	I-Reply	I-1	Reply	18
‚Äù Importantly, the SPAIR authors also confirmed via personal communication that they also recently realized that parallelization without performance degradation is possible even if they didn‚Äôt know it when they published SPAIR.	I-Reply	I-1	Reply	18
This confirms that our findings constitute new knowledge correcting a false narrative on an important problem.	I-Reply	I-1	Reply	18
<sep> <sep> In any case, the principal contribution of this paper should be considered from the perspective of sequential modeling.	I-Reply	I-1	Reply	18
As described in the paper, it is highly non-trivial to make a sequential approach scalable.	I-Reply	I-1	Reply	18
This is mainly because of the problem of combining a set of propagated objects with a newly discovered set of objects.	I-Reply	I-1	Reply	18
This bipartite matching problem in object-oriented sequential representation learning has not been noticed in the community before because SQAIR is fully sequential for processing these objects.	I-Reply	I-1	Reply	18
We found that this is an important problem to deal with in order to scale up the model beyond the previous state-of-the-art of operating on just a few objects.	I-Reply	I-1	Reply	18
To resolve this, we devise our proposal-and-rejection mechanism, which may be considered as a key contribution along with the identification of the problem itself.	I-Reply	I-1	Reply	18
Furthermore, demonstrating the feasibility of scaling up such a model to nearly a hundred objects with dynamic background as well as a complex natural scenes should be another dimension of the contribution, considering that the previous state-of-the-art involved operating on a few MNIST digits.	I-Reply	I-1	Reply	18
<sep> <sep> ** Comparison to SPAIR (‚Äúnot compared against SPAIR‚Äù)	O	O	Reply	18
<sep> Unlike SQAIR, SPAIR is not a temporal model.	B-Reply	B-3	Reply	18
It only works on static images, not on video feeds.	I-Reply	I-3	Reply	18
Hence, it cannot track objects, but would need to re-discover objects for each image without providing any tracking information.	I-Reply	I-3	Reply	18
It does not deal with propagation and discovery (everything should be re-discovered).	I-Reply	I-3	Reply	18
It does not deal with the background.	I-Reply	I-3	Reply	18
Given all these reasons, despite our discovery mechanism being partly inspired by SPAIR, a comparison with SPAIR is not an obvious point for evaluation regarding our claimed contributions in the paper.	I-Reply	I-3	Reply	18
Note that our main claim is that the parallel discovery combined with temporal propagation modeling should be better than SQAIR.	I-Reply	I-3	Reply	18
We thus believe, as pointed out by R1, that a comparison to SQAIR is a more reasonable one, which we further explain below.	I-Reply	I-3	Reply	18

UPDATE: My original main concern was the lack of baseline, but during the rebuttal period the authors have conducted the request comparison and addressed my questions satisfactorily.	O	O	Review	18
Therefore, I would recommend the paper be accepted.	O	O	Review	18
<sep> <sep> ---	O	O	Review	18
Summary: This paper proposes a generative model and inference algorithm for discovering and propagating object latents in a way that scales to hundreds of objects.	O	O	Review	18
The key components of their approach is the parallel discovery and propagation of object latents as well as the explicit modeling of the background.	O	O	Review	18
The authors show that the model is able to model and generalize to scenes with hundreds of objects, including a real-world scene of a train station.	O	O	Review	18
<sep> <sep> Research Problem: This paper tackles the problem of scaling object-oriented generative modeling of scenes to scenes with a large number of objects.	O	O	Review	18
<sep> <sep> The main weakness of the submission is the lack of a baseline, and mainly for this result I would recommend rejecting the submission at its current state.	B-Review	B-1	Review	18
However, if the authors are able to revise the submission to include such comparisons (with Kosiorek et al (2018), van Steenkiste et al (2018), and Alahi et al (2016), detailed below), then I would highly consider accepting the paper, as the paper makes a novel contribution to modeling scenes with many more objects than previous work, as far as I am aware.	I-Review	I-1	Review	18
<sep> <sep> Strengths:	O	O	Review	18
- The authors show that the method can model various synthetic and real-world datasets that show the efficacy of the method	O	O	Review	18
- The method can also generalize to more objects and longer timesteps than trained on.	O	O	Review	18
<sep> <sep> Weaknesses:	O	O	Review	18
- The main weakness of the submission is the lack of a baseline.	B-Review	B-1	Review	18
It would be important to understand the differences between Kosiorek et al (2018), which the authors claim is the closest work to theirs, and van Steenkiste et al (2018), which also models objects in a parallel fashion.	I-Review	I-1	Review	18
Alah et al (2016) also takes an approach of dividing the scene into grid cells and also demonstrate results on modeling human trajectories.	I-Review	I-1	Review	18
<sep> - Motivation: Whereas the authors motivate the benefits for modeling objects, the motivation for specifically scaling to model hundreds of objects is less clear.	B-Review	B-2	Review	18
It would be helpful for the authors to provide examples or arguments for the benefits of modeling so many objects at once.	I-Review	I-2	Review	18
One argument against such a need is that humans only pay attention to a few number of objects at a time and do not explicitly model every possible object in parallel.	I-Review	I-2	Review	18
One argument in favor of such a need is the ability to gain superhuman performance on tasks that could benefit from modeling multiple entities, such as playing Starcraft, detecting anamolies in medical scans, or modeling large scale weather patterns.	I-Review	I-2	Review	18
<sep> - A possible limitation of the method may be in modeling interactions between entities.	B-Review	B-3	Review	18
What mechanism in the propagation step allows for modeling such interactions, and if not, how could such a mechanism be incorporated?	I-Review	I-3	Review	18
<sep> - How would SCALOR behave if the grid cells were smaller than the objects?	B-Review	B-4	Review	18
In this case an object may occupy multiple grid cells.	I-Review	I-4	Review	18
Would the authors provide an experiment analyzing this case?	I-Review	I-4	Review	18
Would SCALOR model a object as multiple entities in this case (because the object spans multiple grid cells), or would SCALOR model the object with a single latent variable?	I-Review	I-4	Review	18
<sep> <sep> Question:	O	O	Review	18
- What is the fundamental reason for why the structure of such a generative model would cause the latents to model objects, rather than something else, such as the image patches that show the empty space between objects?	B-Review	B-5	Review	18
<sep> <sep> Alahi, A., Goel, K., Ramanathan, V., Robicquet, A., Fei-Fei, L., &amp; Savarese, S. (2016).	O	O	Review	18
Social lstm: Human trajectory prediction in crowded spaces.	O	O	Review	18
In Proceedings of the IEEE conference on computer vision and pattern recognition (pp.961-971).	O	O	Review	18
<sep> <sep> Van Steenkiste, S., Chang, M., Greff, K., &amp; Schmidhuber, J. (2018).	O	O	Review	18
Relational neural expectation maximization: Unsupervised discovery of objects and their interactions.	O	O	Review	18
arXiv preprint arXiv:1802.10353.	O	O	Review	18
<sep> <sep> Kosiorek, A., Bewley, A., &amp; Posner, I. (2017).	O	O	Review	18
Hierarchical attentive recurrent tracking.	O	O	Review	18
In Advances in Neural Information Processing Systems (pp.3053-3061).	O	O	Review	18
** Baseline: SQAIR	O	O	Reply	18
<sep> &gt; Regarding the issue of baselines, please first refer to the relevant answer to reviewer 1.	O	O	Reply	18
<sep> <sep> ** Baseline: Social LSTM, RNEM, and HART	O	O	Reply	18
<sep> Thank you for pointing out these approaches.	B-Reply	B-1	Reply	18
We notice that the reviewer mentions Kosiorek et al (2018) in the main text but refers to Hierarchical Attentive Recurrent Tracking (HART, 2017) in the reference.	I-Reply	I-1	Reply	18
We believe that the reference to HART is a mistake and the reviewer intended to point to SQAIR. (	I-Reply	I-1	Reply	18
But we still include HART in the following discussion.)	I-Reply	I-1	Reply	18
The four methods mentioned in the review are SQAIR, Social LSTM, RNEM, and HART.	I-Reply	I-1	Reply	18
For the most related work SQAIR, please refer to the relevant answer to reviewer 1.	I-Reply	I-1	Reply	18
<sep> <sep> For the other three approaches, we decided not to include them in our experiment for the following reasons.	I-Reply	I-1	Reply	18
First, all three methods are deterministic (no uncertainty), while SCALOR and SQAIR are probabilistic latent variable models.	I-Reply	I-1	Reply	18
Second, both Social LSTM and HART are supervised methods, while SCALOR and SQAIR are unsupervised.	I-Reply	I-1	Reply	18
Social LSTM requires object coordinates as input instead of raw images, while SQAIR and SPAIR use only raw images as input.	I-Reply	I-1	Reply	18
Thus, it is not practical to compare an unsupervised model to supervised models.	I-Reply	I-1	Reply	18
<sep> <sep> RNEM [1], while unsupervised, is a deterministic model targeting a different task than our work.	I-Reply	I-1	Reply	18
In particular, methods such as RNEM, IODINE [2], MoNet [3], and GENESIS [4] are scene decomposition methods constructing a scene via mixture components.	I-Reply	I-1	Reply	18
SCALOR, SQAIR, SPAIR [5] and AIR [6] take a different approach based on attention (using bounding boxes) to learn ‚Äúobject representations‚Äù rather than a ‚Äúscene decomposition‚Äù.	I-Reply	I-1	Reply	18
Although they are relevant, these are actually quite different approaches.	I-Reply	I-1	Reply	18
For example, the scene decomposition methods do not provide any explicit positions of objects, do not provide its bounding box, and do not explicitly provide counts of objects, or object-level appearance representations (but it is a scene decomposition level).	I-Reply	I-1	Reply	18
Thus, we cannot measure tracking metrics.	I-Reply	I-1	Reply	18
In contrast, the ‚Äúobject-oriented‚Äù methods normally cannot cope with full scenes with backgrounds, but only focus on spatially local objects ‚Äì SCALOR is the first model among the object-oriented methods that can deal with backgrounds.	I-Reply	I-1	Reply	18
Due to this significant difference between these two tasks, no paper has compared both lines of work as baselines.	I-Reply	I-1	Reply	18
Rather, the comparison is made within the relevant line of work.	I-Reply	I-1	Reply	18
For example, IODINE is compared to RNEM but not to AIR.	I-Reply	I-1	Reply	18
NEM [7] also is not compared to AIR.	I-Reply	I-1	Reply	18
Similarly, SPAIR is compared against AIR but not to NEM or RNEM.	I-Reply	I-1	Reply	18
Therefore, it seems that a comparison to SQAIR and VRNN (for generation quality measured by NLL) are the only appropriate baselines focusing on the same task setting.	I-Reply	I-1	Reply	18
In the revision, we thus focus on comparing our method to SQAIR and VRNN.	I-Reply	I-1	Reply	18
<sep> <sep> [1] Van Steenkiste, S., Chang, M., Greff, K., &amp; Schmidhuber, J. (2018).	O	O	Reply	18
Relational neural expectation maximization: Unsupervised discovery of objects and their interactions.	O	O	Reply	18
arXiv preprint arXiv:1802.10353.	O	O	Reply	18
<sep> <sep> [2] Greff, K., Kaufmann, R. L., Kabra, R., Watters, N., Burgess, C., Zoran, D., ... &amp; Lerchner, A. (2019).	O	O	Reply	18
Multi-object representation learning with iterative variational inference.	O	O	Reply	18
arXiv preprint arXiv:1903.00450.	O	O	Reply	18
<sep> <sep> [3] Burgess, C. P., Matthey, L., Watters, N., Kabra, R., Higgins, I., Botvinick, M., &amp; Lerchner, A. (2019).	O	O	Reply	18
Monet: Unsupervised scene decomposition and representation.	O	O	Reply	18
arXiv preprint arXiv:1901.11390.	O	O	Reply	18
<sep> <sep> [4] Engelcke, M., Kosiorek, A. R., Jones, O. P., &amp; Posner, I. (2019).	O	O	Reply	18
GENESIS: Generative Scene Inference and Sampling with Object-Centric Latent Representations.	O	O	Reply	18
arXiv preprint arXiv:1907.13052.	O	O	Reply	18
<sep> <sep> [5] Crawford, E., &amp; Pineau, J. (2019).	O	O	Reply	18
Spatially invariant unsupervised object detection with convolutional neural networks.	O	O	Reply	18
In Proceedings of AAAI.	O	O	Reply	18
<sep> <sep> [6] Eslami, S. A., Heess, N., Weber, T., Tassa, Y., Szepesvari, D., &amp; Hinton, G. E. (2016).	O	O	Reply	18
Attend, infer, repeat: Fast scene understanding with generative models.	O	O	Reply	18
In Advances in Neural Information Processing Systems (pp.3225-3233).	O	O	Reply	18
<sep> <sep> [7] Greff, K., van Steenkiste, S., &amp; Schmidhuber, J. (2017).	O	O	Reply	18
Neural expectation maximization.	O	O	Reply	18
In Advances in Neural Information Processing Systems (pp.6691-6701).	O	O	Reply	18

The authors formulate a recurrent deep neural network to predict human fixation locations in videos as a mixture of Gaussians.	O	O	Review	338
They train the model using maximum likelihood with actual fixation data.	O	O	Review	338
Apart from evaluating how good the model performs at predicting fixations, they combine the saliency predictions with the C3D features for action recognition.	O	O	Review	338
<sep> <sep> quality: I am missing a more thorough evaluation of the fixation prediction performance.	B-Review	B-1	Review	338
The center bias performance in Table 1 differs significantly from the on in Table 2.	I-Review	I-1	Review	338
All the state-of-the-art models reported in Table 2 have a performance worse than the center bias performance reported in Table 1.	I-Review	I-1	Review	338
Is there really no other model better than the center bias?	I-Review	I-1	Review	338
Additionally I am missing details on how central bias and human performance are modelled.	I-Review	I-1	Review	338
Is human performance cross-validated?	I-Review	I-1	Review	338
<sep> <sep> You claim that your "results are very close to human performance (the difference is only 3.2%).	B-Review	B-2	Review	338
This difference is actually larger than the difference between Central Bias and your model reported in Table 1.	I-Review	I-2	Review	338
Apart from this, it is dangerous to compare AUC performance differences due to e.g. saturation issues.	I-Review	I-2	Review	338
<sep> <sep> clarity: the explanation for Table 3 is a bit confusing, also it is not clear why the CONV5 and the FC6 models differ in how the saliency map is used.	B-Review	B-3	Review	338
At least one should also evaluate the CONV5 model when multiplying the input with the saliency map to see how much of the difference comes from the different ways to use the saliency map and how much from the different features.	I-Review	I-3	Review	338
<sep> <sep> Other issues:	O	O	Review	338
<sep> You cite K√ºmmerer et al 2015 as a model which "learns ... indirectly rather than from explicit information of where humans look", however the their model has been trained on fixation data using maximum-likelihood.	B-Review	B-4	Review	338
<sep> <sep> Apart from these issues, I think the paper make a very interesting contribution to spatio-temporal fixation prediction.	O	O	Review	338
If the evaluation issues given above are sorted out, I will happily improve my rating.	O	O	Review	338
As mentioned in the pre-review answer ‚ÄúAnswer to Central Bias‚Äù, the trained central bias is reported in Table 1 while Table 2 reports the manually-created central bias from Mathe & Sminchisescu, 2015.	B-Reply	B-1	Reply	338
The trained central bias is used as a comparative simple baseline that does not consider the content of the frames.	I-Reply	I-1	Reply	338
<sep> Human performance is computed as described below in the pre-review answer ‚ÄúAnswer to empirical distribution‚Äù.	I-Reply	I-1	Reply	338
Since the human performance uses fixations to create the saliency maps, we believe that Mathe & Sminchisescu, 2015 tuned the parameters \sigma and p (Sec.	I-Reply	I-1	Reply	338
4.1).	I-Reply	I-1	Reply	338
However, this information is missing from their paper.	I-Reply	I-1	Reply	338
<sep> We clarified these points in the new version of the manuscript (last paragraph of Sec.4.1).	I-Reply	I-1	Reply	338
<sep> <sep> Our results on Table 2 are in between the human performance and the trained central bias.	B-Reply	B-1	Reply	338
We agree that AUC is not the best metric for evaluation because of the saturation problem.	I-Reply	I-1	Reply	338
In fact we used also NSS, CC and Sim to evaluate the variants of our method.	I-Reply	I-1	Reply	338
However, we needed to use the AUC to compare with the methods of Mathe & Sminchisescu, 2015.	I-Reply	I-1	Reply	338
<sep> <sep> About the evaluation in Table 3, we wanted to evaluate two different ways to merge the saliency map.	B-Reply	B-2	Reply	338
We thank the reviewer for pointing out that one relevant baseline is missing: CONV5 when multiplying the input with the saliency map.	I-Reply	I-2	Reply	338
We are in the process of running this experiment.	I-Reply	I-2	Reply	338
We will report the result as soon as we obtain it.	I-Reply	I-2	Reply	338
<sep> <sep> K√ºmmerer et al 2015 reference was misplaced by mistake.	B-Reply	B-4	Reply	338
In fact, their model is trained on fixations for saliency prediction in images.	I-Reply	I-4	Reply	338
We removed it from the second paragraph of Sec.2.	I-Reply	I-4	Reply	338
2 and correctly placed it in the third paragraph of Sec.	I-Reply	I-4	Reply	338

This work proposes to a spatiotemporal saliency network that is able to mimic human fixation patterns,	O	O	Review	338
thus helping to prune irrelevant information from the video and improve action recognition.	O	O	Review	338
<sep> <sep> The work is interesting and has shown state-of-the-art results on predicting human attention on action videos.	O	O	Review	338
<sep> It has also shown promise for helping action clip classification.	O	O	Review	338
<sep> <sep> The paper would benefit from a discussion on the role of context in attention.	B-Review	B-1	Review	338
<sep> For instance, if context is important, and people give attention to context, why is it not incorporated automatically in your model?	I-Review	I-1	Review	338
<sep> <sep> One weak point is the action recognition section, where the comparison between the two (1)(2) and (3) seems unfair.	B-Review	B-2	Review	338
<sep> The attention weighted feature maps in fact reduce the classification performance, and only improve performance when doubling the feature and associated model complexity by concatenating the weighted maps with the original features.	I-Review	I-2	Review	338
<sep> <sep> Is there a way to combine the context and attention without concatenation?	B-Review	B-3	Review	338
<sep> The rational for concatenating the features extracted from the original clip,	I-Review	I-3	Review	338
and the features extracted from the saliency weighted clip seems to contradict the initial hypothesis that `eliminating or down-weighting pixels that are not important' will improve performance.	I-Review	I-3	Review	338
<sep> <sep> The authors should also mention the current state-of-the-art results in Table 4, for comparison.	B-Review	B-4	Review	338
<sep> <sep> # Other comments:	O	O	Review	338
# Abstract	B-Review	B-5	Review	338
- Typo: `mixed with irrelevant ...'	I-Review	I-5	Review	338
``Time consistency in videos ... expands the temporal domain from few frames to seconds'' - These two points are not clear, probably need a re-write.	I-Review	I-5	Review	338
<sep> <sep> # Contributions	B-Review	B-6	Review	338
- 1) `The model can be trained without having to engineer spatiotemporal features' - you would need to collect training data from humans though..	I-Review	I-6	Review	338
<sep> # Section 3.1	B-Review	B-7	Review	338
The number of fixation points is controlled to be fixed for each frame - how is this done?	I-Review	I-7	Review	338
<sep> <sep> In practice we freeze the layers of the C3D network to values pretrained by Tran etal.	B-Review	B-8	Review	338
<sep> What happens when you allow gradients to flow back to the C3D layers?	I-Review	I-8	Review	338
<sep> Is it not better to allow the features to be best tuned for the final task?	I-Review	I-8	Review	338
<sep> <sep> The precise way in which the features are concatenated needs to be clarified in section 3.4.	B-Review	B-9	Review	338
<sep> <sep> Minor typo:	O	O	Review	338
`we added them trained central bias'	B-Review	B-10	Review	338
The context and attention parts are capturing slightly different information (as confirmed empirically in our study).	B-Reply	B-1	Reply	338
The context features represent the video in its entirety.	I-Reply	I-1	Reply	338
Therefore they may contain elements from the background, which may be useful for action categorization but at times also potentially distracting.	I-Reply	I-1	Reply	338
Instead, the attention part focuses only on the most salient spatiotemporal volumes in the video.	I-Reply	I-1	Reply	338
We agree that there are many other ways to use the saliency maps produced by our model.	I-Reply	I-1	Reply	338
For example, the saliency map could be used to sample higher-resolution crops of the frames.	I-Reply	I-1	Reply	338
We opted for the simplest model in order to show that what is contributing to the improvement in action categorization is truly coming from the saliency map and not from a more complex model.	I-Reply	I-1	Reply	338
<sep> <sep> ‚ÄúComparison between [(1), (2)] and (3) seems unfair.	O	O	Reply	338
‚Äù As we mentioned in the pre-review answer ‚ÄúAnswer to few questions, comments‚Äù, we ran an experiment with PCA to yield the same feature dimensionality as (1) in order to have a more fair comparison.	B-Reply	B-2	Reply	338
The resulting testing mAP of this compressed descriptor (using both context and attention) is 51.82%, which is quite a bit better than method (1) (based on context only), despite having the same dimensionality.	I-Reply	I-2	Reply	338
We added this relevant result to the paper (last paragraph in page 8).	I-Reply	I-2	Reply	338
<sep> <sep> The number of fixations are randomly subsampled (first paragraph, Sec.3.1) if greater than A. Conversely, they are  randomly duplicated if less than A.	B-Reply	B-7	Reply	338
<sep> In our experiments, we froze the layers of the C3D. We ran several fine-tuning experiments for action recognition using the Hollywood2 dataset, however we have never obtained any significant improvement.	B-Reply	B-8	Reply	338
We think that this might be due to the small size of the dataset and to the fact that the C3D features are already representative and general since they were trained on a huge dataset.	I-Reply	I-8	Reply	338
This discouraged us to run fine-tuning experiments for saliency prediction.	I-Reply	I-8	Reply	338
<sep> <sep> About feature concatenation: for each clip, we stacked the d-dimensional context feature vector on top of the d-dimensional attention-based feature vector to form a (2*d)-dimensional descriptor.	B-Reply	B-9	Reply	338

This paper proposes a new method for estimating visual attention in videos.	O	O	Review	338
The input clip is first processed by a convnet (in particular, C3D) to extract visual features.	O	O	Review	338
The visual features are then passed to LSTM.	O	O	Review	338
The hidden state at each time step in LSTM is used to generate the parameters in a Gaussian mixture model.	O	O	Review	338
Finally, the visual attention map is generated from the Gaussian mixture model.	O	O	Review	338
<sep> <sep> Overall, the idea in this paper is reasonable and the paper is well written.	O	O	Review	338
RNN/LSTM has been used in lots of vision problem where the outputs are discrete sequences, there has not been much work on using RNN/LSTM for problems where the output is continuous like in this paper.	O	O	Review	338
<sep> <sep> The experimental results have demonstrated the effectiveness of the proposed approach.	O	O	Review	338
In particular, it outperforms other state-of-the-art on the saliency prediction task on the Hollywood2 datasets.	O	O	Review	338
It also shows improvement over baselines (e.g. C3D + SVM) on the action recognition task.	O	O	Review	338
<sep> <sep> My only "gripe" of this paper is that this paper is missing some important baseline comparisons.	B-Review	B-1	Review	338
In particular, it does not seem to show how the "recurrent" part help the overall performance.	I-Review	I-1	Review	338
Although Table 2 shows RMDN outperforms other state-of-the-art, it might be due to the fact that it uses strong C3D features (while other methods in Table 2 use traditional handcrafted features).	I-Review	I-1	Review	338
Since saliency prediction is essentially a dense image labeling problem (similar to semantic segmentation).	I-Review	I-1	Review	338
For dense image labeling, there has been lots of methods proposed in the past two years, e.g. fully convolution neural network (FCN) or deconvnet.	I-Review	I-1	Review	338
A straightforward baseline is to simply take FCN and apply it on each frame.	I-Review	I-1	Review	338
If the proposed method still outperforms this baseline, we can know that the "recurrent" part really helps.	I-Review	I-1	Review	338
<sep> <sep> <sep> <sep> We agree with the reviewer that it is instructive to separately assess the importance of the recurrent part of our model.	B-Reply	B-1	Reply	338
However, we believe that comparing our model with a fully convolutional network or a deconvolutional network would not provide an answer to this question, since these are methods that differ considerably from our proposed model, not only in their lack of recurrence.	I-Reply	I-1	Reply	338
If the reviewer agrees, we propose instead to run a more informative ablation study, involving the removal of the recurrent link between time t-1 and time t from our model.	I-Reply	I-1	Reply	338
This will provide a more direct answer concerning the usefulness of recurrency.	I-Reply	I-1	Reply	338

Paper summary: The paper presents a 2-step approach to generate strong adversarial examples at a far lesser cost as compared to recent iterative multi-step adversarial attacks.	O	O	Review	808
The authors show the improvements of this technique against different attacks and show that the robustness of their 2-step approach is comparable to the iterative multi-step methods.	O	O	Review	808
<sep> <sep> The paper presents an interesting technique, is nicely written and easy to read.	O	O	Review	808
The fact that their low-cost 2-step method achieves is robust enough to iterative multi-step methods that are expensive is significant.	O	O	Review	808
<sep> Pros:	O	O	Review	808
1) The technique is low-cost as compared to other expensive techniques like PGD and IFGSM	O	O	Review	808
2) The technique tries to use the categorical distribution of the generated example in the first step to generate an example in the second step, such that the generated image is most different from the first.	O	O	Review	808
This is important and different from the most common technique of iteratively maximizing the loss between the generated samples.	O	O	Review	808
<sep> 3) The authors show the effetiveness  and improvement of the approach to various attack methods as compared to existing defense techniques	O	O	Review	808
4) The authors evaluate their technique on MNIST and SVHN datasets	O	O	Review	808
<sep> <sep> Cons or shortcomings/things that need more explanation :	O	O	Review	808
1) It would have been really good to the kind of adversarial examples generated by this technique look like as compared to the examples generated by the other strategies.	B-Review	B-1	Review	808
<sep> 2) In table 2, for the substitute models of FGSM trained on H and S labels (rows 2 and 5), it is unclear why the accuracies are so low when attacked on FGSM (hard) and FGSM(soft) models.	B-Review	B-2	Review	808
<sep> FGSM and I-FGSM are not strong attacks and evaluating against them does not mean much - a lot of approaches that claim increased robustness simply cause gradient masking by making the optimization landscape more difficult.	B-Reply	B-2	Reply	808
The proposed defense has all the hallmarks of gradient masking and will likely break when attacked with PGD with several random restarts.	I-Reply	I-2	Reply	808

UPDATE: Based on the extensive improvements by the authors, I have updated my rating.	O	O	Review	20092
However, I still have doubts about the potential of this approach to reach practically useful levels of accuracy.	B-Review	B-7	Review	20092
<sep> <sep> This paper introduces a simple method to weight pretrained lexical features for use in meta learning of few-shot text classification.	O	O	Review	20092
The method boils down to weighting word inut features, in the form of pretrained word-embeddings, by attention computed from inverse document frequency and class local mutual information.	O	O	Review	20092
The idea is that this measure of feature informativeness transfers between tasks, whereas lexical features themselves are highly task-specific.	O	O	Review	20092
The approach is well motivated and is empirically shown to outperform existing approaches to few-shot text classification with a significant margin.	O	O	Review	20092
<sep> <sep> While the improvement over existing approaches is quite substantial, I believe the paper should not be accepted to ICLR for the following reasons.	B-Review	B-1	Review	20092
First, the contribution is quite limited and not particularly novel.	I-Review	I-1	Review	20092
While two weight functions are proposed, the majority of improvement comes simply from normalizing IDF with attention.	I-Review	I-1	Review	20092
Based on existing work on delexicalized features for NLP tasks such as parsing, this is quite a straightforward extension.	I-Review	I-1	Review	20092
Given the limited contribution, a short paper seems a better fit.	I-Review	I-1	Review	20092
Second, the approach simply trades variance for bias.	I-Review	I-1	Review	20092
This brings us to the question of how likely the approach is to be a building block in bringing us towards a pratically useful few-shot classification method.	I-Review	I-1	Review	20092
Given the weak representational power of the model, I believe this is unlikely.	I-Review	I-1	Review	20092
I see a situation similar to syntactic parsing for low-resource languages, where a collection of simple techniques similar in spirit to the current approach, like delexicalization, brought results far above the naive baselines, but never approached practically useful results.	I-Review	I-1	Review	20092
I think this is a crucial point to address in meta-learning research in general to make sure we‚Äôre not just solving a toy problem with tailored heuristics.	I-Review	I-1	Review	20092
<sep> <sep> Additional notes:	O	O	Review	20092
<sep> What is the motivation for using a BiLSTM to combine inverse document frequency and inverse class entropy?	B-Review	B-2	Review	20092
Is the sequence information at all useful, or would a simple projection and nonlinearity give the same result?	I-Review	I-2	Review	20092
<sep> <sep> The theoretical analysis is completely self-evident from the definition of the feature space.	B-Review	B-3	Review	20092
Replaing a feature with an equivalent feature of course gives the same result and I don‚Äôt see the need to ‚Äúmathematize‚Äù this.	I-Review	I-3	Review	20092
<sep> <sep> The effect of approximating logistic regression with linear regression + calibration is not analyzed and it is not clear what the effect of this approximation is in the text classification scenario.	B-Review	B-4	Review	20092
I would suggest to compare to differentiating through a direct optimization of the logistic formulation, for example with Newton‚Äôs method, or plain SGD, as in Bertinetto et al (2019).	I-Review	I-4	Review	20092
<sep> <sep> Table 1.	B-Review	B-5	Review	20092
Why not run the attention-based feature aggregator together with all algorithms.	I-Review	I-5	Review	20092
The main contribution is at the input representation level, and this should be applicable across algorithms.	I-Review	I-5	Review	20092
In fact, if we remove the BiLSTM which seems to have a very small effect the representation function does not contain learnable parameters in itself.	I-Review	I-5	Review	20092
<sep> <sep> Please provide the average across datasets in Table 1.	B-Review	B-6	Review	20092
[This comment has been updated to reflect changes in paper numbering]	O	O	Reply	20092
<sep> Thank you for your detailed comments!	O	O	Reply	20092
<sep> <sep> We would like to emphasize that this paper makes unique and valuable contributions to the few-shot learning community.	B-Reply	B-1	Reply	20092
<sep> <sep> - It is the first to identify that meta-learning algorithms only memorize useful training features, instead of actually learning to adapt quickly to new settings.	I-Reply	I-1	Reply	20092
Thus, standard meta-learning algorithms may not generalize in NLP, when word distributions differ vastly among tasks.	I-Reply	I-1	Reply	20092
Later on, [a] reported similar findings for vision.	I-Reply	I-1	Reply	20092
<sep> <sep> - The main contribution of this paper is not a specific set of delexicalised features for an end task (classification/parsing), but rather a meta-learning approach towards generalizable representations in low-resource settings.	B-Reply	B-1	Reply	20092
In few-shot learning, we are the first to propose that meta-knowledge can be learned on top of feature statistics, instead of features themselves (which are not transferable).	I-Reply	I-1	Reply	20092
<sep> <sep> - We provide the largest publicly available few-shot text classification benchmarks to the community.	B-Reply	B-1	Reply	20092
Previous work [b, c] focus on binary sentiment classifiers across different domains, while we are interested in multi-class text classification.	I-Reply	I-1	Reply	20092
The setup of [d] is similar to ours, but neither their datasets nor code are publicly available, and they only run experiments on two datasets (RCV1, Reuters).	I-Reply	I-1	Reply	20092
<sep> <sep> In terms of raw representation power, our model is definitely weaker than fully-lexical models.	I-Reply	I-1	Reply	20092
Instead, the key benefit is that it generalizes in low-resource settings (Figure 6).	I-Reply	I-1	Reply	20092
Quantitatively, our 5-shot accuracy is approximately equivalent to a fully supervised model trained on 50 examples (Figure 14).	I-Reply	I-1	Reply	20092
<sep> <sep> While 50 examples does not seem like very much, even for low-resource languages, we would like to present one case we have faced where we cannot hope for this many.	I-Reply	I-1	Reply	20092
We are given a set of pathology reports, which detail the diagnoses of various tissues in a patient‚Äôs body (e.g. lung, ovary).	I-Reply	I-1	Reply	20092
We want to predict whether the patient has a disease.	I-Reply	I-1	Reply	20092
This is not a ‚Äúhard‚Äù task, and a CNN would perform quite well, given enough data.	I-Reply	I-1	Reply	20092
However, these individual diagnoses correspond to potentially thousands of diseases.	I-Reply	I-1	Reply	20092
The total number of {tissue diagnosis, disease} pairs far exceeds the number of reports.	I-Reply	I-1	Reply	20092
Often, each pair only has one or two examples.	I-Reply	I-1	Reply	20092
In this case, it is unrealistic to train a fully-supervised classifier for each pair.	I-Reply	I-1	Reply	20092
<sep> <sep> If we resort to standard meta-learning techniques, learning lexical information from well-represented disease/tissue pairs may be distracting for rarer cases: there is a staggering number of medical terms regarding each disease/tissue, few of these terms overlap across tasks.	I-Reply	I-1	Reply	20092
On the other hand, if we work with distributional statistics, we can learn to ignore terms that are not useful, regardless of task.	I-Reply	I-1	Reply	20092
As a result, we can better focus on words that are meaningful for classification.	I-Reply	I-1	Reply	20092
<sep> <sep> Additional Notes:	O	O	Reply	20092
1.	O	O	Reply	20092
We provide the comparison in the ablation study (Table 1, OUR w/o biLSTM), where we learn a projection from the two statistics using an MLP.	B-Reply	B-2	Reply	20092
On average, the biLSTM improves accuracy from 77.2 to 78.0 (best baseline RR+IDF is 74.1).	I-Reply	I-2	Reply	20092
<sep> 2.	O	O	Reply	20092
The idea was to provide some intuition about distributional signatures, if the reader finds them clearer to understand in this way.	B-Reply	B-3	Reply	20092
<sep> 3.	O	O	Reply	20092
We have added experiments comparing ridge regression vs. logistic regression with Newton‚Äôs method in Appendix A.7.	B-Reply	B-4	Reply	20092
On average, RR+OUR performs slightly better than LR+OUR (78.0 vs. 77.1 on 5-shot, 60.1 vs. 58.8 on 1-shot), but both significantly outperform the best baselines (RR+IDF, 74.1 on 5-shot; LR+IDF, 52.7 on 1-shot).	I-Reply	I-4	Reply	20092
<sep> 4.	O	O	Reply	20092
In this paper, we focused on RR as the main downstream predictor due to its simplicity and effectiveness.	B-Reply	B-5	Reply	20092
However, our experiments show that the attention-based feature aggregator also improves performance for other algorithms.	I-Reply	I-5	Reply	20092
Appendix A.9 contains results from distributional signatures + other classifiers.	I-Reply	I-5	Reply	20092
For prototypical networks, we improve 1-shot accuracy by 9.9 and 5-shot accuracy by 16.7 on average across 6 datasets, compared to the best baseline.	I-Reply	I-5	Reply	20092
For induction networks, we improve average accuracy by 14.3% on 1-shot and 25.1% on 5-shot (Table 7).	I-Reply	I-5	Reply	20092
<sep> 5.	O	O	Reply	20092
Done, thank you for the suggestion.	B-Reply	B-6	Reply	20092
<sep> <sep> We hope we have adequately addressed your concerns.	O	O	Reply	20092
Please let us know if you have any more questions.	O	O	Reply	20092
Thank you!	O	O	Reply	20092
<sep> <sep> <sep> References	O	O	Reply	20092
[a] Rapid Learning or Feature Reuse?	O	O	Reply	20092
Towards Understanding the Effectiveness of MAML	O	O	Reply	20092
[b] Diverse Few-Shot Text Classification with Multiple Metrics	O	O	Reply	20092
[c] Induction Networks for Few-Shot Text Classification	O	O	Reply	20092
[d] Attentive Task-Agnostic Meta-Learning for Few-Shot Text Classification	O	O	Reply	20092

This paper focuses on applying meta learning approaches to text classification.	O	O	Review	20092
<sep> <sep> The primary contribution is an attention mechanism based on word statistics --- most importantly word frequency.	O	O	Review	20092
This novel attention mechanism is motivated by the observation that the base units in text (lexemes) are more likely to have task specific interpretations than lower level patterns in vision.	O	O	Review	20092
And, while a lexeme based attention mechanism trained on one task may not transfer well to other tasks, a mechanism based on coarser word statistics is less likely to focus in on task specific patterns.	O	O	Review	20092
<sep> <sep> A secondary contribution is the use of ridge regression [1] to perform meta-learning for text classification.	O	O	Review	20092
<sep> <sep> The paper presents experiments on a number of text classification tasks from the NLP literature.	O	O	Review	20092
Aside from the new attention mechanism and the use of ridge regression, the proposed approach makes use of FastText word embeddings or BERT sentence representations, depending on the task.	O	O	Review	20092
The paper demonstrates significant improvements over baselines that use other methods of aggregating word representations.	O	O	Review	20092
All of baselines were implemented for this paper.	O	O	Review	20092
<sep> <sep> The idea of using coarse statistical signatures to calculate attention is an interesting one.	O	O	Review	20092
However, I have concerns about both the clarity of this paper and the lack of clear comparison to previous work.	B-Review	B-1	Review	20092
<sep> <sep> == Clarity ==	O	O	Review	20092
<sep> Many of the details of the model and learning approach are vaguely discussed, or relegated to Figures 4 &amp; 5.	B-Review	B-2	Review	20092
I think the paper would benefit from a more formal definition of the entire learning procedure.	I-Review	I-2	Review	20092
<sep> <sep> == Comparison to previous work ==	O	O	Review	20092
<sep> This paper seems to be following the standard FewRel experimental setup.	B-Review	B-3	Review	20092
Also, the RCV1 experiments seem to follow the [2] which was cited by the in the paper under review.	I-Review	I-3	Review	20092
However, it is not clear if the setups are the same or if the numbers are comparable.	I-Review	I-3	Review	20092
<sep> <sep> I am not sure about the existence of comparable results for the other tasks, but for FewRel at least the baselines presented here significantly underperform other papers' reports of equivalent models.	B-Review	B-4	Review	20092
<sep> <sep> - The paper from [3] that introduced FewRel reported 69.2 / 84.8 for CNN based prototypical networks --- far above the 49.8 / 65.2 reported here.	B-Review	B-5	Review	20092
<sep> <sep> - [4] found that a BERT model with no FewRel specific training at all achieves 72.9% on the 5way/1shot task.	B-Review	B-6	Review	20092
Which is above all of the BERT based models reported in Table 2.	I-Review	I-6	Review	20092
<sep> <sep> I may be missing something, but if these numbers are actually not comparable then this paper should contain an explanation of how the experimental setup differs.	B-Review	B-7	Review	20092
And if the setup is actually the same as previous work, I expect to see a comparison of results.	I-Review	I-7	Review	20092
<sep> <sep> [1] <a href="https://openreview.net/pdf?id=HyxnZh0ct7" target="_blank" rel="nofollow">https://openreview.net/pdf?id=HyxnZh0ct7</a>	O	O	Review	20092
[2] <a href="https://openreview.net/forum?id=SyxMWh09KX" target="_blank" rel="nofollow">https://openreview.net/forum?id=SyxMWh09KX</a>	O	O	Review	20092
[3] <a href="https://www.aclweb.org/anthology/D18-1514/" target="_blank" rel="nofollow">https://www.aclweb.org/anthology/D18-1514/</a>	O	O	Review	20092
[4] <a href="https://arxiv.org/abs/1906.03158" target="_blank" rel="nofollow">https://arxiv.org/abs/1906.03158</a>	O	O	Review	20092
[This comment has been updated to reflect changes in paper numbering]	O	O	Reply	20092
<sep> Thank you for the detailed comments!	O	O	Reply	20092
<sep> <sep> Clarity: Figures 4 and 5 are provided as summaries of the learning procedure and model; all components are formally defined in Sections 3 and 4, with implementation details in Section 5.	B-Reply	B-2	Reply	20092
<sep> <sep> Model: All notation is formally defined within the main text, with additional implementation details in the Appendix.	B-Reply	B-2	Reply	20092
<sep> - For the attention generator, the raw statistics s(.)	I-Reply	I-2	Reply	20092
and t(.)	I-Reply	I-2	Reply	20092
are defined in equations 1 and 2 respectively.	I-Reply	I-2	Reply	20092
Implementation details regarding t(.)	I-Reply	I-2	Reply	20092
are found in Appendix A.1, as cited.	I-Reply	I-2	Reply	20092
The attention score \alpha is defined in equation 3.	I-Reply	I-2	Reply	20092
Details for the biLSTM are noted in Section 5.	I-Reply	I-2	Reply	20092
<sep> - For the ridge regressor, the weighted representations \phi are defined in equation 4, and W is written out in equation 6.	I-Reply	I-2	Reply	20092
<sep> <sep> Learning Procedure: Based on the suggestions, we have added Appendix A.3 containing pseudocode for our entire learning procedure.	B-Reply	B-2	Reply	20092
Hyperparameters for training are already noted in Section 5.	I-Reply	I-2	Reply	20092
<sep> <sep> Experimental Setup: This paper does not follow the standard FewRel setup, as noted by Appendix A.4 and Table 3 (referenced in Section 5.1).	B-Reply	B-3	Reply	20092
We combine the train/val data of FewRel (test is not publicly available) and split it further into train/val/test.	I-Reply	I-3	Reply	20092
<sep> <sep> For data splits, we consider two settings: ‚Äúeasy split‚Äù randomly permuted classes and divided into train/val/test, and ‚Äúhard split‚Äù selected train/val/test classes based on class hierarchies or similar heuristics, such that train classes are distant from val/test.	I-Reply	I-3	Reply	20092
Following [a], we use the ‚Äúhard split‚Äù to test the meta-learning algorithm‚Äôs generalization capacity when testing tasks may not come from the same domain as training tasks.	I-Reply	I-3	Reply	20092
Please see the Appendix for details regarding each dataset.	I-Reply	I-3	Reply	20092
<sep> <sep> For RCV1 and Reuters, [b] does not provide pruned classes, data splits, or code, so we cannot directly compare.	I-Reply	I-3	Reply	20092
Our code (including all baselines), data splits, and processed data are publicly available.	I-Reply	I-3	Reply	20092
<sep> <sep> We hope we have adequately addressed your concerns.	O	O	Reply	20092
Please let us know if you have any more questions.	O	O	Reply	20092
Thank you!	O	O	Reply	20092
<sep> <sep> References	O	O	Reply	20092
<sep> [a] Zero-Shot Learning - The Good, the Bad and the Ugly	O	O	Reply	20092
[b] Attentive Task-Agnostic Meta-Learning for Few-Shot Text Classification	O	O	Reply	20092

This paper studies the effects of using function of ngram statistics as feature to generate attention score per word.	O	O	Review	20092
The attention score is then used as weights to aggregate document embedding by doing a weighted average on word embedding.	O	O	Review	20092
The output is finally fed into a ridge regressor to do the final predictions on target labels.	O	O	Review	20092
<sep> <sep> Main comments:	O	O	Review	20092
This paper has a clear motivation and decent experimental results (though some concern on baseline models, see below).	B-Review	B-1	Review	20092
The introduction of using distributional signature to derive attention scores seems interesting and a novel contribution.	I-Review	I-1	Review	20092
However I was not able to fully understand the intuition behind the benefit of doing attention mechanism on top of ngram statistics (see my question below as well).	I-Review	I-1	Review	20092
<sep> Also the reference/baseline models used in the experiment might not be strong enough.	B-Review	B-2	Review	20092
If you could compare your model with some latest algorithms proposed in the few-shot-learning communities, that would be more convincing as well.	I-Review	I-2	Review	20092
<sep> To list a few:	I-Review	I-2	Review	20092
* P-MAML: [Zhang et al 2019]	I-Review	I-2	Review	20092
* Induction-Network-Routing: [Geng et al 2019]	I-Review	I-2	Review	20092
* ROBUSTTC-FSL [Yu et al 2018]	I-Review	I-2	Review	20092
<sep> I am leaning to give a "weak reject" based on my current knowledge and understanding of the paper.	O	O	Review	20092
But I will be willing to revisit the decision after we get feedback from the author(s).	O	O	Review	20092
<sep> <sep> In particular, I would be glad if the author could clarify the questions below.	O	O	Review	20092
<sep> <sep> * From table 1, it seems Method IDF+RR is a competitive model.	B-Review	B-3	Review	20092
IIUC, the statistics of s(.)	I-Review	I-3	Review	20092
is highly correlated with IDF which also indicates general word importance in corpus.	I-Review	I-3	Review	20092
My questions are that,	I-Review	I-3	Review	20092
1) regarding ablation test "OUR w/o biLSTM", how is calculated in this case (without biLSTM)?	I-Review	I-3	Review	20092
<sep> 2) since each word is represented based on two statistical number (map function by t(.)	B-Review	B-4	Review	20092
and s(.)),	I-Review	I-4	Review	20092
can you give any intuitive explanation that why getting attention score from that makes sense?	I-Review	I-4	Review	20092
<sep> 3) do you have any experiments using the distributional signature as a common feature in standard text classification problems?	B-Review	B-5	Review	20092
In other words, is this method only (significantly) beneficial to few-short-learning?	I-Review	I-5	Review	20092
If it is also useful in general text classification task, it would be a good "plus" here.	I-Review	I-5	Review	20092
<sep> <sep> * From table 2, can you explain why CNN+RR benefits a lot from the BERT embedding?	B-Review	B-6	Review	20092
Actually it gets more percentage of improvement than the model "OUR".	I-Review	I-6	Review	20092
<sep> <sep> * For all the usages of pre-trained embedding (fasttext or BERT), are you further finetuning the embedding parameters during your training?	B-Review	B-7	Review	20092
Or you freeze the embedding parameters?	I-Review	I-7	Review	20092
<sep> <sep> [Zhang et al 2019] Ningyu Zhang et al Improving Few-shot Text Classification via Pretrained Language Representations.	O	O	Review	20092
arXiv preprint arXiv: 1908.08788	O	O	Review	20092
[Geng et al 2019] Ruiying Geng, Binhua Li, Yongbin Li, Yuxiao Ye, Ping Jian, and Jian Sun.	O	O	Review	20092
2019.	O	O	Review	20092
Few-shot text classification with induction network.	O	O	Review	20092
arXiv preprint arXiv:1902.10482.	O	O	Review	20092
<sep> [Yu et al 2018] Mo Yu, Xiaoxiao Guo, Jinfeng Yi, Shiyu Chang, Saloni Potdar, Yu Cheng, Gerald Tesauro, Haoyu Wang,	O	O	Review	20092
and Bowen Zhou.	O	O	Review	20092
2018.	O	O	Review	20092
Diverse few-shot text classification with multiple metrics.	O	O	Review	20092
arXiv preprint arXiv:1805.07513	O	O	Review	20092
Thank you for the detailed comments and suggestions!	O	O	Reply	20092
<sep> <sep> The main idea of the paper is that if we want to learn transferable knowledge, methods that memorize word identities will fail when the word distribution shifts.	B-Reply	B-1	Reply	20092
By learning meta-knowledge on top of n-gram statistics, class-specific words will still be important (and common stop words unimportant), even if the actual words themselves change. (	I-Reply	I-1	Reply	20092
More specific example regarding our two statistics below.)	I-Reply	I-1	Reply	20092
<sep> <sep> Additional Experiments: Based on the suggestions, we have compared our work to P-MAML and Induction Network Routing.	B-Reply	B-2	Reply	20092
Detailed results are located in Appendix A.5.	I-Reply	I-2	Reply	20092
<sep> On average, our method outperforms P-MAML by 18.5% on 1-shot and 19.3% on 5-shot, and Induction Networks by 21.1% on 1-shot and 32.4% on 5-shot (Table 4).	I-Reply	I-2	Reply	20092
While both P-MAML and Induction Networks are able to overfit the meta-train data easily, they are unable to generalize when faced with lexical mismatch (Figure 9).	I-Reply	I-2	Reply	20092
<sep> <sep> Furthermore, we show that we can improve Induction Networks by replacing its lexically-aware encoder with our attention-weighted representation learned from distributional signatures  (Appendix A.9).	I-Reply	I-2	Reply	20092
On average, distributional signatures increase Induction Networks accuracy by 14.3% on 1-shot and 25.1% on 5-shot.	I-Reply	I-2	Reply	20092
<sep> <sep> RobustTC-FSL is not directly applicable to our setting since it considers a fixed set of tasks during meta-training (e.g. binary sentiment classification across 23 Amazon domains) and utilizes their cross-task transferability.	I-Reply	I-2	Reply	20092
<sep> <sep> Questions:	O	O	Reply	20092
* s(.)	B-Reply	B-3	Reply	20092
and IDF both indicate general word importance.	I-Reply	I-3	Reply	20092
We experimented with both during our development stage and found that they perform similarly when used in our attention generator (idf 77.8 vs s(.)	I-Reply	I-3	Reply	20092
78.0 for 5 shot classifications averaged across 6 datasets).	I-Reply	I-3	Reply	20092
We choose the current formulation as it is more interpretable in context of robustness against word-substitution perturbation.	I-Reply	I-3	Reply	20092
<sep> <sep> 1) We apply an MLP on top of the [s(); t()] at each position, where ; denotes concatenation.	I-Reply	I-3	Reply	20092
After that we applied softmax over the output of the MLP.	I-Reply	I-3	Reply	20092
This MLP has 2 inputs, 50 hidden units (ReLU activation) and 1 output.	I-Reply	I-3	Reply	20092
<sep> <sep> 2) One indicates word importance for general classification (estimated from source pool) and the other indicates how important the feature is for this particular task (a rough estimate).	B-Reply	B-4	Reply	20092
<sep> <sep> For example, suppose we have lots of data from political and sports news, and we want to expand into arts news.	I-Reply	I-4	Reply	20092
General word importance (learned from politics and sports) can tell us that words like ‚Äúthe‚Äù and ‚Äúwe‚Äù are not useful, so we learn to ignore them.	I-Reply	I-4	Reply	20092
However, politics and sports news also have no use for arts-specific words, like ‚Äúpainting‚Äù or ‚Äúperformance.	I-Reply	I-4	Reply	20092
‚Äù Thus, we require task-specific word importance (learned from few arts examples) to refine our understanding of useful words.	I-Reply	I-4	Reply	20092
<sep> <sep> 3) The general idea of ‚Äúdistributional signatures‚Äù is not new.	B-Reply	B-5	Reply	20092
Prior to the age of deep learning, linear SVM + TF-IDF was considered a strong baseline to beat, and more recently, Arora 2016 showed that SIF-weighted representations (statistics used for s(.)	I-Reply	I-5	Reply	20092
in our model) do outperform LSTMs/CNNs on some (standard) tasks.	I-Reply	I-5	Reply	20092
In our setting, we noted that the idea may also be helpful for few-shot classification, as these statistics are more transferable across tasks.	I-Reply	I-5	Reply	20092
For general classification tasks with lots of annotation, the representation power of distribution signatures may be limited (though this is slightly beyond the scope of our paper).	I-Reply	I-5	Reply	20092
<sep> <sep> * BERT is contextual, so the embedding of one word represents not only itself, but also its surroundings.	B-Reply	B-6	Reply	20092
Correspondingly, if a CNN downweights an important word from an unseen class, its adjacent words still contain information about that word.	I-Reply	I-6	Reply	20092
This means that it is less ‚Äúcostly‚Äù to ignore important words from unseen classes, as a result of overfitting on seen classes.	I-Reply	I-6	Reply	20092
For OUR, this means that we don‚Äôt have to be as precise about picking out each important word.	I-Reply	I-6	Reply	20092
<sep> <sep> * Since the vocabulary of meta-train classes and meta-test classes may be very different, we freeze the pre-trained embeddings (Fasttext or BERT) during meta training.	B-Reply	B-7	Reply	20092
This is to avoid disrupting the inherent geometry of word embeddings, as finetuning will cause these embeddings to lose the relationship between meta-train vocabulary (seen during finetuning) and meta-test vocabulary (not seen, and thus not optimized for).	I-Reply	I-7	Reply	20092
Empirically, we show that freezing word embeddings outperforms finetuning (Table 6).	I-Reply	I-7	Reply	20092
<sep> <sep> We hope we have adequately addressed your concerns.	O	O	Reply	20092
Please let us know if you have any more questions.	O	O	Reply	20092
Thank you!	O	O	Reply	20092

This paper describes a new large scale dataset of aligned MIDI and audio from real piano performances and presents experiments using several existing state-of-the-art models for transcription, synthesis, and generation.	O	O	Review	125
As a result of the new dataset being nearly an order of magnitude larger than existing resources, each component model (with some additional tuning to increase capacity) yields impressive results, outperforming the current state-of-the-art on each component task.	O	O	Review	125
<sep> Overall, while the modeling advances here are small if any, I think this paper represents a solid case study in collecting valuble supervised data to push a set of tasks forward.	O	O	Review	125
The engineering is carefully done, well-motivated, and clearly described.	O	O	Review	125
The results are impressive on all three tasks.	O	O	Review	125
Finally, if the modeling ideas here do not, the dataset itself will go on to influence and support this sub-field for years to come.	O	O	Review	125
<sep> Comments / questions:	O	O	Review	125
-Is MAPS actually all produced via sequencer?	B-Review	B-1	Review	125
Having worked with this data I can almost swear that at least a portion of it (in particular, the data used here for test) sounds like live piano performance captured on Disklavier.	I-Review	I-1	Review	125
Possibly I'm mistaken, but this is worth a double check.	I-Review	I-1	Review	125
<sep> -Refering to the triple of models as an auto-encoder makes me slightly uncomfortable given that they are all trained independently, directly from supervised data.	B-Review	B-2	Review	125
<sep> -The MAESTRO-T results are less interesting than they might appear at first glance given that the transcriptions are from train.	B-Review	B-3	Review	125
The authors do clearly acknowledge this, pointing out that val and test transcription accuracies were near train accuracy.	I-Review	I-3	Review	125
But maybe that same argument could be used to support that the pure MAESTRO results are themselves generalizable, allowing the authors to simplify slightly by removing MAESTRO-T altogether.	I-Review	I-3	Review	125
In short, I'm not sure MAESTRO-T results offer much over MAESTRO results, and could therefore could be omitted.	I-Review	I-3	Review	125
<sep> <sep> Thank you for your review and comments.	O	O	Reply	125
<sep> <sep> * Is MAPS actually all produced via sequencer?	O	O	Reply	125
Having worked with this data I can almost swear that at least a portion of it (in particular, the data used here for test) sounds like live piano performance captured on Disklavier.	O	O	Reply	125
Possibly I'm mistaken, but this is worth a double check.	O	O	Reply	125
<sep> <sep> According to the PDF file that accompanies the MAPS dataset (‚ÄúMAPS - A piano database for multipitch estimation and automatic transcription of music‚Äù): ‚ÄúThese high quality files have been carefully hand-written in order to obtain a kind of musical interpretation as a MIDI file.	B-Reply	B-1	Reply	125
‚Äù We have updated the citation to point to this paper specifically to make things more clear.	I-Reply	I-1	Reply	125
More information about the process is available on the website that contains the source MIDI files for MAPS: <a href="http://www.piano-midi.de/technic.htm" target="_blank" rel="nofollow">http://www.piano-midi.de/technic.htm</a>	I-Reply	I-1	Reply	125
<sep> * Referring to the triple of models as an auto-encoder makes me slightly uncomfortable given that they are all trained independently, directly from supervised data.	O	O	Reply	125
<sep> <sep> This is a very reasonable point, because there are no learned feature vectors in the latent representation (they come from labels).	B-Reply	B-2	Reply	125
We have updated the text to instead refer to the model as a ‚Äúgenerative model with a discrete latent code of musical notes‚Äù.	I-Reply	I-2	Reply	125
We have kept the encoder/decoder/prior notation because it still seems appropriate.	I-Reply	I-2	Reply	125
<sep> <sep> * The MAESTRO-T results are less interesting than they might appear at first glance given that the transcriptions are from train.	O	O	Reply	125
The authors do clearly acknowledge this, pointing out that val and test transcription accuracies were near train accuracy.	O	O	Reply	125
But maybe that same argument could be used to support that the pure MAESTRO results are themselves generalizable, allowing the authors to simplify slightly by removing MAESTRO-T altogether.	O	O	Reply	125
In short, I'm not sure MAESTRO-T results offer much over MAESTRO results, and could therefore could be omitted.	O	O	Reply	125
<sep> <sep> Our goal with the MAESTRO-T dataset was to clearly demonstrate that both the language modeling tasks (Music Transformer) and audio synthesis (WaveNet) can produce compelling results without having access to ground truth labels.	B-Reply	B-3	Reply	125
We agree that using the train dataset does somewhat diminish this demonstration, but argue that it does more clearly demonstrate the usefulness of the ‚ÄúWave2Midi2Wave‚Äù process than just using ground truth labels.	I-Reply	I-3	Reply	125
In future work, we plan to expand our use of these models to datasets that do not have ground truth labels.	I-Reply	I-3	Reply	125
We have added to the conclusion to clarify this point.	I-Reply	I-3	Reply	125

The paper addresses the challenge of using neural networks to generate original and expressive piano music.	O	O	Review	125
The available techniques today for audio or music generation are not able to sufficient handle the many levels at which music needs to modeled.	O	O	Review	125
The result is that while individual music sounds (or notes) can be generated at one level using tools like WaveNet, they don't come together to create a coherent work of music at the higher level.	O	O	Review	125
The paper proposes to address this problem by imposing a MIDI representation (piano roll) in the neural modeling of music audio that serves as an intermediate (and interpretable) representation between the analysis (music audio -> MIDI) and synthesis (MIDI -> music audio) in the pipeline of piano music generation.	O	O	Review	125
In order to develop and validate the proposed learning architecture, the authors have created a large data set of aligned piano music (raw audio along with MIDI representation).	O	O	Review	125
Using this data set for training, validation and test, the paper reports on listening tests that showed slightly less favorable results for the generated music.	O	O	Review	125
A few questions and comments are as follows.	O	O	Review	125
MIDI itself is a rich language with ability to drive the generation of music using rich sets of customizable sound fonts.	B-Review	B-1	Review	125
Given this, it is not clear that it is necessary to reproduce this function using neural network generation of sounds.	I-Review	I-1	Review	125
The further limitation of the proposed approach seems to be the challenge of decoding raw music audio with chords, multiple overlayed notes or multiple tracks.	B-Review	B-2	Review	125
MIDI as a representation can support multiple tracks, so it is not necessarily the bottleneck.	I-Review	I-2	Review	125
How much does the data augmentation (audio augmentation) help?	B-Review	B-3	Review	125
Thank you for your review and comments.	O	O	Reply	125
<sep> <sep> * MIDI itself is a rich language with ability to drive the generation of music using rich sets of customizable sound fonts.	O	O	Reply	125
Given this, it is not clear that it is necessary to reproduce this function using neural network generation of sounds.	O	O	Reply	125
<sep> <sep> Synthesizing realistic audio from symbolic representations is a complex task.	B-Reply	B-1	Reply	125
While there are many good sounding piano synthesizers, many of them fall well short of producing audio that would be a convincing substitute for a real piano recording.	I-Reply	I-1	Reply	125
For example, the SoundFont technology referenced can only play particular samples for particular notes (with some simple effects processing).	I-Reply	I-1	Reply	125
It is incapable of modeling complex physical interactions between different parts of the piano, such as sympathetic resonance, and is limited by the quality and variety of samples included with a particular font (for example, the ability to play longer notes is often achieved by simply looping over a section of a sample).	I-Reply	I-1	Reply	125
That said, there are some piano synthesis systems that can do a good job of modeling these types of interactions, though they are not as widely available as SoundFonts and are difficult to create.	I-Reply	I-1	Reply	125
For a good overview of the difficulties and successes in piano modeling, see the paper we cited by Bank et al	I-Reply	I-1	Reply	125
<sep> Our WaveNet model is able to learn to generate realistic-sounding music with no information other than audio recordings of piano performances, information which would be insufficient for the creation of a SoundFont or physics-informed model.	I-Reply	I-1	Reply	125
The ‚ÄúTranscribed‚Äù WaveNet model clearly demonstrates this because we use only the audio from the dataset and we derive training labels by using our transcription model.	I-Reply	I-1	Reply	125
By training on the audio directly, we implicitly model the complex physical interactions of the instrument, unlike a SoundFont.	I-Reply	I-1	Reply	125
<sep> <sep> It is also interesting to note that the WaveNet model recreates non-piano subtleties of the recording, including the response of the room, breathing of the player, and shuffling of listeners in their seats.	I-Reply	I-1	Reply	125
These results are encouraging and indicate that such methods could also capture the sound of more dynamic instruments (such as string and wind instruments) for which convincing synthesis/sampling methods lag behind piano.	I-Reply	I-1	Reply	125
To clarify this point, we have added a paragraph to the Piano Synthesis section of the paper.	I-Reply	I-1	Reply	125
<sep> <sep> We have also updated the paper to further demonstrate our ability to control the output sound by adding year conditioning.	I-Reply	I-1	Reply	125
Different competition years within the MAESTRO dataset had different microphone placements (e.g., near the piano or farther back in the room), and by conditioning on year, we can control whether the output sounds like a close mic recording or one with more room noise.	I-Reply	I-1	Reply	125
We present several audio examples in the online supplement: <a href="https://goo.gl/6RzHZM" target="_blank" rel="nofollow">https://goo.gl/6RzHZM</a>	I-Reply	I-1	Reply	125
<sep> * The further limitation of the proposed approach seems to be the challenge of decoding raw music audio with chords, multiple overlaid notes or multiple tracks.	O	O	Reply	125
MIDI as a representation can support multiple tracks, so it is not necessarily the bottleneck.	O	O	Reply	125
<sep> <sep> We chose to model the music with full polyphony for a couple reasons.	B-Reply	B-2	Reply	125
One is that, as described above, there are complex interactions in the physical piano and recording environment that would not be reproducible by rending notes separately and then layering them into a single output.	I-Reply	I-2	Reply	125
Another is that the training data is presented as a single MIDI stream and the audio is not easily separated into multiple tracks.	I-Reply	I-2	Reply	125
<sep> <sep> * How much does the data augmentation (audio augmentation) help?	O	O	Reply	125
<sep> <sep> We have added a table showing the differences between training with and without audio augmentation.	B-Reply	B-3	Reply	125
In the process of analyzing these results, we realized that audio augmentation helps significantly when evaluating on the MAPS dataset (likely because the model is more robust to differences in recording environment and piano qualities), it actually incurs a slight penalty when evaluating on the MAESTRO test set.	I-Reply	I-3	Reply	125
We have updated the paper with a discussion of these differences.	I-Reply	I-3	Reply	125

This paper combines state of the art models for piano transcription, symbolic music synthesis, and waveform generation all using a shared piano-roll representation.	O	O	Review	125
It also introduces a new dataset of 172 hours of aligned MIDI and audio from real performances recorded on Yamaha Disklavier pianos in the context of the piano-e-competition.	O	O	Review	125
<sep> By using this shared representation and this dataset, it is able to expand the amount of time that it can coherently model music from a few seconds to a minute, necessary for truly modeling entire musical pieces.	O	O	Review	125
<sep> <sep> Training an existing state of the art transcription model on this data improves performance on a standard benchmark by several percentage points (depending on the specific metric used).	O	O	Review	125
<sep> <sep> Listening test results show that people still prefer the real recordings a plurality of the time, but that the syntheses are selected over them a fair amount.	O	O	Review	125
One thing that is clear from the audio examples is that the different systems produce output with different equalization levels, which may lead to some of the listening results.	O	O	Review	125
If some sort of automatic mastering were done to the outputs this might be avoided.	O	O	Review	125
<sep> <sep> While the novelty of the individual algorithms is relatively meager, their combination is very synergistic and makes a significant contribution to the field.	O	O	Review	125
Piano music modeling is a long-standing problem that the current paper has made significant progress towards solving.	O	O	Review	125
<sep> <sep> The paper is very well written, but there are a few minor issues:	O	O	Review	125
* Eq (1) this is really the joint distribution between audio and notes, not the marginal of audio	B-Review	B-1	Review	125
* Table 4: What do precision, recall, and f1 score mean for notes with velocity?	B-Review	B-2	Review	125
How close does the system have to be to the velocity to get it right?	I-Review	I-2	Review	125
<sep> * Table 6: NLL presumably stands for Negative Log Likelihood, but this should be made explicity	B-Review	B-3	Review	125
* Figure 2: Are the error bars the standard deviation of the mean or the standard error of the mean?	B-Review	B-4	Review	125
<sep> <sep> Thank you for your review and comments.	O	O	Reply	125
<sep> <sep> * Eq (1) this is really the joint distribution between audio and notes, not the marginal of audio	O	O	Reply	125
<sep> Thank you for catching the mistake.	B-Reply	B-1	Reply	125
We have updated the equation to include the marginalizing integral through the expectation over notes: P(audio) = E_{notes} [ P(audio|notes) ]	I-Reply	I-1	Reply	125
<sep> * Table 4: What do precision, recall, and f1 score mean for notes with velocity?	O	O	Reply	125
How close does the system have to be to the velocity to get it right?	O	O	Reply	125
<sep> <sep> We use the mir_eval library for calculating those metrics, and a full description is available here: <a href="https://craffel.github.io/mir_eval/#module-mir_eval.transcription_velocity" target="_blank" rel="nofollow">https://craffel.github.io/mir_eval/#module-mir_eval.transcription_velocity</a>	B-Reply	B-2	Reply	125
<sep> It implements the evaluation procedure described in Hawthorne et al (2018).	I-Reply	I-2	Reply	125
<sep> <sep> We have updated the caption for Table 4 to make this more clear.	I-Reply	I-2	Reply	125
<sep> <sep> * Table 6: NLL presumably stands for Negative Log Likelihood, but this should be made explicitly	O	O	Reply	125
<sep> Thanks, updated the table caption to make this more clear.	B-Reply	B-3	Reply	125
<sep> <sep> * Figure 2: Are the error bars the standard deviation of the mean or the standard error of the mean?	O	O	Reply	125
<sep> <sep> We are calculating the standard deviation of the means (we did not divide by the square root of the sample size).	B-Reply	B-4	Reply	125

This paper studies the theoretical aspects of HRL.	O	O	Review	125
It provides theoretical analysis for the complexity of Deep HRL.	O	O	Review	125
The idea is to exploit a given action hierarchy, and known state decomposition, the fact that the high-level state space shares similar low-level structures.	O	O	Review	125
The final result is an exponential improvement of HRL to flat RL.	O	O	Review	125
<sep> <sep> Overall, the paper pursues an ambitious goal that analyses the complexity of Deep HRL.	O	O	Review	125
The writing is not easy to follow.	O	O	Review	125
I some questions and concerns as follows	O	O	Review	125
<sep> - I wonder why the state space must be defined in a product form?	B-Review	B-1	Review	125
If a standard RL is used, then it could be applied directly to the state space ) on that primitive actions operate.	I-Review	I-1	Review	125
Hence L-1 state spaces will be discarded?	I-Review	I-1	Review	125
I don't see why a flat RL must estimate policies for states at all levels.	I-Review	I-1	Review	125
It looks like many later derivations based on the assumption of factored state spaces and factored transitions on different levels.	I-Review	I-1	Review	125
In the case of factored representation, the authors should make clear assumptions and find a better way to describe the overall algorithm.	I-Review	I-1	Review	125
<sep> <sep> - Section 3.2: the authors use time index for Q and V, does that mean all analysis is for non-stationary MDPs?	B-Review	B-2	Review	125
This is not the assumption in Jaksch et al (2010) and this paper.	I-Review	I-2	Review	125
The description in this section is very confusing and contains a lot of imprecise definitions	I-Review	I-2	Review	125
e.g. should H = \prod {i=1} H_i??	I-Review	I-2	Review	125
is h =(h_1,...h_L) not in [1,H]?	I-Review	I-2	Review	125
what is the definition of the immediate next lexicographical tuple?	I-Review	I-2	Review	125
etc.	I-Review	I-2	Review	125
The definition of \sigma is also unclear and hard to understand.	I-Review	I-2	Review	125
<sep> <sep> - The analysis in Section 4.	B-Review	B-3	Review	125
and Algorithm 1 are not for Deep HRL as said in Abstract and Introduction.	I-Review	I-3	Review	125
The analysis is based on PAC-MDP learning for models at each action level.	I-Review	I-3	Review	125
This paper's contributions might be clearer if the authors made clearer assumptions, e.g. on action hierarchy, abstract state space structures etc..	I-Review	I-3	Review	125
<sep> <sep> Thanks for these questions and suggestions.	O	O	Reply	125
We have revised our paper and fixed typos.	O	O	Reply	125
Please find our responses to your questions below.	O	O	Reply	125
<sep> 1.	B-Reply	B-1	Reply	125
In our model, we assume the transition model shares the hierarchical structure, but the reward can be arbitrary (the reward is defined as, which is a function of states at every level and the action).	I-Reply	I-1	Reply	125
Hence we have to plan on the product state space and make actions for all states at all levels.	I-Reply	I-1	Reply	125
<sep> 2.	O	O	Reply	125
Here we use indexed Q and V to denote the value functions at different horizons, which are common notations for finite-horizon MDP.	B-Reply	B-2	Reply	125
As for the notation, we actually means, which is the lexicographical number of tuple.	I-Reply	I-2	Reply	125
The lexicographical tuple next to is if is the largest index such that (meaning tuple).	I-Reply	I-2	Reply	125
Also, in the previous tuple, we use to denote the level where the carry happens.	I-Reply	I-2	Reply	125
<sep> 3.	O	O	Reply	125
In our model, we use ‚Äúdeep hierarchical RL‚Äú to denote the model with many layers requiring planning.	B-Reply	B-3	Reply	125

This paper proposes a new kind of episodic finite MDPs called "deep hierarchical MDP" (hMDP).	O	O	Review	125
An L-layer hMDP can be *roughly* thought of as L episodic finite MDPs stacked together.	O	O	Review	125
A variant of UCRL2 [JOA10] is proposed to solve these hMDPs and some results from its regret analysis are provided.	O	O	Review	125
<sep> <sep> Pros:	O	O	Review	125
<sep> 1.	O	O	Review	125
The essential result (Theorem 4.1) on the regret bound of the proposed algorithm seems correct.	O	O	Review	125
I have not checked the proofs in detail but in part because it does not seem surprising and that a precise assessment is hindered by many typos (see Min2 and Con2).	O	O	Review	125
<sep> <sep> Cons (in descending order of their weights in my decisions):	O	O	Review	125
<sep> 1.	O	O	Review	125
The proposed hMDPs do _not_ seem to capture important features or challenges in hierarchical RL.	B-Review	B-1	Review	125
My understanding is that the transitions in hMDPs work _like_ a clockwork (more on this in Mis6), the algorithm interacts with the sub-MDPs at each layer in turns according to their fixed horizons H_l's.	I-Review	I-1	Review	125
This structure is very rigid temporally and seems to exclude the mentioned example of autonomous driving: the number of decision steps between intersections would be fixed.	I-Review	I-1	Review	125
<sep> <sep> 2.	O	O	Review	125
There are many (typographical) errors in both the text and mathematical expressions.	B-Review	B-2	Review	125
Some of them are more severe than others hindering understanding.	I-Review	I-2	Review	125
<sep> <sep> 3.	O	O	Review	125
Possible as a consequence of Con2, some quantities defined seem unclear or incorrect at worst.	B-Review	B-3	Review	125
For example, the "standard regret" defined in (2) is an expectation, not a random variable as in convention.	I-Review	I-3	Review	125
<sep> <sep> 4.	O	O	Review	125
There are some notable deviations from similar settings in prior works.	B-Review	B-4	Review	125
They might be worthwhile innovations but their significance or motivations is omitted.	I-Review	I-4	Review	125
For example, the rewards in hMDPs are defined as a function of the full state, i.e. in general not decomposable to rewards on the states of each layer, yet the analogy for hMDP is "L levels of episodic MDPs."	I-Review	I-4	Review	125
<sep> <sep> A non-exhaustive list of obvious mistakes/typos:	B-Review	B-2	Review	125
1.	I-Review	I-2	Review	125
In the title, "Provably" -&gt; Provable.	I-Review	I-2	Review	125
<sep> 2.	I-Review	I-2	Review	125
In the abstract, "often both" -&gt; often requires both.	I-Review	I-2	Review	125
<sep> 3.	I-Review	I-2	Review	125
In Organization, "theoremm" -&gt; theorems.	I-Review	I-2	Review	125
<sep> 4.	I-Review	I-2	Review	125
In Section 2, ‚Äúbetween exploration‚Äù -&gt; between exploration and exploitation.	I-Review	I-2	Review	125
<sep> 5.	I-Review	I-2	Review	125
Above Section 3, "carried" -&gt; carried out.	I-Review	I-2	Review	125
<sep> 6.	I-Review	I-2	Review	125
Below (1), "amount reward" -&gt; amount of reward.	I-Review	I-2	Review	125
<sep> 7.	I-Review	I-2	Review	125
The definition of horizon H is incorrect.	I-Review	I-2	Review	125
Consider H_1 = 2 and H_2 = 3, the algorithm will interact with the sub-MDPs in the following order within one episode: 1, 1, 2, 1, 1, 2, 1, 1, 2.	I-Review	I-2	Review	125
There are 9 steps not 6 = 2 * 3 as defined.	I-Review	I-2	Review	125
<sep> 8.	I-Review	I-2	Review	125
Section 3.3, "able accumulate" -&gt; able to accumulate.	I-Review	I-2	Review	125
<sep> 9.	I-Review	I-2	Review	125
Section 3.3, the definition of V_h^\pi, there should be not \max.	I-Review	I-2	Review	125
<sep> 10. (	I-Review	I-2	Review	125
5), "H" -&gt; H - h.	I-Review	I-2	Review	125
11.	I-Review	I-2	Review	125
Section 6, "tabular R" -&gt; tabular RL.	I-Review	I-2	Review	125
<sep> 12.	I-Review	I-2	Review	125
In References, "Posterior sampling for reinforcement learning: worst-case regret bounds" -&gt; Optimistic posterior sampling for reinforcement learning: worst-case regret bounds.	I-Review	I-2	Review	125
<sep> 13.	I-Review	I-2	Review	125
In References, "Temporal abstraction in reinforcement learning" should be cited as a PhD thesis.	I-Review	I-2	Review	125
<sep> <sep> Some other possible errors/inconsistencies:	O	O	Review	125
1.	O	O	Review	125
Related work listed regret bounds from prior works (the presentation closely mirrors that of [JABJ18]) assume an episodic MDP with non-stationary transitions, i.e. P_t ‚â† P_{t'} in general.	B-Review	B-5	Review	125
However, in 3.1 the transitions are stationary.	I-Review	I-5	Review	125
Relatedly, regardless of the stationarity of the transitions, there may not be an optimal _stationary_ policy in an episodic MDP contrary to the claim in the paper.	I-Review	I-5	Review	125
<sep> 2.	O	O	Review	125
Indexing seems inconsistent near the top of page 3.	B-Review	B-6	Review	125
The initial state is s_0 but the trajectory starts with s_1.	I-Review	I-6	Review	125
<sep> 3.	B-Review	B-7	Review	125
Near the top of page 3, V_h^\pi and Q_h^\pi should sum from h'=h, not h'=1.	I-Review	I-7	Review	125
I assume that the authors intend to define h-step values (to appear in the Bellman equations).	I-Review	I-7	Review	125
<sep> 4.	B-Review	B-8	Review	125
Section 3.3, what are the k's in the equations?	I-Review	I-8	Review	125
<sep> 5. (	B-Review	B-9	Review	125
6), what is n(k-1, e)?	I-Review	I-9	Review	125
<sep> <sep> Minor (factored little to none in my decision):	O	O	Review	125
1.	O	O	Review	125
The claim in Introduction that some games "do not require high-level planning" while others do is highly speculative and vague.	B-Review	B-10	Review	125
Note that any policy can be written a function with codomain in the primitive actions.	I-Review	I-10	Review	125
In fact, many people thought to solve a game like chess or Go requires some temporal hierarchy (opening, mid-game, and end-game).	I-Review	I-10	Review	125
<sep> 2.	O	O	Review	125
The comparison to running UCRL2 on hMDP ignoring the given structure seems weak.	B-Review	B-11	Review	125
Given the knowledge of the particular clockwork-like structure of hMDP at each layer (horizons, states, actions), the natural attempt would be run O(L) copies of UCRL2, one for each sub-MDP (under different terminating states of the immediately lower sub-MDP).	I-Review	I-11	Review	125
Frankly, in my understanding, that seems to be roughly what the authors propose as the solution (thus the results unsurprising).	I-Review	I-11	Review	125
Moreover, it is not immediately clear that UCRL2 can apply to the proposed setting of hMDP without checking regular conditions like communicating (diameter being finite).	I-Review	I-11	Review	125
<sep> 3.	O	O	Review	125
The claim that RL with options ‚Äúcan be viewed as a two-layer HRL‚Äù needs much elaboration if not correction.	B-Review	B-12	Review	125
Note that in the former, primitive actions are always taken in the original MDP at consecutive steps.	I-Review	I-12	Review	125
<sep> 4.	O	O	Review	125
There is a limited relevance to deep learning or deep RL central to the themes at ICLR, i.e. the general issue of representation.	B-Review	B-13	Review	125
This work may be more suitable for other general ML venues.	I-Review	I-13	Review	125
<sep> <sep> Some suggestions	O	O	Review	125
<sep> I agree with the authors' sentiment that our theoretical understanding of hierarchical RL is relatively limited.	B-Review	B-13	Review	125
I applaud the authors' effort to address this limitation.	I-Review	I-13	Review	125
But judging from this aim of advancing our theoretical understanding, I think the paper may be improved by	I-Review	I-13	Review	125
<sep> 1.	I-Review	I-13	Review	125
better articulating the motivations for hMDPs (concrete examples would help)	I-Review	I-13	Review	125
<sep> 2.	I-Review	I-13	Review	125
contextualizing hMDPs with respect to other well-known models such as semi-MDPs (technical and precise comparison would help).	I-Review	I-13	Review	125
<sep> <sep> To put it in a different way, it is unclear to the readers why we want to solve this special class of hMDPs and what does hMDPs have to do with the general issues in hierarchical RL.	I-Review	I-13	Review	125
Technically, I feel that assuming episodicity seems against the spirit of hierarchical RL where subtasks are often delimited by their subgoals instead of durations.	I-Review	I-13	Review	125
<sep> <sep> In conclusion, I cannot recommend accepting the current article.	O	O	Review	125
<sep> <sep> (To authors and other reviewers) Please do not hesitate to directly point out my misunderstandings if there is any.	O	O	Review	125
I am open to acknowledging mistakes and revising my assessment accordingly.	O	O	Review	125
<sep> <sep> <sep> Post-rebuttal update:	O	O	Review	125
<sep> Thank you for replying to my review and incorporating some of my suggestions into your revision.	O	O	Review	125
However, I found many concerns (and mistakes) unaddressed, such as Mis7.	O	O	Review	125
The use of driving in Manhattan as an example troubles me because even stopping for a traffic light seems to disrupt the fixed temporal hierarchy of decisions.	B-Review	B-14	Review	125
In conclusion, I will maintain my recommendation.	O	O	Review	125
Thank you for the questions and suggestions.	O	O	Reply	125
We have revised our paper and fixed typos.	B-Reply	B-2	Reply	125
Please find out responses to your comments below.	O	O	Reply	125
<sep> 1.	B-Reply	B-1	Reply	125
For autonomous driving, if we assume that each road has the same lengths, and our vehicle needs to make a decision after going a certain distance, then indeed the number of decision steps between interactions is fixed.	I-Reply	I-1	Reply	125
When the lengths of streets are of the same lengths, as long as they are straight like roads in Manhattan, our model is also suitable after slight modification.	I-Reply	I-1	Reply	125
<sep> 2.	O	O	Reply	125
The episodic way given in our model is a different explanation of the hierarchical model in comparison to models like option MDP, where jumps between layers happen when meeting the stopping criterion.	B-Reply	B-4	Reply	125
Our model is more suitable for a situation like autonomous driving, or some computer games where we have a time limit in each challenge since in these cases, the number of steps in each layer is fixed.	I-Reply	I-4	Reply	125
<sep> 3.	B-Reply	B-13	Reply	125
The ‚Äúdeep‚Äù in our model means deep layers of hierarchy, instead of algorithms using deep learning or deep RL.	I-Reply	I-13	Reply	125

This paper performs a regret analysis for a new hierarchical reinforcement learning (HRL) algorithm that claims an exponential improvement over applying a naive RL approach to the same problem.	O	O	Review	125
The proposed algorithm and the regret analysis performed seem rigorous and well-thought out.	O	O	Review	125
<sep> <sep> However, I think that this paper should be rejected because (1) the algorithm does not appear to be a substantial improvement over existing algorithms, (2) the paper makes strong claims about an exponential improvement over standard RL, but doesn't provide a strong benchmark to compare to, and (3) the paper is imprecise and unpolished, with many grammatical errors.	B-Review	B-3	Review	125
<sep> <sep> I would be open to reconsidering my score if a) the authors submit a revised version with significantly cleaned up text, and b) if the authors could provide more information about how their contribution compares to the existing literature.	O	O	Review	125
<sep> <sep> Main argument	O	O	Review	125
<sep> The paper would benefit from establishing stronger context for the central contributions of their paper.	B-Review	B-1	Review	125
For instance, the paper begins by contrasting HRL approaches with a number of standard RL algorithms, saying that approaches such as AlphaGo do not require high-level planning.	I-Review	I-1	Review	125
This seems surprising; many RL researchers would describe MCTS (the base of the AlphaGo algorithm) as performing planning.	I-Review	I-1	Review	125
It would be great if the authors could go into more detail as to what they view as planning, and why AlphaGo does not do so.	I-Review	I-1	Review	125
<sep> <sep> Additionally, the main comparison the authors seem to make is between HRL and naive RL, which does not provide sufficient context to properly analyse their algorithm.	B-Review	B-2	Review	125
Many algorithms are better than applying a classical RL algorithm naively.	I-Review	I-2	Review	125
As such, it is not sufficient to show that the algorithm proposed by the authors is stronger than a naive approach; it would be better to compare the algorithm to either a) the state of the art (SOTA) approach, or b) a more credible approach than the naive one.	I-Review	I-2	Review	125
Experimental evidence would help.	I-Review	I-2	Review	125
<sep> <sep> One point of comparison is Fruit et al (2017), which is mentioned as another paper which carries out a regret analysis in a HRL setting.	I-Review	I-2	Review	125
Fruit et al (2017) contains a number of simple numerical simulations; a similar effort here would help.	I-Review	I-2	Review	125
<sep> <sep> Another issue is that the paper is confusing, with systematic grammar errors and typos.	B-Review	B-3	Review	125
The paper would benefit significantly with some copy-editing/proofreading by a native English speaker.	I-Review	I-3	Review	125
For instance, the title should (presumably) read "Provable Benefits of Deep Hierarchical RL."	I-Review	I-3	Review	125
Such errors appear throughout the paper.	I-Review	I-3	Review	125
Fixing them would make the paper much easier to understand.	I-Review	I-3	Review	125
<sep> <sep> Finally, although this did not factor into the score I awarded the paper, the terminology used by the authors is confusing, referring to their setting as "Deep Hierarchical Reinforcement Learning." "	B-Review	B-4	Review	125
Deep Reinforcement Learning" is a widely used term in industry, referring to algorithms that apply Deep Learning to RL problems, such as AlphaGo or DeepStack.	I-Review	I-4	Review	125
I would encourage the authors to use a different term to describe the setting.	I-Review	I-4	Review	125
<sep> <sep> Questions to the authors:	O	O	Review	125
<sep> 1) In what way is AlphaGo not doing planning?	B-Review	B-5	Review	125
What is an example of an algorithm that does planning in a standard RL setting?	I-Review	I-5	Review	125
e.g. what would planning look like in Go?	I-Review	I-5	Review	125
<sep> 2) Did you run any experiments/simulations of your work?	B-Review	B-6	Review	125
If not, why not?	I-Review	I-6	Review	125
<sep> 3) Can you elaborate on what a classical RL algorithm would look like that would serve as a proper benchmark to this algorithm?	B-Review	B-7	Review	125
<sep> 4) In your mind, what is the SOTA algorithm for your setting?	B-Review	B-8	Review	125
<sep> 5) What are some simple domains that your algorithm would apply to?	B-Review	B-9	Review	125
<sep> <sep> [0]: Moravƒç√≠k, Matej &amp; Schmid, Martin &amp; Burch, Neil &amp; Lis√Ω, Viliam &amp; Morrill, Dustin &amp; Bard, Nolan &amp; Davis, Trevor &amp; Waugh, Kevin &amp; Johanson, Michael &amp; Bowling, Michael. (	O	O	Review	125
2017).	O	O	Review	125
DeepStack: Expert-Level Artificial Intelligence in No-Limit Poker.	O	O	Review	125
Science.	O	O	Review	125
356.	O	O	Review	125
10.1126/science.aam6960.	O	O	Review	125
Thank you for the questions and suggestions.	O	O	Reply	125
<sep> We want to emphasize that our goal is to formalize the deep hierarchical reinforcement learning problem and give a provably efficient algorithm for this setting.	B-Reply	B-2	Reply	125
The main focus is theoretical, and we do not claim to beat any SOTA algorithm.	I-Reply	I-2	Reply	125

The paper proposes to use graph neural networks (GNN) for inference in MLN.	B-Review	B-2	Review	125
The main motivation seems to be that inference in traditional MLN is computationally inefficient.	I-Review	I-2	Review	125
The paper is cryptic about precisely why this is the case.	O	O	Review	125
There is some allusion in the introduction as to grounding being exponential in the number of entities and the exponent being related to the number of variables in the clauses of the MLN but this should be more clearly stated (e.g., does inference being exponential in the number of entities hold for lifted BP?).	B-Review	B-1	Review	125
In an effort to speed up inference, the authors propose to use GNN instead.	B-Review	B-3	Review	125
Since GNN expressivity is limited, the authors propose to use entity specific embeddings to increase expressivity.	I-Review	I-3	Review	125
The final ingredient is a mean-field approximation that helps break up the likelihood expression.	I-Review	I-3	Review	125
Experiments are conducted on standard MLN benchmarks (UW-CSE, Kinship, Cora) and link prediction tasks.	I-Review	I-3	Review	125
ExpressGNN achieves a 5-10X speedup compared to HL-MRF.	I-Review	I-3	Review	125
On Cora HL-MRF seems to have run out of memory.	I-Review	I-3	Review	125
On link prediction tasks, ExpressGNN seems to achieve better accuracy but this result is a bit difficult to appreciate since the ExpressGNN can't learn rules and the authors used NeuralLP to learn the rules followed by using ExpressGNN to learn parameters and inference.	I-Review	I-3	Review	125
<sep> <sep> Here are the various reasons that prevent me from rating the paper favorably:	O	O	Review	125
<sep> - MLNs were proposed in 2006.	B-Review	B-6	Review	125
Statistical relational learning is even older.	I-Review	I-6	Review	125
This is not a paper where the related work section should be delegated to the appendix.	I-Review	I-6	Review	125
The reader will want to know the state of inference and its computational complexity right at the very beginning.	I-Review	I-6	Review	125
Otherwise, its very difficult to read the paper and appreciate the results.	I-Review	I-6	Review	125
<sep> <sep> - Recently, a number of papers have been tried to quantify the expressive power of GNNs.	B-Review	B-5	Review	125
MLN is fairly general, being able to incorporate any clause in first-order logic.	I-Review	I-5	Review	125
Does the combination with GNN result in any loss of expressivity?	I-Review	I-5	Review	125
This question deserves an answer.	I-Review	I-5	Review	125
If so, then the speedup isn't free and ExpressGNN would be a special case of MLN, albeit with the advantage of fast inference.	I-Review	I-5	Review	125
<sep> <sep> - Why doesn't the paper provide clear inference time complexities to help the reader appreciate the results?	B-Review	B-7	Review	125
At the very least, the paper should provide clear time complexities for each of the baselines.	I-Review	I-7	Review	125
<sep> <sep> - There are cheaper incarnations of MLN that the authors should compare against (or provide clear reasons as to why this is not needed).	B-Review	B-4	Review	125
Please see BoostSRL (Khot, T.; Natarajan, S.; Kersting, K.; and Shavlik, J. 2011.	I-Review	I-4	Review	125
Learning Markov logic networks via functional gradient boosting.	I-Review	I-4	Review	125
In ICDM)	I-Review	I-4	Review	125
First of all, thank you for your valuable comments.	O	O	Reply	125
We briefly respond to a couple of points as follows.	O	O	Reply	125
<sep> <sep> <sep> &gt; Why traditional MLN is computationally inefficient?	O	O	Reply	125
Provide the inference time complexities.	O	O	Reply	125
<sep> <sep> The computational complexity of probabilistic MLN inference is known to be #P-complete when MLN was proposed [1]. To make it feasible, there are three categories of approximate inference methods: Monte Carlo methods, loopy belief BP, and variational methods [2]. Previous methods (including MCMC, BP, lifted BP) require to fully construct the ground Markov network before performing approximate inference, and the size of the ground Markov network is O(M^d) where M is the number of entities and d is the highest arity of the logic formula.	B-Reply	B-2	Reply	125
Typically, there are a large number of entities in a practical knowledge graph, making the full grounding infeasible.	I-Reply	I-2	Reply	125
<sep> <sep> With mean-field approximation, our stochastic inference method avoids to fully construct the grounded Markov network, which only requires local grounding of the formulae in each sampled minibatch.	I-Reply	I-2	Reply	125
Our method has constant time complexity for each sampled minibatch, and the overall time complexity is O(N) where N is the number of iterations.	I-Reply	I-2	Reply	125
We have compared the inference efficiency on two benchmark datasets.	I-Reply	I-2	Reply	125
Experimental results reported Fig.4 show that our method is both more efficient and scalable than traditional MLN inference methods.	I-Reply	I-2	Reply	125
<sep> <sep> <sep> &gt; Does Lifted BP reduce the computational cost of grounding?	O	O	Reply	125
<sep> <sep> Lifted BP constructs the minimal lifted network via merging the nodes as the first step, and then performs belief propagation on the lifted network to save the computational cost.	B-Reply	B-1	Reply	125
However, there is no guarantee that the lifted network is much smaller than the ground network.	I-Reply	I-1	Reply	125
In the worst case, the lifted network can have the same size as the original ground network [2]. Moreover, the construction of the lifted network is also computationally expensive, which is even slower than the construction of the full network as reported in Table 3 of their paper [2]. In fact, our experiments demonstrate that Lifted BP is NOT efficient even on small dataset like UW-CSE and Kinship (please refer to Fig.4 in our paper), and it certainly cannot scale up to the FB15K-237 dataset.	I-Reply	I-1	Reply	125
<sep> <sep> <sep> &gt; Why use Neural LP to learn the rules?	O	O	Reply	125
<sep> <sep> The FB15K-237 dataset is not designed for evaluating MLN inference / learning methods, and hence, have no logic formulae provided.	B-Reply	B-3	Reply	125
Our work focuses on MLN inference and learning with a set of logic formulae, thus we need to generate the rules first.	I-Reply	I-3	Reply	125
Similarly, recent work [3] uses simple brute-force search to generate the rules for MLN.	I-Reply	I-3	Reply	125
However, brute-force rule search can be very inefficient on large-scale data.	I-Reply	I-3	Reply	125
Instead, our method employs Neural LP to efficiently generate the rules.	I-Reply	I-3	Reply	125
We use the training set only for rule learning, which guarantees that there is no information leakage during the evaluation on the test set.	I-Reply	I-3	Reply	125
<sep> <sep> <sep> &gt; Why not compare to BoostSRL?	O	O	Reply	125
<sep> <sep> The BoostSRL work uses MC-SAT as the inference method, which has been compared with our work in the experiments.	B-Reply	B-4	Reply	125
According to the inference time reported in Fig.4, our method is much more efficient and scalable than MC-SAT.	I-Reply	I-4	Reply	125
<sep> <sep> Moreover, BoostSRL is not directly comparable to our method, since the task is completely different.	I-Reply	I-4	Reply	125
Our method is designed for MLN inference and rule weight learning with logic rules provided, while BoostSRL was proposed for MLN structure learning, i.e., learning logic rules for MLN.	I-Reply	I-4	Reply	125
We chose Neural LP instead of this method to generate the rules, since Neural LP has been demonstrated to be effective in rule induction on the Freebase dataset.	I-Reply	I-4	Reply	125
In the updated paper, we have included BoostSRL as related work to supplement our literature review.	I-Reply	I-4	Reply	125
<sep> <sep> <sep> &gt; MLN is fairly general, does GNN result in any loss of expressivity?	O	O	Reply	125
<sep> <sep> We have discussed the expressive power of GNNs in our paper in the section titled ‚ÄúWhy combine GNN and tunable embeddings‚Äù.	B-Reply	B-5	Reply	125
To make it more clear, in the updated paper, we change the section title to: ‚ÄúExpressive power of GNN as inference network ‚Äù.	I-Reply	I-5	Reply	125
In this section, we have shown an example in Fig.3 where GNN produces the same embedding for nodes that should be distinguished.	I-Reply	I-5	Reply	125
We have also formally proved the sufficient and necessary condition to distinguish any non-isomorphic nodes in the knowledge graph.	I-Reply	I-5	Reply	125
Inspired by this, we augment GNN with additional tunable embeddings to trade-off the compactness and expressiveness of the model.	I-Reply	I-5	Reply	125
<sep> <sep> <sep> &gt; Related work should appear in the main paper.	O	O	Reply	125
<sep> <sep> Thanks for the suggestion.	B-Reply	B-6	Reply	125
In the updated paper, we‚Äôve added the related work section right after the introduction to provide a clear background of statistical relational learning and Markov Logic Networks.	I-Reply	I-6	Reply	125
<sep> <sep> <sep> References	O	O	Reply	125
<sep> [1] Richardson, Matthew, and Pedro Domingos. ‚	O	O	Reply	125
ÄúMarkov Logic Networks.	O	O	Reply	125
‚Äù Machine Learning.	O	O	Reply	125
<sep> <sep> [2] Singla, Parag, and Pedro M. Domingos. ‚	O	O	Reply	125
ÄúLifted First-Order Belief Propagation.	O	O	Reply	125
‚Äù AAAI.	O	O	Reply	125
<sep> <sep> [3] Qu, Meng, and Jian Tang. ‚	O	O	Reply	125
ÄúProbabilistic Logic Neural Networks for Reasoning.	O	O	Reply	125
‚Äù arXiv.	O	O	Reply	125

This paper proposes a framework for solving the probabilistic logic reasoning problem by integrating Markov neural networks and graph neural networks to combine their individual features into a more expressive and scalable framework.	O	O	Review	125
Graph neural networks are used for learning representations for Knowledge graphs and are quite scalable when it comes to probabilistic inference.	O	O	Review	125
But no prior rules can be incorporated and it requires significant amount of examples per target in order to converge.	O	O	Review	125
On the other hand, MLN are quite powerful for logical reasoning and dealing with noisy data but its inference process is computationally intensive and does not scale.	O	O	Review	125
Combining these two frameworks seem to result in a powerful framework which generalizes well to new knowledge graphs, does inference and is able to scale to large entities.	O	O	Review	125
<sep> <sep> Regarding its contribution, the paper seems to consider a training process which is done using the variational EM algorithm.	O	O	Review	125
The variational EM is used to optimize the ELBO term (motivation for this is the intractability of the computing the partition term).	O	O	Review	125
In the E-step, they infer the posterior distribution and in the M-step they learn the weights.	O	O	Review	125
The integration of variational EM algorithm and MLN has been explored in another work (pLogicNet: Probabilistic Logic Neural Networks for Reasoning), but this paper proposes a new pipeline of tools: MLN, GNN and variational EM which seem to outperform all the existing baseline methods.	B-Review	B-2	Review	125
The paper looks technically sound to me and the evaluations results are delivered neatly, however the flow of the paper makes it a bit difficult to follow sometimes due to many topics covered in it.	I-Review	I-2	Review	125
<sep> Regarding the significance of the paper, it tries to combine logic reasoning and probabilistic inference which is of great interest among the researchers recently.	O	O	Review	125
ExpressGNN proves to generalise well and perform accurate inference due to the tunable embeddings added at the GNN.	O	O	Review	125
<sep> <sep> Overall, the work of this paper seems technically sound but I don‚Äôt find the contributions particularly surprising or novel.	B-Review	B-1	Review	125
Along with plogicnet, there have been many extensions and applications of Gnns, and I didn‚Äôt find that the paper expands this perspective in any surprising way.	I-Review	I-1	Review	125
<sep> <sep> Thanks for your comments.	O	O	Reply	125
We briefly respond to a couple of points as follows.	O	O	Reply	125
<sep> <sep> <sep> &gt; The integration of variational EM and MLN has been explored in another work pLogicNet.	O	O	Reply	125
<sep> <sep> We have to clarify that our ExpressGNN work was proposed earlier than the pLogicNet.	B-Reply	B-2	Reply	125
In fact, we have submitted an earlier version of our work to arXiv 15 days before the pLogicNet appeared on arXiv ( <a href="https://arxiv.org/abs/1906.08495" target="_blank" rel="nofollow">https://arxiv.org/abs/1906.08495</a> ).	I-Reply	I-2	Reply	125
Due to the ongoing anonymous period, we could not provide the link of our arXiv submission here.	I-Reply	I-2	Reply	125
<sep> <sep> <sep> &gt; With pLogicNet, the contributions are not surprising or novel.	O	O	Reply	125
<sep> <sep> 1) As claimed above, we proposed the idea of integrating stochastic variational inference and MLN before the pLogicNet work appeared.	B-Reply	B-1	Reply	125
As a concurrent and later work, pLogicNet also employs variational EM for MLN inference, which should not hurt the originality and novelty of our work.	I-Reply	I-1	Reply	125
<sep> <sep> 2) Compared to pLogicNet, our work employs GNNs to capture the structure knowledge that is implicitly encoded in the knowledge graph.	B-Reply	B-1	Reply	125
For example, an entity can be affected by its neighborhood entities, which is not modeled in pLogicNet but can be captured by GNNs.	I-Reply	I-1	Reply	125
Our work models such implicit knowledge encoded in the graph structure to supplement the knowledge from logic formulae, while pLogicNet has no graph structure knowledge and only has a flattened embedding table for all the entities.	I-Reply	I-1	Reply	125
<sep> <sep> 3) Our method is a general framework that can trade-off the model compactness and expressiveness by tuning the dimensionality of the GNN part and the embedding part.	B-Reply	B-1	Reply	125
Thus, pLogicNet can be viewed as a special case of our work with the embedding part only.	I-Reply	I-1	Reply	125
<sep> <sep> 4) We compared our method with pLogicNet in the experiments.	B-Reply	B-1	Reply	125
Please refer to Table 3 for the experimental results.	I-Reply	I-1	Reply	125
Our method achieves significantly better performance than pLogicNet (MRR 0.49 vs 0.33, Hits@10 60.8 vs 52.8) on the FB15K-237 dataset.	I-Reply	I-1	Reply	125
<sep> <sep> We have updated the paper to incorporate the discussions above.	O	O	Reply	125

In this paper the authors propose a system, called ExpressGNN, that combines MLNs and GNNs.	O	O	Review	125
This system is able to perform inference and learning the weights of the logic formulas.	O	O	Review	125
<sep> <sep> The proposed approach seems valid and really intriguing.	O	O	Review	125
Moreover the problems it tackles, i.e. inference and learning over big knowledge graphs, are of foremost importance and are interesting for a wide community of researchers.	O	O	Review	125
<sep> I have just one concern and it is about the experiments for the knowledge graph completion task.	B-Review	B-1	Review	125
In fact, this task was performed only on one KG.	I-Review	I-1	Review	125
I think the proposed system should be evaluated on more KGs.	I-Review	I-1	Review	125
<sep> <sep> For these reasons I think the paper, after an extension of the experimental results, should be accepted.	O	O	Review	125
<sep> <sep> [Minor]	O	O	Review	125
Page 3. ‚	B-Review	B-2	Review	125
ÄúThe equality holds‚Äù which equality are you talking about?	I-Review	I-2	Review	125
<sep> <sep> Thanks for your review comments.	O	O	Reply	125
We briefly respond to your questions as follows.	O	O	Reply	125
<sep> <sep> <sep> &gt; The proposed system should be evaluated on more KGs.	O	O	Reply	125
<sep> <sep> In fact, our method is evaluated on four benchmark datasets with four different KGs: UW-CSE, Cora, Kinship, and Freebase.	B-Reply	B-1	Reply	125
These knowledge graphs are of different knowledge types and data distributions, and are widely used as benchmark datasets to evaluate MLNs and knowledge graph reasoning methods.	I-Reply	I-1	Reply	125
<sep> <sep> <sep> &gt; Page 3. ‚	O	O	Reply	125
ÄúThe equality holds‚Äù which equality are you talking about?	O	O	Reply	125
<sep> <sep> ‚ÄúThe equality holds‚Äù points to the equality in Eq. (2).	B-Reply	B-2	Reply	125
To make it more clear, we have added a reference to Eq. (2) in the updated paper.	I-Reply	I-2	Reply	125

In this paper, the authors introduce a black box adversarial attack based on estimating the sign of the gradient.	O	O	Review	10014
To estimate this more efficiently than the gradient itself, the authors exploit the fact that directional derivatives can be estimated using finite differences using only two function evaluations, and use a simple flip/revert procedure to estimate a number of sign bits simultaneously.	O	O	Review	10014
This sign bit gradient vector is then used in place of the true gradient in an FGSM-like procedure.	O	O	Review	10014
The central arguments are that (1) estimating the sign bits alone is sufficient to produce adversarial examples, and (2) this can be done quickly enough in practice to yield an efficient procedure.	O	O	Review	10014
<sep> <sep> Overall, I feel that this paper makes a decent contribution to blackbox adversarial generation in settings where confidence scores are available.	O	O	Review	10014
In particular, many algorithms in this area are often quite complicated and involve machinery like genetic programming.	O	O	Review	10014
Recent work has begun to demonstrate that significantly simpler routines can not only generate adversarial images, but can do so with significantly fewer queries than their more complicated counterparts.	O	O	Review	10014
<sep> <sep> In particular, two of the methods compared to (NES, Bandits-TD) are state of the art or nearly state of the art, and seem to be significantly outperformed in most regimes considered -- at a glance it appears this approach may outperform other recent work that isn't compared to, such as the method of Guo et al 2019.	B-Review	B-1	Review	10014
The inclusion of results on the public blackbox attack challenges is also welcome.	I-Review	I-1	Review	10014
<sep> <sep> Could the authors comment on the apparent degradation of performance on L2 performance as the image dimensionality increases?	B-Review	B-2	Review	10014
Is this simply an artifact of the fact that the ||x||_{2} &lt;= sqrt(n) ||x||_{\infty} bound directly scales with the input dimensionality?	I-Review	I-2	Review	10014
It would be interesting to verify this shortcoming by determining whether applying recent techniques for dimensionality reduction and approximating signed gradients in the subspace alters the relative performance of methods in the L2 perturbation constraint experiments.	I-Review	I-2	Review	10014
We thank the reviewer for their appreciation of our contribution‚Äôs effectiveness and simplicity.	O	O	Reply	10014
We are pleased s/he  noted our NES, Bandits-TD and public black box attack challenges results.	O	O	Reply	10014
<sep> -	O	O	Reply	10014
The comparison to Guo et al is a bit involved (and also requested by Maksym Andriushchenko in a public comment as item [2]).	B-Reply	B-1	Reply	10014
First, as we have highlighted in the discussion of our results, SignHunter is more suited to the perturbation setup.	I-Reply	I-1	Reply	10014
Nevertheless, for completeness, our experiments report performance on both and perturbation threats.	I-Reply	I-1	Reply	10014
On the other hand, Guo et al reports just L2 results and against models different from those considered in our paper‚Äîexcept for the IMAGENET v3 model, which the authors find much more difficult to attack.	I-Reply	I-1	Reply	10014
The v3 curves at 10, 000 queries in (Guo et al 2019, Figure 4) for SIMBA (and its variant SIMBA-DCT) look comparable to SignHunter‚Äôs of Figure 9 in our paper.	I-Reply	I-1	Reply	10014
Therefore, one can‚Äôt establish a direct comparison without dedicated experiments.	I-Reply	I-1	Reply	10014
<sep> Second, looking at Guo et al‚Äôs algorithm (SIMBA) implementation (<a href="https://github.com/cg563/simple-blackbox-attack/blob/master/simba_single.py)," target="_blank" rel="nofollow">https://github.com/cg563/simple-blackbox-attack/blob/master/simba_single.py),</a> it appears that it performs a single random coordinate flip at a time over {+1, 0,-1}. In our work towards SignHunter, we have found out that flipping one coordinate at a time is inefficient without dimensionality reduction.	I-Reply	I-1	Reply	10014
<sep> <sep> For the two points above, we have conducted two experiments.	I-Reply	I-1	Reply	10014
In the first experiment, we implemented Guo et al‚Äôs algorithm and evaluated it against the CIFAR10 model in Section 4 for both and.	I-Reply	I-1	Reply	10014
Results are discussed in Appendix H and they show that SIMBA is comparable to SignHunter in the setup but its performance drops significantly in the setup.,	I-Reply	I-1	Reply	10014
In the second experiment, we implement SIMBA‚Äôs single coordinate flips in the framework of SignHunter.	I-Reply	I-1	Reply	10014
That is, similar to SIMBA, we flip one coordinate at a time but the flips are over {-1,+1} instead of Guo et al‚Äôs {+1,0,-1}, we refer to this scheme as Naive.	I-Reply	I-1	Reply	10014
Results are shown in Appendix G and they demonstrate that single coordinate flips are not as effective as SignHunter‚Äôs adaptive coordinate flips.	I-Reply	I-1	Reply	10014
<sep> <sep> In addition to Guo et al‚Äôs work, we have discussed two other related recent works in the rest of Appendix G.	I-Reply	I-1	Reply	10014
<sep> -:	O	O	Reply	10014
We believe the relative performance degradation form Linf to L2 is primarily due to the reduced perturbation space that SignHunter has compared to other algorithms ‚Äî it only deals with {+1,-1} perturbations per pixel whereas other algorithms deal with {+1, 0, -1}.  As discussed in Section 4  vs. Perturbation Threat.),	B-Reply	B-2	Reply	10014
in an threat setup, other algorithms can vary each pixel x within.	I-Reply	I-2	Reply	10014
On the other hand, SignHunter is restricted to.	I-Reply	I-2	Reply	10014
In other words, SignHunter in perturbation setup behaves exactly the same when used in perturbation setup.	I-Reply	I-2	Reply	10014
We  add a new experiment in a new appendix (Appendix I) to intentionally highlight the additional perturbation space that other algorithms have over SignHunter in the setup by choosing to compare against NES and Bandits-TD as representative examples of standard and dimensionality-reduction-based algorithms against the CIFAR10 model used in Section 4 with an perturbation setup of.	I-Reply	I-2	Reply	10014
In this and and the setup used in Section 4, SignHunter behaves the same, while the performance of NES and Bandits-TD drops significantly from their performance due to the reduction in the perturbation space.	I-Reply	I-2	Reply	10014
<sep> <sep> A simple fix to this performance gap would be to extend the notion of binary sign flips over {+1,-1} to ternary sign flips and we intend to explore this thoroughly in future work.	I-Reply	I-2	Reply	10014

Summary:	O	O	Review	10014
This paper proposes a black-box adversarial sample generation algorithm, which proceeds by learning the signs of the gradient using an adaptive query scheme, which the authors call _SignHunter_. The authors begin by deriving an upper bound on the query complexity for _SignHunter_. Next, the authors empirically compare the performance of _SignHunter_	O	O	Review	10014
with existing sign-based optimization schemes in the literature, and demonstrate the advantages of _SignHunter_.	O	O	Review	10014
<sep> <sep> Main Comments:	O	O	Review	10014
<sep> - Theoretical analysis of the Adaptive Scheme: The authors emphasize the adaptive nature of the proposed scheme as one of the contributions.	B-Review	B-1	Review	10014
However, this claim is not justified theoretically:  it would be interesting if the benefits of adaptivity could be quantified in terms of improved worst-case query complexity etc.	I-Review	I-1	Review	10014
as compared to any non-adaptive scheme.	I-Review	I-1	Review	10014
The query complexity of 2^{\log(n)+1} given in Theorem 1 is not very informative, since a lower complexity (n) is achieved by a simple open-loop  scheme which serially queries each coordinate (i.e., the first query is coordinate 1, the second query is coordinate 2, and so on).	I-Review	I-1	Review	10014
<sep> <sep> -  Comparison with Hazan el.	B-Review	B-2	Review	10014
al (2018): A closely related work in optimizing real-valued functions with domain \{-1,1\}^n is Hazan et al published in ICLR 2018, which assumes that the black-box function is sparse or compressible in the Fourier domain, and employs compressed sensing techniques to get fast convergence rates in the optimization error.	I-Review	I-2	Review	10014
Since that paper considers a very similar optimization problem and proposes a scheme with provable convergence guarantees,  I think it is important that the authors compare,  either theoretically or empirically,  the performance of their proposed scheme with Harmonica (the algorithm of Hazan et al (2018)) to justify the benefits their proposed scheme.	I-Review	I-2	Review	10014
<sep> <sep> - Parameter Free Algorithm: The statement of Theorem 1 contains the following hypothesis: "the directional derivative is well approximated by the finite difference (Eq.1)".	B-Review	B-3	Review	10014
This condition must be clarified, because it seems to contradict the claim made by the authors later in the last line of Page 5 that _SignHunter_ is "parameter-free" as they set \delta= \epsilon.	I-Review	I-3	Review	10014
The condition in the statement of Theorem 1 will not necessarily be satisfied for any \delta, and admissible values of \delta must depend on the properties of the function.	I-Review	I-3	Review	10014
Informally, I think that the condition will only be satisfied for \delta "small enough", and one way to make precise the meaning of "small enough" is in terms of the Lipschitz constant of the neural network.	I-Review	I-3	Review	10014
However, in that case, I am not sure that the algorithm would remain parameter-free.	I-Review	I-3	Review	10014
I think the authors should make the assumption in Theorem 1 precise and derive suitable sufficient conditions on \delta under which the assumption is satisfied.	I-Review	I-3	Review	10014
<sep> <sep> References:	O	O	Review	10014
1.	O	O	Review	10014
Hazan, Elad, Adam Klivans, and Yang Yuan. "	O	O	Review	10014
Hyperparameter optimization: A spectral approach."	O	O	Review	10014
ICLR (2018).	O	O	Review	10014
<sep> <sep> We thank the reviewer for the insightful comments and remarks that improved the paper significantly.	O	O	Reply	10014
Please find our responses below.	O	O	Reply	10014
<sep> <sep> -:	O	O	Reply	10014
We acknowledge the limitations of the complexity upper bound  while pointing out that no other black-box bound exists.	B-Reply	B-1	Reply	10014
We can clarify our intent.	I-Reply	I-1	Reply	10014
The theorem is not intended to derive or motivate the algorithm, rather we are trying to draw attention to the cost of full sign recovery so we can contrast how  SignHunter succeeds with only partial recovery.	I-Reply	I-1	Reply	10014
We think it is of interest that SignHunter demonstrably outperforms other algorithms with tighter and better bounds because they have to complete all queries (wrt to their bounds) while SignHunter can exit much earlier.	I-Reply	I-1	Reply	10014
To demonstrate this, we ran over all the dataset/perturbation setups the open-loop scheme of sequential sign flips, which as the reviewers pointed out has a better query bound of in addition to other sign flip schemes.	I-Reply	I-1	Reply	10014
We have put the results in a new appendix ).	I-Reply	I-1	Reply	10014
The results highlight the advantage of SignHunter‚Äôs sign flips over the sequential flips, despite having a worse upper-bound on the query complexity.	I-Reply	I-1	Reply	10014
<sep> <sep> -:	O	O	Reply	10014
Thank you for drawing this interesting connection.	B-Reply	B-2	Reply	10014
Indeed, both algorithms seek to optimize a black-box function over the binary hypercube, albeit with different assumptions on the objective function.	I-Reply	I-2	Reply	10014
As the reviewer pointed out, Harmonica assumes that the objective function can be approximated by a sparse and low degree polynomial in the Fourier basis.	I-Reply	I-2	Reply	10014
Our assumption with SignHunter is that the objective function is separable (Property 1 in Section 3), this lets us optimize the black-box function with queries given an initial guess instead of searching over the vertices.	I-Reply	I-2	Reply	10014
If this assumption is not met, we can restart SignHunter with another guess with a search complexity of where m is the number of restarts.	I-Reply	I-2	Reply	10014
With this difference in assumptions of the two algorithms, we conducted an empirical comparison using two sample problems provided by Harmonica‚Äôs authors and used their implementation to run Harmonica.	I-Reply	I-2	Reply	10014
The comparison is illustrated in the newly added notebook in the code‚Äôs repo (<a href="https://github.com/sign4bb/sign_4_bb/tree/master/harmonica)."	I-Reply	I-2	Reply	10014
target="_blank" rel="nofollow">https://github.com/sign4bb/sign_4_bb/tree/master/harmonica).</a> The results show that SignHunter optimizes the two problems with 8x less number of queries than Harmonica, not to mention its significant computational advantage.	I-Reply	I-2	Reply	10014
The comparison is tabulated and discussed in of the revised manuscript.	I-Reply	I-2	Reply	10014
<sep> <sep> -:	O	O	Reply	10014
We view the algorithm as parameter-free viewing as a constraint on the allowed perturbation that is imposed upon all attacks and as the algorithm always takes as without any tuning.	B-Reply	B-3	Reply	10014
This is just like it needs to know the dimensionality of the model‚Äôs input.	I-Reply	I-3	Reply	10014
The other algorithms, on the other hand, tune for each dataset/perturbation constraint besides other parameters (see Appendix C, Tables 2 to 6).	I-Reply	I-3	Reply	10014
We revised our use of parameter-free to stress the tuning-free aspect of the algorithm, thank you for the remark.	I-Reply	I-3	Reply	10014
All black-box attacks that rely on finite-difference approximation, including, assume the directional derivative is well approximated by the finite-difference.	I-Reply	I-3	Reply	10014
We reiterate this prior to the proof in Appendix B in the revised manuscript.	I-Reply	I-3	Reply	10014

I'm satisfied with the response.	O	O	Review	10014
I'll keep my original rating towards acceptance.	O	O	Review	10014
<sep> <sep> ----------------------------	O	O	Review	10014
<sep> This paper proposes a black-box adversarial attack method to improve query efficiency and attack success rate.	O	O	Review	10014
Instead of estimating the gradient of a black-box model, the proposed method estimates the sign of the gradient, which is an easier task.	O	O	Review	10014
The SignHunter algorithm is proposed to estimate the sign of the gradient by a divide-and-conquer search.	O	O	Review	10014
And adversarial examples are generated based on the sign gradient.	O	O	Review	10014
Extensive experiments prove the effectiveness of the proposed attack method.	O	O	Review	10014
<sep> <sep> Overall, the proposed method on estimating the sign of the gradient for black-box attacks is novel.	O	O	Review	10014
The authors provide sufficient analysis to present the algorithm, making it clear to see the advantage of the proposed method over previous methods.	O	O	Review	10014
I have some minor comments on this paper.	O	O	Review	10014
<sep> <sep> 1.	O	O	Review	10014
In Section 2 (Line 15), the authors argue that "However, the queries are not adaptive, they are constructed based on i.i.d.	B-Review	B-1	Review	10014
random vectors {vi}".	I-Review	I-1	Review	10014
However, in Ilyas et al (2019), the queries are designed based on the time prior, which are actually adaptive.	I-Review	I-1	Review	10014
<sep> <sep> 2.	O	O	Review	10014
Estimating the sign of the gradient is more suitable for attacks based on the l_\infty norm, but could affect the results for l_2 attacks, since it reduces the search space.	B-Review	B-2	Review	10014
The experiments also show that the proposed method for l_2 attacks is not as effective as l_\infty attacks.	I-Review	I-2	Review	10014
<sep> <sep> 3.	B-Review	B-3	Review	10014
It's better to show some tabular results in Section 4 rather than appendix to compare the performance with numbers.	I-Review	I-3	Review	10014
We thank the reviewer for the insightful remarks.	O	O	Reply	10014
Please find the responses below.	O	O	Reply	10014
<sep> <sep> 1.	O	O	Reply	10014
We use the term adaptive to characterize how the algorithm constructs its perturbation vector deterministically based on the previous perturbations.	B-Reply	B-1	Reply	10014
Mathematically, the perturbation vector at time can be expressed as, where is the sign flip mask at step and is the indicator vector to keep the sign flips at step--multiplications are element-wise.	I-Reply	I-1	Reply	10014
In contrast, other algorithms construct I.I.D randomly perturbation vectors:.	I-Reply	I-1	Reply	10014
We have added a footnote that discusses the above (Section 1, Page 2).	I-Reply	I-1	Reply	10014
<sep> <sep> 2.	O	O	Reply	10014
The reviewer is correct.	B-Reply	B-2	Reply	10014
We have added a new appendix (Appendix I) that discusses the reduction in the search space for SignHunter in the setup in more detail.	I-Reply	I-2	Reply	10014
<sep> <sep> 3.	O	O	Reply	10014
Thank you for the remark.	B-Reply	B-3	Reply	10014
As a representative of the datasets, we have included a tabulated summary of the CIFAR10 experiments in Section 4.	I-Reply	I-3	Reply	10014

Authors propose three modifications to dropout, specifically in context of dropout applied to deep networks utilizing the ReLU non-linearity.	O	O	Review	1464
The three modifications seem independently motivated and aim to overcome separate potential shortcomings of the current dropout approach.	O	O	Review	1464
These three modifications are combined into a new approach termed Jumpout.	O	O	Review	1464
<sep> <sep> Overall I find this to be a weak paper requiring further work, for the following main reasons:	O	O	Review	1464
<sep> * The proposed modifications are intuitively motivated and then empirically supported.	B-Review	B-1	Review	1464
However, I find the intuitive reasoning unclear and have to lean much more on empirical evidence.	I-Review	I-1	Review	1464
For instance, the motivation for modification 2 ‚Äúdropout rate adapted to number of active neurons‚Äù, is that in case ReLU causes a large number of neurons to ‚Äòshut down‚Äô then the dropout rate in that layer should be reduced (or increased, depending on how it is defined) causing fewer neurons to further dropout.	I-Review	I-1	Review	1464
However, if preventing co-adaptation is a reason to dropout neurons then the issue of conditional correlation (or co-activation given related inputs) will remain regardless of number of active neurons in a layer, thus changing the dropout rate as a function of ReLU activation is not fully justified.	I-Review	I-1	Review	1464
Similarly, modification 3 ‚Äúrescale outputs to work with batch normalization‚Äù proposes exponentiation by -0.75 with weak justification as a compromise.	I-Review	I-1	Review	1464
<sep> <sep> * I find the empirical evidence and support for the three modifications lacking in detail.	B-Review	B-2	Review	1464
The authors provide results of the combined Jumpout technique on a number of tasks, but do not demonstrate effectiveness and contribution of individual modifications on error rates on the tasks they evaluated.	I-Review	I-2	Review	1464
<sep> <sep> * I also find the baseline systems to be on the weaker side (e.g. on CIFAR100 many systems now have higher than 82% accuracy with best being over 84, on STL-10 many systems now are well above 85%).	B-Review	B-3	Review	1464
<sep> <sep> Thanks for your comments!	O	O	Reply	1464
We add a thorough ablation study as you suggested, but do not agree with other points.	O	O	Reply	1464
<sep> <sep> Q1: However, I find the intuitive reasoning unclear and have to lean much more on empirical evidence.	O	O	Reply	1464
<sep> <sep> R1: Modification 1 and 2 are theoretically supported by the rigorous analysis of ReLU DNNs in Section 2, i.e., a ReLU DNN equals to a set of local linear models defined on a set of respective convex polyhedra in the input space, each containing a few data points.	B-Reply	B-1	Reply	1464
Modification 1 improves the local smoothness of the generalization of each linear model (associated with a specific polyhedron), by training it also on data points located at other nearby polyhedra with higher probability.	I-Reply	I-1	Reply	1464
Modification 2 ensures the homogeneity of the local smoothness, i.e., it generalizes each linear model to the nearby polyhedra of equal distance to the original one (measured by the number of different activation patterns) with the same probability.	I-Reply	I-1	Reply	1464
Modification 3 aims to reduce and balance the mean drift and variance drift when applying dropout together with batch normalization.	I-Reply	I-1	Reply	1464
<sep> <sep> Q2: For instance, the motivation for modification 2...However, if preventing co-adaptation is a reason to dropout neurons then the issue of conditional correlation (or co-activation given related inputs) will remain regardless of the number of active neurons in a layer, thus changing the dropout rate as a function of ReLU activation is not fully justified.	O	O	Reply	1464
<sep> <sep> R2: It is wrong to entirely block co-adaptation.	B-Reply	B-1	Reply	1464
Dropout aims to weaken co-adaptation but not to entirely remove it, since exploring the correlation between hidden nodes is an important part of optimizing the model weights (considering backpropagation for example).	I-Reply	I-1	Reply	1464
Comparing to dropout, jumpout allows slightly more co-adaptation, but the amount is extremely small and negligible.	I-Reply	I-1	Reply	1464
Because the adaptive dropout rate is a single number applied to hundreds of thousands of hidden nodes in a layer and a mini-batch.	I-Reply	I-1	Reply	1464
Considering how much a single number can describe the correlation among hundreds of thousands of variables: its influence is negligible.	I-Reply	I-1	Reply	1464
<sep> <sep> In addition, it is worth noting that fixing dropout rate can be catastrophic during training.	I-Reply	I-1	Reply	1464
As shown in Figure 1, since existing training methods do not have any control on the ratio of activated neurons per layer, it is very possible that some layers have many activated nodes while some have very few.	I-Reply	I-1	Reply	1464
For the former, a relatively large dropout rate is required to avoid overfitting.	I-Reply	I-1	Reply	1464
However, applying the same large dropout rate to the latter will almost cut the information flow sent from input to deeper layers.	I-Reply	I-1	Reply	1464
In this case, the output will almost independent to the input, which is catastrophic.	I-Reply	I-1	Reply	1464
<sep> <sep> Q3: Similarly, modification 3 ‚Äúrescale outputs to work with batch normalization‚Äù proposes exponentiation by -0.75 with weak justification as a compromise.	O	O	Reply	1464
<sep> <sep> R3: Modification 3 is theoretically derived from the given analysis of mean/variance drift in Section 3.3.	B-Reply	B-1	Reply	1464
In order to balance the reduced mean drift and variance drift, the power in the rescaling factor should be between and.	I-Reply	I-1	Reply	1464
Without any extra information about the weight matrices of the following layers, -0.75 provides a good trade-off between reducing the mean drift and the variance drift (as shown in Figure 3), and also shows promising and consistent performance boost in our experiments.	I-Reply	I-1	Reply	1464
So modification 3 does not rely on any "weak justification".	I-Reply	I-1	Reply	1464

This paper proposes jumpout, which is a 3 step modification based on dropoout	O	O	Review	1464
that is designed to work better with batch normalization.	O	O	Review	1464
Unfortunately, I did not understand the arguments on locally linear regions and ReLu and its relationship with the monotone dropout scheme,	B-Review	B-1	Review	1464
or why the half Gaussian is chosen.	I-Review	I-1	Review	1464
<sep> <sep> Still, jump out the procedure is fairly clear in Algorithm 1, and the results seems good.	O	O	Review	1464
<sep> However, I could not make out much of why each step is done, and could not find empirical tests of the value of each step.	B-Review	B-2	Review	1464
<sep> <sep> I think the paper needs more work.	B-Review	B-3	Review	1464
All the proposals seem very heuristic, and it is important to test their separate effects.	I-Review	I-3	Review	1464
It should be easy to perform a ablation analysis since the 3 proposed steps are pretty independent and can be tested separately.	O	O	Review	1464
Since two of these have to do with modifying the dropout rate, it would be important to compare with carefully cross-validated dropout rates, which I also do not see.	O	O	Review	1464
Thanks for your comments!	O	O	Reply	1464
We added the ablation study you suggested, and briefly explained the locally linear region in the following.	O	O	Reply	1464
The three modifications are based on theoretical analysis and are not heuristic.	O	O	Reply	1464
<sep> <sep> Q1: Unfortunately, I did not understand the arguments on locally linear regions and ReLu and its relationship with the monotone dropout scheme, or why the half Gaussian is chosen.	O	O	Reply	1464
<sep> <sep> R1: Intuitively, we show that a ReLU DNN equals to a set of linear models defined on a set of respective convex polyhedra in the input space.	B-Reply	B-1	Reply	1464
Each linear model is only applied to the data point within the respective polyhedron.	I-Reply	I-1	Reply	1464
The monotone dropout rate encourages the local smoothness of the generalization of each linear model, by training the linear model also on data points located at other nearby polyhedra with higher probability.	I-Reply	I-1	Reply	1464
Sampling from the half Gaussian ensures that the data points from closer polyhedra have a higher probability to be used to train the linear model.	I-Reply	I-1	Reply	1464
<sep> <sep> Q2: However, I could not make out much of why each step is done, and could not find empirical tests of the value of each step...it is important to test their separate effects...It should be easy to perform an ablation analysis...	O	O	Reply	1464
<sep> R2: In the updated draft (Table 1), we provided a thorough ablation study on multiple datasets.	B-Reply	B-2	Reply	1464
It compares the performance of all the 7 different combinations of the three modifications.	I-Reply	I-2	Reply	1464
This will provide a complete answer to your question.	I-Reply	I-2	Reply	1464
<sep> <sep> Q3: All the proposals seem very heuristic.	O	O	Reply	1464
<sep> <sep> R3: This is not true.	B-Reply	B-3	Reply	1464
Modification 1 and 2 are theoretically supported by the rigorous analysis of ReLU DNNs in Section 2, while modification 3 is derived from the given analysis of mean/variance drift in Section 3.3 (it aims to balance the reduced mean drift and variance drift).	I-Reply	I-3	Reply	1464

The paper proposes yet another variant of the celebrated Dropout algorithm.	O	O	Review	1464
Specifically, the proposed method attempts to address the obvious drawbacks of Dropout: (i) the need to heuristically select the Dropout rate; and (ii) the universality of this selection across a layer.	B-Review	B-1	Review	1464
<sep> <sep> As the authors have admitted in the paper (Sec.	O	O	Review	1464
1.2), there is a variety of methods already addressing the same problem.	O	O	Review	1464
They argue that contrary to some of these methods "jumpout does not rely on additional trained models: it adjusts the dropout rate solely based on the ReLU activation patterns.	O	O	Review	1464
Moreover, jumpout introduces negligible computation and memory overhead relative to the original dropout methods, and can be easily incorporated into existing model architectures."	O	O	Review	1464
<sep> <sep> However, this is argument is certainly untrue and rather misleading.	B-Review	B-2	Review	1464
The works of Kingma et al (2015) and Molchanov et al (2017), that the authors cite, does not introduce additional trained models.	I-Review	I-2	Review	1464
In addition, there is additional related work that the authors do not cite, but ought to:	I-Review	I-2	Review	1464
<sep> [1] Yarin Gal, Jiri Hron, Alex Kendall, "Concrete Dropout," Proc.	I-Review	I-2	Review	1464
NIPS 2017.	I-Review	I-2	Review	1464
<sep> [2] Yingzhen Li, Yarin Gal, "Dropout Inference in Bayesian Neural Networks with Alpha-divergences," Proc ICML 2017.	I-Review	I-2	Review	1464
<sep> [3] Harris Partaourides, Sotirios Chatzis, ‚ÄúDeep Network Regularization via Bayesian Inference of Synaptic Connectivity,‚Äù J. Kim et al (Eds.):	I-Review	I-2	Review	1464
PAKDD 2017, Part I, LNAI 10234, pp.30‚Äì41, 2017.	I-Review	I-2	Review	1464
<sep> <sep> These methods also address a similar problem, without introducing extra networks or imposing extra costs art inference time.	I-Review	I-2	Review	1464
Thus, citing them, as well as COMPARING to them, is a necessity for this paper to be convincing.	I-Review	I-2	Review	1464
<sep> <sep> These crucial shortcoming aside, there are various theoretical claims in this paper that are not sufficiently substantiated.	O	O	Review	1464
To begin with, the arguments used in the last paragraph of page 4 seem at least speculative; then,  the authors proceed to propose a solution to the alleged problem in the beginning of page 5.	O	O	Review	1464
They suggest sampling from a truncated Gaussian, but they do not elaborate on why this selection solves the problem; they limit themselves to noting that other selections, such as the Beta distribution, may also be considered in the future.	B-Review	B-3	Review	1464
We must also underline that [3] have suggested exactly that; sampling from a Beta.	I-Review	I-3	Review	1464
<sep> <sep> Finally, the last two modifications the authors propose seem reasonable, yet they are extremely heuristic.	O	O	Review	1464
No one knows (which can be guaranteed through theoretical proofs or solid experimental evidence) that without these the method would not work.	B-Review	B-4	Review	1464
In addition, previous papers, e.g. [1-3] achieve similar goals in a principled fashion (ie by inferring proper posterior densities); without experimental comparisons, nobody knows which paradigm is best to adopt.	I-Review	I-4	Review	1464
<sep> <sep> <sep> Thanks for your comments!	O	O	Reply	1464
We added the ablation study to demonstrate the effectiveness of every individual modification.	O	O	Reply	1464
We further emphasize that jumpout is not a variational dropout approach, and can scale to very large networks.	O	O	Reply	1464
We also added a comparison with concrete dropout[1] as suggested (Table 3 in Appendix).	O	O	Reply	1464
<sep> <sep> Q1: Overview of the paper: "Specifically, the proposed method attempts to address the obvious drawbacks of Dropout: (i) the need to heuristically select the Dropout rate; and (ii) the universality of this selection across a layer."	O	O	Reply	1464
<sep> <sep> R1: "(i) the need to heuristically select the Dropout rate" is merely one observation of the paper and 1/3 of the drawbacks we aim to address, and we never attempt to address "(ii) the universality of this selection across a layer", i.e., for all nodes on a layer, jumpout applies the same drop rate.	B-Reply	B-1	Reply	1464
The primary purpose of jumpout is to improve the original dropout performance without introducing extra computational costs.	I-Reply	I-1	Reply	1464
The truncated Gaussian distribution aims to improve the dropout performance based on the linear model geometry of ReLU networks.	I-Reply	I-1	Reply	1464
The change of dropout rate based on ReLU pattern tries to address the dropout rate selection problem.	I-Reply	I-1	Reply	1464
The change of rescaling factor resolves the disharmony between dropout and batchnorm, so for a network with both kinds of layers, the performance gets boosted.	I-Reply	I-1	Reply	1464
<sep> <sep> Q2: Comparison to [1],[2] and [3].	O	O	Reply	1464
<sep> R2: We note that jumpout is NOT a variational approach of dropout, which does not require Bayesian training or inference.	B-Reply	B-2	Reply	1464
Jumpout does not introduce extra inference cost, and it also has similar training costs as the original dropout.	I-Reply	I-2	Reply	1464
Jumpout can therefore work on modern networks with deep and wide structures, whereas the variational approaches [2] and [3] do not scale to the networks we include in the paper.	I-Reply	I-2	Reply	1464
For [1], we add comparison experiments and show that jumpout significantly outperforms [1].	I-Reply	I-2	Reply	1464
[1],[2] and [3] tries to address the problem similar to our observation 2, namely, selection of the dropout rate.	I-Reply	I-2	Reply	1464
Jumpout has 2 other major changes: we choose to impose a truncated Gaussian distribution on the dropout rate based on the linear model geometry of the ReLU network, and we change the rescaling factor to account for the disharmony between dropout and batchnorm.	I-Reply	I-2	Reply	1464
<sep> <sep> Q3: They suggest sampling from a truncated Gaussian, but they do not elaborate on why this selection solves the problem.	O	O	Reply	1464
<sep> <sep> R3:The truncated Gaussian distribution is a natural choice based on the intuition based on the linear model geometry of ReLU networks.	B-Reply	B-3	Reply	1464
Again, jumpout is not a variational approach, and the truncated Gaussian distribution is not aimed to solve the dropout rate selection problem.	I-Reply	I-3	Reply	1464
The truncated Gaussian is applied because the original dropout has the uniform preference for both nearby and faraway linear models, while in principle, close linear models should be preferred.	I-Reply	I-3	Reply	1464
Also, for [3], the beta distribution is selected with no clear reason at all.	I-Reply	I-3	Reply	1464
<sep> <sep> Q4: No one knows without these the method would not work.	O	O	Reply	1464
<sep> <sep> R4: We add thorough ablation studies on all combinations of the 3 modifications to show that 1) they all have positive impacts on the performance, and 2) 3 modifications can work together to get the best performance.	B-Reply	B-4	Reply	1464

This article presents an interesting if heuristic approach to source separation, NES, buttressed by the use of GLO masking for initialization, with promising results on data generated from synthetic source mixing.	O	O	Review	1316
<sep> <sep> The paper is well written and on the whole clear.	O	O	Review	1316
My main concern with the work is the empirical nature of the NES iterative procedure.	B-Review	B-1	Review	1316
As far as I can tell there is no guarantee of convergence (nor discussion concerning this point).	I-Review	I-1	Review	1316
Since i am not familiar with the tasks, it is hard for me to judge the quality of the empirical results -- though the results do seem promising.	I-Review	I-1	Review	1316
<sep> <sep> re: Bags & shoes task / table 1: "...  Finetuning from GLOM, helped NES achieve stronger performance, nearly identical to the fully-supervised upper bound.	B-Review	B-2	Review	1316
It performed better than finetuning from AM (which achieved 22.5/0.85 and 22.7/0.86)": I can't place the first number in the table, therefore i'm not quite sure what is being pointed out here.	I-Review	I-2	Review	1316
<sep> <sep> re: Music task / table 3: "... GLOM was much better than AM initialization (that achieved 0.9 and 2.9)": I don't see either number in the table.	B-Review	B-3	Review	1316
I'd assumed that GLOM was used to fine-tune NES, so I was expecting to see the 2.9 under "FT".	I-Review	I-3	Review	1316
<sep> <sep> ==	O	O	Review	1316
<sep> I think the authors' response is reasonable.	O	O	Review	1316
They have added clarifying material to the paper addressing my concerns.	O	O	Review	1316
I have raised my rating from a 5 to a 6.	O	O	Review	1316
We thank the reviewer for the positive review, particularly for commending the ‚Äúinteresting ideas‚Äù, ‚Äúpromising results‚Äù and clarity of the paper.	O	O	Reply	1316
<sep> <sep> We are able to theoretically show that the correct separation result is a global minimum of NES, but we are yet unaware of a convergence guarantee.	B-Reply	B-1	Reply	1316
The same can be said however for most successful deep learning methods.	I-Reply	I-1	Reply	1316
We establish the good performance of our method via extensive empirical experiments, which the reviewer described as ‚Äúpromising‚Äù.	I-Reply	I-1	Reply	1316
We have added this to the discussion.	I-Reply	I-1	Reply	1316
<sep> <sep> Thank you for asking for clarifications on the AM-FT results (different from the AM results).	B-Reply	B-3	Reply	1316
We did not insert them into the table for space considerations, they only appear in the text.	I-Reply	I-3	Reply	1316
We changed the text to elucidate this.	I-Reply	I-3	Reply	1316
<sep> <sep> We hope that the reviewer will be able to change the decision to an acceptance given the positive nature of the review.	O	O	Reply	1316

This paper describes a signal separation method called neural egg separation (NES).	O	O	Review	1316
<sep> The separation problem is tackled in a semi-supervised setting where the observed mixture contains a target signal and a background noise, with access to the distributions of target and mixture signals.	B-Review	B-5	Review	1316
<sep> <sep> The strength of the paper is that it describes the importance of the problem setup for practical use with some motivating examples.	O	O	Review	1316
<sep> However, some unclear notations weaken the claim of the paper.	O	O	Review	1316
<sep> <sep> Specific comments follow.	O	O	Review	1316
<sep> * The loss in (1) is unclear.	B-Review	B-1	Review	1316
<sep> Assuming latex grammar, \| \| is usually used to denote a vector norm, but (1) has two values inside.	I-Review	I-1	Review	1316
<sep> I would write \ell(T(y_i), b_i) to show a loss function, instead of the \| \| style.	I-Review	I-1	Review	1316
<sep> More importantly, the loss should be explicitly defined.	I-Review	I-1	Review	1316
Does this mean the l2 error?	I-Review	I-1	Review	1316
<sep> <sep> * The iterative separation process of (2) is even unclear.	B-Review	B-2	Review	1316
<sep> Does T^m(b_j + x_i^m) share the parameter of that from previous iterations like T^{m-1}?	I-Review	I-2	Review	1316
<sep> Or are the parameters fixed throughout the iterations?	I-Review	I-2	Review	1316
<sep> <sep> * Use of \cdot.	B-Review	B-3	Review	1316
<sep> There may be a confusion between the inner product and element-wise product with the \cdot operator.	I-Review	I-3	Review	1316
<sep> Right after (5), there is an inequality z \cdot z \leq 1, which is meant to be the inner product.	I-Review	I-3	Review	1316
<sep> On the other hand, the use of \cdot in (8) looks like the element-wise product to describe a masking operation.	I-Review	I-3	Review	1316
<sep> <sep> Clarifying the objective and overall procedures is necessary for presenting the proposed method.	O	O	Review	1316
<sep> <sep> =================================	O	O	Review	1316
EDIT: I confirmed the revisions regarding the notation issues, but there still have confusing parts.	B-Review	B-4	Review	1316
<sep> * Definitions of norm operator \| \| is unclear.	I-Review	I-4	Review	1316
<sep> * L_1 is mentioned below (1), and used other parts (3) or Algorithm 1.	I-Review	I-4	Review	1316
Equation (12) in Appendix uses |W1|_1^2, which looks like the l1 norm as well.	I-Review	I-4	Review	1316
Use consistent notations.	I-Review	I-4	Review	1316
<sep> * Equations (12, 13, 14) uses \|\|_2 or \|\|_1 to specify the type of norm, whereas (5), (6), (7) and other parts after (15) use \|\|. This confuses me.	I-Review	I-4	Review	1316
What do you mean by \|\| without subscript?	I-Review	I-4	Review	1316
<sep> * \|\| operator taking to symbols is a weird notation for me.	I-Review	I-4	Review	1316
Usually, norm is defined for a single vector (or a matrix).	I-Review	I-4	Review	1316
For example in (5), I would write \| b - G(z_b) \|, if you want to measure the difference between b and G(z_b).	I-Review	I-4	Review	1316
<sep> <sep> The experimental result is impressive, as the other reviewers mention.	O	O	Review	1316
I strongly recommend clarifying the notation to better deliver the method.	O	O	Review	1316
Thank you for recognizing the importance of our formulation.	O	O	Reply	1316
<sep> <sep> ‚Äúa semi-supervised setting where the observed mixture contains a target signal and a background noise, with access to the distributions of target and mixture signals.	O	O	Reply	1316
‚Äù : We would like to highlight that our method is more general than merely separating between target and noise while being given the distribution of the target.	O	O	Reply	1316
We also deal with the much harder case of separating the target being given only pure samples from the nuisance signal (this is the case for the speech and music separation experiments).	O	O	Reply	1316
The only assumption is that one of the sources is given (regardless of which one it is).	O	O	Reply	1316
<sep> <sep> Thank you for pointing out some notational improvements:	B-Reply	B-5	Reply	1316
<sep> ‚ÄúThe loss in (1) is unclear‚Äù : As per the suggestion by the reviewer, we replaced the \|,\| notation by \ell().	B-Reply	B-1	Reply	1316
We use an L1 loss throughout the paper and made it clear where appropriate.	I-Reply	I-1	Reply	1316
<sep> <sep> ‚ÄúDoes T^m(b_j + x_i^m) share the parameter of that from previous iterations like T^{m-1}?‚Äù : The separation function T^m() is initialized by the weights of the separation function T^{m-1} from the previous iteration (starting from random initialization would also work, however it would require more epochs per iteration).	B-Reply	B-2	Reply	1316
T^m() is of course trained during the iteration.	I-Reply	I-2	Reply	1316
In response to the reviewer‚Äôs question, we removed the superscript altogether, thereby significantly simplifying the notation (while the algorithm does not change).	I-Reply	I-2	Reply	1316
We also added a description of our method in the form of an algorithm, further improving clarity.	I-Reply	I-2	Reply	1316
<sep> <sep> ‚Äúconfusion between the inner product and element-wise product‚Äù: We resolved the overloading of dot products with both scalar and element-wise product by replacing all element-wise products by the operation \odot.	B-Reply	B-3	Reply	1316
<sep> <sep> We believe this addresses all issues raised by the reviewer.	O	O	Reply	1316
If there are any remaining issues, we would be most enthusiastic to address them.	O	O	Reply	1316

This paper presents an iterative approach to separate unobserved distribution signal from a mixture with observed distribution.	O	O	Review	1316
The proposed approach looks reasonable to me, however, the experiment and analysis are insufficient.	O	O	Review	1316
<sep> 1.	B-Review	B-1	Review	1316
At test time, does the input also go through the same number of iterations (10)?	I-Review	I-1	Review	1316
I would like to see how the separated results evolve over iterations.	I-Review	I-1	Review	1316
<sep> 2.	B-Review	B-2	Review	1316
It is not clear what is the quality of samples generated by GLO.	I-Review	I-2	Review	1316
In the image separation task, GLOM performs better than GAN, but worse in other tasks.	I-Review	I-2	Review	1316
Analysis is needed here.	I-Review	I-2	Review	1316
<sep> 3.	B-Review	B-3	Review	1316
I noticed that only in the music separation task, finetuning is significantly better than vanilla NES.	I-Review	I-3	Review	1316
Is it because generative models can synthesize more realistic data samples?	I-Review	I-3	Review	1316
For example, would the generator learn to synthesize X+B with temporal synchronization?	I-Review	I-3	Review	1316
More analysis is also needed here.	I-Review	I-3	Review	1316
<sep> <sep> ============================	O	O	Review	1316
<sep> I think the reviewer addressed my questions and concerns in the rebuttal, so I raised my rating to 6.	O	O	Review	1316
Thank you for your positive opinion of our method and request for further analysis.	O	O	Reply	1316
<sep> <sep> ‚ÄúAt test time, does the input also go through the same number of iterations (10)?‚Äù : At test time there are no iterations, just a single application of T(), our approach is only iterative in training.	B-Reply	B-1	Reply	1316
The objective of our approach is to create synthetic training samples from the unobserved distribution, which are very similar to unobserved real samples.	I-Reply	I-1	Reply	1316
Once obtained, it suffices to train a separation function T() which minimizes the supervised regression objective - using the synthetic mixtures.	I-Reply	I-1	Reply	1316
This separation function - which is just a single neural network - can be directly applied at test time for any mixture y and yield separated signals x and b (which are given by T(y) and y-T(y)).	I-Reply	I-1	Reply	1316
Following the responses by the reviewers, we significantly simplified the notation and added a description of our method in the form of an algorithm.	I-Reply	I-1	Reply	1316
Our edits are marked in red.	I-Reply	I-1	Reply	1316
<sep> <sep> ‚ÄúIn the image separation task, GLOM performs better than GAN, but worse in other tasks.	O	O	Reply	1316
Analysis is needed here.	O	O	Reply	1316
‚Äù : We would like to explain that we do not claim the generations by GLO are of better quality than GAN.	B-Reply	B-2	Reply	1316
In our experiments, GLOM as a standalone method always underperformed AM in terms of PSNR or SDR, with the sole exception of vocal-instrumental separation.	I-Reply	I-2	Reply	1316
GLOM however does not suffer from mode-dropping, making it more suitable for initializing NES.	I-Reply	I-2	Reply	1316
It is crucial for an initialization to not be too close to a bad local minimum.	I-Reply	I-2	Reply	1316
As GANs generate high quality samples but suffer from mode dropping, they push NES towards suboptimal solutions.	I-Reply	I-2	Reply	1316
We think that GLOM provides an initialization that is further away from bad local minima with missing modes and is therefore a better initialization for NES.	I-Reply	I-2	Reply	1316
<sep> <sep> ‚Äúonly in the music separation task, finetuning is significantly better than vanilla NES.	O	O	Reply	1316
Is it because generative models can synthesize more realistic data samples?‚Äù : We think that the good performance of GLOM initialization for music separation comes from the fact that it makes no assumption of the relation between the two sources.	B-Reply	B-3	Reply	1316
Vanilla NES assumes independence between the sources, which is not true for instrumental and vocal (or drums) sources in music.	I-Reply	I-3	Reply	1316
It is therefore empirically found to be important to use a good initialization by a technique that does not make the independence assumption (which can be AM or GLOM).	I-Reply	I-3	Reply	1316
We give possible reasons above for GLOM being a better initializer than AM.	I-Reply	I-3	Reply	1316
<sep> <sep> ‚Äúwould the generator learn to synthesize X+B with temporal synchronization?‚Äù :  It should be noted that GLOM does not consist of a single generator but two generators.	B-Reply	B-3	Reply	1316
G_X() for X and G_B() for B. By using clean training samples from B, we train G_B(), while using the mixture samples we can then train G_X().	I-Reply	I-3	Reply	1316
GLOM never learns about the dependance between X and B. G_X() and G_B() use unrelated latent spaces (and do not rely on dependence or independence assumptions).	I-Reply	I-3	Reply	1316
We therefore do not expect them to generate signals that are synchronized, but do expect them to be effective in all cases of synchronization.	I-Reply	I-3	Reply	1316
<sep> <sep> We will add results addressing the other requests made by the reviewer within the next few days.	O	O	Reply	1316
We would be happy to provide the reviewer with any additional information.	O	O	Reply	1316

This paper assesses feature learning algorithms by comparing their performance on an object classification task to that of Macaque IT and V4 neurons.	O	O	Review	3
The work provides a new dataset of images, an analysis method for comparing feature representations based on kernel analysis, and neural feature vectors recorded from V4 and IT neurons in response to these images.	O	O	Review	3
The authors evaluate a number of recent representational learning algorithms, and identify a recent approach based on deep convolutional networks outperforms V4 and IT neurons.	O	O	Review	3
<sep> <sep> The paper is the first of its kind in providing easy tools to evaluate new representations against high level neural visual representations.	O	O	Review	3
It's comparison method differs from prior work by investigating representational learning with respect to a task, and hence is less influenced by potentially task-irrelevant idiosyncrasies of the neural response.	O	O	Review	3
The final conclusion reached, that recent models are beginning to surpass V4 and IT models, is very interesting.	O	O	Review	3
The authors have clearly explained their rationale behind the many design choices required, and their choices seem very reasonable.	O	O	Review	3
<sep> <sep> Because of the many design choices to be made in reducing neural data to a feature representation (the use of multi units rather than singular units, time averaging, short presentation times--many of which are discussed by the authors in the text), the resulting V4/IT performance is likely a lower bound on the true performance.	B-Review	B-1	Review	3
To surpass a lower bound is good news, but to be a useful metric for future research efforts, this lower bound would should lie above current models' performance.	I-Review	I-1	Review	3
The fact that the Krizhevsky model already outperforms V4/IT means there is less reason to compare future representation algorithms using the proposed metric in its current form.	I-Review	I-1	Review	3
<sep> <sep> The kernel analysis metric asks whether neural and artificial data can achieve similar classification performance for a given model complexity, but this is a separate question from asking whether the neural representation is similar to the artificial representation; e.g., for a classification task, one could imagine many different pairwise similarity structures that would remain linearly separable (or said with the standard metaphor, both a bird and a plane can fly, but rely on different mechanisms).	B-Review	B-2	Review	3
While some aspects of the neural response may be task irrelevant, it may be complementary to augment the KA-AUC approach with a similarity-based approach.	I-Review	I-2	Review	3
This could also be computed from the collected data and would help map levels within a computational model to visual brain areas.	I-Review	I-2	Review	3
In general a more extensive discussion of and contrast with the Kriegeskorte approach would be helpful.	I-Review	I-2	Review	3
Thank you for your review and feedback. (	O	O	Reply	3
>-mark indicates quote from review)	O	O	Reply	3
<sep> > Because of the many design choices to be made in reducing neural data to a feature representation (the use of multi units rather than singular units, time averaging, short presentation times--many of which are discussed by the authors in the text), the resulting V4/IT performance is likely a lower bound on the true performance.	O	O	Reply	3
To surpass a lower bound is good news, but to be a useful metric for future research efforts, this lower bound would should lie above current models' performance.	O	O	Reply	3
The fact that the Krizhevsky model already outperforms V4/IT means there is less reason to compare future representation algorithms using the proposed metric in its current form.	O	O	Reply	3
<sep> <sep> These are good points.	B-Reply	B-1	Reply	3
We did not know what to expect before we began measuring models and have been quite surprised by the performance of the Krizhevsky et al model.	I-Reply	I-1	Reply	3
Even given that this model surpasses IT, we still believe it is a relevant benchmark for algorithmic research.	I-Reply	I-1	Reply	3
There are many interesting factors that go into the performance that will be worthwhile exploring, especially those related to efficiency (our opinion).	I-Reply	I-1	Reply	3
<sep> <sep> Furthermore, given the assumed ‚Äúlower-bound‚Äù nature of the neural representation, we hope that this effort will encourage experimentalists to collect higher lower-bounds of the neural representation.	B-Reply	B-1	Reply	3
Ideally, over time, we imagine a scenario similar to the progression in computer vision of increasingly challenging benchmarks of neural representation.	I-Reply	I-1	Reply	3
<sep> <sep> > The kernel analysis metric asks whether neural and artificial data can achieve similar classification performance for a given model complexity, but this is a separate question from asking whether the neural representation is similar to the artificial representation; e.g., for a classification task, one could imagine many different pairwise similarity structures that would remain linearly separable (or said with the standard metaphor, both a bird and a plane can fly, but rely on different mechanisms).	O	O	Reply	3
While some aspects of the neural response may be task irrelevant, it may be complementary to augment the KA-AUC approach with a similarity-based approach.	O	O	Reply	3
This could also be computed from the collected data and would help map levels within a computational model to visual brain areas.	O	O	Reply	3
In general a more extensive discussion of and contrast with the Kriegeskorte approach would be helpful.	O	O	Reply	3
<sep> <sep> This is a very good point.	B-Reply	B-2	Reply	3
We think matching neural and model representations at ever increasing levels of detail is an important pursuit.	I-Reply	I-2	Reply	3
Generally, we consider a sort of ‚Äúhierarchy of measures‚Äù of increasing specificity between neural responses and model responses.	I-Reply	I-2	Reply	3
The one we have proposed here is relatively abstract, and task dependent by intention.	I-Reply	I-2	Reply	3
The methods and approach of Kriegeskorte measures a, relatively, more constraining mapping between neural and model representations.	I-Reply	I-2	Reply	3
As the current manuscript is longer than the conference organizers had hoped, we will reserve a more extensive discussion of the Kriegeskorte approach for a longer journal version of the manuscript.	I-Reply	I-2	Reply	3
In ultimately choosing a measure, which level of abstraction one chooses to be satisfied with is largely dependent on one‚Äôs goals.	I-Reply	I-2	Reply	3

This paper applies the methodology for 'kernel analysis of deep networks' (Montavon et al, 2011) to the neural code measured on two areas (V4 and IT) on the visual cortex of the macaque.	O	O	Review	3
It compares, on the same test set, the biological responses of V4 or IT (spike counts measured at about 100 electrode sites) to the hidden unit activations on the penultimate layer of several state-of-the-art deep learning architectures trained on large image datasets: the 10 million YouTube images and deep sparse auto-encoder paper by Le et al (2012), a convolutional network by Krizhevsky et al (2012), two papers by Pinto et al, one on the V1 model, another on the high throughput L3 model class and the unsupervised learning paper by Coates et al (2012).	O	O	Review	3
<sep> <sep> The authors show that the IT area of the visual cortex seems to have a neural code that is more discriminative than the neural code of the V4 area for a 7-class image categorization task under variations of pose, position and scale.	O	O	Review	3
The authors also show that one supervised deep learning algorithm (Krizhevsky et al, 2012) even produces hidden layer representation that seems to outperform IT on that task.	O	O	Review	3
<sep> <sep> <sep> Pros, novelty and quality:	O	O	Review	3
<sep> This paper is the first to apply the same method for evaluating feature representations of both the biological neural code (measured on the visual cortex of a primate) and of hidden unit activations in state-of-the-art methods for image classification.	O	O	Review	3
It provides an extensive comparison of the penultimate hidden layer of several deep learning algorithms, vs. the V4 and IT areas of the visual cortex of two macaques.	O	O	Review	3
As such, it provides insight into which algorithms make a good hidden representation of images.	O	O	Review	3
<sep> <sep> The method for evaluating the feature representations is essentially non-parametric and provides a robust way to assess the complexity of the decision boundary.	O	O	Review	3
The kernel analysis method measures what percentage of the information coming from the sample images is required to successfully train a nonlinear Gaussian SVM-like classifier on the features (neural code or hidden unit activations), or a linear classifier in the dual space, for a simple image categorization task.	O	O	Review	3
The kernel PCA approach of keeping the top d eigenvectors of the kernel matrix in the dual solution is more robust than the cross-validation performance or than the number of support vectors, when the number of samples is small.	O	O	Review	3
<sep> <sep> The paper is well written, the claims are well supported by the experiments.	O	O	Review	3
The metric used in this study is robust and the main results (IT vs V4, Krizhevsky et al 2012 vs IT on high variations) are statistically significant.	O	O	Review	3
<sep> <sep> Cons:	O	O	Review	3
<sep> There are no cons per se in this paper, only limitations in the methodology (linked to the choice of the dataset) that could be improved upon by using a more extensive dataset.	O	O	Review	3
Most of these limitations have been preemptively mentioned and discussed by the authors in section 4.	O	O	Review	3
<sep> <sep> * The two macaque subjects in the study by Majaj et al (2012) are unlikely to have been exposed to images of 3 object categories in the dataset: cars, planes or other animals such as cows and elephants.	B-Review	B-1	Review	3
They may have been exposed to images from the 4 remaining object classes: faces, chairs, tables and fruits.	I-Review	I-1	Review	3
By consequence, their V4 or IT cortical areas might not be trained to recognize, even after prolonged exposure, that the image of a car at an angle is still a car with a variation, and not another type of objects.	I-Review	I-1	Review	3
The authors do raise the question whether the neural representation could be enhanced with increased exposure.	I-Review	I-1	Review	3
<sep> <sep> * The paper does mention that only about a hundred sites, on the cortex surface, are selected for the image categorization task, compared to all the tens of thousands of hidden units in the deep architecture.	B-Review	B-2	Review	3
Some further discussion on the fairness of such a comparison would be welcome.	I-Review	I-2	Review	3
<sep> <sep> Other comments:	O	O	Review	3
<sep> * The Gaussian kernel uses a single coefficient sigma for all the features (i.e., all the neurons / hidden units).	B-Review	B-3	Review	3
On one hand, the neural data are taken on the visual cortex areas V4 and IT, where all the electrode sites are expected to measure information that is relevant for image recognition tasks in general, and the deep learning architectures were all trained on image classification tasks.	I-Review	I-3	Review	3
On the other hand, not all the features (hidden units or electrode sites) are equally relevant, all the time, to all these tasks, but their values are all scaled nevertheless.	I-Review	I-3	Review	3
Would it make sense to tune the individual per-feature sigma coefficients in the Gaussian kernel, as in Chapelle et al (2002) 'Choosing multiple parameters for support vector machines'?	I-Review	I-3	Review	3
<sep> <sep> * Are all the 5 references by Pinto et al necessary for this paper?	B-Review	B-4	Review	3
<sep> <sep> Minor comments:	O	O	Review	3
<sep> * The authors do not indicate how the images from the dataset were split among the two monkeys (were they shown the same images, or two, different, random sets of images?)	B-Review	B-5	Review	3
and how the neural observations from the different electrode sites (58 IT and 70 V4 sites on one monkey, 110 IT and 58 V4 sites on the other monkey) were grouped.	I-Review	I-5	Review	3
My guess is that the same sets of images were shown to the two monkeys and that their responses were concatenated into IT or V4 matrices of site vs image.	I-Review	I-5	Review	3
<sep> <sep> * The authors do not need to mention the low computational complexity of the LSE loss (section 2.2).	B-Review	B-6	Review	3
It is not more complex than the logistic loss and the real point is what they say about intra-class variance and inter-class variance.	I-Review	I-6	Review	3
<sep> <sep> * I do not fully understand the protocol in section 2.3, namely: 'we evaluate 10 pre-defined subsets of images, each taking 80% of the data from each variation level'.	B-Review	B-7	Review	3
<sep> <sep> * Is total dimensionality D equal to the number of samples n?	B-Review	B-8	Review	3
Thank you for your review and feedback.	O	O	Reply	3
Here are some specific replies. (	O	O	Reply	3
>-mark indicates quote from review)	O	O	Reply	3
<sep> > * The two macaque subjects in the study by Majaj et al (2012) are unlikely to have been exposed to images of 3 object categories in the dataset: cars, planes or other animals such as cows and elephants.	O	O	Reply	3
They may have been exposed to images from the 4 remaining object classes: faces, chairs, tables and fruits.	O	O	Reply	3
By consequence, their V4 or IT cortical areas might not be trained to recognize, even after prolonged exposure, that the image of a car at an angle is still a car with a variation, and not another type of objects.	O	O	Reply	3
The authors do raise the question whether the neural representation could be enhanced with increased exposure.	O	O	Reply	3
<sep> <sep> Some additional information, not included in the paper:	B-Reply	B-1	Reply	3
<tab>* Our data suggest that during the passive viewing paradigm there is no change in classifier performance trained on the early part of the recording vs. a later part of the recording.	I-Reply	I-1	Reply	3
So we see no exposure dependent classifier improvement through time.	I-Reply	I-1	Reply	3
<tab>* When examining per-category classifier performance, there is no obvious pattern between the two sets of categories you point out (cars/planes/animals vs. faces/chairs/tables/fruits).	B-Reply	B-1	Reply	3
<sep> <tab>* The absolute performance of classifiers trained for Cars, or Planes or Animals does not seem to be significantly different from classifiers trained on the other categories.	B-Reply	B-1	Reply	3
<sep> It remains an interesting question how the neural representational performance would change through training the animal to make the desired categorizations.	B-Reply	B-1	Reply	3
<sep> <sep> > * The paper does mention that only about a hundred sites, on the cortex surface, are selected for the image categorization task, compared to all the tens of thousands of hidden units in the deep architecture.	O	O	Reply	3
Some further discussion on the fairness of such a comparison would be welcome.	O	O	Reply	3
<sep> <sep> One important point is that the measure we have chosen, by measuring accuracy against complexity, allows us to compare representations of different dimensionality.	B-Reply	B-2	Reply	3
How a representation is affected by subsampling depends on the properties of that representation, and it appears that the neural representation is quite robust to such subsampling.	I-Reply	I-2	Reply	3
For example, we have attempted to estimate the convergence of our measure as we increase the number of recording sites, from within our sample.	I-Reply	I-2	Reply	3
It has been somewhat surprising to us that this curve appears to asymptote so quickly, but of course this may be due to a sampling bias in the procedure.	I-Reply	I-2	Reply	3
<sep> <sep> There are a number of factors that may bias the neural results related to sampling such a small number of sites from the cortex.	B-Reply	B-2	Reply	3
Here is a short discussion of some of these factors:	I-Reply	I-2	Reply	3
<tab>* Neurons that are close together in cortical space are typically correlated.	I-Reply	I-2	Reply	3
This indicates that the number of relevant dimensions is far less than the total number of neurons in cortex.	I-Reply	I-2	Reply	3
This is in-line with the fast convergence we observe of our measurement with increasing the number of sites.	I-Reply	I-2	Reply	3
<sep> <tab>* The placement of the grids, and the spacing between electrodes in the grid may affect our measurement.	B-Reply	B-2	Reply	3
<sep> <tab>* We examine multi-unit activity, instead of individual neurons.	B-Reply	B-2	Reply	3
At the least this indicates that we are recording from more neurons than the number of sites.	I-Reply	I-2	Reply	3
We estimate that the number of total neurons we are recording from is about 5x times the number of multi-units (estimated using the spike count ratio between multi-units and single-units collected in V4 and IT in our lab).	I-Reply	I-2	Reply	3
It is not clear how single units would change our result, if at all.	I-Reply	I-2	Reply	3
<sep> <tab>* A point that may not be obvious is that an inherit property of electrophysiology is that we are ‚Äúblind‚Äù to the neurons that do not fire during our experimental procedure.	B-Reply	B-2	Reply	3
Therefore, we may be introducing a bias by recording from only active neurons and ‚Äúdiscarding‚Äù neurons that are not active.	I-Reply	I-2	Reply	3
This would also introduce an underestimate to the number of potential neurons we are effectively recording.	I-Reply	I-2	Reply	3
Note that including such silent neurons would not affect our kernel analysis measure, just the estimate of the total number of neurons we recorded.	I-Reply	I-2	Reply	3
<sep> <tab>* We have a hardware limitation that limits us to recording 128 sites at a time.	B-Reply	B-2	Reply	3
For a given animal, we chose the top-128 best visually driven sites.	I-Reply	I-2	Reply	3
‚ÄúVisual drivenness‚Äù was measured with a separate pilot image set (see Rust and DiCarlo 2012 and Chou et al).	I-Reply	I-2	Reply	3
Roughly this measure is the mean across the top 10% of absolute per-image d-primes between an image and blank.	I-Reply	I-2	Reply	3
The top 10% is cross-validated and the absolute value is necessary to account for inhibitory sites.	I-Reply	I-2	Reply	3
This sampling bias may affect our measure by discarding neural activity not relevant for the task, thus increasing or KA-AUC estimate of the neural representation.	I-Reply	I-2	Reply	3
<sep> <sep> One final point, at this technological point in time, we are only able to record from 128 multi-unit sites simultaneously.	B-Reply	B-2	Reply	3
We achieve the total number of sites through multiple recording sessions and multiple animals.	I-Reply	I-2	Reply	3
Given these limitations, this dataset is cutting-edge in terms of the number of sites, the number of images presented, and the number of repetitions of each image, especially for IT cortex recordings.	I-Reply	I-2	Reply	3
<sep> <sep> > The Gaussian kernel uses a single coefficient sigma for all the features (i.e., all the neurons / hidden units).	O	O	Reply	3
On one hand, the neural data are taken on the visual cortex areas V4 and IT, where all the electrode sites are expected to measure information that is relevant for image recognition tasks in general, and the deep learning architectures were all trained on image classification tasks.	O	O	Reply	3
On the other hand, not all the features (hidden units or electrode sites) are equally relevant, all the time, to all these tasks, but their values are all scaled nevertheless.	O	O	Reply	3
Would it make sense to tune the individual per-feature sigma coefficients in the Gaussian kernel, as in Chapelle et al (2002) 'Choosing multiple parameters for support vector machines'?	O	O	Reply	3
<sep> <sep> Under our proposed methodology, modifying the representation, even by rescaling dimensions, during test time is not allowed.	B-Reply	B-3	Reply	3
It would be reasonable to take a representation, apply the method in Chapelle et al (2002) on the training set, and thus create a new representation to be used during testing.	I-Reply	I-3	Reply	3
This sounds like a good idea, and we are interested to see what else the community comes up with!	I-Reply	I-3	Reply	3
<sep> <sep> > Are all the 5 references by Pinto et al necessary for this paper?	O	O	Reply	3
<sep> <sep> Most are, but we will remove the Cosyne 2010 abstract and the FG 2011 paper in the next revision, as these points are covered by the remaining references.	B-Reply	B-4	Reply	3
<sep> <sep> > The authors do not indicate how the images from the dataset were split among the two monkeys (were they shown the same images, or two, different, random sets of images?)	O	O	Reply	3
and how the neural observations from the different electrode sites (58 IT and 70 V4 sites on one monkey, 110 IT and 58 V4 sites on the other monkey) were grouped.	O	O	Reply	3
My guess is that the same sets of images were shown to the two monkeys and that their responses were concatenated into IT or V4 matrices of site vs image.	O	O	Reply	3
<sep> You are correct.	B-Reply	B-5	Reply	3
The same sets of images (all of them) were shown to each of the monkeys.	I-Reply	I-5	Reply	3
The sites from each monkey IT cortex were concatenated, as were the sites from each monkey V4 cortex.	I-Reply	I-5	Reply	3
We will update the text to clarify.	I-Reply	I-5	Reply	3
<sep> <sep> > The authors do not need to mention the low computational complexity of the LSE loss (section 2.2).	O	O	Reply	3
It is not more complex than the logistic loss and the real point is what they say about intra-class variance and inter-class variance.	O	O	Reply	3
<sep> Thanks for the feedback, we will update the text.	B-Reply	B-6	Reply	3
<sep> <sep> > I do not fully understand the protocol in section 2.3, namely: 'we evaluate 10 pre-defined subsets of images, each taking 80% of the data from each variation level'.	O	O	Reply	3
<sep> We have updated the text to clarify.:	B-Reply	B-7	Reply	3
<sep> For each variation level, we compute the kernel analysis curve and KA-AUC ten times, each time sampling 80% of the images with replacement.	I-Reply	I-7	Reply	3
The ten samples for each variation level are fixed for all representations.	I-Reply	I-7	Reply	3
<sep> <sep> > Is total dimensionality D equal to the number of samples n?	O	O	Reply	3
<sep> <sep> Yes.	B-Reply	B-8	Reply	3
We indicate this now in the text.	I-Reply	I-8	Reply	3
<sep> <sep> Will update arXiv posting shortly.	I-Reply	I-8	Reply	3

The paper presents a benchmark for comparing representations of image data in brains and machines.	O	O	Review	3
The benchmark consists of looking at how the image categorization task is encoded in the leading kernel principal components of the representation, thus leading to an analysis of complexity and noise.	O	O	Review	3
The paper contains extensive experiments based on a representive set of state-of-the-art learning algorithms on the machine learning side, and real recordings of macaques brain activity on the neural side.	O	O	Review	3
<sep> <sep> The research presented in this paper is well-conducted, timely and highly innovative.	O	O	Review	3
It is to my knowledge the first time, that representations obtained with state-of-the-art machine learning techniques for vision are systematically compared with real neural representations.	O	O	Review	3
The authors motivate the use of kernel analysis, by the inbuilt robustness to sample size being desirable in this heterogeneous setting.	O	O	Review	3
<sep> <sep> The dataset used in the paper is composed of objects that are superposed to an independent background.	B-Review	B-1	Review	3
While authors motivate their choice by controlling the factors of variations in the representation, it would be interesting to know whether machine learning or brain representations benefit most from this particular setting.	I-Review	I-1	Review	3
<sep> <sep> This paper also raises the important question of what is the best way of comparing representations.	B-Review	B-2	Review	3
One can wonder, for example, whether the reduced set of kernels considered here (Gaussian kernels with multiple scales) introduces some bias in favor of 'Gaussian-friendly' representations.	I-Review	I-2	Review	3
Also, as suggested by the authors, it could be that the way neural recordings are represented leads to underestimating their discriminative ability.	I-Review	I-2	Review	3
Thank you for your review and feedback.	O	O	Reply	3
Here are some comments on your suggestions:	O	O	Reply	3
<sep> > The dataset used in the paper is composed of objects that are superposed to an independent background.	O	O	Reply	3
While authors motivate their choice by controlling the factors of variations in the representation, it would be interesting to know whether machine learning or brain representations benefit most from this particular setting.	O	O	Reply	3
<sep> <sep> As you point out, we inevitably have to make trade-offs when designing our experiments.	B-Reply	B-1	Reply	3
Your feedback on removing this controlled variation as an interesting question helps us to design future datasets for experiments.	I-Reply	I-1	Reply	3
<sep> <sep> > This paper also raises the important question of what is the best way of comparing representations.	O	O	Reply	3
One can wonder, for example, whether the reduced set of kernels considered here (Gaussian kernels with multiple scales) introduces some bias in favor of 'Gaussian-friendly' representations.	O	O	Reply	3
<sep> <sep> We agree that exploring the effect of the kernel choice is an interesting direction.	B-Reply	B-2	Reply	3
We hope to include this in future work (possibly a longer journal version).	I-Reply	I-2	Reply	3

This paper proposes to use reinforcement learning for constructing discretziation stencils of numerical schemes.	O	O	Review	300
More specifically, the method focuses on the widely used WENO schemes, which are an established class of finite difference schemes.	O	O	Review	300
Within this context, the method aims for training models to infer the weighting for a specific stencil with eight flux terms.	O	O	Review	300
<sep> <sep> For RL this task requires a continuous action space, and the DDPG algorithm is used for training the policy.	O	O	Review	300
The network itself is an MLP with 6 layers, and ca.	O	O	Review	300
20000 weights in total.	O	O	Review	300
This is a significant number, given the focus on 1D problems.	O	O	Review	300
<sep> <sep> The tests are quite thorough and interesting, while at the same time being limited in scope.	B-Review	B-1	Review	300
The paper targets 1D cases, which make the problem very low-dimensional.	I-Review	I-1	Review	300
Despite the simplicity, only a single data set (Burgers) is used, and a single modified target function with a u^4 term.	I-Review	I-1	Review	300
Targeting 1D casesl, I would have expected a broader range of tests and model equations.	I-Review	I-1	Review	300
<sep> <sep> Despite the limited scope of the models, table 1 and 2 assess a nice range of different timestep and discretization parameters.	B-Review	B-6	Review	300
I found it very interesting to see that the method consistently outperforms the regular WENO scheme.	I-Review	I-6	Review	300
The gains are relatively small, with 4-5%, but WENO already represents a quite accurate scheme, so it's surely not easy to outperform it.	I-Review	I-6	Review	300
<sep> <sep> While reading the paper, I was wondering about the bigger picture, i.e. using RL in the context of discretization stencils.	B-Review	B-2	Review	300
We have model equations, and discretized versions of all operators involved in training.	I-Review	I-2	Review	300
Why employ a "brute force" approach like RL here?	I-Review	I-2	Review	300
Wouldn't it be better in terms of efficiency and potentially also accuracy to train the stencils in a supervised manner, e.g., with a more accurate discretization as reference?	I-Review	I-2	Review	300
One could argue that it would be expensive to pre-compute such data, but I think RL scales even worse to higher dimensional problems.	I-Review	I-2	Review	300
<sep> <sep> What's also missing in the current version is a more thorough discussion of inference and training performance.	B-Review	B-3	Review	300
I guess that despite the small model problems, the training takes a substantial amount of time.	I-Review	I-3	Review	300
And due to the large size of the trained model, which has to be evaluated for every single node in the 1D mesh, it's probably also quite slow.	I-Review	I-3	Review	300
I think this is worth a discussion in the text.	I-Review	I-3	Review	300
One could even estimate the number of operations necessary to evaluate the model, and run a higher-order WENO scheme for a "fair" comparison.	I-Review	I-3	Review	300
<sep> <sep> Minor, but in equation (1), I guess the t subscript should indicate a material derivative, and just just a time derivative, right?	B-Review	B-4	Review	300
This could be clarified in the text (or written out).	I-Review	I-4	Review	300
<sep> <sep> I am somewhat on the edge with this paper - the 1D case for the two equations is carefully evaluated in the submission, and it's great to see the trained model can improve the accuracy across a fairly wide range of settings.	B-Review	B-7	Review	300
As such, it's definitely a good and interesting first step.	I-Review	I-7	Review	300
On the other hand, there are a range of open questions, as outlined above, and it's not clear whether the approach could be easily translated to higher dimensions.	I-Review	I-7	Review	300
I hope the authors can clarify some of these points in the rebuttal, right now I'm leaning towards the positive side.	I-Review	I-7	Review	300
<sep> <sep> Thanks the reviewer for the useful feedbacks!	O	O	Reply	300
Below are our responses.	O	O	Reply	300
<sep> <sep> -- manuscirpt update	O	O	Reply	300
We have updated the manuscript for the following 3 parts, where all the updates are in the "Complementary Experiments" section (section A) in the Appendix.	B-Reply	B-5	Reply	300
1) We added experiments on comparing our RL-based method and a SL-based method, in appendix A.1.	I-Reply	I-5	Reply	300
2) We add more figures analyzing the performance of our RL policy on smooth regions and near singularities of the PDE solutions in appendix A.2.	I-Reply	I-5	Reply	300
3) We report and compare the inference time of our RL policy and WENO in appendix A.3.	I-Reply	I-5	Reply	300
Currently we put these contents in appendix, but if the paper gets accepted, we would then incorporate them into the main body in the final version.	I-Reply	I-5	Reply	300
<sep> <sep> <sep> -- "Why employ a "brute force" approach like RL here?	O	O	Reply	300
Wouldn't it be better to train the stencils in a supervised manner, e.g., with a more accurate discretization as reference?	O	O	Reply	300
One could argue that it would be expensive to pre-compute such data, but I think RL scales even worse to higher dimensional problems"	O	O	Reply	300
As already explained in our paper (bullet discussions in section 1.2), the main motivation of using RL is that the problem is naturally a sequential decision making problem.	B-Reply	B-2	Reply	300
Thus, it can naturally be formulated into a MDP and solved by RL.	I-Reply	I-2	Reply	300
The main benefit of using RL is that it enforces long term accuracy on the learned policy, making it non-greedy.	I-Reply	I-2	Reply	300
Since this is a rather important question from the reviewers, we have added more experiments and discussions in the appendix (section A.1) of the revised manuscript.	I-Reply	I-2	Reply	300
Please let us know if you have further questions.	I-Reply	I-2	Reply	300
<sep> <sep> As for the reviewer's concern that the approach might not be easily translated to the high-dimensional problems, there is actually a simple design for doing so.	I-Reply	I-2	Reply	300
We can simply use the splitting method for high-dimensional problems, which is essentially applying the trained RL policy alternatively on the one-dimensional problem in each spatial direction.	I-Reply	I-2	Reply	300
<sep> <sep> <sep> -- "What's also missing in the current version is a more thorough discussion of inference and training performance."	O	O	Reply	300
<sep> The training time for the RL policy reported in our paper is roughly one and half a day, using a single custom GTX 1080 GPU.	B-Reply	B-3	Reply	300
For the inference time, it is true that the computation operations in the trained NN model is much more than that of WENO, but we could parallel and accelerate the computations using GPU, and the real computation time always depends on the implementation.	I-Reply	I-3	Reply	300
<sep> We compared four methods: RL-WENO on CPU, RL-WENO on GPU, a well-optimzied WENO (e.g., with good numpy vectorization in python), a poor-implemented WENO (e.g. use lots of loops), and detailed results are reported in table 5 at appendix A.3.	I-Reply	I-3	Reply	300
The conclusion is: as the grid becomes more dense, all methods except the RL-WENO GPU requires more time to finish the computation.	I-Reply	I-3	Reply	300
The reason that the time cost of the GPU-version of RL-WENO does not grow up is that on GPU, we can compute all approximations in the next step ) together in parallel, so the increase of grid numbers does not affect the computation time at all.	I-Reply	I-3	Reply	300
So for coarse grid, well-optimized WENO indeed has clear advantage over RL-WENO (even on GPU), but with a more dense grid, RL-WENO could finish the computation even faster than well-optimzied WENO by leveraging the power of paralleling.	I-Reply	I-3	Reply	300

In this paper, the author maps the problem of time series PDE into a naive reinforcement learning problem.	B-Review	B-1	Review	300
Under the MDP assumption, the author sets the initial state of the particles as the current state, the flux at all spaces as the possible actions, and map the state-action pair deterministically to the next state of the particle diffusion.	I-Review	I-1	Review	300
The reward is defined as the two norms between the prediction and the Burger‚Äôs equation.	I-Review	I-1	Review	300
The naiveness comes from the fact that the typical reinforcement learning problem, the agent needs to decide how to choose an action.	I-Review	I-1	Review	300
In this paper, it is formulated as an intrinsic proper that follows Burger‚Äôs equation instead.	I-Review	I-1	Review	300
<sep> <sep> While the motivation is interesting, the author argues this work is novel due to it does not fall under supervised learning, but rather reinforcement learning.	B-Review	B-2	Review	300
This perspective is not completely correct.	I-Review	I-2	Review	300
The correct category for this work would be more similar to imitation learning using WANO‚Äôs algorithm as the expert label.	I-Review	I-2	Review	300
This is a field of supervised reinforcement learning.	I-Review	I-2	Review	300
<sep> <sep> The author‚Äôs work has brought the possibility of using neural network architecture in the field of particle diffusion.	O	O	Review	300
The benefit is the improved estimation of how particles diffuse in long-horizon conditions.	O	O	Review	300
The author has shown in their paper their simple fully connected network has already performed better prediction than the current state of the art non-neural network model: WENO.	O	O	Review	300
<sep> <sep> While the framing of the problem is perhaps novel in the space of PDE, algorithmically there needs to have a breakthrough or new invention.	B-Review	B-1	Review	300
The lack of comparison with other neural-network-based models also hurts the credibility of the model.	B-Review	B-3	Review	300
Therefore, I reject this paper under the ICLR conference.	O	O	Review	300
I would suggest that this paper would be better suited as a paper submission under the perspective science field conference instead.	O	O	Review	300
<sep> <sep> Some suggestions to further improve this paper: The author could add CNN and RNN structure to the prediction model.	B-Review	B-4	Review	300
These structures would further expand other possibilities in the solution space.	I-Review	I-4	Review	300
CNN would help turn the limited 1D problem to a higher-dimensional, a more real-world like problem space.	I-Review	I-4	Review	300
RNN is known for its‚Äô ability to model long horizon problems, perhaps even better breakthrough would happen with these architectures.	I-Review	I-4	Review	300
<sep> <sep> As a whole, the paper is written very well such that even nonexpert can grab onto the logic flow of this paper.	O	O	Review	300
The weaknesses of the paper are the lack of diversity in comparison with other models and the paper needs some level of novel breakthrough in an algorithmic sense.	B-Review	B-5	Review	300
<sep> <sep> We thank the reviewer for the constructive feedbacks.	O	O	Reply	300
We answer the reviewer's major concerns as below.	O	O	Reply	300
<sep> <sep> -- manuscirpt update	O	O	Reply	300
We have updated the manuscript for the following 3 parts, where all the updates are in the "Complementary Experiments" section (section A) in the Appendix.	B-Reply	B-6	Reply	300
1) We added experiments on comparing our RL-based method and a SL-based method, in appendix A.1.	I-Reply	I-6	Reply	300
2) We add more figures analyzing the performance of our RL policy on smooth regions and near singularities of the PDE solutions in appendix A.2.	I-Reply	I-6	Reply	300
3) We report and compare the inference time of our RL policy and WENO in appendix A.3.	I-Reply	I-6	Reply	300
Currently we put these contents in appendix, but if the paper gets accepted, we would then incorporate them into the main body in the final version.	I-Reply	I-6	Reply	300
<sep> <sep> <sep> -- "the mapping of the problem of time series PDE to a reinforcement learning problem is naive; algorithmically there needs to have a breakthrough or new invention"	O	O	Reply	300
The reviewer mentioned that our casting of the problem of solving a evolutionary PDE to a RL problem is naive due to our design of the agent's action.	B-Reply	B-1	Reply	300
We want to clarify that there are actually a lot of subtleties in such seemingly easy mapping, which we could not explain in detail in the paper due to the page limit.	I-Reply	I-1	Reply	300
For example, there are numerous different designs for the agent's action: we could have designed it to be a spatial discretization, a temporal discretization, or the flux.	I-Reply	I-1	Reply	300
We had initial experiments with such designs, but the main problem is that they either do not obey the conservation property of the equation (when you directly learn a spatial or temporal discretization), or they generalize poorly (when you directly learn the fluxes).	I-Reply	I-1	Reply	300
After countless trial and error by ourselves, we found that the current setting works the best and indeed improves over WENO near singularities.	I-Reply	I-1	Reply	300
<sep> <sep> The reviewer also mentioned that our methods lack an algorithmeically invention.	B-Reply	B-1	Reply	300
We admit that we were just using standard RL algorithm for training.	I-Reply	I-1	Reply	300
However, part of our innovation comes from the formulation of the problem to a proper MDP.	I-Reply	I-1	Reply	300
One of them is explained in the last bullet of section 3.1 in the paper, and we rephrase here: ``since the next state depends on not a single but several actions at the current step, the formulated MDP is essentially a multi-agent RL problem.	I-Reply	I-1	Reply	300
However, it is impractical to train a number of individual agents that is equal to the grid number, so we share the weight among the agents, and the problem can be addressed under a single agent view".	I-Reply	I-1	Reply	300
This design further leads to another invention of our formulation: with a single shared RL policy operating on the current 1-D line of grid points sequentially from "left" to "right" (i.e., operates on, then, till ), we are essentially applying a special convolution to the current line of grid points to generate the stencil, where the kernel is the non-linear MLP RL policy.	I-Reply	I-1	Reply	300
We will update these discussions in the paper if accepted.	I-Reply	I-1	Reply	300
<sep> <sep> <sep> -- "the method is using weno as label.	O	O	Reply	300
the method is actually supervised reinforcement learning"	O	O	Reply	300
The reviewer mentioned that we are doing "supervised reinforcement learning", or imitation learning using WENO as the label.	B-Reply	B-2	Reply	300
We want to clarify that we are not imitating WENO.	I-Reply	I-2	Reply	300
Instead of learning towards WENO's output, we are minimizing the error between the RL generated solution and the true solution which is obtained from WENO scheme on a much denser grid.	I-Reply	I-2	Reply	300
One could use any other algorithm than WENO to generate the true solution.	I-Reply	I-2	Reply	300
Besides, figure 2 in our paper demonstrates that our RL policy has learned to generate very different stencils from WENO, which further proves the learned RL policy is not just imitating WENO.	I-Reply	I-2	Reply	300
It attempts to surpass WENO by learning from the true solution.	I-Reply	I-2	Reply	300
<sep> <sep> <sep> --"the lack of comparison with other neural-network-based models also hurts the credibility of the model."	O	O	Reply	300
<sep> We have added more discussions on using other NN-based methods to learn the stencil, and also experiments of using a SL-based (actually, BP-based) method to train a NN to choose the stencil, in appendix A.1 of the revised manuscript.	B-Reply	B-3	Reply	300
We found our RL trained NN consistently outperforms the SL trained NN, which verifies RL's advantage on guaranteeing long-term accuracy and generalization ability.	I-Reply	I-3	Reply	300
<sep> <sep> <sep> --"using CNN and RNN as the policy network."	O	O	Reply	300
<sep> We thank the reviewer's suggestion of using CNN and RNN for our RL policy.	B-Reply	B-4	Reply	300
We agree that they have stronger representation power and will consider using them in future works.	I-Reply	I-4	Reply	300

<sep> ##### Rebuttal Response:	O	O	Review	300
The other reviewers seem to have understood more than me.	O	O	Review	300
Their opinion and the rebuttal did not convince me to update my score.	B-Review	B-3	Review	300
In my opinion the writing must be adapted to be interesting to the ICLR community and the bigger picture should be highlighted more, as the bigger picture is remains quite unclear at the current state.	I-Review	I-3	Review	300
<sep> <sep> <sep> ##### Review:	O	O	Review	300
Summary:	O	O	Review	300
[...]	O	O	Review	300
<sep> <sep> Conclusion:	O	O	Review	300
I have read the paper multiple times and I still have a problem summarizing the paper with my own words.	O	O	Review	300
The contributions summarize the most fundamental works of RL but do not really relate these methods to the proposed approach.	B-Review	B-1	Review	300
Therefore, I am still uncertain about the general motivation and intention of the work as well as the evaluation.	I-Review	I-1	Review	300
Currently I vote for borderline reject as I am familiar with RL &amp; PDE'S but do not understand the motivation and intention.	I-Review	I-1	Review	300
I am leaning towards rejection as the paper is a resubmission from Neurips and has not been substantially improved.	I-Review	I-1	Review	300
However, I am not certain about my evaluation.	I-Review	I-1	Review	300
I am happy to adapt my vote based on the other reviewers and a clarified and better structured paper, which can be submitted during the rebuttal.	O	O	Review	300
Thanks the reviewer for your feedbacks.	O	O	Reply	300
<sep> <sep> We have updated the manuscript for the following 3 parts, where all the updates are in the "Complementary Experiments" section (section A) in the Appendix.	B-Reply	B-2	Reply	300
1) We added experiments on comparing our RL-based method and a SL-based method, in appendix A.1.	I-Reply	I-2	Reply	300
2) We add more figures analyzing the performance of our RL policy on smooth regions and near singularities of the PDE solutions in appendix A.2.	I-Reply	I-2	Reply	300
3) We report and compare the inference time of our RL policy and WENO in appendix A.3.	I-Reply	I-2	Reply	300
Currently we put these contents in appendix, but if the paper gets accepted, we would then incorporate them into the main body in the final version.	I-Reply	I-2	Reply	300

This paper presents STOVE, an object-centric structured model for predicting the dynamics of interacting objects.	O	O	Review	20148
It extends SuPAIR, a probabilistic deep model based on Sum-Product Networks, towards modeling multi-object interactions in video sequences.	O	O	Review	20148
Compared to prior work, the model uses graph neural networks for learning the transition dynamics and reuses the dynamics model for the state-space inference model, further regularising the learning process.	O	O	Review	20148
The approach has been tested on simple multi-body physics tasks and performs well compared to other unsupervised and supervised baselines.	O	O	Review	20148
Additionally, an action-conditional version of STOVE was tested on a visual MPC task (using MCTS for planning) and was shown to learn significantly faster compared to model-free baselines.	O	O	Review	20148
<sep> <sep> The paper is well written and clearly motivated but comes across as an incremental improvement on top of prior work.	O	O	Review	20148
Here are a few comments:	O	O	Review	20148
1.	O	O	Review	20148
The idea of reusing the dynamics model for inference is neat as it helps to regularise the learning process and remove the costly double recurrence, potentially speeding up learning.	B-Review	B-1	Review	20148
It would be great if this could be evaluated experimentally via an ablation study ‚Äî this can be done by using two separate instances of the transition model with separate weights.	I-Review	I-1	Review	20148
<sep> 2.	O	O	Review	20148
A keys step that allows to reconcile the transition model and the object detection network is the matching process.	B-Review	B-2	Review	20148
Currently, this is done via choosing the pair with the least position and velocity difference between subsequent time steps.	I-Review	I-2	Review	20148
This could give erroneous results in the case of object interactions when objects are fairly close to each other (or colliding).	I-Review	I-2	Review	20148
A potentially better way could be to additionally use the content/latent codes for this matching process ‚Äî as long as the object‚Äôs appearance stays similar these can provide good signal that disambiguates different objects.	I-Review	I-2	Review	20148
<sep> 3.	B-Review	B-3	Review	20148
The experiments presented in the paper are quite simplistic visually ‚Äî it is not clear if this approach can generalise to more complicated visual settings.	I-Review	I-3	Review	20148
Additionally, it would be good to see further comparisons and ablations that quantifies the effect of the different components ‚Äî e.g. comparing to a combination of image model + black-box MLP dynamics model can quantify the effect of the graph neural network.	I-Review	I-3	Review	20148
These results can add further strength to the paper.	I-Review	I-3	Review	20148
<sep> <sep> Overall, the approach presented in the paper is a bit incremental and the experiments are somewhat simplistic.	B-Review	B-4	Review	20148
Further comparisons and ablation experiments can significantly<tab>strengthen the paper.	I-Review	I-4	Review	20148
I would suggest a borderline accept.	O	O	Review	20148
Dear Reviewer 2,	O	O	Reply	20148
<sep> thank you for your valuable feedback.	O	O	Reply	20148
<sep> Below, we give a detailed response to your questions and comments.	O	O	Reply	20148
<sep> Please also see the changes to the manuscript outlined in our top level comment.	O	O	Reply	20148
<sep> <sep> [Ablations]	O	O	Reply	20148
We have added results for three different ablations of STOVE, including the suggested one in which two separate dynamics nets are used for generation and inference, demonstrating the value of reusing the dynamics net.	B-Reply	B-1	Reply	20148
Please see (3) in our general comment and Table 1 in the manuscript.	I-Reply	I-1	Reply	20148
We have chosen not to explore black-box MLPs as dynamics models, as the benefits of graph neural networks for multi-object dynamics tasks are well documented in the literature, see e.g. Battaglia et al (2016) and Watters et al (2017).	I-Reply	I-1	Reply	20148
We therefore do not believe this to be a crucial baseline.	I-Reply	I-1	Reply	20148
<sep> <sep> [Appearance-Based Matching]	O	O	Reply	20148
We agree, and have tried matching procedures which involve object appearance encodings.	B-Reply	B-2	Reply	20148
However, one of the main features of SuPAIR in contrast to AIR is that it does not necessitate a latent encoding of the object appearance.	I-Reply	I-2	Reply	20148
This means that an encoder network would have to be 'tacked on' to the model in order to allow for appearance based matching, as mentioned in Section 2.4.	I-Reply	I-2	Reply	20148
We did not find this necessary, since for the settings we considered, STOVE precisely inferred object centers with a mean error of less than 1/3 of a pixel, which suffices even during collisions or in scenarios with partial overlap.	I-Reply	I-2	Reply	20148
We therefore leave the exploration of appearance-based matching to future work.	I-Reply	I-2	Reply	20148
<sep> <sep> [Visual Complexity]	O	O	Reply	20148
The visual complexity of scenes and robustness of SuPAIR with respect to visual noise has been explored by Stelzner et al.	B-Reply	B-3	Reply	20148
We expect that these results translate to STOVE, i.e., that STOVE is able to handle background noise better than AIR (and, by extension, DDPAE and SQAIR).	I-Reply	I-3	Reply	20148
Figure 5 in the appendix shows that we are able to model scenes of differently shaped object sprites.	I-Reply	I-3	Reply	20148
However, we did not focus on this in this paper, as its main contributions are the techniques presented to combine image and dynamics models, as opposed to the performance of the specific image model used.	I-Reply	I-3	Reply	20148
Due to the compositional nature of STOVE, more sophisticated image models may easily be plugged in in place of SuPAIR.	I-Reply	I-3	Reply	20148
Finally, we note that the complexity of the experiments is in line with previous work (DDPAE, R-NEM).	I-Reply	I-3	Reply	20148
We choose to extend them by exploring the RL domain, which brings additional challenges, such as dynamics depending on object identities and actions.	I-Reply	I-3	Reply	20148
<sep> <sep> [Meaningful Improvement]	O	O	Reply	20148
Please see (1) of our top level comment, as we believe the energy conservation plot clearly demonstrates the stark performance improvements achieved with STOVE over prior work.	B-Reply	B-4	Reply	20148
While previous approaches break down after less than 100 frames of rollout, STOVE predicts trajectories with constant mean energy trajectories for 100,000 frames or more.	I-Reply	I-4	Reply	20148
Additionally, DDPAE and SQAIR predict overlapping, stopping, or teleporting objects after a short period.	I-Reply	I-4	Reply	20148
Apart from the added conservation plot, this is also apparent from the animated GIFs in our anonymized GitHub [1].	I-Reply	I-4	Reply	20148
<sep> [1] <a href="https://github.com/ICLR20/STOVE" target="_blank" rel="nofollow">https://github.com/ICLR20/STOVE</a>	O	O	Reply	20148

In this paper the authors present a graph neural network for modeling the dynamics of objects in simple environments from video.	O	O	Review	20148
The intuition of the presented system is that it first identifies the different objects from the image using Sum-Product Attend-Infer-Repeat (SuPAIR), which gives the objects positions and sizes.	O	O	Review	20148
The system uses a ‚Äúsimple matching procedure‚Äù to map objects between frames, which allows for the system to extra the object‚Äôs velocities.	O	O	Review	20148
Then a graph neural network is employed to model the dynamics of the particular environment (whether objects bounce, whether there are other forces at play like gravity, etc.).	O	O	Review	20148
The authors present two environments (Billiards and Gravity) and two evaluations, one focused on predicting future states, and the second focused on using these predictions to play the game.	O	O	Review	20148
<sep> <sep> I think that this paper presents an interesting approach and I agree with the authors of the importance of developing approaches that allow AI to make good predictions of future environments.	O	O	Review	20148
However, I‚Äôm not convinced of many of the technical details in the paper.	O	O	Review	20148
<sep> <sep> I am not certain whether I would classify this work as unsupervised learning.	B-Review	B-1	Review	20148
While it‚Äôs certainly true that there are no labels in the raw video, the object-finding can be understood as a preprocessing step after which the data is in fact in a fairly standard supervised learning framework.	I-Review	I-1	Review	20148
The authors use the term ‚Äúself-supervised‚Äù in the first section, which I believe describes the work more clearly.	I-Review	I-1	Review	20148
<sep> <sep> The primary technical contributions of the work appear to be the graph network, the experiments, and their results.	B-Review	B-2	Review	20148
While I would have preferred more detail on the graph network in an appendix, it‚Äôs acceptable to instead have access to the code.	I-Review	I-2	Review	20148
However, the experiments seem set up primarily to evaluate the system as a whole.	I-Review	I-2	Review	20148
For example, the inclusion of a supervised learning version of the system where the object‚Äôs positions are given exactly sheds light on the quality of SuPAIR.	I-Review	I-2	Review	20148
However, SuPAIR is taken from prior work.	I-Review	I-2	Review	20148
I would have thought that an entirely different approach, like that used by Ha and Schmidhuber in their World Models paper would have been more appropriate as a comparison as it represents an alternate approach entirely.	B-Review	B-3	Review	20148
<sep> <sep> There is a repeated claim made in the paper that the system presents output that is ‚Äúconvincing‚Äù and ‚Äúrealistic‚Äù over hundreds of time steps.	B-Review	B-4	Review	20148
There is no clear definition given for what this means.	I-Review	I-4	Review	20148
Figure 1 only presents pixel and positional error for 80 frames, and the error appears to go pretty large (~15%) after only forty frames.	I-Review	I-4	Review	20148
The results presented in Figure 4 suggests a much larger timescale, but it‚Äôs unclear the quality of the output predictions from it.	I-Review	I-4	Review	20148
Some clarity on this or scaling back the claims would improve the paper.	I-Review	I-4	Review	20148
<sep> <sep> In terms of related work Guzdial and Riedl‚Äôs 2017 ‚ÄúGame Engine Learning from Gameplay Video‚Äù appear to use a very similar approach (but with OpenCV instead of SuPAIR and search instead of a graph network) as does Ersen and Sariel‚Äôs 2015 ‚ÄúLearning behaviors of and interactions among objects through spatio‚Äìtemporal reasoning‚Äù.	B-Review	B-5	Review	20148
These approaches also function over much more complex environments with variable numbers of objects.	B-Review	B-6	Review	20148
It would be helpful for the authors to continue adding some discussion of this and related papers.	I-Review	I-6	Review	20148
<sep> <sep> ---	O	O	Review	20148
<sep> Edit: In response to the author's changes I have increased my rating to a weak accept.	O	O	Review	20148
This is in large part due to Figure 4, which provides a great deal of additional support to the author's claims and clarity on the technical value of the results.	O	O	Review	20148
Dear Reviewer 3,	O	O	Reply	20148
<sep> thank you for your valuable feedback.	O	O	Reply	20148
<sep> Below, we give a detailed response to your questions and comments.	O	O	Reply	20148
<sep> <sep> [Realistic Rollouts]	O	O	Reply	20148
We have quantified the notion of realistic rollouts by adding a plot of the kinetic energy in the billiards ball system across prediction timesteps.	B-Reply	B-4	Reply	20148
This energy should be conserved, as collisions are fully elastic and energies thus remain constant in the training data.	I-Reply	I-4	Reply	20148
For STOVE, the mean energy remains constant even over extremely long timeframes (we checked up to 100,000 steps), whereas for the baselines, it quickly diverges (after less than 100 steps).	I-Reply	I-4	Reply	20148
While in chaotic systems like the billiards environment, model predictions will necessarily differ from the ground truth after a number of timesteps, it is a desirable property of STOVE to continue to exhibit physical behavior.	I-Reply	I-4	Reply	20148
In contrast, all baselines predict overlapping, stopping, or teleporting objects after a short period.	I-Reply	I-4	Reply	20148
This can be observed visually in our animated GIFs [1].	I-Reply	I-4	Reply	20148
<sep> [1] <a href="https://github.com/ICLR20/STOVE" target="_blank" rel="nofollow">https://github.com/ICLR20/STOVE</a>	O	O	Reply	20148
<sep> [Unsupervised Learning]	O	O	Reply	20148
We agree that 'self-supervised' is a good term for STOVE.	B-Reply	B-1	Reply	20148
However, we do not view the end-to-end learning approach of STOVE as equivalent to decomposing the task into two distinct steps, one for feature extraction and one for supervised prediction.	I-Reply	I-1	Reply	20148
Kosiorek et al (SQAIR) have shown that training dynamics and recognition models jointly can significantly improve object detection performance through the incorporation of a temporal consistency bias.	I-Reply	I-1	Reply	20148
We therefore believe that maintaining this coupling is a valuable feature of STOVE.	I-Reply	I-1	Reply	20148
In any case, the successive training of SuPAIR and dynamics model is more brittle and raises the need for additional auxiliary losses (as in Watters et al (2017)), such as a carefully tuned discounted rollout error.	I-Reply	I-1	Reply	20148
<sep> <sep> [Contribution]	O	O	Reply	20148
As requested, we have added detailed information on the graph neural network and other components of STOVE to the appendix.	B-Reply	B-2	Reply	20148
We disagree with the assessment that our paper's main contribution is the graph network architecture.	I-Reply	I-2	Reply	20148
The benefits of relational architectures for multi-object dynamics tasks have previously been demonstrated, e.g. by Battaglia et al (2016) and Watters et al (2017).	I-Reply	I-2	Reply	20148
What has not been done before is to employ them in a setting in which state information is entirely latent, and only raw video is available.	I-Reply	I-2	Reply	20148
Our main contributions are to show how to do this (structured latent space, reuse of the dynamics model, joint variational inference), and to demonstrate that this enables predictions of comparable quality to the supervised setting with observed states.	I-Reply	I-2	Reply	20148
This comparison does not merely evaluate SuPAIR, but rather the techniques we proposed for connecting image and dynamics models.	I-Reply	I-2	Reply	20148
<sep> <sep> [Ha &amp; Schmidhuber]	O	O	Reply	20148
We compare to VRNN, which belongs to the same class of model as the one Ha &amp; Schmidhuber propose.	B-Reply	B-3	Reply	20148
Both encode input images via a VAE, and model the dynamics of the latent state via an RNN.	I-Reply	I-3	Reply	20148
It has been repeatedly demonstrated in the literature that models with object-factorized state representations such as STOVE outperform models with unstructured states, and our results support this, too.	I-Reply	I-3	Reply	20148
See e.g. the papers on SQAIR (Kosiorek et al (2018)), and DDPAE (Hsieh et al (2018)).	I-Reply	I-3	Reply	20148
We therefore deem a comparison to VRNN as a representative of unstructured models sufficient.	I-Reply	I-3	Reply	20148
<sep> <sep> [Diverse Number of Objects]	O	O	Reply	20148
Even though we did not explore this in this paper, one of the main appeals of both GNNs and AIR-based models is the ability to handle a variable number of objects.	B-Reply	B-6	Reply	20148
This is enabled by the GNNs focus on pairwise interactions.	I-Reply	I-6	Reply	20148
STOVE can thus be easily extended to handle a variable number of objects.	I-Reply	I-6	Reply	20148
As an ad-hoc demonstration, we provide an animated rollout with 6 objects on our GitHub [1].	I-Reply	I-6	Reply	20148
<sep> [Game Engine Learning]	O	O	Reply	20148
Both Ersen &amp; Sariel and Guzdial &amp; Riedl share our motivation of learning the rules of games from video, we have therefore added the references.	B-Reply	B-5	Reply	20148
However, they explore a very different setting, since they assume access to a curated set of sprites to handle object detection, and use logical rules instead of continuous dynamics to model interactions.	I-Reply	I-5	Reply	20148
We find it misleading to credit these works with being able to handle more complex visual environments, as the a-priori knowledge of pixel-perfect object appearances trivializes the detection task.	I-Reply	I-5	Reply	20148
The goal of the field of representation learning, including AIR and all of its derivatives, is to extract meaningful, potentially discrete information from noisy and continuous input data without relying on domain specific knowledge.	I-Reply	I-5	Reply	20148
While hand-engineered approaches to object detection would certainly work on the domains we considered here, the techniques we present in this paper generalize to different image models and different environments.	I-Reply	I-5	Reply	20148
It is our hope that models like ours will make it possible to apply logical reasoning to domains where it was previously impossible, because of their continuous and noisy nature, and the absence of domain-specific knowledge.	I-Reply	I-5	Reply	20148

This paper introduces a structured deep generative model for video frame prediction, with an object recognition model based on the Attend, Infer, Repeat (AIR) model by Eslami et al (2016) and a graph neural network as a latent dynamics model.	O	O	Review	20148
The model is evaluated on two synthetic physics simulation datasets (N-body gravitational systems and bouncing billiard balls) for next frame prediction and on a control task in the billiard domain.	O	O	Review	20148
The model can produce accurate predictions for several time steps into the future and beats a variational RNN and SQAIR (sequential AIR variant) baseline, and is more sample-efficient than a model-free PPO agent in the control task.	O	O	Review	20148
<sep> <sep> Overall, the paper is well-structured, nicely written and addresses an interesting and challenging problem.	O	O	Review	20148
The experiments use simple domains/problems, but give good insights into how the model performs.	O	O	Review	20148
<sep> <sep> Related work is covered to a satisfactory degree, but a discussion of some of the following closely related papers could improve the paper:	B-Review	B-7	Review	20148
* Chang et al A Compositional Object-Based Approach To Learning Physical Dynamics, ICLR 2017	I-Review	I-7	Review	20148
* Greff et al Neural Expectation Maximization, NeurIPS 2017	I-Review	I-7	Review	20148
* Kipf et al Neural Relational Inference for Interacting Systems, ICML 2018	I-Review	I-7	Review	20148
* Greff et al Multi-object representation learning with iterative variational inference, ICML 2019	I-Review	I-7	Review	20148
* Sun et al Actor-centric relation network, ECCV 2018	I-Review	I-7	Review	20148
* Sun et al Relational Action Forecasting, CVPR 2019	I-Review	I-7	Review	20148
* Wang et al NerveNet: Learning structured policy with graph neural networks, ICLR 2018	I-Review	I-7	Review	20148
* Xu et al Unsupervised discovery of parts, structure and dynamics, ICLR 2019	I-Review	I-7	Review	20148
* Erhardt et al Unsupervised intuitive physics from visual observations, ACCV 2018	I-Review	I-7	Review	20148
<sep> In terms of clarity, the paper could be improved by making the used model architecture more explicit, e.g., by adding a model figure, and by providing an introduction to the SuPAIR model (Stelzner et al 2019) ‚Äî the authors assume that the reader is more or less familiar with this particular model.	B-Review	B-1	Review	20148
It is further unclear how exactly the input data is provided to the model; Figure 2 makes it seem that inputs are colored frames, section 3.1 mentions that inputs are grayscale videos (do all objects have the same appearance or different shades of gray?),	B-Review	B-2	Review	20148
which is in conflict with the statement on page 5 that the model is provided with mean values of input color channels.	I-Review	I-2	Review	20148
Please clarify.	I-Review	I-2	Review	20148
<sep> <sep> In terms of novelty, the proposed modification of SQAIR (separating object detection and latent dynamics prediction) is novel and likely leads to a speed-up in training and evaluation.	B-Review	B-3	Review	20148
Using a Graph Neural Network for modeling latent physics is reasonable and has been shown to work on related problems before (see referenced work above and related work mentioned in the paper).	I-Review	I-3	Review	20148
Similarly, using such a model for planning/control is interesting and adds to the value of the paper, but has in related settings been explored before (e.g. Wang et al (ICLR 2018) and Sanchez-Gonzalez (ICML 2018)).	I-Review	I-3	Review	20148
<sep> <sep> Experimentally, it would be good to provide ablation studies (e.g. a different object detection module like AIR instead of SuPAIR, not splitting the latent variables into position, velocity, size etc.)	B-Review	B-4	Review	20148
and run-time comparisons (wall-clock time), as one of the main contributions of the paper is that the proposed model is claimed to be faster than SQAIR.	I-Review	I-4	Review	20148
The overall model predictions are (to my surprise) somewhat inaccurate, when looking at e.g. the billiard ball example in Figure 2.	I-Review	I-4	Review	20148
In Steenkiste et al (ICLR 2018), roll-outs appear to be more accurate.	B-Review	B-5	Review	20148
Maybe a quantitative experimental comparison could help?	I-Review	I-5	Review	20148
<sep> <sep> Why does the proposed model perform worse than a model-free PPO baseline when trained to convergence on the control task?	B-Review	B-6	Review	20148
What is missing to close this gap?	I-Review	I-6	Review	20148
<sep> <sep> Do all objects have the same appearance (color/greyscale values) or are they unique in appearance?	B-Review	B-7	Review	20148
In the second case, a simpler encoder architecture could be used such as in Jaques et al (2019) or Xu et al (ICLR 2019).	I-Review	I-7	Review	20148
<sep> <sep> Overall, I think that this paper addresses an important issue and is potentially of high interest to the community.	O	O	Review	20148
Nonetheless I think that this paper needs a bit more work and at this point I recommend a weak reject.	O	O	Review	20148
<sep> <sep> Other comments:	O	O	Review	20148
* This sentence is unclear to me: ‚ÄúAn additional benefit of this approach is that the information learned by the dynamics model is reused for inference ‚Äî [‚Ä¶]‚Äù	B-Review	B-8	Review	20148
* What are the failure modes of the model?	B-Review	B-9	Review	20148
Where does it break down?	I-Review	I-9	Review	20148
<sep> * How does the model deal with partial occlusion?	B-Review	B-10	Review	20148
<sep> <sep> ---------------------	O	O	Review	20148
UPDATE (after reading the author response and the revised manuscript): My questions and comments are addressed and the additional ablation studies and experimental results on energy conservation are convincing and insightful.	O	O	Review	20148
I think the revised version of the paper meets the bar for acceptance at ICLR.	O	O	Review	20148
<sep> <sep> Dear Reviewer 1,	O	O	Reply	20148
<sep> thank you for your valuable feedback.	O	O	Reply	20148
<sep> Below, we give a detailed response to your questions and comments.	O	O	Reply	20148
<sep> Please also see the changes to the manuscript outlined in our top level comment.	O	O	Reply	20148
<sep> <sep> [Added a "Model Figure"]	O	O	Reply	20148
We have revised Figure 1 to include a visualisation of the latent space and the corresponding recognition distributions.	B-Reply	B-1	Reply	20148
We hope this clarifies the model structure.	I-Reply	I-1	Reply	20148
<sep> <sep> [Introduction to SuPAIR]	O	O	Reply	20148
We chose to omit details on SuPAIR as they are not required for understanding STOVE - in principle, any image model delivering a likelihood p(x | z_where) based on location information z_where could be used in its stead, including AIR.	B-Reply	B-1	Reply	20148
As said, we mainly chose SuPAIR due to its fast training times.	I-Reply	I-1	Reply	20148
If you have specific suggestions for what should be clarified about SuPAIR, we will be glad to do so.	I-Reply	I-1	Reply	20148
<sep> <sep> [Color vs. Grayscale]	O	O	Reply	20148
For the video modeling task, we use grayscale images in which all objects are the same shade of white.	B-Reply	B-2	Reply	20148
Color has been added to Figure 2 to make it more readable.	I-Reply	I-2	Reply	20148
For the RL task, we use colored images such that the models may recognize the object which is controlled by the agent.	I-Reply	I-2	Reply	20148
The mean values per color channels are added to each objects state, as a simple encoding of appearance.	I-Reply	I-2	Reply	20148
We clarified this in the revision.	I-Reply	I-2	Reply	20148
<sep> <sep> [RL experiments]	O	O	Reply	20148
The main motivation of our RL experiments is to demonstrate planning based on an object-aware dynamics model learned on purely visual input, which to our knowledge has not been done in prior work.	B-Reply	B-3	Reply	20148
Wang et al use GNNs very differently from us, by employing them in a model-free policy network.	I-Reply	I-3	Reply	20148
Sanchez-Gonzalez et al like us, use GNNs as a dynamics model for planning, but assume access to the ground truth states as opposed to inferring them from images.	I-Reply	I-3	Reply	20148
<sep> <sep> [Realistic Rollouts]	O	O	Reply	20148
We find that STOVE significantly improves upon prior work in that it predicts physical behavior across long timeframes, instead of stopping or teleporting objects.	B-Reply	B-3	Reply	20148
We quantify this in the revision by plotting the conservation of kinetic energy in the rollouts, which STOVE achieves up to at least 100,000 steps, while DDPAE and SQAIR break down after less than 100.	I-Reply	I-3	Reply	20148
See (1) of our top level comment and the animated GIFs in our anonymized GitHub [1].	I-Reply	I-3	Reply	20148
<sep> [Ablations]	O	O	Reply	20148
In the revision, we provide results for three ablations (see (3) in our general comment and Table 1), including two with an ablated state representation.	B-Reply	B-4	Reply	20148
We did not explore AIR as an alternative object detector, since we chose SuPAIR for its faster training times.	I-Reply	I-4	Reply	20148
We do not claim, or even expect, that AIR would perform worse.	I-Reply	I-4	Reply	20148
<sep> <sep> [Steenkiste et al]	O	O	Reply	20148
For a visual evaluation, please compare our animated rollouts [1] with the ones presented by Steenkiste et al [2, very bottom]. We find that STOVE more accurately captures object permanence and energy conservation.	B-Reply	B-5	Reply	20148
We decided against a quantitative comparison due to qualitative differences:	I-Reply	I-5	Reply	20148
(a) R-NEM requires around 10 given observations before the iterative inference procedure converges to a good segmentation,	I-Reply	I-5	Reply	20148
(b) it does not explicitly model object positions, and	I-Reply	I-5	Reply	20148
(c) it requires noisy input to avoid local minima.	I-Reply	I-5	Reply	20148
<sep> We have instead added DDPAE as a baseline.	I-Reply	I-5	Reply	20148
See (2) in our top level comment.	I-Reply	I-5	Reply	20148
<sep> <sep> [1] <a href="https://github.com/ICLR20/STOVE" target="_blank" rel="nofollow">https://github.com/ICLR20/STOVE</a>	O	O	Reply	20148
[2] <a href="https://sites.google.com/view/r-nem-gifs/" target="_blank" rel="nofollow">https://sites.google.com/view/r-nem-gifs/</a>	O	O	Reply	20148
<sep> [RL Performance]	O	O	Reply	20148
The performance of MCTS+STOVE was very close to the performance of MCTS on the ground truth environment.	B-Reply	B-6	Reply	20148
This indicates that the weak point of the agent was not the model (STOVE), but rather the planner, and that more thorough planning would allow it to match PPO's performance.	I-Reply	I-6	Reply	20148
Since the goal of our RL experiments was to highlight the applicability and sample efficiency of our model in the RL domain, we opted for an off-the-shelf planner instead of tuning for final performance.	I-Reply	I-6	Reply	20148
<sep> <sep> [Suggested Related Work]	O	O	Reply	20148
Thank you for the references, we have added them.	B-Reply	B-7	Reply	20148
<sep> <sep> [Reuse of Dynamics Model]	O	O	Reply	20148
Previous models, such as SQAIR and DDPAE, use an inference distribution which is entirely separate from the generative dynamics model.	B-Reply	B-8	Reply	20148
We argue that this is wasteful, as much of the knowledge captured by the generative dynamics model is also relevant for the inference network.	I-Reply	I-8	Reply	20148
We therefore reuse it in our formulation of the inference network (Eq.2), saving model parameters and regularizing training.	I-Reply	I-8	Reply	20148
We explore the benefits of this in one of the new ablations ("double dynamics").	I-Reply	I-8	Reply	20148
<sep> <sep> [Failure Modes]	O	O	Reply	20148
The main failure mode is that the inductive bias in the image model is insufficient to reliably detect objects.	B-Reply	B-9	Reply	20148
See Stelzner et al for a discussion of noisy backgrounds in SuPAIR.	I-Reply	I-9	Reply	20148
In addition, our matching procedure assumes that objects move continuously.	I-Reply	I-9	Reply	20148
<sep> <sep> [Occlusion]	O	O	Reply	20148
Occlusion is explicitly modelled in SuPAIR: If objects overlap, the hidden parts of the occluded object are treated as unobserved, and therefore marginalized during the evaluation of the object appearances' likelihood.	B-Reply	B-10	Reply	20148
<sep> <sep> We hope that the changes made will address your concerns and look forward to further discussion.	O	O	Reply	20148

Summarize what the paper claims to do/contribute.	O	O	Review	20167
<sep> * The paper proposes a new image-to-image GAN-based translator that uses attention and a new normalization that learns a proper ratio between instance and layer normalization.	O	O	Review	20167
Experiments benchmark the new method against multiple prior ones, and on a number of dataset pairs.	O	O	Review	20167
<sep> <sep> Clearly state your decision (accept or reject) with one or two key reasons for this choice.	O	O	Review	20167
<sep> Weak Accept	O	O	Review	20167
<sep> * The paper was well-written and the method and contributions are clearly explained.	O	O	Review	20167
<sep> * There is clear novelty in this paper, even if slightly limited.	O	O	Review	20167
However, the newly proposed normalization seems to work quite well.	O	O	Review	20167
<sep> * The results look good, however it is hard to compare methods quantitatively with only few samples. (	B-Review	B-1	Review	20167
Nothing that the authors could have done: there are many samples in the supplementary material and results seem consistent.)	I-Review	I-1	Review	20167
Qualitative measures like FID and KID should be taken with a grain of salt also.	I-Review	I-1	Review	20167
It is a big plus that a user study was conducted! (	I-Review	I-1	Review	20167
However, details of how these subjects were selected would be useful)	I-Review	I-1	Review	20167
We thank the reviewer for the valuable comments and constructive feedback , and would like to answer the reviewer‚Äôs questions as follows:	O	O	Reply	20167
The perceptual study was conducted on 153 participants of an AI community, which includes a mix of experts and non-specialists.	B-Reply	B-1	Reply	20167

I have read the authors' rebuttal and satisfied with their response.	B-Review	B-1	Review	20167
Novelty is a little on the lower side, but thorough writing, results, and insightful comparisons make up for this in my opinion.	I-Review	I-1	Review	20167
I have updated my score to 8: Accept.	O	O	Review	20167
<sep> <sep> =====	O	O	Review	20167
<sep> This paper proposes an approach to perform image translation called U-GAT-IT.	O	O	Review	20167
In image translation, the goal is to learn a mapping from images in a source domain to corresponding images in a target domain.	O	O	Review	20167
Contemporary image translation approaches are able to transfer local texture but struggle to handle shape transfer.	O	O	Review	20167
To address this concern, the authors introduce an attention mechanism based on CAM [1] and an adaptive normalization layer into a GAN-based image translation framework.	O	O	Review	20167
Results indicate favorable quantitative and qualitative performance relative to a number of baselines.	O	O	Review	20167
<sep> <sep> Specific contributions include:	O	O	Review	20167
* Introduction of a normalization layer called AdaLIN that can interpolate between instance normalization and layer normalization based on the input.	O	O	Review	20167
<sep> * Introduction of an attention mechanism based on CAM [1] that allows the model to focus on specific parts of the image when either generating or discriminating.	O	O	Review	20167
<sep> * Collection and release of a selfie-to-anime dataset.	O	O	Review	20167
<sep> * Release of U-GAT-IT code.	O	O	Review	20167
<sep> In my opinion this paper is borderline, leaning towards weak accept.	O	O	Review	20167
The experiments are thorough and the paper is well-written.	O	O	Review	20167
I have concerns about the novelty and significance of the work, but overall the paper feels very close to being a finished piece of work in spite of its (relatively minor) flaws.	B-Review	B-1	Review	20167
<sep> Strong points of this work include the writing and experiments.	O	O	Review	20167
The paper is clearly organized and feels polished.	O	O	Review	20167
It cites many relevant works, giving the reader a sense of the contemporary approaches for image translation.	O	O	Review	20167
There is a thorough description of model architecture, dataset and tuning parameters in the appendix.	O	O	Review	20167
In addition, code and the selfie-to-anime dataset have been released by the authors.	O	O	Review	20167
In terms of experiments, the authors provide many qualitative visualizations comparing the proposed model to baselines on various datasets.	O	O	Review	20167
Quantitative evaluation includes KID and a perceptual evaluation on human subjects.	O	O	Review	20167
<sep> <sep> Weak points include novelty and significance.	B-Review	B-1	Review	20167
The proposed approach combines two ideas already applied to image translation (adaptive normalization [3] and attention [4]).	I-Review	I-1	Review	20167
It therefore synthesizes these ideas into an effective algorithm rather than directly adding something new.	I-Review	I-1	Review	20167
It is unclear to me how others can build on top of this work to further advance state-of-the-art in image translation.	I-Review	I-1	Review	20167
Are more sophisticated normalization and attention mechanisms truly the key to improving image translation in the future?	I-Review	I-1	Review	20167
<sep> <sep> Specific comments:	O	O	Review	20167
* The formulation of AdaLIN in Equation (1) is vague.	B-Review	B-2	Review	20167
The text states "parameters are dynamically computed by a fully connected layer from the attention map", but it's not clear what those parameters are in the equation.	I-Review	I-2	Review	20167
Explicitly writing \gamma and \beta as functions of the fully-connected layer and \mu_I, \sigma_I, \mu_L, \sigma_L as the corresponding mean and standard deviation expressions would make things more clear.	I-Review	I-2	Review	20167
<sep> * The motivation for using layer normalization was discussed in 2.1.1 but I still do not understand why it is beneficial.	B-Review	B-3	Review	20167
<sep> * The term "importance weights" has a specific meaning in the context of Monte Carlo methods.	B-Review	B-4	Review	20167
I would suggest choosing a different term here.	I-Review	I-4	Review	20167
<sep> <sep> Questions for the authors:	O	O	Review	20167
* How does U-GAT-IT compare to TransGaGa [2]?	B-Review	B-5	Review	20167
One of the stated goals of U-GAT-IT is to better handle shape when performing image translation.	I-Review	I-5	Review	20167
TransGaGa has a similar motivation and so I would have liked to see an experimental comparison or at the very least a description of how U-GAT-IT differs.	I-Review	I-5	Review	20167
What sorts of shape transfer could U-GAT-IT handle that TransGaGa couldn't and vice versa?	I-Review	I-5	Review	20167
<sep> * What are the shortcomings of the model and how could they possibly be addressed?	B-Review	B-6	Review	20167
<sep> [1] Zhou, B., Khosla, A., Lapedriza, A., Oliva, A. and Torralba, A., 2016.	O	O	Review	20167
Learning deep features for discriminative localization.	O	O	Review	20167
In Proceedings of the IEEE conference on computer vision and pattern recognition (pp.2921-2929).	O	O	Review	20167
<sep> [2] Wu, W., Cao, K., Li, C., Qian, C. and Loy, C.C., 2019.	O	O	Review	20167
Transgaga: Geometry-aware unsupervised image-to-image translation.	O	O	Review	20167
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp.8012-8021).	O	O	Review	20167
<sep> [3] Huang, X. and Belongie, S., 2017.	O	O	Review	20167
Arbitrary style transfer in real-time with adaptive instance normalization.	O	O	Review	20167
In Proceedings of the IEEE International Conference on Computer Vision (pp.1501-1510).	O	O	Review	20167
<sep> [4] Mejjati, Y.A., Richardt, C., Tompkin, J., Cosker, D. and Kim, K.I., 2018.	O	O	Review	20167
Unsupervised attention-guided image-to-image translation.	O	O	Review	20167
In Advances in Neural Information Processing Systems (pp.3693-3703).	O	O	Review	20167
We thank the reviewer for the valuable comments and constructive feedback.	O	O	Reply	20167
In the revised draft, we mark our major revisions by ‚Äúviolet‚Äù , and would like to answer the reviewer‚Äôs questions as follows:	O	O	Reply	20167
*About Novelty:	O	O	Reply	20167
<sep> 1.	B-Reply	B-1	Reply	20167
Attention mechanism	I-Reply	I-1	Reply	20167
<sep> Although we proposed similar attention concept, the goal and how to generate are different.	I-Reply	I-1	Reply	20167
Previous attention-based work [1] do not allow to transform the shape of the instance because of attaching the background to the (translated) cropped instances.	I-Reply	I-1	Reply	20167
Unlike these works, we assumed that our model will guide to focus on more important regions and ignore minor regions by distinguishing between the target and not-target domains based on the importance map obtained by the auxiliary classifier.	I-Reply	I-1	Reply	20167
These attention maps are embedded into the generator and discriminator to focus on semantically important areas, thus facilitating the shape transformation.	I-Reply	I-1	Reply	20167
The attention map in the generator induces focus on areas that specifically distinguish between the two domains.	I-Reply	I-1	Reply	20167
The attention map in discriminator helps fine-tuning by focusing on the difference between real image and fake image in target domain.	I-Reply	I-1	Reply	20167
<sep> <sep> 2.	B-Reply	B-1	Reply	20167
Normalization	I-Reply	I-1	Reply	20167
<sep> AdaLIN tells the model how much it should transform.	I-Reply	I-1	Reply	20167
Instance Norm (IN) is capable of preserving the characteristics of source image.	I-Reply	I-1	Reply	20167
Layer Norm (LN) which uses layer-wise feature statistics is better at transforming to target domain.	I-Reply	I-1	Reply	20167
We found that combining advantages of both IN and LN is beneficial to image-to-image translation task in various datasets by controlling the amount of transform.	I-Reply	I-1	Reply	20167
Though its idea borrows from previous work [2], the proposed method is the first attempt to combine IN and LN in image-to-image translation task as far as we investigated.	I-Reply	I-1	Reply	20167
<sep> <sep> [1] Y. Alami Mejjati, C. Richardt, J. Tompkin, D. Cosker, and K. I. Kim.	O	O	Reply	20167
Unsupervised attention-guided image-to-image translation.	O	O	Reply	20167
In NIPS.	O	O	Reply	20167
2018.	O	O	Reply	20167
<sep> [2] H. Nam and H.-E. Kim.	O	O	Reply	20167
Batch-instance normalization for adaptively style-invariant neural networks.	O	O	Reply	20167
In NIPS, 2018.	O	O	Reply	20167
<sep> <sep> *Specific Comments:	O	O	Reply	20167
<sep> 1.	O	O	Reply	20167
The formulation of AdaLIN in Equation (1)	O	O	Reply	20167
<sep> I agree with the comment from the Reviewer.	B-Reply	B-2	Reply	20167
In the revised draft, I modify like  "parameters, /gamma and /beta are dynamically computed by a fully connected layer from the attention map" in sec 2.1.1.	I-Reply	I-2	Reply	20167
<sep> <sep> 2.	O	O	Reply	20167
The motivation for using layer normalization	O	O	Reply	20167
<sep> We assumed that optimal stylization method was "whitening and Coloring Transform".	B-Reply	B-3	Reply	20167
However, the computational cost is high due to the calculation of the covariance matrix and matrix inverse.	I-Reply	I-3	Reply	20167
To compensate between the computational cost and the quality of the result, we borrowed two sub-optimal normalization methods, AdaIN and Layer Normalization.	I-Reply	I-3	Reply	20167
During stylization, while the AdaIN has the characteristics keeping more contents information, the Layer Normalization tends to make stylization more obvious instead keeping content information less.	I-Reply	I-3	Reply	20167
<sep> <sep> 3.	O	O	Reply	20167
The term "important weights"	O	O	Reply	20167
<sep> In the revised draft, we modify it to "the weight of the k-th feature map for the source domain"  in sec 2.1.1.	B-Reply	B-4	Reply	20167
<sep> <sep> *Questions for the authors:	O	O	Reply	20167
<sep> 1.	O	O	Reply	20167
U-GAT-IT vs TransGaGa	O	O	Reply	20167
<sep> The goal of U-GAT-IT is to change the shape of the foreground while maintaining the content of the background.	B-Reply	B-5	Reply	20167
TransGaGa deal with the geometry and appearance separately and fully converts the appearance of the source domain into that of the target domain without considering the foreground and background.	I-Reply	I-5	Reply	20167
Therefore, as can be seen from the experimental results, the background of the source image is not maintained at all.	I-Reply	I-5	Reply	20167
However, U-GAT-IT can maintain or change the contents of the source domain adaptively through attention.	I-Reply	I-5	Reply	20167
In addition, U-GAT-IT can achieve good results in style transfer as well as shape change through AdaLIN.	I-Reply	I-5	Reply	20167
Therefore, we think U-GAT-IT is a more generalized version than TransGaGa.	I-Reply	I-5	Reply	20167
<sep> <sep> 2.	O	O	Reply	20167
What are the shortcomings of the model and how could they possibly be addressed?	O	O	Reply	20167
<sep> <sep> The shortcomings for our model is "one-to-one mapping".	B-Reply	B-6	Reply	20167
But we will design UGATIT with our future work to be multi-modal and multi-domain together.	I-Reply	I-6	Reply	20167

This paper proposes a new attention mechanism for unsupervised image-to-image translation task.	O	O	Review	20167
The proposed attention mechanism consists of an attention module and a learnable normalization function.	O	O	Review	20167
Sufficient experiments and analysis are done on five datasets.	O	O	Review	20167
<sep> Pros:	O	O	Review	20167
1.	O	O	Review	20167
The proposed method seems to generalize well to the different datasets with the same network architecture and hyper-parameters compared to previous works.	O	O	Review	20167
This could benefit other researchers who want to apply the method to other data or tasks.	O	O	Review	20167
<sep> 2.	O	O	Review	20167
The translated results seem more semantic consistent with the source image compared to other methods, although the sores are not the top on photo2portrait and photo2vangogh.	O	O	Review	20167
The results also look more pleasing.	O	O	Review	20167
<sep> <sep> Cons:	O	O	Review	20167
1.	O	O	Review	20167
The CAM loss is one of the key components in the proposed method.	B-Review	B-1	Review	20167
However, there is only the reference and no detailed description in the paper.	I-Review	I-1	Review	20167
More intuitive descriptions are necessary for easy understanding.	I-Review	I-1	Review	20167
<sep> 2.	O	O	Review	20167
The local and global discriminators are not explained until the result analysis.	B-Review	B-2	Review	20167
It‚Äôs a bit confusing when I see the local and global attention maps visualization results.	I-Review	I-2	Review	20167
It‚Äôs better to mention it in the method section.	I-Review	I-2	Review	20167
<sep> 3.	O	O	Review	20167
I wonder why some translations are not done at all in the results without CAM in Figure 2(f).	B-Review	B-3	Review	20167
Because without CAM, the framework would be somehow similar to MUNIT or DRIT.	I-Review	I-3	Review	20167
I suppose the hyper-parameters are not suitable for this setting.	I-Review	I-3	Review	20167
<sep> 4.	B-Review	B-4	Review	20167
The generator model architecture in Figure 1 is confusing.	I-Review	I-4	Review	20167
The adaptive residual blocks only receive the gamma and beta parameters.	I-Review	I-4	Review	20167
I suppose that the encoder feature maps are also fed into the adaptive residual blocks.	I-Review	I-4	Review	20167
<sep> 5.	O	O	Review	20167
In Figure 3, the comparison of the results using each normalization function is reported.	B-Review	B-5	Review	20167
While in my view, the results only using GN in decoder with CAM looks more natural.	I-Review	I-5	Review	20167
I wonder why the proposed method only consists of instance norm and layer norm?	I-Review	I-5	Review	20167
I suppose the group norm might help with the predefined group.	I-Review	I-5	Review	20167
<sep> 6.	B-Review	B-6	Review	20167
In the ablation study, the CAM is evaluated for generator and discriminator together.	I-Review	I-6	Review	20167
I would recommend doing this ablation study for generator and discriminator separately to see if it‚Äôs necessary for generator or discriminator.	I-Review	I-6	Review	20167
<sep> 7.	B-Review	B-7	Review	20167
It would be good to see some discussion on the attention mechanism compared with other related works.	I-Review	I-7	Review	20167
For example,  [a,b] predict the attention masks for unsupervised I2I, but applies them on the pixel/feature spatial level to keep the semantic consistency.	I-Review	I-7	Review	20167
<sep> [a] Unsupervised-Attention-guided-Image-to-Image-Translation.	O	O	Review	20167
NIPS‚Äô18	O	O	Review	20167
[a] Exemplar guided unsupervised image-to-image translation with semantic consistency.	O	O	Review	20167
ICLR‚Äô19	O	O	Review	20167
<sep> My initial rating is above boardline.	O	O	Review	20167
Thank you for the valuable comments and constructive feedback.	O	O	Reply	20167
In the revised draft, we mark our major revisions by ‚Äúviolet‚Äù , and would like to answer the reviewer‚Äôs questions as follows:	O	O	Reply	20167
<sep> 1.	O	O	Reply	20167
Description for CAM	O	O	Reply	20167
<sep> As you suggested, in the revised draft, we add the related works including the description for CAM in Appendix A.	B-Reply	B-1	Reply	20167
<sep> 2.	O	O	Reply	20167
The local and global discriminators	O	O	Reply	20167
<sep> As you suggested, in the revised draft, we add the description for the multi-scale discriminator in Sec.2.1.2.	B-Reply	B-2	Reply	20167
<sep> <sep> 3.	O	O	Reply	20167
Result without CAM (Figure2(f))	O	O	Reply	20167
<sep> To make sure that the effect of the CAM, we have all set the same hyper-parameters and retrained the model.	B-Reply	B-3	Reply	20167
<sep> <sep> 4.	O	O	Reply	20167
The generator model architecture  (Figure 1)	O	O	Reply	20167
<sep> You're right.	B-Reply	B-4	Reply	20167
We will modify the figure to make it appear that the encoder feature maps are fed into the adaptive residual blocks.	I-Reply	I-4	Reply	20167
<sep> <sep> <sep> 5.	O	O	Reply	20167
Why not using GN?	O	O	Reply	20167
<sep> <sep> We thought GN was theoretically an intermediate version of IN and LN.	B-Reply	B-5	Reply	20167
Therefore, the GN can be properly expressed by the /rho value.	I-Reply	I-5	Reply	20167
The selection was based on whether the result would be closer to the target domain or more biased toward the source domain rather than the naturality of the results.	I-Reply	I-5	Reply	20167
In Figure 3 (f), you can see more textures from the background of the source domain.	I-Reply	I-5	Reply	20167
<sep> <sep> 6.	O	O	Reply	20167
Ablation Study	O	O	Reply	20167
<sep> As shown in Table 1, it includes the ablation study for generator and discriminator separately with KID.	B-Reply	B-6	Reply	20167
If space is allowed, we will add the image results.	I-Reply	I-6	Reply	20167
<sep> <sep> 7.	O	O	Reply	20167
Discussion on the attention mechanism compared with other related works	O	O	Reply	20167
<sep> Our experiment results already are including the result of AGGAN[1] and discussed about that.	B-Reply	B-7	Reply	20167
<sep> [1] Unsupervised-Attention-guided-Image-to-Image-Translation.	O	O	Reply	20167
NIPS‚Äô18	O	O	Reply	20167

Background disclaimer: I work in RL research for quite an amount of time, but I do not know much about the domain of distributed systems.	O	O	Review	20006
For this reason, I may not know the details of technical terms, and I might not be the best person to review this work (when compared with the literature in this field).	O	O	Review	20006
Nevertheless, below I try to give my evaluation based on reading the paper.	O	O	Review	20006
<sep> <sep> ====================	O	O	Review	20006
In this work, the authors applied value-based reinforcement learning to learn an optimal policy for global parameter tuning in the parameter server (PS) that trains machine learning models in a distributed way using  stochastic gradient descent.	B-Review	B-1	Review	20006
Example parameters include SGD hyper-parameters (such as learning rate) and system-level parameters.	I-Review	I-1	Review	20006
Immediate cost is to minimize the training time of the SGD algorithm, and i believe the states are the server/worker parameters.	I-Review	I-1	Review	20006
From the RL perspective, the algorithm used here is a standard DQN with discrete actions (choices of parameters).	I-Review	I-1	Review	20006
But in general I am puzzled why the action space is discrete instead of continuous, if the actions are the hyper-parameters.	I-Review	I-1	Review	20006
State transition wise, I am not sure if the states follow an action-dependent MDP transition, and therefore at this point I am not sure if DQN is the best algorithm for this applications (versus bandits/combinatorial bandits).	I-Review	I-1	Review	20006
While it is impressive to see that RL beats many of the SOTA baselines for parameter tuning, I also find that instead of using data in the real system to do RL training, the paper proposes generating "simulation" data by training a separate DNN.	I-Review	I-1	Review	20006
I wonder how the performance would differ if the RL policy is trained on the batch real data.	I-Review	I-1	Review	20006
<sep> <sep> <sep> In the following, we list your concerns on the Problem I and our detailed responses.	O	O	Reply	20006
<sep> <sep> Problem I:	O	O	Reply	20006
In this work, the authors applied value-based reinforcement learning to learn an optimal policy for global parameter tuning in the parameter server (PS) that trains machine learning models in a distributed way using  stochastic gradient descent.	O	O	Reply	20006
Example parameters include SGD hyper-parameters (such as learning rate) and system-level parameters.	O	O	Reply	20006
Immediate cost is to minimize the training time of the SGD algorithm, and i believe the states are the server/worker parameters.	O	O	Reply	20006
From the RL perspective, the algorithm used here is a standard DQN with discrete actions (choices of parameters).	O	O	Reply	20006
In general I am puzzled why the action space is discrete instead of continuous, if the actions are the hyper-parameters.	O	O	Reply	20006
State transition wise, I am not sure if the states follow an action-dependent MDP transition, and therefore at this point I am not sure if DQN is the best algorithm for this applications (versus bandits/combinatorial bandits).	O	O	Reply	20006
<sep> <sep> Response to Problem I:	O	O	Reply	20006
Thank you for your kind review.	O	O	Reply	20006
First let us clarify the difference of our work with learning hyperparameters, then answer the question on actions and states.	B-Reply	B-1	Reply	20006
<sep> <sep> In this paper, we learn an optimal ''synchronization policy'' used for the distributed training of machine learning models with Stochastic Gradient Descent (SGD) in Parameter-Server (PS)-based environment.	I-Reply	I-1	Reply	20006
This setting consists of one (or several) PS maintaining model parameters and receiving updated gradients from workers, and multiple workers pulling model parameters from PS, computing gradients and pushing them back to PS.	I-Reply	I-1	Reply	20006
<sep> <sep> The synchronization policy is a mechanism to coordinate the execution progress of all workers in the PS setting.	I-Reply	I-1	Reply	20006
It determines in each step, i.e., whenever a worker pushes its gradient to the PS, whether this worker should continue to run for the next step or wait for sometime for the completion of some other workers.	I-Reply	I-1	Reply	20006
Thus, it is independent of the hyper-parameters of SGD and system parameters.	I-Reply	I-1	Reply	20006
Hence, we are trying to optimize the mechanism of the synchronization policy to save training time but not tuning the global hyperparameters of SGD.	I-Reply	I-1	Reply	20006
In short, our work falls in the category of "learning how to learn" to train the underlying ML models while hyperparameter tuning falls in the category of "learning which model to learn" to optimize the hyperparameters of the underlying ML models.	I-Reply	I-1	Reply	20006
<sep> <sep> To  this end, we formalize the design of a synchronization policy as a reinforcement learning problem (see Figure 1 in Page 5 for an illustration).	I-Reply	I-1	Reply	20006
In this RL problem, for the state we choose  features which characterize the execution progress of SGD training in each step.	I-Reply	I-1	Reply	20006
To ensure the expression power of the state, the state space in our problem is large when compared to more standard RL problem instances.	I-Reply	I-1	Reply	20006
Each state vector may contain dozens to hundreds of features (See the paragraphs in Page 4 entitled with "State" for more details).	I-Reply	I-1	Reply	20006
Therefore, we choose a deep neural network to represent the transition function \pi(S, a) and apply DQN to train the RL policy.	I-Reply	I-1	Reply	20006
The tabular and bandits algorithms are unable to represent the large and complex transition function in this application.	I-Reply	I-1	Reply	20006
<sep> <sep> In our RL problem, each action represents a decision for each worker to run or wait at each step.	I-Reply	I-1	Reply	20006
Therefore, the action space is discrete.	I-Reply	I-1	Reply	20006
It contains at most 2^n actions for n workers since for each worker it need to be decided whether to run or wait, respectively.	I-Reply	I-1	Reply	20006
We choose a small but powerful action space containing three valid actions to enable fast training of the RL policy (See the paragraphs in Page 5 entitled with "Action" for more details).	I-Reply	I-1	Reply	20006
We design the state and action in this manner in our RL setting to ensure its generality while keeping training and inference efficiency.	I-Reply	I-1	Reply	20006
<sep> <sep> The state clearly follows an action-dependent MDP transition since the next position of execution process is purely determined by the current state (where we are) and the next action (where we go).	I-Reply	I-1	Reply	20006

This paper proposes to use deep RL to learn a policy for communication in the parameter-server setup of distributed training.	O	O	Review	20006
From the perspective, the problem formulation is a nice contribution.	O	O	Review	20006
<sep> <sep> While it is a reasonable idea and the initial results are promising, the lack of an evaluation on a real cluster, or for training more computationally-demanding models, is limiting.	B-Review	B-1	Review	20006
I fully appreciate the need to perform experiments in a controlled environment, such as the ones reported in the paper.	I-Review	I-1	Review	20006
These are useful to validate the idea and explore its potential limitations.	I-Review	I-1	Review	20006
However, to truly validate such an idea completely it is also necessary to implement it and run it "in the wild" on an actual distributed system.	I-Review	I-1	Review	20006
From my experience, although performing such experiments is certainly more involved and challenging, there can also be significant differences in the outcomes when one goes to such an implementation.	I-Review	I-1	Review	20006
Normally these are due to discrepancies between the assumed/simulated model, and real system behavior.	I-Review	I-1	Review	20006
<sep> <sep> Is it clear that deep RL is needed for this application, as opposed to more traditional RL approaches (either tabular, with suitably quantized actions, or a simpler form of function approximation?	B-Review	B-2	Review	20006
And to ask in the other direction, did you consider using a more complex policy architecture, e.g., involving an LSTM or other recurrent unit?	I-Review	I-2	Review	20006
<sep> <sep> <sep> In the following, we list your concerns on the Problem III and our detailed responses.	O	O	Reply	20006
<sep> <sep> Problem III:	O	O	Reply	20006
While it is a reasonable idea and the initial results are promising, the lack of an evaluation on a real cluster, or for training more computationally-demanding models, is limiting. ... (	O	O	Reply	20006
omitted due to space limit) ... Normally these are due to discrepancies between the assumed/simulated model, and real system behavior.	O	O	Reply	20006
<sep> <sep> Response to Problem III:	O	O	Reply	20006
Thank you very much for your very helpful reviews and suggestions.	O	O	Reply	20006
We very much appreciate your understanding of the challenges of the experiments in a real distributed system.	O	O	Reply	20006
In fact, we have been following a three-step plan for this work which almost follows your recommendation.	O	O	Reply	20006
<sep> <sep> For the first step, we have implement a simulated environment to validate the idea and explore  potential limitations.	B-Reply	B-1	Reply	20006
In the second step, we have implemented a prototype distributed system to further examine the method and address possible problems.	I-Reply	I-1	Reply	20006
In the third step, we plan to implement this method as an builtin component for Tensorflow, so that it may be used in real-world production scenarios.	I-Reply	I-1	Reply	20006
<sep> <sep> This papers mainly shows our results for the first step and concentrates on exhibiting our novel ideas in applying RL into synchronization policy design.	I-Reply	I-1	Reply	20006
After submission, we have implemented a prototype distributed system and further tested our method.	I-Reply	I-1	Reply	20006
We build the system by directly following the standard PS architecture which contains one PS node and multiple worker nodes.	I-Reply	I-1	Reply	20006
They are connected through a network.	I-Reply	I-1	Reply	20006
Based on this real distributed system, we do more experiments and present you the outline as follows.	I-Reply	I-1	Reply	20006
We have added the new experimental results in the Appendix B, Pages 12-13, in the revised paper.	I-Reply	I-1	Reply	20006
<sep> <sep> First, for the experimental setting, we use the same settings for  the hyperparameters as in the  experiments in the simulated environment.	I-Reply	I-1	Reply	20006
We use the same method to generate instances to train the RL policy except that we do not use the sleep() function to simulate the behavior of stragglers.	I-Reply	I-1	Reply	20006
Before training, we also apply existing policies to pre-train the policy network of RL.	I-Reply	I-1	Reply	20006
This time, we find that RLP needs to be trained with more instances (around 1, 500 to 2000 episodes) to converge, since the situation is more complex.	I-Reply	I-1	Reply	20006
<sep> <sep> Second, for comparing the performance of RLP w.r.t.existing policies, we find that RLP still outperforms them, and sometimes performs even better than the simulation environment.	I-Reply	I-1	Reply	20006
As shown in Figure 6, RLP is 2.11 and 1.64 times faster than BSP and SSP, respectively, which are higher than the simulation environment; and RLP is 1.28 times faster than ASP, which is lower than the simulation environment.	I-Reply	I-1	Reply	20006
We conjecture that the key reason underlying this is that the straggler effect is much more significant than the staleness effect in a real cluster environment.	I-Reply	I-1	Reply	20006
In real clusters, the variance of running times of different workers tends to be higher, hence more workers are likely to be stragglers.	I-Reply	I-1	Reply	20006
Meanwhile, the network may delay the updates of some workers, which further amplify the straggler effects.	I-Reply	I-1	Reply	20006
However, the staleness effect is a property which is more closely related with the trained ML model itself and not as vulnerable as the straggler effect due to the cluster environment.	I-Reply	I-1	Reply	20006
Therefore, ASP runs faster than BSP and SSP on real clusters.	I-Reply	I-1	Reply	20006
As a result, our RLP improves more on BSP and SSP while less on ASP.	I-Reply	I-1	Reply	20006
Notice that, this result once again verifies the adaptivity of our RLP method, which can find better policies both in the simulation environment and real cluster environments.	I-Reply	I-1	Reply	20006
<sep> <sep> Third, on the generality of the RLP, as shown in Figure 7, we observe that the trained RLP policy can generalize to clusters with different numbers of workers, new models and new data.	I-Reply	I-1	Reply	20006
This is because in our RL formulation, both the state and action representation are irrelevant to the number of workers.	I-Reply	I-1	Reply	20006
Meanwhile, we record only the loss value information  in the state information of RLP.	I-Reply	I-1	Reply	20006
Thus, training models with similar loss curve may also speed up by our RLP policy experience.	I-Reply	I-1	Reply	20006
<sep> <sep> In this paper, we mention in limitations (Page 2) that we do not apply our method on very demanding models such as CNN or BERT-like model due to resource constraints.	I-Reply	I-1	Reply	20006
We are currently implementing RLP in order to deal with these computationally-demanding models more efficiently in a  distributed environment.	I-Reply	I-1	Reply	20006
However, these models are much more complex and needs more time to train and tune, so the results are not yet ready to be provided in this paper.	I-Reply	I-1	Reply	20006
We will address this in future work.	I-Reply	I-1	Reply	20006
<sep> <sep> Regarding an integration into Tensorflow we are currently in discussion regarding a modification of the token queue mechanism underlying TensorFlow's builtin PS.	I-Reply	I-1	Reply	20006
Ultimately, we  want to integrate RLP into the generation and fetching procedures of the token queue in order to implement our synchronization policy beyond the prototype distributed implementation.	I-Reply	I-1	Reply	20006

This paper studies how to improve the synchronization policy for parameter server based distributed SGD algorithm.	O	O	Review	20006
Existing work focus on either synchronous or asynchronous policy, which often results in straggler or staleness problems.	O	O	Review	20006
Recent research proposes different ways to make the policy design fully adaptive and autonomous.	O	O	Review	20006
This paper proposes a reinforcement learning (RL) approach and shows promising results to reduce the total training time on various scenario.	O	O	Review	20006
<sep> <sep> A major challenge is to design the state and action spaces in the reinforcement learning setting.	O	O	Review	20006
It requires the design can be generalized to different scenario, while ensuing efficient policy learning.	O	O	Review	20006
Compared to existing policies such as BSP, ASP and SSP, RL has an advantage to adapt to non-stationary situations over the training process.	O	O	Review	20006
Compared to other existing approaches, RL could be fully data-driven.	O	O	Review	20006
<sep> <sep> The paper formalizes an RL problem by minimizing the total training time to reach a given validation accuracy.	O	O	Review	20006
To minimize the number of actions, only 3 actions coming from BSP, ASP and SSP are used.	O	O	Review	20006
The state space is designed to capture similar loss curves, and to be independent of the number of workers (as much as possible).	O	O	Review	20006
A policy network is used make decisions after trained with exiting methods.	O	O	Review	20006
<sep> <sep> Numerical results validate that the RL policy improves the training time compared to BSP, ASP and SSP.	O	O	Review	20006
Different number of works and models, dataset are also tested to show the RL policy is generalizable to unseen scenario.	O	O	Review	20006
Although all the results are simulated in a controlled environment, Figure 4 gives a very interesting illustration showing the advantage of using the RL policy.	O	O	Review	20006
I still have detailed comments (see below), but I find the paper well written, and the author(s) has obtained promising results.	O	O	Review	20006
<sep> <sep> Detailed comments:	O	O	Review	20006
-<tab>The validation accuracy 88% on MINST seems pretty low to me to stop the algorithm, in particular when training multiple layer neural networks.	B-Review	B-1	Review	20006
What would happen if the accuracy is increased, can the RL approach still find a good policy?	I-Review	I-1	Review	20006
What about the validation accuracy on CIFAR-10?	I-Review	I-1	Review	20006
<sep> -<tab>I still have some concern of the computation time obtain the RL state per step.	B-Review	B-2	Review	20006
In particular, the time cost to compute the loss L on different weights w. How do you address this issue?	I-Review	I-2	Review	20006
Is L computed on the validation set?	I-Review	I-2	Review	20006
What is its size?	I-Review	I-2	Review	20006
This parameter seems to me highly sensitive when the policy is used for different dataset, in particular the dataset vary.	I-Review	I-2	Review	20006
It would be better to have more discussions in the paper or appendix.	I-Review	I-2	Review	20006
<sep> -<tab>What is the final test accuracy on the trained models using different policies?	B-Review	B-3	Review	20006
This allows us to see whether the approach has not over-fitted to the training/validation set.	I-Review	I-3	Review	20006
<sep> <sep> Some typo:	B-Review	B-4	Review	20006
Page 2 line 2 AP -&gt; ASP	I-Review	I-4	Review	20006
Page 5, last line 4: converge -&gt; convergence	I-Review	I-4	Review	20006
<sep> In the following, we list your concerns on the Problem V and our detailed responses.	O	O	Reply	20006
<sep> <sep> Problem V:	O	O	Reply	20006
The validation accuracy 88% on MINST seems pretty low to me to stop the algorithm, in particular when training multiple layer neural networks.	O	O	Reply	20006
What would happen if the accuracy is increased, can the RL approach still find a good policy?	O	O	Reply	20006
What about the validation accuracy on CIFAR-10?	O	O	Reply	20006
<sep> <sep> Response to Problem V:	O	O	Reply	20006
Thank you for your kind review.	O	O	Reply	20006
In our experimental settings, we set the validation accuracy bound to 88% as the termination condition for each testing case on the MNIST dataset.	B-Reply	B-1	Reply	20006
We elaborate the two reasons for choosing such value bound as follows.	I-Reply	I-1	Reply	20006
<sep> <sep> On one hand, taking a relative lower bound saves  evaluation time and allows us to quickly examine the performance of our proposed method.	I-Reply	I-1	Reply	20006
We observed that the accuracy of the underlying trained DNN models improves in general much slower when the accuracy value is high.	I-Reply	I-1	Reply	20006
Therefore, for large accuracy bounds, each training instance needs more time to terminate.	I-Reply	I-1	Reply	20006
In our experiments, each testing case involves running thousands of instances to train the RL policy, so we just take a relative lower accuracy bound.	I-Reply	I-1	Reply	20006
In  Ref.[Wei Dai et.al.,	I-Reply	I-1	Reply	20006
ICLR'19], a benchmark evaluation on the staleness effects,  a lower validation accuracy bound (71%) is also adopted for fast examination.	I-Reply	I-1	Reply	20006
<sep> <sep> On the other hand, we argue that the experimental results obtained on 88% are representative enough to exhibit the superiority of RLP.	I-Reply	I-1	Reply	20006
To avoid confusion, we do more testing and provide the experimental results with higher validation accuracy bounds, i.e., 92% and 95%, in the Appendix A, Page 11.	I-Reply	I-1	Reply	20006
From Figure 5 in Page 11, we find that RLP still runs much faster than BSP, ASP and SSP on higher validation accuracy bounds.	I-Reply	I-1	Reply	20006
The only difference is that the speedup ratio of RLP w.r.t.ASP decreases for higher accuracy bound.	I-Reply	I-1	Reply	20006
BSP (and SSP) increases for higher accuracy bound while the speedup ratio of RLP w.r.t.	I-Reply	I-1	Reply	20006
We explain the reasons in Appendix A, Page 11.	I-Reply	I-1	Reply	20006
In the training stage where the underlying trained models attain a high accuracy,  the gain of each iteration is already very small, so the staleness effect is not significant at this time.	I-Reply	I-1	Reply	20006
All synchronization policies will have to perform a large number of iterations to converge.	I-Reply	I-1	Reply	20006
Therefore, the best synchronization policy for this training stage is ASP, which costs less time that BSP and SSP.	I-Reply	I-1	Reply	20006
In our case, RLP is able to learn to act as ASP in this training stage.	I-Reply	I-1	Reply	20006
Observing Figure 4(d), Page 8, we find that RLP has very less synchronization barriers and acts very similar to ASP near the end of the training process.	I-Reply	I-1	Reply	20006
As a result, for higher validation accuracy bound, the time difference widens between RLP and BSP/SSP while narrows between RLP and ASP.	I-Reply	I-1	Reply	20006
<sep> <sep> For the CIFAR-10 case, our underlying DNN model has a relatively small capacity and hence cannot attain high accuracy on this more complex dataset.	I-Reply	I-1	Reply	20006
We thus set the validation accuracy bound to 35% in the generalization experiments.	I-Reply	I-1	Reply	20006
We have added into as a footnote in the paper.	I-Reply	I-1	Reply	20006

Revised Review:	O	O	Review	279
<sep> The authors have largely addressed my concerns with the revised manuscript.	B-Review	B-1	Review	279
I still have some doubts about the C > N setting (the new settings of C / N of 4 and 2 aren't C > N, and the associated results aren't detailed clearly in the paper), but I think the paper warrants acceptance.	I-Review	I-1	Review	279
<sep> <sep> Original Review:	O	O	Review	279
<sep> The paper proposes fixing the classification layers of neural networks, replacing the traditional learned affine transformation with a fixed (e.g., Hadamard) matrix.	O	O	Review	279
This is motivated by the observation that classification layers frequently constitute a non-trivial fraction of a network's overall parameter count, compute requirements, and memory usage, and by the observation that removal of pre-classification fully-connected layers has often been found to have minimal impact on performance.	O	O	Review	279
Experiments are performed on a range of datasets and network architectures, in both image classification and NLP settings.	O	O	Review	279
<sep> <sep> First, I'd like to note that the empirical component of this paper is strong: I was impressed by the breadth of architectures and settings covered, and the experiments left me reasonably convinced that the classification layer can often be fixed, at least for image classification tasks, without significant loss of accuracy.	O	O	Review	279
<sep> <sep> I have two general concerns.	B-Review	B-2	Review	279
For one, removing the fully connected classification layer is not a novel idea; All Convolutional Networks (<a href="https://arxiv.org/abs/1412.6806)" target="_blank" rel="nofollow">https://arxiv.org/abs/1412.6806)</a> reported excellent results without an additional fully connected affine transform (just a global average pooling after the last convolutional layer).	I-Review	I-2	Review	279
I think it would be worth at least referencing/discussing differences with this and other all-convolutional architectures.	I-Review	I-2	Review	279
Including a fixed Hadamard matrix for the classification layer is I believe new (although related to an existing literature on using structured matrices in neural networks).	I-Review	I-2	Review	279
<sep> <sep> However, I have doubts about the ability of the approach to scale to problems with a larger number of classes, which arguably is a primary motivation of the paper ("parameters ... grow linearly with the number of classes").	B-Review	B-3	Review	279
Specifically, the idea of using a fixed N x C matrix with C orthogonal columns (such as Hadamard) is only possible when N > C. This is a critical point: in the N > C regime, a final hidden representation with N dimensions can be chosen to achieve *any* C-dimensional output, regardless of the projection matrix used (so long as it is full rank).	I-Review	I-3	Review	279
This makes it seem fairly reasonable to me that the network can (at least approximately, and complicated by the ReLU nonlinearities) fold the "desired" classification layer into the previous layer, especially with a learned scaling and bias term.	I-Review	I-3	Review	279
In fact it's not clear to me that the fixed&nbsp;classification layer accomplishes anything here, beyond projecting from N -> C (i.e., if N = C, I'd guess it could be removed entirely similar to all convolutional nets, as long as the learned scaling and bias were retained).	I-Review	I-3	Review	279
<sep> <sep> On the other hand, when C > N, it is not possible to have mutually orthogonal columns, and in general the output is constrained to lie in an N-dimensional subspace of the overall C-dimensional output space.	B-Review	B-4	Review	279
Picking somewhat randomly a *fixed* N-dimensional subspace seems like a bad idea when N < C, since it is unlikely to select a subspace in which it is possible to adequately capture correlations between the different classes.	I-Review	I-4	Review	279
This makes the proposed technique much less appealing for precisely the family of problems where it would be most effective in reducing compute/memory requirements.	I-Review	I-4	Review	279
It also provides (in my view) a clearer explanation for the failure of the approach in the NLP setting.	I-Review	I-4	Review	279
These issues were not discussed anywhere in the text as far as I can tell, and I think it's necessary to at least acknowledge that mutually orthogonal columns can't be chosen when C > N in section 2.2 (and probably include a longer discussion on the probable implications).	I-Review	I-4	Review	279
<sep> <sep> Overall, I think the paper provides a useful observation that clearly isn't common knowledge, since classification layers persist in many popular recent architectures.	O	O	Review	279
But the notion of fixing or removing the classification layer isn't particularly novel, and I don't believe the proposed technique would scale well to settings with many classes.	B-Review	B-3	Review	279
As is I think the paper falls slightly short.	O	O	Review	279
<sep> We thank the reviewer for his detailed feedback on our paper.	O	O	Reply	279
<sep> We hope to address the 2 main concerns raised:	O	O	Reply	279
1) Novelty - "removing the fully connected classification layer is not a novel idea; All Convolutional Networks (<a href="https://arxiv.org/abs/1412.6806)" target="_blank" rel="nofollow">https://arxiv.org/abs/1412.6806)</a> reported excellent results without an additional fully connected affine transform (just a global average pooling after the last convolutional layer)"	O	O	Reply	279
<sep> We believe there is a slight misunderstanding here: in the "All convolutional networks" paper the fully-connected was not removed, as it just got replaced with a convolutional layer with the same number of parameters.	B-Reply	B-2	Reply	279
This means there is still a final classifier (a conv layer) with number of parameters proportional to the number of classes.	I-Reply	I-2	Reply	279
<sep> Our work introduces what we believe to be a novel idea - removing the classifier layer altogether making the number of network parameters independent from the number of classes.	I-Reply	I-2	Reply	279
We added a clarification to this matter in our recent revision.	I-Reply	I-2	Reply	279
<sep> <sep> 2) Applicability of our method when C > N:	O	O	Reply	279
<sep> The reviewer is right in his claim that when C > N we can not have mutually orthogonal columns, but this is true even for a fully learned weight matrix.	B-Reply	B-4	Reply	279
<sep> We empirically verified that for the vision use-cases brought in the paper we achieve good performance for C > N (e.g., on imagenet, so C=1000, with either mobilenet 0.5 where N = 512 or resnet with N reduced to 256).	I-Reply	I-4	Reply	279
<sep> We do agree with the reviewer that this can be limiting when the classes have strong correlation with one another (as in the NLP case) and we add this as another possible explanation.	I-Reply	I-4	Reply	279
We still, however, feel that this can be useful even for C > N in other domains such as vision.	I-Reply	I-4	Reply	279

This paper proposes replacing the weights of the final classifier layer in a CNN with a fixed projection matrix.	O	O	Review	279
In particular a Hadamard matrix can be used, which can be represented implicitly.	O	O	Review	279
<sep> <sep> I'd have liked to see some discussion of how to efficiently implement the Hadamard transform when the number of penultimate features does not match the number of classes, since the provided code does not do this.	B-Review	B-1	Review	279
<sep> <sep> How does this approach scale as the number of classes grows very large (as it would in language modeling, for example)?	B-Review	B-2	Review	279
<sep> <sep> An interesting experiment to do here would be to look this technique interacts with distillation, when used in the teacher or student network or both.	B-Review	B-3	Review	279
Does fixing the features make it more difficult to place dog than on boat when classifying a cat?	I-Review	I-3	Review	279
Do networks with fixed classifier weights make worse teachers for distillation?	I-Review	I-3	Review	279
<sep> <sep> We thank the reviewer for his feedback and suggestions.	O	O	Reply	279
We added an explanation as well as extended the supplementary code for the case where number of penultimate features does not match the number of classes.	B-Reply	B-1	Reply	279
<sep> We also added to the discussion the case where C > N. Regarding distillation - we found no apparent difference when distilling a network with fixed classifier.	B-Reply	B-3	Reply	279

The paper proposes to use a fixed weight matrix to replace the final linear projection in a deep neural network.	O	O	Review	279
<sep> This fixed classifier is combined with a global scaling and per output shift that are learned.	O	O	Review	279
<sep> The authors claim that this can be used as a drop in replacement for standard architectures and does not result in reduced performance.	O	O	Review	279
<sep> The key advantage is that it generates a reduction in parameters (e.g. for resent 50 8% of parameters are eliminated).	O	O	Review	279
<sep> <sep> The idea is extremely simple and I like it conceptually.	B-Review	B-1	Review	279
<sep> Currently it looks like my reimplementation on resent 50 is working.	I-Review	I-1	Review	279
<sep> I do lose a about 1% in accuracy compared to my baseline learned projection implementation.	I-Review	I-1	Review	279
<sep> Is the scale and bias regularized?	I-Review	I-1	Review	279
<sep> <sep> I have assigned a score of 6 now.	O	O	Review	279
but I will wait for my final rating when I get the actual results.	O	O	Review	279
<sep> Overall the evaluation is seems reasonably thorough many tasks were presented and the model was applied to different architectures.	O	O	Review	279
<sep> <sep> I also think the manuscript could benefit from the following experiments:	O	O	Review	279
- how does the chosen projection matrix affect performance.	B-Review	B-2	Review	279
<sep> - is the scale needed	B-Review	B-3	Review	279
I assume the authors did these experiments when they developed the method but it is unclear how important these choices are.	I-Review	I-3	Review	279
<sep> Including these experiments would make it a more scientific contribution.	I-Review	I-3	Review	279
<sep> <sep> The amount of computation saved seems rather limited?	B-Review	B-4	Review	279
Especially since the gradient of the scale parameter has to go through the weight vector?	I-Review	I-4	Review	279
<sep> Therefore my assumption is that only the application of the gradients save a limited amount of time and memory?	I-Review	I-4	Review	279
<sep> At least in my experiments reproducing these results, the computational benefit is not there/obvious.	I-Review	I-4	Review	279
<sep> <sep> While I like the idea, the way the manuscript is written is a bit strange at times.	B-Review	B-6	Review	279
<sep> The introduction appears to be there to be because you need a introduction, not to explain the background.	I-Review	I-6	Review	279
<sep> For this reason some of the cited work seems a bit out of place.	I-Review	I-6	Review	279
<sep> Especially the universal approximation and data memorization references.	I-Review	I-6	Review	279
<sep> What I find interesting is that this work is the complement of the reservoir computing/extreme learning machines approach.	I-Review	I-6	Review	279
<sep> There the final output layer is trained but the network itself uses random weights.	I-Review	I-6	Review	279
<sep> It would be nice if Fig 2 had a better caption.	O	O	Review	279
Which dataset, model, ‚Ä¶.	O	O	Review	279
Is there an intuition why the training error remains higher but the validation error is identical?	B-Review	B-5	Review	279
This is difficult to get my head round.	I-Review	I-5	Review	279
<sep> Also, it would be nice if an analysis was provided where the computational cost of not doing the gradient update was computed.	B-Review	B-6	Review	279
<sep> <sep> We thank the reviewer for his detailed feedback on our paper and his suggestions.	O	O	Reply	279
We hope to answer his questions below.	O	O	Reply	279
We also made adjustments to latest revision accordingly.	O	O	Reply	279
<sep> <sep> 1) "Are the scale and bias regularized?" -	O	O	Reply	279
Yes.	B-Reply	B-1	Reply	279
We found that regularization can help with the final validation error in the same way it helps with common learned weights.	I-Reply	I-1	Reply	279
Best results appeared when trained with weight decay for several epochs and removed later.	I-Reply	I-1	Reply	279
<sep> <sep> 2) "how does the chosen projection matrix affect performance" - We found no significance change in final accuracy when using different projection matrix.	B-Reply	B-2	Reply	279
We do find slight change in convergence rate when initial scale is changed.	I-Reply	I-2	Reply	279
<sep> <sep> 3) "is the scale needed" - We added some experiments to show that the scale is not needed as a learned parameter, but this may help convergence.	B-Reply	B-3	Reply	279
<sep> <sep> 4) "The amount of computation saved seems rather limited?" -	O	O	Reply	279
The compute saved is for the gradient of the classifier weights (which is not needed to get the gradient for the scale).	B-Reply	B-4	Reply	279
This may be limited for the cases shown, but becomes more apparent when number of classes is larger.	I-Reply	I-4	Reply	279
As we noted, these gradients and weights can now be avoided in communication over several nodes in distributed setting - saving precious bandwidth.	I-Reply	I-4	Reply	279
Moreover using a Hadamard matrix we can replace all multiplication operations preformed by the classifier with additions which are far more hardware friendly.	I-Reply	I-4	Reply	279
<sep> <sep> 5)"Is there an intuition why the training error remains higher but the validation error is identical?" -	O	O	Reply	279
Our conjecture is that with our new fixed parameterization, the network can no longer increase the norm of a given sample's representation - thus learning its label requires more effort.	B-Reply	B-5	Reply	279
As this may happen for specific seen samples - it affects only training error.	I-Reply	I-5	Reply	279
<sep> <sep> Regarding clarity and manuscript structure - we have taken the reviewer's comments into account and revised our paper accordingly.	B-Reply	B-6	Reply	279

This paper proposes an approach that uses GAN framework to generate audio through modeling log magnitudes and instantaneous frequencies with sufficient frequency resolution in the spectral domain.	O	O	Review	279
Experiments on NSynth dataset show that it gives better results then WaveNet.	O	O	Review	279
The most successful deep generative models are WaveNET,  Parallel WaveNet and Tacotran that are applied to speech synthesis, the method should be tested for speech synthesis and compared with WaveNet, Parallel WaveNet as well as Tacotran.	B-Review	B-1	Review	279
<sep> <sep> For WaveNet, the inputs are text features, but for Tacotran, the inputs are mel-spectrogram.	B-Review	B-2	Review	279
Here the inputs are log magnitudes and instantaneous frequencies.	I-Review	I-2	Review	279
So the idea is not that much new.	I-Review	I-2	Review	279
<sep> <sep> GAN has been used in speech synthesis, see	B-Review	B-3	Review	279
Statistical Parametric Speech Synthesis Incorporating Generative Adversarial Networks	I-Review	I-3	Review	279
IEEE/ACM Transactions on Audio, Speech, and Language Processing ( Volume: 26 , Issue: 1 , Jan. 2018 )	I-Review	I-3	Review	279
<sep> So for this work, GAN's application to sound generation is not new.	B-Review	B-2	Review	279
Thank you for your review.	O	O	Reply	279
We've done our best to address your concerns with paper revisions and in the comments below:	O	O	Reply	279
<sep> > ‚ÄúThe method should be tested for speech synthesis and compared with WaveNet, Parallel WaveNet as well as Tacotran‚Äù	O	O	Reply	279
<sep> We agree that it would be very interesting to adapt these methods to speech synthesis tasks, but believe that this lies outside the scope of this initial paper on adversarial audio synthesis.	B-Reply	B-1	Reply	279
As we note in AnonReviewer2‚Äôs comments, adapting the current methods to incorporate variable-length conditioning and generate variable-length sequences is a non-trivial extension and requires further research.	I-Reply	I-1	Reply	279
In the context of this study, we‚Äôve done our best to provide strong autoregressive baselines from state-of-the-art implementations of WaveNet models (including 8-bit and 16-bit output representations).	I-Reply	I-1	Reply	279
<sep> <sep> Thank you for highlighting that this is an important direction for this research.	O	O	Reply	279
We have updated the text of the paper with a paragraph highlighting the importance and difficulty of pushing the current methods forward for more general audio synthesis tasks.	O	O	Reply	279

This paper proposes a strategy to generate audio samples from noise with GANs.	O	O	Review	279
The treatment is analogous to image generation with GANs, with the emphasis being the changes to the architecture and representation necessary to make it possible to generate convincing audio that contains an interpretable latent code and is much faster than an autoregressive Wavenet based model ("Neural Audio Synthesis of Musical Notes with WaveNet AutoEncoders" - Engel et al (2017)).	O	O	Review	279
Like the other two related works (WaveGAN - "Adversarial Audio Synthesis" - Donahue et al 2018) and the Wavenet model above, it uses the NSynth dataset for its experiments.	O	O	Review	279
<sep> <sep> Much of the discussion is on the representation itself - in that, it is argued that using audio (WaveGAN) and log magnitude/phase spectrograms  (PhaseGAN) produce poorer results as compared with the version with the unrolled phase that they call 'IF' GANs, with high frequency resolution and log scaling to separate scales.	O	O	Review	279
<sep> The architecture of the network is similar to the recently published paper  (Donahue et al 2018), with convolutions and transpose convolutions adapted for audio.	O	O	Review	279
However, there seem to be two important developments.	O	O	Review	279
The current paper uses progressive growing of GANs (the current state of the art for producing high resolution images), and pitch conditioning (Odena et al, where labels are used to help training dynamics).	O	O	Review	279
<sep> <sep> For validation, the paper presents several metrics, with the recently proposed "NDB" metric figuring in the evaluations, which I think is interesting.	O	O	Review	279
The IF-Mel + high frequency resolution model seems to outperform the others in most of the evaluations, with good phase coherence and interpolation between latent codes.	O	O	Review	279
<sep> <sep> My thoughts:	O	O	Review	279
Overall, it seems that the paper's contributions are centered around the representation (with "IF-Mel" being the best).	O	O	Review	279
The architecture itself is not very different from commonly used DCGAN variants - the authors say that using PGGAN is desirable, but not critical, and the use of labels from Odena et al	O	O	Review	279
<sep> Many of my own experiments with GANs were plagued by instability (especially at higher resolution) and mode collapse problems without special treatment (largely documented, such as adding noise, adjusting learning rates and so forth).	B-Review	B-1	Review	279
To this end, what do the authors see as 'high' resolution vis a vis audio signals?	I-Review	I-1	Review	279
<sep> <sep> I am curious if we can adapt these ideas for recurrent generators as might appear in TTS problems.	B-Review	B-2	Review	279
<sep> <sep> I rate this paper as an accept since this is one of the few existing works that demonstrate successful audio generation from noise using GANs, and  owing to its novelty in exploring representation for audio.	O	O	Review	279
<sep> <sep> Thank you for your time and expertise in your review, we've addressed the key points below:	O	O	Reply	279
<sep> > ‚Äú...what do the authors see as 'high' resolution vis a vis audio signals?‚Äù	O	O	Reply	279
<sep> In the context of these audio datasets, we use ‚Äúhigh‚Äù resolution to refer more to the dimensionality of the signal to model with a single latent vector, rather than the temporal resolution of the audio.	B-Reply	B-1	Reply	279
The spectral ‚Äúimages‚Äù that GANSynth models, have 1024 frequencies, 128 timesteps, and 2 channels, [1024, 128, 2], which is roughly equivalent to a [295, 295, 3] RGB image.	I-Reply	I-1	Reply	279
This puts the task comparable to some of the higher-resolution GANs for images.	I-Reply	I-1	Reply	279
<sep> <sep> > ‚ÄúI am curious if we can adapt these ideas for recurrent generators as might appear in TTS problems.	O	O	Reply	279
‚Äú	O	O	Reply	279
<sep> We agree that would be an interesting development.	B-Reply	B-2	Reply	279
Recurrent generators, and even discriminators, would allow for variable-length sequences and variable-length conditioning as is common in speech synthesis or music generation beyond single notes.	I-Reply	I-2	Reply	279
Our initial experiments at using recurring generators were not very successful, so we opted to adopt a better tested architecture for this study, but this is definitely still an area ripe for exploration.	I-Reply	I-2	Reply	279

This is an exciting paper with a simple idea for better representing audio data so that convolutional models such as generative adversarial networks can be applied.	O	O	Review	279
The authors demonstrate the reliability of their method on a large dataset of acoustic instruments and report human evaluation metrics.	O	O	Review	279
I expect their proposed method of preprocessing audio to become standard practice.	O	O	Review	279
<sep> <sep> Why didn't you train a WaveNet on the high-resolution instantaneous frequency representations?	B-Review	B-1	Review	279
In addition to conditioning on the notes, this seems like it would be the right fair comparison.	I-Review	I-1	Review	279
<sep> <sep> I'm still not clear on unrolled phase which is central to this work.	B-Review	B-2	Review	279
If you can, spend more time explaining this in detail, maybe with examples / diagrams?	I-Review	I-2	Review	279
In figure 1,  in unrolled phase, why is time in reverse?	I-Review	I-2	Review	279
<sep> <sep> Small comments:	O	O	Review	279
<sep> - Figure 1 & 2: label the x-axis as time.	B-Review	B-3	Review	279
Makes it a lot easier to understand.	I-Review	I-3	Review	279
<sep> <sep> - I appreciate the plethora of metrics.	O	O	Review	279
The inception score you propose is interesting.	O	O	Review	279
Very cool that number of statistically-different bins tracks human eval!	O	O	Review	279
<sep> <sep> - sentence before sec 2.2, and other small grammatical mistakes.	B-Review	B-4	Review	279
Reread every sentence carefully for grammar.	I-Review	I-4	Review	279
<sep> <sep> - Figure 5 is low-res.	B-Review	B-5	Review	279
Please fix.	I-Review	I-5	Review	279
All the other figures are beautiful - nice work!	O	O	Review	279
Thank you for your time and insight in your review.	O	O	Reply	279
We've incorporated changes to the paper and respond to your main points below:	O	O	Reply	279
<sep> > ‚ÄúWhy didn't you train a WaveNet on the high-resolution instantaneous frequency representations?‚Äù	O	O	Reply	279
<sep> That‚Äôs an interesting avenue of research to explore.	B-Reply	B-1	Reply	279
We trained WaveNets on the raw audio waveforms to provide strong and proven baseline models to compare against.	I-Reply	I-1	Reply	279
Generating spectra with WaveNets is relatively unexplored and complicated by the high dimensionality at each timestep (number of frequencies * 2), each of which would have to be quantized in a traditional autoregressive treatment.	I-Reply	I-1	Reply	279
It‚Äôs quite possible that 2 dimensional convolutions and autoregression could help overcome this, but then the model would most resemble pixelCNN and be far from a proven audio generation method for a strong baseline.	I-Reply	I-1	Reply	279
<sep> <sep> > ‚ÄúI'm still not clear on unrolled phase which is central to this work.	O	O	Reply	279
If you can, spend more time explaining this in detail, maybe with examples / diagrams?	O	O	Reply	279
In figure 1,  in unrolled phase, why is time in reverse?‚Äù	O	O	Reply	279
<sep> Apologies for the confusion.	B-Reply	B-2	Reply	279
To help clarify, we‚Äôve renamed the ‚Äúunrolled‚Äù phase as ‚Äúunwrapped‚Äù throughout the paper, which is better alignment to standards in the literature and popular software packages such as Matlab and Numpy (for example <a href="https://www.mathworks.com/help/dsp/ref/unwrap.html)."	I-Reply	I-2	Reply	279
target="_blank" rel="nofollow">https://www.mathworks.com/help/dsp/ref/unwrap.html).</a> We have also added text further describing figure 1 (2nd to last paragraph of introduction) to help explain unwrapping to be the process of adding 2*Pi to the wrapped phase whenever it crosses a phase discontinuity such as to recover the monotonically increasing phase.	I-Reply	I-2	Reply	279
The time derivative of this unwrapped phase is then the radial instantaneous frequency.	I-Reply	I-2	Reply	279
<sep> <sep> > ‚ÄúFigure 1 & 2: label the x-axis as time.	O	O	Reply	279
Makes it a lot easier to understand.	O	O	Reply	279
<sep> <sep> Thank you for the helpful pointer.	B-Reply	B-3	Reply	279
We‚Äôve added time axis labels to the figures and have also labeled the interpolation amounts for the interpolation figure.	I-Reply	I-3	Reply	279
<sep> <sep> > ‚Äúsentence before sec 2.2, and other small grammatical mistakes.	O	O	Reply	279
Reread every sentence carefully for grammar.	O	O	Reply	279
‚Äù	O	O	Reply	279
<sep> We have read through the paper several times to revise grammatical mistakes including the sentence you highlighted.	B-Reply	B-4	Reply	279
<sep> <sep> > ‚ÄúFigure 5 is low-res.	O	O	Reply	279
Please fix.	O	O	Reply	279
All the other figures are beautiful - nice work!‚Äù	O	O	Reply	279
<sep> Thanks for catching this!	B-Reply	B-5	Reply	279
We‚Äôve updated the figure to be high resolution.	I-Reply	I-5	Reply	279

This paper revisits the way RL algorithms are typically evaluated on the ALE benchmark, advocating for several key changes that contribute to more robust and reliable comparisons between algorithms.	O	O	Review	10159
It also brings the following additional contributions: (1) a new measure of comparison to human performance based on actual human world records (which shows that RL algorithms are not as ¬´ super-human ¬ª as is generally believed), and (2) an evaluation (based on the proposed guidelines) of Rainbow as well as a Rainbow-IQN variant (replacing the C51 component of Rainbow with Implicit Quantile Networks), showing that the latter brings a significant improvement upon the original Rainbow algorithm.	O	O	Review	10159
<sep> <sep> Overall I am leaning towards acceptance as I believe that such papers encouraging better benchmarking practice on Atari are definitely needed.	O	O	Review	10159
Even if the technical contribution is limited, this paper could have a positive impact on the field by providing a clearer picture of the current state of deep RL algorithms on Atari (assuming that other researchers start following these recommendations -- and if that is not the case at least it will highlight issues with the way evaluation is currently done).	O	O	Review	10159
<sep> <sep> I do have a few concerns / questions though:	O	O	Review	10159
<sep> 1.	O	O	Review	10159
<tab>I am not convinced by the recommendation to use performance during training for evaluation purpose.	B-Review	B-1	Review	10159
In Machado et al (2018) it is argued that ¬´ this better aligns the performance metric with the goal of continual learning ¬ª, but most deep RL algorithms trained on Atari games have not been intended to be used in a continual learning setting.	I-Review	I-1	Review	10159
It definitely has the advantage of being simple, but it seems to me that it can cause some issues, like making it difficult to compare different exploration techniques for off-policy learning (the exploration may cause poor behavior during training even if it helps the agent learn a better greedy policy), and more generally not being representative of the common practical use case where the goal is to obtain the best agent possible to use in production (with no further learning).	I-Review	I-1	Review	10159
Finally, it could make results even harder to reproduce due to the potential high variance of an agent‚Äôs performance at a fixed # of timesteps (vs. considering the max performance it can reach over the whole period).	I-Review	I-1	Review	10159
As a result, I am currently reluctant to see the proposed performance measure become the standard evaluation metric on ALE, and I would appreciate some additional justification from the authors on this point.	I-Review	I-1	Review	10159
<sep> <sep> 2.	O	O	Review	10159
<tab>Why not suggest to remove reward clipping in the recommendations?	B-Review	B-2	Review	10159
As mentioned in Section 6, reward clipping can prevent RL algorithms from properly playing some games, and thus in my opinion should be removed if the goal is to reach the highest score possible on all games.	I-Review	I-2	Review	10159
It seems to me that the choice of clipping the reward should be part of the algorithm (if it is not able to handle the high variety of ¬´ raw ¬ª rewards) and not of the benchmark environment, thus enabling further advancements towards algorithms that are robust to a wide range of rewards.	I-Review	I-2	Review	10159
<sep> <sep> 3.	O	O	Review	10159
<tab>Why bother to keep the mean performance when, as mentioned, it is highly sensitive to outliers compared to the median?	B-Review	B-3	Review	10159
<sep> <sep> <sep> Additional remarks:	O	O	Review	10159
‚Ä¢<tab>I might have missed it but I do not see the link to the source code.	B-Review	B-4	Review	10159
Am I correct to assume it will be released, to help with reproducibility?	I-Review	I-4	Review	10159
<sep> ‚Ä¢<tab>It is not clear, when reading the paper, that the distributed version of Rainbow is actually constrained to mimic a single agent sequential algorithm in the experiments.	B-Review	B-5	Review	10159
I would suggest to remove mentions of the distributed version in the main text to avoid confusion, and mention it only in the Appendix section where it is used.	I-Review	I-5	Review	10159
<sep> ‚Ä¢<tab>The ¬´ infinite reward loop ¬ª point at the end of Section 6 does not seem relevant in the list of reasons why Deep RL algorithms are far from the best human performance, since with infinite playtime and an infinite reward loop, the algorithm should be guaranteed to outperform humans.	B-Review	B-6	Review	10159
<sep> ‚Ä¢<tab>I would have appreciated an evaluation of Rainbow-IQN with the current most commonly used evaluation schemes (e.g. the one used in the original Rainbow paper), for comparison purpose (even if such an evaluation has flaws, it is often the only performance measure available for existing deep RL algorithms)	B-Review	B-7	Review	10159
<sep> Review update: thank you for the response, I am currently keeping my "Weak accept" rating because I agree it is important to highlight and (try to) fix the problems with the way algorithms are currently evaluated on ALE, in spite of the limited technical contributions (and the fact that I remained unconvinced regarding #1)	B-Review	B-1	Review	10159
Thank you for your comments and feedback.	O	O	Reply	10159
We will try to answer to all your questions and remarks in the following.	O	O	Reply	10159
<sep> <sep> 1) Concerning the recommendation of reporting performance during training, we will base our argument on Machado et al paper where they specifically speak about "Evaluation after learning" and "Evaluation of the best policy" (page 8).	B-Reply	B-1	Reply	10159
First we think that evaluating the best policy after learning hides both the data efficiency and the stability of the algorithm.	I-Reply	I-1	Reply	10159
Indeed most paper actually do not mention when the best results were encountered.	I-Reply	I-1	Reply	10159
Finally as stated in Machado et al we think that "the best score achieved across training is a statistically biased estimate of an agent‚Äôs best performance".	I-Reply	I-1	Reply	10159
However, it could be interesting to report training performance along with a re-evaluation of the best model encountered while training.	I-Reply	I-1	Reply	10159
<sep> <sep> 2) We think that finding algorithms capable of managing high variety of rewards is still an open problem and most of algorithms are yet not suited to this.	B-Reply	B-2	Reply	10159
And as you mentioned clipping reward is an algorithmic choice, so we estimate it is out of scope of the recommendations of SABER.	I-Reply	I-2	Reply	10159
We think games on which reward clipping actually leads to sub-optimal policy are an important margin of improvement for algorithms trying to handle highly variable rewards.	I-Reply	I-2	Reply	10159
<sep> <sep> 3) We kept mean performance as most of previous works were reporting both median and mean.	B-Reply	B-3	Reply	10159
However, we think this is of limited interest and that is why all our graphics just plot the median normalized score.	I-Reply	I-3	Reply	10159
<sep> <sep> Additional remarks:	O	O	Reply	10159
‚Ä¢<tab>The source code is currently available here: <a href="https://anonymous.4open.science/r/728e379d-4d38-49e2-9dd8-bf2fb4bd4844/" target="_blank" rel="nofollow">https://anonymous.4open.science/r/728e379d-4d38-49e2-9dd8-bf2fb4bd4844/</a>	B-Reply	B-4	Reply	10159
‚Ä¢<tab>We mentioned our distributed version of Rainbow as we think this give a good value on our source code even if like you mentioned we constrained it to mimic a single agent version in our experiments.	B-Reply	B-5	Reply	10159
<sep> ‚Ä¢<tab>We have reformulate this "Infinite reward loop" section in the revision we just submitted.	B-Reply	B-6	Reply	10159
The idea we wanted to highlight there was that agents are often stuck in a loop which in many cases is a sub-optimal behavior (in fact most of Atari games incorporate a timeout when not moving along the game and Elevator Action was the only one we found with an infinite reward loop).	I-Reply	I-6	Reply	10159
<sep> ‚Ä¢<tab>Unfortunately, we did not have time nor computational resources to run Rainbow-IQN following commonly used evaluation schemes.	B-Reply	B-7	Reply	10159

The paper proposes an extension to the work of Machado et al (2018) for standardizing training and evaluation procedures in the Arcade Learning Environment (ALE).	O	O	Review	10159
It then introduces a collection of human world records for each Atari game to refute previous claims of superhuman performance, as well as recommend comparisons against these records.	O	O	Review	10159
They proceed to evaluate Rainbow under their proposed evaluation procedures, as well as introduce a new algorithm, Rainbow-IQN, with similar evaluations made based on their proposal.	O	O	Review	10159
<sep> <sep> I'm proposing a weak rejection as I feel some of the arguments made in the paper aren't very strong.	O	O	Review	10159
In particular, I'd like the authors to comment on the following:	O	O	Review	10159
<sep> 1) The key difference between their evaluation benchmark and the recommendations in Machado et al (2018) are that episodes should not have a time limit.	B-Review	B-1	Review	10159
The justification for this is that many algorithms might achieve practically optimal performance within this time limit, and so one wouldn't be able to compare algorithms on certain games within significance.	I-Review	I-1	Review	10159
They further emphasize that human high scores were achieved without limiting to 30 minutes of play.	I-Review	I-1	Review	10159
That said, several algorithms performing similarly within said limit can be instead interpreted as shifting emphasis toward comparing performance on the harder games.	I-Review	I-1	Review	10159
As the paper acknowledged, removing the maximum episode length ended up introducing more issues, such as the emulator never ending an episode (due to a supposed bug), as well as increasing the likelihood of the score overflowing.	I-Review	I-1	Review	10159
The paper suggested a trick of limiting how long an agent can go without receiving a reward, but it's unclear (1) if needing this fix is worth the proposed change, and (2) if the fix introduces additional game-specific nuances in evaluation; e.g., are there any situations where this can be detrimental to properly evaluating performance, or introduce biases based on a game's reward distribution?	I-Review	I-1	Review	10159
<sep> <sep> 2) The paper gathered a list of human world records for the Atari games in the ALE.	B-Review	B-2	Review	10159
In my opinion, this is very valuable for the literature in terms of addressing prior work misrepresenting the competency of an algorithm relative to what humans are capable of; a professional game tester is supposed to be representative of the average game player, who is typically tasked with optimizing fun, whereas speedrunners and scorerunners of games are tasked with optimizing a comparable objective to an RL agent.	I-Review	I-2	Review	10159
Beyond this though, I think an alternative conclusion would be to use this information in support of not comparing results to human scores, and to focus on comparisons between algorithms.	I-Review	I-2	Review	10159
A considerable number of the human world records have reached the maximum allowable score, over drastically variable gameplay times to achieve these scores, that it might still not be that fair a comparison.	I-Review	I-2	Review	10159
Have the authors considered this possibility?	I-Review	I-2	Review	10159
<sep> <sep> 3) Were any other algorithms evaluated on this benchmark, beyond Rainbow?	B-Review	B-3	Review	10159
While there are computational considerations, it seems odd for a benchmarking-focused paper to only evaluate one standard algorithm and slight modification of it.	I-Review	I-3	Review	10159
<sep> <sep> Suggestions	O	O	Review	10159
<sep> 1) The introduction of Rainbow-IQN in this paper feels a little random and out of place given the context created by the rest of the paper's contributions- I feel it might be more appropriate for a benchmarking paper to focus on a representative set of "standard" or relatively simple/trivial algorithms (Like Machado et al (2018) did) to give a frame of reference for comparing novel ones.	B-Review	B-4	Review	10159
Thank you for your comments and feedback.	O	O	Reply	10159
We will try to answer to all your questions and remarks in the following.	O	O	Reply	10159
<sep> <sep> 1) It is true that removing the maximum length time introduced some issues but we think those issues are easily solved with our.	B-Reply	B-1	Reply	10159
On the other hand, the fact that 2 main papers (PPO and C51) did a mistake with this parameter is a good indicator of how much such limitation is a source of error and ambiguity.	I-Reply	I-1	Reply	10159
Moreover Machado et al used only 5 minutes whereas some other papers used 30 minutes, which is an example of a comparison issue.	I-Reply	I-1	Reply	10159
<sep> Concerning the possible biases based on game's reward distribution, we actually tested both 5 and 30 minutes as maximum stuck time.	I-Reply	I-1	Reply	10159
It led to the exact same results: being stuck 5 min always meant being stuck over 30 min.	I-Reply	I-1	Reply	10159
Moreover Machado et al used 5 minutes as their max episode length, implying that 5 min is a significant unit of time for an ALE game.	I-Reply	I-1	Reply	10159
This is comforted when considering those games were designed with the patience of human players in mind.	I-Reply	I-1	Reply	10159
<sep> <sep> 2) We are not sure on how to interpret this question.	B-Reply	B-2	Reply	10159
We assume it is referring to the actual time human players played to reach the world record, typically to the fact that some famous games as Pacman and Space Invaders received much more interest than the other Atari games by the gamers community.	I-Reply	I-2	Reply	10159
This indeed can lead to world records harder to beat than others, but we still think those records are much more representative of best human capabilities than the human baseline commonly used.	I-Reply	I-2	Reply	10159
If this interpretation is wrong, could the reviewer kindly provide more details so the authors can answer accordingly?	I-Reply	I-2	Reply	10159
<sep> <sep> 3) We choose to evaluate Rainbow as it is the current state-of-the-art on Atari and thus is one of the most important to re-evaluate.	B-Reply	B-3	Reply	10159
As mentioned we had limited amount of computational resources to conduct a full Atari benchmark with other DRL algorithms.	I-Reply	I-3	Reply	10159
As a side note, even Machado et al just re-evaluated on a single DRL algorithm, DQN.	I-Reply	I-3	Reply	10159
The second algorithm evaluated didn't imply DRL and therefore was much faster to train.	I-Reply	I-3	Reply	10159
Moreover, the focus of the article is first on measuring the impact of the diverging evaluation procedures, which is detailed in section 5.1 (applied to Rainbow), rather than re-ranking existing algorithms.	I-Reply	I-3	Reply	10159

<sep> This paper proposes a new way to benchmark DRL algorithms using the Atari environment which is twofold, one part is a set of emulator recommendations, the other part is what quantity we should consider as a "human reference".	O	O	Review	10159
The paper also compares Rainbow and Rainbow-IQN, where the IQN improvement matches the proposed human normalized score improvment.	O	O	Review	10159
<sep> <sep> I'm not quite sure how to rate this paper, I have put weak-reject for now, as I don't strongly disagree with anything in the paper, but at the same time:	O	O	Review	10159
- the difference to Machados et al is marginal, but is a bit surprising	B-Review	B-1	Review	10159
- the Rainbow-IQN improvement is too incremental to be considered a significant contribution	B-Review	B-2	Review	10159
- there are some interesting remarks on why Atari is _not_ necessarily a good environment, e.g. most of Section 6, but this clashes with the paper's premise that we should be using Atari.	B-Review	B-3	Review	10159
<sep> <sep> In a way, this paper reads like an interesting technical review of Atari, but I don't think it provides enough new knowledge to be a conference paper.	B-Review	B-3	Review	10159
<sep> <sep> Detailed comments:	O	O	Review	10159
- I find it a bit weird that the many weaknesses of Atari as a platform are presented at DRL being bad at Atari.	B-Review	B-3	Review	10159
The line between environment design and algorithm design can be blurry, but in Atari's case, the weird peculiarities of each game are known to make it an inconvenient benchmark.	I-Review	I-3	Review	10159
<sep> - In the same vein, why is Atari+SABER better than other RL environments?	B-Review	B-7	Review	10159
This is rather crucial.	I-Review	I-7	Review	10159
We should only work on improving a benchmark if it is a useful benchmark, yet, we have many clues that Atari is not.	I-Review	I-7	Review	10159
<sep> - The link to TwinGalaxies should be a proper reference with the time of visit, especially if humans break new records in the future.	B-Review	B-4	Review	10159
<sep> - Why only compare Rainbow and a variant of Rainbow?	B-Review	B-5	Review	10159
I understand compute resources being a limitation, but at the same time, the reasoning behind having standardized testing is to be able to compare a wide variety of algorithms.	I-Review	I-5	Review	10159
This paper would be much stronger if it focused on a few representative games (e.g. one reflex game, one hard exploration game, etc.)	I-Review	I-5	Review	10159
and tested these games with a bunch of DRL algorithms.	I-Review	I-5	Review	10159
That ranking might reveal something very interesting.	I-Review	I-5	Review	10159
<sep> - The paper is easy to read, but there are a few grammar mistakes here and there.	B-Review	B-6	Review	10159
Thank you for your comments and feedback.	O	O	Reply	10159
We will try to answer to all your questions and remarks in the following.	O	O	Reply	10159
<sep> <sep> "the difference to Machados et al is marginal, but is a bit surprising": We think the difference with Machado et al is not marginal, because we expose a significant divergence source, the game evaluation time.	B-Reply	B-1	Reply	10159
Machado et al used a 5 minutes maximum length, to be compared with most of other works using 30 minutes.	I-Reply	I-1	Reply	10159
Moreover as mentioned in the main paper, we think this parameter is a source of ambiguity and led to mistakes even on important published papers in the field.	I-Reply	I-1	Reply	10159
<sep> <sep> "there are some interesting remarks on why Atari is not necessarily a good environment, e.g. most of Section 6": The authors are in fact convinced that Atari is a good environment for general RL and AI.	B-Reply	B-3	Reply	10159
Indeed, the Section 6 gives some hypotheses on why the RL algorithms are that bad, not that the ALE environment is.	I-Reply	I-3	Reply	10159
In fact, those remarks are even an explanation of why Atari is indeed a good environment describing its remaining difficulties and variability.	I-Reply	I-3	Reply	10159
The authors actually think that on the 3 most commonly used benchmark for DRL: ALE, DeepMind Lab and MuJoCo, ALE is the one with the most variability.	I-Reply	I-3	Reply	10159
We argue that this variability comes from the fact that those games were designed for human players and human don't like to play games that are too similar.	I-Reply	I-3	Reply	10159
In conclusion, we think that ALE is still a really interesting environment for general AI because current DRL algorithms are far from solving most of Atari games.	I-Reply	I-3	Reply	10159
<sep> <sep> "The link to TwinGalaxies should be a proper reference with the time of visit": We described all the world records we used in the Supplementary Materials, this allows easy reproducibility and comparison and avoid the cumbersome process of checking world records one by one.	B-Reply	B-4	Reply	10159
As suggested, we have specifically included the time of visit for additional clarity in the revision we just submitted.	I-Reply	I-4	Reply	10159
<sep> <sep> "This paper would be much stronger if it focused on a few representative games (e.g. one reflex game, one hard exploration game, etc.)	O	O	Reply	10159
and tested these games with a bunch of DRL algorithms": We agree it would have been really interesting to evaluate different DRL algorithms but this was not possible regarding our computational resources.	B-Reply	B-5	Reply	10159
Regarding testing on few representative games, we actually think this can bias the results and not represent the generality of the algorithm tested.	I-Reply	I-5	Reply	10159
A concurrent submission at ICLR, <a href="https://openreview.net/forum?id=BJewlyStDr" target="_blank" rel="nofollow">https://openreview.net/forum?id=BJewlyStDr</a> , actually supports our argument.	I-Reply	I-5	Reply	10159
Their abstract claims "the real pace of progress in exploration research for Atari 2600 games may have been obfuscated by good results on a single domain".	I-Reply	I-5	Reply	10159
Indeed they showed that most of advance for hard-exploration games were most of the time overfitting to Montezuma Revenge and not really leading to improvement on other hard-exploration games and often even led to lower performances on easy exploration Atari games.	I-Reply	I-5	Reply	10159

This paper presents a new discriminator metric for adversarial attack's detection by deriving the different properties of l-th neuron network layer on different adv/benign samples.	O	O	Review	251
This method can achieve good AUC score comparing to other start-of-art detection methods and also achieve good robustness under corresponding adaptive attack.	O	O	Review	251
The framework is clear and the experiment is solid.	O	O	Review	251
<sep> <sep> However, I have several concerns:	O	O	Review	251
<sep> Major:	O	O	Review	251
1.	B-Review	B-1	Review	251
It seems that the whole process assumes that there is difference for the parameters in the environment of GGD with adv/benign samples, and the goal is to search for the major components of it and use a classifier to detect.	I-Review	I-1	Review	251
To extract the approximation of parameters,  the authors use the "response entries" of l-th layer for several observations =&gt; this means the authors regard all the "response entries" of one layer as different samples on one certain GGD.	I-Review	I-1	Review	251
This makes me feel a bit tricky, and it would be great if you the authors can provide some evidence or explanation here.	I-Review	I-1	Review	251
<sep> <sep> 2.	B-Review	B-2	Review	251
In the experiment's remark, the authors mentioned that the mean parameter of GGD is set to 0 and most of them are actually close to 0 (around 1e-2) so the assumption is right.	I-Review	I-2	Review	251
However 1e-2 is not a value "very close to zero" and it would be great to show / explain the variance here.	I-Review	I-2	Review	251
<sep> <sep> 3.	B-Review	B-3	Review	251
I can't find the parameter of your evaluated attack method (like confidence, eps, etc.)	I-Review	I-3	Review	251
Please also provide experimental details for reproducibility.	I-Review	I-3	Review	251
<sep> <sep> Minor:	O	O	Review	251
<sep> Here are some reference error (e.g. P6, "For each database, as described in Section ??").	B-Review	B-4	Review	251
Please fix that.	I-Review	I-4	Review	251
<sep> <sep> Overall, this paper is a interesting based on the performance of detection.	O	O	Review	251
But the  assumptions made by the paper are a bit confusing and it would be good to clarify and provide clarification for them.	O	O	Review	251
Authors should explain the assumptions and give some extra experiment results if needed.	O	O	Review	251
<sep> <sep> We thank the reviewer for the comments and appreciation, and would like to answer the reviewer‚Äôs questions as follows:	O	O	Reply	251
Major 1.	O	O	Reply	251
<sep> Yes, we indeed assume that ‚Äúall the response entries of one layer as different samples on one certain GGD‚Äù.	B-Reply	B-1	Reply	251
However, it should be emphasized that, as demonstrated above Eq. (5), ‚Äúassume that x = {x1, ‚Ä¶, x_M} is a set of M i.i.d.	I-Reply	I-1	Reply	251
points sampled from GGD with the same shape factor‚Äù.	I-Reply	I-1	Reply	251
It means that we only assume the shape factor of GGD is same, while the parameters mean and standard deviation could be different.	I-Reply	I-1	Reply	251
Thus, we only extract the features of the magnitude of Benford-Fourier coefficient which could estimate the shape factor as the discriminative features between adversarial and benign examples.	I-Reply	I-1	Reply	251
<sep> To validate this assumption, we present hypothesis tests for both benign and adversarial examples, in Section 4.5.	I-Reply	I-1	Reply	251
As shown in Table 6, the p-values under different attacks are all over 5%, that means the hypothesis H0 is accepted, i.e., the benign/adversarial responses follow GGD with the same shape factor.	I-Reply	I-1	Reply	251
Thus, we can claim that this assumption is statistically true.	I-Reply	I-1	Reply	251
Our experimental results also support this assumption.	I-Reply	I-1	Reply	251
<sep> Finally, we try to clarify the rationale behind this assumption once again.	I-Reply	I-1	Reply	251
1) We believe the features (including the internal responses and the fully-connected features) of adversarial examples should also follow some distributions, similar to benign examples.	I-Reply	I-1	Reply	251
If not that case, it is difficult to understand/explain why the adversarial examples (generated by different attack methods and on different benign examples) could be enforced to avoid the original class (untargeted attack) or to be predicted as one certain target class (targeted attack).	I-Reply	I-1	Reply	251
2) We don‚Äôt believe that the features of adversarial and benign examples simply follow different Gaussian distributions, as the parameter mean and standard deviation of Gaussian distribution could vary significantly among different data sources and attack methods.	I-Reply	I-1	Reply	251
These adversarial examples should be similar to each other and different to benign examples at some higher-level perspectives.	I-Reply	I-1	Reply	251
Thus, we choose the GGD distribution, which is very general to cover many widely used distributions.	I-Reply	I-1	Reply	251
And, the shape factor of GGD is more robust than the mean and standard deviation, across different data sources.	I-Reply	I-1	Reply	251
This is why we propose such an assumption.	I-Reply	I-1	Reply	251
<sep> Hope above explanations could provide some informative messages to understand the proposed assumption.	I-Reply	I-1	Reply	251
<sep> <sep> Major 2.	O	O	Reply	251
<sep> Thanks for this helpful suggestion.	B-Reply	B-2	Reply	251
We do a detailed statistics of all response layers on CIFAR-10.	I-Reply	I-2	Reply	251
We find that although the mean parameters at most layers are close to 0, the mean parameters at a few layers could be large.	I-Reply	I-2	Reply	251
Specifically, for each image and each layer, we compute one mean parameter.	I-Reply	I-2	Reply	251
Then, for each layer, we compute the average and standard deviation of the mean parameters across the whole database.	I-Reply	I-2	Reply	251
The average values of all layers range from 6e-3 to 6.9, and the standard deviation of all layers range from 0 to 4.3.	I-Reply	I-2	Reply	251
However, in our experiments, the mean value is subtracted from each response entry when we extract the MBF features.	I-Reply	I-2	Reply	251
Thus, the assumption that the mean parameter of GGD is always satisfied.	I-Reply	I-2	Reply	251
This point has been clarified in the revised manuscript.	I-Reply	I-2	Reply	251
<sep> <sep> Major 3.	O	O	Reply	251
<sep> Thanks for this helpful suggestion.	B-Reply	B-3	Reply	251
In experiments, we adopt the default parameter setting in Foolbox (v1.8.0).	I-Reply	I-3	Reply	251
Specifically, the default parameters of each attack methods are:	I-Reply	I-3	Reply	251
‚ÄòBIM‚Äô(eps=0.3, stepsize=0.05, iterations=10); ‚ÄòCarliniWagnerL2Attack‚Äô(binary_search_steps=5, confidence=0, learning_rate=0.005, max_iterations=1000); ‚ÄòDeepFoolAttack‚Äô(max_steps=100); ‚ÄòRandomPGD‚Äô(epsilon=0.3, stepsize=0.01, iterations=40).	I-Reply	I-3	Reply	251
These have been clarified in the revised manuscript.	I-Reply	I-3	Reply	251
<sep> <sep> Minor 1.	O	O	Reply	251
<sep> Thanks.	B-Reply	B-4	Reply	251
It has been corrected in the revised manuscript.	I-Reply	I-4	Reply	251

This paper proposes an approach to adversarial detection.	O	O	Review	251
The approach first computes a representation of the activation layers using the Benford-Fourier coefficients.	O	O	Review	251
One then generates a range of noisy instances, and trains an SVM using those noisy instances as supervised labels (e.g., noisy instances are adversarial).	O	O	Review	251
The SVM uses the Benford-Fourier coefficients of the activation layer as the input features.	O	O	Review	251
The results show good performance against some baselines such as LID.	O	O	Review	251
<sep> <sep> I'm not really an expert in this area, but I'm a bit surprised that LID is considered the baseline to beat.	B-Review	B-1	Review	251
I imagine that most adversarial defense approaches are for robust prediction, rather than detection.	I-Review	I-1	Review	251
It also seems the authors chose to compare with defenses that are computationally cheaper (so not RCE or Defense-GAN), but a study of computational trade-offs is absent in the paper.	B-Review	B-2	Review	251
Thanks for the constructive comments.	O	O	Reply	251
<sep> 1)<tab>We should clarify that the reason we choose LID as the baseline is not the cheap computation.	B-Reply	B-1	Reply	251
The real reason is that LID can be seen one state-of-the-art adversarial detection methods, as it has been cited by 114 times since its publication at ICLR 2018, and it is compared in many recent works about adversarial detection.	I-Reply	I-1	Reply	251
Our experimental results also show that LID is the most competitive among all compared methods.	I-Reply	I-1	Reply	251
Another important reason is that LID and our MBF method share the similar idea that extracting discriminative features for detection from the responses, based on some assumptions.	I-Reply	I-1	Reply	251
LID assumes that the features of adversarial and benign have different densities, while our MBF method assumes that they follow different GGDs.	I-Reply	I-1	Reply	251
<sep> 2)<tab>In contrast, Defense-GAN is designed using a totally different philosophy with LID and our MBF method, i.e., approximating the adversarial noises using GAN.	B-Reply	B-2	Reply	251
Since the official code of Defense-GAN only supports the three datasets of MNIST, Fashion-MNIST, and CelebA, we compare with Defense-GAN on MNIST, as shown below.	I-Reply	I-2	Reply	251
There are two key hyper-parameters in Defense-GAN, including the iteration number in each GD run, and the total number of GD runs.	I-Reply	I-2	Reply	251
After trying multiple settings of these two hyper-parameters, we report the best result (evaluated by AUROC score).	I-Reply	I-2	Reply	251
Our MBF method show much better performance than Defense-GAN.	I-Reply	I-2	Reply	251
The detailed comparisons with Defense-GAN have been added in the revised manuscript.	I-Reply	I-2	Reply	251
<sep> __________________________________________________________________________________________________________	I-Reply	I-2	Reply	251
Iteration number in each GD run | Number of GD runs |  BIM  | CW-L2 | DeepFool | R-PGD	I-Reply	I-2	Reply	251
__________________________________________________________________________________________________________	I-Reply	I-2	Reply	251
200                          |                 10                | 0.744 |  0.980  |     0.702     |  0.746	I-Reply	I-2	Reply	251
__________________________________________________________________________________________________________	I-Reply	I-2	Reply	251
MBF                                  | 1.000 |  0.991  |     1.000     |  1.000	I-Reply	I-2	Reply	251
__________________________________________________________________________________________________________	I-Reply	I-2	Reply	251

This paper proposes an adversarial detection method via Fourier coefficients.	O	O	Review	251
The proposed method seems promising, and empirical evaluations are reasonable.	O	O	Review	251
<sep> <sep> However, I find that the proposed MBF detection metric is much more complicated to calculate than any of its baselines, e.g., LID or K-density.	B-Review	B-1	Review	251
So I wonder if the good performance of MBF mainly comes from its ‚Äôcomplexity‚Äò.	I-Review	I-1	Review	251
I mean, if we use the feature vectors of different layers in CNNs and combine them with a different non-linear function and feed into an SVM classifier,  can we still obtain a hard-to-evade detector?	I-Review	I-1	Review	251
I think a fair complexity is particularly important when you try to evade the detector by optimization-based adaptive attacks and claim superiority over other baselines.	B-Review	B-2	Review	251
Thanks for the constructive comments.	O	O	Reply	251
<sep> 1)<tab>The equation for computing the MBF feature, i.e., Eq. (8), may look ‚Äúcomplicated‚Äù, since it involves sin and cosine function.	B-Reply	B-1	Reply	251
But the truth is that it is rather simple, and the computational cost is only O(M_i^l) for the l-th layer of the i-th training image, with M_i^l being the number of entries in that layer.	I-Reply	I-1	Reply	251
In contrast, the features computed in LID will utilize the responses of other training images, and its computation is more complicated than ours.	I-Reply	I-1	Reply	251
<sep> 2)<tab>However, the question that whether the complexity of features is important for an effective detector is very interesting.	B-Reply	B-2	Reply	251
If we understand correctly, this sentence ‚Äúif we use the feature vectors of different layers in CNNs and combine them with a different non-linear function and feed into an SVM classifier, can we still obtain a hard-to-evade detector‚Äù is asking that whether the discriminative features included in the responses could be approximated by one additional model (e.g., the neural network).	I-Reply	I-2	Reply	251
The answer should be yes.	I-Reply	I-2	Reply	251
As mentioned in the response to Reviewer 2 (see above), Defense-GAN actually do that.	I-Reply	I-2	Reply	251
It is like to compare the hand-crafted features + shallow classifier (i.e., shallow learning) and the features learned together with the classifier (e.g., deep learning).	I-Reply	I-2	Reply	251
Both our MBF method and LID belong to the same type, while Defense-GAN belongs to the second type.	I-Reply	I-2	Reply	251
It is difficult to tell which type is better for adversarial detection.	I-Reply	I-2	Reply	251
Both of them have advantages and limitations.	I-Reply	I-2	Reply	251
The first type is computationally cheaper, as the features are computed following some fixed equations.	I-Reply	I-2	Reply	251
In contrast, the second type has to train a new model, maybe for each database and each attack method, which is rather costly.	I-Reply	I-2	Reply	251
Besides, the second type is likely to require much more training data than the first type to achieve satisfied performance, as there are much more parameters.	I-Reply	I-2	Reply	251
At least on MNIST, as shown in the response to Reviewer 2, our MBF method performs much better than Defense-GAN.	I-Reply	I-2	Reply	251
These discussions have been added into the revised manuscript.	I-Reply	I-2	Reply	251

The paper presents a generalization of the Adagrad type methods using a min-max formulation and then presents two alternate algorithms to solve this formulation.	O	O	Review	1188
<sep> <sep> It is unclear to me that much extra generalization has been achieved over the original AdaGrad paper.	B-Review	B-1	Review	1188
That paper simply presents the choice of hyperparameters as an optimal solution to a proximal primal dual formulation.	I-Review	I-1	Review	1188
The formulation presented here appears to be another form of the proximal mapping formulation, and so it is unclear what the advance here is.	I-Review	I-1	Review	1188
The AdaGrad paper used a particular Bregman divergence, and different divergences yield slightly different methods, as is observed here by the authors when they use different divergence measures.	I-Review	I-1	Review	1188
<sep> <sep> The Bregman divergences do make sense from a primal pual proximal formulation point of view, but why do you use a discrepancy function in your min-max formulation that comes from the \phi - divergence family?	B-Review	B-2	Review	1188
Why not consider an L_p normalization of the discrepancy?	I-Review	I-2	Review	1188
<sep> <sep> The difference between formulations (5) and (6) is not clearly specified.	B-Review	B-3	Review	1188
Did you mean to drop the constraints that \beta \in \cal{B}_t ?	I-Review	I-3	Review	1188
Otherwise, why is (6) , which looks to be a re-write of (5), unconstrained and hence separable?	I-Review	I-3	Review	1188
<sep> <sep> The authors claim that the method is free of parameter choices, but the initial \beta_0 seems to be a crucial parameter here since it forms both a target and a lower bound for subsequent \beta_t's.	B-Review	B-4	Review	1188
How is this parameter chosen and what effect does it have on convergence?	I-Review	I-4	Review	1188
From the results (Figs in Sec 5), this choice does significantly impact the final test loss obtained.	I-Review	I-4	Review	1188
<sep> I could not find a proof for Thm 6 in the appendix.	B-Review	B-5	Review	1188
Did I over look it or is there a typo?	I-Review	I-5	Review	1188
1) Our main contribution (or focus) of this paper is to propose a framework for adjusting learning rate adaptively.	B-Reply	B-1	Reply	1188
We offer a novel viewpoint different from previous main approaches like line search and approximate second-order methods (BBstep, Adagrad, etc.).	I-Reply	I-1	Reply	1188
<sep> 2) Compared with Bregman divergence, \phi-divergence naturally imposes nonnegative constraint about \beta and \eta_t, which is necessary for learning rates, while the L_p normalization still can‚Äôt guarantee nonnegative condition for learning rate.	B-Reply	B-2	Reply	1188
<sep> 3) Equation (6) is equivalent to (5).	B-Reply	B-3	Reply	1188
We just want to rewrite (5) to a more clear scheme.	I-Reply	I-3	Reply	1188
<sep> 4) In the classical gradient descent algorithm formulated as x_{t+1} = x_t - g_t / \beta, for small \beta, more precisely for \beta < 2 / L, the algorithm has no guarantee for convergence.	B-Reply	B-4	Reply	1188
Our framework gives a upper bound for runtime (O(1 / \varepsilon)) or regret (O(\sqrt(T))) for arbitrary \beta_0.	I-Reply	I-4	Reply	1188
Moreover, like Adagrad or gradient descent, algorithms derived from our framework also can be suggested a best initial learning rate for optimization ( based on our regret bounds).	I-Reply	I-4	Reply	1188
<sep> 5) The proof of Theorem 6 can be found in the proofs of Theorems 21, 22, and 23.	B-Reply	B-5	Reply	1188

This paper presents a method for adaptively tuning the learning rate in gradient descent methods.	O	O	Review	1188
The authors consider the formulation of each gradient descent update as a quadratic minimization problem and they propose adding a phi-divergence between the learning rate that would be used and an auxiliary vector.	O	O	Review	1188
The authors also propose adding a maximization over all learning rates in the update.	O	O	Review	1188
<sep> The authors study an important problem and propose a novel method.	O	O	Review	1188
The algorithms suggested by the author are also relatively clear, and it is great that the paper presents both theoretical results as well as numerical experiments.	O	O	Review	1188
<sep> <sep> On the other hand, I didn't find the main idea of hyper-regularization to be well-justified.	B-Review	B-1	Review	1188
It is not clear why adding an additional regularization term for the learning rate makes sense , and it is even less clear why this should be presented as a maxmin problem.	I-Review	I-1	Review	1188
This can make the update step much more complicated and is probably why the authors also propose a simpler alternating optimization algorithm as an alternative.	I-Review	I-1	Review	1188
Unfortunately, the authors do not discuss how this alternating optimization problem relates to the original one, and the theoretical guarantees are only presented for the original algorithm.	I-Review	I-1	Review	1188
The authors also do not justify the choice of phi-divergence as the regularizer for the learning rate.	B-Review	B-2	Review	1188
The theoretical guarantees in the paper also do not suggest that the algorithm presented in the paper is better than existing state-of-the-art methods, even in specific situations (i.e. the regret bounds don't appear better than the AdaGrad regret bounds).	I-Review	I-2	Review	1188
Moreover, without tests for statistical significance, I also didn't find the experimental results sufficiently compelling.	B-Review	B-3	Review	1188
<sep> <sep> Specific comments and questions:	O	O	Review	1188
1) Page 3: Equation (4): The paper would be stronger if the authors motivated why the regularization should be posed as an outer maximization.	B-Review	B-4	Review	1188
<sep> 2) Page 3: "we use the \phi-divergence as our hyper-regularization".	B-Review	B-5	Review	1188
Why is this a good choice of reuglarizer?	I-Review	I-5	Review	1188
<sep> 3) Page 3: "only a few extra calculations are required for each step".	B-Review	B-6	Review	1188
This is a misleading comment, because the maximization can be hard when phi is complicated, even if the problem splits across dimensions.	I-Review	I-6	Review	1188
<sep> 4) Page 4: "The solution of problem (5) is the same as (7) in unconstrained case".	B-Review	B-7	Review	1188
You should provide a reference for this statement as well as discuss the specific assumptions on the objective that allow you to arrive at this claim.	I-Review	I-7	Review	1188
<sep> 5) Page 4: "while the solution of (7) is more difficult to get.	B-Review	B-8	Review	1188
Thus, we choose (5) as our basic problem".	I-Review	I-8	Review	1188
This seems like a very bad motivation for choosing the maxmin formulation.	I-Review	I-8	Review	1188
For instance, the problem would be even simpler if  you didn't include this extra phi-divergence at all.	I-Review	I-8	Review	1188
<sep> 6) Page 4: "Although setting \eta-t=\beta_t is our main focus...".	B-Review	B-9	Review	1188
Why is smoothness in the learning rate a good property?	I-Review	I-9	Review	1188
<sep> 7) Page 5: Equation (11).	B-Review	B-10	Review	1188
How do these iterates relate to the ones in equation (5) (e.g. when do they coincide, if ever)?	I-Review	I-10	Review	1188
<sep> 8) Page 5: "influence the efficient of our algorithms."	B-Review	B-11	Review	1188
Grammatical error.	I-Review	I-11	Review	1188
<sep> 9) Page 6. "	B-Review	B-12	Review	1188
our algorithms are robust to the choice of initial learning rates and do not rely on the Lipschitz constant or smoothness constant".	I-Review	I-12	Review	1188
I'm not sure why this is a valuable property, since AdaGrad doesn't rely on these parameters either.	I-Review	I-12	Review	1188
<sep> 10) Page 6: Theorems 6 and 7.	B-Review	B-13	Review	1188
How do these results depend on alpha and \beta_t?	I-Review	I-13	Review	1188
This paper would be much stronger if the bounds depend on \phi more clearly and if the authors were able to show that there exist choices of phi that make this algorithm better than existing methods.	I-Review	I-13	Review	1188
<sep> 11) Page 6: Theorem 7: The dependence on G in the regret bound actually makes this worse than the AdaGrad regret bound.	B-Review	B-14	Review	1188
<sep> 12) Page 7: "KL_devergence".	B-Review	B-15	Review	1188
Typo.	I-Review	I-15	Review	1188
<sep> 13) Page 7: "different update rules were compared in advance to select the specific one for any phi divergence in the following experiments."	B-Review	B-16	Review	1188
What does this mean exactly?	I-Review	I-16	Review	1188
How much of a difference does the choice of update rule make?	I-Review	I-16	Review	1188
<sep> 14) Page 7: "growth clipping is applied to all algorithms in our framework".	B-Review	B-17	Review	1188
Why is this necessary, and how does it affect the theoretical results?	I-Review	I-17	Review	1188
<sep> 14) Page 7-8: Figures 1, 2, and 3.	B-Review	B-18	Review	1188
It's hard to interpret the significance of these results without error bars.	I-Review	I-18	Review	1188
<sep> <sep> <sep> <sep> <sep> <sep> <sep> <sep> <sep> <sep> 1) Our idea stems  from  the  work  of  Daubechies  et  al.	B-Reply	B-1	Reply	1188
(2010),  where  the  authors  adjusted  the weights of the weighted least squares problem by solving an extra objective function which added a regularizer about the weights to origin objective function.	I-Reply	I-1	Reply	1188
<sep> 2) We give theoretical analysis for both update rules (see Theorems 6 and 7) not only for the original algorithm.	B-Reply	B-1	Reply	1188
<sep> 3) Compared with Bregman divergence, \phi-divergence naturally imposes nonnegativity on \beta and \veta_t, which is necessary for learning rates.	B-Reply	B-2	Reply	1188
<sep> <sep> <sep> Specific comments and questions:	O	O	Reply	1188
<sep> 1) Since taking a convex regularization term of learning rate and viewing it as a penalty according to current learning rate, we need to regard this as a maximum problem.	B-Reply	B-4	Reply	1188
And there is little difference when adding a regularization and viewing it as a minimum problem.	I-Reply	I-4	Reply	1188
Actually, our paper proposes a framework of adaptive step size learning.	I-Reply	I-4	Reply	1188
<sep> <sep> 2)Since \phi-divergence is natural for nonnegative variable, compared with Bregman divergence, and doesn‚Äôt have to be a probability (sum is 1) compared to KL-divergence.	B-Reply	B-5	Reply	1188
<sep> <sep> 3) We have shown some common \phi-divergence and relevant update rules in Appendix D.1, and most of them seem simple to solve.	B-Reply	B-6	Reply	1188
<sep> <sep> 4) The objective functions of  problems (5) and (7) are concave for \beta and convex for x (since \beta > 0), and let the equations of both partial derivatives equal zero (it is somehow like the equation(12) ), then the solutions satisfy saddle point condition, so the solutions are identical.	B-Reply	B-7	Reply	1188
<sep> 5) We have shown in Lemma 2 that the solution of (5) can easily be extended to constrained cases.	B-Reply	B-8	Reply	1188
Moreover, in practical use, growth clipping is often necessary, which indicates constrained cases.	I-Reply	I-8	Reply	1188
Therefore, we choose maxmin formulation instead of minmax formulation.	I-Reply	I-8	Reply	1188
<sep> <sep> 6) We would like to adaptively choose the learning rate in the optimization period rather than setting priori \eta_t for \beta_t, while not on account of the smoothness.	B-Reply	B-9	Reply	1188
<sep> <sep> 7) Equation (11), got by alternating update rule, first uses recommended step size \eta to minimizes x, and then maximizes \beta to get next step size, next turn back to get x by using this step size.	B-Reply	B-10	Reply	1188
Our theorem showed the convergence bound for both methods.	I-Reply	I-10	Reply	1188
Perhaps, there is no need to show when they coincide.	I-Reply	I-10	Reply	1188
<sep> <sep> 9) First, we focus on the convergence with different choice of initial learning rate, while many methods, like GD, would fail for extremely large initial learning rate.	B-Reply	B-12	Reply	1188
However, this doesn't bother us at all since we are free of choosing the initial rate.	I-Reply	I-12	Reply	1188
Second, like GD and many other optimization methods, the choice of initial learning rate may need Lipschitz constant or smoothness constant for the sake of convergence, but in our methods, it doesn't.	I-Reply	I-12	Reply	1188
<sep> <sep> 10) We propose a novel framework on adaptively updating the learning rate with a regularization term, which we take \phi divergence as an example in the paper.	B-Reply	B-13	Reply	1188
In this way, the bounds are given for \phi divergence generally.	I-Reply	I-13	Reply	1188
Therefore, we do not make special assumptions on \alpha or \beta_t.	I-Reply	I-13	Reply	1188
<sep> <sep> 11) The bounds are given for general \phi divergence.	B-Reply	B-14	Reply	1188
Viewed as a special case of our framework with a specialized \phi divergence, AdaGrad is of no wonder to enjoy lower regret bound than the general regret bound we give.	I-Reply	I-14	Reply	1188
<sep> <sep> 13) Due to the space limitation, our description may mislead you.	B-Reply	B-16	Reply	1188
Given a \phi divergence, we totally have three different ways on how to update x_t and \beta_t alternately, corresponding to Algorithms 1 and 2 in page 5, and Algorithm 3 in Appendix C. Actually, we should not mention Algorithm 1 here, for it is shown in Appendix D.1 that Algorithm 1 is always computationally unfriendly.	I-Reply	I-16	Reply	1188
As shown in Figure 1, Algorithm 2 outperforms Algorithm 3 when the initial learning rate is extremely large.	I-Reply	I-16	Reply	1188
However, at their best initial learning rates, their performance is comparable.	I-Reply	I-16	Reply	1188
Out of the consideration on training stability with large initial learning rate, we finally choose the second update rule corresponding to Algorithm 2.	I-Reply	I-16	Reply	1188
<sep> <sep> 14) Growth clipping does not affect the theoretical result, since it is only applied to the algorithms in the experiment.	B-Reply	B-17	Reply	1188
The practical optimization problem neither generally guarantees the gradient smoothness, nor guarantees the global strong convexity.	I-Reply	I-17	Reply	1188
So it is necessary to apply growth clipping in case of training collapses due to the stochastic gradient.	I-Reply	I-17	Reply	1188
<sep> <sep> 15)Figure 2 describes the results of experiments carried out in the full gradient setting.	B-Reply	B-18	Reply	1188
Since there is no randomness, it is of no use to carry out duplicated experiments.	I-Reply	I-18	Reply	1188

Summary:	O	O	Review	1188
%%%%%%%%%%%%%%%	O	O	Review	1188
The paper explores ways to adapt the learning rate rule through a new minimax formulation.	O	O	Review	1188
<sep> The authors provide regret bounds for their method in the online convex optimization setting.	O	O	Review	1188
<sep> <sep> Comments:	O	O	Review	1188
%%%%%%%%%%%%%%%	O	O	Review	1188
-I found the motivation of the approach to be very lacking.	B-Review	B-1	Review	1188
<sep> Concretely, it is not clear at all why the minimax formulation even makes sense, and the authors do not explain this issue.	I-Review	I-1	Review	1188
<sep> <sep> -While the authors provide regret guarantees for their method, the theoretical analysis does not reflect when is their approach  beneficial compared to standard adaptive methods.	B-Review	B-2	Review	1188
Concretely, their bounds compare with the well known bounds of AdaGrad.	I-Review	I-2	Review	1188
<sep> It is nice that their approach enables to extract AdaGrad as a private case.	I-Review	I-2	Review	1188
But again, it is not clear what is the benefit of their extension.	I-Review	I-2	Review	1188
<sep> <sep> -Finally, the experiments do not illustrate almost any benefit of the new approach compared to standard adaptive methods.	B-Review	B-3	Review	1188
<sep> <sep> <sep> Summary	O	O	Review	1188
%%%%%%%%%%%%%%%	O	O	Review	1188
The paper suggests a different approach to adapt the learning rate.	O	O	Review	1188
<sep> Unfortunately, the reasoning behind the new approach is not very clear.	B-Review	B-4	Review	1188
<sep> Also, nor theory neither experiments illustrate the benefit of this new approach over standard methods.	B-Review	B-5	Review	1188
<sep> <sep> 1) Our main contribution (or focus) of this paper is to propose a framework for adjusting learning rate adaptively.	B-Reply	B-1	Reply	1188
We offer a novel viewpoint different from previous main approaches like line search and approximate second-order methods (BBstep, Adagrad, etc.).	I-Reply	I-1	Reply	1188
<sep> <sep> 2) Our idea stems  from  the  work  of  Daubechies  et  al.	B-Reply	B-3	Reply	1188
(2010),  where  the  authors  adjusted  the weights of the weighted least squares problem by solving an extra objective function which added a regularizer about the weights to origin objective function.	I-Reply	I-3	Reply	1188
<sep> <sep> 3) Since our framework can derive AdaGrad as a private case, we are more general scene so our bound doesn‚Äôt better than AdaGrad.	B-Reply	B-2	Reply	1188
However, our bound are almost same as AdaGrad.	I-Reply	I-2	Reply	1188

[Summary]	O	O	Review	986
<sep> This paper presents an interesting idea that to append the agent's action space with the expert's most frequent action pairs, by which the agent can perform better exploration as to achieve the same performance in a shorter time.	O	O	Review	986
The authors show performance gain by comparing their method with two baselines - Dagger and InfoGAIL.	O	O	Review	986
<sep> <sep> <sep> [Stengths]	O	O	Review	986
<sep> The proposed method is simple yet effective, and I really like the analogy to mini-moves in sports as per the motivation section.	O	O	Review	986
<sep> <sep> <sep> [Concerns]	O	O	Review	986
<sep> - How to choose the number and length of the action sequences?	B-Review	B-1	Review	986
<sep> The authors empirically add the same number of expert's action sequences as the basic ones and select the length k as 2.	I-Review	I-1	Review	986
However, no ablation studies are performed to demonstrate the sensitivity of the selected hyperparameters.	I-Review	I-1	Review	986
Although the authors claim that "we limit the size of meta-actions k to 2 because large action spaces may lead to poor convergence", a more systematic evaluation is needed.	I-Review	I-1	Review	986
How will the performance change if we add more and longer action sequences?	I-Review	I-1	Review	986
When will the performance reach a plateau?	I-Review	I-1	Review	986
How does it vary between different environments?	I-Review	I-1	Review	986
<sep> <sep> - Analysis of the selected action sequences.	B-Review	B-2	Review	986
<sep> It might be better to add more analysis of the selected action sequences.	I-Review	I-2	Review	986
What are the most frequent action pairs?	I-Review	I-2	Review	986
How does it differ from game to game?	I-Review	I-2	Review	986
What if the action pairs are selected in a random fashion?	I-Review	I-2	Review	986
<sep> <sep> - Justification of the motivation	B-Review	B-3	Review	986
The major motivation of the method is to release the burden of memory overheads.	I-Review	I-3	Review	986
However, no quantitative evaluations are provided as to justify the claim.	I-Review	I-3	Review	986
Considering that the input images are resized to 84x84, storing them should not be particularly expensive.	I-Review	I-3	Review	986
<sep> <sep> - The choice of baseline.	B-Review	B-4	Review	986
<sep> InfoGAIL (Li et al 2017) is proposed to identify the latent structures in the expert's demonstration, hence it is not clear to me how it suits the tasks in the paper.	I-Review	I-4	Review	986
The paper also lacks details describing how they implemented the baselines, e.g. beta in Dagger and the length of the latent vector in InfoGAIL.	I-Review	I-4	Review	986
<sep> <sep> - The authors only show experiments in Atari games, where the action space is discrete.	B-Review	B-5	Review	986
It would be interesting to see if the idea can generalize to continuous action space.	I-Review	I-5	Review	986
Is it possible to cluster the expert action sequences and form some basis for the agent to select?	I-Review	I-5	Review	986
<sep> <sep> - Typos	B-Review	B-6	Review	986
{LRR, RLR/RRL} --> {LRR, RLR, RRL}	I-Review	I-6	Review	986
sclability --> scalability	I-Review	I-6	Review	986
we don't need train a ... --> we don't need to train a ...	I-Review	I-6	Review	986
Atmost --> At most	I-Review	I-6	Review	986
<sep> <sep> [Recommendation]	O	O	Review	986
<sep> The idea presents in the paper is simple yet seemingly effective.	O	O	Review	986
However, the paper lacks a proper evaluation of the proposed method, and I don't think this paper is ready with the current set of experiments.	B-Review	B-7	Review	986
I will decide my final rating based on the authors' response to the above concerns.	O	O	Review	986
Q1.	O	O	Reply	986
Action triplets are inconsistent and statistically insignificant with limited demonstration: Our focus was on using very limited (small) demonstration.	B-Reply	B-1	Reply	986
The number of episodes that we use is quite small (25 episodes each with actions ranging from 700 to 7000) as we wanted very limited demonstration.	I-Reply	I-1	Reply	986
We observe that with such limited demonstration, only action-pairs are reliable.	I-Reply	I-1	Reply	986
An expert should be consistent with the frequent action pairs/triplets over a set of episodes.	I-Reply	I-1	Reply	986
In our analysis, we found that the frequent action pairs are consistent after 12 hrs, 13 hrs, 14 hrs and 15 hrs of training the expert network.	I-Reply	I-1	Reply	986
The action pairs at different time instants in training were just permutations of each other.	I-Reply	I-1	Reply	986
The same was not true for action triplets.	I-Reply	I-1	Reply	986
Furthermore, for the game FishingDerby with 18 basic actions, the top 18 action pairs account for 33.85% of all the action-pairs in the 25 expert episodes.	I-Reply	I-1	Reply	986
The top 18 action triplets account to just 7.36% of the all triplets in the same 25 episodes.	I-Reply	I-1	Reply	986
Even for other games, we have similar discrepancy for action pairs vs triplets (DemonAttack-27.21% vs 8.87%, Asteroids-21.67% vs 6.37%, Atlantis 31.32% vs 9.61%, SpaceInvaders-28.82% vs 10.24%, BeamRider-14.78% vs 2.81%, TimePilot-15.41% vs 2.05%, Qbert-67% vs 51%).	I-Reply	I-1	Reply	986
We still experimented with 3-step actions and noticed that for Atlantis, action triplets outperform action-pairs which Is great.	I-Reply	I-1	Reply	986
But for other games, action-triplets perform worse than action-pairs.	I-Reply	I-1	Reply	986
<sep> <sep> Q2.	O	O	Reply	986
Thank you for the suggestion.	B-Reply	B-2	Reply	986
It is an interesting exercise to interpret frequent action pairs.	I-Reply	I-2	Reply	986
<sep> <sep> Q3.	O	O	Reply	986
The memory advantage of our approach is quite straight forward.	B-Reply	B-3	Reply	986
Out of all imitation baseline, only our method does not need to store state information at all.	I-Reply	I-3	Reply	986
Even when we are resizing images to 84*84*4, we need several thousands of those images to get noticeable advantage when compared to having no information at all.	I-Reply	I-3	Reply	986
<sep> <sep> Q4.	O	O	Reply	986
InfoGAIL in one of the most recent techniques in Imitation Learning.	B-Reply	B-4	Reply	986
Hence, we wanted to compare against InfoGAIL and ensure that we are not missing any subtleties.	I-Reply	I-4	Reply	986
For our Dagger implementation, we used the simple parameter free version of beta=Indicator(i=1), i.e., 1 for the first episode and then 0 from the second episode.	I-Reply	I-4	Reply	986
<sep> <sep> Q5.	O	O	Reply	986
Thanks for the great suggestion!	B-Reply	B-5	Reply	986
We were intending to explore this direction in future on continuous action spaces by binning continuous values to discrete.	I-Reply	I-5	Reply	986
<sep> <sep> Thank you for spotting typos, we have corrected them in the current version.	B-Reply	B-6	Reply	986
Since our idea is simple and very effective, it needs more visibility so that more investigation can be made on this idea.	B-Reply	B-7	Reply	986
Simplicity is the very reason why we can beat GA3C by significant margin.	I-Reply	I-7	Reply	986
If the idea is not computationally simple, most likely it won‚Äôt beat GA3C (a highly optimized implementation on GPUs) on running time.	I-Reply	I-7	Reply	986
We hope you will change your opinion about the overall score.	I-Reply	I-7	Reply	986

The paper proposes an idea of using the most frequent expert action sequence to assist the novice, which, as claimed, has lower memory overhead than other imitation learning methodologies.	O	O	Review	986
The authors present comparison of their proposed method with state-of-the-art and show its superior performance.	O	O	Review	986
However I do have the following few questions.	O	O	Review	986
<sep> <sep> 1.	O	O	Review	986
The proposed method requires a long time of GA3C training.	B-Review	B-1	Review	986
How is that a fair comparison in Figure 2, where proposed method already has a lead over GA3C?	I-Review	I-1	Review	986
It could be argued that it's not using all of the training outcome, but have the authors considered other form of experts and see how that works?	I-Review	I-1	Review	986
<sep> <sep> 2.	O	O	Review	986
The authors claimed one of the advantages of their method is reducing the memory overhead.	B-Review	B-2	Review	986
Some supporting experiments will be more convincing.	I-Review	I-2	Review	986
<sep> <sep> 3.	B-Review	B-3	Review	986
In Figure 3, atlantis panel, the score shows huge variance, which is not seen in Figure 2.	I-Review	I-3	Review	986
Are they generated from the same runs?	I-Review	I-3	Review	986
Could the authors give some explanation on the phenomenon in Figure 3?	I-Review	I-3	Review	986
<sep> <sep> Overall, I think the paper has an interesting idea.	O	O	Review	986
But the above unresolved questions raises some challenge on its credibility and reproducibility.	O	O	Review	986
Q1.	O	O	Reply	986
We would like to stress that our setting, also clearly mentioned in the paper at several places, is standard imitation learning setting, where access to expert information is given input to the algorithm.	B-Reply	B-1	Reply	986
We do not need any GA3C training.	I-Reply	I-1	Reply	986
It is a proxy to generate very few expert action sequences.	I-Reply	I-1	Reply	986
For the other imitation learning baselines, the same pretrained GA3C training is used as a proxy for expert.	I-Reply	I-1	Reply	986
Hence, it is a fair comparison.	I-Reply	I-1	Reply	986
<sep> <sep> Q2.	O	O	Reply	986
The memory advantage of our approach is quite straight forward.	B-Reply	B-2	Reply	986
Out of all imitation baseline, only our method does not need to store state information at all.	I-Reply	I-2	Reply	986
We only need few action sequences for ~25 episodes (each with a few 1000 integers) which takes trivially low memory.	I-Reply	I-2	Reply	986
On the other hand, to store any reasonable (say 10000) state-action pairs of an expert in an environment, we will need at least 4032MB memory.	I-Reply	I-2	Reply	986
Please note that each state is an image is originally 210*160*3 dimensional.	I-Reply	I-2	Reply	986
<sep> <sep> Q3.	O	O	Reply	986
As we understand, you‚Äôre concerned about difference in variance when we plot episode-wise and time-wise.	B-Reply	B-3	Reply	986
Please note that we ran all the 5 runs of each game for 15 hrs.	I-Reply	I-3	Reply	986
But the number of episodes in each run is different.	I-Reply	I-3	Reply	986
For Atlantis game, the number of episodes range between 9114 to 10366.	I-Reply	I-3	Reply	986
In our episode-wise plots, we only show the mean and variance of first 9114 episodes for each run.	I-Reply	I-3	Reply	986
Hence, even though the time-wise and episode-wise plots are generated from the same output, the variance is higher for episode-wise plot.	I-Reply	I-3	Reply	986
This is more glaring on Atlantis game as our idea gets much higher score than the baselines.	I-Reply	I-3	Reply	986
<sep> <sep> We believe we have answered all your questions.	B-Reply	B-4	Reply	986
If you have any questions on reproducibility, we‚Äôve our code ready for release once the review period is over.	I-Reply	I-4	Reply	986
Since our idea is simple and very effective, it needs more visibility so that more investigation can be made on this idea.	I-Reply	I-4	Reply	986
Simplicity is the very reason why we can beat GA3C by significant margin.	I-Reply	I-4	Reply	986
If the idea is not computationally simple, most likely it won‚Äôt beat GA3C (a highly optimized implementation on GPUs) on running time.	I-Reply	I-4	Reply	986
We hope you will change your opinion about the overall score.	I-Reply	I-4	Reply	986

The paper describes an imitation reinforcement learning approach where	O	O	Review	986
the primitive actions of the agent are augmented with the most common	O	O	Review	986
sequences of actions perform by experts.	O	O	Review	986
It is experimentally shown	O	O	Review	986
how this simple change has clear improvements in the performance of	O	O	Review	986
the system in Atari games.	O	O	Review	986
In practice, the authors double the number	O	O	Review	986
of primitive actions with the most frequent double actions perform by	O	O	Review	986
experts.	O	O	Review	986
<sep> <sep> A positive aspect of this paper comes from the simplicity of the	O	O	Review	986
idea.	O	O	Review	986
There are however several issues that should be taken into	O	O	Review	986
account:	O	O	Review	986
- It is not clear how to determine when the distribution of action	B-Review	B-1	Review	986
pair saturates.	I-Review	I-1	Review	986
This is relevant for the use of the proposed approach.	I-Review	I-1	Review	986
<sep> - The total training time should consider both the initial time to	B-Review	B-2	Review	986
obtain the extra pairs of frequent actions plus the subsequent	I-Review	I-2	Review	986
training time used by the system.	I-Review	I-2	Review	986
Either obtained from a learning	I-Review	I-2	Review	986
system (15 hours) or by collecting traces of human experts (< 1	I-Review	I-2	Review	986
hour?).	I-Review	I-2	Review	986
<sep> - It would be interesting to see the performance of the system with	B-Review	B-3	Review	986
all the possible pairs of primitive actions and with a random subset	I-Review	I-3	Review	986
of these pairs, to show the benefits of choosing the most frequent	I-Review	I-3	Review	986
pairs used by the expert.	I-Review	I-3	Review	986
<sep> - This analysis could be easily extended to triplets and so on, as	B-Review	B-4	Review	986
long as they are the most frequently used by experts.	I-Review	I-4	Review	986
<sep> - The inclusion of macro-actions has been extensively studied in	B-Review	B-5	Review	986
search algorithms.	I-Review	I-5	Review	986
In general, the utility of those macros depends on	I-Review	I-5	Review	986
the effectiveness of the heuristic function.	I-Review	I-5	Review	986
Perhaps the authors	I-Review	I-5	Review	986
could revise some of the literature.	I-Review	I-5	Review	986
<sep> - Choosing the most frequent pairs in all the game may not be a	B-Review	B-6	Review	986
suitable strategy.	I-Review	I-6	Review	986
Some sequences of actions may be more frequent	I-Review	I-6	Review	986
(important) at certain stage of the game (e.g., at the beginning/end	I-Review	I-6	Review	986
of the game) and the most frequent sequences over all the game may	I-Review	I-6	Review	986
introduce additional noise in those cases.	I-Review	I-6	Review	986
<sep> <sep> The paper is well written and easy to follow, there are however, some	B-Review	B-7	Review	986
small typos:	I-Review	I-7	Review	986
- expert(whose => expert (whose	I-Review	I-7	Review	986
% there are several places where there is no space between a word and	I-Review	I-7	Review	986
% its following right parenthesis	I-Review	I-7	Review	986
- don't need train => don't need to train	I-Review	I-7	Review	986
- experiments4.	I-Review	I-7	Review	986
=> experiments.	I-Review	I-7	Review	986
<sep> - Atmost => At most	I-Review	I-7	Review	986
<sep> Please check the updated figures in our paper that include the comparison of a random subset of action pairs vs the most frequent action pairs (the line in magenta).	O	O	Reply	986
The new plots strengthen our proposal that the most-frequent action pairs have useful information.	O	O	Reply	986
<sep> <sep> Q1.	B-Reply	B-1	Reply	986
Ideally, an expert should be consistent with the action pair distribution over a set of few episodes.	I-Reply	I-1	Reply	986
In our analysis, we found that the frequent action pairs after 12 hrs, 13 hrs, 14 hrs and 15 hrs of training the expert network are consistent.	I-Reply	I-1	Reply	986
Hence, it is evident that after training the expert network for reasonable time, the top action pairs saturate.	I-Reply	I-1	Reply	986
We have made our choice more concrete by training all expert networks for 15 hrs.	I-Reply	I-1	Reply	986
<sep> <sep> Q2.	O	O	Reply	986
As mentioned in the paper, imitation learning algorithms presume that the expert information is available beforehand.	B-Reply	B-2	Reply	986
We just substitute human data with a pre-trained network.	I-Reply	I-2	Reply	986
Collecting traces of human data is a fast and viable but it is highly dependent on the task/game.	I-Reply	I-2	Reply	986
In our case, assuming access to expert action sequences, calculating the frequency distribution and obtaining top action sequences is a trivial task with few seconds of time.	I-Reply	I-2	Reply	986
<sep> <sep> Q3.	B-Reply	B-3	Reply	986
Please check the new plots for random subset of action-pairs.	I-Reply	I-3	Reply	986
As for adding all possible action-pairs, the action space grows exponentially, and the network must classify lot more classes with the same information.	I-Reply	I-3	Reply	986
With games like FishingDerby and Asteroids (18 and 14 actions), it become too hard for network to classify hundreds of classes with same information.	I-Reply	I-3	Reply	986
<sep> <sep> Q4.	O	O	Reply	986
Action triplets are inconsistent and statistically insignificant with limited demonstration: Our focus was on using very limited (small) demonstration.	B-Reply	B-4	Reply	986
The number of episodes that we use is quite small (25 episodes each with actions ranging from 700 to 7000) as we wanted very limited demonstration.	I-Reply	I-4	Reply	986
We observe that with such limited demonstration, only action-pairs are reliable.	I-Reply	I-4	Reply	986
The frequent action triplets after 12 hrs, 13 hrs, 14 hrs and 15 hrs of training expert network are different each time.	I-Reply	I-4	Reply	986
Furthermore, for the game FishingDerby with 18 basic actions, the top 18 action pairs account for 33.85% of all the action-pairs in the 25 expert episodes.	I-Reply	I-4	Reply	986
The top 18 action triplets account to just 7.36% of the all triplets in the same 25 episodes.	I-Reply	I-4	Reply	986
Even for other games, we have similar discrepancy for action pairs vs triplets (DemonAttack-27.21% vs 8.87%, Asteroids-21.67% vs 6.37%, Atlantis 31.32% vs 9.61%, SpaceInvaders-28.82% vs 10.24%, BeamRider-14.78% vs 2.81%, TimePilot-15.41% vs 2.05%, Qbert-67% vs 51%).	I-Reply	I-4	Reply	986
We still experimented with 3-step actions and noticed that for Atlantis, action triplets outperform action-pairs which Is great.	I-Reply	I-4	Reply	986
But for other games, action-triplets perform worse than action-pairs.	I-Reply	I-4	Reply	986
<sep> <sep> Q5.	O	O	Reply	986
Thank you for the suggestion.	B-Reply	B-5	Reply	986
We‚Äôll investigate search algorithms in the future to identify informative action-sequences.	I-Reply	I-5	Reply	986
One class of models that we mentioned in the paper is ‚ÄòOptions Framework‚Äô.	I-Reply	I-5	Reply	986
The main drawback of Options Framework is that we need human designed options.	I-Reply	I-5	Reply	986
Our work is a generic way of identifying options.	I-Reply	I-5	Reply	986
<sep> <sep> Thank you for spotting typos.	B-Reply	B-7	Reply	986
We have fixed them in the latest revision.	I-Reply	I-7	Reply	986

Thanks for submitting your paper.	O	O	Review	1623
It takes a lot of effort and courage to put your ideas out into the world.	O	O	Review	1623
Sometimes the hardest work for researchers is conveying their thoughts to others in a manner in which those ideas can be understood.	O	O	Review	1623
<sep> <sep> With that in mind, I had an extremely difficult time following your arguments.	O	O	Review	1623
<sep> <sep> I noticed several things:	O	O	Review	1623
- There are numerous places in the text that lack proper citation, or are cited improperly.	B-Review	B-1	Review	1623
<sep> <sep> - Why was there not a related methods section?	B-Review	B-2	Review	1623
I find it hard to believe that all of your ideas have no precursor.	I-Review	I-2	Review	1623
<sep> <sep> - When there are citations, there is usually only one text and it is quite old.	B-Review	B-3	Review	1623
For example, all of your neuroscience citations reference a work that is almost 40 years old.	I-Review	I-3	Review	1623
There have been quite a few improvements in our biological understanding as well as theoretical understanding since then. (	I-Review	I-3	Review	1623
I make this point as a common justification used in the manuscript is that the method describes how synapses function in biology. )	I-Review	I-3	Review	1623
<sep> <sep> - There is a claim regarding how this can be used in fintech.	B-Review	B-4	Review	1623
This statement doesn't belong in this work.	I-Review	I-4	Review	1623
<sep> <sep> - There are many different equations given throughout the text.	B-Review	B-5	Review	1623
Some of these equations come from areas like physics or information theory, and others seem to be of your own design.	I-Review	I-5	Review	1623
Regarding the latter, there is no justification or explanation for the origin of the equations.	I-Review	I-5	Review	1623
Regarding the former, if you are using equations from lots of different fields, or even field you think part of your audience might not be familiar with, you should, at the very least, include a some description of the algorithm or intuition as to why it is being leveraged.	I-Review	I-5	Review	1623
<sep> <sep> - It wasn't clear from your diagrams or your descriptions what the difference between a synapse and a neuron was in your architecture.	B-Review	B-6	Review	1623
It seemed like the name was used interchangeably in some areas, but then had a strict definition in others.	I-Review	I-6	Review	1623
<sep> <sep> - I was also not able to understand how the excitatory and the inhibitory connections that were to enter each neuron were connected to the previous layer of the network.	B-Review	B-7	Review	1623
Is a link between neurons in Figure 2 actually two links?	I-Review	I-7	Review	1623
If this is the case, then it is a direct violation of Dale's law.	I-Review	I-7	Review	1623
Again, I only mention this because most arguments seem to be of the form "this is correct because it is how it is done biologically".	I-Review	I-7	Review	1623
<sep> <sep> - There were a few claims made in the paper that were completely unsubstantiated.	B-Review	B-8	Review	1623
A good example of this was in the conclusion section part ii) where it was stated that "using a large number of synapses and neurons SynaNN can solve the complex problems in the real world."	I-Review	I-8	Review	1623
<sep> <sep> - Also, the last sentence of the conclusion was not discussed anywhere in the rest of the paper.	B-Review	B-9	Review	1623
Nor was the statement itself supported except with a single citation and no description.	I-Review	I-9	Review	1623
<sep> <sep> Regarding the empirical testing of your algorithm, I was very dissapointed to see that the only dataset it was tested against was MNIST.	B-Review	B-10	Review	1623
Furthermore there was absolutely no benchmarking against other comparative algorithms.	I-Review	I-10	Review	1623
At the very least I would have expected a comparison to the perceptron algorithm that you use as inspiration, but that would also still not have been enough.	I-Review	I-10	Review	1623
<sep> <sep> This paper needs heavy amounts of work to make it understandable.	O	O	Review	1623
Once it is understandable an attempt to evaluate the merit of the scientific contribution would then be possible.	O	O	Review	1623
Thanks to your suggestion to do a comparison testing.	O	O	Reply	1623
<sep> <sep> We have done two MLP tests in the same configuration of Keras/Tensorflow python code.	B-Reply	B-10	Reply	1623
<sep> The only difference is to replace Dense layer by Synapse layer in the hidden layer.	I-Reply	I-10	Reply	1623
Both the input layer and output layer are Dense.	I-Reply	I-10	Reply	1623
<sep> <sep> Keras/Synapse:	I-Reply	I-10	Reply	1623
Test loss: 0.09429045873575433	I-Reply	I-10	Reply	1623
Test accuracy: 0.9802000087499618	I-Reply	I-10	Reply	1623
<sep> Keras/Dense:	I-Reply	I-10	Reply	1623
Test loss: 0.09061271685754718	I-Reply	I-10	Reply	1623
Test accuracy: 0.9830000066757202	I-Reply	I-10	Reply	1623
<sep> The accuracy is not such a disappointment.	I-Reply	I-10	Reply	1623
Everybody, including us, has thought MLP can achieve 99% in any way.	I-Reply	I-10	Reply	1623
In our testing, without BatchNormlization, it is even hard to achieve 98%.	I-Reply	I-10	Reply	1623
This reminds us many disappoint results on MNIST from other models such as Spike Neural Network.	I-Reply	I-10	Reply	1623
The intrinsic limitation of MLP may be the reason for the poor results.	I-Reply	I-10	Reply	1623
The model itself is not wrong.	I-Reply	I-10	Reply	1623
<sep> <sep> Below is the configuration.	I-Reply	I-10	Reply	1623
<sep> <sep> Using TensorFlow backend.	I-Reply	I-10	Reply	1623
<sep> 60000 train samples	I-Reply	I-10	Reply	1623
10000 test samples	I-Reply	I-10	Reply	1623
_________________________________________________________________	I-Reply	I-10	Reply	1623
Layer (type)                 Output Shape              Param #	I-Reply	I-10	Reply	1623
=================================================	I-Reply	I-10	Reply	1623
dense_1 (Dense)              (None, 300)             235500	I-Reply	I-10	Reply	1623
_________________________________________________________________	I-Reply	I-10	Reply	1623
batch_normalization_1 (Batch (None, 300)   1200	I-Reply	I-10	Reply	1623
_________________________________________________________________	I-Reply	I-10	Reply	1623
activation_1 (Activation)    (None, 300)           0	I-Reply	I-10	Reply	1623
_________________________________________________________________	I-Reply	I-10	Reply	1623
synapse_1 (Synapse)          (None, 300)          90000	I-Reply	I-10	Reply	1623
_________________________________________________________________	I-Reply	I-10	Reply	1623
batch_normalization_2 (Batch (None, 300)   1200	I-Reply	I-10	Reply	1623
_________________________________________________________________	I-Reply	I-10	Reply	1623
dense_2 (Dense)              (None, 10)                3010	I-Reply	I-10	Reply	1623
=================================================	I-Reply	I-10	Reply	1623
Total params: 330,910	I-Reply	I-10	Reply	1623
Trainable params: 329,710	I-Reply	I-10	Reply	1623
Non-trainable params: 1,200	I-Reply	I-10	Reply	1623
_________________________________________________________________	I-Reply	I-10	Reply	1623
Train on 60000 samples, validate on 10000 samples	I-Reply	I-10	Reply	1623
Epoch 1/30	I-Reply	I-10	Reply	1623

The authors propose a hybrid neural network, composed of a synapse graph that can be embedded into and a standard neural network, such that the entire architecture can be trained in a way that is compatible with the gradient descent and backpropagation of.	O	O	Review	1623
As a proof of concept, the hybrid architecture is trained to classify MNIST.	O	O	Review	1623
<sep> <sep> I am not convinced by the way this work is motivated.	B-Review	B-1	Review	1623
What problem are the authors actually addressing?	I-Review	I-1	Review	1623
Just because biological neurons use synapses does not mean we should try hard to put a certain instance of them into deep neural networks.	I-Review	I-1	Review	1623
Clearly this is not an attempt to add to neuroscience, as beyond the inspiration of neurons having synapses, there is little attempt to biologically plausible.	I-Review	I-1	Review	1623
As an attempt to add to machine learning research, the neuroscience motivation is unconvincing.	B-Review	B-2	Review	1623
Provided that the math works out (and I admit that I did not attempt to follow the detailed derivations), this looks like an interesting intellectual exercise, but it also seems a bit like a discovery of a hammer that is in need for nails to be applied to.	I-Review	I-2	Review	1623
And it‚Äôs not even clear to me how practical the hammer would actually be, even if we had a convincing problem setting at hand.	I-Review	I-2	Review	1623
How scalable is it beyond toy-settings?	I-Review	I-2	Review	1623
The final sentence makes a tantalizing claim, but at this stage the work has to resort to promising potential, rather than being able to demonstrate that it is practically useful.	B-Review	B-3	Review	1623
<sep> <sep> Moreover, this work is not presented right for the venue and audience, and would need substantial rewriting and restructuring to make the central claims and contributions sufficiently clear.	B-Review	B-4	Review	1623
Recall the history of the neural network, current neural networks come from the simulation of biological neurons and their systems.	B-Reply	B-1	Reply	1623
An artificial neural network is the simplified mathematical model of the biological neural network.	I-Reply	I-1	Reply	1623
The deep neural network is far more simple in topology than the human brain.	I-Reply	I-1	Reply	1623
History has proved the method to study simplified neuron model and expand it to bring rich fruits.	I-Reply	I-1	Reply	1623
In reverse, we know more brain from model studying.	I-Reply	I-1	Reply	1623
<sep> <sep> The motivation of this work is based on the research and analysis of the biological neural system.	I-Reply	I-1	Reply	1623
First, synapse plays an important role in learning and memory.	I-Reply	I-1	Reply	1623
In neuroscience, it is synaptic plasticity.	I-Reply	I-1	Reply	1623
The excitation and inhibition are observed in the synapse network.	I-Reply	I-1	Reply	1623
In advanced, the random opening of ion channels is also observed.	I-Reply	I-1	Reply	1623
Second, synapses can connect to other synapses to form a synapse network.	I-Reply	I-1	Reply	1623
Third, synapse makes a non-linear transform.	I-Reply	I-1	Reply	1623
<sep> <sep> Synapse in the artificial neural network is supposed as a simple linear amplifier, it is the multiplication of a parameter and an input variable.	I-Reply	I-1	Reply	1623
There are no synapses connecting to synapses.	I-Reply	I-1	Reply	1623
But one thing is the same, the learning and memory are related to synapses, the change of synaptic parameters.	I-Reply	I-1	Reply	1623
Current artificial neural network ignored the existence of synapses but simply consider them as weights.	I-Reply	I-1	Reply	1623
All the focus are on neurons.	I-Reply	I-1	Reply	1623
<sep> <sep> Back to our motivation.	I-Reply	I-1	Reply	1623
Why synapse act as a transform?	I-Reply	I-1	Reply	1623
Why is it non-linear?	I-Reply	I-1	Reply	1623
What is the distribution of the synaptic matrix?	I-Reply	I-1	Reply	1623
The same question for an artificial neural network is what is the distribution of its weight matrix?	I-Reply	I-1	Reply	1623
Make sense?	I-Reply	I-1	Reply	1623
<sep> <sep> OK.	I-Reply	I-1	Reply	1623
We found a reasonable synapse function.	I-Reply	I-1	Reply	1623
The reasons were explained in the paper.	I-Reply	I-1	Reply	1623
The function is not a simulation of a synapse but an abstraction of the probability.	I-Reply	I-1	Reply	1623
It is a non-linear function with parameters.	I-Reply	I-1	Reply	1623
From their connection, we can form a synapse network.	I-Reply	I-1	Reply	1623
<sep> <sep> What is our "interesting intellectual exercise" bring in our paper?	B-Reply	B-2	Reply	1623
<sep> <sep> 1.	I-Reply	I-2	Reply	1623
Probability Space and Surprisal Space	I-Reply	I-2	Reply	1623
<sep> Logarithmic space has been studied in artificial neural network for a long history.	I-Reply	I-2	Reply	1623
But fruitless in ANN.	I-Reply	I-2	Reply	1623
Because the data field of ANN is the real number field from negative to positive.	I-Reply	I-2	Reply	1623
The surprisal has been defined in information theory and natural language processing and it is related to a random variable.	I-Reply	I-2	Reply	1623
Direct select variable from probability space,  the surprisal is the negative log function.	I-Reply	I-2	Reply	1623
Moreover, we found that it is useful to define the surprisal space.	I-Reply	I-2	Reply	1623
Two difference between logarithmic space and surprisal space: 1) different in a negative sign 2) real space vs (0,1) space.	I-Reply	I-2	Reply	1623
<sep> surprisal represents a self-information bit.	I-Reply	I-2	Reply	1623
The non-linear product in probability space is the linear addition in surprisal space.	I-Reply	I-2	Reply	1623
There may have a lot of new things need to be studied in the surprisal space.	I-Reply	I-2	Reply	1623
Surprisal Space opens a door.	I-Reply	I-2	Reply	1623

The authors present a biologically-inspired neural network model based on the excitatory and inhibitory ion channels in the membranes of real cells.	O	O	Review	1623
Unfortunately, the paper is structured incoherently, making it nearly impossible to appreciate the authors' contribution.	B-Review	B-1	Review	1623
The introduction references neuroscience alongside ResNets, FinTech, surprisal spaces, Bose-Einstein statistics, and topological conjugacy without adequately motivating or defining any of the above.	B-Review	B-2	Review	1623
The fundamental definition of the model synapse as a conditional probability (Eq.1) is not guaranteed to be non-negative, casting serious doubt on any of the subsequent conclusions.	B-Review	B-3	Review	1623
Figure 1 conveys no further information about the proposed model.	B-Review	B-4	Review	1623
There is no explicit related work or background section.	B-Review	B-5	Review	1623
The single experiment offers no comparison to alternative methods.	B-Review	B-6	Review	1623
I suggest the authors invest serious effort into rewriting the paper to clarify the presentation and explicitly state their contributions in the context of existing work on biologically-inspired learning models.	B-Review	B-7	Review	1623
This is indeed a subfield of machine learning worthy of more investigation.	I-Review	I-7	Review	1623
Thanks for your review.	O	O	Reply	1623
<sep> <sep> Q1: "Unfortunately, the paper is structured incoherently, making it nearly impossible to appreciate the authors' contribution."	O	O	Reply	1623
<sep> <sep> This paper was constructed in the structure of a math paper.	B-Reply	B-1	Reply	1623
We first defined a basic formula and gave an explanation of the formula that was based on an abstraction of the biological neural network.	I-Reply	I-1	Reply	1623
Then we gave the definition of the model, related concepts, and theorems with proofs.	I-Reply	I-1	Reply	1623
In this way, we explored and concluded many features of the model, the target was to figure out the learning rules be applied with backpropagation.	I-Reply	I-1	Reply	1623
Finally, we showed an experiment to prove the concept.	I-Reply	I-1	Reply	1623
<sep> <sep> Authors' contributions: (A lot of)	O	O	Reply	1623
<sep> 1.	B-Reply	B-7	Reply	1623
The neural network model is the authors' creation.	I-Reply	I-7	Reply	1623
<sep> The biologically-inspired synapse equation S(x,y; a,b)=ax(1-by) is defined by the product of the opening probability of excitatory channels of a synapse and the opening probability of inhibitory channels of a synapse.	I-Reply	I-7	Reply	1623
Unlike the synapse in spike neural network, we consider the ion channels as the basis to build our synapse model.	I-Reply	I-7	Reply	1623
We ignored the spike feature of the biological neural network because it is the feature of neurons not synapses.	I-Reply	I-7	Reply	1623
The flow of ions and the random opening of the channels are the foundation of our synapse analysis.	I-Reply	I-7	Reply	1623
From a probability perspective, we abstract the synapse equation.	I-Reply	I-7	Reply	1623
In contrast to classical neural network with weights, its synapse is simply a product of the input variable and the weight.	I-Reply	I-7	Reply	1623
Our synapse is a non-linear unit.	I-Reply	I-7	Reply	1623
The practical biological synapse is much complex, But we present a simple model that can be analyzed in math.	I-Reply	I-7	Reply	1623
<sep> <sep> 2.	B-Reply	B-7	Reply	1623
We defined the surprisal space to connect Information Theory with our model.	I-Reply	I-7	Reply	1623
<sep> <sep> Although entropy is widely used in machine learning but surprisal is the more fundamental concept.	I-Reply	I-7	Reply	1623
When we apply surprisal on synapse equation, we have a linear combination in log space which has been used in machine learning analysis.	I-Reply	I-7	Reply	1623
With a negative in front of the log function, we can convert data to the surprisal space.	I-Reply	I-7	Reply	1623
In surprisal space, we can explain the negative log probability as the bits of self-information.	I-Reply	I-7	Reply	1623
That does make sense of surprisal space.	I-Reply	I-7	Reply	1623
It can be a new representation of the neural network.	I-Reply	I-7	Reply	1623
If somebody finds papers to applying surprisal space to explain neural network please let us know, we are going to list them as our references.	I-Reply	I-7	Reply	1623
<sep> <sep> By defining surprisal space, we build the mapping between a probability space and the surprisal space.	I-Reply	I-7	Reply	1623
It is a real positive space in our definition.	I-Reply	I-7	Reply	1623
The bits addition is the basic operation of a neural network.	I-Reply	I-7	Reply	1623
<sep> <sep> 3.	O	O	Reply	1623
Synapse with topological conjugacy is our discovery	B-Reply	B-7	Reply	1623
<sep> It is very exciting to find that the surprisal of the inhibitory probability is a topological conjugation in our model.	I-Reply	I-7	Reply	1623
That means the dynamical behavior in probability space can be bijected into surprisal space and both have the same dynamics.	I-Reply	I-7	Reply	1623
<sep> <sep> In advance, we discovered that this topological conjugation is a commutative diagram in category theory.	I-Reply	I-7	Reply	1623
That opened the door to apply new mathematic tools to study neural network.	I-Reply	I-7	Reply	1623
The discovery between the connection of the neural network and category theory is unexpected.	I-Reply	I-7	Reply	1623
That is one of our exciting contributions.	I-Reply	I-7	Reply	1623
<sep> 4.	O	O	Reply	1623
We discovered gradient updating in synapse learning followed Bose-Einstein distribution	B-Reply	B-7	Reply	1623
<sep> This is a direct conclusion from synapse equation in surprisal space without any statistical hypothesis.	I-Reply	I-7	Reply	1623
That solved the famous black box problem in our model.	I-Reply	I-7	Reply	1623
So we can expect some kind of BE distribution in the parametric matrix.	I-Reply	I-7	Reply	1623
It is a new representation of a neural network.	I-Reply	I-7	Reply	1623
<sep> <sep> 5.	O	O	Reply	1623
We constructed a fully-connected synaptic neural network as synapse tensor	B-Reply	B-7	Reply	1623
<sep> We successfully convert fully-connected non-linear synapse network into a matrix (tensor) computing.	I-Reply	I-7	Reply	1623
This synapse tensor is a special connection of synapses.	I-Reply	I-7	Reply	1623
Other network topologies are possible.	I-Reply	I-7	Reply	1623
Synapse tensor can be basic blocks to construct a large-scale neural network.	I-Reply	I-7	Reply	1623
<sep> <sep> 6.	O	O	Reply	1623
We discovered that synaptic neural network has a similar block to ResNet block in surprisal space	B-Reply	B-7	Reply	1623
<sep> That is why we mentioned ResNet.	I-Reply	I-7	Reply	1623
Except we apply surprisal non-linear function but still computing identity mapping.	I-Reply	I-7	Reply	1623
So we expect some features of ResNet such as protect gradient from vanishing in the very deep synaptic neural network.	I-Reply	I-7	Reply	1623
<sep> <sep> 7.	O	O	Reply	1623
We proved the gradient rule with loss function that mapped in surprisal space	B-Reply	B-7	Reply	1623
<sep> That is proof that we can apply the backpropagation algorithm on the fully-connected synaptic neural network.	I-Reply	I-7	Reply	1623
The proof is in very details because we want to verify that the new gradient computing is correct.	I-Reply	I-7	Reply	1623
<sep> <sep> In conclusion, our synaptic neural network is compatible with backpropagation, however, spike neural network is not.	B-Reply	B-7	Reply	1623

Quality - poor	O	O	Review	1623
The highly complicated work is evaluated only on the simplest of benchmarks with no significant results.	B-Review	B-1	Review	1623
<sep> <sep> Clarity - poor	O	O	Review	1623
The paper seems to amount to gobbledygook, many disparate terminology strung together.	B-Review	B-2	Review	1623
<sep> <sep> Originality	B-Review	B-3	Review	1623
No idea.	I-Review	I-3	Review	1623
<sep> <sep> Significance	B-Review	B-4	Review	1623
None.	I-Review	I-4	Review	1623
<sep> <sep> cons: the paper to me seems a hashing of citations to the main works in neuroscience and deep learning for which only the simplest network is demonstrated (single hidden layer MLP on MNIST) with results that do not exceed that of a standard MLP.	B-Review	B-5	Review	1623
<sep> pros: the only pro I can think of for this work is that synaptic computing imo deserves more consideration, as real synapses are very complicated beasts, the functioning of which relatively little is known about.	O	O	Review	1623
"the paper to me seems a hashing of citations to the main works in neuroscience and deep learning"	O	O	Reply	1623
<sep> Please show us what main works in neuroscience and deep learning we have been hashing?	B-Reply	B-5	Reply	1623

Summary	O	O	Review	20337
---	O	O	Review	20337
This paper proposes to learn simultaneously all the parameters of grouped convolutions by factorizing the weights of the convolutions as a sum of lower rank tensors.	O	O	Review	20337
This enables architecture search for the convolution parameters in a differentiable and efficient way.	O	O	Review	20337
<sep> <sep> Comments	O	O	Review	20337
---	O	O	Review	20337
I think was paper is well written, and was clear at least until 3.2.	B-Review	B-1	Review	20337
I believe some clarifications could be useful here, it is not written clearly that t' and u', the 2 first dimensions of the core are R times smaller than t and u. There is some explanation in the bracket (3) but 1) it should be stated clearly in the text, 2) I believe there are several typos on the 4th line of bracket (3) making it hard to understand.	I-Review	I-1	Review	20337
<sep> <sep> I did not know about the expansion function, and while I trust the authors that it is correctly used, I would have like either more explanations on how it works or some reference.	B-Review	B-2	Review	20337
<sep> <sep> Can you justify the softmax and the very high temperature?	B-Review	B-3	Review	20337
For N = 8, s_1 will be sampled 98.2% of the time s_2 1.8% and the other sampling probabilities are close to neglibigle.	I-Review	I-3	Review	20337
While I understand it seems to work better in practice, it looks extremely aggressive.	I-Review	I-3	Review	20337
<sep> <sep> In 4.4 you say you perform finetuning for 150 epochs, which is huge, while on the abstract you said "GroSS represents a significant step towards	B-Review	B-4	Review	20337
liberating network architecture search from the burden of training and finetuning".	I-Review	I-4	Review	20337
Can you comment?	I-Review	I-4	Review	20337
<sep> <sep> As you say GroSS is an alternative to NAS (for the convolutions parameters that is), is the GroSS method proposed really faster and more accurate than a NAS baseline for finding these architectures?	B-Review	B-5	Review	20337
<sep> <sep> I don't find the column titles in Table 3 to be always informative. "	B-Review	B-6	Review	20337
After train" means after the finetuning?	I-Review	I-6	Review	20337
I took me some time to realize the delta was the delta in accuracies, it is not very informative and it was not clear for me for some time what it meant.	I-Review	I-6	Review	20337
Either the titles should be chosen more carefully or the caption should be more precise I believe.	I-Review	I-6	Review	20337
<sep> <sep> In figure 1, the legend should be more informative, at least incorporate a "alpha" or "temperature" title in the legend.	B-Review	B-7	Review	20337
<sep> <sep> Conclusion	O	O	Review	20337
---	O	O	Review	20337
While the method is interesting I am wondering whether GroSS enables more efficient architecture search that tradional methods as there is still a long finetuning step, furthermore it can only be applied to grouped convolutions parameters.	B-Review	B-5	Review	20337
As the authors present it in the abstract and introduction as an alternative to NAS, I believe a comparison to a NAS would be needed.	I-Review	I-5	Review	20337
‚ÄúI did not know about the expansion function, and while I trust the authors that it is correctly used, I would have like either more explanations on how it works or some reference.	O	O	Reply	20337
‚Äù	O	O	Reply	20337
<sep> As far as we are aware, we are the first to exploit the expansion of grouped convolution weights.	B-Reply	B-2	Reply	20337
We can provide more detail on the appearance of the expansion, however it is dependent on how the specific tensor/convolution library stores weights.	I-Reply	I-2	Reply	20337
Therefore, we hope to provide more intuition of how the expansion function works in the paper.	I-Reply	I-2	Reply	20337
<sep> <sep> ‚ÄúCan you justify the softmax and the very high temperature?	O	O	Reply	20337
For N = 8, s_1 will be sampled 98.2% of the time s_2 1.8% and the other sampling probabilities are close to neglibigle.	O	O	Reply	20337
While I understand it seems to work better in practice, it looks extremely aggressive.	O	O	Reply	20337
‚Äù	O	O	Reply	20337
<sep> When decomposing into multiple group sizes, each successive size in the series only aims to capture information not approximated by the previous order term.	B-Reply	B-3	Reply	20337
In Table 2, we show that even a depthwise factorisation of the network is able to recover almost all of the original accuracy (83.99 vs 81.74).	I-Reply	I-3	Reply	20337
Therefore, most of the energy of the approximation should be captured by the lowest rank term in the decomposition series.	I-Reply	I-3	Reply	20337
This provides intuition that the increasing rank terms in the series should be sampled with frequency that reflects the energy which they capture in the approximation, hence a high sampling temperature.	I-Reply	I-3	Reply	20337
<sep> <sep> ‚ÄúIn 4.4 you say you perform finetuning for 150 epochs, which is huge, while on the abstract you said "GroSS represents a significant step towards liberating network architecture search from the burden of training and finetuning".	O	O	Reply	20337
Can you comment?‚Äù	O	O	Reply	20337
<sep> We found that for each single configuration, convergence was most reliably achieved by fine-tuning for 100 epochs.	B-Reply	B-4	Reply	20337
When a network is factorised using GroSS it is fine-tuned for a longer schedule of 150 epochs, but provides 252 configurations in our 4-layer network (4^12 configurations for our VGG16 decomposition).	I-Reply	I-4	Reply	20337
There are very likely more optimal fine-tuning strategies for both individual configurations and GroSS, but they still provide fair comparison to each other.	I-Reply	I-4	Reply	20337
If both training strategies were optimised, we would still expect to see the number of additional configurations trained by GroSS to vastly exceed the relative increase in number of epochs.	I-Reply	I-4	Reply	20337

Summary: The authors introduce GROSS---a reformulation of block tensor decomposition, which allows multiple grouped convolutions (with varying group sizes) to be trained simultaneously.	O	O	Review	20337
The basic idea is to reformulate the BTD so that higher-order decompositions can be expressed as functions of lower-order decompositions.	O	O	Review	20337
Given this nesting, it is possible to implicitly train the lower-order decompositions while training the higher-order ones.	O	O	Review	20337
<sep> <sep> The authors frame this contribution as a form of "neural architecture search" (NAS), arguing that this allows researchers to simultaneously train grouped-convolution CNNs with varying group sizes.	O	O	Review	20337
After the simultaneous training based on the GROSS approach, the researcher can then select the group size that gives the best performance/accuracy tradeoff.	O	O	Review	20337
The selected model can be further fine-tuned on the task, and the authors found that this improved performance.	O	O	Review	20337
<sep> <sep> Empirical results on the CIFAR-10 dataset show that the proposed approach performs as expected, allowing for the simultaneous training of CNNs with grouped convolutions of varying orders.	O	O	Review	20337
The results show the the proposed approach can find "better" solutions than a simple search over fixed architectures.	O	O	Review	20337
<sep> <sep> Assessment: Overall, this is a well-written and soundly derived contribution.	B-Review	B-1	Review	20337
However, it is quite niche and---while the authors frame it as a form of NAS---in my view, this contribution is more in the realm of hyperparameter search for grouped convolutions, and not NAS in general.	I-Review	I-1	Review	20337
I would recommend reframing the introduction to make this fact more explicit, as the approach does not provide a general strategy for differentiable NAS.	B-Review	B-2	Review	20337
In addition, the empirical results are relatively shallow, with only one dataset and without detailed discussion of the variance of the results.	I-Review	I-2	Review	20337
<sep> <sep> Reasons to accept:	O	O	Review	20337
- Well-written	O	O	Review	20337
- Sound and well-motivated algorithm	O	O	Review	20337
- Potential applications in cases where grouped convolutions are useful	O	O	Review	20337
- Empirical results demonstrate validity of the proposed approach	O	O	Review	20337
<sep> Reasons to reject:	O	O	Review	20337
- Relatively niche contribution incorrectly framed as general contribution to NAS	B-Review	B-1	Review	20337
- Limited empirical analysis (e.g., only one dataset).	B-Review	B-2	Review	20337
‚ÄúOverall, this is a well-written and soundly derived contribution.	O	O	Reply	20337
However, it is quite niche and---while the authors frame it as a form of NAS---in my view, this contribution is more in the realm of hyperparameter search for grouped convolutions, and not NAS in general.	O	O	Reply	20337
I would recommend reframing the introduction to make this fact more explicit, as the approach does not provide a general strategy for differentiable NAS.‚Äù	O	O	Reply	20337
<sep> While we agree that the specific method discussed in the paper is applied only to grouped convolutions search, we believe series-based representations of networks is a more general contribution to the architecture search task.	B-Reply	B-1	Reply	20337
We envisage a number of tasks where series-based search spaces can be trained, evaluate and searched using the philosophy as GroSS, such as number of channels present in a bottleneck layer or even kernel dimensions.	I-Reply	I-1	Reply	20337
We will aim to make the distinction between the series-based train and search philosophy, and our the specific application of GroSS for grouped convolution search.	I-Reply	I-1	Reply	20337
<sep> <sep> ‚ÄúIn addition, the empirical results are relatively shallow, with only one dataset and without detailed discussion of the variance of the results.	O	O	Reply	20337
‚Äù	O	O	Reply	20337
<sep> We would like to point you towards the additional results presented in our response to Reviewer #3 for VGG16 on CIFAR10.	B-Reply	B-2	Reply	20337
We are continuing to work on more experiments, and hope to add them soon.	I-Reply	I-2	Reply	20337

The authors propose to express the weight of a convolutional neural network as a coupled Tucker decomposition.	O	O	Review	20337
The Tucker formulation allows for an efficient reformulation.	O	O	Review	20337
The weigths of the sum of Tucker decompositions allows is randomly set at each iteration during training, with each term of the sum having a different rank.	O	O	Review	20337
<sep> The method is interesting, however the novelty is low.	B-Review	B-1	Review	20337
There is already large bodies of work on parametrizing neural networks with tensor decomposition, including coupled decomposition.	I-Review	I-1	Review	20337
<sep> <sep> <sep> How does the proposed method compared to the related method DART?	B-Review	B-2	Review	20337
And to a simple coupled decomposition?	I-Review	I-2	Review	20337
<sep> How is the method different to training several network with the same Tucker parametrization but different ranks?	I-Review	I-2	Review	20337
What about memory and computational efficiency?	I-Review	I-2	Review	20337
<sep> In any case, these should be compared to.	I-Review	I-2	Review	20337
<sep> <sep> The notation should be kept consistent throughout: e.g. either use t,u,v,w or d1,d2,d3,d4.	B-Review	B-5	Review	20337
Notation should be unified in the text and captions (e.g. Table 1).	I-Review	I-5	Review	20337
<sep> In 3.2, when specifying the size of G, should it be G_r?	I-Review	I-5	Review	20337
Same for B and C.	I-Review	I-5	Review	20337
<sep> Why the convolution R should be grouped?	B-Review	B-3	Review	20337
Should it not be a regular convolution?	I-Review	I-3	Review	20337
<sep> <sep> For ot', u' being the group-size, what is o?	B-Review	B-6	Review	20337
It was not introduced.	I-Review	I-6	Review	20337
<sep> <sep> The response reconstruction is only useful if the same, uncompressed network is already trained, would not be applicable for end-to-end training.	B-Review	B-7	Review	20337
<sep> <sep> The model is a simple 4-layer network, not fully described.	B-Review	B-4	Review	20337
An established architecture, such as ResNet should be employed.	I-Review	I-4	Review	20337
<sep> <sep> Experiments should be carried on ImageNet, or at least not just on CIFAR10.	B-Review	B-8	Review	20337
<sep> <sep> There is no comparison with existing work, e.g. parametrization of the network with Tucker [1, 2] or CP [3]	B-Review	B-9	Review	20337
<sep> [1] Compression of Deep Convolutional Neural Networks for Fast and Low Power Mobile Applications, ICLR 2016	O	O	Review	20337
[2] T-Net: Parametrizing Fully Convolutional Nets with a Single High-Order Tensor, CVPR 2019	O	O	Review	20337
[3] Speeding-up Convolutional Neural Networks Using Fine-tuned CP-Decomposition, ICLR 2015	O	O	Review	20337
<sep> ‚ÄúThe method is interesting, however the novelty is low.	O	O	Reply	20337
There is already large bodies of work on parametrizing neural networks with tensor decomposition, including coupled decomposition.	O	O	Reply	20337
‚Äù	O	O	Reply	20337
<sep> While there are works on parameterising and factorising networks with tensor decomposition, rank selection for decomposition remains relatively unexplored.	B-Reply	B-1	Reply	20337
<sep> The novelty of GroSS comes, not from the mechanics of decomposition, where we can use standard BTD due to the process described in Eq.6, but instead from the formulation of the search space as the combination (and interaction) of a number of series components.	I-Reply	I-1	Reply	20337
Each of these can be changed on-the-fly and therefore allow for simultaneous training.	I-Reply	I-1	Reply	20337
Here, we apply this series formulation to rank search for factorisation of networks, but we envisage similar series-based search can be used for a number of search tasks, such as number of channels and kernel dimensions.	I-Reply	I-1	Reply	20337
<sep> <sep> ‚ÄúHow is the method different to training several network with the same Tucker parametrization but different ranks?‚Äú	O	O	Reply	20337
<sep> GroSS differs from the training of individual rank configurations since GroSS is able to train each rank factorisation of each layer, as well as all the possible combinations of ranks between layers.	B-Reply	B-2	Reply	20337
To explore our 4-layer network this would require 252 individual training runs, and 4^12 for our VGG16 network.	I-Reply	I-2	Reply	20337
However GroSS allows for all these configurations to be fine-tuned simultaneously, in a single training run.	I-Reply	I-2	Reply	20337
<sep> <sep> ‚ÄúWhy the convolution R should be grouped?	O	O	Reply	20337
Should it not be a regular convolution?‚Äù	O	O	Reply	20337
<sep> We perform BTD, rather than pure Tucker decomposition.	B-Reply	B-3	Reply	20337
BTD is the extension of Tucker decomposition as it is the factorisation of a single tensor into the sum of multiple Tucker decompositions.	I-Reply	I-3	Reply	20337
When the number of Tuckers present in the BTD sum and the size of each Tucker kernel are set to the specific values, as described in our paper, the factorisation becomes equivalent to the grouped bottleneck architecture.	I-Reply	I-3	Reply	20337
Full derivation of this can be found in (paper ref: Yunpeng et al 2017).	I-Reply	I-3	Reply	20337
<sep> <sep> ‚ÄúThe model is a simple 4-layer network, not fully described.	O	O	Reply	20337
An established architecture, such as ResNet should be employed.	O	O	Reply	20337
‚Äù	O	O	Reply	20337
<sep> We agree and now have provided preliminary search results for VGG16 on CIFAR10, where we decompose all but the first convolutional layer into sizes [1, 4, 16, 32], therefore the number of possible configurations from our GroSS decomposition of VGG16 is 4^12.	B-Reply	B-4	Reply	20337
We implement a rudimentary breadth-first search to find configuration proposals.	I-Reply	I-4	Reply	20337
We can provide full implementation details of the search, network definition and fine-tuning strategy in an appendix.	I-Reply	I-4	Reply	20337
<sep> <sep> Config                                                       | MACs         | Accuracy	I-Reply	I-4	Reply	20337
-------------------------------------------------- | -------------- | ----------	I-Reply	I-4	Reply	20337
Baseline 4s                                              | 9.36M         | 91.00	I-Reply	I-4	Reply	20337
1, 4, 1, 32, 1, 1, 16, 1, 4, 16, 32, 4           | 8.84M         | 91.28	I-Reply	I-4	Reply	20337
Baseline 16s                                            | 29.04M       | 91.48	I-Reply	I-4	Reply	20337
1, 32, 16, 32, 16, 16, 32, 32, 32, 1, 4, 16 | 26.19M      | 91.56	I-Reply	I-4	Reply	20337
Full Network                                            | 313.74M    | 91.52	I-Reply	I-4	Reply	20337
<sep> Here, we perform similar testing to that with our 4-layer network.	I-Reply	I-4	Reply	20337
We set baseline configurations, where every layer is set to the same rank (4 or 16).	I-Reply	I-4	Reply	20337
We then employ GroSS to find a configuration which requires fewer MACs, while acheiving higher accuracy than the baseline.	I-Reply	I-4	Reply	20337
This was possible in each case, and notably one of our found configurations outperforms the original network before factorisation, requiring an order of magnitude fewer operations.	I-Reply	I-4	Reply	20337

The paper proposes a novel way to formulate intrinsic reward based on optical flow prediction error.	O	O	Review	20259
The prediction is done with Flownet-v2 architecture and the training is formulated as self-supervision (instead of the ground-truth-based supervised learning in the original Flownet-v2 paper).	O	O	Review	20259
The flow predictor takes two frames, predicts forward and backward flows, then warps the first/second frame respectively and compares the warped result with real frame.	O	O	Review	20259
The comparison error serves as the intrinsic reward signal.	O	O	Review	20259
The results are demonstrated on 7 environments: SuperMario + 5 Atari games + ViZDoom.	O	O	Review	20259
On those environments, the proposed method performs better or on-par with ICM and RND baselines.	O	O	Review	20259
<sep> <sep> I am leaning towards rejecting this paper.	O	O	Review	20259
Two key factors motivate this decision.	O	O	Review	20259
<sep> First, the motivation for this work is not fully clear: why would the error in flow prediction be a good driving force for curiosity?	B-Review	B-1	Review	20259
Optical flow has certain weaknesses, e.g. might not work well for textureless regions because it's hard to find a match.	I-Review	I-1	Review	20259
Why would those weaknesses drive the agent to new locations?	I-Review	I-1	Review	20259
<sep> Second, the choice of tasks where the largest improvement is shown (i.e. 5 Atari games) seems not well-motivated and rather crafted for the proposed method.	B-Review	B-2	Review	20259
Those 5 Atari games are not established hard exploration games.	I-Review	I-2	Review	20259
<sep> <sep> Detailed arguments for the decision above:	O	O	Review	20259
[major concerns]	O	O	Review	20259
* Analysis is need on how the method deals with known optical flow problems: occlusion, large displacements, matching ambiguities.	B-Review	B-3	Review	20259
Those problems don't fully go away with learning and it is unclear how correlated corresponding errors would be with state novelty.	I-Review	I-3	Review	20259
<sep> * "Please note that ri is independent of the action taken by the agent, which distinguishes FICM from the intrinsic curiosity module (ICM) proposed in Pathak et al (2017)" - but would it then be susceptible to spurious curiosity effects when the agent is drawn to motion of unrelated things?	B-Review	B-4	Review	20259
Like leaves trembling in the wind.	I-Review	I-4	Review	20259
ICM was proposed to eliminate those effects in the first place, but what is this paper's solution to that problem?	I-Review	I-4	Review	20259
Furthermore, the experiments on BeamRider show that this concern is not a theoretical one but quite practical.	I-Review	I-4	Review	20259
<sep> * "CrazyClimber, Enduro, KungFuMaster, Seaquest, and Skiing" - none of those Atari environments are known to be hard exploration games (which are normally Gravitar, Montezuma Revenge, Pitfall!,	B-Review	B-5	Review	20259
PrivateEye, Solaris, Venture according to Bellemare et al "Unifying count-based exploration and intrinsic motivation").	I-Review	I-5	Review	20259
I understand that every game becomes hard-exploration if the rewards are omitted but then there is a question why those particular games.	I-Review	I-5	Review	20259
Moreover, if you omit the rewards the question remains how to select hyperparameters of your method.	I-Review	I-5	Review	20259
Was the game reward used for selecting hyperparameters?	I-Review	I-5	Review	20259
If not, what is the protocol for their selection?	I-Review	I-5	Review	20259
This is a very important question and I hope the authors will address this.	I-Review	I-5	Review	20259
<sep> * "These games are characterized by moving objects that require the agents to concentrate on and interact with." -	B-Review	B-6	Review	20259
this looks like tailoring the task to suit the method.	I-Review	I-6	Review	20259
<sep> * Figure 6 - those results are not great compared to the results of Episodic Curiosity: <a href="https://arxiv.org/abs/1810.02274" target="_blank" rel="nofollow">https://arxiv.org/abs/1810.02274</a> .	B-Review	B-7	Review	20259
Maybe this is because of the basic RL solver (A3C vs PPO) but that brings up another question: why are different solvers used for different tasks in this paper?	I-Review	I-7	Review	20259
PPO is normally significantly better than A3C, why not use throughout the whole paper?	I-Review	I-7	Review	20259
<sep> [minor concerns]	O	O	Review	20259
* Figures are very small and the font in them is not readable.	B-Review	B-8	Review	20259
Figure 2 is especially difficult to read because the axes titles are tiny.	I-Review	I-8	Review	20259
<sep> * "complex or spare reward" -&gt; sparse	I-Review	I-8	Review	20259
* "However, RND does not consider motion features, which are essential in motivating an agent for exploration." -	I-Review	I-8	Review	20259
this is unclear, why are those features essential?	I-Review	I-8	Review	20259
<sep> * "We demonstrated the proposed methodology and compared it against a number of baselines on Atari games, Super Mario Bros., and ViZDoom." -	I-Review	I-8	Review	20259
please state more clearly that only 5 out of 57 Atari games are considered, here and in the abstract.	I-Review	I-8	Review	20259
<sep> * "Best extrinsic returns on eight Atari games and Super Mario Bros." - but only 5 games are shown, where are the other 3?	I-Review	I-8	Review	20259
<sep> <sep> Suggestions on improving the paper:	O	O	Review	20259
1) Better motivating the approach in the paper would help.	B-Review	B-1	Review	20259
Why using the flow prediction error as a curiosity signal?	I-Review	I-1	Review	20259
<sep> 2) Better motivating the choice of the environments and conducting experiments on more environments would be important for evaluating the impact of the paper.	B-Review	B-2	Review	20259
The authors appreciate the thoughtful feedback from the reviewer and would like to respond to the questions in the following paragraphs.	O	O	Reply	20259
Please note that we first address the two major concerns from the reviewer, which also cover our responses to a few questions raised in the detailed comments part provided by the reviewer.	O	O	Reply	20259
Then, we respond to the remaining questions raised in the detailed comments part.	O	O	Reply	20259
<sep> <sep> ===To address two major concerns===	O	O	Reply	20259
[Comment]	O	O	Reply	20259
Better motivating the approach in the paper would help.	O	O	Reply	20259
Why using the flow prediction error as a curiosity signal?	O	O	Reply	20259
<sep> [Response]	O	O	Reply	20259
We appreciate the time and efforts of the reviewer to read through the paper thoroughly.	B-Reply	B-1	Reply	20259
As the reviewer has raised concerns about the motivations of FICM, we would definitely love to share our perspectives with the reviewer and expect a rigorous discussion afterward.	I-Reply	I-1	Reply	20259
<sep> <sep> Ôº∑e believe that rapidly changing parts in two consecutive frames, i.e., motion features extracted by a flow predictor, do usually serve as an important indicator of information in an environment.	I-Reply	I-1	Reply	20259
As depicted in Fig.1, the motions of Mario and the fire traps contain essential information for the agent to perform well in SuperMario Bros. Biologically, human beings and animals also tend to concentrate on motion features of objects.	I-Reply	I-1	Reply	20259
For instance, animals may not be able to memorize the exact appearance of the objects in their habitats, but do posses the capability to discover whether or not unfamiliar newcomers have intruded into their territories.	I-Reply	I-1	Reply	20259
It is a natural instinct that arouses an animal‚Äôs curiosity from motions of unfamiliar feature patterns appearing in its field of view.	I-Reply	I-1	Reply	20259
Our FICM is therefore inspired by the observations mentioned above, and is designed to focus on motion features of objects extracted from two consecutive frames by adopting optical flow estimation for evaluating the novelty of the frames.	I-Reply	I-1	Reply	20259
<sep> <sep> We do agree with the reviewer‚Äôs concern about the limitations of optical flow.	I-Reply	I-1	Reply	20259
This is why we incorporated additional paragraphs in Section 4.3 for discussing the applicable domains of FICM as a balanced discussion.	I-Reply	I-1	Reply	20259
It is not our paper‚Äôs objective to claim or argue that optical flow is omnipotent.	I-Reply	I-1	Reply	20259
Optical flow suffers from occlusions or textureless images, which have already been prevalently recognized by researchers in the domain of computer vision.	I-Reply	I-1	Reply	20259
However, it is still widely adopted in numerous researches as an effective tool for extracting information between consecutive frames.	I-Reply	I-1	Reply	20259
Our research similarly intends to leverage this tool in the domain of reinforcement learning.	I-Reply	I-1	Reply	20259
To validate that the prediction errors from an optical flow estimator can indeed serve as a satisfactory novelty indicator, we presented an experiment in Fig.2 with a discussion to demonstrate that the prediction errors do gradually decrease over training iterations.	I-Reply	I-1	Reply	20259
This implies that FICM is able to learn and gradually become familiar with the transitions and the motions between consecutive observations in spite of those potential problems.	I-Reply	I-1	Reply	20259
<sep> <sep> Based on the motivations discussed above, we consider that the flow-based intrinsic reward is worth sharing with the community in ICLR.	I-Reply	I-1	Reply	20259
FICM contributes to the concept of employing flow prediction errors to generate intrinsic rewards, which has never been discussed in the literature before.	I-Reply	I-1	Reply	20259
The concept is proposed to bring new insights to the research community, and provide a potential direction for future enhancements in the realm of intrinsic reward based exploration.	I-Reply	I-1	Reply	20259

Well motivated paper	O	O	Review	20259
<sep> The authors study the problem of exploration and exploitation in deep reinforcement learning.	O	O	Review	20259
The authors propose a new intrinsic curiosity-based method that deploys the methods developed in optical flow.	O	O	Review	20259
Following this algorithm, the agents utilize the reconstruction error in the optical flow network to come up with intrinsic rewards.	O	O	Review	20259
The authors show that this approach boosts up the behavior of the RL agents and improves the performance on a set of test environments.	O	O	Review	20259
<sep> <sep> A few comments that I hope might help the authors to improve the clarity of their paper.	O	O	Review	20259
<sep> <sep> 1) While the paper is nicely written, I would encourage the authors, of course, if they think necessary, to make the paper slightly more self-contained by explaining the optical flow problem, FlowNet, and warping approach.	B-Review	B-1	Review	20259
While a cruise reader might be required to either know literature in optical flow or go and study them along with this paper, it might be helpful for a bit more general readers to have these tools and approaches in access.	I-Review	I-1	Review	20259
<sep> <sep> 2) Regarding the first line of introduction, I would recommend to rephrase it to one imply that the mentioned "aim" is one of the aims of the DRL study.	B-Review	B-2	Review	20259
<sep> <sep> 3) In the fourth line of the intro, the authors mention that the current DRL methods are "constraint" to dense reward.	B-Review	B-3	Review	20259
I believe the authors' aim was to imply that these methods perform more desirably in dense reward settings rather than being constrained to such settings.	I-Review	I-3	Review	20259
<sep> <sep> 4) I would also recommend to the authors to elaborate more on the term "attention area" Greydanue et al 2018.	B-Review	B-1	Review	20259
<sep> <sep> 5) It would be helpful to have a better evaluation of this paper if the authors could clarify and motivate the choice of games in their empirical study.	B-Review	B-5	Review	20259
For example the empirical study in Fig 5.	I-Review	I-5	Review	20259
<sep> <sep> <sep> 6) While I find this study interesting and valuable, the novelty of the approach might fall short to be published at a conference like ICLR with a low acceptance rate.	B-Review	B-6	Review	20259
This does not mean that there is anything unscientific about this paper, in fact, the scientific value of this work is appreciated and this work adds a lot to the community.	I-Review	I-6	Review	20259
<sep> <sep> 7) It would also be useful to explicitly explain the advances of this approach over the next frame predictions approaches in stochastic environments.	B-Review	B-7	Review	20259
And also, if there is a shortcoming, what are those.	I-Review	I-7	Review	20259
<sep> <sep> 8) Also, what the authors think would happen when the action directly does not change the scene, at least immediately.	B-Review	B-4	Review	20259
<sep> <sep> <sep> <sep> <sep> <sep> The authors appreciate the reviewer‚Äôs time and efforts for reviewing this paper, and would like to respond to the questions in the following paragraphs.	O	O	Reply	20259
<sep> <sep> [Comment]	O	O	Reply	20259
The authors should elaborate more on optical flow problem, Flownet, warping approach, and the term ‚Äúattention area‚Äù.	O	O	Reply	20259
<sep> [Response]	O	O	Reply	20259
We appreciate the reviewer‚Äôs thoughtful feedback.	B-Reply	B-1	Reply	20259
We agree with the reviewer and have prepared additional paragraphs at the end of this response post, including the background materials for optical flow, FlowNet, warping approach, as well as attention area.	I-Reply	I-1	Reply	20259
We would be glad to incorporate those paragraphs into our manuscript, and discuss with you should you have any further comments or suggestions regarding the sufficiency of the background material.	I-Reply	I-1	Reply	20259
<sep> <sep> [Comment]	O	O	Reply	20259
It would be helpful to have a better evaluation of this paper if the authors could clarify and motivate the choice of games in their empirical study.	O	O	Reply	20259
For example the empirical study in Figure 5.	O	O	Reply	20259
<sep> [Response]	O	O	Reply	20259
We would like to thank the reviewer for raising this question, and are glad to share our perspectives with the reviewer.	B-Reply	B-5	Reply	20259
The selection criteria of our environments is determined by the relevance of motions of the foreground and background components (including the controllable agent and the uncontrollable objects) to the performance (i.e., obtainable scores) of the agent.	I-Reply	I-5	Reply	20259
As the primary theme of this work is to leverage flow features as intrinsic reward signals, we benchmarked our methodology on Atari and Super Mario Bros game environments characterizing sophisticated motions of objects.	I-Reply	I-5	Reply	20259
Taking the Atari game ‚ÄúEnduro‚Äù for example.	I-Reply	I-5	Reply	20259
The agent not only has to understand the motion of its controllable car, but is also required to perceive and comprehend the motions of the other cars, as their motions are directly related to the final score of this agent.	I-Reply	I-5	Reply	20259
BeamRider, on the other hand, is not considered as an environment satisfying the above property.	I-Reply	I-5	Reply	20259
According to our experiments, our method does assist the agents to explore better and deliver more satisfactory results in the environments satisfying the above criteria.	I-Reply	I-5	Reply	20259
As a result, instead of focusing on those hard-explored environments, the emphasis of this paper is on bringing to the community the existence and effectiveness of flow-based intrinsic rewards, and motivating researchers with a potential direction in their future endeavors.	I-Reply	I-5	Reply	20259
We have therefore dedicated significant portions of our manuscript to demonstrating and validating that FICM is able to master the environments featuring the above property, and is more effective than other intrinsic motivated approaches when motion features play a vital role in determining the performance of the agents.	I-Reply	I-5	Reply	20259
<sep> <sep> Moreover, as the necessity of taking complex motion features into account during the exploration phase of an agent becomes critically important for first-person perspective games, we benchmarked the proposed FICM on ViZDoom, and showed that FICM is naturally more capable of capturing motion features than the baseline methods in Section 4 of our manuscript.	I-Reply	I-5	Reply	20259
As human beings and animals inherently tend to be motivated, attracted, and encouraged by moving objects, we consider that our approach aligns with animal instinct, and believe that our work brings a different perspective to the reinforcement learning community.	I-Reply	I-5	Reply	20259
<sep> <sep> Furthermore, in order to provide a balanced analysis of FICM as a complete and comprehensive study, we additionally conducted another set of experiments on ‚ÄúBeamRider‚Äù to reveal the limitation of FICM and discussed its applicable domains in Section 4.3.	I-Reply	I-5	Reply	20259
Based on the motivations discussed above, we consider that the flow-based intrinsic reward is worth sharing with the community in ICLR.	I-Reply	I-5	Reply	20259
FICM contributes to the concept of employing flow prediction errors to generate intrinsic rewards, which has never been discussed in the literature before.	I-Reply	I-5	Reply	20259
Rather than finding a panacea for RL exploration, we consider that introducing different perspectives of intrinsic rewards to the existing set of approaches is more likely the correct way to proceed.	I-Reply	I-5	Reply	20259
<sep> <sep> We hope that the above discussions have adequately responded to the reviewer‚Äôs concerns, and hope that the reviewer can take our perspective into consideration.	O	O	Reply	20259

<sep> <sep> Pros	O	O	Review	20259
Solid technical innovation/contribution:	O	O	Review	20259
- The paper proposed a novel method FICM that bridged the intrinsic reward in DRL with optical flow loss in CV to encourage exploration in an environment with sparse rewards.	O	O	Review	20259
To the best of my knowledge, this was the first paper proposed to use moving patterns in two consecutive observations to motivate agent exploration.	O	O	Review	20259
<sep> <sep> Balanced view:	O	O	Review	20259
- The authors discussed both the advantages of FICM and settings that FICM might fail to perform well, and conducted experiments to better help the readers understand such nuances.	O	O	Review	20259
Such balanced view should be valuable to RL communities in both academia and industry.	O	O	Review	20259
<sep> <sep> Clarity:	O	O	Review	20259
- In general this was a very well-written paper, I had no difficulty in following the paper throughout.	O	O	Review	20259
The proposed method (FICM) was clearly motivated, and the authors provided good coverage of related works.	O	O	Review	20259
Notably, the authors reviewed two relevant methods upon which FICM was motivated, which made the paper self-contained.	O	O	Review	20259
<sep> <sep> <sep> Cons	O	O	Review	20259
Experiments:	B-Review	B-1	Review	20259
- Experiments were conducted only using a few recent results as baselines (ICM, forward dynamics, RND).	I-Review	I-1	Review	20259
It would be interesting to compare FICM against simpler exploration baselines such as epsilon-greedy or entropy regularization.	I-Review	I-1	Review	20259
<sep> - I‚Äôd also like to see more extensive comparisons between FICM and ICM across different datasets, for example, Super Mario Bros. and the Atari games, instead of only comparing FICM against ICM on ViZDoom.	I-Review	I-1	Review	20259
<sep> <sep> Significance of the innovation:	B-Review	B-2	Review	20259
- The proposed exploration method seemed to be applicable with a particular RL setting: the environment changes could be represented through consecutive frames (e.g., video games), and optical flow could be used to interpret any object displacements in such consecutive frames.	I-Review	I-2	Review	20259
And as the authors discussed, even under such constraints the applicability of proposed method depends on how much changes of the environment were relevant to the goal.	I-Review	I-2	Review	20259
<sep> <sep> Reproducibility:	B-Review	B-3	Review	20259
- Although the authors discussed the experiment setting in detail in supplements, I believe open-sourcing the code / software used to conduct the experiments would be greatly help with the reproducibility of the proposed method for researchers or practitioners.	I-Review	I-3	Review	20259
<sep> <sep> <sep> <sep> <sep> Summary	O	O	Review	20259
A good paper overall, but the experiments were relatively weak (common for most ICLR submissions) and the novelty was somewhat limited.	O	O	Review	20259
<sep> <sep> <sep> The authors appreciate the reviewer‚Äôs time and efforts for reviewing this paper and would like to respond to the questions in the following paragraphs.	O	O	Reply	20259
<sep> <sep> [Comment]	O	O	Reply	20259
Compare FICM against simpler exploration baselines such as epsilon-greedy or entropy regularization.	O	O	Reply	20259
<sep> [Response]	O	O	Reply	20259
We would like to thank the reviewer for raising this interesting question, and would like to bring to the reviewer's kind attention that in the original paper of our baseline "ICM" [1], the authors had provided a comparison against an ‚ÄòA3C‚Äô baseline (using entropy regularization) with epsilon-greedy exploration method (Section 3 of [1]).	B-Reply	B-1	Reply	20259
According to the experimental results presented in Section 4 of [1], it has been demonstrated that ICM is superior to that baseline in a number of environments.	I-Reply	I-1	Reply	20259
This is the reason why we omit that baseline in our paper.	I-Reply	I-1	Reply	20259
As our primary interest and focus is prediction-based exploration methods using intrinsic reward signals (as discussed in Section 1 of our paper), we only compare our FICM with ICM [1], RND [2] and large-scale [3], concentrating on analyzing the pros and cons between our proposed method and the other prediction-based ones.	I-Reply	I-1	Reply	20259
<sep> <sep> However, we would still be glad to include additional comparisons against the suggested methods in the final version of our paper, if the reviewer considers that is informative for the readers to comprehend the paper.	I-Reply	I-1	Reply	20259
<sep> <sep> [Comment]	O	O	Reply	20259
More extensive comparisons between FICM and ICM across different datasets, for example, Super Mario Bros. and the Atari games, instead of only comparing FICM against ICM on ViZDoom.	O	O	Reply	20259
<sep> [Response]	O	O	Reply	20259
We appreciate the suggestions from the reviewer and would like to share with the reviewer our additional experimental results of ICM using the same hyper-parameter settings described in Section 4.1 in the following figure. (	B-Reply	B-1	Reply	20259
figure link: <a href="https://imgur.com/5pPl8PV" target="_blank" rel="nofollow">https://imgur.com/5pPl8PV</a> )	I-Reply	I-1	Reply	20259
It is observed that ICM is only able to deliver comparable performance to our method in Atari game "Seaquest".	I-Reply	I-1	Reply	20259
We would definitely be glad to incorporate these new results in our manuscript in the revised version.	I-Reply	I-1	Reply	20259
<sep> <sep> [Comment]	O	O	Reply	20259
Reproducibility.	O	O	Reply	20259
<sep> [Response]	O	O	Reply	20259
Thank you very much for the suggestions.	O	O	Reply	20259
We have already uploaded our source codes as well as the demonstration videos to the following sites.	B-Reply	B-3	Reply	20259
Our experimental results and statements presented in the manuscript are fully reproducible and verifiable.	I-Reply	I-3	Reply	20259
<sep> <sep> Github: <a href="https://github.com/IclrPaperID2276/iclr_paper_2276" target="_blank" rel="nofollow">https://github.com/IclrPaperID2276/iclr_paper_2276</a>	I-Reply	I-3	Reply	20259
Demo Video: <a href="https://youtu.be/JL68QFNj_N8" target="_blank" rel="nofollow">https://youtu.be/JL68QFNj_N8</a>	I-Reply	I-3	Reply	20259
<sep> We hope that we have adequately responded to your questions, and would be very glad to discuss with you if you have any further comments or suggestions.	O	O	Reply	20259
<sep> <sep> [1] D. Pathak, P. Agrawal, A. A. Efros, and T. Darrell.	O	O	Reply	20259
Curiosity-driven exploration by self-supervised prediction.	O	O	Reply	20259
In Proc.	O	O	Reply	20259
Int.	O	O	Reply	20259
Conf.	O	O	Reply	20259
Machine Learning (ICML), pp.2778‚Äì2787, May 2017.	O	O	Reply	20259
<sep> [2] Y. Burda, H. Edwards, A. Storkey, and O. Klimov.	O	O	Reply	20259
Exploration by random network distillation.	O	O	Reply	20259
In Proc.	O	O	Reply	20259
Int.	O	O	Reply	20259
Conf.	O	O	Reply	20259
Learning Representations (ICLR), May 2019b.	O	O	Reply	20259
<sep> [3] Y. Burda, H. Edwards, D. Pathak, A. J. Storkey, T. Darrell, and A. A. Efros.	O	O	Reply	20259
Large-scale study of curiosity-driven learning.	O	O	Reply	20259
In Proc.	O	O	Reply	20259
Int.	O	O	Reply	20259
Conf.	O	O	Reply	20259
Learning Representation (ICLR), May 2019a.	O	O	Reply	20259

This paper deals with the underfitting problem happening in neural process and sequential neural process (SNP).	O	O	Review	167
The idea is to incorporate the attention scheme in SNP and carry out the so-called attentive sequential neural process (ASNP) for sequence learning.	O	O	Review	167
<sep> <sep> Strength:	O	O	Review	167
1.	O	O	Review	167
A combination of attention into SNP.	O	O	Review	167
<sep> 2.	O	O	Review	167
Some formulations were provided.	O	O	Review	167
<sep> 3.	O	O	Review	167
Different tasks were evaluated to investigate the merit of this method.	O	O	Review	167
<sep> <sep> Weakness:	O	O	Review	167
1.	O	O	Review	167
The comparison for time complexity and parameter size was missing.	B-Review	B-1	Review	167
<sep> 2.	O	O	Review	167
The labels in figures were inconsistent.	B-Review	B-2	Review	167
<sep> 3.	O	O	Review	167
An incremental research.	B-Review	B-3	Review	167
We are grateful for the comments.	O	O	Reply	167
We have modified the paper and addressed them as follows.	O	O	Reply	167
<sep> <sep> Time-complexity comparison:   In the appendix, we show the training curves against the wall clock time.	B-Reply	B-1	Reply	167
It shows that the proposed ASNP converges the fastest among the baselines.	I-Reply	I-1	Reply	167
<sep> <sep> Parameter-size comparison: We tested the proposed ASNP with representation size n=128 against the baselines NP, ANP, and SNP with n=128 and n=512.	B-Reply	B-1	Reply	167
While the baselines improve going from n=128 to n=512, they still underperform ASNP.	I-Reply	I-1	Reply	167
In scenario c) which tests how well a model accumulates contexts over time, this gap is clear.	I-Reply	I-1	Reply	167
The reason we choose size=512 in the baselines is that it shows a similar performance when size=1024 in ANP (Kim et al) and also needs a shorter training time that allowed us to produce these new findings within the rebuttal period.	I-Reply	I-1	Reply	167
From these findings, we can say that having a bigger latent size or equivalently more parameters in the baselines is not sufficient and imaginary context itself plays a useful role.	I-Reply	I-1	Reply	167
<sep> <sep> Figure label inconsistency:   We have fixed the inconsistent labels of the figures.	B-Reply	B-2	Reply	167
<sep> <sep> Incremental Research:   The problem we address (as also described in the response for all reviewers) is real and an important one.	B-Reply	B-3	Reply	167
From this perspective, we believe our performance gains are a significant step forward.	I-Reply	I-3	Reply	167
NP and SNP are crucial meta-learning frameworks with nice properties which were originally demonstrated on relatively simpler tasks.	I-Reply	I-3	Reply	167
Addressing under-fitting is the key to making them usable in realistic settings.	I-Reply	I-3	Reply	167
Our imaginary context shows that attention on a sequentially-updated memory outperforms using a lossless copy of the past while also being more size-efficient.	I-Reply	I-3	Reply	167

This paper combines ideas from attentive and sequential neural processes to incorporate an attention mechanism to the existing sequential neural process, which results in an attentive sequential neural processes framework.	O	O	Review	167
<sep> <sep> While the idea is somewhat interesting, I think this paper is technically vague and not well-motivated, which makes it hard for me to feel convinced that the problem exists and is non-trivial, and that the proposed solution is significant.	B-Review	B-1	Review	167
Let me elaborate on my thoughts below:	O	O	Review	167
<sep> First, the authors stated that SNP is subject to the underfitting problem that plagues NP but it is not clear to me why, in the temporal context of SNP, do we need to focus our attention on past contexts, which are no longer relevant.	B-Review	B-2	Review	167
Could the authors please motivate this with a concrete application scenario?	I-Review	I-2	Review	167
Without a concrete scenario, I do not feel very convinced that the problem exists.	I-Review	I-2	Review	167
<sep> <sep> Second, the argument that augmenting SNP with an attention mechanism is not trivial is somewhat contrived.	B-Review	B-3	Review	167
In particular, the reason for this non-triviality is that (in the authors' own words) SNP assumes that it cannot store the past context as is -- so what if we simply store the past context &amp; condition the representation on the entire history of past context instead?	I-Review	I-3	Review	167
<sep> <sep> Apparently, this can come across trivially by replacing C_t with both C_&lt;t and C_t in Eq. (2).	I-Review	I-3	Review	167
This is in fact very similar to what the authors did in Eq. (4) which summarizes the generative process of ASNP -- the only difference is the generation of imaginary contexts, whose necessity is again questionable, as I elaborate next.	I-Review	I-3	Review	167
<sep> <sep> Third, the motivation for imaginary context is pulled from a very distant literature on how a human brain memorizes past experiences in a lossy memory consolidation, which only retains the most important sketches.	B-Review	B-4	Review	167
In the context of ASNP, it is not, however, clear to me why this mechanism is necessary given that entire lossless memory can be stored except that without a lot of contexts, there is not a need for an attention component (as implied in first paragraph of Section 3) which is a contrived motivation.	I-Review	I-4	Review	167
<sep> <sep> Fourth, the technical exposition of this paper is too vague.	B-Review	B-5	Review	167
Given that the key contribution here is about an attention component, the background review on ANP is surprisingly informal with no technical detail at all.	I-Review	I-5	Review	167
For the other parts, the technical part is also mostly abstracted away -- what is presented is therefore not that much different from a typical generative model with latent variables, which makes it unclear whether there is a technical challenge here.	I-Review	I-5	Review	167
<sep> <sep> In fact, from what I see, going from Eq. (4).	B-Review	B-6	Review	167
2) to Eq. (	I-Review	I-6	Review	167
4) is not much of a conceptual challenge and the execution of Eq. (	I-Review	I-6	Review	167
4) (particularly the attention component described in Section 3.2) seems like a bunch of arbitrary engineering ideas which were put together to substantiate Eq. (	I-Review	I-6	Review	167
<sep> <sep> Is there a technical challenge in the entire pipeline that should have been highlighted?	B-Review	B-7	Review	167
<sep> <sep> For the experiment, could the author compare the performance between ASNP and ASNP without the imaginery component (but with the attention mechanism)?	B-Review	B-8	Review	167
It would be a good experiment to see if the imaginery component is necessary.	I-Review	I-8	Review	167
<sep> <sep> To summarize, I believe the paper in its current state is not well-motivated and appears very incremental given the prior works of SNP and ANP.	O	O	Review	167
Even its imaginery component, which is the key contribution here,  is, if I understand Eq. (3) correctly, not much different from context sampling of a NP.	B-Review	B-9	Review	167
<sep> <sep> Thank you for the detailed review.	O	O	Reply	167
With these points, we have revised our paper in numerous ways.	O	O	Reply	167
We address the raised questions in the following points.	O	O	Reply	167
<sep> <sep> Why attend past contexts:   SNP and ASNP are meta-transfer learning frameworks that require fewer observations from the current contexts because they also simultaneously use the information learned in the past.	B-Reply	B-2	Reply	167
Although the contexts of the past come from a different stochastic process, they are still related to the current stochastic process through the underlying transition dynamics.	I-Reply	I-2	Reply	167
For instance, consider an agent playing soccer.	I-Reply	I-2	Reply	167
Its sight is focussed on the ball in the front gathering only a limited observation in the current moment.	I-Reply	I-2	Reply	167
But using the past knowledge, the player still maintains a dynamic representation of the entire field and especially of the important information (like the locations of the key players) which is useful for making predictions/actions.	I-Reply	I-2	Reply	167
In the additional experiment (see the response to the next question) where we allow SNP to only attend its own time-step (i.e. K=1) and then increase the K to allow it to attend the past, its performance, not surprisingly, improves with increasing K (although still underperforming against ASNP).	I-Reply	I-2	Reply	167
So attending to the past contexts is useful.	I-Reply	I-2	Reply	167
<sep> <sep> Why not attend on the entire history of contexts:  We hypothesize and also empirically show that it is a better design choice to have a sequentially updated memory than a simple memory buffer that stores all the observed context points.	B-Reply	B-3	Reply	167
A sequentially updated memory has the benefit that the model learns to optimize the memory contents for its usefulness in predictions.	I-Reply	I-3	Reply	167
Another benefit is that it requires fewer storage locations as it does not naively store each and every incoming context point.	I-Reply	I-3	Reply	167
As mentioned, we compared the proposed ASNP against SNP endowed with attention on lossless memory of all context points gathered in the most recent K time-steps.	I-Reply	I-3	Reply	167
Although the performance of the latter improves with increasing K = 1 -&gt; 3 -&gt; 5 -&gt; infinity, it quickly saturates at infinity while still under-performing the proposed ASNP clearly highlighting the benefits of the imaginary context.	I-Reply	I-3	Reply	167
Another interesting point is that when K=infinity, the lossless memory buffer can collect up to 100 or more context points while ASNP outperforms this by attending only on 25 imaginary context points at any given time-step -- clearly highlighting that the imagined context is more size-efficient.	I-Reply	I-3	Reply	167
<sep> <sep> Why analogy to the human brain and need for sequentially-updated memory:   We have reduced the emphasis on the brain analogy in the updated manuscript.	B-Reply	B-4	Reply	167
Our work is inspired by the under-fitting in SNP that hinders its wider usage.	I-Reply	I-4	Reply	167
The analogy to the human brain supports our hypothesis that an imagination process for recalling the past is effective and the right way forward to resolve under-fitting.	I-Reply	I-4	Reply	167
<sep> <sep> Technical exposition is too vague:   Thank you for pointing out.	B-Reply	B-5	Reply	167
We have worked on making the ANP description and the technical exposition of ASNP clearer (see updated manuscript).	I-Reply	I-5	Reply	167
At the same time, due to space limitations, the finer details have been delegated to the appendices.	I-Reply	I-5	Reply	167
<sep> <sep> The arbitrariness of the design choices: The main idea is in introducing the imaginary context via and our implementation design choices realize that idea -- demonstrated by our better performance on a variety of tasks.	B-Reply	B-6	Reply	167
The finer design choices are a result of empirical model selection but some broad design choices were hypothesized as follows.	I-Reply	I-6	Reply	167
A. Imaginary queries should complement the available real context and therefore should depend on them.	I-Reply	I-6	Reply	167
<sep> B. Having imagination-tracker RNNs should be beneficial for prediction using the inferred knowledge of the underlying dynamics.	I-Reply	I-6	Reply	167
<sep> C. Attention on the tracker RNN hidden states helps capture the pairwise interactions between the context points and also updates the imagined memory with the more correct information from the real contexts.	I-Reply	I-6	Reply	167
<sep> <sep> Key technical challenge:    As responded in a previous question, making use of the past contexts is necessary for the attention to operate on.	B-Reply	B-7	Reply	167
Realizing that a simple memory buffer of the context history is a sub-optimal design choice, developing the idea and the implementation of the imaginary context was the key technical challenge.	I-Reply	I-7	Reply	167
<sep> <sep> Attention without imaginary context:   As answered in an earlier question, it is possible to truncate the stored contexts to hold the K most recent ones.	B-Reply	B-8	Reply	167
We have also tested this with K=infinity for the 1D regression tasks as described in the response for all reviewers, we found that our proposed ASNP still outperforms.	I-Reply	I-8	Reply	167
<sep> <sep> NP/ANP not much different from Eq.3:   We politely disagree.	B-Reply	B-9	Reply	167
Eq.3 depicts how the imaginary queries and values can be propagated from one time-step to the next and it is implemented using attention mechanisms.	I-Reply	I-9	Reply	167
This is clearly different from NP which does not use attention and also different from ANP because it can neither produce nor propagate imaginary contexts.	I-Reply	I-9	Reply	167

Authors present a method to address the problem of underfitting found in sequential neural processes.	O	O	Review	167
They cover the literature appropriately in regards to neural processes and developments pertaining to tackling the underfitting problem by applying an attention mechanism.	O	O	Review	167
Although, this has successfully been achieved with Neural Processes, the case is different with sequential neural processes, as they cannot store the past context.	O	O	Review	167
<sep> Authors addressed this problem by introducing an attention mechanism and model, i.e. Attentive sequential neural processes, which incorporates a memory mechanism of imaginary context.	O	O	Review	167
This imaginary context is generated through an RNN network and are treated as latent variables.	O	O	Review	167
<sep> The results presented show some promising improvements over other methods used and more results have been included in the appendix.	O	O	Review	167
It would be nice to demonstrate the performance in more challenging tasks as well, however the results presented and the new context-imagination introduced are quite promising indeed.	B-Review	B-1	Review	167
<sep> I have read the rebuttal carefully.	O	O	Review	167
I appreciate the extra effort put by the authors to address the issues raised from the other reviewers.	O	O	Review	167
I think, albeit not ground-breaking research, it could be a good addition to the programme nonetheless.	O	O	Review	167
Thank you for the positive review.	O	O	Reply	167
Yes, we agree that demonstrating ASNP on more challenging tasks would be a nice and fruitful future work.	B-Reply	B-1	Reply	167

<sep> ------------------------------------------------------------------------------------	O	O	Review	167
Rebuttal Response:	O	O	Review	167
Thanks for the clarifications.	O	O	Review	167
Nevertheless, the rebuttal and the comments of the other reviewers did not convince me that this paper is ready for publication at ICLR and I keep my vote with weak reject.	O	O	Review	167
IMO this paper can be improved by either focussing more on the HRL part and performing simpler qualitative evaluations to highlight the HRL contribution OR by focussing completly on the robotics part by incorporating more classical robotics approaches and demonstrating their shortcommings within the experiments.	O	O	Review	167
<sep> <sep> ------------------------------------------------------------------------------------	O	O	Review	167
Summary:	O	O	Review	167
The paper proposes a hierarchical reinforcement learning scheme to search for objects specified by an image.	O	O	Review	167
The proposed learning approach is applied to a virtual house setting and compared against multiple baselines.	O	O	Review	167
<sep> <sep> I like that the authors do an extensive comparison of different baselines and compare their results.	O	O	Review	167
My main concern is the setup with the task, which seems quite artificial.	B-Review	B-1	Review	167
Learning to search for objects using pure RL seems like neglecting all robotics research from the past 50 years.	I-Review	I-1	Review	167
By now we can generate maps, planners and low-level control policies to navigate within these maps.	I-Review	I-1	Review	167
Such approaches would be able to remember the objects location and just return to them and do not need to discover them 1000x times to remember them.	I-Review	I-1	Review	167
Therefore, one would only need to learn an optimal search pattern.	I-Review	I-1	Review	167
Therefore, I would like to see the proposed HRL approach in a more appropriate experiment or even more excitingly be combined with classical robotics.	I-Review	I-1	Review	167
I think that this combination should be quite exciting.	I-Review	I-1	Review	167
<sep> <sep> Regarding the HRL, could the authors please state their contributions in more detail?	B-Review	B-2	Review	167
There is quite some work on subgoal generation within HRL.	I-Review	I-2	Review	167
How does your work differ from these?	I-Review	I-2	Review	167
<sep> <sep> Currently, I am for borderline reject but I am happy to increase my rating during the rebuttal, when the authors clarify the motivation for the experiment and their contribution to HRL.	O	O	Review	167
<sep> <sep> Minor Comments:	O	O	Review	167
I think that the acronym is badly chosen.	B-Review	B-3	Review	167
The term ROS is already famously coined within the robotics community for the Robot Operating System.	I-Review	I-3	Review	167
Therefore, using this acronym for a robotics tasks is really confusing.	I-Review	I-3	Review	167
<sep> <sep> Thank you for the constructive comments.	O	O	Reply	167
We address the concerns as below.	O	O	Reply	167
<sep> 1.	O	O	Reply	167
We definitely agree with the reviewer that the classic robotic research, such as map-based navigation, has achieved great success, while we also believe they still have limits in the robotic object search task and we are trying to explore a new way to overcome these limits.	B-Reply	B-1	Reply	167
To be specific ,	I-Reply	I-1	Reply	167
1) Map is not always necessary for target-driven navigation.	I-Reply	I-1	Reply	167
Building a map is non-trivial and consequently navigating with the map may be inefficient especially when the indoor environment is typically dynamic.	I-Reply	I-1	Reply	167
<sep> 2) Separating the mapping and planning is again not necessary and may compromise the robustness of the whole system.	B-Reply	B-1	Reply	167
<sep> 3) To search the target object specified by an image, the robot needs an object recognition model.	B-Reply	B-1	Reply	167
Combining the object recognition model with the classic navigation algorithm may require additional efforts since they are not designed to work together.	I-Reply	I-1	Reply	167
<sep> <sep> 2.	O	O	Reply	167
Regarding the HRL, we would like to reiterate the contribution of our work: our proposed hierarchical RL 1) builds upon the human specified sub-goal space to incorporate human prior knowledge, that makes such a challenge task easier to learn and the solution interpretable; 2) optimizes with the intrinsic and the extrinsic rewards jointly to overcome the lingering inconsistency coming from the unsatisfied prior knowledge.	B-Reply	B-2	Reply	167
<sep> Although there are many work on sub-goal generation, they either learn to build the hierarchy and the sub-goal space themselves without prior knowledge, leaving the performance on challenge tasks much to be desired (as the poor performance of the Option-Critic method in our experiments demonstrated), or they fully adopt the human-specified sub-goal space without considering the possibility that the prior knowledge may not be accurate enough for learning the hierarchical policy.	I-Reply	I-2	Reply	167
In fact, the more challenging the task is, the more difficult it is for humans to provide satisfied prior knowledge and designate sub-goal space.	I-Reply	I-2	Reply	167
<sep> <sep> 3.	O	O	Reply	167
Thanks again for the suggestions on the ROS acronym, we will come up with a more proper one.	B-Reply	B-3	Reply	167

Summary:	O	O	Review	167
The paper proposes an intuitive 2-layer hierarchy for robotic object search.	O	O	Review	167
The high-level policy does subgoal selection, whereas the low-level layer handles explicit control.	O	O	Review	167
Notably, the low-level policy is trained to be aware of both the subgoal and the final goal.	O	O	Review	167
The authors conducted a series of ablations, demonstrating the value of training the low-level policy to be final goal-aware, and empirically demonstrated the strength of their method compared to other baselines.	O	O	Review	167
<sep> <sep> Decision: Weak Reject.	O	O	Review	167
The idea is intuitive and seems to be empirically successful (on some metrics).	B-Review	B-2	Review	167
My primary concern is that the work appears incremental when compared to the baselines HRL and HRL with Stop.	I-Review	I-2	Review	167
<sep> <sep> I think the acceptability of the paper is contingent on whether the tuning of alpha is considered a sufficiently significant contribution.	B-Review	B-3	Review	167
The authors themselves noted that their method (alpha = 1) is similar to HRL---differing only in the introduction of a termination signal.	I-Review	I-3	Review	167
This in and of itself suggests that the main contribution of the paper boils down to learning a suitable choice of alpha to manage the termination signal.	I-Review	I-3	Review	167
<sep> <sep> I would also like to better understand the distinction between the author‚Äôs method versus HRL with Stop.	B-Review	B-2	Review	167
Both methods have employ a low-level network capable of pre-emptive stopping.	I-Review	I-2	Review	167
How, then, is the termination signal for HRL with Stop trained?	I-Review	I-2	Review	167
<sep> <sep> If the authors can convincingly demonstrate the novelty of the proposal to learn the terminal signal via extrinsic reward supervision, and if the other reviewers feel similarly convinced, then I would feel more comfortable re-evaluating my concerns about the significance of this work.	I-Review	I-2	Review	167
<sep> <sep> I would also, in general, encourage a more thoughtful exposition of the results shown in Table 1.	B-Review	B-1	Review	167
Can the authors posit/explain why, for example, High-Level Only performs so much better on AS than the other models, but so poorly on the other metrics?	I-Review	I-1	Review	167
Thank you for the constructive comments.	O	O	Reply	167
We address the concerns as below,	O	O	Reply	167
1.	B-Reply	B-3	Reply	167
We would like to reiterate the contribution of our work:  we propose a general hierarchical RL framework that 1) builds upon the human specified sub-goal space to incorporate human prior knowledge, that makes such a challenge task easier to learn and the solution interpretable; 2) optimizes with the intrinsic and the extrinsic rewards jointly to overcome the lingering inconsistency coming from the unsatisfied prior knowledge.	I-Reply	I-3	Reply	167
<sep> Existing work either learn to build the hierarchy and the sub-goal space themselves (such as Option-Critic method), or fully adopt the human-specified sub-goal space without considering the possibility that the prior knowledge may not be accurate enough for learning the hierarchical policy (such as HRL method).	I-Reply	I-3	Reply	167
Both of them can be seen as specific cases of our framework (setting alpha as 0 or 1).	I-Reply	I-3	Reply	167
However, our empirical experiments show neither one performs as well as our method, demonstrating that not only the value of the alpha matters, but also the way to properly integrate the advantages of both methods is of high significance.	I-Reply	I-3	Reply	167
<sep> Compared to HRL with stop method, though we both have a termination signal, HRL with stop method simply extends the HRL method by adding an additional ‚Äústop‚Äù action into the low-level atomic action space.	B-Reply	B-2	Reply	167
Therefore, training the ‚Äústop‚Äù action remains the same as other low-level actions, i.e., which depends on the intrinsic advantage the ‚Äústop‚Äù action brings compared to other low-level actions.	I-Reply	I-2	Reply	167
While our method trains the termination signal by, that depends on the extrinsic advantage the current sub-goal brings compared to other sub-goals.	I-Reply	I-2	Reply	167
The experimental results also demonstrate our training strategy is more efficient.	I-Reply	I-2	Reply	167
<sep> <sep> 2.	B-Reply	B-1	Reply	167
For the experimental results, we define AS metric as the average steps over all successful cases.	I-Reply	I-1	Reply	167
As we can see from Table 1, High-level only achieves very low success rate (SR), so the small AS actually indicates the method can successfully reach the goal states only when the starting positions are close to the goal states.	I-Reply	I-1	Reply	167
Since SPL and AR take both SR and AS into consideration, they are reasonably low for the High-level only method.	I-Reply	I-1	Reply	167

This paper proposed a hierarchical approach to perform robotic object search (ROS).	O	O	Review	167
<sep> The idea is to use a high-level policy which produces subgoals and a low-level policy which produces atomic actions conditioned on both the subgoals and the true goal, and which is trained with a weighted sum of the original extrinsic reward and a reward for reaching the subgoal.	O	O	Review	167
Subgoals are consist of different objects in the field of view which the robot can choose to approach.	O	O	Review	167
<sep> The approach is evaluated on the House3D dataset, where it is shown to perform well.	O	O	Review	167
<sep> <sep> Recommendation: weak reject.	O	O	Review	167
<sep> <sep> This isn't a bad paper, but I'm not sure it will be of broad interest at ICLR.	B-Review	B-1	Review	167
<sep> It is very specific to ROS problem and House3D dataset and doesn't seem to propose a general algorithm which can be broadly applicable elsewhere.	I-Review	I-1	Review	167
The mechanism for generating subgoals and training the low-level policy is very task dependent (subgoals are constrained to be objects in the field of view, the intrinsic reward for training the low level policy is dependent on the size of the bounding box of the object defining the subgoal).	I-Review	I-1	Review	167
While this probably accounts for improved performance on the House3D dataset, I think the audience of ICLR would be more interested in a general approach which can be used in many different domains (even at the cost of performing less well on a specific domain than something more tailored).	I-Review	I-1	Review	167
This paper may be a better fit for a robotics conference.	I-Review	I-1	Review	167
<sep> <sep> Another point concerning the experimental evaluation.	B-Review	B-2	Review	167
Sparsity of the rewards is mentioned as a main motivation for the hierarchical approach.	I-Review	I-2	Review	167
However, there are a number of methods which use exploration bonuses to address this issue (pseudocounts, random network distillation, ICM etc. [	I-Review	I-2	Review	167
1, 2, 3]).	I-Review	I-2	Review	167
At least one of these should be included as a baseline.	I-Review	I-2	Review	167
<sep> <sep> Specific comments:	B-Review	B-3	Review	167
- using two letters for denote a single variable is confusing, since it seems like a product.	I-Review	I-3	Review	167
I.e. using "sg" to denote a subgoal, "at_t" to denote area.	I-Review	I-3	Review	167
Please use a single letter and add subscripts if necessary to disambiguate.	I-Review	I-3	Review	167
<sep> - in the various equations, please use "\log" instead of "log" so that it is not italicized.	I-Review	I-3	Review	167
<sep> - bottom of page 4: "Q-leaning" -&gt; "Q-learning"	I-Review	I-3	Review	167
- page 2: "way pf" -&gt; "way of"	I-Review	I-3	Review	167
- please use more informative names for Settings A/B	I-Review	I-3	Review	167
- First paragraph in Section 2: "hierarchical policy for the robot to perform the object search, motivated by how human beings conduct object search".	I-Review	I-3	Review	167
Saying the method is similar to how humans behave is a fairly big claim that should be substantiated by appropriate references, or not made at all.	I-Review	I-3	Review	167
<sep> <sep> References:	O	O	Review	167
[1] <a href="https://arxiv.org/abs/1810.12894" target="_blank" rel="nofollow">https://arxiv.org/abs/1810.12894</a>	O	O	Review	167
[2] <a href="https://arxiv.org/abs/1703.01310" target="_blank" rel="nofollow">https://arxiv.org/abs/1703.01310</a>	O	O	Review	167
[3] <a href="https://arxiv.org/abs/1705.05363" target="_blank" rel="nofollow">https://arxiv.org/abs/1705.05363</a>	O	O	Review	167
<sep> Thank you for the constructive comments.	O	O	Reply	167
We address the concerns as below,	O	O	Reply	167
1.	O	O	Reply	167
We would like to reiterate the contribution of our work is the general hierarchical RL framework we proposed that 1) builds upon the human specified sub-goal space to incorporate human prior knowledge, that makes such a challenge task easier to learn and the solution interpretable; 2) optimizes with the intrinsic and the extrinsic rewards jointly to overcome the lingering inconsistency coming from the unsatisfied prior knowledge.	B-Reply	B-1	Reply	167
<sep> The motivation is that we observed for challenge tasks, previous work that learn to build the hierarchy and the sub-goal space themselves without prior knowledge achieve poor performance, while other work that fully adopt the human-specified sub-goal space ignore the possibility that the prior knowledge may not be accurate enough for learning the hierarchical policy.	I-Reply	I-1	Reply	167
<sep> Robotic object search is such a task where humans can specify the sub-goal space as approaching a currently visible object based on the prior knowledge that approaching a related object may increase the probability of seeing the target object.	I-Reply	I-1	Reply	167
However, such prior knowledge and sub-goal space is not satisfied for learning an optimal hierarchical policy, i.e. to approach the target object, the robot does not necessarily to be close enough to a sub-goal specified object.	I-Reply	I-1	Reply	167
We therefore demonstrate our proposed hierarchical RL framework on this task, and we believe  the more challenging the task is, the more difficult it is for humans to provide satisfied prior knowledge and designate sub-goal space.	I-Reply	I-1	Reply	167
<sep> Overall, we believe our proposed hierarchical RL framework shed light on learning challenge tasks by utilizing human prior knowledge in a proper way.	I-Reply	I-1	Reply	167
The definitions of  the sub-goals or reward functions can be modified willingly in accordance with the different tasks.	I-Reply	I-1	Reply	167
<sep> <sep> 2.	B-Reply	B-2	Reply	167
The focus of this paper is to learn a hierarchical policy for robotic object search task that is able to address the sparse reward issue, so we compared our method with other hierarchical RL methods rather than all methods addressing the sparse reward issue.	I-Reply	I-2	Reply	167
<sep> <sep> 3.	O	O	Reply	167
Thanks again for pointing out the typos, and we have updated our paper properly.	B-Reply	B-3	Reply	167

The paper proposes an online variant of segment to segment transducers, which allows to circumvent the necessity of observing whole sentence, before making target predictions.	O	O	Review	299
Authors mostly build on their previous work, allowing additionally to leverage independent priors on the target hypotheses, like the language grammar or sentence length.	O	O	Review	299
<sep> <sep> Strong points:	O	O	Review	299
- well written, interesting idea of combining various sources of information in a Bayesian framework for seq2seq models	O	O	Review	299
Handling something in an online manner typically makes things more difficult, and this is what the authors are trying to do here - which is definitely of interest to the community	O	O	Review	299
- strong experimental section, with some strong results (though not complete: see weak points)	O	O	Review	299
<sep> Weak points:	O	O	Review	299
- Authors do not improve on computational complexity (w.r.t Tillmann proposal), hence the algorithms may be found difficult to apply in scenarios where inputs may be long (this already takes into account a rather constrained model of alignment latent variables)	B-Review	B-1	Review	299
- What about the baseline where you only combine direct, LM and bias contributions (no channel)?	B-Review	B-2	Review	299
Was there any (non-obvious) algorithmic constraint why - this has not been included?	I-Review	I-2	Review	299
<sep> <sep> Some other (minor) comments:	O	O	Review	299
<sep> - Related to the first weak point: can you elaborate more on how the clue of your work is conceptually different from the work of Tillmann et al (1997) (except, of course, the fact you use connectionist discriminative models to derive particular conditional probabilities).	B-Review	B-1	Review	299
<sep> - How sensitive is the model to different choices of hyper-parameters in eq (3).	B-Review	B-3	Review	299
Do you naively search through the search space of those, or do something more clever?	I-Review	I-3	Review	299
<sep> - Some more comments on details of the auxiliary direct model would be definitely of interest.	B-Review	B-4	Review	299
<sep> - How crucial is the correct choice of the pruning variables (K1 and K2)?	B-Review	B-5	Review	299
<sep> - Sec.2: makes no Markovian assumptions -> no first-order Markovian assumption?	B-Review	B-6	Review	299
<sep> <sep> Typos:	O	O	Review	299
Table 1: chanel -> channel (one before last row)	O	O	Review	299
<sep> Apologies for late review.	O	O	Review	299
Thanks for your review.	O	O	Reply	299
<sep> <sep> We will add the results for direct + LM + bias soon, but our preliminary experiments indicated this is a quite ineffective combination (in line with previous findings of Gulcehre et al 2015).	B-Reply	B-2	Reply	299
<sep> <sep> The hyperparameters in Eq3 controls how much each model contributes to the score of output sequences.	B-Reply	B-3	Reply	299
In the sentence compression task, increasing the weight for the channel model (\lambda_1) and and the bias (\lambda_4) results in higher recall and lower precision.	I-Reply	I-3	Reply	299
Increasing the weights for the direct model (\lambda_2) and language model (\lambda_3) results in lower recall and higher precision.	I-Reply	I-3	Reply	299
The bias for length is less sensitive than the others.	I-Reply	I-3	Reply	299
On the heldout dataset with 1000 sentence pairs, ROUGE recall/precision increase/decrease by 1 point when \lambda_4 is increased by 0.2.	I-Reply	I-3	Reply	299
The ratio between \lambda_1, \lambda_2 and \lambda_3 influences the performance significantly.	I-Reply	I-3	Reply	299
The model behaves badly when the ratio, i.e. the difference between \lambdas, is big.	I-Reply	I-3	Reply	299
For example, keeping the other weights to 1, decrease \lambda_3 from 1.0 to 0.8, the ROUGE-1 precision drops from ~33 to 30.	I-Reply	I-3	Reply	299
If \lambda_3 is set to 0.5, the ROUGE-1 precision drops even further reaching ~23.	I-Reply	I-3	Reply	299
We simply use grid search to find the relatively optimal hyperparameters, with the range of [0.2, 0.5, 0.8, 1.0].	I-Reply	I-3	Reply	299
<sep> The performance is not sensitive to the beam size K1 and K2.	B-Reply	B-5	Reply	299
Using a big K1 and K2 does not have much difference as using smaller ones.	I-Reply	I-5	Reply	299
We did not tune these values in the experiments.	I-Reply	I-5	Reply	299
<sep> <sep> In general, our decoding algorithm shares the same search criterion as the work of Tillmann et al (1997).	B-Reply	B-1	Reply	299
There are a few subtle differences: 1) Without any pruning, as described in (Tillmann et al, 1997), the decoding algorithm has a complexity of I * J_max * |V|^2, where I is the length of the source sequence, and J_max is the maximum length of target sequence and |V| is the size of vocabulary.	I-Reply	I-1	Reply	299
We reduce the complexity to I * I * J_max * |V| by introducing the auxiliary direct model to propose a constant number of candidate output sequences, followed by reranking with the noisy channel model.	I-Reply	I-1	Reply	299
2) In the work of Tillmann et al (1997), they restrict the difference z_j - z_{j - 1} (jump size) to be no greater than 2 and use a bigram language model.	I-Reply	I-1	Reply	299
By contrast, in our algorithm, we don‚Äôt have this restriction.	I-Reply	I-1	Reply	299

This paper proposes the neural noisy channel model, P(x|y), where (x, y) is a input-to-out sequence pair,  based on the authors' previous work on segment to segment neural transduction (SSNT) model.	O	O	Review	299
For the noisy channel model, the key difference from sequence-to-sequence is that the complete sequence y is not observed beforehand.	O	O	Review	299
SSNT handles this problem elegantly by performing incremental alignment and prediction.	O	O	Review	299
However, this paper does not present anything that is particular novel on top of the SSNT.	O	O	Review	299
The SSNT model is still applicable by reverting the input and output sequences.	O	O	Review	299
The authors said that an unidirectional LSTM has to be used as an encoder instead of the bidirectional LSTM, but I think the difference is minor.	O	O	Review	299
The decoding algorithm presented in the appendix is relatively new.	O	O	Review	299
<sep> <sep> The experimental study is very comprehensive and strong, however, there is one important baseline number that is missing for all the experiments.	O	O	Review	299
Can you give the number that uses direct + LM + bias, and if you can give direct + bias number would be even better.	B-Review	B-1	Review	299
Although using a LM for the direct model does not make a lot of sense mathematically, however, it works pretty well in practice, and the LM can rescore and smooth your predictions, see	I-Review	I-1	Review	299
<sep> Deep Speech 2: End-to-End Speech Recognition in English and Mandarin	I-Review	I-1	Review	299
<sep> from Baidu for example.	I-Review	I-1	Review	299
I think the LM may be also the key to explain why noisy channel is much better than direct model in Table 3.	I-Review	I-1	Review	299
A couple minor questions are	O	O	Review	299
<sep> 1.	O	O	Review	299
it is not very clear to me is your direct model in the experiments SSNT or sequence-to-sequence model?	B-Review	B-2	Review	299
<sep> <sep> 2.	O	O	Review	299
O(|x|^2*|y|) training complexity is OK, but it would be great to further cut down the computational cost, as it is still very expensive for long input sequences, for example, for paragraph or document level modeling, or speech sequences.	B-Review	B-3	Review	299
<sep> <sep> The paper is well written, and overall, it is still an interesting paper, as the channel model is always of great interest to the general public.	O	O	Review	299
<sep> <sep> Thanks for your review.	O	O	Reply	299
We will add the results for direct + LM + bias soon.	B-Reply	B-1	Reply	299
<sep> The direct model in the paper refers to SSNT.	B-Reply	B-2	Reply	299

This paper proposes MaskGAN, a GAN-based generative model of text based on	O	O	Review	299
the idea of recovery from masked text.	O	O	Review	299
<sep> For this purpose, authors employed a reinceforcement learning approach to	O	O	Review	299
optize a prediction from masked text.	O	O	Review	299
Moreover, authors argue that the	O	O	Review	299
quality of generated texts is not appropriately measured by perplexities,	O	O	Review	299
thus using another criterion of a diversity of generated n-grams as well as	O	O	Review	299
qualitative evaluations by examples and by humans.	O	O	Review	299
<sep> <sep> While basically the approach seems plausible, the issue is that the result is	B-Review	B-1	Review	299
not compared to ordinary LSTM-based baselines.	I-Review	I-1	Review	299
While it is better than a	I-Review	I-1	Review	299
conterpart of MLE (MaskedMLE), whether the result is qualitatively better than	I-Review	I-1	Review	299
ordinary LSTM is still in question.	I-Review	I-1	Review	299
<sep> <sep> In fact, this is already appearent both from the model architectures and the	O	O	Review	299
generated examples: because the model aims to fill-in blanks from the text	O	O	Review	299
around (up to that time), generated texts are generally locally valid but not	O	O	Review	299
always valid globally.	O	O	Review	299
This issue is also pointed out by authors in Appendix	O	O	Review	299
A.2.	O	O	Review	299
<sep> While the idea of using mask is interesting and important, I think if this	B-Review	B-2	Review	299
idea could be implemented in another way, because it resembles Gibbs sampling	I-Review	I-2	Review	299
where each token is sampled from its sorrounding context, while its objective	I-Review	I-2	Review	299
is still global, sentence-wise.	I-Review	I-2	Review	299
As argued in Section 1, the ability of	I-Review	I-2	Review	299
obtaining signals token-wise looks beneficial at first, but it will actually	I-Review	I-2	Review	299
break a global validity of syntax and other sentence-wise phenoma.	I-Review	I-2	Review	299
<sep> <sep> Based on the arguments above, I think this paper is valuable at least	B-Review	B-3	Review	299
conceptually, but doubt if it is actually usable in place of ordinary LSTM	I-Review	I-3	Review	299
(or RNN)-based generation.	I-Review	I-3	Review	299
<sep> More arguments are desirable for the advantage of this paper, i.e. quantitative	I-Review	I-3	Review	299
evaluation of diversity of generated text as opposed to LSTM-based methods.	I-Review	I-3	Review	299
<sep> <sep> *Based on the rebuttals and thorough experimental results, I modified the global rating.	O	O	Review	299
Thank you for your review and comments!	O	O	Reply	299
<sep> <sep> We reiterate your two primary concerns as the following:	O	O	Reply	299
1.	O	O	Reply	299
A standard LSTM-baseline of a non-masked task should be included.	O	O	Reply	299
<sep> 2.	O	O	Reply	299
The MaskGAN algorithm is enforcing only local consistency within text, but does not aid with global consistency.	O	O	Reply	299
<sep> *Standard Baselines*	O	O	Reply	299
To address your first concern, we added a thorough human evaluation of a language model (LM) LSTM baseline.	B-Reply	B-1	Reply	299
We use the samples produced from our Variational Dropout-LSTM language model and evaluate the resulting sample quality for both the PTB and IMDB datasets using Amazon Mechanical Turk.	I-Reply	I-1	Reply	299
You can see these results updated in our paper in Table 7 and Table 8.	I-Reply	I-1	Reply	299
We demonstrate that the MaskGAN training algorithm results in improvements over both the language model and the MaskMLE benchmarks on all three metrics: grammaticality, topicality and overall quality.	I-Reply	I-1	Reply	299
In particular, MaskGAN samples are preferred over LM LSTM baseline samples, 58.0% vs 15.7% of the time for IMDB reviews.	I-Reply	I-1	Reply	299
<sep> <sep> *Local vs. Global Consistency*	O	O	Reply	299
In regards to your comment on Gibbs sampling, we do agree that this would likely be a valid and helpful technique for inference.	B-Reply	B-2	Reply	299
In our paper, we in-fill our samples autoregressively from left to right, as is conventional in language modeling.	I-Reply	I-2	Reply	299
(This approach allows for fast unconditional generation as with the LM baseline and is what our human evaluation is targeted at).	I-Reply	I-2	Reply	299
This autoregressive process relies on the attention module of our decoder in order to provide full context during the sampling process.	I-Reply	I-2	Reply	299
For instance, when the decoder is producing the probability distribution over token x_t, it is attending over the future context to create this distribution.	I-Reply	I-2	Reply	299
If the subject of the sentence is known to be a female leader and the model is generating a pronoun, the model has the ability to attend to the future context and select the correct gender-matched pronoun.	I-Reply	I-2	Reply	299
If the model fails to do this, a well-trained discriminator will ascribe a low reward to this pronoun selection which in turn will generate useful gradients through the attention mechanism.	I-Reply	I-2	Reply	299
We have observed this behaviour during preliminary experiments.	I-Reply	I-2	Reply	299
We argue that global consistency is built into this architecture but to solve the boundary problems in appendix C.2, allowing the autoregressive model decide when to stop instead of forcing it to output a fix number of words may resolve some of the syntactic issues.	I-Reply	I-2	Reply	299
<sep> <sep> We also expand table 6 to show the diversity of the generated samples compared to a standard LM-LSTM.	B-Reply	B-3	Reply	299

Generating high-quality sentences/paragraphs is an open research problem that is receiving a lot of attention.	O	O	Review	299
This text generation task is traditionally done using recurrent neural networks.	O	O	Review	299
This paper proposes to generate text using GANs.	O	O	Review	299
GANs are notorious for drawing images of high quality but they have a hard time dealing with text due to its discrete nature.	O	O	Review	299
This paper's approach is to use an actor-critic to train the generator of the GAN and use the usual maximum likelihood with SGD to train the discriminator.	O	O	Review	299
The whole network is trained on the "fill-in-the-blank" task using the sequence-to-sequence architecture for both the generator and the discriminator.	O	O	Review	299
At training time, the generator's encoder computes a context representation using the masked sequence.	O	O	Review	299
This context is conditioned upon to generate missing words.	O	O	Review	299
The discriminator is similar and conditions on the generator's output and the masked sequence to output the probability of a word in the generator's output being fake or real.	O	O	Review	299
With this approach, one can generate text at test time by setting all inputs to blanks.	O	O	Review	299
<sep> <sep> Pros and positive remarks:	O	O	Review	299
--I liked the idea behind this paper.	O	O	Review	299
I find it nice how they benefited from context (left context and right context) by solving a "fill-in-the-blank" task at training time and translating this into text generation at test time.	O	O	Review	299
<sep> --The experiments were well carried through and very thorough.	O	O	Review	299
<sep> --I second the decision of passing the masked sequence to the generator's encoder instead of the unmasked sequence.	O	O	Review	299
I first thought that performance would be better when the generator's encoder uses the unmasked sequence.	O	O	Review	299
Passing the masked sequence is the right thing to do to avoid the mismatch between training time and test time.	O	O	Review	299
<sep> <sep> Cons and negative remarks:	O	O	Review	299
--There is a lot of pre-training required for the proposed architecture.	B-Review	B-1	Review	299
There is too much pre-training.	I-Review	I-1	Review	299
I find this less elegant.	I-Review	I-1	Review	299
<sep> --There were some unanswered questions:	O	O	Review	299
(1) was pre-training done for the baseline as well?	B-Review	B-2	Review	299
<sep> (2) how was the masking done?	B-Review	B-3	Review	299
how did you decide on the words to mask?	I-Review	I-3	Review	299
was this at random?	I-Review	I-3	Review	299
<sep> (3) it was not made very clear whether the discriminator also conditions on the unmasked sequence.	B-Review	B-4	Review	299
It needs to but	I-Review	I-4	Review	299
that was not explicit in the paper.	I-Review	I-4	Review	299
<sep> --Very minor: although it is similar to the generator, it would have been nice to see the architecture of the discriminator with example input and output as well.	B-Review	B-5	Review	299
<sep> <sep> <sep> Suggestion: for the IMDB dataset, it would be interesting to see if you generate better sentences by conditioning on the sentiment as well.	B-Review	B-6	Review	299
<sep> <sep> Thank you for your review!	O	O	Reply	299
<sep> <sep> *Pretraining*	O	O	Reply	299
We found evidence that this architecture could replicate simple data distributions without pretraining and found it could perform reasonably on larger data sets, however, in the interest of computational efficiency, we relied on pretraining procedures, similar to other work in this field.	B-Reply	B-2	Reply	299
All our baselines also included pre-training.	I-Reply	I-2	Reply	299
<sep> <sep> To test whether all the pretraining steps were necessary, we experimented with training MaskMLE and MaskGAN on PTB without initializing from a pretrained language model.	I-Reply	I-2	Reply	299
The perplexity of the generated samples were 117 without pretraining and 126 with pretraining, showing that at least for PTB language model pretraining does not appear to be necessary.	I-Reply	I-2	Reply	299
<sep> <sep> Models trained from scratch were found to more computationally intense.	I-Reply	I-2	Reply	299
By building off near state-of-the-art language models, we were able to rapidly iterate over architectures thanks to faster convergence.	I-Reply	I-2	Reply	299
Additionally, we were working at a word-level representation where our softmax is producing a distribution over O(10K)-tokens.	I-Reply	I-2	Reply	299
Attempting reinforcement learning methods from scratch on an ‚Äòaction space‚Äô of this magnitude is prone to extreme variance.	I-Reply	I-2	Reply	299
The likelihood of producing a correct token and receiving a positive reward is exceedingly rare; therefore, the model spends a long time exploring the space with almost always negative rewards.	I-Reply	I-2	Reply	299
As a related and budding research avenue, one could consider the properties and characteristics of exclusively GAN-trained language models.	I-Reply	I-2	Reply	299
<sep> *Masking Strategy*	O	O	Reply	299
We predominantly evaluated two masking strategies at training time.	B-Reply	B-3	Reply	299
One was a completely random mask and the other was a contiguous mask, where blocks of adjacent words are masked.	I-Reply	I-3	Reply	299
Though we were able to train with both strategies, we found that the random mask was more difficult to train.	I-Reply	I-3	Reply	299
However, and more significantly, the random mask doesn‚Äôt share the primary benefit of GAN autoregressive text generation (termed free-running mode in the literature).	I-Reply	I-3	Reply	299
One can see this because for a given percentage of words to omit, a Generator given the random mask will fill-in shorter sequences autoregressively than the contiguous mask will.	I-Reply	I-3	Reply	299
GAN-training allows our training and inference procedure to be the same, in contrast to teacher-forcing in maximum likelihood training.	I-Reply	I-3	Reply	299
Therefore, we generally found it beneficial to allow the model to produce long sequences, conditioned on what it had produced before, rather than filling in short disjoint sequences or or even single tokens.	I-Reply	I-3	Reply	299

Quality: The work focuses on a novel problem of generating text sample using GAN and a novel in-filling mechanism of words.	O	O	Review	299
Using GAN to generate samples in adversarial setup in texts has been limited due to the mode collapse and training instability issues.	O	O	Review	299
As a remedy to these problems an in-filling-task conditioning on the surrounding text has been proposed.	O	O	Review	299
But, the use of the rewards at every time step (RL mechanism) to employ the actor-critic training procedure could be challenging computationally challenging.	O	O	Review	299
<sep> <sep> Clarity: The mechanism of generating the text samples using the proposed methodology has been described clearly.	B-Review	B-1	Review	299
However the description of the reinforcement learning step could have been made a bit more clear.	I-Review	I-1	Review	299
<sep> <sep> Originality: The work indeed use a novel mechanism of in-filling via a conditioning approach to overcome the difficulties of GAN training in text settings.	B-Review	B-2	Review	299
There has been some work using GAN to generate adversarial examples in textual context too to check the robustness of classifiers.	I-Review	I-2	Review	299
How this current work compares with the existing such literature?	I-Review	I-2	Review	299
<sep> <sep> Significance: The research problem is indeed significant since the use of GAN in generating adversarial examples in image analysis has been more prevalent compared to text settings.	B-Review	B-3	Review	299
Also, the proposed actor-critic training procedure via RL methodology is indeed significant from its application in natural language processing.	I-Review	I-3	Review	299
<sep> <sep> pros:	O	O	Review	299
(a) Human evaluations applications to several datasets show the usefulness of MaskGen over the maximum likelihood trained model in generating more realistic text samples.	O	O	Review	299
<sep> (b) Using a novel in-filling procedure to overcome the complexities in GAN training.	O	O	Review	299
<sep> (c) generation of high quality samples even with higher perplexity on ground truth set.	O	O	Review	299
<sep> <sep> cons:	O	O	Review	299
(a) Use of rewards at every time step to the actor-critic training procure could be computationally expensive.	B-Review	B-4	Review	299
<sep> (b) How to overcome the situation where in-filling might introduce implausible text sequences with respect to the surrounding words?	B-Review	B-5	Review	299
<sep> (c) Depending on the Mask quality GAN can produce low quality samples.	B-Review	B-6	Review	299
Any practical way of choosing the mask?	I-Review	I-6	Review	299
Thank you for your review!	O	O	Reply	299
<sep> *Importance and Computational Cost of Actor-Critic*	O	O	Reply	299
We‚Äôd like to address your concern about the importance and the computational challenges of the actor-critic method.	B-Reply	B-3	Reply	299
We believe that this was a crucial component to get the results we did and it was achieved with no significant additional computational cost.	I-Reply	I-3	Reply	299
<sep> In building architectures for this novel task, we were contending with both reinforcement learning challenges as well as GAN-mode collapse issues.	I-Reply	I-3	Reply	299
Specifically, variance in the gradients to the Generator was a major issue.	I-Reply	I-3	Reply	299
To remedy this, we simply added a value estimator as an additional head on the Discriminator.	I-Reply	I-3	Reply	299
The critic estimates the expected value of the current state, conditioned on everything produced before.	I-Reply	I-3	Reply	299
This is very lightweight in terms of additional parameters since we‚Äôre sharing almost all parameters with the Discriminator.	I-Reply	I-3	Reply	299
We found that using this reduced the advantage to the Generator by over an order of magnitude.	I-Reply	I-3	Reply	299
This was a critical piece of efficiently training our algorithm.	I-Reply	I-3	Reply	299
We compared the performance of this actor-critic approach against a standard exponential moving average baseline and found there to be no significant difference in training step time.	I-Reply	I-3	Reply	299
<sep> <sep> *Clarity*	O	O	Reply	299
Thanks and we updated the writing to more clearly delineate the reinforcement learning training.	B-Reply	B-1	Reply	299
<sep> <sep> *Originality*	O	O	Reply	299
As far as we are aware, no work has considered this conditional task where a per-time-step reward is architected in.	B-Reply	B-2	Reply	299
Additionally, our use of an actor-critic methodology in GAN-training is a minimally explored avenue.	I-Reply	I-2	Reply	299
Finally, the existing literature on textual adversarial examples focus on classifier accuracy and generally don't do human evaluations on the quality of the generated examples as we do.	I-Reply	I-2	Reply	299
<sep> <sep> *Masking Strategy*	O	O	Reply	299
We predominantly evaluated two masking strategies at training time.	B-Reply	B-6	Reply	299
One was a completely random mask and the other were contiguous masks, where blocks of adjacent words are masked.	I-Reply	I-6	Reply	299
Though we were able to train with both strategies, we found that the random mask was more difficult to train.	I-Reply	I-6	Reply	299
However, and more significantly, the random mask doesn‚Äôt share the primary benefit of GAN autoregressive text generation (termed free-running mode in the literature).	I-Reply	I-6	Reply	299
One can see this because for a given percentage of words to omit, a Generator given the random mask will fill-in shorter sequences autoregressively than the contiguous mask.	I-Reply	I-6	Reply	299
GAN-training allows our training and inference procedure to be the same, in contrast to teacher-forcing in the maximum likelihood training.	I-Reply	I-6	Reply	299
Therefore, we generally found it beneficial to allow the model to produce long sequences, conditioned on what it had produced before, rather than filling in short disjoint sequences or or even single tokens.	I-Reply	I-6	Reply	299

This paper revisits on a simulated model learned from data, previous work by Kenet et al 2003 in the journal Nature, on the statistics of spontaneous neural activities in the visual cortex, in particular, their correlations to orientation maps.	O	O	Review	62
The authors first learn to model image patches in an unsupervised fashion.	O	O	Review	62
In a second step, the spontaneous hidden activities produced by the learned model are recorded and compared to the ones observed by Kenet et al 2003.	O	O	Review	62
<sep> <sep> The authors build on the centered deep Boltzmann machines, adapting them to real-valued Gaussian-like inputs.	B-Review	B-1	Review	62
An important aspect of the solution learned by a DBM is the amount of sparsity.	I-Review	I-1	Review	62
Authors do not use an explicit sparse penalty, but biases are shown in Algorithm 1 to be initialized to -4, suggesting that sparsity is still important.	I-Review	I-1	Review	62
<sep> <sep> Activation patterns produced by the proposed model are shown to be similar to measurements by Kenet et al 2003 on real neural activity.	B-Review	B-2	Review	62
The use of an unconstrained Gibbs sampler to compute spontaneous activities is questionable, as to my understanding, input should be deactivated.	I-Review	I-2	Review	62
A more powerful result would be to show similar activation patterns when the input units are explicitly constrained to be inactive.	I-Review	I-2	Review	62
Conditional DBMs might be useful in this regard.	B-Review	B-3	Review	62
Thanks for your helpful comments.	O	O	Reply	62
<sep> <sep> 1) ‚ÄúAn important aspect of the solution learned by a DBM is the amount of sparsity.	O	O	Reply	62
Authors do not use an explicit sparse penalty, but biases are shown in Algorithm 1 to be initialized to -4, suggesting that sparsity is still important.	O	O	Reply	62
‚Äù	O	O	Reply	62
<sep> We agree that initializing the biases to -4 potentially encourage the sparse representation in the hidden layers.	B-Reply	B-1	Reply	62
However, the claim that the learned representation is sparse needs further experiment supports.	I-Reply	I-1	Reply	62
<sep> <sep> 2) ‚ÄúThe use of an unconstrained Gibbs sampler to compute spontaneous activities is questionable, as to my understanding, input should be deactivated.	O	O	Reply	62
A more powerful result would be to show similar activation patterns when the input units are explicitly constrained to be inactive.	O	O	Reply	62
‚Äù	O	O	Reply	62
<sep> We argue that it is not necessary to constrain the visible units to be inactive during modeling the spontaneous activity.	B-Reply	B-2	Reply	62
Briefly, Spontaneous activity is the ongoing activity in the absence of intentional sensory input.	I-Reply	I-2	Reply	62
Biologically, it is not necessary to cut off the bottom-up stimulus input [22] as in [6, 7]. See details in the response to the common comments C).	I-Reply	I-2	Reply	62
<sep> <sep> 3) ‚ÄúConditional DBMs might be useful in this regard.	O	O	Reply	62
‚Äù	O	O	Reply	62
<sep> Sorry for my limited knowledge.	B-Reply	B-3	Reply	62
Could you please send me a link to the work on ‚Äúconditional DBMs‚Äù?	I-Reply	I-3	Reply	62

In this paper the authors train a DBM model on natural image patches, conduct a pseudo-physiology experiment on the model, and show that the spontaneous correlation structure of the model resembles that in a V1 experiment.	O	O	Review	62
<sep> <sep> The claimed results of the paper are:	O	O	Review	62
+ Receptive fields that resemble V1 and V2 (only a qualitative statement is made)	B-Review	B-1	Review	62
+ Correlation structure that resembles spontaneous activity	O	O	Review	62
<sep> My biggest concern relates to the question, 'Why are any of these results unexpected?'	B-Review	B-2	Review	62
The V1 and V2 receptive field results have been previously reported (ad nauseam for V1), and are not the focus of the paper, so I will ignore these.	I-Review	I-2	Review	62
The correlation structure also appears to be a result entirely expected by the model construction.	I-Review	I-2	Review	62
Isn't it the case that the DBM should be capturing statistical relationships in natural images and that co-linearity (and feature non-orthogonality, or high inner product) is a well known property of natural scene statistics?	I-Review	I-2	Review	62
Taking the results at face value, why is this model unique to the finding, or what does this teach me about the brain, or about the model?	I-Review	I-2	Review	62
<sep> <sep> Another concern, is that the main result in Figure 3 is not very convincing.	B-Review	B-3	Review	62
Is there any statistical test to show the difference between the distributions in 3a?	B-Review	B-4	Review	62
Why is the uncorrelated noise distribution the proper control?	I-Review	I-4	Review	62
For Figure 3b, the max (solid blue line) looks pretty close to the relative occurrence line (solid red line), while the neural data seems to have larger divergence in these two measures.	B-Review	B-5	Review	62
What is the important characteristic of this curve?	I-Review	I-5	Review	62
Is there anything surprising about it?	I-Review	I-5	Review	62
It peaks at 0 and 90, just like the neural data, but what makes this model unique to capturing this phenomena?	I-Review	I-5	Review	62
<sep> <sep> Some of the most interesting statements in the paper are given in the footnotes or stated as ongoing work.	O	O	Review	62
For example, I find it most interesting that certain models show the observed behavior, while others do not (footnote 6).	B-Review	B-6	Review	62
In fact, I would have preferred to see the entire paper revolve around this finding.	I-Review	I-6	Review	62
Far too many papers of this type propose one and only one model to account for the data.	O	O	Review	62
The advancement of this type of work requires the comparison of models and the invalidation of models.	O	O	Review	62
Also, your title seems to indicate that a 'centered Gaussian-binary DBM' is necessary to fit the findings.	B-Review	B-7	Review	62
<sep> <sep> I am very confused about your use of the term 'homeostatic'.	B-Review	B-8	Review	62
You seem to refer to homeostatic as the condition where you sample from your model with the input unclamped.	I-Review	I-8	Review	62
However, in biology homeostasis is the regulation of variables (or machinery) such that some state is held fixed.	I-Review	I-8	Review	62
I thought that homeostasis in your model would be more related to learning, i.e. weight updates.	I-Review	I-8	Review	62
<sep> <sep> Why, in your model, isn't the spontaneous activity condition a situation where the input is black (or all zeros)?	B-Review	B-9	Review	62
Isn't this the 'stimulus' condition that resembles the experiment?	I-Review	I-9	Review	62
How should we model closing the eyes, going into a pitch black room, or severing the input from retina to LGN (or LGN to V1)?	I-Review	I-9	Review	62
<sep> <sep> Why did you use mean-field to approximate the response to the stimuli?	B-Review	B-10	Review	62
This means for one condition you run mean-field and the other you run sampling.	I-Review	I-10	Review	62
It seems that this just introduces discrepancy between the conditions.	I-Review	I-10	Review	62
<sep> <sep> A note on exposition, I would prefer less detail on already published models and training algorithms, e.g. section 2.1 and Algorithm 1.	B-Review	B-11	Review	62
and more detail on the experiment that you ran (sampling procedure, and explaining better the background of Figure 3b).	I-Review	I-11	Review	62
Thanks for your helpful comments.	O	O	Reply	62
<sep> 1)	O	O	Reply	62
1.1) ‚ÄúReceptive fields that resemble V1 and V2 (only a qualitative statement is made)‚Äù	O	O	Reply	62
<sep> Removed the statement suggesting that the model captures receptive field properties in V2.	B-Reply	B-1	Reply	62
Please refer to the detailed discussion in the response to common comments 2).	I-Reply	I-1	Reply	62
<sep> <sep> 1.2) ‚ÄúWhy are any of these results unexpected? ‚	O	O	Reply	62
Ä¶ why is this model unique to the finding, or what does this teach me about the brain, or about the model?‚Äù	O	O	Reply	62
<sep> Clarified the contribution and conclusion of our work.	B-Reply	B-2	Reply	62
See more details in the responses to common comments A).	I-Reply	I-2	Reply	62
<sep> <sep> We agree that a GDBM as a probabilistic model is expected to capture the statistical relationships in natural scene statistics.	I-Reply	I-2	Reply	62
However, there two points we want to make here.	I-Reply	I-2	Reply	62
<sep> <sep> i) The patterns found in the spontaneous visual cortical activity show similar properties as the prior distribution of the trained GDBMs, which has been mainly demonstrated in our paper.	B-Reply	B-2	Reply	62
This suggests that a brain might learn to generate expectations of internal states as a generative model.	I-Reply	I-2	Reply	62
<sep> <sep> ii)  By comparing different models in modeling the spontaneous activity and different sampling procedures (, which is added in section 4 of the revised version), we suggest that the observed spontaneous activity patterns needs both bottom-up and top-down interactions.	B-Reply	B-2	Reply	62
To be specific, we found that neither GRBMs nor DBNs can match the biological experiments as well as GDBMs.	I-Reply	I-2	Reply	62
Besides, by clamping either the visible units or the second-layer hidden units to the centering offsets, we could not observe any activity patterns in the spontaneous frames even in the GDBMs.	I-Reply	I-2	Reply	62
See more details in the responses to common comments E).	I-Reply	I-2	Reply	62
<sep> <sep> 2) ‚ÄúAnother concern, is that the main result in Figure 3 is not very convincing.	O	O	Reply	62
‚Äù	O	O	Reply	62
<sep> Clarified the purpose we plot Figure 4 (used to be Figure 3 in previous version) is to demonstrate that the spontaneous frames of centered GDBMs encompass similar properties as the spontaneous activity found in [1]. We wrote in section 3.2.3 of the revised version that ‚ÄúTo establish the similarity between the single-condition maps and the spontaneous frames, we calculated the spatial correlation coefficients between them.	B-Reply	B-3	Reply	62
‚Äù	O	O	Reply	62
<sep> 2.1) ‚ÄúIs there any statistical test to show the difference between the distributions in 3a?	O	O	Reply	62
Why is the uncorrelated noise distribution the proper control?‚Äù	O	O	Reply	62
<sep> In Figure 4a, we have chosen the random generated activity patterns in order to show the correlations between the spontaneous frames and the orientation maps are stronger than expected by chance.	B-Reply	B-4	Reply	62
We used t-test for checking the significance of the correlations, i.e. the threshold of significant correlation was chosen to be 0.182 (P<0.01) as described in the text.	I-Reply	I-4	Reply	62
It can be seen in Figure 4a that the correlation coefficients between the spontaneous frames and the random generated patterns rarely exceed this threshold.	I-Reply	I-4	Reply	62
<sep> <sep> We added the description of statistical details of the distributions in Figure 4a and wrote '... the max correlation coefficient is 0.50+/-0.06, whereas the correlation coefficients between the spontaneous frames and the random generated pattern seldom reach 0.2'.	I-Reply	I-4	Reply	62
<sep> <sep> 2.2) ‚ÄúFor Figure 3b, the max (solid blue line) looks pretty close to the relative occurrence line (solid red line), while the neural data seems to have larger divergence in these two measures.	O	O	Reply	62
What is the important characteristic of this curve?	O	O	Reply	62
Is there anything surprising about it?	O	O	Reply	62
It peaks at 0 and 90, just like the neural data, but what makes this model unique to capturing this phenomenon?‚Äù	O	O	Reply	62
<sep> As for Figure 4b, we followed the convention in the Figure 3b in [1]. As in [1], the purpose is to show that i) states corresponding to cardinal orientations emerged with larger correlation coefficients than oblique ones, ii) the former emerged more often than the latter.	B-Reply	B-5	Reply	62
As for the exact shape of the curves, it was highly variable as reported in [1]. Therefore, we argue that the spontaneous frames from the GDBMs show the same properties as the spontaneous activity in early visual cortex.	I-Reply	I-5	Reply	62
<sep> <sep> We added more interpretations of Figure 4b and wrote ‚ÄúThe results match those from the cats; visual cortex in [1] fairly well, i.e. the spontaneous frames corresponding to the cardinal orientations emerged more often than those corresponding to the oblique ones and the former also have larger correlation coefficients.	I-Reply	I-5	Reply	62
‚Äù	I-Reply	I-5	Reply	62
<sep> 3)	O	O	Reply	62
3.1) ‚ÄúI find it most interesting that certain models show the observed behavior, while others do not (footnote 6).	O	O	Reply	62
In fact, I would have preferred to see the entire paper revolve around this finding.	O	O	Reply	62
‚Äù	O	O	Reply	62
<sep> We extended the footnote #6 into a new paragraphs in the discussion part to describe briefly the results from different models.	B-Reply	B-6	Reply	62
Please refer to the common responses E).	I-Reply	I-6	Reply	62
However, as for the detailed comparison of the results from different models, we find that they do not fit to the logic flow of current version and might exceed the page limits.	I-Reply	I-6	Reply	62
Therefore we decide not to include them in the current ICLR version.	I-Reply	I-6	Reply	62
But thanks for your tips.	I-Reply	I-6	Reply	62
We will consider to include more details in the future.	I-Reply	I-6	Reply	62
<sep> <sep> 3.2) ‚ÄúAlso, your title seems to indicate that a ‚Äòcentered Gaussian-binary DBM‚Äô is necessary to fit the findings.	O	O	Reply	62
‚Äù	O	O	Reply	62
<sep> By the current title, we want to emphasize two points, i) the centering is useful for training the proposed model, ii) the GDBM is a meaningful model for the spontaneous activity in early cortical visual areas.	B-Reply	B-7	Reply	62
After revising the manuscript, we think the title fits the paper.	I-Reply	I-7	Reply	62
<sep> <sep> 4) ‚ÄúI am very confused about your use of the term ‚Äòhomeostatic‚Äô '.	O	O	Reply	62
<sep> <sep> Removed the term ‚Äúhomeostasis‚Äù to avoid misunderstanding.	B-Reply	B-8	Reply	62
See details in the response to the common comments D).	I-Reply	I-8	Reply	62
<sep> <sep> 5) ‚ÄúWhy, in your model, isn't the spontaneous activity condition a situation where the input is black (or all zeros)?	O	O	Reply	62
Isn't this the 'stimulus' condition that resembles the experiment?	O	O	Reply	62
How should we model closing the eyes, going into a pitch black room, or severing the input from retina to LGN (or LGN to V1)?‚Äù	O	O	Reply	62
<sep> Clarified the reason why we do not clamp the visible units to zero in the discussion part.	B-Reply	B-9	Reply	62
We argue that it is not necessary to constrain the visible units to be inactive during modeling the spontaneous activity.	I-Reply	I-9	Reply	62
Briefly, Spontaneous activity is the ongoing activity in the absence of intentional sensory input.	I-Reply	I-9	Reply	62
Biologically, it is not necessary to cut off the bottom-up stimulus input [22] as in [6, 7]. See details in the response to the common comments C).	I-Reply	I-9	Reply	62
<sep> <sep> 6) ‚ÄúWhy did you use mean-field to approximate the response to the stimuli?‚Äù	O	O	Reply	62
<sep> Clarified we used mean-field estimation to estimate the response in order to be consistent with the way of estimating data-dependent term during learning.	B-Reply	B-10	Reply	62
We have tried to use Gibb sampling in both cases, but we didn't observe any significant differences in our results.	I-Reply	I-10	Reply	62
<sep> <sep> 7) ‚ÄúI would prefer less detail on already published models and training algorithms, e.g. section 2.1 and Algorithm 1.	O	O	Reply	62
and more detail on the experiment that you ran (sampling procedure, and explaining better the background of Figure 3b).‚Äù	O	O	Reply	62
<sep> 7.1) Although GDBM and centering have been published before, to our knowledge, it is first time to combine them together.	B-Reply	B-11	Reply	62
Nevertheless, the formulas varies from the previous publication at several points, therefore we think it is reasonable and necessary to include the details of both the model and the algorithm.	I-Reply	I-11	Reply	62
<sep> 7.2) Added more details of the samplings procedure in the section 3.2.1 and 3.2.2.	B-Reply	B-11	Reply	62
An illustration of the sampling procedures is added in Figure 1.	I-Reply	I-11	Reply	62
<sep> <sep> 7.3) Added more interpretations of Figure 4.	B-Reply	B-11	Reply	62
Please refer to 3) for details.	I-Reply	I-11	Reply	62

The authors use a Gaussian-binary deep Boltzmann machine (GDBM) to model aspects of visual cortex.	O	O	Review	62
Training of the GDBM involves the centering trick of [8]. The comparison to visual cortex is in terms of learned receptive field properties, and by reproducing experimentally observed properties of activity in V1 as reported by [1]. In particular, these findings relate spontaneous activity in the absence of external stimulation to evoked activity.	O	O	Review	62
<sep> <sep> On the positive side, I think the issue of the nature of spontaneous activity is interesting, and the authors put effort into reproducing the experimental findings of [1]. On the negative side, the significance of the main contributions seems lacking to me, and the authors need to motivate better why their work is important or relevant.	O	O	Review	62
Quality and clarity need to be improved in several points as well.	O	O	Review	62
<sep> <sep> <sep> Details:	O	O	Review	62
<sep> To expand on the above, I'll discuss three main points: 1) The centered GDBM.	O	O	Review	62
2) Reproducing aspects of visual cortex.	O	O	Review	62
3) The connection to homeostasis.	O	O	Review	62
<sep> <sep> 1) I wouldn't see this part as a major contribution of the paper.	B-Review	B-1	Review	62
The centering trick was originally applied to a fully binary DBM.	I-Review	I-1	Review	62
Applying the same trick to the GDBM (which only differs in having a Gaussian visible layer) seems a very natural thing to do.	I-Review	I-1	Review	62
Moreover, there is no further analysis on the efficacy of the centering trick.	I-Review	I-1	Review	62
The authors say that centering makes the GDBM easy to train compared to [15], but they don't actually evaluate the performance of the GDBM (other than comparing it to biological phenomenology), and only apply it to image patches.	I-Review	I-1	Review	62
In [15], the GDBM was trained on images of faces and evaluated in terms of filling in missing parts of the image.	I-Review	I-1	Review	62
Hence, it is not clear whether centering makes the more complicated training of [15] obsolete, as suggested by the authors.	I-Review	I-1	Review	62
<sep> <sep> Also, when it comes to clarity: given that the authors emphasize the importance of centering, they need to better explain what it is, why it works, and how the centering parameters are computed (the latter is only described in the algorithm float).	I-Review	I-1	Review	62
These things are unclear to the reader unless they look at the reference.	I-Review	I-1	Review	62
<sep> <sep> <sep> 2) Reproducing aspects of visual cortex is the main contribution of the paper.	B-Review	B-2	Review	62
First, the learned receptive fields are suggested to qualitatively resemble those in V1 and V2.	I-Review	I-2	Review	62
Learning V1-like Gabor filters is of course a quite common result nowadays.	I-Review	I-2	Review	62
I don't think it's possible to conclude that the model captures receptive field properties V2 well, just from looking at Figure 1b.	I-Review	I-2	Review	62
<sep> <sep> Hence, the main contribution here is the analysis of activity.	O	O	Review	62
I think the results are fine and somewhat interesting, though not surprising.	B-Review	B-3	Review	62
What is missing is better motivating/explaining why these results are interesting/relevant.	I-Review	I-3	Review	62
Sure, the GDBM reproduces certain experimental findings.	I-Review	I-3	Review	62
But have we learned something new about the brain?	I-Review	I-3	Review	62
Is the GDBM particularly well suited as a general model of visual cortex?	I-Review	I-3	Review	62
Does the model make predictions?	I-Review	I-3	Review	62
What about alternative, perhaps simpler models that could have been used instead?	I-Review	I-3	Review	62
Etc.	I-Review	I-3	Review	62
<sep> <sep> Also, are there related models or theoretical approaches to spontaneous activity?	I-Review	I-3	Review	62
For example, this comes to mind:	O	O	Review	62
<sep> Berkes, P., Orb√°n, G., Lengyel, M., & Fiser, J. (2011).	O	O	Review	62
Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment.	O	O	Review	62
Science (New York, N.Y.), 331(6013), 83‚Äì7.	O	O	Review	62
doi:10.1126/science.1195870	O	O	Review	62
<sep> As for clarity: when collecting the spontaneous frames, presumably you are sampling from the full model distribution P(x,y,z) via Gibbs-sampling, with all layers unclamped, correct?	B-Review	B-4	Review	62
Because writing that samples were collected from P(y|x,z) seems to suggest that you clamp to a specific x and z and collect multiple samples from the same conditional (not just as a step during Gibbs sampling).	O	O	Review	62
<sep> <sep> <sep> 3) Lastly, the connection between homeostasis and the author's model is unclear.	B-Review	B-5	Review	62
The authors mention homeostasis in the abstract, introduction and discussion, but do not explain homeostasis or how their results relate to it specifically.	O	O	Review	62
This needs to be explained better, especially to this audience.	O	O	Review	62
Personally, I know the literature somewhat (e.g. [4]), but am nevertheless unclear about what exactly the authors intend to say.	O	O	Review	62
<sep> Sentences such as 'we are able to make the model learn the homeostasis from natural image patches' are unclear.	O	O	Review	62
<sep> <sep> When I first read the paper, I thought the authors were referring to the centering trick as something that can be understood as a homeostatic mechanism (i.e., a neuronal mechanism that maintains a certain average firing rate, see [4], [6,7]), which would make sense to me.	B-Review	B-5	Review	62
However, on further reading it seems to me that the authors refer to the fact that spontaneous activity resembles evoked activity as an aspect of homeostasis?	I-Review	I-5	Review	62
Why?	I-Review	I-5	Review	62
For comparison, [6,7] clamped the input to empty images (to simulate blindness), and had an active homeostatic mechanism at play that led to spontaneous activity resembling evoked activity.	I-Review	I-5	Review	62
In the authors' paper, spontaneous activity resembles evoked activity simply because the former is taken to be sampled from the unconditioned model distribution..?	I-Review	I-5	Review	62
I'm not sure where homeostasis, i.e. being subject to an active self-regularity mechanism, comes into play at this point.	I-Review	I-5	Review	62
<sep> <sep> (As an aside, I don't think the Friston reference [3] clears up what the authors' notion of homeostasis is, in particular as Friston talks about states of agents in their environments.	I-Review	I-5	Review	62
Frankly, Friston's theoretical claims are often unclear to me, to say the least, in particular when it comes to mixing together internal models in the brain, and methods that should apply to the latter such as variational inference, and external probabilistic descriptions of agents and environments.	I-Review	I-5	Review	62
Either way, if the authors would like to make a connection to Friston's theories in particular, then that connection should be explained better.	I-Review	I-5	Review	62
Generative/predictive brain models and homeostatic mechanisms per se are not exclusive to Friston's theory.)	I-Review	I-5	Review	62
<sep> <sep> <sep> Further comments:	O	O	Review	62
<sep> * Abstract, 'Spontaneous cortical activity [...] are' -> is	B-Review	B-9	Review	62
<sep> * 2.1 first para, 'consisted' -> consisting	B-Review	B-10	Review	62
<sep> * Not sure why x,y,z are sometimes capitalized, sometimes not.	B-Review	B-7	Review	62
<sep> <sep> * 3.1 'sparse DBNs show worse match to the biological findings as reported in [1]. A quantitative comparison between centered GDBMs and sparse DBNs is still open for future studies.'	B-Review	B-6	Review	62
Where was it shown to be a worse match then?	I-Review	I-6	Review	62
<sep> <sep> * Figure 2: shouldn't the angles (figure titles) go from 0 to 180?	B-Review	B-8	Review	62
<sep> <sep> <sep> In conclusion, I think this work could potentially be interesting, but in its current form quality and clarity are somewhat lacking and significance is not quite clear.	O	O	Review	62
Thanks for your helpful comments.	O	O	Reply	62
<sep> 1) ‚ÄúThe centered GDBM.‚Äù	O	O	Reply	62
<sep> Clarified applying centering to Gaussian DBM is an extension of the previous work in [8]. The point we want to make here is that GDBM with centering can be trained without the pre-training procedure as described in [3]. In comparison, we followed the same setting in [3] with centered GDBM.	B-Reply	B-1	Reply	62
The reconstruction error here is 41.6 +/- 0.40 compared to the results of about 40 in [3]. We agree that the minor differences are not sufficient to claim the advantages of centered GDBMs over the non-centered version. (	I-Reply	I-1	Reply	62
This is also why we did not include this result in the previous version.)	I-Reply	I-1	Reply	62
Importantly however, as shown in [8], centering leads to improved conditions.	I-Reply	I-1	Reply	62
In our paper, we show that hidden units in both layers of the centered GDBM can learn meaningful features.	I-Reply	I-1	Reply	62
Thus, our present results also show empirically that the centering helps to overcome the commonly observed difficulties during training of GDBMs.	I-Reply	I-1	Reply	62
<sep> We have added more details about the centering in the revised version.	I-Reply	I-1	Reply	62
Because the main focus of this paper is to illustrate the capacity of GDBM in modeling spontaneous cortical activity, we did not include further analyses of the centering specifically for GDBMs.	I-Reply	I-1	Reply	62
<sep> <sep> 2) ‚ÄúReproducing aspects of visual cortex‚Äù	O	O	Reply	62
2.1) ‚ÄúI don't think it's possible to conclude that the model captures receptive field properties V2 well, just from looking at Figure 1b.	O	O	Reply	62
‚Äù	O	O	Reply	62
<sep> Done - We removed the statement suggesting that the model captures receptive field properties in V2.	B-Reply	B-2	Reply	62
See more details in the responses to the common comments B).	I-Reply	I-2	Reply	62
<sep> <sep> 2.2) ‚ÄúWhat is missing is better motivating/explaining why these results are interesting/relevant. ‚	O	O	Reply	62
Ä¶. have we learned something new about the brain?	O	O	Reply	62
Is the GDBM particularly well suited as a general model of visual cortex?	O	O	Reply	62
Does the model make predictions?	O	O	Reply	62
What about alternative, perhaps simpler models that could have been used instead?	O	O	Reply	62
Etc.	O	O	Reply	62
Also, are there related models or theoretical approaches to spontaneous activity?‚Äù	O	O	Reply	62
<sep> We mainly demonstrate that the GDBM is a meaningful model approach for basic receptive field properties and the emergence of spontaneous activity patterns in early cortical visual areas.	B-Reply	B-3	Reply	62
Compared to other models for modeling spontaneous cortical activity, GDBMs (or DBMs in general) are not limited to simple, low-dimensional, non-hierarchical variables [7], but extend to generative, hierarchical-structured models with an unsupervised learning fashion.	I-Reply	I-3	Reply	62
<sep> <sep> Moreover, by reproducing the findings in [1] with centered GDBMs, we suggest that i) the spontaneous activity in early visual cortex are the result of interactions between sensory inputs and feedbacks from higher areas, ii) thus, early visual areas are sufficient to generate the observed spontaneous activity patterns.	I-Reply	I-3	Reply	62
<sep> <sep> Together with the discussion of the failures to model the cortical activity with GRBMs and DBN (see details in the responses to the common comments E)), we have a new paragraph in the discussion to describe the interpretations of our results.	I-Reply	I-3	Reply	62
<sep> <sep> 2.3) ‚Äúwhen collecting the spontaneous frames, presumably you are sampling from the full model distribution P(x,y,z) via Gibbs-sampling, with all layers unclamped, correct?‚Äù	O	O	Reply	62
<sep> Clarified - During collecting the spontaneous frames, we indeed ran sampling from the full model distribution P(X, Y, Z) via Gibbs-sampling with all layers unclamped.	B-Reply	B-4	Reply	62
This sampling procedure is supposed to approximate the samples from the model‚Äôs prior distribution P(Y), which are the expected states of the Y without any knowledge of X and Z. And we use P(Y|x, z) from a single step during Gibbs sampling as an approximation of Y, which is referred as to a spontaneous frame.	I-Reply	I-4	Reply	62
We added more details of the samplings procedure in section 3.2.1 and 3.2.2.	I-Reply	I-4	Reply	62
See more details in the responses to common comments C).	I-Reply	I-4	Reply	62
<sep> <sep> 3) ‚Äúthe connection between homeostasis and the author's model is unclear.	O	O	Reply	62
‚Äù	O	O	Reply	62
<sep> Removed the term ‚Äúhomeostasis‚Äù to avoid misunderstanding.	B-Reply	B-5	Reply	62
See more details in the responses to common comments D).	I-Reply	I-5	Reply	62
<sep> <sep> 4) ‚Äú3.1 'sparse DBNs show worse match to the biological findings as reported in [1]. A quantitative comparison between centered GDBMs and sparse DBNs is still open for future studies.'	O	O	Reply	62
Where was it shown to be a worse match then?‚Äù	O	O	Reply	62
<sep> We have attempted to use the (sparse) DBN to model the cortical activity.	B-Reply	B-6	Reply	62
But the results show worse match to the biological results in [1] as the spontaneous frames show less correlation to the orientation maps.	I-Reply	I-6	Reply	62
Both the comparison of results and the interpretation have been included in the revised discussion part.	I-Reply	I-6	Reply	62
See more details in the responses to common comments E).	I-Reply	I-6	Reply	62
<sep> <sep> 5)	O	O	Reply	62
* ‚ÄúNot sure why x,y,z are sometimes capitalized, sometimes not.	O	O	Reply	62
‚Äù	O	O	Reply	62
<sep> We use the upper case letters to denote the un-instantiated variables, i.e. the values of variables are not given.	B-Reply	B-7	Reply	62
In contrast, the lower case letters represent the instantiated variables.	I-Reply	I-7	Reply	62
<sep> <sep> * ‚ÄúFigure 2: shouldn't the angles (figure titles) go from 0 to 180?‚Äù	O	O	Reply	62
<sep> Figure 2: Done ‚Äì Thanks for the hint, typo corrected.	B-Reply	B-8	Reply	62
The angles should go from 0 to 180.	I-Reply	I-8	Reply	62

This paper proposes the use of an MLP that predicts both mean and std for predicting the time of a surgical operation.	O	O	Review	139
<sep> They extend the method also to Laplace distribution.	O	O	Review	139
<sep> The method is simple, not novel, but the combination of the method and the application is novel.	O	O	Review	139
<sep> What worries me is the marginal improvements reported in table 1.	B-Review	B-1	Review	139
Most of the improvement comes from the use of an MLP, more than the prediction of the variance - see the difference between Gaussian and Gaussian HS, and Laplace and Laplace HS.	I-Review	I-1	Review	139
<sep> My conclusion is that the choice of the distribution/loss in conjunction with the use of an MLP is more important than anything else, and in particular, it is more important than predicting variance (which is the main point of the abstract).	B-Review	B-2	Review	139
<sep> <sep> Dear reviewer,	O	O	Reply	139
<sep> Thanks for taking the time to review our paper.	O	O	Reply	139
The purpose of estimating the conditional variance is precisely to get *good estimates of the variance*.	O	O	Reply	139
<sep> The superiority (in this respect) of the predictions of the heteroscedastic models is born out by figures 1 and 2 which show just how strongly the predicted standard deviations correlate with observed errors.	B-Reply	B-1	Reply	139
<sep> <sep> We realize that some amount of the confusion owes to a bug in our initial reporting.	I-Reply	I-1	Reply	139
The initial table 1 had a scaling bug in calculating NLL numbers.	I-Reply	I-1	Reply	139
This reporting bug came to light when we were adding late-breaking results on a gamma predictive distribution.	I-Reply	I-1	Reply	139
Thus the original table 1 didn't make it clear just how much the heteroscedastic models improve over their homoscedastic counterparts.	I-Reply	I-1	Reply	139
<sep> <sep> We've updated the draft with the fixed numbers and it's obvious that the heteroscedastic modeling fits the observed errors dramatically better.	I-Reply	I-1	Reply	139
<sep> <sep> We also added a line to the results table 1 showing results using a gamma predictive distribution, which slightly outperforms even the best heteroscedastic laplacian regression model.	B-Reply	B-2	Reply	139
We hope you'll take the chance to re-assess the review.	I-Reply	I-2	Reply	139

Summary:	O	O	Review	139
<sep> This work models the distribution of surgery durations using unimodal	O	O	Review	139
parameteric distributions (viz.,	O	O	Review	139
Gaussian and Laplace) by regressing their	O	O	Review	139
parameters using multi-layer perceptrons based on patient and clinical	O	O	Review	139
environment attributes.	O	O	Review	139
<sep> <sep> Using the uncertainty (or standard-deviation) estimates, they report	O	O	Review	139
improvements of 18% in scheduling surgeries.	O	O	Review	139
<sep> <sep> This is the first application of heteroscedastic neural regression to clinical	O	O	Review	139
medical data.	O	O	Review	139
<sep> <sep> <sep> Comments:	O	O	Review	139
1.	O	O	Review	139
In Table 1, it is not clear what "Current Method" corresponds to.	B-Review	B-1	Review	139
<sep> <sep> <sep> Assessment:	O	O	Review	139
<sep> Clarity:	O	O	Review	139
The method has been presented clearly, with all the details to reproduce the	O	O	Review	139
results (although it is not clear if the medical data is publicly available).	O	O	Review	139
<sep> <sep> Novelty & Significance:	O	O	Review	139
<sep> The method presented uses multi-layer perceptrons (MLPs) for regressing	B-Review	B-2	Review	139
parameters of univariate unimodal parametric distributions, which is not quite	I-Review	I-2	Review	139
novel, and is a simple application MLP to this specific domain (clinical medical	I-Review	I-2	Review	139
data).	I-Review	I-2	Review	139
Dear reviewer,	O	O	Reply	139
<sep> Thanks for the thoughtful feedback.	O	O	Reply	139
We'd like to offer the following responses and clarifications:	O	O	Reply	139
<sep> Good catch that we didn't define "current method" in the extended abstract.	B-Reply	B-1	Reply	139
The current method is the ad-hoc times that are currently entered into the system to reserve the rooms.	I-Reply	I-1	Reply	139
These are the actual "human-expert" times predicted by the surgeons and administrators.	I-Reply	I-1	Reply	139
<sep> <sep> We'd like to point out that this work is more novel than the reviewer acknowledges.	B-Reply	B-2	Reply	139
While several papers have proposed neural heteroscedastic regression, we are to our knowledge one of only two papers to revisit the idea in the context of modern deep learning (multiple hidden layers, rectifier activations, dropout regularization).	I-Reply	I-2	Reply	139
Moreover, our paper is the only one, to our knowledge, to demonstrate the efficacy of neural heteroscedastic regression on a dataset of real-world importance.	I-Reply	I-2	Reply	139
The other paper only tested the idea on generic UCI dataset and the classic papers address synthetic & toy problems.	I-Reply	I-2	Reply	139
<sep> <sep> We'd also like to let the reviewer know that we've gone a step further and improved the results by using gamma distributions.	B-Reply	B-2	Reply	139
These are especially suited to our problem because the distribution of surgery durations can only be long-tailed on only one side (no surgery can take less than 0 minutes).	I-Reply	I-2	Reply	139
The gamma predictive distribution indeed gives lower NLL than both Gaussian and Laplace.	I-Reply	I-2	Reply	139
We plan to update the draft with these numbers and the relevant empirical analysis in the next week.	I-Reply	I-2	Reply	139

Summary: The authors design a new model for bidirectional joint image-text modeling using a variational hetero-encoder	O	O	Review	454
(VHE) randomized generative adversarial network (GAN) that integrates a probabilistic text decoder, probabilistic image encoder, and GAN into an end-to-end multimodal model.	O	O	Review	454
Their proposed VHE-GAN model encodes an image to decode its associated text and feeds the variational posterior as the source of randomness into the GAN image generator.	O	O	Review	454
The authors also incorporate a deep topic model, a ladder-structured image encoder, and StackGAN++ into their framework for improved photo-realistic images.	O	O	Review	454
<sep> <sep> Strengths:	O	O	Review	454
- The authors have proposed a nice multimodal model that allows inference of latent variables given only text or image, and also allows realistic synthesis of images from images, text, or noise.	O	O	Review	454
<sep> - The paper is quite dense but generally well written.	O	O	Review	454
<sep> <sep> Weaknesses:	O	O	Review	454
- The experimental comparison only included old baselines and the authors should compare to some more recent work such as TA-GAN (NIPS18), and Object-GAN (CVPR19).	B-Review	B-1	Review	454
<sep> - It would help if the paper contained more ablation studies across different modules that the framework uses.	B-Review	B-2	Review	454
<sep> <sep> ### Post rebuttal ###	O	O	Review	454
Thank you for your detailed answers to my questions.	O	O	Review	454
Thank you for your comments and suggestions.	O	O	Reply	454
Following your suggestions, we have performed comparisons against both TA-GAN and Obj-GAN, and included two additional variations of VHE-raster-scan-GAN for ablation studies.	B-Reply	B-1	Reply	454
The newly added discussions and results have been highlighted in blue in the revised paper.	I-Reply	I-1	Reply	454
Please see our "Response to All" for more details.	I-Reply	I-1	Reply	454

This paper proposes a combined architecture for image-text modeling.	O	O	Review	454
Though the proposed architecture is extremely detailed, the authors explain clearly the overarching concepts and methods used, within limited space.	O	O	Review	454
The experimental results are extremely strong, especially on sub-domains where conditional generative models have historically struggled such as images with angular, global features - often mechanical or human constructed objects. "	O	O	Review	454
Computers" and "cars" images in Figure 2 show this quite clearly.	O	O	Review	454
The model also functions for tagging and annotating images - performing well compared to models designed *only* for this task.	O	O	Review	454
<sep> <sep> The authors have done a commendable job adding detail, further analysis, and experiments in the appendix of the paper.	O	O	Review	454
Combined with the included code release, this paper should be of interest to many.	O	O	Review	454
<sep> <sep> My chief criticisms come for the density of the paper - while it is difficult to dilute such a complex model to 8 pages, and the included appendix clarifies many questions in the text body, it would be worth further passes through the main paper with a specific focus on clarity and brevity, to aid in the accessibility of this work.	B-Review	B-1	Review	454
<sep> <sep> As usual, more experiments are always welcome, and given the strengths of GAN based generators for faces a text based facial image generator could have been a great addition.	B-Review	B-2	Review	454
The existing experiments are more than sufficient for proof-of-concept though.	I-Review	I-2	Review	454
<sep> <sep> Finally, though this version of the paper includes code directly in a google drive link it would be ideal for the final version to reference a github code link - again to aid access to interested individuals.	B-Review	B-3	Review	454
Being able to read the code online, without downloading and opening locally can be nice, along with other benefits from open source release.	I-Review	I-3	Review	454
However the authors should release the code however they see fit, this is more of a personal preference on the part of this reviewer.	I-Review	I-3	Review	454
<sep> <sep> To improve my score, the primary changes would be more editing and re-writing, focused on clarity and brevity of the text in the core paper.	O	O	Review	454
Thank you for your comments and suggestions.	O	O	Reply	454
We have revised our paper to add additional comparisons to recent work, more ablation studies, and more experimental results, with the major additions highlighted in blue.	O	O	Reply	454
Please see our "Response to All" for details.	O	O	Reply	454
Below please find our additional response.	O	O	Reply	454
<sep> <sep> To enhance clarity and brevity, we have modified our ablation studies to better focus on presenting the proposed VHE-raster-scan-GAN.	B-Reply	B-1	Reply	454
<sep> <sep> We have added the task of text-to-face-image generation.	B-Reply	B-2	Reply	454
More specifically, we have trained our models on the CelebA dataset, where each facial image is described by 40 textual attributes.	I-Reply	I-2	Reply	454
We have added preliminary results of text-attributes-to-face-image generation to Appendix B of the revised paper.	I-Reply	I-2	Reply	454
Note limited by the rebuttal time and our computational resource, these examples facial images at 128 *128 resolution were generated from a relatively small network trained with only 20 epochs.	I-Reply	I-2	Reply	454
We are working on adding more training epochs and increasing the network size and image resolution to further improve these preliminary results, which will be included in our next revision.	I-Reply	I-2	Reply	454
We are also seeking facial image datasets with textual descriptions beyond only attributes (it seems that we might need to build them by our own), which will be our future work.	I-Reply	I-2	Reply	454
<sep> <sep> We released the code on Google drive to help better preserve anonymity.	B-Reply	B-3	Reply	454
After the acceptance of this paper, we will release it in GitHub for better access.	I-Reply	I-3	Reply	454

This paper proposed VHE-GAN for the text-to-image generation task.	O	O	Review	454
The proposed method utilizes the off-the-shell modules and feeds the VHE variational posterior into the generator.	O	O	Review	454
The experiments are conducted on three datasets.	O	O	Review	454
<sep> <sep> The motivation for the paper is not clear.	B-Review	B-1	Review	454
Most of the components used, such as text-encoder, image-encoder, generator-discriminator follow previous works.	I-Review	I-1	Review	454
Therefore, the authors should claim how the proposed VHE variational posterior can help the task.	I-Review	I-1	Review	454
However, I did not see the clear motivation for this part.	I-Review	I-1	Review	454
<sep> <sep> Besides the basic version VHE-StackGAN++, it proposed another version  VHE-raster-scan-GAN.	B-Review	B-2	Review	454
However, the paper also fails to tell the intuition of the deep topic model and PGBN text decoder.	I-Review	I-2	Review	454
<sep> <sep> The experimental results are not solid.	B-Review	B-3	Review	454
The comparison only included old baselines.	I-Review	I-3	Review	454
However, several recent state-of-the-art approaches are missing: a. attnGAN (CVPR18), b. TA-GAN (NIPS18), c. Object-GAN (CVPR19).	I-Review	I-3	Review	454
Without these comparisons, it is difficult to evaluate how the method works.	I-Review	I-3	Review	454
In addition, the paper does not provide an ablation study to analyze the effect of each component proposed (e.g., Poisson gamma belief network, a deep topic mode).	I-Review	I-3	Review	454
We thank AnonReviewer4 for the comments.	O	O	Reply	454
We'd like to strongly argue against these comments that were used to support the low rating.	O	O	Reply	454
Please see our point-by-point response below.	O	O	Reply	454
<sep> <sep> First, we emphasize that the proposed VHE-GANs are deep generative models that can not only perform text-to-image generation tasks, but also many other tasks, such as text based zero shot learning (image-to-text) and noise to image-text pairs generation.	B-Reply	B-1	Reply	454
Please see our "Response to All" on the versatility of the proposed models.	I-Reply	I-1	Reply	454
<sep> <sep> Second, a key motivation of the paper is to build VHE-raster-scan-GAN.	B-Reply	B-1	Reply	454
While it does include a variety existing modeling components, both the VHE-GAN framework, which integrates various components for bidirectional image-text modeling, and the raster-scan structure, which leads to state-of-the-art results in a variety of tasks, are first proposed in this paper.	I-Reply	I-1	Reply	454
Please see our "Response to All" on additional ablation studies that have been added to better demonstrate the importance of having both the stacking structure and raster-scan structure.	I-Reply	I-1	Reply	454
<sep> <sep> Third, we did explain the intuition of why using the the PGBN deep topic model (together with the raster-scan structure) in multiple places, such as in the last paragraph of Section 2.2, first paragraph of Section 2.3, and last paragraph of Section 3.1.	B-Reply	B-2	Reply	454
More specifically, a key intuition behind VHE-raster-scan-GAN is to use the PGBN deep topic model to help capture hierarchical semantic structures, which are related to coarse-to-fine visual concepts with the help of the raster-scan structure, as visually demonstrated in Figs.	I-Reply	I-2	Reply	454
4, 5, 21-23 and a variety of comparisons between VHE-StackGAN++ and VHE-raster-scan-GAN.	I-Reply	I-2	Reply	454
Higher layer topics are mainly related to the general shapes and colors of objects, or backgrounds, while the lower layer ones are focused on finer details.	I-Reply	I-2	Reply	454
VHE-raster-scan-GAN exploits the hierarchical semantic structure, which matches coarse-to-fine visual concepts, to gradually refine its generation under the proposed VHE-GAN framework.	I-Reply	I-2	Reply	454
<sep> <sep> Fourth, we note in the original submission, we did include AttnGAN for comparison in Table 1, and an ablation study in Table 4 to examine the effect of varying the depth of PGBN used in VHE-raster-scan-GAN, as discussed in the last paragraph of Section 3.2.	B-Reply	B-3	Reply	454
In Fig.2 of our original manuscript, we did not show the results of AttnGAN as it provided  no results on Flower.	I-Reply	I-3	Reply	454
<sep> <sep> To address your concerns, we have now added AttnGAN into Fig.2 and more results of AttnGAN in Appendices C.2 and C.3 in our revised paper, included two additional variations of VHE-raster-scan-GAN for ablation studies, and added both TA-GAN and Obj-GAN into comparisons.	I-Reply	I-3	Reply	454
The newly added discussions and results have been highlighted in blue in the revised paper.	I-Reply	I-3	Reply	454
Please see our "Response to All" for more details.	I-Reply	I-3	Reply	454

Name standardization is an important problem in Chemical Information Extraction.	O	O	Review	1519
In the chemical literature, the same chemical could be referred to by many different names.	O	O	Review	1519
This work focusses on standardizing non systematic names (for example Asprin to 2-Acetoxybenzoic acid).	O	O	Review	1519
<sep> <sep> The authors approach this as a machine translation problem.	O	O	Review	1519
They create a parallel corpus of non-systematic and systematic names and build a seq2seq model for accomplishing this task.	O	O	Review	1519
The authors report accuracy and BLEU score for the translation task.	O	O	Review	1519
<sep> <sep> My main concern with this work is novelty.	B-Review	B-1	Review	1519
It seems like this is a straightforward application of an existing model for this task.	I-Review	I-1	Review	1519
Also it is not clear why BLEU score is an appropriate metric for this task.	B-Review	B-2	Review	1519
Is it okay for downstream applications to have the systematic name partially right?	B-Review	B-3	Review	1519
<sep> <sep> Overall, I think this paper does not present substantially new ideas to merit publication.	O	O	Review	1519
We'd like to address the importance of our concerned task and how we make contribution other than model novelty.	O	O	Reply	1519
<sep> <sep> Chemical name identification and 3D-conversion is the core task for all chemical information processing (CIP), though from a view of NLP, it seems a routine information extraction that may be solved by various existing models.	B-Reply	B-1	Reply	1519
Without proper chemical names, all the rest CIP cannot be effectively done further.	I-Reply	I-1	Reply	1519
We already have mass data about chemistry including research papers and patents, from which we already have extracted a lot of chemical information databases.	I-Reply	I-1	Reply	1519
However, all the extraction is limited by the unsatisfactory accuracy on chemical names.	I-Reply	I-1	Reply	1519
So far, incomplete statistics show that the largest database maybe only contains 2% chemical names appearing in the literature, and the rest 98% that are supposed to be extracted cannot be exploited by CIP techniques just due to the name problem.	I-Reply	I-1	Reply	1519
The bottleneck of CIP is just located at its pipeline entrance, which is right what we do for in this work.	I-Reply	I-1	Reply	1519
<sep> <sep> We'd like to re-paraphrase our contribution as formulization or solution novelty from the non-trivality of our concerned task.	B-Reply	B-1	Reply	1519
As we know, our original aim in the task is to restore molecule structure just from a linear symbol sequence, chemical names which maybe have diverse spelling errors.	I-Reply	I-1	Reply	1519
It is surely uneasy from such a form by considering we have to let computer convert erring linear sequence into standard/exact 3D structure.	I-Reply	I-1	Reply	1519
Even though we re-formulize the most challenging part of the task into a chemical name correction subtask, it is still hard to solve.	I-Reply	I-1	Reply	1519
As no blanks are between chemical name stems and all the parts can be swap positions freely in different literature.	I-Reply	I-1	Reply	1519
We tried straightforward spell correction methods in NLP as the task looks like such a type, however, all methods including classical language model were shown to be a failure, for example, the most effectivel edit distance correction can only solve less than 2% cases.	I-Reply	I-1	Reply	1519
Machine translation solution come to us very late, whose effectiveness has been shown in this paper you are reading now.	I-Reply	I-1	Reply	1519
<sep> <sep> Overall, we contribute a novel ML solution for a bottleneck problem in CIP in this paper.	B-Reply	B-1	Reply	1519
Our components are not new maybe, but our solution especially for the task and our attempt that introduce these ML methods are new for sure.	I-Reply	I-1	Reply	1519
<sep> <sep> As we do not have enough space in the paper, we choose to submit the above comments here.	O	O	Reply	1519

Pros: This seems like very competent and important work in an under-served area: Doing the mapping (or "entity linking") of chemical names to their standardized systematic forms.	O	O	Review	1519
It's not my area, but I was frankly surprised when the paper said there was only one relevant prior piece of work, but having searched for a few minutes on Google Scholar, I'm at least inclined to believe that the authors are (approximately) right on that one. (	O	O	Review	1519
This stands in stark contradistinction to the large quantity of biomedical entity recognition and linking work.)	O	O	Review	1519
So, it's valuable to have work in this area, and the approach and application are sensible.	O	O	Review	1519
In one sense, this gives the work significance and originality (as to domain).	O	O	Review	1519
The paper is also clearly written, and certainly sufficiently accessible to an ML reader.	O	O	Review	1519
<sep> <sep> Cons: Unfortunately, though, I just don't think this qualifies for acceptance at ICLR.	B-Review	B-1	Review	1519
It's application of known techniques, and lacks any ML novelty or sufficient ML interest.	I-Review	I-1	Review	1519
It would only be appropriate for an "ML applications" track, which ICLR does not have.	I-Review	I-1	Review	1519
And while its performance is _way_ better than that of the only previous work on the topic that they know, accuracy of mapping non-systematic chemical terms (54.04%) is still low enough that this technique doesn't seem ready for prime time.	I-Review	I-1	Review	1519
<sep> <sep> Other comments: In table 5, you show that a prior pipeline stage of spelling correction is definitely useful in your system (table 5).	B-Review	B-2	Review	1519
And yet, given the power of deep learning seq2seq transductions, and the potential to use them for spelling correction, one might wonder whether this prior step of spelling correction is really necessary.	I-Review	I-2	Review	1519
It might be interesting to explore further where it helps and whether the gains of spelling correction might be obtainable in other ways such as using data augmentation (such as spelling error insertion) in the seq2seq training data.	I-Review	I-2	Review	1519
The Golebiewski bib entry is lacking any information as to where it is published, which seems especially bad for the key citation to prior work of the whole paper.	I-Review	I-2	Review	1519
In general, the bibliography has issues: non-ASCII characters have been lost (you either need to LaTeX-escape them or to load a package like utf8, and capitalization of acronyms, etc.	I-Review	I-2	Review	1519
should be improved with curly braces.	I-Review	I-2	Review	1519
Please refer to our comments to AnonReviewer3 about our contribution and the role of this work.	O	O	Reply	1519
<sep> Here we want to add facts about the performance.	B-Reply	B-1	Reply	1519
According to our industrial partner,  the largest chemical database maybe only contains 2% chemical names appearing in all the chemical literature just because of the name obstacle.	I-Reply	I-1	Reply	1519
So, when an accuracy of about 60% is argued, we'd better look backwards.	I-Reply	I-1	Reply	1519
Only several percents of extraction accuracy has supported all the existing chemical database building for a broad range of practical application, while our system boosts nearly 10 times accuracy improvement compared to previous state-of-the-art.	I-Reply	I-1	Reply	1519
Just imagine how a new world we open for the community of CIP through this work.	I-Reply	I-1	Reply	1519
<sep> Please keep it in mind that even 6% extraction accuracy (ChemHits) can effectively and well serve all CIP work so far.	B-Reply	B-1	Reply	1519

This work presents a method to translate non-systematic names of chemical compounds into their systematic equivalents.	O	O	Review	1519
Beyond that, a corpus of systematic and non-systematic chemical names is introduced that were extracted from chemistry and manually labelled.	O	O	Review	1519
<sep> <sep> The paper is well-structured and the authors introduce the problem setting very nicely to a machine learning audience, explain the challenges and motivate the architecture of their model.	O	O	Review	1519
The model is a combination of tested approaches such as a spelling error correction, a byte pair encoding tokenizer and a sequence-to-sequence model consisting of (Bi)LSTMs and attention mechanisms.	O	O	Review	1519
<sep> <sep> The evaluation appears solid.	O	O	Review	1519
The model achieves significantly improved results on the proposed corpus, even though compared to a underwhelming baseline.	O	O	Review	1519
The analysis could be improved by showing and explaining some examples of failed translation attempts.	B-Review	B-2	Review	1519
It would also be interesting to see how the failed attempts are distributed over the error types (spelling, order, common name, synonym).	I-Review	I-2	Review	1519
The authors suggest a scenario where non-systematic names are converted and checked against a database of systematic names.	B-Review	B-3	Review	1519
For this, it would be interesting to know whether there are cases where a non-systematic name was translated into the wrong (but valid) systematic name.	I-Review	I-3	Review	1519
<sep> <sep> Concluding, the paper presents an interesting application for machine translation, a new dataset and a method that successfully labels 50% of the given corpus.	O	O	Review	1519
<sep> <sep> Minor issue: The color scale of Fig.5 is hard to recognize due to low contrast.	B-Review	B-4	Review	1519
Thank you for your positive feedback and insightful review.	O	O	Reply	1519
Because of the huge amount of data, we cannot check the error type of failed attempts one by one so we randomly select 100 fail attempts and label their error types manually and carefully.	B-Reply	B-2	Reply	1519
The result is reported in the section 3.4 of the updated version of our paper, in which some failed translation examples are also added.	I-Reply	I-2	Reply	1519
For the scenario, we admit that there could be the case where a non-systematic name is translated into the wrong (but valid) systematic name.	B-Reply	B-3	Reply	1519
For the preciseness, we delete this statement in the updated version of our paper.	I-Reply	I-3	Reply	1519

This work proposes an autoregressive video generation model, which is based on a newly proposed three-dimensional self-attention mechanism.	O	O	Review	231
It generalizes the Transformer architecture of Vaswani et al (2017) to spatiotemporal data (video).	O	O	Review	231
The original Transform implies self-attention among different words in a sentence.	O	O	Review	231
Considering the larger scale of video, this work proposes to divide it into small blocks, and apply the self-attention (part of block-local self-attention modular) on each block.	O	O	Review	231
At the same time, it addresses the information exchange between blocks problem, by spatiotemporal sub-scaling (described in section 3.2).	O	O	Review	231
The proposed method achieves competitive results across multiple metrics on popular benchmark datasets (BAIR Robot Pushing and KINETICS), for which they produce continuations of high fidelity.	O	O	Review	231
<sep> <sep> Some questions:	O	O	Review	231
-      The proposed model is claimed to work on competitive results across multiple metrics on popular benchmark datasets.	B-Review	B-1	Review	231
However, it only compares with stat-of-the-art models on BAIR Robot Pushing dataset (for the other dataset, the author only compares with the variations of the proposed model).	I-Review	I-1	Review	231
Further, the author only reports the result of Bits/dim and FVD, instead of PSNR and SSIM, which are reported in the original papers.	I-Review	I-1	Review	231
Any justification for this?	I-Review	I-1	Review	231
Though FVD has its own advantages, showing PSNR and/or SSIM at the same time would help us get better sense of the performance.	I-Review	I-1	Review	231
<sep> -      In table 1 (left) in section 4.2, the author mentions that results from all the stat-of-the-art models are not strictly comparable, since prior works use longer priming sequences of two or three frames, whereas the proposed models only observe a single prime frame.	B-Review	B-2	Review	231
I am confused of why the proposed model can only see a single frame.	I-Review	I-2	Review	231
<sep> -      The proposed block-local self-attention modular works on divideding video into small blocks, which seems to be a matrix of 3 or 4 dimensions (t,h,w,c).	B-Review	B-3	Review	231
However, in the experiment, the input of the model for the BAIR Robot Pushing dataset is the first frame.	I-Review	I-3	Review	231
How can this frame be feed into the block-local self-attention modular?	I-Review	I-3	Review	231
<sep> -     In section 3.3, it splits the 3x8-bit RGB channel into 6x4-bit channels.	B-Review	B-4	Review	231
It would be better if the author can show an example and clarify the advantages.	I-Review	I-4	Review	231
<sep> -     In section 3.3, U_k, N_v and P seems not defined in the context.	B-Review	B-5	Review	231
<sep> -    Videos are divided into small blocks and feed into the block-local self-attention modular separately.	B-Review	B-6	Review	231
Then, I‚Äôm confused on how to aggregate these different blocks together to predict future frames.	I-Review	I-6	Review	231
<sep> <sep> I would like to raise up my score if the author can address my questions.	O	O	Review	231
<sep> <sep> Additional clarification concerning the definition of U_k, N_v and P in section 3.3.	B-Reply	B-5	Reply	231
<sep> <sep> We define the dimensionality of U_k and P in Eq.8.	B-Reply	B-5	Reply	231
These are trainable parameters.	I-Reply	I-5	Reply	231
<sep> <sep> N_v is actually defined in the text as "N_v=16".	B-Reply	B-5	Reply	231
It is 16 because we predict 6 channels ("N_c=6") of 4bit per channel.	I-Reply	I-5	Reply	231
4bit translates to 2^4=16 potential values.	I-Reply	I-5	Reply	231

This paper presents an approach for scalable autoregressive models for video synthesis.	O	O	Review	231
Key to the approach is a form of 3D (2 space and one time) self-attention that operates in a softly local manner (through a bias on the attention weights that makes them tend to prefer nearby connections), and also limits its field of view to a specific 3D sub-"block" of video at each layer for scalability.	O	O	Review	231
They also propose a clever ordering for autoregressive synthesis of the video subsampling spatially and temporally to generate multiple slices that are synthesized autoregressively one after the other.	O	O	Review	231
Each of these ideas is individually close to ideas proposed elsewhere before in other forms, as the authors themselves acknowledge [Vaswani et al 2017, Parmar et al 2018, Parikh et al 2016, Menick et al 2019], but this paper does the important engineering work of selecting and combining these ideas in this specific video synthesis problem setting.	O	O	Review	231
<sep> <sep> Results on standard datasets for video generation match up to and/or surpass prior methods, in line with prior work on autoregressive image generation that has been shown to do very well on similar metrics (perplexity and FID).	O	O	Review	231
What is perhaps more interesting is that this paper presents initial promising results for open-world Youtube video settings (Kinetics dataset) that have not been evaluated systematically in any prior work in this area, to my knowledge.	O	O	Review	231
<sep> <sep> The downsides of this paper are largely common to this method class (autoregressive generative models): training time (one of their models is "trained in parallel on 128 TPU v3 instances for 1M steps"), inference time (four short 64x64 video clips of 30 frames take 8 mins to generate on a Tesla V100), and model sizes (373M parameters for the Kinetics model).	B-Review	B-1	Review	231
However, this does not take away from the contributions made here, that make it possible at all to train an autoregressive model of this size.	O	O	Review	231
<sep> <sep> On the experiments, some questions, comments, and suggestions that the authors might consider addressing:	O	O	Review	231
- How well do methods like SVG, SAVP, SV2P do on Kinetics, for comparison?	B-Review	B-2	Review	231
It would be still more interesting if those models were scaled to have similar sizes to the large model in this work.	I-Review	I-2	Review	231
While these methods have never been evaluated before on such unconstrained data, it is not clearly established that they do not work at all.	I-Review	I-2	Review	231
<sep> - To what extent does the blocking help, and when does it breaks down?	B-Review	B-3	Review	231
e.g. how many layers/how large do blocks have to be for the idea of using different block sizes to suffice for smooth video synthesis?	I-Review	I-3	Review	231
What happens when the blocking idea is not used at all?	I-Review	I-3	Review	231
<sep> - Other choices that aren't ablated in experiments: the choice of a local preference using the bias term in attention, the Transformer-style multi-attention heads.	B-Review	B-4	Review	231
I do understand that these models are expensive to train and evaluate, but perhaps a smaller dataset might still suffice to demonstrate the value of these choices.	I-Review	I-4	Review	231
<sep> - Why is the proposed approach evaluated only on video prediction?	B-Review	B-5	Review	231
Could it not be used for video generation without conditioning or with class conditioning?	I-Review	I-5	Review	231
<sep> - It is surprising to me that the perplexity of Kinetics models is lower than BAIR.	B-Review	B-6	Review	231
Is there a reasonable explanation?	I-Review	I-6	Review	231
<sep> <sep> Writing and presentation are good for the most part, despite the main paper being dense with details and multiple fairly involved ideas.	B-Review	B-7	Review	231
I particularly enjoyed parts of related work, the illustration of slicing in Fig 1, and the illustrative examples in Fig 3.	I-Review	I-7	Review	231
<sep> <sep> I would suggest however, that the paper might benefit from placing Sec 3.2 which describes the framework, before Sec 3.1.	B-Review	B-8	Review	231
Fig 1 also belongs closer to Sec 3.2 anyway.	I-Review	I-8	Review	231
<sep> <sep> There are also terms/phrases I don't understand despite being reasonably familiar with the field like "positional embbeddings" (Sec 3.2).	B-Review	B-9	Review	231
I also don't understand the need for "one-hot encoding of the discretized pixel intensities" (in that same paragraph).	I-Review	I-9	Review	231
As a more minor comment, a footnote 1 before Eq 1 declares that capital letters denote matrices right before using capital letters to denote constants (T, H, W etc.).	I-Review	I-9	Review	231
Thank you for your detailed comments and recommendations for improvement in clarity!	O	O	Reply	231
We will try to clarify the terms in the final version.	O	O	Reply	231
<sep> <sep> == Model size, training- and generation time ==	O	O	Reply	231
We would like to point out that training time is not a problem specific to autoregressive models - on the contrary since there are no latent variables to infer and no recurrence to unroll, fully attention-based autoregressive models are among the most efficient to train as gradient computation is completely parallel across the 3D volume during training.	B-Reply	B-1	Reply	231
<sep> <sep> We agree that generation time is currently a considerable practical limitation of these methods.	B-Reply	B-1	Reply	231
However, as mentioned in the paper, we believe that parallel generation methods (e.g., Stern et al 2018) and low-latency hardware could bring down this substantially.	I-Reply	I-1	Reply	231
<sep> <sep> Regarding model-size, note that VideoFlow (Kumar et al 2019), for instance, has about the same number of parameters than our base models, yet our perplexity is much lower, our generated videos have much better fidelity and maintain long-range temporal dependencies (e.g., objects hidden by the robot arm for multiple frames) better.	B-Reply	B-1	Reply	231
<sep> <sep> UPDATE: The authors of VideoFlow corrected their initial response to us regarding model size.	B-Reply	B-1	Reply	231
Though still slightly higher, it turns out that their models' number of parameters are in the same ball park as our base models.	I-Reply	I-1	Reply	231
Hence, we corrected our statements above.	I-Reply	I-1	Reply	231
<sep> <sep> == Comparison on Kinetics ==	O	O	Reply	231
Our aim with this work is to push the limits of autoregressive models and demonstrate their effectiveness as baselines for competitive video prediction, as illustrated by the experiments on BAIR, while also providing momentum towards exploring much more challenging tasks.	B-Reply	B-2	Reply	231
We would definitely be interested in seeing how other methods would perform on the Kinetics dataset and hope that the community will take on this challenge.	I-Reply	I-2	Reply	231
<sep> <sep> == Block-local attention ==	O	O	Reply	231
Block-local attention is necessary to limit memory requirements as attention is quadratic in the number of pixels, which grows prohibitive for 3D volumes.	B-Reply	B-3	Reply	231
Block-local attention brings this down to linear complexity, similarly to the concurrently proposed flattened sparse attention of Child et al (2019), while maintaining the explicit 3D structure of videos and not requiring any custom kernels.	I-Reply	I-3	Reply	231
<sep> <sep> We did experiment with varying block sizes in the time- and space dimensions across different layers and found the model robust to this choice.	I-Reply	I-3	Reply	231
It seems that what matters is that there is a sufficient connectivity between pixels across the video volume, rather than the exact choice of per-layer connectivity.	I-Reply	I-3	Reply	231
<sep> <sep> == Ablation and relative-position prior ==	O	O	Reply	231
To clarify, the relative position attention-bias term does not enforce a local preference - it is a learned parameter which simply gives the model capacity to take relative position information into account.	B-Reply	B-4	Reply	231
Note that we do ablate the number of attention heads, number of layers and the hidden size in Table 3 of the appendix, where we find the hidden size to be the most effective way to improve perplexity.	I-Reply	I-4	Reply	231
<sep> <sep> == Why focus on video prediction ==	O	O	Reply	231
This is an interesting question.	B-Reply	B-5	Reply	231
We have focused on video generation conditioning on an initial frame to stay comparable to existing work.	I-Reply	I-5	Reply	231
Completely free video generation is much more difficult to evaluate, beyond visual inspection and perplexity.	I-Reply	I-5	Reply	231
By conditioning on an initial frame, measures such as FVD are much more informative.	I-Reply	I-5	Reply	231
We also believe that predicting future frames is a more practically interesting task.	I-Reply	I-5	Reply	231
However, we believe that autoregressive models could be competitive for unconditional generation as well, following the results on unconditional image generation by Menick &amp; Kalchbrenner (2019).	I-Reply	I-5	Reply	231
<sep> <sep> == Lower perplexity on Kinetics ==	O	O	Reply	231
This is indeed an intriguing finding.	B-Reply	B-6	Reply	231
There are many potential reasons.	I-Reply	I-6	Reply	231
However, we think this might be due to the lower frame-rate in the BAIR robotic pushing dataset (10 frames per second) compared to Kinetics (25), resulting in faster movement between frames.	I-Reply	I-6	Reply	231

<sep> Summary	O	O	Review	231
This papers presents a pixel-autoregressive model for video generation, in the spirit of VPN (Kalchbrenner‚Äô16).	O	O	Review	231
The proposed method uses video transformers and is made computationally efficient by extending block-local attention (Parmar‚Äô18, Chen‚Äô18) and sub-scaling (Menick‚Äô19) to 3D volumes.	O	O	Review	231
The block-local attention is separable, meaning that in theory it is possible to connect every two pixels through a sequence of block-local layers.	O	O	Review	231
However, for efficient parallelization implement via masking mechanism it is necessary to ignore certain connections, introducing independence assumptions.	B-Review	B-1	Review	231
The model is shown to substantially exceed state-of-the-art in terms of likelihood as well as quantitative and qualitative visual quality on several datasets, including the very challenging Kinetics-600.	I-Review	I-1	Review	231
Interestingly, it is shown that the model with spatiotemporal subscaling is more robust to higher generation temperatures, which could imply robustness to accumulating errors.	O	O	Review	231
<sep> <sep> Decision	O	O	Review	231
The paper proposes a well-motivated method backed by solid state-of-the-art results.	O	O	Review	231
I recommend accept.	O	O	Review	231
<sep> <sep> Pros	O	O	Review	231
- The proposed method is relevant and well-motivated.	O	O	Review	231
<sep> - The experimental results are strong.	O	O	Review	231
<sep> <sep> Cons	O	O	Review	231
- The paper novelty is somewhat limited as it is mostly a combination of previously existing techniques.	B-Review	B-2	Review	231
<sep> - The paper does not provide code which makes the results not easily reproducible.	B-Review	B-3	Review	231
I think a minimal example of the code should be provided that is trainable at least on a simple dataset.	I-Review	I-3	Review	231
<sep> <sep> Questions	O	O	Review	231
- No videos are provided.	B-Review	B-4	Review	231
Please provide an (anonymous immutable) link to video results.	I-Review	I-4	Review	231
<sep> - Strong aliasing artifacts can be seen in the supplement on the Kinetics data, such as vegetables becoming increasingly ‚Äúblocky‚Äù as well as general cube-like aliasing artifacts in Fig.9.	B-Review	B-5	Review	231
This indicates that the introduced independence assumptions are likely hurting the video quality.	I-Review	I-5	Review	231
The paper discusses this in the appendix C, stating that there seems to be no remedy for the independence assumptions that does not increase the computational cost.	I-Review	I-5	Review	231
However, this is exactly the problem that latent variable models such as variational inference or normalizing flows are designed to address.	I-Review	I-5	Review	231
Would a certain combination of latent variable models with the proposed autoregressive approach alleviate these issues?	I-Review	I-5	Review	231
<sep> <sep> Minor comments	O	O	Review	231
- Contrary to the summary in the related work section, Kumar‚Äô19 does not use variational inference and operates purely on the normalizing flows technique.	B-Review	B-6	Review	231
Similarly, Mathieu‚Äô16 and Vondrick‚Äô16 do not use variational inference either instead relying on adversarial techniques.	I-Review	I-6	Review	231
The paper correctly states that Lee‚Äô18, Castrejon‚Äô19 use variational inference.	I-Review	I-6	Review	231
<sep> - Figure 2 is never referred to in the text.	B-Review	B-7	Review	231
<sep> <sep> We updated our related work section slightly so that it becomes clearer that many of the mentioned works (after discussing VAE based approaches) are actually completely different directions and not additions upon VAEs.	B-Reply	B-6	Reply	231
<sep> <sep> We added a reference for Figure 2 in section 4.2, paragraph "Qualitative Observations".	B-Reply	B-7	Reply	231

Review of ‚ÄúUnsupervised-Learning of time-varying features‚Äù	O	O	Review	20590
<sep> This work looks at using a conditional VAE-based approach to model transformations of sequential data (transformations can be spatial, such as rotation of MNIST, or temporal, i.e. screenshots of a car racing game).	O	O	Review	20590
Like how our own visual system encodes differences in time and space [1], they show that in generative modelling with VAEs, ‚Äúthere is an advantage of only learning features describing change of state between images, over learning the states of the images at each frame.	O	O	Review	20590
‚Äù	O	O	Review	20590
<sep> Such an encoding allows the model to ignore features that are constant over time, and also makes it easier to represent data in a rotating curved manifold.	O	O	Review	20590
They demonstrate this using data collected from CarRacing-v0 task (a task where agents have to learn to drive from pixel observation of a top-down track), and also on MNIST where the digits are rotated around the center of an image.	O	O	Review	20590
They provide interesting analysis of the latent space learned and show that indeed this approach can handle both stationary and non-stationary features well (in CarRacing-v0).	O	O	Review	20590
For MNIST, they compare the latent space learned from transformations (z_dot) and show that this approach can encode image geometric transformations quite well.	O	O	Review	20590
<sep> <sep> While this paper is interesting and highlights advantages of modeling transformations of sequential data, I don't think the contributions are currently sufficient for ICLR conference (right now it is a good workshop paper IMHO).	B-Review	B-3	Review	20590
For it to be at the conference level, I can make a few suggestions of things that will bring it there, hopefully the authors can take these points as feedback to help improve the work:	O	O	Review	20590
<sep> 1) Would be great to see how this approach can compare to existing proposed algorithms (i.e. TD-VAE as cited)?	B-Review	B-1	Review	20590
Are there problems where this approach will perform really well that current methods are inadequate?	I-Review	I-1	Review	20590
<sep> <sep> 2) As the method is based on an RL-task, would the latent representation learned be useful for an RL agent that relies on the latent code across several representative RL tasks (in both sample efficiency, and/or terminal performance)?	B-Review	B-2	Review	20590
<sep> <sep> I don't mean to discourage the authors (esp as an Anon Reviewer #2...), as I like the direction of the work, and also appreciate that a lot of effort has gone into this work.	O	O	Review	20590
I hope to see the authors take the criticism to make their work better.	O	O	Review	20590
Good luck!	O	O	Review	20590
<sep> <sep> [1] Concetta1988, Feature detection in human vision: A phase-dependent energy model	O	O	Review	20590
<sep> <sep> Hi,	O	O	Reply	20590
<sep> Thanks a lot for your review.	O	O	Reply	20590
Don't worry, reviewer 2 is always appreciated and thought provoking.	O	O	Reply	20590
Also thanks for the reference!	O	O	Reply	20590
<sep> <sep> I think you are right that a follow-up experiment would have been very helpful, but we did not want to go overlength and/or cut on the experiment description.	B-Reply	B-2	Reply	20590
<sep> <sep> 1) In general, models like TD-VAE would lead to models akin to 5a/b/e/f/i/j insofar that the decoder has to learn to reconstruct the images.	B-Reply	B-1	Reply	20590
If you are not interested in the space of constant-features, this is probably wasteful.	I-Reply	I-1	Reply	20590
In some tasks there might also be no meaningful z-space.	I-Reply	I-1	Reply	20590
For example.	I-Reply	I-1	Reply	20590
if \dot{z} encodes translation, z would encode position.	I-Reply	I-1	Reply	20590
but in carracing, there is no natural coordinate-system to encode position.	I-Reply	I-1	Reply	20590
So you will likely not get a position feature, but instead a set of features that encodes image-content and by comparing the relative position of content, translation can be derived.	I-Reply	I-1	Reply	20590
i.e. we would expect a TD-VAE to learn a much more complicated feature-space for encoding translation.	I-Reply	I-1	Reply	20590
It would probably still perform very good, but the model might not be "physical" or interpretable in any meaningful way.	I-Reply	I-1	Reply	20590
<sep> <sep> 2) I think we could use the model in an RL-task.	B-Reply	B-2	Reply	20590
Because when we have a model p(x_{t+1}|x_t, \dot{z}_t) we could obtain a full world-model by learning p(\dot{z}_t|a_t,\dot{z}_{t-1}).	I-Reply	I-2	Reply	20590
where a_t is the position of the agent.	I-Reply	I-2	Reply	20590
And in turn we could use that to implement a Q-function (using Q(x_t,\dot{z}_t)).	I-Reply	I-2	Reply	20590
We felt that this would be a bit too much, because it would move us far from a method-paper to an application domain.	I-Reply	I-2	Reply	20590
But I see this might be required.	I-Reply	I-2	Reply	20590

This paper presents a VAE model.	O	O	Review	20590
The authors consider time series data and claim that in this situation it is better to model the transformations in the latents instead of each datum independently.	O	O	Review	20590
The setup is reasonable and seems novel, but since it stops at image registration, which is a well-known existing model I cannot qualify the paper as novel.	B-Review	B-1	Review	20590
The paper is mostly clear, some claims are not backed up by experiments and the experiments are lacking.	O	O	Review	20590
As I motivate below I find the current content more at a workshop level than a conference paper.	O	O	Review	20590
<sep> <sep> Major issues:	O	O	Review	20590
* This paper can become a conference paper in two ways in my opinion.	B-Review	B-2	Review	20590
1) It either needs to show that richer modeling has benefits (if anything it would seem from fig 5 that this is not the case).	I-Review	I-2	Review	20590
A way towards that would be to take data where there are no simple transformations that we can introduce and show that it discovers reasonable ones.	I-Review	I-2	Review	20590
And 2) show on some highly varying temporal domain that this is better than differences of z.	I-Review	I-2	Review	20590
* on page 2 " the initial assumption that the time-series must be stationary can be fulfilled" -- The data doesn't have to comply with our standards of stationarity.	B-Review	B-3	Review	20590
A more sensible formulation is we add these additional constraints to our model which are correct if the data is stationary.	I-Review	I-3	Review	20590
<sep> * On page 3 "to make sure that the latent space can be interpreted".	B-Review	B-4	Review	20590
This is a very strong claim, it implies that if we do this the latent space will always be interpretable, which I think is false and definitely not backed up by experiments.	I-Review	I-4	Review	20590
<sep> * The conditions on \dot{z} are interesting and potentially useful and they should be explored in experiments.	B-Review	B-5	Review	20590
Putting them in or not does it really make the sense that we think it should make ?	I-Review	I-5	Review	20590
Ideally in a setup where the data is not trivial.	I-Review	I-5	Review	20590
<sep> * I am not sure what insight a reader can possibly get from figure 3.	B-Review	B-6	Review	20590
<sep> * Given the final image-registration setup I find that the following citations are necessary:	B-Review	B-7	Review	20590
jaderberg et al Spatial transformer networks, Shu et al Deforming auto-encoders: unsupervised disentangling of shape and appearance.	I-Review	I-7	Review	20590
<sep> Minor issues:	B-Review	B-8	Review	20590
* the authors should number all equations.	I-Review	I-8	Review	20590
<sep> * In their first equation (not numbered) the indices go beyond N+1.	I-Review	I-8	Review	20590
Hi,	O	O	Reply	20590
<sep> Thanks for reviewing our paper!	O	O	Reply	20590
<sep> * issue 1:	O	O	Reply	20590
Figure 5c/g/k (the richer modeling) show an improvement over d/h/l.	B-Reply	B-2	Reply	20590
It is unclear why we don't observe it between 5a/b.	I-Reply	I-2	Reply	20590
Similarly, in the carracing task, the z-model failed to learn movement direction.	I-Reply	I-2	Reply	20590
see error histogram in 4d that shows a clear improvement of learning the \dot{z} model.	I-Reply	I-2	Reply	20590
Regarding the difficulty of the task, i will copy our answer to another reviewer:	I-Reply	I-2	Reply	20590
<sep> [snip]	I-Reply	I-2	Reply	20590
I think the most important result is the carracing task where the z-model fails to learn the translation direction.	I-Reply	I-2	Reply	20590
This is kind of obvious because here it is impossible to disentangle "content" from "position" (without observing x_t there is no valid coordinate system to define position on and translation is the relative shift of all content in the image).	I-Reply	I-2	Reply	20590
The only way to define translation using z_t coordinates would be to treat all "constant/slow changing" features c/f as changing variables z and define translation based on this high level image description of the whole content.	I-Reply	I-2	Reply	20590
This is probably what the encoder in the \dot{z}-model does.	I-Reply	I-2	Reply	20590
<sep> [/snip]	I-Reply	I-2	Reply	20590
<sep> The carracing task was based on real time-series data and the model found the 3 most important directions.	I-Reply	I-2	Reply	20590
Since carracing is a relevant RL task that got only solved recently, we think that showing that we can discover a parametrization of the movement-space is relevant.	I-Reply	I-2	Reply	20590
<sep> <sep> * issue 2: Could you elaborate why this is a major issue?	B-Reply	B-3	Reply	20590
This paragraph states that we can transform a time-series that does not conform to the assumptions into one that does.	I-Reply	I-3	Reply	20590
It is clear that for the "real" time-series only the part of the learned feature-space that actually occurs is relevant, but this procedure ensures that we learn it.	I-Reply	I-3	Reply	20590
Figures 4 e/f/g/h actually show this difference of modeling, which in this task just leads to a symmetrization of the space.	I-Reply	I-3	Reply	20590
There would only be an issue when sampling from the learned distribution as this would only generate stationary time-series.	I-Reply	I-3	Reply	20590
But this is a small issue as we can learn afterwards, which part of the feature-space is relevant.	I-Reply	I-3	Reply	20590
<sep> * issue 3: We will use a weaker wording here.	B-Reply	B-4	Reply	20590
We mainly wanted to indicate that e.g. length or directions of the \dot{z} vector carry meaning (unlike when, for example, the identity would be placed away from 0).	I-Reply	I-4	Reply	20590
<sep> * issue 4: Which data would you deem non-trivial?	B-Reply	B-5	Reply	20590
the carracing task is hard to model correctly, even though the underlying transformations turn out to be simple.	I-Reply	I-5	Reply	20590
We are further constrained by the fact that the learned feature-space should still be accessible to human analysis.	I-Reply	I-5	Reply	20590
<sep> *issue 5: We write for a)  "Figure 3[a] (typo in the paper: we wrote 3b, sorry for this) , reveals	B-Reply	B-6	Reply	20590
that the learned encoding of ≈º (and z by construction) is a piecewise-linear function with large	I-Reply	I-6	Reply	20590
jumps.	I-Reply	I-6	Reply	20590
When plotting a larger area of the space (not shown), we found that the decoder had matching	I-Reply	I-6	Reply	20590
discontinuities that allow for correct reconstruction.	I-Reply	I-6	Reply	20590
Thus, the encoding developed multiple ≈º-values	I-Reply	I-6	Reply	20590
that parameterize the same rotation."	I-Reply	I-6	Reply	20590
We will clarify the sentence to indicate that we meant a larger space of Figure 5d.	I-Reply	I-6	Reply	20590
The learnt topology in 3a is incompatible with a circle and therefore the decoder has to apply "tricks" to fix the jumps in the encoding.	I-Reply	I-6	Reply	20590
This is the only valid encoding because the model only sees differences of the underlying z-values and for these to make sense, all z-values must lie on a line.	I-Reply	I-6	Reply	20590
If they don't, you get Figure 3b) where we show that the same rotation is encoded differently depending on the orientation of the first image.	I-Reply	I-6	Reply	20590
Therefore the difference-vector \dot{z}_t must be interpreted with respect to z_t.	I-Reply	I-6	Reply	20590
The difference between a) and b) is that the model in Figure 5d) can't do this re-interpretation, while the model in 5b can(Since it observes x_t and thus can compute z_t)	I-Reply	I-6	Reply	20590
* Thanks for the references, we will add them to the paper	B-Reply	B-7	Reply	20590

This paper presents a VAE architecture that separates a fixed content representation and time varying features of an image, that can be used to learn a representation of image transformations in a temporal setting.	O	O	Review	20590
<sep> <sep> The paper is well written and the ideas presented are interesting, but in my opinion not novel enough or thoroughly demonstrated to justify acceptance:	O	O	Review	20590
<sep> - there is a very relevant work that is not mentioned by the authors and that can be seen as a generalization of the model presented in this paper: "Disentangled Sequential Autoencoder" by Li and Mandt (ICML 2018), which introduces a model that is also disentangling a content and a temporal representation of sequential data.	B-Review	B-1	Review	20590
This is basically the more general model introduced by the authors of this submission in the beginning of section 2, without all the assumptions made in the rest of section 2.	I-Review	I-1	Review	20590
A comparison with this related work would help assess the differences in terms of modelling power and in performances.	I-Review	I-1	Review	20590
<sep> <sep> - The assumptions made in this work are fairly strong for most interesting applications, in particular the fact that the content cannot change across time steps.	B-Review	B-2	Review	20590
<sep> <sep> - To me, the issue with the novelty of this model would not be a big problem if the authors focused more on showing its usefulness in different applications (e.g. medical domain or RL as mentioned in the conclusions).	B-Review	B-3	Review	20590
However, the authors only demonstrate the TEVAE on relatively simple experiments that are only tailored to simple image transformations.	I-Review	I-3	Review	20590
<sep> <sep> Thanks for the review and the reference which we will cite and discuss in the paper.	B-Reply	B-1	Reply	20590
Indeed the underlying generative model we start up with is the same as (1) in the reference.	I-Reply	I-1	Reply	20590
However, the main purpose of the paper is that we argue against modeling z_t directly and instead propose our generative model (1) which focuses on the differences between the time-steps.	I-Reply	I-1	Reply	20590
You are right that our model has stronger assumptions insofar that we do not model constant features directly ( c in our paper or f in the reference) and therefore need to assume that c/f and z_t can be correctly estimated from the previous image.	I-Reply	I-1	Reply	20590
<sep> <sep> In our paper, we focused on tasks that are simple enough to illustrate the differences in modelling of z_t and \dot{z_t}. We are confident that we could apply it to experiment 4.1 in the reference, which would amount to learning the actions without learning the appearance.	I-Reply	I-1	Reply	20590
However, this task, while looking more fancy, would be easier, because the action-space is discrete(the frame number in the animation) and there is no difficult topology to learn - a flat topology would suffice.	I-Reply	I-1	Reply	20590
In this case, modeling z_t and \dot{z}_t would be equivalent.	I-Reply	I-1	Reply	20590
The experiment 4.3 also sounds very interesting and would require an extension of the model to encode transitions p(\dot{z}_{t+1}|\dot{z}_t, x_t) for the forward-prediction task (to model the elastic collisions).	I-Reply	I-1	Reply	20590
Still, the \dot{z} space would probably be simpler compared to what we consider in our experiments, since movement of the ball is just learning position/velocity, which is a flat space.	I-Reply	I-1	Reply	20590
<sep> <sep> In our experiments on MNIST, focusing on scaling and rotation reveals that it is difficult for a VAE to learn an encoding that is compatible with the normal prior and can not be described as disentangled.	I-Reply	I-1	Reply	20590
This is very important, because even if models in Figure 5 e/f/ would produce better visual results, sampling z_t or \dot{z}_t from the prior would not lead to good samples since the true learned encoding lies on a curved manifold.	I-Reply	I-1	Reply	20590
Also, since the manifold changes depending on object symmetry(and involves a twist in 2d space), recent approaches like manifold-based priors are not easy to adapt to this.	I-Reply	I-1	Reply	20590
When enforcing a flat manifold that is consistent with the prior (figure h/l) we obtain that the model fails at reconstructing roughly half of the rotation-space, except when learning a model where the encoder has enough information to perform the parallel transport of the tangent space (Figure g/k).	I-Reply	I-1	Reply	20590
So we claim that the model in Figure g/k is the only one that actually solves the task.	I-Reply	I-1	Reply	20590
<sep> <sep> I think the most important result is the carracing task where the z-model fails to learn the translation direction.	I-Reply	I-1	Reply	20590
This is kind of obvious because here it is impossible to disentangle "content" from "position" (without observing x_t there is no valid coordinate system to define position on and movement is the relative shift of all content in the image).	I-Reply	I-1	Reply	20590
The only way to define translation using z_t coordinates would be to treat all "constant/slow changing" features c/f as changing variables z and define translation based on this high level image description of the whole content.	I-Reply	I-1	Reply	20590
This is probably what the encoder in the \dot{z}-model does.	I-Reply	I-1	Reply	20590
<sep> <sep> Regarding content: while this is true for the registration model, this is not true for a general NN approach.	B-Reply	B-2	Reply	20590
It is just very difficult to find a proper architecture for that.	I-Reply	I-2	Reply	20590
since changing content is a varying variable, it would be modeled via z_t/\dot{z}_t.	I-Reply	I-2	Reply	20590
E.g. in a video game the only truely constant feature would be "which level am I in".	I-Reply	I-2	Reply	20590
In our paper, we had to change the loss-function on the carracing task to ignore the borders, otherwise we would have needed a much larger feature space to model all content in the image(or at least the borders).	I-Reply	I-2	Reply	20590
<sep> <sep> Final words:	O	O	Reply	20590
I agree with your review that our model has its limits.	B-Reply	B-2	Reply	20590
We don't model higher order time-dependencies (which is a simple extension that is only relevant for n-step (n&gt;1) prediction tasks) and we don't model c. This is not a simple extension because (c, \dot{z}_t) is not a complete description of the state and we would also need to model z_t somehow.	I-Reply	I-2	Reply	20590
<sep> <sep> In the end, ICLR is about learning representations and we learn a representation for \dot{z} that is meaningful and minimal.	B-Reply	B-3	Reply	20590
One might debate whether this is enough or not, but this might be standpoint specific.	I-Reply	I-3	Reply	20590
We definitely have not answered all questions (e.g. how to get a neural network in the MNIST task to learn the flat manifold as in Figure 5c), but we think there are a lot of tasks out there were our current results are important(e.g.	I-Reply	I-3	Reply	20590
modeling progression of diseases).	I-Reply	I-3	Reply	20590

The goal in this work is to improve machine interpretability of images.	O	O	Review	10083
<sep> The authors main claims are:	O	O	Review	10083
-<tab>Their proposed approach improves image recognition accuracy even without knowing subsequent recognition tasks and recognition models used to perform them (transferable model to different recognition models/tasks).	O	O	Review	10083
<sep> -<tab>For this they propose what they call ‚ÄúRecognition-Aware‚Äù processing that combines image processing loss and recognition loss.	O	O	Review	10083
<sep> -<tab>The approach is evaluated on three image processing tasks with two downstream recognition tasks:	O	O	Review	10083
o<tab>Image super-resolution, de-noising, and JPEG-de-blocking processing tasks, with	O	O	Review	10083
o<tab>Image classification and object detection recognition tasks.	O	O	Review	10083
<sep> <sep> The paper is well written and organized, experiments carried are extensive but the reuse of known neural networks, many simplifications (shortcuts), a not clear enough methodology (see below), limited processing &amp; recognition tasks used to support it, do not justify in our opinion the main (over-arching) work‚Äôs claim:	B-Review	B-1	Review	10083
-<tab>In 3.2 optimizing recognition loss/Last paragraph:  ‚ÄúInterestingly, we find that image processing models trained with the loss of one recognition model R1, can also boost the performance when evaluated using recognition model R2, even if model R2 has a different architecture, recognizes a different set of categories or even is trained for a different task.	I-Review	I-1	Review	10083
‚Äù.	I-Review	I-1	Review	10083
<sep> <sep> The paper would greatly benefit (to understand the context of the work or the explanations provided) from clarification of the many under-defined, not clearly introduced concepts it carries:	B-Review	B-2	Review	10083
-<tab>Meaning of ‚ÄúNetwork‚Äù is not clearly defined:	I-Review	I-2	Review	10083
o<tab>Abstract: ‚Äúimage processing network‚Äù.	I-Review	I-2	Review	10083
<sep> o<tab>Introduction: ‚Äúthe network maps an image to a semantic label‚Äù	I-Review	I-2	Review	10083
o<tab>Later in the paper only networks introduced are deep neural networks.	I-Review	I-2	Review	10083
That should be clear from beginning of the paper.	I-Review	I-2	Review	10083
<sep> -<tab>‚ÄúRetraining/Adaptation‚Äù  in 1st paragraph page 2.	B-Review	B-3	Review	10083
<sep> -<tab>In 1.	B-Review	B-4	Review	10083
Introduction/Paragraph 1: You use ‚Äú.. techniques .. have been proposed for making the output images look natural to human‚Äù:	I-Review	I-4	Review	10083
o<tab>Noise is part of nature.	I-Review	I-4	Review	10083
A de-noised (smoothed) image is not ‚Äúmore natural‚Äù.	I-Review	I-4	Review	10083
<sep> o<tab>Enhanced (processed) images are not necessarily ‚Äúmore‚Äù natural, rather they take advantage of the human visual perception characteristics to enhance recognition for example.	I-Review	I-4	Review	10083
<sep> -<tab>In 1.	B-Review	B-5	Review	10083
Introduction/Paragraph 3:	I-Review	I-5	Review	10083
o<tab>‚Äú.. of great importance that the processed images be recognizable‚Äù  Should explain the concept of image recognition!	I-Review	I-5	Review	10083
Because it could be related to contained objects, overall description (for captioning for example) etc.	I-Review	I-5	Review	10083
<sep> -<tab>‚ÄúImage processing‚Äù in the context of the paper is intended only as ‚Äúimage enhancement for recognition‚Äù.	B-Review	B-6	Review	10083
Pattern detection, segmentation, object extraction etc.	I-Review	I-6	Review	10083
are not included in this restrictive definition.	I-Review	I-6	Review	10083
Should specify for example: image enhancement and restoration.	I-Review	I-6	Review	10083
<sep> -<tab>Figure 1: As an illustration, it‚Äôs completely counterproductive for your discourse as many simple image recognition algorithms would recognize the bird even in the noisy image.	B-Review	B-7	Review	10083
<sep> -<tab>In 3.	B-Review	B-8	Review	10083
Unsupervised optimization of recognition loss: The ‚Äúunsupervised RA‚Äù process is not  clear enough to us especially the statement:	I-Review	I-8	Review	10083
o<tab>‚Äú.. only ‚Äúunsupervised‚Äù for training model P, but the target pre-trained model R can still be trained in full supervision.	I-Review	I-8	Review	10083
‚Äù.	I-Review	I-8	Review	10083
<sep> <sep> <sep> -<tab>‚ÄúWe may not know what network architectures (e.g. ResNet or VGG) will be used for inference, what object categories the downstream model recognizes (e.g. animals or scenes), or even what task will be performed on the processed image (e.g. classification or detection)‚Äù.	B-Review	B-9	Review	10083
<sep> o<tab>Is your goal a universal ‚Äúrecognition model‚Äù applicable to anything?	I-Review	I-9	Review	10083
<sep> -<tab>I also have some trouble with the terminology:	B-Review	B-10	Review	10083
o<tab>In 1.	I-Review	I-10	Review	10083
Introduction/Paragraph 4: ‚ÄúIt is also important that the enhanced machine semantics is not specific to any concrete recognition model‚Äù: ‚Äúenhanced machine semantics‚Äù!	I-Review	I-10	Review	10083
<sep> o<tab>In 1.	I-Review	I-10	Review	10083
Introduction/Paragraph 4: ‚Äú..transferable among different recognition architectures..‚Äù.	I-Review	I-10	Review	10083
Does ‚Äúarchitectures‚Äù refer to deep neural networks (DNN)?	I-Review	I-10	Review	10083
If yes, is recognition performed only by DNN?	I-Review	I-10	Review	10083
What about the preceding bullet (‚Äúis not specific to any concrete recognition model‚Äù)?	I-Review	I-10	Review	10083
<sep> -<tab>In 1.	B-Review	B-11	Review	10083
Introduction/Paragraph 3:	I-Review	I-11	Review	10083
o<tab> ‚Äú.. we argue that image processing systems should maintain/enhance machine semantics‚Äù.	I-Review	I-11	Review	10083
Do not see what‚Äôs to argue here?	I-Review	I-11	Review	10083
<sep> o<tab>‚ÄúRecognition-Aware Image Processing‚Äù is it simply put Image Processing techniques for recognition enhancement (‚ÄúRecognition‚Äù still needs to be defined)?	I-Review	I-11	Review	10083
<sep> -<tab>In 2 Related work :	B-Review	B-12	Review	10083
o<tab> ‚Äú .. we assume we do not have the control on the recognition model, as it might be on the cloud or decided in the future, thus we advocate adapting the image processing model only.	I-Review	I-12	Review	10083
This also ensures the recognition model is not harmed on natural images.	I-Review	I-12	Review	10083
‚Äù Care to explain?	I-Review	I-12	Review	10083
<sep> o<tab>: ‚Äúto achieve better recover the face identity from low-resolution images‚Äù, Typo?	I-Review	I-12	Review	10083
<sep> -<tab>In 1.	B-Review	B-13	Review	10083
Introduction/Paragraph 1:	I-Review	I-13	Review	10083
o<tab>‚Äú .. might not look ‚Äúnatural‚Äù to machines‚Äù: Care to explain this concept?	I-Review	I-13	Review	10083
<sep> ÔÇß<tab>Would advise to just keep the second part of the sentence.	I-Review	I-13	Review	10083
<sep> -<tab>In 1.	B-Review	B-14	Review	10083
Introduction/Paragraph 2: ‚ÄúOne could specifically train a recognition model only on these output images produced by the de-noising model to achieve better performance on such images, but the performance on natural images can be harmed.	I-Review	I-14	Review	10083
‚Äù  Care to explain?.	I-Review	I-14	Review	10083
<sep> o<tab>More complicated images (noisier, multiple obstructions etc.)	I-Review	I-14	Review	10083
are recognized nowadays and true to actual applications.	I-Review	I-14	Review	10083
<sep> <sep> -<tab>3.4 using an intermediate transformer/Last paragraph:	B-Review	B-15	Review	10083
o<tab>‚Äú .. that there are two instances for each image (the output of model P and T), one is ‚Äúfor human‚Äù and the other is ‚Äúfor machines‚Äù.	I-Review	I-15	Review	10083
‚Äù:	I-Review	I-15	Review	10083
ÔÇß<tab>The ‚ÄúTransformer‚Äù characteristics are not clearly defined for the intended output (For machines?).	I-Review	I-15	Review	10083
<sep> ÔÇß<tab>Why is output of model T not represented in Figure 2 (Right)?	I-Review	I-15	Review	10083
Thank you for your constructive feedback!	O	O	Reply	10083
We answer your questions below, and we have uploaded a revision addressing your concerns.	O	O	Reply	10083
For easier reading we pasted some of your comments, and please bear with the length of our response.	O	O	Reply	10083
<sep> <sep> First paragraph:	O	O	Reply	10083
‚Äúthe reuse of known neural networks, many simplifications (shortcuts), a not clear enough methodology (see below), limited processing &amp; recognition tasks used to support it, do not justify in our opinion the main (overarching) work‚Äôs claim‚Äù	O	O	Reply	10083
<sep> ‚Äúreuse of known neural networks‚Äù	O	O	Reply	10083
We would like to clarify that our contribution does not lie in designing new neural architectures, but the use of recognition loss on image processing outputs.	B-Reply	B-1	Reply	10083
To demonstrate the general usefulness of our method, we chose popular neural networks (SRResNet, VGG, ResNet, DenseNet) in the literature for experiments.	I-Reply	I-1	Reply	10083
<sep> <sep> ‚Äúmany simplifications (shortcuts)‚Äù	O	O	Reply	10083
Could you elaborate more on this point?	B-Reply	B-1	Reply	10083
Sorry but we are not sure what ‚Äúsimplifications‚Äù refer to here.	I-Reply	I-1	Reply	10083
If ‚Äúsimplifications‚Äù refers to the use of neural networks as processing/recognition models, we acknowledge this point, but we also would like to mention that NNs are currently popular models for such tasks.	I-Reply	I-1	Reply	10083
<sep> <sep> ‚Äúa not clear enough methodology (see below)‚Äù	O	O	Reply	10083
We answer your detailed questions about our method below.	B-Reply	B-1	Reply	10083
<sep> <sep> ‚Äúlimited processing &amp; recognition tasks‚Äù	O	O	Reply	10083
We experimented with three image processing tasks &amp; two recognition tasks (in total six pairs), and transferability between the two recognition tasks, for all three of our main methods and five recognition architectures, thus we respectfully disagree that our used tasks are limited.	B-Reply	B-1	Reply	10083
Most prior works (e.g., [1,2]) only consider one processing/recognition task.	I-Reply	I-1	Reply	10083
In the revision, we also added some results on the ImageNet-C benchmark [3] which has 17 types of corruptions in Appendix D.	I-Reply	I-1	Reply	10083
<sep> ‚Äúdo not justify in our opinion the main (overarching) work‚Äôs claim‚Äù	O	O	Reply	10083
We believe the experiments in section 4.2-4.4 and appendix B demonstrated how the performance gain is transferable (as in the claim) under these various conditions.	B-Reply	B-1	Reply	10083
<sep> <sep> Second paragraph:	O	O	Reply	10083
1.	O	O	Reply	10083
Definition of ‚ÄúNetwork‚Äù	B-Reply	B-2	Reply	10083
The ‚Äúnetwork‚Äù mentioned in the paper means a (deep) convolutional neural network, we have clarified this in abstract in the revision (network -&gt; neural network), following your suggestion.	I-Reply	I-2	Reply	10083
<sep> <sep> 2. ‚	O	O	Reply	10083
ÄúRetraining/Adaptation‚Äù	O	O	Reply	10083
Here ‚Äúretraining/adapting‚Äù means training a recognition specifically on the image processing outputs (instead of natural images as usual) or adapting (e.g., using some domain adaptation approaches) the naturally trained image recognition model so that it specifically recognizes images output by an image processing model (e.g., denoised images).	B-Reply	B-3	Reply	10083
This was briefly explained in the sentence before, and we‚Äôve made it more clear in the revision.	I-Reply	I-3	Reply	10083
<sep> <sep> 3. ‚	O	O	Reply	10083
Äúlook ‚Äònatural‚Äô to human‚Äù	O	O	Reply	10083
We agree that denoised or enhanced images are not necessarily more ‚Äúnatural‚Äù, and we‚Äôve changed it to ‚Äúfor making the output images more perceptually pleasing to human‚Äù.	B-Reply	B-4	Reply	10083
Thanks for your suggestion.	I-Reply	I-4	Reply	10083
<sep> <sep> 4.	O	O	Reply	10083
Definition of recognition.	O	O	Reply	10083
<sep> In the revision, we added a brief explanation about ‚Äúrecognizable‚Äù in paragraph 3: ‚ÄúIn other words, recognition systems (e.g., image classifier or object detector), should be able to accurately explain the underlying semantic meaning of the image content .‚Äù In our context, this recognition system could be any neural network including a neural-based captioning system.	B-Reply	B-5	Reply	10083
<sep> <sep> 5.	O	O	Reply	10083
Specifying as enhancement/restoration.	O	O	Reply	10083
<sep> Following your suggestion we have changed in the last paragraph of introduction from ‚ÄúWe conduct extensive experiments, on multiple image processing tasks‚Äù to ‚ÄúWe conduct extensive experiments, on multiple image enhancement/restoration tasks‚Äù.	B-Reply	B-6	Reply	10083
We also added a clarification in the experiment section: ‚ÄúMore specifically, these are image enhancement or restoration tasks, where usually the target image is an enhanced image or the original image.	I-Reply	I-6	Reply	10083
Other more broader image processing tasks such as pattern detection, segmentation, object extraction are not considered in this work.	I-Reply	I-6	Reply	10083
‚Äù We will also consider updating the title to reflect this modification.	I-Reply	I-6	Reply	10083
<sep> <sep> 6.	O	O	Reply	10083
Figure 1.	O	O	Reply	10083
<sep> We agree that many recognition systems would still recognize this particular noisy bird image correctly, but the accuracy on noisy images is also severely hurt on noisy images compared with normal ones.	B-Reply	B-7	Reply	10083
In this case, we used a modern network architecture (i.e., ResNet-18) and it indeed incorrectly classifies this noisy image as a kite.	I-Reply	I-7	Reply	10083
<sep> <sep> 7.	O	O	Reply	10083
Meaning of ‚Äúunsupervised‚Äù.	O	O	Reply	10083
<sep> This ‚Äúunsupervised RA‚Äù scheme means in the recognition loss we regress the probability output of the original image (‚Äúsoft label‚Äù), rather than the hard label in the supervised case. ‚	B-Reply	B-8	Reply	10083
Äúonly ‚Äòunsupervised‚Äô for training model P‚Äù means that in training the image processing model P, we do not need image labels, but the recognition model R could be trained in any manner, either with or without full label supervision, because we assume R is a pretrained model in our problem setting.	I-Reply	I-8	Reply	10083
We‚Äôve added more clarification in the revision.	I-Reply	I-8	Reply	10083

This paper presents several models for visual recognition in the presence of image degradation (e.g., low-resolution, noise, compression artifacts).	O	O	Review	10083
In the models, an image enhancement network is placed in front of a recognition model and trained together with the recognizer to improve the recognition accuracy as well as to enhance the image quality.	O	O	Review	10083
The proposed approach is simple, straightforward, yet effective.	O	O	Review	10083
It has been also shown that the image enhancement module is transferable between different recognition tasks and architectures.	O	O	Review	10083
<sep> <sep> Although the paper addresses a timely topic and the performance gain is substantial, my current decision is reject mainly because of its weakness in technical novelty and contribution.	B-Review	B-1	Review	10083
The proposed models are simple and straightforward combinations of two separate networks, one for image enhancement and the other for recognition.	I-Review	I-1	Review	10083
This approach also makes the entire networks overly heavy, and introduces hyper-parameters (e.g., lambda) that have to be carefully tuned.	I-Review	I-1	Review	10083
Overall, it was hard to find interesting ideas that future readers may learn from the paper.	I-Review	I-1	Review	10083
<sep> <sep> Other comments:	O	O	Review	10083
<sep> The 2nd model based on knowledge distillation (KD) is called "unsupervised", which however sounds weird.	B-Review	B-2	Review	10083
As already mentioned in the manuscript, the teacher network for KD is trained in a fully supervised manner for the target task, so it cannot be considered as an unsupervised model.	I-Review	I-2	Review	10083
Further, the advantage of the 2nd model is marginal in practice.	I-Review	I-2	Review	10083
<sep> <sep> The advantage of the transformer in the 3rd model is not clearly discussed.	B-Review	B-3	Review	10083
It is unknown in the paper why the 3rd model with the transformer works best in the experiments.	I-Review	I-3	Review	10083
Also, regarding the main goal of the paper (i.e., image enhancement not for human but for recognition networks), the reason for adopting the transformer is hard to understand.	I-Review	I-3	Review	10083
<sep> <sep> The degrees of image corruption (e.g., down-sampling, noise, compression) applied during testing are not mentioned at all, although they are important to understand the empirical advantage of the proposed models.	B-Review	B-4	Review	10083
<sep> <sep> The transferability is one of the most important benefit of the proposed model, but not convincing sufficiently.	B-Review	B-5	Review	10083
The proposed models are transferable between different object categories, but the plain models seem to be also transferable, sometime more transparently.	I-Review	I-5	Review	10083
Also, it is not clearly discussed what makes the proposed models attaining the transferability.	I-Review	I-5	Review	10083
<sep> <sep> It would be nice to apply the proposed models to the ImageNet-C benchmark.	B-Review	B-6	Review	10083
<sep> <sep> Missing references	O	O	Review	10083
- Studying Very Low Resolution Recognition Using Deep Networks, CVPR 2016	O	O	Review	10083
-  Benchmarking Neural Network Robustness to Common Corruptions and Perturbations, ICLR 2019	O	O	Review	10083
Thank you for your constructive feedback!	O	O	Reply	10083
We are happy to address your concerns below and we have uploaded a revision reflecting the changes.	O	O	Reply	10083
For easier reading, we‚Äôve pasted some of your comments in our response, and please bear with the length of our response.	O	O	Reply	10083
<sep> <sep> Response to major concern:	O	O	Reply	10083
<sep> Technical novelty and contribution	O	O	Reply	10083
We are glad to see the reviewer agrees that we are addressing an important and timely problem (making image processing outputs more accurately recognized by machines), and our method brings substantial performance gain.	B-Reply	B-1	Reply	10083
We agree that our method towards this goal is simple and straightforward, but we would like to view this simplicity as a strength.	I-Reply	I-1	Reply	10083
It makes our methods easy to implement and potentially more widely used in practice.	I-Reply	I-1	Reply	10083
Our contribution does not lie in designing network architectures or components, but is to showcase our simple methods can work favorably on an important but largely ignored problem, and more interestingly the improvement is even ‚Äútransferable‚Äù.	I-Reply	I-1	Reply	10083
We agree that architecture-wise, our method consists of two separate networks, but the key idea is to use a fixed recognition loss upon the original image processing loss for better machine recognizability of image processing outputs.	I-Reply	I-1	Reply	10083
Our technical contributions are bringing this problem to the community, developing a simple and effective method which imposes a recognition loss, with its variants that are useful in different scenarios, and showing the performance gain is transferable under various conditions.	I-Reply	I-1	Reply	10083
<sep> <sep> ‚ÄúOverly heavy‚Äù system	O	O	Reply	10083
Our system might be ‚Äúheavier‚Äù during training than plain processing, since it incorporates an additional loss computation with the recognition model.	B-Reply	B-1	Reply	10083
Our training still finishes in a reasonable amount of time (less than one hour to a few hours with a single GPU).	I-Reply	I-1	Reply	10083
More importantly, once the training is finished, the recognition model used as loss is not needed anymore, and during inference, we only need the processing model P, so no additional overhead is introduced when the model is actually put to deployment.	I-Reply	I-1	Reply	10083
We have included this point in section 3.2 in the revision.	I-Reply	I-1	Reply	10083
<sep> <sep> Hyperparameter	O	O	Reply	10083
Incorporating a new loss function often requires tuning of the coefficient hyperparameter, but in our case this hyperparameter is only grid searched once within a short range for each variant of our methods (RA Processing, Unsupervised RA and RA w/ Transformer), using ResNet-18 as the recognition model and super-resolution as processing tasks.	B-Reply	B-1	Reply	10083
The same is then used on other processing tasks and recognition models.	I-Reply	I-1	Reply	10083
This means a consistent works well with different conditions.	I-Reply	I-1	Reply	10083
An analysis of the hyperparameter with RA Processing is presented at Table 6, we can see that from 1e-4 to 1e-2 all bring substantial improvement in terms of recognition accuracy.	I-Reply	I-1	Reply	10083
As for each variant of our method, this brief grid search is necessary since unsupervised RA and RA processing have very different forms of loss functions and the two losses differ a lot in scales.	I-Reply	I-1	Reply	10083
<sep> <sep> ‚ÄúIt was hard hard to find interesting ideas that future readers may learn from the paper‚Äù	O	O	Reply	10083
Overall, we raised an important problem to the community, developed a simple method (and several variants for different use cases) that can work on the problem, and presented the intriguing ‚Äútransferability‚Äù of our method.	B-Reply	B-1	Reply	10083
This transferability phenomenon is quite surprising to us.	I-Reply	I-1	Reply	10083
It could bring insights into questions like how neural networks function and what do different neural networks share in common.	I-Reply	I-1	Reply	10083
We believe our work can be useful to the research community as a new problem is raised, and we hope it encourages researchers to further develop better methods on this problem.	I-Reply	I-1	Reply	10083
Also our method could be useful for industry usage as it is simple and gives substantial performance gain on a very practical problem.	I-Reply	I-1	Reply	10083
<sep> <sep> <sep> Response to other comments:	O	O	Reply	10083
1.‚ÄúThe 2nd model based on knowledge distillation (KD) is called "unsupervised", which however sounds weird.	B-Reply	B-2	Reply	10083
As already mentioned in the manuscript, the teacher network for KD is trained in a fully supervised manner for the target task, so it cannot be considered as an unsupervised model.	I-Reply	I-2	Reply	10083
Further, the advantage of the 2nd model is marginal in practice.	I-Reply	I-2	Reply	10083
‚Äù	I-Reply	I-2	Reply	10083
<sep> First we would like to clarify on the relation with KD.	I-Reply	I-2	Reply	10083
Our system is similar to the KD in terms of the loss function (using a predicted ‚Äúsoft‚Äù probability distribution to guide the training instead of ‚Äúhard‚Äù ground truth labels), but not in terms of the ‚Äúteacher-student‚Äù model paradigm.	I-Reply	I-2	Reply	10083
In our system, the probability distribution is obtained by feeding the original image to the same pretrained recognition model, but in KD, it‚Äôs obtained by feeding the image to a different teacher model.	I-Reply	I-2	Reply	10083
Thus, the pretrained model R is not considered as a ‚Äúteacher model‚Äù, but the original image can be considered as a ‚Äúteacher image‚Äù.	I-Reply	I-2	Reply	10083

Claims:	O	O	Review	10083
<sep> The paper presents a concept of "recognition-aware (RA) image processing": when one enhances image in a some way, not only human judjement should be taken into account, but also performance of various computer vision application using that image.	O	O	Review	10083
<sep> <sep> As an example of processing tasks, authors take super-resolution, denoising and JPEG-artifacts removal.	O	O	Review	10083
Downstream applications covered are image classification and object detection.	O	O	Review	10083
<sep> <sep> Authors propose a several training schemas to solve this problem and discuss a limitations of each one:	O	O	Review	10083
- "simple" preprocessing, when the only image enhancement loss is optimized	O	O	Review	10083
- "RA" joint optimization of recognition and enhancement loss (supervised and unsupervised)	O	O	Review	10083
- a variant when two images are created: one for human and one for machine.	O	O	Review	10083
<sep> ****	O	O	Review	10083
<sep> Recommendation: strong accept	O	O	Review	10083
<sep> ****	O	O	Review	10083
Comments:	O	O	Review	10083
<sep> Experiments are vast and performed on a variety of CNN architectures: ResNets, DenseNet ant VGGNet.	O	O	Review	10083
<sep> Because one cannot predict, which computer vision tasks will be needed in the future, the natural question arise: how the results got for one set of tasks, architectures and image enhancement types transfer to another.	O	O	Review	10083
Paper carefully studies this aspect as well.	O	O	Review	10083
<sep> Overall paper is well written and is pleasure to read.	O	O	Review	10083
While reading, I made notes to ask in review - just to see the my questions answered in a next section.	O	O	Review	10083
<sep> Authors also provide source code for training.	O	O	Review	10083
I haven`t run them though, but glanced through them.	O	O	Review	10083
<sep> Weaknesses: I cannot really find a significant one.	O	O	Review	10083
As a minor points:	O	O	Review	10083
- I would recommend to cite not the last papers for image enhancement porblems themselves like super-resolution and denoising: these are old problems with rich history, e.g.	B-Review	B-1	Review	10083
L. Rudin, S. Osher, and E. Fatemi, Nonlinear total variation based noise removal algorithms Physica D, 60 (1992), pp.259‚Äì268.	O	O	Review	10083
<sep> - "Transformer" is probably bad name for deep learning component, as it is already widely used for a specific seq2seq architecture	B-Review	B-2	Review	10083
<sep> <sep> ****	O	O	Review	10083
After rebuttal: I am now even more convinced that paper should be accepted.	O	O	Review	10083
Thank you for your positive feedback!	O	O	Reply	10083
We are glad to see your acknowledgement on our contributions, and we are happy address your concerns below:	O	O	Reply	10083
<sep> 1.	O	O	Reply	10083
In the updated revision, we‚Äôve added a few citations of classic papers on super-resolution and denoising, in the first sentence of related work: ‚ÄúImage processing/enhancement problems such as super-resolution and denoising have a long history [1,2,3,4].‚Äù	B-Reply	B-1	Reply	10083
<sep> [1] Tsai, R. Multiframe image restoration and registration.	O	O	Reply	10083
Advance Computer Visual and Image Processing 1 (1984): 317-339.	O	O	Reply	10083
<sep> [2] Park S C, Park M K, Kang M G. Super-resolution image reconstruction: a technical overview.	O	O	Reply	10083
IEEE signal processing magazine, 2003, 20(3): 21-36.	O	O	Reply	10083
<sep> [3] Rudin L I, Osher S, Fatemi E. Nonlinear total variation based noise removal algorithms.	O	O	Reply	10083
Physica D: nonlinear phenomena, 1992, 60(1-4): 259-268.	O	O	Reply	10083
<sep> [4] Cand√®s E J, Romberg J, Tao T. Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information.	O	O	Reply	10083
IEEE Transactions on information theory, 2006, 52(2): 489-509.	O	O	Reply	10083
<sep> <sep> 2.	B-Reply	B-2	Reply	10083
Thanks for your suggestion on the naming of the ‚ÄúTransformer‚Äù.	I-Reply	I-2	Reply	10083
We are also considering renaming it possibly into ‚Äútransforming model‚Äù.	I-Reply	I-2	Reply	10083
But to keep the naming consistent throughout the discussion period, we will keep the original name for now.	I-Reply	I-2	Reply	10083
<sep> <sep> Thank you for your review again!	O	O	Reply	10083
Any further questions or suggestions are welcome.	O	O	Reply	10083

The paper suggests to use temperature scaling in adversarial attack design for improving transferability under black-box attack setting.	O	O	Review	20556
Based on this, the paper proposes several new attacks: D-FGSM, D-MIFGSM, and their ensemble versions.	O	O	Review	20556
Experimental results found that the proposed methods improves transferability from VGG networks, compared to the non-distillated counterparts.	O	O	Review	20556
<sep> <sep> In overall, I liked its novel motivation and simplicity of the method, but it seems to me the manuscript should be improved to meet the ICLR standard.	B-Review	B-1	Review	20556
Firstly, the presentation of the method is not that clear to me.	I-Review	I-1	Review	20556
The mathematical notations are quite confusing for me as most of them are used without any definitions.	I-Review	I-1	Review	20556
I am still not convinced that the arguments in Section 3.1 and 3.2 are indeed relevant to the actual practice of black-box adversarial attacks, which usually includes extremely non-smooth boundaries with multiple gradient steps.	I-Review	I-1	Review	20556
Even though the experiments show effectiveness partially on VGGNets, but the overall improvements are not sufficient for me to claim the general effectiveness of the method unless the paper could provide additional results on broader range of architectures and  threat models.	I-Review	I-1	Review	20556
<sep> <sep> - I feel Section 2.3 is too subjective with vague statements.	B-Review	B-2	Review	20556
The following statement was particularly unclear to me: "The first problem with gradient based methods is that they lose their effectiveness after a certain number of iterations.":	I-Review	I-2	Review	20556
Does the term "effectiveness" indicate some relative effectiveness compared to other methods, e.g. optimization-based attacks?	I-Review	I-2	Review	20556
Is this really a general phenomenon in gradient-based attacks?	I-Review	I-2	Review	20556
Also, please elaborate more on "So, insufficient information acquisition for different categories and premature stop of gradient update are the reasons ..."	I-Review	I-2	Review	20556
<sep> - Regarding that the softmax is the problem, one could try to directly minimize the logit layers skipping the softmax, i.e., gradient on logits?	B-Review	B-3	Review	20556
This is actually one of common techniques and there are many simple tricks in the context of adversarial attack, so the paper may include comparisons with such of tricks as well.	I-Review	I-3	Review	20556
<sep> <sep> - It is important to specify the exact threat model used throughout the experiments, e.g. perturbation constraints and attack details.	B-Review	B-4	Review	20556
Demonstrating the effectiveness on a variety of threat models could also strengthen the manuscript.	I-Review	I-4	Review	20556
<sep> <sep> - Table 1 and 2 may include other baseline (black-box attack) methods for comparison.	B-Review	B-5	Review	20556
This would much help to understand the method better.	I-Review	I-5	Review	20556
Thanks a lot.	O	O	Reply	20556
We think you did read our manuscript very carefully.	O	O	Reply	20556
Here are our responses to your major concerns.	O	O	Reply	20556
<sep> Q: The first problem with gradient based methods is that they lose their effectiveness after a certain number of iterations.":	O	O	Reply	20556
Does the term "effectiveness" indicate some relative effectiveness compared to other methods, e.g.	O	O	Reply	20556
A: In fact, ‚Äúeffectiveness‚Äù is compared with any non-distilled version of the gradient-based method.	B-Reply	B-2	Reply	20556
In our experiment, we found that our method could make the gradient-based method iterate more times and bring about improvement, which is really a pity that we did not put this part of the experimental results in our manuscript.	I-Reply	I-2	Reply	20556
<sep> <sep> Q:It is important to specify the exact threat model used throughout the experiments, e.g. perturbation constraints and attack details.	O	O	Reply	20556
Demonstrating the effectiveness on a variety of threat models could also strengthen the manuscript.	O	O	Reply	20556
<sep> A: In Section 5.7, we have written the experimental Settings such as noise level, temperature, etc.	B-Reply	B-4	Reply	20556
However, we did ignore the very important setting instructions in some places.	I-Reply	I-4	Reply	20556
In fact, in the experiments we compared with other methods, the noise was 32 and the temperature was about 16.	I-Reply	I-4	Reply	20556
<sep> Thank you very much for your pertinent suggestions!	O	O	Reply	20556

This paper proposes distillation attacks to generate transferable targeted adversarial examples.	O	O	Review	20556
The technique itself is pretty simple: instead of only using the raw logits L(x) to compute the cross entropy loss for optimization, they also use the distilled logits L(x)/T to generate adversarial examples.	O	O	Review	20556
Their evaluation setup largely follows the style of Liu et al but they construct a different subset of ILSVRC validation set, and some of the model architectures in their ensemble are different from Liu et al Their results show that by including the distilled logits when computing the gradient, the generated adversarial examples can transfer better among different models using both single-model and ensemble-based attacks.	O	O	Review	20556
<sep> <sep> I think their proposed attack is interesting due to its simplicity and effectiveness.	O	O	Review	20556
However, I would like to see clarification of some evaluation details, as well as more experiments to compare with Liu et al:	O	O	Review	20556
<sep> 1.	O	O	Review	20556
To assess the effectiveness of targeted attacks, it is important to ensure that the semantic meaning of target label is far from the ground truth label.	B-Review	B-1	Review	20556
Some of the 1000 ImageNet labels have very similar meanings to each other, thus different choices of the target label would dramatically affect the difficulty of the attacks.	I-Review	I-1	Review	20556
In Liu et al they manually inspect the image-target pairs to ensure that the target label is very different from the ground truth in its meaning.	I-Review	I-1	Review	20556
To enable a fair comparison, it would be helpful to provide results on the same image-target pairs constructed by Liu et al which could be found in the public repo linked in their paper.	I-Review	I-1	Review	20556
<sep> <sep> 2.	O	O	Review	20556
For ensemble attacks, is including both the raw and the distilled logits crucial in obtaining a good performance?	B-Review	B-2	Review	20556
What is the performance of including distilled logits only?	I-Review	I-2	Review	20556
How do different values of \lambda_1 and \lambda_2 in (8) affect the attack performance?	I-Review	I-2	Review	20556
<sep> <sep> 3.	B-Review	B-3	Review	20556
Could you visualize some generated adversarial examples, so that we can view the qualitative results?	I-Review	I-3	Review	20556
<sep> <sep> 4.	B-Review	B-4	Review	20556
In general this paper lacks empirical analysis on why distillation helps improve the transferability.	I-Review	I-4	Review	20556
Some more discussion would be helpful.	I-Review	I-4	Review	20556
<sep> <sep> -------------	O	O	Review	20556
Post-rebuttal comments	O	O	Review	20556
<sep> Thanks for your response!	B-Review	B-5	Review	20556
I think this paper still misses a more in-depth analysis, and thus I keep my original assessment.	I-Review	I-5	Review	20556
<sep> -------------	O	O	Review	20556
Q: The target labels should be far from the true labels.	O	O	Reply	20556
<sep> A: Thanks!	B-Reply	B-1	Reply	20556
It's really a great suggestion.	I-Reply	I-1	Reply	20556
In our experiments, we all randomly generate the true labels.	I-Reply	I-1	Reply	20556
Statistically speaking, the probability of a similar labels is very small.	I-Reply	I-1	Reply	20556
Although this effect cannot be completely ruled out, the results should be credible.	I-Reply	I-1	Reply	20556
We also manually check our experimental data to ensure that the impact of such problems is minimized.	I-Reply	I-1	Reply	20556
<sep> <sep> Q: Is including both the raw and the distilled logits crucial in obtaining a good performance?	O	O	Reply	20556
What is the performance of including distilled logits only?	O	O	Reply	20556
How do \lambda_1 and \lambda_2 in (8) affect the attack performance?	O	O	Reply	20556
<sep> A: Another great question!	B-Reply	B-2	Reply	20556
In our experiments, only include the distilled logits to generate the cross entropy is not a good idea.	I-Reply	I-2	Reply	20556
Since the distillation makes the distance of true labels and target labels, and it makes the attack will stop when the attack distance is enough to the new distance, but not enough to the origin distance.	I-Reply	I-2	Reply	20556
The lack of attack distance also cause the lower transferability.	I-Reply	I-2	Reply	20556
So we include both the raw and the distilled logits to generate the cross entropy, to make up the attack distance.	I-Reply	I-2	Reply	20556
<sep> Actually, the different value of \lambda_1 and \lambda_2 in (8) do affect, but the affect is not as significant as we expected, and we are looking for the reason.	I-Reply	I-2	Reply	20556

This paper proposes an attack method to improve the transferability of targeted adversarial examples.	O	O	Review	20556
The proposed method uses a temperature T to convert the logit of the network, and calculates the gradient based on the new logit, yielding the distillation-based attack method.	O	O	Review	20556
It has been integrated into FGSM and MI-FGSM.	O	O	Review	20556
<sep> <sep> Overall, this paper has the poor quality based on the writing, presentation, significance of the algorithm, insufficient experiments.	O	O	Review	20556
The detailed comments are provided below.	O	O	Review	20556
<sep> <sep> 1.	O	O	Review	20556
The writing of this paper is poor.	B-Review	B-1	Review	20556
There are a lot of typos in the paper.	I-Review	I-1	Review	20556
The notations are used without definitions.	I-Review	I-1	Review	20556
These make the paper hard to read and understand.	I-Review	I-1	Review	20556
<sep> <sep> 2.	B-Review	B-2	Review	20556
Based on my understanding of the paper, the motivation of the proposed method is that the softmax function on top of neural networks can make the gradient unable to accurately penetrate classification boundaries.	I-Review	I-2	Review	20556
And the distillation-based method is proposed to reduce the magnitude of the logits to make the gradient more stable.	I-Review	I-2	Review	20556
However, if the argument were true, we could use the C&amp;W loss to perform the attack, which is defined on the logit layer without affected by the softmax function.	I-Review	I-2	Review	20556
<sep> <sep> 3.	O	O	Review	20556
There are a lot of recent attack methods proposed to improve the transferability of adversarial example, e.g., "Improving transferability of adversarial examples with input diversity" (Xie et al 2019); "Evading defenses to transferable adversarial example by translation-invariant attacks" (Dong et al 2019).	B-Review	B-3	Review	20556
The authors are encouraged to compare the proposed methods with previous works.	I-Review	I-3	Review	20556
Q: It seems the softmax layer can be avoided, like CW attack.	O	O	Reply	20556
<sep> A: Thank you for this suggestion.	B-Reply	B-2	Reply	20556
Compare to gradient-based method, CW can get better attack success rate, but it takes too much time to attack, and the L-2 distance and L-inf distance is far bigger.	I-Reply	I-2	Reply	20556
What we do is to increase the transferability of adversarial examples without the increase of attack time and distance, so CW is not a good choice to our work.	I-Reply	I-2	Reply	20556
<sep> <sep> Q: There are a lot of recent attack methods proposed to improve the transferability of adversarial example, like (Xie et al 2019) and (Dong et al 2019).	O	O	Reply	20556
<sep> A: There are some works on the improvement of the transferability of adversarial examples before, but these works focus on the untargeted attack.	B-Reply	B-3	Reply	20556
In fact, the transferability in the targeted attack, especially gradient-base attack, is known as impossible before.	I-Reply	I-3	Reply	20556
What we do is the breakthrough of the transferability of targeted attack.	I-Reply	I-3	Reply	20556

This paper presents a paradigm for generating saliency maps for video models, specifically, I3D (3D CNN) and C-LSTM.	O	O	Review	614
It extends Fong &amp; Vedaldi, 2017 to generate a temporal mask and introduces two types of "meaningful perturbations" for videos: freezing and reversing frames; they use Grad-CAM (with no modifications) for generating spatial masks.	O	O	Review	614
The problem is well-motivated, as saliency maps have been extensively studied for image classification models, but rarely for video classification.	O	O	Review	614
Quantitatively, they demonstrate that frame-reversal is meaningful for the Something-something dataset but less for KTH because those actions rely more on spatial information than temporal (i.e., running, clapping).	O	O	Review	614
Qualitatively, they show their spatial and temporal masks on both datasets and suggest the a few insights:	O	O	Review	614
* I3D's Grad-CAM visualizations show a center, default bias * I3D is less sensitive to the reverse perturbation * I3D temporal masks are typically shorter.	O	O	Review	614
<sep> <sep> I currently rate this paper as a weak reject (though closer to borderline) paper for the following reasons (all of which can be improved in rebuttal):	O	O	Review	614
1.	O	O	Review	614
Quality of technique	O	O	Review	614
While the temporal masks are novel and qualitatively "make sense" (though this is subjective), the generation of the spatial masks is not novel, is unconnected to the temporal mask generation, and often doesn't make sense because of lack of temporal smoothness / cohesion, particularly for C-LSTM, where the visualizations when the mask is on appear quite "jumpy" (see Fig 2, Seq 1).	B-Review	B-4	Review	614
It would be great to see more innovation on the temporal mask generation to address some of these issues (one natural approach that comes to mind would be learn spatial masks as done in Fong &amp; Vedaldi, 2017, possibly with a temporal smoothness term between spatial masks and possibly combining temporal + spatial masks for freezing operation, i.e., only freeze spatial pixels) -- that said, I realize that this may be out of scope for a rebuttal.	I-Review	I-4	Review	614
<sep> <sep> 2.	O	O	Review	614
Lack of support for qualitative claims	O	O	Review	614
The paper makes 3 claims based on qualitative examples shown (see above bullets in summary); these claims could be easily substantiated qualitatively (by evaluating over the dataset or a subset of it).	B-Review	B-3	Review	614
<sep> <sep> 3.	O	O	Review	614
Lack of discussion on limitations/benefits of technique + how to use/interpret technique	O	O	Review	614
* There are no baseline comparisons for the proposed temporal mask generation.	B-Review	B-1	Review	614
natural ones would be visualizing saliency methods (i.e., gradient, SmoothGrad, occlusion [Zeiler &amp; Fergus, 2014], RISE [BMVC 2018], for instance, as examples of a few easy-to-implement, representative methods for backprop and perturbation methods) w.r.t.to temporal dimensions and then thresholding and applying those baseline temporal masks and demonstrating that the proposed temporal mask generation is.	I-Review	I-1	Review	614
<sep> * There's no discussion (or experiments) on the benefits &amp; limitations of their approach; this is important as we've seen from papers like Mahendran &amp; Vedaldi, ECCV 2016, Adebayo et al NeurIPS 2018 and Kindermans et al arXiv 2017 that some saliency methods fail to meet basic desirata (i.e., specificity to output class and model weights, etc.).	B-Review	B-2	Review	614
Ideally, the authors would show that their temporal mask generation meets some desired criteria (as well as compare with baseline methods) to justify their approach.	I-Review	I-2	Review	614
<sep> * One limitation of Fong &amp; Vedaldi 2017 is the difficulty of finding global optimum for the different hyper-parameter terms (Fong et al, ICCV 2019 addresses this, which might be of interest to the authors).	B-Review	B-5	Review	614
There's no discussion about whether this problem persists for this work.	I-Review	I-5	Review	614
Also -- it'd be interesting to see whether the reverse loss function (i.e., maximizing class score) yields similar results.	I-Review	I-5	Review	614
<sep> * More discussion can be added about how to interpret results / use the technique (i.e., what is this technique useful/not useful for?	B-Review	B-6	Review	614
what do results mean?).	I-Review	I-6	Review	614
For instance, the claim that I3D temporal mask is shorter suggests a complex phenomenon -- that the necessary temporal evidence is smaller.	I-Review	I-6	Review	614
This is a bit surprising to me, as I3D performs better overall, so I would have expected it to encode more redundancy (this can be checked by exploring the classes in which I3D does perform better) -- however, this interpretation differs from that of the authors ("This is especially visible in the temporal mask of Sequence #3, where it is active specifically").	I-Review	I-6	Review	614
<sep> <sep> In addition to responding to the above with relevant text + preliminary experimental results, I also had the following questions/asks:	B-Review	B-7	Review	614
* For misclassified classes in Fig 2, are you optimizing w.r.t.the top predicted class or the ground truth class?	I-Review	I-7	Review	614
Do they differ substantially when optimizing for different output classes?	I-Review	I-7	Review	614
<sep> * What were the lambda hyperparameters from Eq.1 (and how were they chosen)?	I-Review	I-7	Review	614
Are these relatively stable or are their instances of technique failure due to the difficulty in balancing these terms?	I-Review	I-7	Review	614
<sep> * Show Table 1 on only the classes that were focused on (i.e., the ones w comparable performance between the two models); I'm wondering if the impact of reversal on I3D is less than that on C-LSTM, as claimed by the authors (it's hard to tell when their baseline performance is different)	I-Review	I-7	Review	614
<sep> Dear reviewer,	O	O	Reply	614
<sep> We are thankful for your very thorough and constructive review.	O	O	Reply	614
We have updated the article including support of the three qualitative claims that you have listed in bullet points (point #2 in your list).	B-Reply	B-3	Reply	614
These numbers can be found in the new Table 2 in the article, confirming the difference between the two models.	I-Reply	I-3	Reply	614
The discussion has also been improved with references to this analysis.	I-Reply	I-3	Reply	614
<sep> <sep> We evaluated the three claims on a subset of the Something-something validation set; we ran the temporal mask optimization and Grad-CAM analysis for 791 samples (150 samples for each of the seven classes presented in that section, fewer when there were less than 150 samples present in the validation set).	I-Reply	I-3	Reply	614
The masks take a few minutes per clip to optimize on one GPU meaning that for the scope of this rebuttal we were limited to this subset.	I-Reply	I-3	Reply	614
For a final version of the article we would like to run this for all eleven classes under consideration and for more than 150 samples per class when available.	I-Reply	I-3	Reply	614
<sep> <sep> As for your first point, we agree that this is a good idea that we will keep in mind for future work.	B-Reply	B-4	Reply	614
Unfortunately, as you point out, it was out of the scope for the rebuttal time window.	I-Reply	I-4	Reply	614
<sep> <sep> Coming to your third point, we first of all agree that especially the work by Adebayo et al (NeurIPS 2018) is highly relevant for our article and are we are again thankful for this suggestion.	B-Reply	B-2	Reply	614
We have now included it in the related work section, pointing out that Grad-CAM is one of the saliency methods that ‚Äòpassed‚Äô in the experiments conducted by Adebayo et al.	I-Reply	I-2	Reply	614
We furthermore would like to stress that it cannot be the foregrounds of the images themselves that are the cause of the saliency maps (as it is for certain revealed-to-be edge detecting methods by Adebayo et al), since we observe a significant difference between the saliency maps of the C-LSTM and those of the I3D (both computed with Grad-CAM) (Table 2).	I-Reply	I-2	Reply	614
Concerning the sanity of the temporal mask method, we also observe a significant difference between the masks generated from the two different models.	I-Reply	I-2	Reply	614
Although the latter is not an exhaustive check, this tells us that the temporal masks are not independent of the model, as was the case for several of the less sane methods listed in Adebayo et al (whose results were unchanged when the weights of a network were random).	I-Reply	I-2	Reply	614
<sep> <sep> Continuing on the third point, the suggestion of running baseline comparisons with temporal masks created from spatial saliency methods is a very constructive idea and something that would be interesting in order to motivate the separate optimization of our temporal mask.	B-Reply	B-1	Reply	614
At the same time, extending the existing saliency methods to the temporal dimension by thresholding would be difficult, since the threshold would be difficult to choose.	I-Reply	I-1	Reply	614
For instance, if we would base it on the magnitude of the saliency maps per frame, this would ultimately not work for clips with very small relevant spatial patches, and the threshold would be difficult to set.	I-Reply	I-1	Reply	614
Thus, this is something we would want to think more about and instead suggest for future work.	I-Reply	I-1	Reply	614
<sep> <sep> (This reply will continue in part 2, see below.)	O	O	Reply	614

This work attempts to experimentally investigate the difference between Conv3Ds and ConvLSTMs with the aid of visualization.	O	O	Review	614
The visualization focuses on two aspects: (1) Temporal masking for identifying key frames and key segments and (2) GradCAM for spatial saliency.	O	O	Review	614
Both visualization techniques are illustrated on two public available video classification datasets.	O	O	Review	614
<sep> <sep> This work has some major issues:	O	O	Review	614
1.	B-Review	B-1	Review	614
The quantitative results are not very relevant.	I-Review	I-1	Review	614
It does not validate any of the following cases: (1) if Conv3Ds are more powerful, one should use the same number of parameters and compare classification results, or (2), in order to achieve the same level of accuracy, one of the two models is more parameter efficient.	I-Review	I-1	Review	614
It is not clear which argument Table 1 is validating against if there is any as both parameters and accuracies vary.	I-Review	I-1	Review	614
<sep> 2.	O	O	Review	614
Qualitative results from Section 5.2 is not substantiated and underwhelming.	B-Review	B-2	Review	614
For instance, it is hard to see why "Conv3Ds has a bias around the center while ConvLSTMs find relevant spatial features in multiple smaller areas".	I-Review	I-2	Review	614
This is most likely due to visualization techniques other than the choice of models.	I-Review	I-2	Review	614
<sep> 3.	B-Review	B-3	Review	614
The fundamental issue of this work is that it does not establish a hypothesis from the beginning and design experiments around it.	I-Review	I-3	Review	614
Plenty of hand-wavy observations are made without further investigating the root of them, leaving readers unsatisfied, and quite often confused.	I-Review	I-3	Review	614
Dear reviewer,	O	O	Reply	614
<sep> Thank you for your valuable feedback.	O	O	Reply	614
Below, we will address each of your raised issues:	O	O	Reply	614
<sep> 1.	O	O	Reply	614
Regarding the fairness of the comparison, it is written at the end of section 4.2:	B-Reply	B-1	Reply	614
<tab>‚Äú(...) Also, due to the computational complexity of backpropagation through time (BPTT), the C-LSTM variants were significantly more time demanding to train and evaluate than their I3D counterparts.	I-Reply	I-1	Reply	614
With this in mind, in order to make the comparison as fair as possible, eleven classes were chosen for which the performance of the two architectures were similar.	I-Reply	I-1	Reply	614
‚Äù	I-Reply	I-1	Reply	614
And in Section 5.2:	I-Reply	I-1	Reply	614
<tab>‚ÄúThe chosen classes were as follows (I3D F1/C-LSTM F1): moving something and something away from each other (0.76/0.58), moving something and something closer to each other (0.77/0.57), moving something and something so they pass each other (0.37/0.31), moving something up (0.43/0.4), pretending to take something from somewhere (0.1/0.07), moving the camera down while filming something (0.67/0.56), and moving the camera up while filming something (0.81/0.73).‚Äù	I-Reply	I-1	Reply	614
We agree with you that this situation is not ideal since I3D has a slight overhand on the C-LSTM for each class.	I-Reply	I-1	Reply	614
Even so, we decided to pursue this track for three reasons:	I-Reply	I-1	Reply	614
<sep> i. We think that the difference in accuracy per class for the two models is within an acceptable range and judge that they should be at least comparable.	I-Reply	I-1	Reply	614
<sep> <sep> ii.	I-Reply	I-1	Reply	614
3D CNNs clearly represent the current state-of-the-art for action recognition.	I-Reply	I-1	Reply	614
Because of this, it is interesting to study what such a model ‚Äî better performing in terms of accuracy ‚Äî  finds, compared to a weaker one (in terms of accuracy), since this reflects a typical real-world situation (where the 3D CNN typically would be the model with highest accuracy).	I-Reply	I-1	Reply	614
Furthermore, there is an argument to be made concerning how ‚Äògood‚Äô it is to score a high accuracy on a quite artificial dataset such as Something-something.	I-Reply	I-1	Reply	614
See also a slightly longer discussion of this point at the end of our response to Official Blind Review #5 (paragraph starting with ‚ÄúIn the reviewer‚Äôs fourth point,...‚Äù).	I-Reply	I-1	Reply	614
<sep> <sep> iii.	I-Reply	I-1	Reply	614
As you correctly point out, the other alternative would be to compare two models on the basis of having the same number of parameters.	I-Reply	I-1	Reply	614
However, this is simply not feasible for the two concerned types of models (C-LSTM and 3D CNN).	I-Reply	I-1	Reply	614
I3D has 12 times as many parameters as the C-LSTM, yet the C-LSTM takes roughly 1.5 times longer to train for one epoch (2.2h vs. 1.5h on Something-something).	I-Reply	I-1	Reply	614
To train a C-LSTM with the same number of parameters as the I3D would simply take a nonviable amount of time.	I-Reply	I-1	Reply	614
It can be noted that the C-LSTM used for these experiments on Something-something was trained for 229 hours (105 epochs) on an Nvidia RTX 2080 TI .	I-Reply	I-1	Reply	614
<sep> <sep> <sep> 2.	O	O	Reply	614
We are not quite sure what is meant by ‚ÄòThis is likely due to visualization techniques other than the choice of models‚Äô since the exact same visualization technique is applied to the two models.	B-Reply	B-2	Reply	614
In what concerns the first comment about our qualitative results being unsubstantiated, we have included more extensive quantitative results in Table 2 of the updated article,  including a global measure of the number of ‚Äòblobs‚Äô (contiguous regions present per frame in the Grad-CAM saliency maps), their average size and distance from the center of the image, average mask length and average difference and ratio for the drop in classification score after freeze and reverse perturbations, respectively.	I-Reply	I-2	Reply	614
This analysis was done across a subset of the validation data for each model (see the first two paragraphs in our response to Official Blind Review #5).	I-Reply	I-2	Reply	614
The results are in line with our findings concerning the center preference of the focus of I3D compared to the C-LSTM.	I-Reply	I-2	Reply	614
<sep> <sep> 3.	O	O	Reply	614
Deliberately, we did not want to establish a hypothesis from the beginning, in order to investigate this question in an unbiased manner.	B-Reply	B-3	Reply	614
When it comes to investigating the root of some claims made in the discussion section of the original version of the article, we have now substantiated these claims in the new Table 2 of the updated article.	I-Reply	I-3	Reply	614
We have also improved the discussion using these results and hope that this altogether can help to diminish the reviewer‚Äôs confusion.	I-Reply	I-3	Reply	614
<sep> <sep> Please don‚Äôt hesitate to reply to this if you have further questions to us at this point.	O	O	Reply	614

The paper shows a way to compare what is learned by two very different networks trained for a video classification task.	O	O	Review	614
The two architectures are state-of-the-art methods, one relying on 3d-CNNs (time= one dimension), the other on conv-LSTMs (time is treated sequentially, using hidden states to pass information).	O	O	Review	614
The idea of the authors is (i) to provide saliency maps for each of them, and (ii) to create interesting perturbations in order to measure the influence on the networks.	O	O	Review	614
The results indicate that these complex networks are usually focused on interesting features, and as we would imagine, LSTMs is more learning from temporal coherence than CNNs.	O	O	Review	614
<sep> <sep> Overall, I think the paper is worth to be published at ICLR, even if I am not aware of the recent publications in this field.	O	O	Review	614
The contribution in terms of method is small, but I think that such careful studies can be very fruitful to the community.	O	O	Review	614
<sep> <sep> Positive aspects:	O	O	Review	614
- A significant effort has been put to creating meaningful perturbations for this particular task, i.e. temporal dependance and coherence.	O	O	Review	614
<sep> - The effort to compare as best as possible two different approaches is fruitful, and very useful for the community as this is a real question to be raised.	O	O	Review	614
<sep> - The experiments are made also with care, on 2 different datasets, and large efforts were made on explaining the different results.	O	O	Review	614
<sep> <sep> Questions/remarks:	O	O	Review	614
- As I was under Linux, I did not manage to view the videos, and I have not seen a link for downloading them.	B-Review	B-1	Review	614
It would be best to add it as supplementary materials?	I-Review	I-1	Review	614
<sep> - What do you mean by 'The TV norm penalizes masks that are not coherent'?	B-Review	B-2	Review	614
what is coherent?	I-Review	I-2	Review	614
<sep> - '...the mask is defined as a vector of values between [0,1]' : I understood that it was a real value between 0 and 1, but I think you meant more 'a binary vector'?	B-Review	B-3	Review	614
<sep> - Have you looked at the importance of the sub-sampling in the CNN framework?	B-Review	B-4	Review	614
i.e., since the LSTM framework does not have that, maybe the differences in activation also depend on the length of the sequence.	I-Review	I-4	Review	614
Maybe the large sequences, where CNN and LSTM would have the same number of frames, are less different?	I-Review	I-4	Review	614
<sep> - You are saying that the code will be made public, is it possible to make it public now?	B-Review	B-5	Review	614
<sep> <sep> Small remarks:	B-Review	B-6	Review	614
- '3D CNNs instead instead convolve'	I-Review	I-6	Review	614
- 'As outlined in section 2' when we are in the introduction	I-Review	I-6	Review	614
- '(Mahdisoltani et al(2018) contains...'.	I-Review	I-6	Review	614
parenthesis.	I-Review	I-6	Review	614
<sep> - Figure 1: the first figure is in too poor quality.	I-Review	I-6	Review	614
<sep> <sep> Dear reviewer,	O	O	Reply	614
<sep> Thank you for your encouraging and insightful assessment!	O	O	Reply	614
In the following, we address the rest of your questions and remarks one by one.	O	O	Reply	614
<sep> <sep> - After the double-blind period, our plan is to make a website for the article displaying all the video material in the browser.	B-Reply	B-1	Reply	614
Until then, unfortunately one needs to use Adobe reader to be able to watch the videos.	I-Reply	I-1	Reply	614
We realize that this is not the most practical solution; however, Adobe should be available for Linux.	I-Reply	I-1	Reply	614
<sep> <sep> - The word ‚Äòcoherent‚Äô has been replaced by the more precise word ‚Äòcontiguous‚Äô in the updated version of the article.	B-Reply	B-2	Reply	614
<sep> <sep> - The code was anonymously made public on OpenReview at the same time that we submitted, see the Dropbox link along with our submission.	B-Reply	B-3	Reply	614
After the double-blind period, we will release a public repository in our names.	I-Reply	I-3	Reply	614
<sep> <sep> - Regarding the vector of values in [0,1], we do in effect mean that the vector can take any real values in the [0,1] interval.	B-Reply	B-4	Reply	614
The reason for is that the mask needs to be differentiable.	I-Reply	I-4	Reply	614
This is explained at the end of Section 3.1, but we have clarified this point throughout Sect.	I-Reply	I-4	Reply	614
3.1 in the updated version of the article and we would like to thank you for pointing to this confusion.	I-Reply	I-4	Reply	614
<sep> <sep> - We also want to thank the reviewer for the valuable comment regarding the sub-sampling of CNN models.	B-Reply	B-5	Reply	614
I3D does indeed subsample the sequence temporally along its forward pass, going from 16 time steps to 8 time steps in the output.	I-Reply	I-5	Reply	614
It would be interesting to include results from a model with no temporal subsampling and study the characters of its temporal masks.	I-Reply	I-5	Reply	614
This was unfortunately out of scope for this rebuttal period but will keep this in mind for future work.	I-Reply	I-5	Reply	614
<sep> <sep> Last, we have corrected the remaining four remarks at the end of your review in the updated version of the article, and we thank the reviewer for spotting these mistakes.	B-Reply	B-6	Reply	614

This paper shows how RNNs can be used to decode convolutional error correcting codes.	O	O	Review	389
While previous recent work has shown neural decoders for block codes results had limited success and for small block lengths.	O	O	Review	389
<sep> This paper shows that RNNs are very suitable for convolutional codes and achieves state of the art performance for the first time.	O	O	Review	389
<sep> The second contribution is on adaptivity outside the AWGN noise model.	O	O	Review	389
The authors show that their decoder performs well for different noise statistics outside what it was trained on.	O	O	Review	389
This is very interesting and encouraging.	O	O	Review	389
It was not very clear to me if the baseline decoders (Turbo/BCJR) are fairly compared here since better decoders may be used for the different statistics, or some adaptivity could be used in standard decoders in various natural ways.	B-Review	B-3	Review	389
<sep> <sep> The last part goes further in designing new error correcting schemes using RNN encoders and decoders for noisy feedback communication.	O	O	Review	389
<sep> For this case capacity is known to be impossible to improve, but the bit error error can be improved for finite lenghts.	O	O	Review	389
<sep> It seems quite remarkable that they beat Schalkwijk and Kailath and shows great promise for other communication problems.	O	O	Review	389
<sep> <sep> The paper is very well written with good historical context and great empirical results.	O	O	Review	389
I think it opens a new area for information theory and communications with new tools.	O	O	Review	389
<sep> <sep> My only concern is that perhaps the neural decoders can be attacked with adversarial noise (which would not be possible for good-old Viterbi ).	B-Review	B-1	Review	389
It would be interesting to discuss this briefly.	I-Review	I-1	Review	389
<sep> A second (related) concern is the lack of theoretical understanding of these new decoders.	B-Review	B-2	Review	389
It would be nice if we could prove something about them, but of course this will probably be challenging.	I-Review	I-2	Review	389
<sep> <sep> <sep> Thank you for your comments.	O	O	Reply	389
<sep> <sep> 1.	O	O	Reply	389
Neural decoders can be attacked with adversarial noise:	O	O	Reply	389
This is a great point, which is related to the current ongoing advances in other areas of neural networks (e.g. classification).	B-Reply	B-1	Reply	389
At a high level, there are two types of adversarial noise that can hurt our approach.	I-Reply	I-1	Reply	389
The first one is poisoning training data.	I-Reply	I-1	Reply	389
If we are training on data collected from real channels, an adversary who knows that we are training can intervene and add adversarial noise to make our trained decoder useless.	I-Reply	I-1	Reply	389
This proposes an interesting game between the designer (us) and the attacker, in the form of how much noise power does the adversary need in order to make our decoder fail.	I-Reply	I-1	Reply	389
This we believe is a fascinating research question, and we will add discussions in the final version of our manuscript.	I-Reply	I-1	Reply	389
<sep> The second type of attack is adversarial examples, where at the test time an adversary changes the channel to make our decoder fail.	I-Reply	I-1	Reply	389
In this scenario, both Viterbi and our decoder are vulnerable.	I-Reply	I-1	Reply	389
Our numerical experiments on robustness is inspired by such scenarios, where we show that neural network decoders are more robust against such attacks (or natural dynamic changes) in Section 3.	I-Reply	I-1	Reply	389
<sep> <sep> 2.	O	O	Reply	389
Fair comparison to baseline decoders:	O	O	Reply	389
There are two ways to run fair experiments on other channels, in our opinion.	B-Reply	B-3	Reply	389
One is to mimic dynamic environment of real world by using encoder-decoders that are tailored for AWGN (both Turbo/BCJR and Neural Network decoder trained on AWGN) and see how robust it is against changes in the channel.	I-Reply	I-3	Reply	389
This is the experiments we run with T-distribution.	I-Reply	I-3	Reply	389
Another is, as suggested by the reviewer, to design decoders based on the new statistics of the channel that work well outside of AWGN.	I-Reply	I-3	Reply	389
This is the experiments we run with bursty channels.	I-Reply	I-3	Reply	389
We agree that these two experiments are addressing two different questions, but we believe we are fair in the comparisons to competing decoders within each setting.	I-Reply	I-3	Reply	389
<sep> <sep> 3.	B-Reply	B-2	Reply	389
Theoretical understanding of these neural decoders/coding schemes is a challenging but very interesting future research direction.	I-Reply	I-2	Reply	389

Error-correcting codes constitute a well-researched area of study within communication engineering.	O	O	Review	389
In communication, messages that are to be transmitted are encoded into binary vector called codewords that contained some redundancy.	O	O	Review	389
The codewords are then transmitted over a channel that has some random noise.	O	O	Review	389
At the receiving end the noisy codewords are then decoded to recover the messages.	O	O	Review	389
Many well known families of codes exist, notably convolutional codes and Turbo codes, two code families that are central to this paper, that achieve the near optimal possible performance with efficient algorithms.	O	O	Review	389
For Turbo and convolutional codes the efficient MAP decodings are known as Viterbi decoder and the BCJR decoder.	O	O	Review	389
For drawing baselines, it is assumed that the random noise in channel is additive Gaussian (AWGN).	O	O	Review	389
<sep> <sep> This paper makes two contributions.	O	O	Review	389
First, recurrent neural networks (RNN) are proposed to replace the Viterbi and BCJR algorithms for decoding of convolutional and Turbo decoders.	O	O	Review	389
These decoders are robust to changes in noise model and blocklength - and shows near optimal performance.	O	O	Review	389
<sep> <sep> It is unclear to me what is the advantage of using RNNs instead of Viterbi or BCJR, both of which are optimal, iterative and runs in linear time.	B-Review	B-1	Review	389
Moreover the authors point out that RNNs are shown to emulate BCJR and Viterbi decodings in prior works - in light of that, why their good performance surprising?	I-Review	I-1	Review	389
<sep> <sep> The second contribution of the paper constitutes the design and decoding of codes based on RNNs for a Gaussian channel with noisy feedback.	O	O	Review	389
For this channel the optimal codes are unknown.	O	O	Review	389
The authors propose an architecture to design codes for this channel.	O	O	Review	389
This is a nice step.	O	O	Review	389
However, in the performance plot (figure 8), the RNN based code-decoder does not seem to be outperforming the existing codes except for two points.	B-Review	B-2	Review	389
For both in high and low SNR the performance is suboptimal to  Turbo codes and a code by Schalkwijk & Kailath.	I-Review	I-2	Review	389
The section is also super-concise to follow.	I-Review	I-2	Review	389
I think it was necessary to introduce an LSTM encoder - it was hard to understand the overall encoder.	B-Review	B-4	Review	389
This is an issue with the paper - the authors previously mentioned (8,16) polar code without mentioning what the numbers mean.	I-Review	I-4	Review	389
<sep> <sep> However, I overall liked the idea of using neural nets to design codes for some non-standard channels.	O	O	Review	389
While at the decoding end it does not bring in anything new (modern coding theory already relies on iterative decoders, that are super fast), at the designing-end the Gaussian feedback channel part can be a new direction.	B-Review	B-2	Review	389
This paper lacks theoretical aspect, as to no indication is given why RNN based design/decoders can be good.	B-Review	B-1	Review	389
I am mostly satisfied with the experiments, barring Fig 8, which does not show the results that the authors claim.	B-Review	B-3	Review	389
<sep> <sep> Thank you for your comments.	O	O	Reply	389
<sep> <sep> 1.	O	O	Reply	389
Representability, Learnability and Generalization:	O	O	Reply	389
There are three aspects to showing that a learning problem can be solved through a parametric architecture.	O	O	Reply	389
<sep> <sep> (1) Representability: The ability to represent the needed function through a neural network.	B-Reply	B-2	Reply	389
For Viterbi/BCJR algorithms, this representability was shown in prior work by handcrafting parameters that represent the Viterbi/BCJR algorithms.	I-Reply	I-2	Reply	389
We note that neural networks with sufficient number of parameters can indeed represent any function through the universal approximation theorem for feedforward networks and RNNs (Cybenko,G.1989, Siegelmann,H.T.&Sontag,E.D.1995) and therefore this result is not that surprising.	I-Reply	I-2	Reply	389
<sep> <sep> (2) Learnability: Can the required function be learnt directly through gradient descent on the observed data?	B-Reply	B-2	Reply	389
For Viterbi and BCJR, learnability was neither known through prior work nor is it obvious.	I-Reply	I-2	Reply	389
One of the main contributions of our work is that those algorithms can be learnt from observed data.	I-Reply	I-2	Reply	389
<sep> <sep> (3) Generalization: Does the learnt function/algorithm generalize to unobserved data?	B-Reply	B-2	Reply	389
We show this not only at the level of new unobserved codewords, but also show that the learnt algorithm trained on shorter blocks of length 100 can generalize well to longer blocks of length up to 10,000.	I-Reply	I-2	Reply	389
Such generalization is rare in many realistic problems.	I-Reply	I-2	Reply	389
<sep> <sep> To summarize, out of the three aspects, only representability was known from prior work (and, we agree with the reviewer, that it is the least surprising given universal representability).	B-Reply	B-2	Reply	389
Learnability and generalization of the learnt Viterbi and BCJR algorithms to much larger block lengths are both unknown from prior art and they are surprising, and interesting in their own right.	I-Reply	I-2	Reply	389
We note that Viterbi and BCJR algorithms are useful in machine learning beyond communications problem, representing dynamic programming and forward-backward algorithms, respectively.	I-Reply	I-2	Reply	389
<sep> <sep> Peter Elias introduced convolutional codes in 1955 but efficient decoding through dynamic programming (Viterbi decoding) was only available in 1967 requiring mathematical innovation.	B-Reply	B-2	Reply	389
We note that ability to learn the Viterbi algorithm from short block length data (which can be generated by full-search) and generalizing them to much longer blocks implies an alternative methodology to solve the convolutional code problem.	I-Reply	I-2	Reply	389
Such an approach could have significant benefits in problems where corresponding mathematically optimal algorithms are not known at the moment.	I-Reply	I-2	Reply	389
<sep> <sep> We demonstrate the power of this approach by studying the problem of channel-with-feedback where no good coding schemes are known despite 70 years of research.	I-Reply	I-2	Reply	389
<sep> <sep> 2.	O	O	Reply	389
Advantages of using RNNs instead of Viterbi or BCJR:	O	O	Reply	389
There are two advantages to RNN decoders, that go beyond mimicing Viterbi/BCJR.	O	O	Reply	389
<sep> <sep> (1) Robustness: Viterbi and BCJR decoders are known to be vulnerable to changes in the channel, as those are highly tailored for the AWGN.	B-Reply	B-1	Reply	389
We show in Section 3, via numerical experiments with T-dsitributed noise, that the neural network decoder trained on AWGN is much more robust against the changes in the channel.	I-Reply	I-1	Reply	389
This makes, among other things, our neural network decoder much more attractive alternative to Viterbi/BCJR decoders in practice, where the channel model is not available.	I-Reply	I-1	Reply	389
<sep> <sep> (2) Adaptivity: It is not easy to extend the idea of Viterbi decoder and iterative Turbo decoding beyond the simple convolutional codes and the standard Gaussian channel (or any other Discrete Memoryless Channel).	B-Reply	B-1	Reply	389
On the other hand, our neural network decoder provides a new paradigm for decoding that can be applied to any encoder and any channel, as it learns from training examples.	I-Reply	I-1	Reply	389
To showcase the power of this ‚Äúadaptivity‚Äù, we show improved performance on the bursty channel.	I-Reply	I-1	Reply	389
<sep> <sep> A more stark example of the utility presents itself in the feedback channel.	B-Reply	B-1	Reply	389
There exists no known practical encoding-decoding scheme for a feedback channel.	I-Reply	I-1	Reply	389
Only because we have a neural network decoder that can adapt to any encoder, we are able to find a novel encoder (also neural network based) that uses the feedback information correctly and achieves the performance significantly better than any other competing schemes.	I-Reply	I-1	Reply	389
This would have not been possible without a neural network decoder and the techniques we learned in training one to mimic the simple Viterbi.	I-Reply	I-1	Reply	389
<sep> <sep> 3.	O	O	Reply	389
Updated curve for new codes on AWGN channel with feedback:	O	O	Reply	389
We have improved our encoder significantly by borrowing the idea of zero-padding from coding theory.	B-Reply	B-3	Reply	389
In short, most of the errors occurs in the last bit, whose feedback information was not utilized by our encoder.	I-Reply	I-3	Reply	389
We resolved this issue by padding a zero in the end of information bits (Hence, the codeword length is 3(K+1) for K information bits).	I-Reply	I-3	Reply	389
This significantly improves the performance as shown in the new Figure 8.	I-Reply	I-3	Reply	389
A full description of the encoder-decoder architecture is provided in Appendix D.	I-Reply	I-3	Reply	389
<sep> 4.	O	O	Reply	389
We replaced "(8,16) polar code" by ‚Äúrate 1/2 polar code over 8 information bits‚Äù.	B-Reply	B-4	Reply	389

In this paper the authors propose to use RNNs and LSTMs for channel coding.	O	O	Review	389
But I have the impression the authors completely miss the state of the art in channel coding and the results are completely useless for any current communication system.	O	O	Review	389
I believe that machine learning, in general, and deep learning, in particular, might be of useful for physical layer communications.	O	O	Review	389
I just do not see why it would be useful for channel coding over the AWGN channel.	O	O	Review	389
Let me explain.	O	O	Review	389
<sep> <sep> If the decoder knows that the encoder is using a convolutional code, why does it need to learn the decoder instead of using the Viterbi or BCJR algorithms that are known to be optimal for sequences and symbols, respectively.	B-Review	B-5	Review	389
I cannot imagine an scenario in which the decoder does not know the convolutional code that it is being used and the encoder sends 120,000 bits of training sequence (useless bits from information standpoint) for the decoder to learn it.	I-Review	I-5	Review	389
More important question, do the authors envision that this learning is done every time there is a new connection or it is learnt once and for all.	B-Review	B-6	Review	389
If it is learnt every time that would be ideal if we were discovering new channel codes everyday, clearly not the case.	I-Review	I-6	Review	389
If we learnt it one and for all and then we incorporated in the standard that would only make sense if the GRU structure was computationally better than the BCJR or Viterbi.	I-Review	I-6	Review	389
I would be surprise if it is.	I-Review	I-6	Review	389
If instead of using 2 or 3 memories, we used 6-8 does 120,000 bits be good enough or we need to exponentially increase the training sequence?	I-Review	I-6	Review	389
So the first result in the paper shows that a tailored structure for convolutional encoding can learn to decode it.	I-Review	I-6	Review	389
Basically, the authors are solving a problem that does not need solving.	I-Review	I-6	Review	389
<sep> <sep> For the Turbocodes the same principle as before applies.	B-Review	B-7	Review	389
In this case the comments of the authors really show that they do not know anything about coding.	I-Review	I-7	Review	389
In Page 6, we can read: ‚ÄúUnlike the convolutional codes, the state of the art (message-passing) decoders for turbo codes are not the corresponding MAP decoders, so there is no contradiction in that our neural decoder would beat the message-passing ones‚Äù.	I-Review	I-7	Review	389
This is so true, so I expected the DNN structure to be significantly better than turbodecoding.	I-Review	I-7	Review	389
But actually, they do not.	I-Review	I-7	Review	389
These results are in Figure 15 page 6 and the solution for the turbo decoders and the DNN architecture are equivalent.	I-Review	I-7	Review	389
I am sure that the differences in the plots can be explained by the variability in the received sequence and not because the DNN is superior to the turbodecoder.	I-Review	I-7	Review	389
Also in this case the training sequence is measured in the megabits for extremely simple components.	B-Review	B-4	Review	389
If the convolutional encoders were larger 6-8 bits, we would be talking about significantly longer training sequences and more complicated NNs.	I-Review	I-4	Review	389
<sep> <sep> In the third set the NNs seems to be superior to the standard methods when burst-y noise is used, but the authors seems to indicate that that NN is trained with more information about these bursts that the other methods do not have.	B-Review	B-3	Review	389
My impression is that the authors would be better of focusing on this example and explain it in a way that it is reproducible.	I-Review	I-3	Review	389
This experiment is clearly not well explained and it is hard to know if there is any merit for the proposed NN structure.	I-Review	I-3	Review	389
<sep> <sep> Finally, the last result would be the more interesting one, because it would show that we can learn a better channel coding and decoding mechanism that the ones humans have been able to come up with.	B-Review	B-2	Review	389
In this sense, if NNs can solve this problem that would be impressive and would turn around how channel coding is done nowadays.	I-Review	I-2	Review	389
If this result were good enough, the authors should only focus in it and forget about the other 3 cases.	I-Review	I-2	Review	389
The issue with this result is that it actually does not make sense.	I-Review	I-2	Review	389
The main problem with the procedure is that the feedback proposal is unrealistic, this is easy to see in Figure 16 in which the neural encoder is proposed.	I-Review	I-2	Review	389
It basically assumes that the received real-valued y_k can be sent (almost) noiselessly to the encoder with minimal delay and almost instantaneously.	I-Review	I-2	Review	389
So the encoder knows the received error and is able to cancel it out.	I-Review	I-2	Review	389
Even if this procedure could be implemented, which it cannot be.	I-Review	I-2	Review	389
The code only uses 50 bits and it needed 10^7 iterations (500Mbs) to converge.	I-Review	I-2	Review	389
The authors do not show how far they are from the Shannon limit, but I can imagine that with 50 bit code, it should be pretty far.	I-Review	I-2	Review	389
<sep> We know that with long enough LDPC codes we can (almost) reach the Shannon limit, so new structure are not needed.	B-Review	B-1	Review	389
If we are focusing on shorter codes (e.g. latency?)	I-Review	I-1	Review	389
then it will be good to understand why do we need to learn the channel codes.	I-Review	I-1	Review	389
A comparison to the state of the art would be needed.	I-Review	I-1	Review	389
Because clearly the used codes are not close to state of the art.	I-Review	I-1	Review	389
For me the authors either do not know about coding or are assuming that we do not, which explains part of the tone of this review.	I-Review	I-1	Review	389
<sep> <sep> As someone who has worked on coding theory for many years, I would like to add a comment, explaining	O	O	Reply	389
why I found this paper very interesting and how it is related to this review.	O	O	Reply	389
<sep> <sep> As mentioned, using density evolution we can design degree sequences for LDPCs that have thresholds that get very close to the Shannon limit.	B-Reply	B-1	Reply	389
The only case where we can actually approach arbitrarily close is the erasure channel.	I-Reply	I-1	Reply	389
For BIAWGN and BSC we can get quite close (but not actually arbitrarily close).	I-Reply	I-1	Reply	389
<sep> However, for slightly more complicated channels we have no idea how to do that or even what the fundamental limits are (e.g. deletion channel).	I-Reply	I-1	Reply	389
I find this paper exciting because it defines a new family of possibilities in code and decoder design.	I-Reply	I-1	Reply	389
It took us 50 years to go from Shannon's paper to modern LDPC and Turbo codes.	I-Reply	I-1	Reply	389
So we should not expect that this paper beats LDPCs in their own game but rather as opening a new area of investigation.	I-Reply	I-1	Reply	389

---	O	O	Review	389
revised score.	O	O	Review	389
rebuttal clears my concerns.	O	O	Review	389
<sep> ---	O	O	Review	389
Summary:	O	O	Review	389
<sep> The paper proposes a partially connected differential architecture search (PC-DARTS) technique, that uses a variant of channel dropout for each node's output feature maps, and a weighted summation of concatenating all previous nodes.	O	O	Review	389
Searched architecture on CIFAR-10 and ImageNet seems to outperform the one discovered by the original DARTS, however, the results are not directly comparable due to the slight change of search space.	O	O	Review	389
<sep> <sep> Introducing this edge normalization is a novel contribution, but it is more like a trick to have a better search space rather than the PC-DARTS itself.	O	O	Review	389
My main concerns are about the incremental novelty and experiments are heavily done on one search run, especially the search space is not the same as baseline DARTS.	B-Review	B-1	Review	389
<sep> <sep> I do not think the current version is ready for ICLR, but I am looking forward to seeing the authors' rebuttal and I am willing to revise my review accordingly.	O	O	Review	389
<sep> <sep> Main concerns	O	O	Review	389
<sep> - Incremental novelty about channel sampling.	B-Review	B-1	Review	389
<sep> Doing edge normalization in the PC-DARTS is indeed novel, however, the channel sampling (abbr.	I-Review	I-1	Review	389
PC for partial channel connection) is not.	I-Review	I-1	Review	389
Dropout is widely adopted in all deep learning training since AlexNet.	I-Review	I-1	Review	389
In NAS with parameter sharing, Pham et al already exploit the channel dropout as shown in ENAS function "def drop_path"(<a href="https://github.com/melodyguan/enas/blob/master/src/cifar10/image_ops.py)."	I-Review	I-1	Review	389
target="_blank" rel="nofollow">https://github.com/melodyguan/enas/blob/master/src/cifar10/image_ops.py).</a> It is true that previous works treated like one hyper-parameters and do not provide deeper insight about this term, but it is not correct to say in Section 3.4 "Channel sampling ... has never been studied in prior work".	I-Review	I-1	Review	389
In my perspective, the key difference of channel sampling is the retained channel number is always fixed to K, the non-selected channels are not zeroed, where the dropout usually has only a probability K / total_channel and non-selected feature is multiplied to a zero constant.	I-Review	I-1	Review	389
<sep> <sep> Thus, I suggest authors provide additional experiments as in Table 3 to compare the original drop-path with proposed channel sampling.	B-Review	B-2	Review	389
Considering the test error drops from 3% to 2.67% while using PC, it will be more convincing to show the original drop path with probability K / total_channel yields a smaller drop to evidence the effectiveness of proposed sampling.	I-Review	I-2	Review	389
<sep> <sep> - Proposed edge normalization is not a new sampling policy but a new search space.	B-Review	B-3	Review	389
<sep> To my understanding, this edge normalization is effectively a change to the search space rather than the sampling policy, and generalize to many other policies as well, and can be a substantial contribution to the NAS community.	I-Review	I-3	Review	389
However, under current experiments setting, it is hard to isolate the improvement is from this new space or the channel sampling, as detailed later.	I-Review	I-3	Review	389
<sep> <sep> - About the motivation.	B-Review	B-4	Review	389
<sep> Throughout the paper, in abstract, introduction, section 3.2 and section 4.4, the authors claim that the larger batch size is particularly important for the stability of architecture search which is not well-studied and lack of references.	I-Review	I-4	Review	389
From Table 4, it is hard to tell the stability is from the larger batch size or the proposed partial channel sampling.	I-Review	I-4	Review	389
<sep> <sep> <sep> - Questions about experiments	O	O	Review	389
<sep> 1.	O	O	Review	389
Experiments comparing to the baseline is not fair.	B-Review	B-6	Review	389
<sep> As in Section 4.2, the CIFAR-10 search is different from the original DARTS and P-DARTS in the following manner.	I-Review	I-6	Review	389
The batch size is changed from 64(in DARTS)/96(in P-DARTS) to 256,  super-net is freezed for the first 15 epochs, and introducing the edge normalization parameter \beta_{i,j} increase the search space.	I-Review	I-6	Review	389
With all these changes, it is quite hard to isolate the effectiveness of proposed PC-DARTS.	I-Review	I-6	Review	389
Two possible simple experiments to compare is, using the original DARTS space and training set, 1) do not update the \beta but use a fixed initialization that all \beta is the same (to mimic original DARTS concatenation); 2) add \beta to original DARTS as well and re-run 1).	I-Review	I-6	Review	389
<sep> <sep> It is completely reasonable to me the contribution of this paper is introducing a novel edge-normalization that is simple and effective to improve the DARTS based approach.	I-Review	I-6	Review	389
If so, the authors could revise the conclusion easily.	I-Review	I-6	Review	389
However, in the least scenario, the experiment comparison should be in a fair way.	I-Review	I-6	Review	389
<sep> <sep> 2.	O	O	Review	389
In original DARTS, error drop from 3% for the first-order gradient to 2.76% while using the second-order one, will this trend occurs with PC-DARTS?	B-Review	B-7	Review	389
<sep> <sep> 3.	B-Review	B-8	Review	389
Robustness	I-Review	I-8	Review	389
Recent work about evaluating neural architecture search reveals that NAS algorithms are sensitive to random initialization[1,2] and the search space [3], this in general leads to a notorious reproducibility problem of current NAS and shows it is not reasonable to only compare final performances on proxy tasks over **one** searched architecture.	I-Review	I-8	Review	389
However, in the stability study in Section 4.4.3, multiple runs are still over the same architecture discovered in earlier experiments.	I-Review	I-8	Review	389
In Section 4.4.2, the paper mentioned the search runs multiple times, yet the reported results in Table 3 are against the single run, as indicated by CIFAR-10 no PC- no EN error 3.00 +- 0.14, which is identical to the results in Table 1 DARTS (1st-order).	I-Review	I-8	Review	389
Could the authors report the results with at least 3 different initializations, and possibly release the seeds?	I-Review	I-8	Review	389
It would significantly strengthen the effectiveness of the proposed approach.	I-Review	I-8	Review	389
<sep> <sep> Minor comments	O	O	Review	389
<sep> - According to Section 4.4.1 and Figure 3, change the K from 1 to 8, the search cost drops significantly.	B-Review	B-9	Review	389
Does this mean the batch size in the ablation study is changing all the time?	I-Review	I-9	Review	389
How could we know if the test-error is reduced due to the sampling ratio or to the batch size?	I-Review	I-9	Review	389
<sep> <sep> Typos	O	O	Review	389
1.	B-Review	B-10	Review	389
Table 2, caption below the table, \dag is not aligned with the one in the used table.	I-Review	I-10	Review	389
<sep> <sep> --- reference ---	O	O	Review	389
[1] Li and Talwalker, Random search and reproducibility of neural architecture search, UAI‚Äô19	O	O	Review	389
[2] Sciuto et al Evaluating the search phase of neural architecture search, arxiv‚Äô19	O	O	Review	389
[3] Radosavovic et al On Network Design Spaces for Visual Recognition, ICCV'19.	O	O	Review	389
<sep> <sep> <sep> We thank the reviewer for the detailed comments.	O	O	Reply	389
Below, we provide detailed responses to each concern and question.	O	O	Reply	389
<sep> <sep> [C: incremental novelty] We admit that Dropout and DropPath are widely used in this field.	B-Reply	B-1	Reply	389
Partial channel connection is closely related to these methods, but the motivation behind it is quite different.	I-Reply	I-1	Reply	389
Our goal, besides regularizing super-network training (same as Dropout and DropPath), also includes reducing computational overhead in both time and space, which cannot be achieved by either Dropout or DropPath.	I-Reply	I-1	Reply	389
We will tune down our statement by saying "channel sampling has not been studied in NAS for reducing computational overhead".	I-Reply	I-1	Reply	389
In addition, the ability to save computation comes from fixing the number of the sampled channels, so this difference is minor but important.	I-Reply	I-1	Reply	389
<sep> <sep> Regarding using DropPath, we agree it is a nice diagnostic study, but since it cannot reduce memory as our channel sub-sampling method, we cannot compare it to our approach in a completely fair environment.	B-Reply	B-2	Reply	389
Under a smaller batch size (as in original DARTS), DropPath and partial channel connection report comparable performance, but the former is slower.	I-Reply	I-2	Reply	389
<sep> <sep> [C: edge normalization is not a new sampling policy but a new search space] This is a major misunderstanding.	B-Reply	B-3	Reply	389
The search space of PC-DARTS is *identical* to that of DARTS (and other DARTS-based methods).	I-Reply	I-3	Reply	389
Note that beta is a parameter to control edge selection: it stabilizes the search stage but does affect the search space.	I-Reply	I-3	Reply	389
All network architectures found by PC-DARTS can also be found by DARTS.	I-Reply	I-3	Reply	389
We welcome further questions of the reviewer and hope that our explanation can prevent this misunderstanding.	I-Reply	I-3	Reply	389
<sep> <sep> [C: about the motivation] We did not see any prior approaches studying the impact of the batch size, but most differentiable search methods including DARTS and P-DARTS [1] tried to maximize the batch size.	B-Reply	B-4	Reply	389
Also, in the field of image classification, it is well known that a larger batch size often leads to a more stable training process.	I-Reply	I-4	Reply	389
The stability does come from a large batch.	I-Reply	I-4	Reply	389
With K=4, we use the original batch size (64) in DARTS, and the test error (over 5 search trials) is 2.71¬±0.13%.	I-Reply	I-4	Reply	389
Although the best model (2.60%) is comparable to that using 256-sized batches (2.57%), the worst model (2.85%) is much worse, and the average is worse and the standard deviation is larger (2.71¬±0.13% vs. 2.67¬±0.07%).	I-Reply	I-4	Reply	389
<sep> <sep> [Q1: comparison is not fair] Regarding the search space issue, please refer to the above concern.	B-Reply	B-6	Reply	389
For batch size and warmup training, they were also used in all our experiments of DARTS and P-DARTS [1] (except for the numbers copied from their papers).	I-Reply	I-6	Reply	389
We also evaluated PC-DARTS with smaller batch sizes and obtained similar performance (2.60¬±0.11%) on CIFAR10, but the search time is ~2.5x longer.	I-Reply	I-6	Reply	389
Note that DARTS becomes even less unstable without a warmup, meanwhile, both P-DARTS [1] and Auto-Deeplab [2] were equipped with a warmup, as claimed in the original paper.	I-Reply	I-6	Reply	389
<sep> <sep> [Q2: using 2nd-order DARTS?]	O	O	Reply	389
We tried the 2nd-order DARTS but the improvement is marginal, though being much slower.	B-Reply	B-7	Reply	389
Actually, many researchers in this field pointed out that the same issue and this was the same reason why 2nd-order DARTS was not used in these works, including P-DARTS [1], ASAP [3] and ProbNAS [4].	I-Reply	I-7	Reply	389
<sep> [Q3: robustness?]	O	O	Reply	389
Sorry for incorrect statements in the paper.	B-Reply	B-8	Reply	389
Indeed, all the standard deviation numbers reported in Tables 3 and 4 are recorded on *independent search and evaluation*, not using the same searched architecture.	I-Reply	I-8	Reply	389
We have fixed this claim in the updated paper.	I-Reply	I-8	Reply	389
The seeds we have used for five individual runs are (0, 1, 2, 3, 4).	I-Reply	I-8	Reply	389
Thanks for correcting this point!	I-Reply	I-8	Reply	389
<sep> <sep> [Minor: impacts of batch size?]	B-Reply	B-9	Reply	389
Yes, the batch sizes in the experiments of Sec 4.4.1 changes all the time (always proportional to K, so that we make full use of GPU memory).	I-Reply	I-9	Reply	389
We do this for acceleration, but changing batch size does not impact search accuracy a lot.	I-Reply	I-9	Reply	389
To verify this, we used a batch size of 64 for K=4 (same as K=1) and the test error is 2.60%, comparable to 2.57% reported in the paper.	I-Reply	I-9	Reply	389
<sep> <sep> [Typos] We have fixed them in the updated paper.	B-Reply	B-10	Reply	389
Thanks!	I-Reply	I-10	Reply	389
<sep> <sep> ===References===	O	O	Reply	389
<sep> [1] X. Chen, et al Progressive differentiable architecture search: Bridging	O	O	Reply	389
the depth gap between search and evaluation.	O	O	Reply	389
arXiv preprint arXiv:1904.12760, 2019.	O	O	Reply	389
<sep> [2] C. Liu, et al Auto-DeepLab: Hierarchical neural architecture search for semantic image segmentation.	O	O	Reply	389
arXiv preprint arXiv:1901.02985, 2019.	O	O	Reply	389
<sep> [3] A. Noy, et al ASAP: Architecture Search, Anneal and Prune.	O	O	Reply	389
arXiv preprint arXiv:1904.04123, 2019.	O	O	Reply	389
<sep> [4] F. P. Casale, et al Probabilistic Neural Architecture Search.	O	O	Reply	389
arXiv preprint arXiv:1902.05116, 2019.	O	O	Reply	389

** Summary **	O	O	Review	389
This paper proposes to improve the previously work DARTS in terms of the training efficiency, from the large memory and computing overheads.	O	O	Review	389
The authors propose a partially-connected DARTS (PC-DARTS) with two components: 1.	O	O	Review	389
Partial channel connection 2.	O	O	Review	389
edge normalization.	O	O	Review	389
To be detailed, they sample a small part of channels to perform connection and add edge normalization to eliminate the potential optimization problem.	O	O	Review	389
The results on CIFAR-10 and IamgeNet show the approach is effective, especially in ImageNet, the approach achieves SOTA results.	O	O	Review	389
<sep> <sep> ** Strengths **	O	O	Review	389
1.	O	O	Review	389
<tab>The research direction of reducing the training/memory effort of Neural Architecture Search is important, which is also very hot in nowadays.	O	O	Review	389
<sep> 2.	O	O	Review	389
<tab>The authors propose two components to perform the efficient search process, which are partial channel connection and edge normalization operations.	O	O	Review	389
These methods are reasonable to reduce the training effort.	O	O	Review	389
The authors are inspired by ShuffleNet or related research topics.	O	O	Review	389
<sep> 3.	O	O	Review	389
<tab>The approach is easy to follow and implement, the description of the method is also clear.	O	O	Review	389
<sep> 4.	O	O	Review	389
<tab>The experiments also show comparable results in CIFAR-10 and strong performance in ImageNet.	O	O	Review	389
<sep> <sep> ** Weaknesses **	O	O	Review	389
1.	O	O	Review	389
<tab>The operation of partial channel connection choses 1/k channels, the remain channels are directly added to the output.	B-Review	B-1	Review	389
This operation somehow feels too straight to be reasonable, since the remain channel has larger weights (1.0) compared to previous weighted combination.	I-Review	I-1	Review	389
Though the second edge normalization can eliminate little, but this modification still suffers from less careful design, for example, another \alpha weighted combination?	I-Review	I-1	Review	389
Besides, directly bypass is same as perform identity operation, is this right?	I-Review	I-1	Review	389
<sep> 2.	O	O	Review	389
<tab>The motivation of edge normalization is somehow weak, as the authors are aware of this can also be applied to the original DARTS.	B-Review	B-2	Review	389
From the ablation study, it also shows it works for the original DARTS, which makes the description of 3.3.	I-Review	I-2	Review	389
to be not so convincing.	I-Review	I-2	Review	389
Besides, in the first paragraph of 3.3, what does it mean that ‚Äúweight-free operations often accumulate larger weights‚Äù compared to other operations?	I-Review	I-2	Review	389
I feel the reason is that the weight-free operations are much easier to pass the gradients and easy to be trained.	I-Review	I-2	Review	389
<sep> 3.	O	O	Review	389
<tab>In imageNet results, it seems P-DARTS significantly outperform PC-DARTS in terms of the search cost, and the accuracy is similar.	B-Review	B-3	Review	389
This makes PC-DARTS approach to be embarrassing.	I-Review	I-3	Review	389
<sep> 4.	O	O	Review	389
<tab>One general point is what the authors mentioned, indeed, for NAS, more training data involved in the training process is much more important compared to perform operations.	B-Review	B-4	Review	389
Therefore, the advantage benefits from the less memory usage of 1/k selection and the more data in one mini-batch.	I-Review	I-4	Review	389
This makes the design of current research directions to be different.	I-Review	I-4	Review	389
Does it mean more training (longer time) and more GPU memory will significantly outperform current results?	I-Review	I-4	Review	389
Even the SOTA approaches.	I-Review	I-4	Review	389
<sep> 5.	O	O	Review	389
<tab>Minor point: compared to ProxylessNAS which only samples two paths at each time, their method is much more efficient (though the binarization consumes much).	B-Review	B-5	Review	389
What‚Äôs the most advantage of PC-DARTS compared to their method?	I-Review	I-5	Review	389
What if combine their approach with edge normalization?	I-Review	I-5	Review	389
<sep> <sep> We thank the reviewer for the detailed comments.	O	O	Reply	389
Below, we provide detailed responses to each point in the weaknesses part.	O	O	Reply	389
<sep> <sep> 1.	O	O	Reply	389
We are not sure if we correctly understand this question.	B-Reply	B-1	Reply	389
If not, please give us feedback and we will respond.	I-Reply	I-1	Reply	389
Yes, directly bypass is equivalent to setting the weight of skip-connect to be 1.	I-Reply	I-1	Reply	389
For the sampled channels, the total weight of all operators is 1, the same as the remaining channels.	I-Reply	I-1	Reply	389
Our approach can be understood as adding a random mask on the channels so that some channels undergo mix-operator computation while others do not.	I-Reply	I-1	Reply	389
The effect is regularization, which prevents the search process to overfit the super-network and thus cause instability on the performance of the preserved sub-network.	I-Reply	I-1	Reply	389
<sep> <sep> We welcome more sophisticated designs that can improve our work, but we do not understand what the reviewer meant by "another alpha weight combination", and look forward to follow-up comments.	I-Reply	I-1	Reply	389
<sep> <sep> 2.	O	O	Reply	389
Sorry for being a bit misleading.	B-Reply	B-2	Reply	389
Our logic is that edge normalization was inspired by improving the search stability when partial channel connection is present, *although it produces accuracy gain individually (on the original DARTS)*. We are not sure which part of Sec 3.3 was made less convincing by the fact that edge normalization works well on the original DARTS, and we look forward to future comments.	I-Reply	I-2	Reply	389
<sep> <sep> Regarding weight-free operations, we did mean that "they are much easier to pass the gradients and easy to be trained", and "they accumulate larger weights" is the consequence.	I-Reply	I-2	Reply	389
This phenomenon was also observed in P-DARTS [1].	I-Reply	I-2	Reply	389
<sep> 3.	B-Reply	B-3	Reply	389
P-DARTS is much faster since it was searched on CIFAR10, a reasonable proxy dataset for ImageNet.	I-Reply	I-3	Reply	389
However, finding a proxy dataset is not always possible, and we argue that directly searching on the target dataset is an important ability of NAS approaches.	I-Reply	I-3	Reply	389
In comparison, we did evaluate P-DARTS [1] with a direct search on ImageNet, but the performance is much lower than PC-DARTS.	I-Reply	I-3	Reply	389
This comparison is a further justification for the contribution of PC-DARTS.	I-Reply	I-3	Reply	389
<sep> <sep> 4.	O	O	Reply	389
This does not seem to be a "weakness", but a take-away message of our approach.	B-Reply	B-4	Reply	389
Note that PC-DARTS did not introduce additional training data, but allowed a larger batch size to be used which largely improves both accuracy and speed.	I-Reply	I-4	Reply	389
It is well known in the community that a large batch size often leads to better and more stable performance, and we, of course, believe that GPUs with larger memory can help in this way.	I-Reply	I-4	Reply	389
PC-DARTS provides an efficient solution under limited GPU memory.	I-Reply	I-4	Reply	389
<sep> <sep> 5.	O	O	Reply	389
We do not quite understand why ProxylessNAS [2] is more efficient (if "their method" means ProxylessNAS).	B-Reply	B-5	Reply	389
The search space of ProxylessNAS is different from ours.	I-Reply	I-5	Reply	389
Besides, ProxylessNAS required 4.0 and 8.3 GPU-days on CIFAR10 and ImageNet, while these numbers for PC-DARTS are only 0.1 and 3.8, respectively.	I-Reply	I-5	Reply	389
ProxylessNAS required more computational overhead because the architecture is changing heavily from iteration to iteration (in comparison, the architectural change in PC-DARTS is channel-level and thus much lighter) so that it required a longer time for the search process to converge reasonably.	I-Reply	I-5	Reply	389
Indeed, the motivation of PC-DARTS is different from ProxylessNAS, and we believe these two approaches claimed independent contributions to the community.	I-Reply	I-5	Reply	389
Of course, we believe that edge normalization can be incorporated into ProxylessNAS, and we will try it in the future.	I-Reply	I-5	Reply	389
<sep> <sep> ===References===	O	O	Reply	389
<sep> [1] X. Chen, L. Xie, J. Wu, and Q. Tian.	O	O	Reply	389
Progressive differentiable architecture search: Bridging	O	O	Reply	389
the depth gap between search and evaluation.	O	O	Reply	389
arXiv preprint arXiv:1904.12760, 2019.	O	O	Reply	389
<sep> [2] H. Cai, L. Zhu, and S. Han.	O	O	Reply	389
ProxylessNAS: Direct neural architecture search on target task and hardware.	O	O	Reply	389
arXiv preprint arXiv:1812.00332, 2018.	O	O	Reply	389

The authors propose with this paper a simple extension of DARTS, a popular neural architecture search (NAS) method.	B-Review	B-1	Review	389
This extension addresses one of the shortcoming of DARTS: the immense memory cost.	O	O	Review	389
This achieved in a simple way.	O	O	Review	389
Instead of using all channels only a random subset is used.	O	O	Review	389
To account for that, the authors propose a method to normalizes edges.	O	O	Review	389
<sep> <sep> The description of the method is very clear.	O	O	Review	389
The related work covers many works.	O	O	Review	389
I suggest to focus more on the more recent work on NAS and particular work that follows the core idea of DARTS.	O	O	Review	389
This deserves more than used two very short sentences since this is the most related work.	O	O	Review	389
The experimental section leaves no question unanswered.	O	O	Review	389
The setup is clearly described in all cases, ablation studies are conducted wherever it is needed.	O	O	Review	389
The method is evaluated on both CIFAR-10 and ImageNet and is even transferred to MS COCO.	O	O	Review	389
The search results show some improvements with respect to time budget.	O	O	Review	389
<sep> Concluding, this might not be a ground-breaking paper but it is well made and I see no obvious flaws so I do not see any reason to reject it.	B-Review	B-1	Review	389
We thank the reviewer for the positive comments.	O	O	Reply	389
<sep> <sep> Indeed, our work introduced a simple approach, partial channel connection, to regularize the architecture search process as well as create two additional benefits: (i) reduce the computational overhead to accelerate the search stage; and (ii) reduce the memory consumption so that the algorithm can be trained under a large batch size to improve search stability.	B-Reply	B-1	Reply	389
In addition, we design edge normalization to compensate for the randomness caused by partial channel connection.	I-Reply	I-1	Reply	389
The overall framework achieves the state-of-the-art search accuracy and speed among all DARTS-based approaches.	I-Reply	I-1	Reply	389
<sep> <sep> In the related work section of the updated paper, we have used an individual paragraph to introduce DARTS and two of its variants, namely, ProxylessNAS [1] and P-DARTS [2].	I-Reply	I-1	Reply	389
<sep> ===References===	O	O	Reply	389
<sep> [1] H. Cai, L. Zhu, and S. Han.	O	O	Reply	389
ProxylessNAS: Direct neural architecture search on target task and hardware.	O	O	Reply	389
arXiv preprint arXiv:1812.00332, 2018.	O	O	Reply	389
<sep> [2] X. Chen, L. Xie, J. Wu, and Q. Tian.	O	O	Reply	389
Progressive differentiable architecture search: Bridging	O	O	Reply	389
the depth gap between search and evaluation.	O	O	Reply	389
arXiv preprint arXiv:1904.12760, 2019.	O	O	Reply	389

The paper presents a maximally expressive parameter-sharing scheme for hypergraphs, and in general when modeling the high order interactions between elements of a set.	O	O	Review	488
This setting is further generalized to multiple sets.	O	O	Review	488
The paper shows that the number of free parameters in invariant and equivariant layers corresponds to the different partitioning of the index-set of input and output tensors.	O	O	Review	488
Experimental results suggest that the proposed layer can outperform existing methods in supervised learning with graphs.	O	O	Review	488
<sep> <sep> The paper presents a comprehensive generalization of a recently proposed model for interaction across sets, to the setting where some of these sets are identical.	O	O	Review	488
This is particularly useful and important due to its applications to graphs and hyper-graphs, as demonstrated in experiments.	O	O	Review	488
<sep> <sep> Overall, I enjoyed reading the paper.	O	O	Review	488
My only concern is the experiments:	O	O	Review	488
<sep> 1) Some of the benchmark datasets for the proposed task as well as some well-known methods (see Battaglia et al‚Äô18 and references in there) are missing.	B-Review	B-2	Review	488
<sep> <sep> 2) Applying the model of Hartford et al‚Äô18 to problems where interacting sets are identical is similar to applying convolution layer to a feature vector that is not equivariant to translation. (	B-Review	B-1	Review	488
In both cases the equivariance group of data is a strict subgroup of the equivariance of the layer.)	I-Review	I-1	Review	488
Do you agree that for this reason, all the experiments on the synthetic dataset is flawed?	I-Review	I-1	Review	488
<sep> <sep> We thank the reviewer for the positive comments.	O	O	Reply	488
Below we address the main concerns.	O	O	Reply	488
<sep> <sep> Q: ‚ÄùApplying the model of Hartford et al to problems where interacting sets are identical is similar to applying convolution layer to a feature vector that is not equivariant to translation... Do you agree that for this reason, all the experiments on the synthetic dataset is flawed?‚Äù	O	O	Reply	488
<sep> A: Our goal in performing the synthetic experiments was to quantify the expressive power that is  gained by adding our basis elements to [Hartford et al 18]. We felt it is an informative experiment since [Hartford et al 18] also discuss applying their model in the jointly exchangeable setting (page 3, second column, top paragraph).	B-Reply	B-1	Reply	488
<sep> Having said that, we agree with the reviewer that [Hartford et al 18] probably cannot handle such tasks by construction.	I-Reply	I-1	Reply	488
As we mentioned in our response to Reviewer1 we will change the wording of this section to better reflect that this is *not* a failure of Hartford et al but merely a setting outside their scope due to a different assumption on the symmetry group of the data.	I-Reply	I-1	Reply	488
If the reviewers feel strongly about this experiment, we are open to replace it with a discussion.	I-Reply	I-1	Reply	488
<sep> --------------------------------------------------------------------------------------------------------------------------------	O	O	Reply	488
Q: ‚ÄúSome of the benchmark datasets for the proposed task as well as some well-known methods (see Battaglia et al‚Äô18 and references in there) are missing‚Äù.	O	O	Reply	488
<sep> <sep> A: We did our best to survey and compare to the most related works on the dataset collection introduced in [Yanardag & Vishwanathan 2015]. These datasets contain graphs from multiple origins, where some of them consist of highly varying graph sizes (within the same dataset).	B-Reply	B-2	Reply	488
In any case we will make the code available as soon as possible.	I-Reply	I-2	Reply	488
--------------------------------------------------------------------------------------------------------------------------------	O	O	Reply	488

Given a graph G of n vertices, the activations at each level of a graph neural network (G-NN) for G	O	O	Review	488
can be arranged in an n^k tensor T for some k. A fundamental criterion is that this tensor must be equivariant	O	O	Review	488
to permutations of the vertices of G in the sense of each index of of T being permuted simultaneously.	O	O	Review	488
<sep> <sep> This paper enumerates the set of all linear maps that satisfy this criterion, i.e., all linear maps	O	O	Review	488
which (the authors claim) can serve as the analog of convolution in equivariant G-NNs.	O	O	Review	488
<sep> The authors find that for invariant neural networks such maps span a space of dimension just b(k), whereas	O	O	Review	488
for equivariant neural networks they span a space of dimension b(2k).	O	O	Review	488
<sep> <sep> The proof of this result is simple, but elegant.	O	O	Review	488
It hinges on the fact that the set of tensor elements of	O	O	Review	488
the same equality type is both closed and transitive under the permutation action.	O	O	Review	488
Therefore, the	O	O	Review	488
dimensionality of the subspace in question is just the number of different identity types, i.e.,	O	O	Review	488
partitions of either {1,...,k} or {1,...,2k}, depending on whether we are talking about invariance or	O	O	Review	488
equivariance.	O	O	Review	488
<sep> <sep> My problem with the paper is that the authors' model of G-NNs doesn't actually map to what is used	O	O	Review	488
in practice or what is interesting and useful.	O	O	Review	488
Let me list my reservations in increasing order of significance.	O	O	Review	488
<sep> <sep> 1.	O	O	Review	488
The authors claim that they give a ``full characterization'' of equivariant layers.	B-Review	B-3	Review	488
This is not true.	I-Review	I-3	Review	488
<sep> Equivariance means that there is *some* action of the symmetric group S_n on each layer, and wrt these actions	I-Review	I-3	Review	488
the network is equivariant.	I-Review	I-3	Review	488
Collecting all the activations of a given layer together into a single object L,	I-Review	I-3	Review	488
this means that L is transformed according to some representation of S_n.	I-Review	I-3	Review	488
Such a representation can always be	I-Review	I-3	Review	488
reduced into a direct sum of the irreducible representations of S_n.	I-Review	I-3	Review	488
The authors only consider the case then	I-Review	I-3	Review	488
the representation is the k'th power of the permutation representation (technically called the defining	I-Review	I-3	Review	488
representation of the S_n).	I-Review	I-3	Review	488
This corresponds to a specific choice of irreducibles and is not the most general case.	I-Review	I-3	Review	488
<sep> In fact, this is not an unnatural choice, and all G-NNs that I know follow this route.	I-Review	I-3	Review	488
<sep> Nonetheless, technically, saying that they consider all possible equivariant networks is not correct.	I-Review	I-3	Review	488
<sep> <sep> 2.	O	O	Review	488
The paper does not discuss what happens when the input tensor is symmetric.	B-Review	B-4	Review	488
On the surface this might seem	I-Review	I-4	Review	488
like a strength, since it just means that they can consider the more general case of undirected graphs (although	I-Review	I-4	Review	488
they should really say so).	I-Review	I-4	Review	488
In reality, when considering higher order activations it is very misleading because	I-Review	I-4	Review	488
it leads to a massive overcounting of the dimensionality of the space of convolutions.	I-Review	I-4	Review	488
In the case of k=2, for	I-Review	I-4	Review	488
example, the dimensionality for undirected graphs is probably closer to 5 than 15 for example (I didn't count).	I-Review	I-4	Review	488
<sep> <sep> 3.	O	O	Review	488
Finally, and critically, in actual G-NNs, the aggregation operation in each layer is *not*	B-Review	B-1	Review	488
linear, in the sense that it involves a product of the activations of the previous layer with the adjacency	I-Review	I-1	Review	488
matrix (messages might be linear but they are only propagated along the edges of the graph).	I-Review	I-1	Review	488
<sep> In most cases this is motivated by making some reference to the geometric meaning of convolution,	I-Review	I-1	Review	488
the Weisfeiler-Lehman algorithm or message passing in graphical models.	I-Review	I-1	Review	488
In any case, it is critical that the	I-Review	I-1	Review	488
graph topology be reintroduced into the network at each layer.	I-Review	I-1	Review	488
The algebraic way to see it is that each layer	I-Review	I-1	Review	488
must mix the information from the vertices, edges, hyperedges, etc.. The model in this paper could only aggregated	I-Review	I-1	Review	488
edge information at the vertices.	I-Review	I-1	Review	488
Vertex information could not be broadcast to neighboring vertices again.	I-Review	I-1	Review	488
<sep> The elemenary step of ``collecting vertex information from the neighbors but only the neighbors'' cannot be	I-Review	I-1	Review	488
realized in this model.	I-Review	I-1	Review	488
<sep> <sep> Therefore, I feel that the model used in this paper is rather uninteresting and irrelevant for practical	B-Review	B-1	Review	488
purposes.	I-Review	I-1	Review	488
If the authors disagree, I would encourage them to explicitly write down how they think the model	B-Review	B-2	Review	488
can replicate one of the standard message passing networks.	I-Review	I-2	Review	488
It is apparent from the 15 operations listed on	B-Review	B-5	Review	488
page 11 that they have nothing to do with the graph topology at all.	I-Review	I-5	Review	488
<sep> <sep> Minor gripes:	B-Review	B-6	Review	488
<sep> - I wouldn't call (3) and (4) fixed point equations, that's usually used in dynamical systems.	I-Review	I-6	Review	488
Here there is	I-Review	I-6	Review	488
an entire subspace fixed by *all* permutations.	I-Review	I-6	Review	488
<sep> <sep> - Below (1), they probably mean that ``up to permutation vec(L)=vec(L^T)''.	I-Review	I-6	Review	488
<sep> <sep> <sep> We thank the reviewer for the detailed review.	O	O	Reply	488
The reviewer's main concern was the practicality of the method, and its inability to model message passing.	O	O	Reply	488
We respectfully disagree.	O	O	Reply	488
Below we show that our model can simulate standard message passing architectures in a simple way, as well as answer other concerns.	O	O	Reply	488
<sep> <sep> --------------------------------------------------------------------------------------------------------------------------------	O	O	Reply	488
Q: ‚ÄúFinally, and critically, in actual G-NNs, the aggregation operation in each layer is *not*	O	O	Reply	488
Linear‚Ä¶ I feel that the model used in this paper is rather uninteresting and irrelevant for practical purposes‚Äù	O	O	Reply	488
<sep> A: We would like to address this from a few points of view.	B-Reply	B-1	Reply	488
<sep> Message passing usually deals with vertex data and adjacency matrix.	I-Reply	I-1	Reply	488
Our goal was to work with data such as general affinity matrices and higher order tensors.	I-Reply	I-1	Reply	488
For example, pairwise distance matrix (order 2 tensor), or area/congruence of triplets (order 3 tensor) which are useful representation for geometric data, for instance.	I-Reply	I-1	Reply	488
<sep> Also note that linear equivariant models like ours are already used in successful methods like PointNet [Qi et al CVPR 2017], DeepSets [Zaheer et al NIPS 2017], and [Hartford el al.	I-Reply	I-1	Reply	488
ICML 2018].	I-Reply	I-1	Reply	488
Having said that, our method is at-least as powerful in terms of universality as standard message passing (see next question).	I-Reply	I-1	Reply	488
We also note that our empirical results support the above mentioned theoretical results.	I-Reply	I-1	Reply	488
<sep> <sep> --------------------------------------------------------------------------------------------------------------------------------	O	O	Reply	488
Q: ‚ÄúI would encourage them to explicitly write down how they think the model	O	O	Reply	488
can replicate one of the standard message passing networks‚Äù.	O	O	Reply	488
<sep> <sep> A: Thank you for raising this question.	O	O	Reply	488
Let us show:	O	O	Reply	488
<sep> Proposition:	O	O	Reply	488
Our model can represent Kipf & Welling‚Äôs message passing [Kipf & Welling ICLR 2017] to arbitrary precision.	B-Reply	B-2	Reply	488
<sep> <sep> Proof:	O	O	Reply	488
Consider input vertex data X\in R^{n x d} (n is the number of vertices in the graph, and d is the feature depth) and adjacency/affinity matrix A\in R^{n x n}  of the graph.	B-Reply	B-2	Reply	488
In our setting we represent this data using a tensor Y\in R^{n x n x d+1} where the first channel is the adjacency matrix A and the last d channels are diagonal matrices that hold X. We would like to approximate the function Y \mapsto A*X. For simplicity we consider d=1 but the following generalizes readily to all d>1.	I-Reply	I-2	Reply	488
A*X can be represented by first using our equivariant linear layer to replicate X values on the rows; denote this new matrix by Z \in R^{n x n x 2}, where the first channel of Z is A and the second is the replication of X. Now multiplying entrywise the two feature channels of Z followed by summing the rows (another equivariant 2->1 operator) will provide A*X.  Since pointwise product between features is not a part of our model we can approximate it to arbitrary precision using an MLP on the feature dimension that can be written as a series of linear equivariant operators and ReLUs. (	I-Reply	I-2	Reply	488
Note that MLP on the feature dimension is the way PointNet and DeepSets work.)	I-Reply	I-2	Reply	488
QED	I-Reply	I-2	Reply	488
<sep> We will add this claim and proof to the paper.	I-Reply	I-2	Reply	488
<sep> <sep> One immediate corollary of this proposition is that in terms of universality our model is at-least as powerful as Kipf & Welling message passing.	I-Reply	I-2	Reply	488
<sep> <sep> --------------------------------------------------------------------------------------------------------------------------------	O	O	Reply	488
Q: ‚ÄúThe authors claim that they give a ``full characterization'' of equivariant layers‚Äù:	O	O	Reply	488
<sep> A: We give a full characterization for equivariant maps for the natural action of the S_n on the graph tensors of all orders: consistent re-labeling of the graph nodes.	B-Reply	B-3	Reply	488
The reviewer is correct in pointing out that not all irreducible representations are considered.	I-Reply	I-3	Reply	488
We will be happy to rephrase our claim.	I-Reply	I-3	Reply	488
<sep> <sep> --------------------------------------------------------------------------------------------------------------------------------	O	O	Reply	488
Q: ‚ÄùThe paper does not discuss what happens when the input tensor is symmetric.	O	O	Reply	488
‚Äù	O	O	Reply	488
<sep> A: This question was addressed in Appendix 1.	B-Reply	B-4	Reply	488
We add a relevant quote:	I-Reply	I-4	Reply	488
‚ÄúWe note that in case the input matrix is symmetric, our basis reduces to 11 elements in the first layer.	I-Reply	I-4	Reply	488
If we further assume the matrix has zero diagonal we get a 6 element basis in the first layer.	I-Reply	I-4	Reply	488
In both cases our model is more expressive than the 4 element basis of Hartford et al (2018) and as the output of the first layer (or other inner states) need not be symmetric nor have zero diagonal the deeper layers can potentially make good use of the full 15 element basis.	I-Reply	I-4	Reply	488
‚Äù	I-Reply	I-4	Reply	488
--------------------------------------------------------------------------------------------------------------------------------	O	O	Reply	488

This paper explores maximally expressive linear layers for jointly exchangeable data and in doing so presents a surprisingly expressive model.	O	O	Review	488
I have given it a strong accept because the paper takes a very well-studied area (convolutions on graphs) and manages to find a far more expressive model (in terms of numbers of parameters) than what was previously known by carefully exploring the implications of the equivariance assumptions implied by graph data.	O	O	Review	488
The result is particularly interesting because the same question was asked about exchangeable matrices (instead of *jointly* exchangeable matrices) by Hartford et al [2018] which lead to a model with 4 bases instead of the 15 bases in this model, so the additional assumption of joint exchangeability (i.e. that any permutations applied to rows of a matrix must also be applied to columns - or equivalently, the indices of the rows and columns of a matrix refer to the same items / nodes) gives far more flexibility but without losing anything with respect to the Hartford et al result (because it can be recovered using a bipartite graph construction - described below).	O	O	Review	488
So we have a case where an additional assumption is both useful (in that it allows for the definition of a more flexible model) and benign (because it doesn't prevent the layer from being used on the data explored in Hartford et al).	O	O	Review	488
<sep> <sep> I only have a couple of concerns:	O	O	Review	488
1 - I would have liked to see more discussion about why the two results differ to give readers intuition about where the extra flexibility comes from.	B-Review	B-1	Review	488
The additional parameters of this paper come from having parameters associated with the diagonal (intuitively: self edges get treated differently to other edges) and having parameters for the transpose of the matrix (intuitively: incoming edges are different to outgoing edges).	I-Review	I-1	Review	488
Neither of these assumptions apply in the exchangeable setting (where the matrix may not be square so the diagonal and transpose can't be used).	I-Review	I-1	Review	488
Because these differences aren't explained, the synthetic tasks in the experimental section make this approach look artificially good in comparison to Hartford et al  The tasks are explicitly designed to exploit these additional parameters - so framing the synthetic experiments as, "here are some simple functions for which we would need the additional parameters that we define" makes sense; but arguing that Hartford et al "fail approximating rather simple functions" (page 7) is misleading because the functions are precisely the functions on which you would expect Hartford et al to fail (because it's designed for a different setting).	I-Review	I-1	Review	488
<sep> 2 - Those more familiar of the graph convolution literature will be more familiar with GCN [kipf et al 2016] / GraphSAGE [Hamilton et al 2017] / Monti et al [2017] / etc.. Most of these approaches are more restricted version of this work / Hartford et al so we wouldn't expect them to perform any differently from the Hartford et al  baseline on the synthetic dataset, but including them will strengthen the author's argument in favour of the work.	B-Review	B-3	Review	488
I would have also liked to see a comparison to these methods in the the classification results.	I-Review	I-2	Review	488
<sep> 3 - Appendix A - the 6 parameters for the symmetric case with zero diagonal reduces to the same 4 parameters from Hartford et al if we constrained the diagonal to be zero in the output as well as the input.	B-Review	B-4	Review	488
This is the case when you map an exchangeable matrix into a jointly exchangeable matrix by representing it as a bipartite graph [0, X; X^T, 0]. So the two results coincide for the exchangeable case.	I-Review	I-4	Review	488
Might be worth pointing this out.	I-Review	I-4	Review	488
<sep> <sep> We thank the reviewer for the detailed review.	O	O	Reply	488
Below we address the main concerns.	O	O	Reply	488
<sep> <sep> --------------------------------------------------------------------------------------------------------------------------------	O	O	Reply	488
Q:‚Äùso framing the synthetic experiments as, "here are some simple functions for which we would need the additional parameters that we define" makes sense; but arguing that Hartford et al "fail approximating rather simple functions" (page 7) is misleading because the functions are precisely the functions on which you would expect Hartford et al to fail‚Äù	O	O	Reply	488
<sep> A: We agree with the reviewer and will change our wording accordingly.	B-Reply	B-1	Reply	488
<sep> --------------------------------------------------------------------------------------------------------------------------------	O	O	Reply	488
Q:‚ÄùI would have liked to see more discussion about why the two results differ to give readers intuition about where the extra flexibility comes from‚Äù.	O	O	Reply	488
‚Äúthe two results coincide for the exchangeable case‚Äù	O	O	Reply	488
<sep> A: We agree with the reviewer that such a discussion will be helpful to the reader.	B-Reply	B-2	Reply	488
We will add such a discussion (in addition to the short discussion at the end of Appendix 1).	I-Reply	I-2	Reply	488
<sep> --------------------------------------------------------------------------------------------------------------------------------	O	O	Reply	488
Q: Comparison to popular graph convolution methods (GCN [kipf et al 2016] / GraphSAGE [Hamilton et al 2017] / Monti et al [2017] / etc.).	O	O	Reply	488
<sep> <sep> A: As discussed in our response to Reviewer 2, We will add a theoretical result that shows that our model is at least as powerful in terms of universality as [Kipf & Welling ICLR 2017].	B-Reply	B-3	Reply	488

*Summary*	O	O	Review	96
This paper compares network pruning masks learned via different iterative pruning methods.	O	O	Review	96
Experiments on LeNet + MNIST show (a) different methods can achieve similar accuracy, (b) pruned sub-networks may differ significantly despite identical initialization, (c) weight reinitialization between pruning iterations yields more structured convolutional layer pruning than not reinitializing, and (d) pruning methods may differ in the stability of weights over pruning iterations.	O	O	Review	96
<sep> <sep> *Rating*	O	O	Review	96
There are interesting bits of data in this paper, but the overall story is somewhat muddled and some inferences seem to be insufficiently supported by data (1-2 below).	B-Review	B-7	Review	96
In addition, the text would benefit from better organization and presentation (3-4 below) and replications on other datasets and architectures (5 below).	I-Review	I-7	Review	96
As a result, my rating is currently weak reject.	O	O	Review	96
<sep> <sep> (1) *Overlap in pruned sub-networks*: In the middle of Sec.4, Fig 3-5 examine the similarity of pruning masks between methods.	B-Review	B-1	Review	96
It seems clear from several of the plots that multiple methods produce identical layer-wise masks, e.g. Fig 3(a), while others show a wide variance.	I-Review	I-1	Review	96
The overlap in lines makes this difficult to assess at times: perhaps a table would communicate it better?	I-Review	I-1	Review	96
Also, are Fig 3-4 depicting the Jaccard distance between masks of unpruned or pruned weights?	I-Review	I-1	Review	96
Is the ordering of training samples fixed in addition to network initialization?	I-Review	I-1	Review	96
Is reinitialization used between iterations?	I-Review	I-1	Review	96
Also, Fig 5 seems to contradict the conclusion that methods tend to learn different masks, since the structures are noticeably similar.	I-Review	I-1	Review	96
<sep> <sep> (2) *Weight stability during pruning*: It is difficult to discern a conclusion in Sec 5.	B-Review	B-2	Review	96
First, a clarification on the figures: are lines for pruned weights terminated where they are pruned?	I-Review	I-2	Review	96
If so, this would be helpful to state.	I-Review	I-2	Review	96
The 4th paragraph claims, "we empirically find a correlation between weight stability and performance", but this is not at all obvious from Figures 6-7.	I-Review	I-2	Review	96
I'm not sure what a more stable evolution looks like.	I-Review	I-2	Review	96
Hybrid is shown to be accurate in Fig 1, but the conv.	I-Review	I-2	Review	96
weights in 6(a) are a spaghetti tangle and the FC weights in 7(a) are constantly increasing in magnitude.	I-Review	I-2	Review	96
Perhaps a mathematical formulation for stability (perhaps based on average standard deviation of each weight's values over training) with a table of values for each method/layer would help to clarify.	I-Review	I-2	Review	96
<sep> <sep> (3) *Organization*: Since the paper has many intertwined observations, a better organization would be helpful.	B-Review	B-3	Review	96
Consider mirroring the structure of Sec 1.1 in a combined Sec.4-5 with clear paragraph headers summarizing each conclusion.	I-Review	I-3	Review	96
<sep> <sep> (4) *Presentation*: Figure is too small throughout to read from a printed copy (or even on a screen without significant zooming).	B-Review	B-4	Review	96
Several results could be presented with less ambiguity in tabular form, as noted above.	I-Review	I-4	Review	96
<sep> <sep> (5) *Replications*: The paper presents results only a single set of experiments using the MNIST dataset with the LeNet architecture.	B-Review	B-5	Review	96
While this isn't a fatal issue, it is a significant weakness.	I-Review	I-5	Review	96
<sep> <sep> *Notes*	O	O	Review	96
Fig 1 and 2: What spacing is used for the x- and y- axes?	B-Review	B-6	Review	96
<sep> Fig 8: Perhaps scale vertically by the standard deviation of the weights?	I-Review	I-6	Review	96
We would like to thank the reviewer for their helpful and detailed comments!	O	O	Reply	96
<sep> <sep> Overall, we thank the reviewer for considering the merits of purely observational work by itself ‚Äî this is critical for moving with a scientific basis of understanding.	B-Reply	B-3	Reply	96
Organizationally we believe that by stating the observations up front in Sec 1.1, we are able to lay out the story of our observations in the manner by which they were uncovered, an ordering and structure we feel to be more natural (related to point 3).	I-Reply	I-3	Reply	96
<sep> <sep> We will answer and respond to specific questions/comments:	O	O	Reply	96
<sep> (1) No method produces identical layer-wise masks to another, unless the layer is too small to be pruned at all (see conv1 for structured pruning).	B-Reply	B-1	Reply	96
In all other cases, the line at distance = 0 is the baseline, and it's shown for sanity check.	I-Reply	I-1	Reply	96
<sep> We believe that the graphical form is useful from an evolution standpoint ‚Äî we note the curvature for the Jaccard distance when plotted against the pruning iteration is directly insightful.	I-Reply	I-1	Reply	96
We agree that perhaps this visualization is not perfect, but, when representing it in a table, we found the information even harder to process and engage with, without immediate visual assistance.	I-Reply	I-1	Reply	96
‚Ä®As the captions and plot labels clearly state, the Jaccard distance is computed between masks, not weights.	I-Reply	I-1	Reply	96
‚Ä®The ordering of training samples is fixed (on top of the initialization).	I-Reply	I-1	Reply	96
We tried to be as thorough as possible to control for any type of confounding factors and sources of variability that would not be directly caused by the effect we were trying to measure, i.e. the role of the pruning method.	I-Reply	I-1	Reply	96
‚Ä®As per the lottery ticket procedure, and as we had hinted at in Sec.3.2, lottery tickets are searched for using rewinding to the initial weight values.	I-Reply	I-1	Reply	96
Again, at first, to be able to focus in on the role of the choice of pruning technique, we conducted our experiments without varying any of the other knobs (the choice of reinitialization strategy being one of them).	I-Reply	I-1	Reply	96
We did explore that dimension of variation as well, though, in the experiments in Appendix A. We did realize, thanks to your question, that Sec.3.2 was not entirely clear about this point, so we slightly modified the language there.	I-Reply	I-1	Reply	96
‚Ä®In Figure 5, columns 2, 3, and 4 all use the same pruning technique (the difference here is only the reinitialization technique).	I-Reply	I-1	Reply	96
The meaningful comparison is between column 1 and 2.	I-Reply	I-1	Reply	96
Indeed, in the case of this specific seed and due to the very small size of the conv1 layer in LeNet, the masks do end up looking similar.	I-Reply	I-1	Reply	96
For other seeds, instead, for example, although unstructured pruning continues to show structured-like patterns, the channels that end up getting pruned are _not_ the same ones that L1-structured pruning prunes.	I-Reply	I-1	Reply	96
The per-layer distances are even more striking in larger, non-convolutional layers.	I-Reply	I-1	Reply	96
‚Ä®	I-Reply	I-1	Reply	96
(2) Yes, lines for pruned weights terminated where they are pruned; we now state that more clearly.	B-Reply	B-2	Reply	96
The point of this section ("we empirically find a correlation between weight stability and performance") is made clearer when also considering the performance plot in Fig 1.	I-Reply	I-2	Reply	96
We have added a note that makes this point clearer, also encouraging the reader to look at Fig 1 for a reminder.	I-Reply	I-2	Reply	96
Regarding your later points, although we note that the evolution looks quite tangled in 6(a), in fact the weight magnitude per weight is not changing drastically from iteration to iteration and, more important, there doesn't seem to be much crossing from negative to positive, which had been identified in previous work as potentially key to the formation of lottery tickets.	I-Reply	I-2	Reply	96
The same holds for 7(a), as from iteration to iteration there is little noise.	I-Reply	I-2	Reply	96
We include a definition of stability and show the results you hint at in Figure 8 (see y-label).	I-Reply	I-2	Reply	96
If the reviewers believe that Figure 8 is sufficient to illustrate the point and Figs 6-7 only confuse the reader, we'd be happy to remove them.	I-Reply	I-2	Reply	96
<sep> <sep> (5) We present results on LeNet+MNIST for ease of interpretation ‚Äî many of the phenomena we document here are difficult to reason about in larger models (though we agree that this will be very important in the future!).	B-Reply	B-5	Reply	96
Our extended results (contained in the appendix) confirm some critical observations on larger scale models.	I-Reply	I-5	Reply	96
We believe that large experiments would detract from the main points of the work at this time, and is welcome future work.	I-Reply	I-5	Reply	96
It is known, as stated in the text, that lottery tickets are harder to find in larger domains and require the introduction of tricks that would introduce confounders in our experiments and invalidate the experimental setup.	I-Reply	I-5	Reply	96
<sep> <sep> Notes:	O	O	Reply	96
<sep> - The axes for Fig 1 and 2 use the "logit" scale setting in matplotlib.	B-Reply	B-6	Reply	96
We found this to be the most appealing representation for the data we were plotting.	I-Reply	I-6	Reply	96
<sep> - Scaling by the std deviation in this case does not change the comparative argument between methods, and we believe it would make the metric/value harder to reason about.	I-Reply	I-6	Reply	96

This paper study the lottery ticket hypothesis by observing the properties of lottery tickets.	O	O	Review	96
In particular, the authors tested several different pruning techniques by varying evaluation criteria (L_1, L_2, L_-\infty and random) and pruning structures (structured, unstructured and hybrid).	O	O	Review	96
The authors perform experiments mainly on LeNet with the MNIST dataset and analyze the observations.	O	O	Review	96
<sep> <sep> Overall, I think that the observations presented in the paper are not significant due to the following reasons.	O	O	Review	96
<sep> <sep> First, the paper consists of the list of observations but how the observations extend to is not clearly described.	B-Review	B-2	Review	96
There are no guidelines how to utilize the observations in future research (e.g., how they can be used for verifying the lottery ticket hypothesis or how they affect to existing pruning techniques) while some observations might be trivial or not very interesting (e.g., contribution 1 and contribution 2) for me.	I-Review	I-2	Review	96
<sep> <sep> Second, the observations are only presented for LeNet and MNIST and it is non-trivial whether they extend to large scale models.	B-Review	B-3	Review	96
The authors present VGG11 and AlexNet results in Appendix but they are not large enough to verify their hypothesis for practice.	I-Review	I-3	Review	96
The authors mentioned that larger models are not their subject, but this significantly reduces the confidence of the observations.	I-Review	I-3	Review	96
<sep> <sep> Other comments:	O	O	Review	96
I think that Figure 5 is not well described.	B-Review	B-1	Review	96
Explicitly noting the meaning of color in the figure would be better.	I-Review	I-1	Review	96
<sep> <sep> Texts in Figure 7 are too small to read.	I-Review	I-1	Review	96
<sep> <sep> First of all, thank you for your comments.	O	O	Reply	96
<sep> <sep> We would like to offer our point of view for why we disagree with the notion that the contributions and observations presented here are not interesting to the field.	B-Reply	B-2	Reply	96
We agree that perhaps these approaches cannot directly be utilized at the moment to help reach SoTA on a given task.	I-Reply	I-2	Reply	96
This utilitarian way of evaluating the contribution is at odds with the stated goal of the paper, which is to simply advance fundamental knowledge in the subdomain of science of deep learning.	I-Reply	I-2	Reply	96
Many of the findings in this paper directly go to address major open questions around the nature and emergence of lottery tickets, including observations #1 and #2, which we therefore deem to be interesting and relevant to the field (or at least to those doing research in this sub-field).	I-Reply	I-2	Reply	96
Objections to the absence of these studies have been raised in the community in the past to challenge the lottery ticket hypothesis itself.	I-Reply	I-2	Reply	96
To the best of the authors knowledge, a thorough study of structure characterization of lottery tickets emerging from a multitude of pruning methods is itself of interest to better begin to understand more about this emergent behavior and move towards principled approaches to lottery ticket discovery.	I-Reply	I-2	Reply	96
<sep> <sep> In addition, we disagree that observations on small models are not significant.	B-Reply	B-3	Reply	96
If we are to understand the dynamics of what is happening in pruned models, under the lottery ticket hypothesis or any other hypothesis, we need to remove factors of variation introduced by SoTA seeking architectures.	I-Reply	I-3	Reply	96
Even in the case where dynamics discovered in small networks do not apply to a large, say, ResNeXt or NasNet, that alone is interesting future work and important to understand and document.	I-Reply	I-3	Reply	96
We do agree that confirmatory experiments in larger more complex domains would be a useful extension of this work, but not a necessary one to make these empirical discoveries worthwhile.	I-Reply	I-3	Reply	96
<sep> While we agree that it is non-trivial to extend lottery tickets to larger models (as is well documented in the literature) we believe that understanding why and when lottery tickets emerge in smaller models will help us better apply them to larger models in the future.	I-Reply	I-3	Reply	96
<sep> <sep> As per your direct comments, we have improved the description of Fig.5. ‚	B-Reply	B-1	Reply	96
Ä®The caption on Figure 7 already contains all the necessary information to decipher what the axes in the subplots represent (the numerical values are not important and the axes could be entirely removed in favor of simply showing the qualitative trend).	I-Reply	I-1	Reply	96

There are major problems with this paper.	O	O	Review	96
It is concerned with the examination of pruning experiments for a LeNet on the MNIST dataset.	B-Review	B-1	Review	96
I fail to see how anything useful can be derived from this, as MNIST is a completely trivial dataset and LeNet is a very old, small architecture which does not at all resemble the massive overparameterised models that we care about.	I-Review	I-1	Review	96
<sep> <sep> From a narrative perspective, I am not sure what the key point is, what should the reader take home?	B-Review	B-2	Review	96
What should they take account of when performing network pruning?	I-Review	I-2	Review	96
<sep> <sep> In terms of presentation, some of the figures are unreadable (figure 4).	B-Review	B-3	Review	96
Figure 15 looks like noise.	I-Review	I-3	Review	96
The writing is good however, if a bit grandiloquent.	I-Review	I-3	Review	96
<sep> <sep> I dislike writing short reviews, but I fear this paper falls too far short of ICLR standard.	B-Review	B-5	Review	96
<sep> <sep> Pros:	O	O	Review	96
- Well written	O	O	Review	96
<sep> Cons:	O	O	Review	96
- Experiments are weak	B-Review	B-1	Review	96
- Unclear narrative; what's the one key message?	B-Review	B-2	Review	96
<sep> <sep> I have to give this paper a reject as the experiments conducted are far too weak, and there is little evidence anything found here will, say, generalise to a ResNet/DenseNet on ImageNet.	B-Review	B-1	Review	96
<sep> <sep> <sep> Thank you for reading our contribution.	O	O	Reply	96
<sep> <sep> We would like to invite the reviewer to consider the strength and extent of experimentation performed in this paper by moving beyond the assessment of the choice of dataset and model.	B-Reply	B-1	Reply	96
While we agree that one shouldn't claim that a proposed architecture achieves SoTA on "solved" (?)	I-Reply	I-1	Reply	96
problems like MNIST, we would like to point out that the goal of this work is, in fact, _not_ to propose a model modification and use MNIST as a simple testbed to validate the performance (which we agree would be inconclusive).	I-Reply	I-1	Reply	96
We maintain that MNIST is still an excellent dataset to study learning dynamics, weight co-adaptation, and deep phenomena in neural networks that we, as a field, are still far from understanding.	I-Reply	I-1	Reply	96
We don't believe it advantageous to study these fundamental properties of neural networks (seen as physical objects with complex, perhaps chaotic dynamics) in large, complicated regimes and architectures when the simplest of cases (like MNIST with LeNet) is still just as poorly understood from the standpoint of the research being conducted in this paper (which, again, is not performance-oriented, with performance, instead, being a very well studied and thoroughly investigated property of this specific task).	I-Reply	I-1	Reply	96
<sep> ‚Ä®We have performed a sensible search over pruning approaches of interest, and have documented nearly every decision along the way.	I-Reply	I-1	Reply	96
We would like to encourage the reviewer to reconsider this point ‚Äî scientific understanding of deep learning in its fundamental form will  need exhaustive experimental observation, and observational experiments are not definitionally weak.	I-Reply	I-1	Reply	96
<sep> <sep> We believe the contributions main points are made very clear in section 1.1, titled contributions.	B-Reply	B-4	Reply	96
We believe some of these are *directly* useful, such as #5 and #6, where #6 may help guide us towards designing stability induced procedures that may help with lottery tickets in larger models.	I-Reply	I-4	Reply	96
<sep> <sep> Finally, observations on the small model-small dataset regime are incredibly important if we are to understand the minimum setting for these methods and approaches to work.	I-Reply	I-4	Reply	96
We aim to shed light on some as-of-yet undocumented behaviors, and now the natural next step is to consider why they do or do not work in the large scale setting.	I-Reply	I-4	Reply	96
We strongly emphasize that the purpose of this work is understanding, and we encourage the reviewer to reconsider the value of scientific, observational work rather than work that seeks to add modifications.	I-Reply	I-4	Reply	96

Summary:	O	O	Review	96
This paper describes a new method for Pseudo-Lidar, that is the reliable recovery of a 3D point cloud from 2D inputs and subsequent detection of 3D objects from the point cloud.	O	O	Review	96
The authors focus on improving the accuracy of the reconstructed point cloud by formulating a loss in depth, rather than disparity space, and by using sparse true lidar readings to align estimates.	O	O	Review	96
These techniques lead to a boost in 3D object detection performance.	O	O	Review	96
<sep> <sep> Strengths:	O	O	Review	96
The Pseudo-Lidar method has been well-received, and it appears that this paper makes a nice improvement on the previous in terms of 3D point cloud accuracy.	O	O	Review	96
While the image results here are convincing, I would have liked to see an added empirical evaluation of precisely how accurate the resulting 3D reconstructions are, measured against ground truth 3D lidar on a test set.	B-Review	B-1	Review	96
Do the point clouds only look accurate locally (and perhaps near known objects give good shape due to regularity), or are the metric results also quite strong indeed?	I-Review	I-1	Review	96
<sep> <sep> I found the author's technical analysis and method description to be clear and well-motivated.	O	O	Review	96
None of the math or formulations are entirely surprising, but they are new to this area, so this appeared as nice sensible progress to me.	O	O	Review	96
<sep> <sep> This area is closely tied to the self-driving car application, and thus bottom-line performance is the key measuring stick for impact on practitioners.	B-Review	B-2	Review	96
For 3D object detection, the main goal of interest, the authors show up to 20% improvements for their combined method over quite recent and strong PL methods (although the new method uses sparse lidar, which is a great advantage, hence not entirely equal comparison).	I-Review	I-2	Review	96
This is the main impact of the paper, as I see it, and enough reason for acceptance.	I-Review	I-2	Review	96
<sep> <sep> Areas for Improvement:	O	O	Review	96
I found that the authors did not sufficiently recognize that there have been a wide variety of methods utilizing sparse 3D along with dense 2D images to interpolate to full 3D. For example, [A] is one I recall well from 15 years back, but at that time there was a strong community in this area, so I encourage the authors to do a bit more thorough review.	B-Review	B-3	Review	96
<sep> <sep> This paper has the fewest qualitative examples of 3D objects detected among the recent papers I've read.	B-Review	B-4	Review	96
The final pages of the Appendix contain a few more of these visuals, but there are too few in the main paper for the reader to get any intuitive feeling of the physical meaning of your performance improvement.	I-Review	I-4	Review	96
I'd like to see you add several examples, even if small, into the paper to aid in this understanding.	I-Review	I-4	Review	96
<sep> <sep> Decision: weak accept due to the nice clear method that gives a strong improvement on an important area to industry today.	O	O	Review	96
<sep> <sep> [A] Statistical Inference and Synthesis in the Image Domain for Mobile Robot Environment Modeling, Luz Abril Torres-M√©ndez and Gregory Dudek.	O	O	Review	96
In Proceedings of the IEEEE/RSJ/GI International Conference on Intelligent Robots and Systems (IROS), Sendai, Japan, 2004.	O	O	Review	96
1. [	O	O	Reply	96
empirical evaluation of 3D reconstructions] Thanks for your question.	B-Reply	B-1	Reply	96
The point clouds are surprisingly accurate even for points quite far from the 4 laser beams.	I-Reply	I-1	Reply	96
You can see this to some degree in Figure 4 of the main paper and Table 11 of the appendix.	I-Reply	I-1	Reply	96
Here, we consider LiDAR points originating from beams beside the selected 4 beams as ground-truth and report the difference between predicted depth and the LiDAR estimates.	I-Reply	I-1	Reply	96
Some of these beams are quite far from the selected 4.	I-Reply	I-1	Reply	96
SDN+GDC achieves the lowest depth estimation error, followed by SDN and then the vanilla disparity-based PSMNet.	I-Reply	I-1	Reply	96
We will highlight this in the final version and add a special table that summarizes the error as a function of distance from the closest LiDAR point.	I-Reply	I-1	Reply	96
<sep> <sep> 2. [	O	O	Reply	96
literature of depth completion] We thank the reviewer for the comment and the reference.	O	O	Reply	96
We will include further discussions with regard to [Torres-M√©ndez and Dudek, 2004], which uses MRFs and may thus require less (or even no) training data compared to deep learning algorithms: a property shared by GDC.	B-Reply	B-3	Reply	96
In Figure 7 and Table 9, we compare our GDC method with PnP, which is a depth completion method proposed recently and can be applied to stereo images.	I-Reply	I-3	Reply	96
We will try to add additional comparisons and delve deeper into more classical techniques and include more details in the final version.	I-Reply	I-3	Reply	96
<sep> <sep> 3. [	O	O	Reply	96
More qualitative results] Thanks for the suggestion, we have updated two more qualitative results in the appendix of the current revised version.	B-Reply	B-4	Reply	96
We will add more qualitative results in the appendix or even in the main paper if we can create space.	I-Reply	I-4	Reply	96

The paper proposes to improve the idea of using stereo&nbsp;+ lidar -style object detection to form stereo-based 3D object detection, building off of pseudo-lidar.	O	O	Review	96
In particular, it proposes to (a) switch the loss function for stereo deep networks from disparity to depth (b) do the stereo cost volume analysis in a depth volume (via resampling) rather than disparity volume and (c) if sparse lidar is available, align the estimated depth with the sparse lidar.	O	O	Review	96
Each seems to improve results, and the resulting&nbsp;system&nbsp;achieves good results&nbsp;on KITTI and outperforms past work in this area.	O	O	Review	96
<sep> <sep> Positives:	O	O	Review	96
+The paper proposes three ideas that seem good and lead to improvements that are demonstrated empirically.	O	O	Review	96
<sep> +The paper is well written&nbsp;	O	O	Review	96
+The experiments are exceptionally thorough	O	O	Review	96
+The ideas seems to me to be of obvious importance, although I realize that I'm likely not qualified to make a statement about this, and this should perhaps be done by a roboticist.&nbsp;	O	O	Review	96
<sep> Negatives:	O	O	Review	96
-Most of the heavy lifting in the case without sparse LIDAR is done by tweaking the loss function rather than the cost, although the remaining gain is still pretty good	B-Review	B-1	Review	96
-I am not sure if this is a negative, but this is really a 3D vision paper.	B-Review	B-2	Review	96
I do some form of 3D vision, but I really don't feel confident about my ability to assess whether doing stereo matching in a depth cost volume as opposed to disparity is correct -- I really haven't worked on stereo.	I-Review	I-2	Review	96
It seems to work well, but I feel as if the wrong people are being asked to review the paper.	I-Review	I-2	Review	96
I leave questions of venue to the area chair though.	I-Review	I-2	Review	96
<sep> <sep> Overall, I am inclined to accept the paper.	O	O	Review	96
I am a tiny bit worried about venue and whether the right people will check the work, but I don't think this should be decided by reviewers.	O	O	Review	96
However, I think the experiments are quite thorough and the paper is clearly above the bar.	O	O	Review	96
<sep> <sep> In more detail:	O	O	Review	96
<sep> Method:	O	O	Review	96
+The method reads quite well and the idea is clean.	O	O	Review	96
I particularly like the graph-based depth correction algorithm, and the LLE-like way of adjusting the estimated depthmap.	B-Review	B-3	Review	96
I have a few small comments below that do not affect my judgment, but I think would improve the paper.	I-Review	I-3	Review	96
<sep> = Small thought: the words systematic bias throughout is primarily referring to a bias for a particular object as opposed to a bias of the system (i.e., any individual object is too far or too close).	I-Review	I-3	Review	96
This seems non-standard to me.	I-Review	I-3	Review	96
A systematic bias would be that everything's too far away by 1m for instance.	I-Review	I-3	Review	96
<sep> <sep> Experiments:	O	O	Review	96
+The experiments are exceptionally thorough, and of my pile of ICLR papers, this by far has the most thorough and well-thought-out experimental analysis.	O	O	Review	96
<sep> +The system shows systematic improvements on 3 different LIDAR-based object detection systems; I think this is great.	O	O	Review	96
<sep> =I'm not sure whether the 64-beam LIDAR can be subsampled to imitate 4-beam LIDAR.	B-Review	B-4	Review	96
I simply don't know enough about the hardware to know if this is a sensible approximation.&nbsp;	I-Review	I-4	Review	96
-Table 3 primarily suggests that the vast majority of the hard work in the non-sparse LIDAR is done by the depth loss rather than the depth cost volume.	B-Review	B-6	Review	96
The resulting change is still pretty good (although I suspect that if you stuck in a coordconv in the disparity cost volume, it would handle the fact that you want unequal smoothing).	I-Review	I-6	Review	96
<sep> -The burial of the results on depth prediction results in the appendix with one is a little surprising as is the solitary table on it, but I understand the need to focus on 3D detection.	O	O	Review	96
<sep> <sep> Small stuff that doesn't affect my review:	B-Review	B-5	Review	96
1) Framing the problem as having ethical considerations is, in my view, not necessary -- should all network compression papers start arguing that it is of profound ethical importance to figure out your bit quantization?&nbsp;	I-Review	I-5	Review	96
2) Last paragraph above Section 4 "gird" -&gt; "Grid"	I-Review	I-5	Review	96
3) Figure 3 caption "pruple" -&gt; "purple"	I-Review	I-5	Review	96
4) Figure 4 is suboptimal -- I assume SDN+GDC &lt; SDN &lt; Disparity Net, but this is hard to verify.	I-Review	I-5	Review	96
<sep> 5) Calling the network "Disparity Net" is a bit of an issue given that there's DispNet already&nbsp;	I-Review	I-5	Review	96
6) "Figure 1 illustrates beautifully how" -&gt; Please don't editorialize like this	I-Review	I-5	Review	96
<sep> -----------------------	O	O	Review	96
<sep> Post rebuttal update: I have read the rebuttal and maintain my belief that the paper should be accepted.	O	O	Review	96
1. [	O	O	Reply	96
Depth cost volume] We would like to point out that the gain depends on the 3D detector in use.	B-Reply	B-1	Reply	96
Table 3 suggests that the depth loss provides more gain than the depth cost volume (for PointRCNN).	I-Reply	I-1	Reply	96
In Table 6, we, however, see that the depth cost volume provides comparable or even bigger gain than the depth loss (for PIXOR and AVOD).	I-Reply	I-1	Reply	96
Nevertheless, Table 3 and Table 6 both suggest the compatibility of the two approaches: combining them leads to the best performance.	I-Reply	I-1	Reply	96
Applying coordconv is an interesting idea, and if it works, it also supports our claim that smoothing the disparity cost volume with conventional convolutions is inappropriate for depth estimation.	I-Reply	I-1	Reply	96
<sep> <sep> 2. [	O	O	Reply	96
Other comments] We thank the reviewer for pointing out the typos, which we will correct.	B-Reply	B-5	Reply	96
We will also search for a better alternative for "Disparity Net" to contrast ‚ÄúStereo Depth Net‚Äù, or clearly indicate that it is not DispNet.	I-Reply	I-5	Reply	96
We will try to use different colors to clarify Figure 4.	I-Reply	I-5	Reply	96
We note that Table 11 provides the error values for Figure 4 and we will clearly mention it in the main paper.	I-Reply	I-5	Reply	96
Section D.3 and Figure 7 also discuss and compare our GDC algorithm to depth completion in terms of the depth estimation error.	I-Reply	I-5	Reply	96

The paper proposes two extensions to the recent work of (Wang et al 2019) on 3D object detection with pseudo LiDAR data.	O	O	Review	96
Wang et al showed that 3D object detection using stereo images as inputs can be significantly improved if the depth map is projected to 3D and treated like a LiDAR point cloud (i.e., using methods that utilize the LiDAR point cloud).	O	O	Review	96
This paper shows that one shortcoming of this approach is given by the fact that the depth uncertainty increases the farther the objects are away.	O	O	Review	96
To remedy this, the authors propose to train the stereo estimation network (based on Chang &amp; Chen, 2018) directly with depth outputs, instead of disparity values (inverse depth), by rewriting the loss and converting the cost volume.	O	O	Review	96
This already boosts the performance for far away objects.	O	O	Review	96
The authors demonstrate that the usage of a (simulated) low-cost 4-beam LiDAR can further facilitate the detection.	O	O	Review	96
For this purpose a graph diffusion algorithm is listed that aligns the pseudo LiDAR point cloud from the stereo set-up with the depth estimates from the low-cost LiDAR.	O	O	Review	96
Simulating the low-cost LiDAR on the Kitti benchmarks shows that this approach further increases the performance of the object detection methods.	O	O	Review	96
<sep> <sep> In general, I am in favour of accepting the paper as it shows two orthogonal and interesting additions to the pseudo LiDAR paper of Wang et al that improve its performance.	O	O	Review	96
However, I would like to see some clarifications in the rebuttal.	O	O	Review	96
<sep> <sep> The proposed stereo network converts a disparity cost volume to a depth cost volume using bilinear interpolation.	O	O	Review	96
I agree, that the 3D convolutions are more meaningful (given the spacing of the grid cells) on the latter, but why the detour over the disparity cost volume?	B-Review	B-1	Review	96
It should be possible to build the depth cost volume directly, which would lead to decreased memory consumption and speed up the method without any loss in accuracy?	I-Review	I-1	Review	96
<sep> <sep> One assumption of the second contribution (GDC) is that at least one beam of the LiDAR will hit the k-connected local point cloud.	B-Review	B-2	Review	96
Can you give some bounds on the likelihood that this happens, especially for far away objects it could be unlikely, although it is most beneficial for those objects.	I-Review	I-2	Review	96
<sep> Further, I am missing a details on the optimization of (7) and (8).	B-Review	B-3	Review	96
What is meant with slight L2 regularization?	B-Review	B-4	Review	96
In the appendix it is also stated that a slightly different objective is optimized?	I-Review	I-4	Review	96
<sep> Finally, the notation could also be improved.	B-Review	B-3	Review	96
The authors are using L and G for the LiDAR point cloud and PL and Z for the pseudo LiDAR point cloud and then in the Z' is used for both.	I-Review	I-3	Review	96
<sep> <sep> Fig.4 shows the median error in meters for the different variants of the stereo network.	B-Review	B-5	Review	96
Why has the median been used?	I-Review	I-5	Review	96
Are there severe outliers?	I-Review	I-5	Review	96
If yes, it would also be interesting to quantify those and compare them (e.g., box plots).	I-Review	I-5	Review	96
<sep> <sep> In the abstract and in the discussion the authors oversell their results a bit.	B-Review	B-6	Review	96
At the one hand they state that PL++ with GDC performs significantly better than PL++ w/o GDC, on the other hand they also claim that PL++ achieves comparable results to models that have access to the full 64-beam LiDAR data.	I-Review	I-6	Review	96
However, if you compare the differences, then the gaps are for several cases almost as big, or bigger as in the former claim.	I-Review	I-6	Review	96
<sep> <sep> Things to improve the paper that did not impact the score:	B-Review	B-7	Review	96
- In equation (2) you could replace the x with a . (	I-Review	I-7	Review	96
\cdot), or completely remove it	I-Review	I-7	Review	96
- On page 5: KNN neighbors -&gt; k-nearest neighbors	I-Review	I-7	Review	96
- Also on page 5: write out W.l.o.g.	I-Review	I-7	Review	96
<sep> - In Tab.1 it would help to highlight (bold) the best entries per column	I-Review	I-7	Review	96
1.[detour over the disparity cost volume] Thanks for pointing this out.	B-Reply	B-1	Reply	96
It is definitely possible to construct the depth cost volume directly, however constructing the disparity cost volume brings us simplicity in implementation and efficiency through utilizing matrix operations.	I-Reply	I-1	Reply	96
Although it does require some additional GPU memory, it is on the order of a few hundred megabytes.	I-Reply	I-1	Reply	96
In terms of computation, the most costly part of the depth estimation model is 3D convolutions on the depth cost volume.	I-Reply	I-1	Reply	96
In comparison, the memory and computation cost of constructing the disparity cost volume first is quite small.	I-Reply	I-1	Reply	96
<sep> <sep> 2.[analysis on GDC] Thanks for mentioning your concern about GDC with regards to lasers missing connected components.	B-Reply	B-2	Reply	96
In practice, we have not observed that this is a problem, in part because the pseudo-Lidar point cloud is sufficiently dense, and we choose k to be large enough (k=10) that the graph is typically connected (or consists of few large connected components).	I-Reply	I-2	Reply	96
We will add a more detailed discussion in the final paper about this issue and provide empirical numbers for various values of k.	I-Reply	I-2	Reply	96
<sep> 3. [	O	O	Reply	96
notation and optimization on equation (7) and (8)] Thanks for pointing out the notational collisions, we will correct these in the final version.	B-Reply	B-3	Reply	96
<sep> <sep> 4. [	O	O	Reply	96
L2-regularization] The first step of GDC, i.e., equation (7), is an under-constrained problem, with infinitely many solutions.	B-Reply	B-4	Reply	96
To identify a single solution, we add a small L2 regularization term to the objective (main paper).	I-Reply	I-4	Reply	96
In the appendix, we switch the objective with the constraints by minimizing the L2-norm of W and set Z-WZ=0 as a constraint.	I-Reply	I-4	Reply	96
These two problems yield identical solutions but we found the first formulation easier to explain (i.e., adding a regularizer to equation (7)) while the second one is easier to solve in practice.	I-Reply	I-4	Reply	96
We apologize for the confusion and will clarify our description in the final version.	I-Reply	I-4	Reply	96
<sep> <sep> 5.[median error] Thanks for the suggestion.	O	O	Reply	96
We re-evaluate depth estimation with mean error and find that it is larger than the median error, which likely results from outliers such as occluded pixels around object boundaries.	B-Reply	B-5	Reply	96
We list the mean error and the standard deviation below.	I-Reply	I-5	Reply	96
SDN+GDC still achieves the lowest mean error (except for 0-10 meters), followed by SDN and then the vanilla disparity-based PSMNet.	I-Reply	I-5	Reply	96
We will include a more detailed box-plot graph in the final version.	I-Reply	I-5	Reply	96
<sep> mean\range  0-10   10-20   20-30   30-40   40-50   50-60   60-70	I-Reply	I-5	Reply	96
PL         0.176   0.359   0.967   2.023   2.936   4.611   6.025	I-Reply	I-5	Reply	96
SDN        0.212   0.352   0.865   1.799   2.668   4.272   5.824	I-Reply	I-5	Reply	96
SDN+GDC    0.209   0.345   0.842   1.744   2.590   4.137   5.721	I-Reply	I-5	Reply	96
<sep> std\range   0-10   10-20   20-30   30-40   40-50   50-60   60-70	I-Reply	I-5	Reply	96
PL         0.929   1.200   2.320   4.049   5.641   8.034   10.317	I-Reply	I-5	Reply	96
SDN        0.894   1.157   2.310   4.218   6.004   8.776   11.232	I-Reply	I-5	Reply	96
SDN+GDC    0.897   1.167   2.338   4.266   6.058   8.852   11.293	I-Reply	I-5	Reply	96
<sep> 6.[Overselling results] We apologize; we did not mean to oversell our results.	B-Reply	B-6	Reply	96
This is an unfortunate naming conflict.	I-Reply	I-6	Reply	96
In the abstract, by PL++ we mean SDN+GDC, while in Table 1, we separate SDN and GDC for analysis but still call them both PL++.	I-Reply	I-6	Reply	96
With SDN+GDC, our model can achieve comparable results to models that have access to the full 64-beam LiDAR data on some of the metrics (as mentioned in section 5.2 and the introduction).	I-Reply	I-6	Reply	96
We will clarify this in the final version.	I-Reply	I-6	Reply	96

<sep> This paper proposes to adapt RL agents from some set of training environments (which, in the current instantiation, vary in some simple respect) to a new domain.	O	O	Review	143
They build on a framework for model-based RL called PETS.	O	O	Review	143
<sep> <sep> The approach goes as follows:	O	O	Review	143
<sep> 2-step process	O	O	Review	143
* train probabilistic model-based RL agents in a ‚Äúpopulation of source domains‚Äù	O	O	Review	143
* dropped into new environment use ‚Äúpessimistic exploration policy‚Äù	O	O	Review	143
<sep> Then at test time, in order to compute estimates for the rewards for each action the authors use a ‚Äúparticle propagation‚Äù technique for unrolling through their dynamics model .	O	O	Review	143
<sep> <sep> The action is chosen by looking at the sum of the 0 through kth percentile rewards.	B-Review	B-1	Review	143
<sep> This is a weird choice.	I-Review	I-1	Review	143
Why are they looking at a sum over quantiles vs a quantile itself?	I-Review	I-1	Review	143
<sep> <sep> The claim is that the models from the first stage capture the epistemic uncertainty due to not knowing z.	B-Review	B-2	Review	143
However, the authors give a too scant a treatment of what these uncertainty estimates really mean.	I-Review	I-2	Review	143
<sep> For example, they appear to only be valid with respect to an assumed distribution over z.	I-Review	I-2	Review	143
The paper‚Äôs experiments however focus in large part on what happens when the model is evaluated	I-Review	I-2	Review	143
on values of z that were outside the support of the distribution over training domains.	I-Review	I-2	Review	143
<sep> In this case, any benefit appears to be ill explained by the underlying motivation.	I-Review	I-2	Review	143
<sep> <sep> <sep> The next step here is to finetune the model as data is collected on the new domain.	O	O	Review	143
<sep> <sep> Authors propose heuristics for this finetuning that include	O	O	Review	143
1.	O	O	Review	143
Drawing experiences from the past experiences (under different domains) and	O	O	Review	143
2. ‚	O	O	Review	143
Äúkeeping the model close to the original model‚Äù, via some sort of regularization presumably.	O	O	Review	143
<sep> <sep> &gt;&gt;&gt; <tab>why isn‚Äôt the exact nature of how they ‚Äúkeep the model near the original model explained in the text?	B-Review	B-3	Review	143
<sep> <tab>perhaps the authors mean that 1.	I-Review	I-3	Review	143
and 2.	I-Review	I-3	Review	143
are one and the same (1 as  means to achieve 2)	I-Review	I-3	Review	143
<tab>if this is the case, then the exposition should be improved to make this more clear.	I-Review	I-3	Review	143
<sep> <sep> <sep> Some important details appear to be missing.	B-Review	B-4	Review	143
For example, how many distinct source domains are seen during pretraining?	I-Review	I-4	Review	143
Do they set z different z for every single episode of pretraining?	I-Review	I-4	Review	143
Some language here is unclear, for example what precisely does an ‚Äúiteration‚Äù mean in the context of the experiments?	I-Review	I-4	Review	143
<sep> <sep> The choice to report ‚Äúaverage maximum reward‚Äù seems strange if what the authors care about is avoiding risk.	B-Review	B-5	Review	143
Can they explain/justify this choice or if not, present a much more comprehensive set of experimental results?	I-Review	I-5	Review	143
<sep> <sep> The figures tracking catastrophic failures vs performance resembles those in	B-Review	B-6	Review	143
‚ÄúCombating Reinforcement Learning's Sisyphean Curse with Intrinsic Fear‚Äù  <a href="https://arxiv.org/abs/1611.01211" target="_blank" rel="nofollow">https://arxiv.org/abs/1611.01211</a>	I-Review	I-6	Review	143
This raises some question about why they don‚Äôt if concerned with ‚Äúcatastrophic events‚Äù model them more explicitly.	I-Review	I-6	Review	143
<sep> Else, if the return accurately captures all desiderata, why to we need to count the failures?	I-Review	I-6	Review	143
<sep> <sep> In short this is a simpzle empirical paper that makes use of heuristic uncertainty estimates,	O	O	Review	143
including in settings when the estimates have no validity.	O	O	Review	143
The writing is reasonably clear	O	O	Review	143
and the ideas are straightforward (which is perfectly fine!).	O	O	Review	143
A few of the decisions are unnatural,	O	O	Review	143
a few are ad hoc, and a few details are missing.	O	O	Review	143
Overall my sense is that this paper	O	O	Review	143
has some good qualitities, including the clarity of much of the exposition,	O	O	Review	143
but it‚Äôs still below the mark to be an impactful ICLR paper.	O	O	Review	143
<sep> <sep> ==========UPDATE=================	O	O	Review	143
I read the rebuttal and am glad that the authors took time to read my review and engage with the criticism as well as try to make some small improvements to the paper, especially exploring the impact on the number of training environments on the results (in the original paper the number of environments available at train time was unlimited).	O	O	Review	143
The answers to some of the other questions were less convincing.	B-Review	B-1	Review	143
E.g. the seemingly incoherent objective of summing over the quantiles falls flat.	I-Review	I-1	Review	143
Why should we care more about being a "strict generalization" of some previous algorithm built upon than of having a coherent objective?	I-Review	I-1	Review	143
Overall, I don't think the paper makes it over the bar to accept but I hope the authors continue to improve upon the work and get it into shape where it could be accepted at another strong conference.	O	O	Review	143
Thank you for this thoughtful review.	O	O	Reply	143
<sep> <sep> === ‚ÄúWhat do the uncertainty estimates really mean?	O	O	Reply	143
Do they really capture epistemic uncertainty due to not knowing z?‚Äù ===	O	O	Reply	143
Thank you.	O	O	Reply	143
We have now added visualizations in Sec 5 (particularly Fig 5)  that show the predicted trajectories from our model for a fixed action sequence, and show how it captures the various possible behaviors among car widths encountered in the training data.	B-Reply	B-2	Reply	143
This provides an empirical validation that the model is indeed able to capture the uncertainty due to unknown car width z. We also include an Appendix B (Fig 7) showing how the model predictions improve during pretraining time until it converges to approximately correctly model the epistemic uncertainty.	I-Reply	I-2	Reply	143
<sep> <sep> === ‚Äúz different for each episode at training?‚Äù ===	O	O	Reply	143
Yes, for the results reported in the paper, we did sample z uniformly at random over the training distribution at the beginning of each episode.	B-Reply	B-4	Reply	143
We have now added additional results in an appendix showing how RADA performance evolves as a function of the number of available pretraining environments.	I-Reply	I-4	Reply	143
In particular, we sample a fixed number (2/5/10) of car widths before pretraining and sample uniformly from those during pretraining.	I-Reply	I-4	Reply	143
Our results indicate that there are significant gains in performance (both reward as well as collision safety) from 2 to 5 to 10.	I-Reply	I-4	Reply	143
At 10 fixed car widths, results are similar to those originally reported in the paper.	I-Reply	I-4	Reply	143
<sep> <sep> === The review points out that while we propose RADA for safe adaptation to new domains, it still builds on probabilistic models that were learned on training domains, which might perform poorly in unseen domains.	O	O	Reply	143
===	O	O	Reply	143
RADA incorporates an inductive bias for ‚Äúcaution‚Äù: when dropped into a new environment, a RADA agent starts acting as though the environment is at least as difficult as the most difficult environments it has been trained on.	B-Reply	B-2	Reply	143
Specifically, it makes the reasonable assumption that actions that rarely caused bad outcomes in training environments are also unlikely to cause bad outcomes in the unseen environments, and selects them.	I-Reply	I-2	Reply	143
The intuition is that while the new environments are indeed outside the support of what our models could have learned from training environments, they are still within the support of this cautious inductive bias which is built into RADA.	I-Reply	I-2	Reply	143
Our empirical results establish that RADA does generalize safely to held-out environments.	I-Reply	I-2	Reply	143
<sep> <sep> This built-in bias does not come for free: in environments that are easier than a RADA agent‚Äôs training environments (such as smaller car widths in our setting), it would be overly cautious during adaptation to a new environment and thus take longer to reach an optimal policy.	I-Reply	I-2	Reply	143
<sep> <sep> ===‚ÄúWhy sum of 0th through kth quantile, rather than just the k^th quantile‚Äù?	O	O	Reply	143
===	O	O	Reply	143
Good question, we made this choice so that the RADA would be a strict generalization of the PETS objective: at gamma=0, the RADA objective in Eq 2 exactly matches the PETS objective of Eq 1.	B-Reply	B-1	Reply	143
<sep> <sep> === ‚ÄúWhy average maximum reward?	O	O	Reply	143
If the return accurately captures all desiderata, why do we count the number of collisions (failures)?‚Äù ===	O	O	Reply	143
We care about two things: (i) quickly reaching good performance in the target environment, and (ii) safety during the adaptation process.	B-Reply	B-5	Reply	143
To capture these two desiderata, we report both the average max reward (consistent with Chua et al 2018, which we build on), and the cumulative number of collisions during adaptation.	I-Reply	I-5	Reply	143
In our experimental setting, collisions correspond to catastrophic states that we can't recover from, and which we aim for RADA to learn to avoid.	I-Reply	I-5	Reply	143
While return and collisions are closely related in our environment, they do not capture exactly the same thing.	I-Reply	I-5	Reply	143
In particular, collisions lead to low reward, but low reward does not always mean that a collision occurred.	I-Reply	I-5	Reply	143
Instead, it might also be due to the agent steering left rather than right, or going about in circles, for example.	I-Reply	I-5	Reply	143
So it is worthwhile to measure collisions separately to evaluate how safe adaptation is.	I-Reply	I-5	Reply	143
<sep> <sep> === ‚ÄúKeep the model close to the original model.	O	O	Reply	143
How?‚Äù ===	O	O	Reply	143
Yes, we meant that RADA does this by using past experience in training environments during the finetuning stage in the target environment.	B-Reply	B-3	Reply	143
We have improved the exposition now to clarify this.	I-Reply	I-3	Reply	143

This paper tries to address the safe adaptation: given a model trained on a variety of past experiences for some task, train a model learning to perform that task in a new situation while avoiding catastrophic failure.	O	O	Review	143
<sep> <sep> <sep> Pros:	O	O	Review	143
- The idea of training on data from varying quartiles, with the goal of preventing overly-conservative models, is quite intriguing and inspiring.	O	O	Review	143
<sep> <sep> Cons &amp; Question:	O	O	Review	143
- Motivation:	O	O	Review	143
Cautious exploration or optimizing the best worst-case performance is conflicting with the philosophy of exploration, such as UCB.	B-Review	B-1	Review	143
As stated in the introduction, ‚Äúenables fast yet safe adaptation within only a handful of episodes.	I-Review	I-1	Review	143
‚Äù Intuitively, we can not expect to be safe and fast at the same time.	I-Review	I-1	Review	143
It would be better to discuss why cautious exploration can ensure fast and safe adaption, which would be more interesting.	I-Review	I-1	Review	143
Additionally, in Figure 3, some fast adaption methods, such as MAML, should be compared to be more persuasive.	I-Review	I-1	Review	143
<sep> <sep> - Method:	O	O	Review	143
1.	O	O	Review	143
In equation (1), sum_N ‚Äî&gt; sum_i.	B-Review	B-2	Review	143
<sep> 2.	O	O	Review	143
This work formulated safe adaption as minimizing the risk of catastrophic failure.	B-Review	B-3	Review	143
What‚Äôs the relationship between ‚Äúthe generalized action score‚Äù and ‚Äúrisk of catastrophic failure‚Äù?	I-Review	I-3	Review	143
The ‚Äúgeneralized action score‚Äù is the main difference with PETs.	I-Review	I-3	Review	143
However, it is a little bit hard to follow the idea from ‚Äúrisk of catastrophic failure‚Äù to ‚Äúthe generalized action scores‚Äù.	I-Review	I-3	Review	143
<sep> 3. ‚	O	O	Review	143
ÄúModel-based RL agents contain dynamics models that can be trained in the absence of any rewards or supervision.	B-Review	B-4	Review	143
‚Äù	I-Review	I-4	Review	143
‚ÄùSince dynamics models do not need any manually specified reward function during training, the ensemble model can continue to be trained in the same way as during the pretraining phase.	I-Review	I-4	Review	143
‚Äù I am confused about these sentences.	I-Review	I-4	Review	143
Without the reward, what‚Äôs the purpose of RL?	I-Review	I-4	Review	143
<sep> <sep> <sep> - Experiments:	O	O	Review	143
1.	B-Review	B-5	Review	143
As stated in experiments, three meta-learning approaches have been deployed as baselines, including GrBal, RL^2 and MOLe.	I-Review	I-5	Review	143
However, the experimental results are missing.	I-Review	I-5	Review	143
Why meta-learning baselines do not work?	I-Review	I-5	Review	143
Are there any explanations?	I-Review	I-5	Review	143
<sep> 2.	O	O	Review	143
There are many robust RL baselines, such as	B-Review	B-6	Review	143
[1] Pinto L, Davidson J, Sukthankar R, et al Robust adversarial reinforcement learning[C]//Proceedings of the 34th International Conference on Machine Learning-Volume 70.	I-Review	I-6	Review	143
JMLR.	I-Review	I-6	Review	143
org, 2017: 2817-2826.	I-Review	I-6	Review	143
<sep> It would be better to compare with robust reinforcement learning work since there are no other baselines apart from meta-learning methods.	I-Review	I-6	Review	143
<sep> <sep> Thank you for your extensive comments.	O	O	Reply	143
<sep> <sep> === ‚ÄúCompare against robust RL.‚Äù ===	O	O	Reply	143
Thank you for this suggestion.	B-Reply	B-6	Reply	143
We have now included a new baseline: Pinto et al, Robust Adversarial Reinforcement Learning, 2017 (‚ÄúRARL‚Äù), per your suggestion.	I-Reply	I-6	Reply	143
Specifically, we train RARL with an adversarial agent that can perturb the motor torques.	I-Reply	I-6	Reply	143
We pretrain RARL for about 30x as many episodes as RADA (necessary for the model-free approach RARL employs), and evaluate adaptation to new environments similar to our approach.	I-Reply	I-6	Reply	143
The results are now included in Fig 2, 3, and 4 in the paper.	I-Reply	I-6	Reply	143
They show that RARL does indeed induce robustness during policy transfer.	I-Reply	I-6	Reply	143
However, in our experiments, RARL adapts more slowly, yields worse rewards, and leads to more collisions than RADA.	I-Reply	I-6	Reply	143
Please see Sec 5 and Figs 2, 3, and 4 for more details.	I-Reply	I-6	Reply	143
<sep> <sep> === ‚ÄúWhy meta-learning baselines do not work?‚Äù ===	O	O	Reply	143
We have tried RL^2, MOLe, and GrBAL (a model-based variant of MAML).	B-Reply	B-5	Reply	143
Unfortunately, none of these methods work well in our setting.	I-Reply	I-5	Reply	143
In particular, training these methods has proven extremely unstable in our environment.	I-Reply	I-5	Reply	143
Following the reviewer's suggestions, we have run experiments to analyze why metalearning fails --- our hypothesis was that it failed due to the large range of training environments.	I-Reply	I-5	Reply	143
In our new expeirments, we decreased the range of pretraining car widths (from 0.05-0.099 in the paper to 0.05-0.06) in an attempt to stabilize metalearning.	I-Reply	I-5	Reply	143
We tried training RL^2 and GrBAL once more with reasonable hyperparameter search around the authors‚Äô code defaults.	I-Reply	I-5	Reply	143
Despite this, neither metalearning approach was able to successfully train.	I-Reply	I-5	Reply	143
We have added a note on this in the paper.	I-Reply	I-5	Reply	143
<sep> <sep> === ‚ÄúThe paper claims fast and safe adaptation, but isn‚Äôt fast and safe impossible?‚Äù ===	O	O	Reply	143
There is indeed a tradeoff between how safe an agent is, and how fast it can hope to adapt.	B-Reply	B-1	Reply	143
However, while standard RL and meta-RL approaches do not consider safety at all and therefore provide no ability to trade off safety for speed and vice versa, RADA provides an intuitive way to do this by setting a caution parameter (gamma in Eq 2).	I-Reply	I-1	Reply	143
It then aims to provide pareto-efficient solutions that pay attention to both safety and adaptation speed, with gamma controlling where on the pareto-frontier the solution is.	I-Reply	I-1	Reply	143
<sep> <sep> ===‚ÄúI am confused about the sentence ‚ÄòSince dynamics models do not need any manually specified reward function during training, the ensemble model can continue to be trained in the same ways as during the pretraining phase.	O	O	Reply	143
‚Äô Without reward, what‚Äôs the purpose of RL?‚Äù ===	O	O	Reply	143
We employ a model-based planning approach to RL, involving two steps: (i) a dynamics model is trained that predicts future states given current states and actions, and (ii) then, an action is selected not through a learned policy, but instead by optimizing for actions that produce the most desirable states as predicted by the learned dynamics model.	B-Reply	B-4	Reply	143
So, the dynamics model is the only component that is learned, and it is task-agnostic and requires no rewards.	I-Reply	I-4	Reply	143
This is convenient in our setting, since the dynamics models can be trained even in the unseen test environment, where no rewards are provided.	I-Reply	I-4	Reply	143
RADA exploits this.	I-Reply	I-4	Reply	143
<sep> <sep> === ‚ÄúWhat is the relationship between the generalized action score and the risk of catastrophic failure?‚Äù ===	O	O	Reply	143
Eq 2 defines the generalized action score.	B-Reply	B-3	Reply	143
This score includes a caution parameter which controls the degree of pessimism with which an action sequence is evaluated during planning with the learned model.	I-Reply	I-3	Reply	143
For instance, when caution gamma is 50, the generalized action score of an action sequence is the average score of the bottom half of the particles propagated through the model.	I-Reply	I-3	Reply	143
This would capture any catastrophic failures resulting from those actions, at the cost of ignoring the most successful trajectories that yielded highest reward.	I-Reply	I-3	Reply	143
As gamma increases, the failures are weighted more relative to the successes.	I-Reply	I-3	Reply	143
This means that during planning, actions that have even a minor risk of failure are assigned a low generalized action score, and therefore avoided.	I-Reply	I-3	Reply	143
The generalized action score thus allows control over the degree to which catastrophic failure is avoided.	I-Reply	I-3	Reply	143
<sep> <sep> ‚Äúsum_N‚Äù -&gt; ‚Äúsum_i‚Äù Thank you, we have fixed this and other minor typos now.	B-Reply	B-7	Reply	143

The paper proposes a novel method called augMix, which creates synthetic samples by mixing multiple augmented images.	O	O	Review	143
Coupled with a Jensen-Shannon Divergence consistency loss, the proposed method has been experimentally, using CIFAR10, CIFAR100, and ImageNet, shown to be able to improve over some augmentation methods in terms of robustness and uncertainty.	O	O	Review	143
<sep> The paper is very well written and easy to follow.	O	O	Review	143
The idea of the approach is simple, and should be easy to be implemented.	O	O	Review	143
The evaluation of the proposed method is currently based on experimental evidence.	O	O	Review	143
Nevertheless, the empirical studies in its current form could be further improved.	O	O	Review	143
Please see my detailed comments below.	O	O	Review	143
<sep> <sep> 1.	B-Review	B-1	Review	143
The proposed approach relies on a chain of augmented methods.	I-Review	I-1	Review	143
In this sense, experimental studies on the sensitivity for how the augmentation methods in the chain (e.g., augmentation operations) and their chain structure (e.g., length of the chain) impact the performance of the augMix should be provided.	I-Review	I-1	Review	143
This is in particular relevant because the authors did mention that ‚Äúadding even more mixing is not necessarily beneficial‚Äù on page 8.	I-Review	I-1	Review	143
<sep> <sep> 2.	O	O	Review	143
Since the proposed method mixes multiple augmented images, a more appropriate comparison baseline would be a method involving creating synthetic data with multiple images.	B-Review	B-2	Review	143
For example, the n-fold Mixup method as discussed in Guo AAAI2019 (Mixup as Locally Linear Out-Of-Manifold Regularization).	I-Review	I-2	Review	143
<sep> <sep> 3.	O	O	Review	143
Some experimental results/observations deserve further discussions.	B-Review	B-3	Review	143
For example, on page 8, the authors mention that ‚Äúapplying augMix on top of Mixup increases the error rate to 13.3%‚Äù.	I-Review	I-3	Review	143
I wonder if the authors could provide any insights or hypothesis on why the proposed model behaviors in this way?	I-Review	I-3	Review	143
<sep> <sep> 4.	B-Review	B-4	Review	143
Would that be any manifold intrusion issue as discussed in Guo‚Äôs AAAI2019 paper?	I-Review	I-4	Review	143
That is, would it be possible to generate images that are very close to some real images but with different labels?	I-Review	I-4	Review	143
For example, by looking at the bottom-center image in the Appendix B, the synthetic image created seems to be close to some birds with other categories.	I-Review	I-4	Review	143
<sep> <sep> 5.	O	O	Review	143
Does the method work for other network architectures such as DenseNet?	B-Review	B-5	Review	143
<sep> <sep> <sep> *********new  comment**********	O	O	Review	143
During the rebuttal period, the paper has been improved with additional experimental results, analyses, and observations.	O	O	Review	143
I therefore have adjusted my evaluation score accordingly.	O	O	Review	143
<sep> <sep> <sep> Thank you for your careful analysis of our paper.	O	O	Reply	143
<sep> <sep> 1.	O	O	Reply	143
In choosing our base augmentation operators we opted to reuse the operators in AutoAugment for the sake of simplicity, while taking out the ones which appeared in the ImageNet-C test set.	B-Reply	B-1	Reply	143
As for the scalar hyperparameters, we have launched several ImageNet sweeps perturbing depth, width, count, and beta/dirichlet coefficients.	I-Reply	I-1	Reply	143
We aim to share these results with you soon, and these experiments are so far indicating that, across different hyperparameter choices, AugMix is quite stable.	I-Reply	I-1	Reply	143
<sep> <sep> 2 and 4.	O	O	Reply	143
<sep> Thanks for pointing out the paper by Guo et al 2019 [1]. We have cited it in the revision and added a discussion in the related work.	B-Reply	B-4	Reply	143
<sep> <sep> We would like to clarify that our method does not mix images of multiple classes together, but rather the three augmentation chains are created from a single image and mixed back into one single image.	I-Reply	I-4	Reply	143
We should like to note that the AugMix pseudocode and Figure 4 illustrate that the label remains constant through the augmentation process.	I-Reply	I-4	Reply	143
Since the base transformations are label preserving, and we only mix different augmentations of the same image, we do not believe the manifold intrusion phenomenon presents a significant issue to our method unlike mixup, as most of the operations are fairly structure-preserving.	I-Reply	I-4	Reply	143
One might expect a performance drop coincident with manifold intrusion, but AugMix increases performance on both clean and corrupted inputs.	I-Reply	I-4	Reply	143
In view of your concern, we looked at several example images from AugMix and did not observe class collisions.	I-Reply	I-4	Reply	143
However, we agree that the concept of manifold intrusion from Guo et al 2019 for mixup is a real concern.	I-Reply	I-4	Reply	143
<sep> <sep> 3.	O	O	Reply	143
Additional discussion	O	O	Reply	143
<sep> One possible explanation for the performance drop of ‚ÄúAugMix on top of Mixup‚Äù is that mixup is not a label preserving transformation, and applying augmix on top of mixup could suffer from manifold intrusion, thereby causing error rate to increase.	B-Reply	B-3	Reply	143
We have added a comment linking to the relevant explanation from Guo et al 2019 in the paper.	I-Reply	I-3	Reply	143
Mixup alone substantially harms calibration as well, which means combining it with AugMix would make uncertainty estimates worse too.	I-Reply	I-3	Reply	143
However, In Table 2 we show that combining AugMix with another label preserving augmentation such as SIN, outperforms both AugMix and SIN individually.	I-Reply	I-3	Reply	143
Hence AugMix can combine with well with other techniques.	I-Reply	I-3	Reply	143
<sep> <sep> Future work on extending AugMix by including ideas from n-fold Mixup (Guo et al 2019) to avoid manifold intrusion could yield further benefits.	I-Reply	I-3	Reply	143
<sep> <sep> 5.	O	O	Reply	143
Additional experiments	O	O	Reply	143
‚ÄúDoes the method work for other network architectures such as DenseNet?‚Äù	O	O	Reply	143
To test robustness across network architectures, we report results with AllConvNet, Wide ResNet, and ResNeXt in Tables 1, Table 5, Table 6, and we observe that AugMix significantly improves performance across different architectures.	B-Reply	B-5	Reply	143
<sep> On DenseNet, we observe that the error rate greatly decreases from 30.7% (baseline) to 12.7% (AugMix).	I-Reply	I-5	Reply	143
We have added DenseNet results (Table 1, 5, 6) in the updated draft, thanks to your suggestion.	I-Reply	I-5	Reply	143
<sep> <sep> We hope we were able to address your valid concerns and we thank you for your helpful suggestions.	O	O	Reply	143
Do you have any remaining concerns?	O	O	Reply	143
<sep> <sep> [1] Hongyu Guo, Yongyi Mao, Richong Zhang.	O	O	Reply	143
MixUp as Locally Linear Out-of-Manifold Regularization.	O	O	Reply	143
Proceedings of the AAAI Conference on Artificial Intelligence, 2019.	O	O	Reply	143

The paper discusses a new  data augmentation method which improves the accuracy of the network for several specific shifted domain scenarios.	O	O	Review	143
The main goal of the paper is to increase the robustness of the deep model trained on the augmented data to generalize well beyond the data corruption like the  rotation, translation, noise,.... For each input, they apply  different operation of image shift and make the weighted combination of them.	O	O	Review	143
The weight vector is generated randomly from Dirichlet distribution with the parameter.	O	O	Review	143
The weighted combined images would be added to the original image in convex combination.	O	O	Review	143
The convex weights are generated from distribution Beta with parameter.	O	O	Review	143
Later they train the network with adding the Jensen-Shannon divergence for the posterior distributions of augmented images as the consistency regularizer.	O	O	Review	143
They show this data augmentation will increase the accuracy of the model for shifted and non-shifted domains and also it leads to more calibrated model for domain shift problem.	O	O	Review	143
<sep> <sep> Pros:	O	O	Review	143
the paper is well-written with clear implementation details.	O	O	Review	143
The level of experiments are wide and cover different aspects.	O	O	Review	143
The experiments shows the significant improvement compared to several baselines.	O	O	Review	143
The authors conducted the experiments for a wide range of model-datasets to show the validity of their ideas.	O	O	Review	143
<sep> <sep> Cons:	O	O	Review	143
1- The title of this work is a strong claim that is not supported in the paper.	B-Review	B-1	Review	143
In this paper, it is mentioned that AugMix is a data augmentation method that generates data to add to the training set and after training with data augmentation, the method would be more robust to other distortions that can be added to the datasets.	I-Review	I-1	Review	143
Generally, the definition of domain shift is wider than just adding perturbation to the dataset.	I-Review	I-1	Review	143
To support the claim, the paper should also report the results for similar tasks datasets such as CIFAT10-STL10- or MINIST-SVHN for different models and with different domain adaptation methods.	I-Review	I-1	Review	143
The claim about the improvement of uncertainty also is not supported well by the experiments.	I-Review	I-1	Review	143
The method should be tested for many model-datasets specifically, to support improving the  uncertainty under the domain shift idea like the paper [1].	I-Review	I-1	Review	143
<sep> 2- The novelty of the work is limited.	B-Review	B-2	Review	143
The generating method of distorted  images is the combination of previously proposed methods like [2] and [3].  The motivation of why the proposed method is working well is not clear.	I-Review	I-2	Review	143
How this objective function can improve the robustness to the image perturbation but it does not lose the accuracy is not discussed.	I-Review	I-2	Review	143
It would be better if the proposed method were supported by theory and also the intuition and explained why it should get better results than previous data augmentation methods such as AutoAugment [3].	I-Review	I-2	Review	143
<sep> 3-  Fine-tuning the parameters like, and is not discussed at all.	B-Review	B-3	Review	143
<sep> <sep> 4- To show the robustness of the proposed method to domain shift, the paper compares the proposed method to other data augmentation methods that are not designed for domain shift which seems unfair.	B-Review	B-4	Review	143
<sep> References:	O	O	Review	143
[1] Ovadia, Yaniv, et al "Can You Trust Your Model's Uncertainty?	O	O	Review	143
Evaluating Predictive Uncertainty Under Dataset Shift."	O	O	Review	143
arXiv preprint arXiv:1906.02530 (2019).	O	O	Review	143
<sep> [2] Zhang, Hongyi, et al "mixup: Beyond empirical risk minimization."	O	O	Review	143
arXiv preprint arXiv:1710.09412 (2017).	O	O	Review	143
<sep> [3] Cubuk, Ekin D., et al "Autoaugment: Learning augmentation policies from data."	O	O	Review	143
arXiv preprint arXiv:1805.09501 (2018).	O	O	Review	143
<sep> <sep> Thank you for your detailed response.	O	O	Reply	143
<sep> <sep> 1. ‚	O	O	Reply	143
ÄúThe claim about the improvement of uncertainty also is not supported well by the experiments‚Äù	O	O	Reply	143
We should like to point to the middle of Figure 7 showing calibration on ImageNet-C. This is a challenging problem as pointed out by the paper you mentioned [1]. AugMix significantly improves the calibration of the baseline method.	B-Reply	B-1	Reply	143
Furthermore, combining AugMix with ensembles (the best performing method in Ovadia et al [1]) significantly improves performance and achieves much better calibration under distributional skew as demonstrated by the near-horizontal calibration error line.	I-Reply	I-1	Reply	143
To the best of our knowledge, AugMix + ensembles achieves state-of-the-art performance on calibration under distribution skew on ImageNet-C. If ensembles are too expensive, then a single-model with AugMix provides superior ImageNet-C calibration over ensembles.	I-Reply	I-1	Reply	143
In addition, Figure 6 (right) and Table 5 also show that AugMix significantly improves calibration.	I-Reply	I-1	Reply	143
We hope this evidence substantiates our claim that AugMix improves uncertainty estimates.	I-Reply	I-1	Reply	143
<sep> <sep> ‚ÄúData shift‚Äù is sometimes used interchangeably with ‚Äúdistributional skew‚Äù and ‚Äúdistribution shift.	I-Reply	I-1	Reply	143
‚Äù For instance, the paper you mentioned by Ovadia et al [1] evaluate ‚Äúcalibration under dataset shift‚Äù on images using ImageNet-C and CIFAR-10-C, and we do too.	I-Reply	I-1	Reply	143
<sep> <sep> That said, ‚Äúdata shift‚Äù is not often used interchangeably with ‚Äúdomain adaptation.	I-Reply	I-1	Reply	143
‚Äù Our paper does not contain experiments with MNIST classifiers transferring to SVHN since that is in the realm of domain adaptation, a setup which assumes knowledge of the structure of the data shift or access to a fine-tuning set.	I-Reply	I-1	Reply	143
We consider the problem of robustness to unseen corruptions, where we assume no knowledge of the data shift a priori.	I-Reply	I-1	Reply	143
<sep> <sep> 2.	O	O	Reply	143
Comparing AugMix to AutoAugment and Mixup	O	O	Reply	143
We believe that the simplicity of our method is a feature.	B-Reply	B-2	Reply	143
AugMix is not a direct combination of AutoAugment and Mixup.	I-Reply	I-2	Reply	143
AutoAugment requires training several thousand models to find an augmentation policy, whereas AugMix requires training only one.	I-Reply	I-2	Reply	143
Hence, its computational cost is in league with that of traditional data augmentation techniques, but even so AugMix can outperform AutoAugment.	I-Reply	I-2	Reply	143
While we use convex combinations of augmentations of one image, this does not make it an extension of Mixup.	I-Reply	I-2	Reply	143
In Mixup, examples are from different classes are mixed, while we do nothing of the sort.	I-Reply	I-2	Reply	143
While AugMix's name may suggest that it is a combination of AutoAugment and Mixup, the proposed method does not mix different training images and obviates the need for training several thousand models.	I-Reply	I-2	Reply	143
<sep> <sep> We believe AugMix works better because (i) augmentations produced by AugMix are more "diverse" as the base operations are randomly sampled and randomly mixed in every minibatch and (ii) consistency between augmentations is enforced with our Jensen-Shannon divergence loss.	I-Reply	I-2	Reply	143
Our ablation experiments in Table 4 show the relative contributions of these ingredients.	I-Reply	I-2	Reply	143
<sep> <sep> 3.	O	O	Reply	143
Further ablations	O	O	Reply	143
Thanks to your reasonable request, we are running numerous additional ablations.	B-Reply	B-3	Reply	143
We aim to share these results soon, which are so far indicating that AugMix is stable across different hyperparameter choices.	I-Reply	I-3	Reply	143
<sep> <sep> 4.	O	O	Reply	143
Competing with other techniques	O	O	Reply	143
There are few techniques in the nascent area of data shift.	B-Reply	B-4	Reply	143
However, we compared to all existing techniques proposed to tackle data shift (SIN, MaxBlurPool, etc.).	I-Reply	I-4	Reply	143
In addition, we also compared to numerous other techniques (Cutmix, adversarial training, etc.)	I-Reply	I-4	Reply	143
in order to provide an extensive comparison.	I-Reply	I-4	Reply	143
<sep> <sep> We hope we were able to address your concerns and we thank you for your helpful suggestions.	O	O	Reply	143
Do you have any remaining concerns?	O	O	Reply	143
<sep> <sep> [1] Ovadia, Yaniv, et al "Can You Trust Your Model's Uncertainty?	O	O	Reply	143
Evaluating Predictive Uncertainty Under Dataset Shift."	O	O	Reply	143
NeurIPS 2019.	O	O	Reply	143

This paper proposes a method called AugMix, which is intended to improve model robustness to data distribution shift.	O	O	Review	143
AugMix appears fairly simple to implement.	O	O	Review	143
Several new images are created by augmenting an original image through chains of sequentially applied transformations (the "Aug" part of AugMix), then the augmented images are combined together, along with the original image, via a weighted sum (the "Mix" part of AugMix).	O	O	Review	143
Additionally, a Jensen-Shannon Divergence consistency loss is applied during training to encourage the model to make similar predictions for all augmented variations of a single image.	O	O	Review	143
This technique is shown to achieve state-of-the-art performance on standard robustness benchmarks without loss of clean test accuracy, and is also shown to improve calibration of model confidence estimates.	O	O	Review	143
<sep> <sep> Overall, I would tend to vote for accepting this paper.	O	O	Review	143
The method is simple yet effective, the paper is very well written and easy to follow, and experiments are extensive and, for the most part, convincing.	O	O	Review	143
<sep> <sep> Questions:	O	O	Review	143
1) The one main concern I have with the training procedure is the amount of time the models were trained for.	B-Review	B-1	Review	143
It is known that model trained with aggressive data augmentation schemes often require much longer training than normal in order to fully benefit from the stronger augmentations.	I-Review	I-1	Review	143
For example, AutoAugment trains ImageNet models for 270 epochs [1], while CutMix trains for 300 epochs [2]. However, the ImageNet experiments in this paper claim to follow the procedure outlined in [3], which only trains for 90 epochs.	I-Review	I-1	Review	143
This is reflected in the clean test accuracy, where AutoAugment only appears to provide a 0.3% gain over standard training, while we might expect 1.3% improvement (according to [2]).	I-Review	I-1	Review	143
The AllConvNet and WideResNet in CIFAR-10 and CIFAR-100 experiments were also trained for only 100 epochs each, where 200 is more conventional.	I-Review	I-1	Review	143
Again this shows in the reported numbers: on WideResNet for CIFAR-10, Mixup only has a 0.3% gain were as we might expect 1% improvement instead [4], and AutoAugment has 0.4% improvement, were as we might expect 1.3% gain if trained longer [1]. My question then is, how much does training time affect results?	I-Review	I-1	Review	143
Do AugMix, and other techniques such as Mixup, CutMix, and AutoAugment, achieve better robustness when models are trained for longer, or do they become more brittle as training time is extended?	I-Review	I-1	Review	143
<sep> <sep> 2) For the Jensen-Shannon divergence consistency, how much worse does it perform when using JS(Porig;Paugmix1) versus JS(Porig;Paugmix1;Paugmix2)?	B-Review	B-2	Review	143
What might cause this behaviour?	I-Review	I-2	Review	143
<sep> <sep> 3) Patch Gaussian is changed to Patch Uniform to avoid overlap with corruptions in ImageNet-C. How does Patch Uniform compare to Patch Gaussian in terms of performance for non-Gaussian noise corruptions?	B-Review	B-3	Review	143
<sep> <sep> 4) How does AugMix perform as an augmentation technique in terms of clean test accuracy compared to other SOTA techniques?	B-Review	B-4	Review	143
Is there a trade-off between clean test accuracy and robustness, or does AugMix improve performance in both domains?	I-Review	I-4	Review	143
Can AugMix be combined with other augmentation techniques or does this destroy robustness properties?	I-Review	I-4	Review	143
<sep> <sep> Things to improve the paper that did not impact the score:	O	O	Review	143
5) It would be nice if the best result in each column could be bolded in Tables 2-4.	B-Review	B-5	Review	143
<sep> <sep> References:	O	O	Review	143
[1] Cubuk, Ekin D., Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc V. Le. "	O	O	Review	143
Autoaugment: Learning augmentation policies from data."	O	O	Review	143
CVPR (2019).	O	O	Review	143
<sep> <sep> [2] Yun, Sangdoo, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun, Junsuk Choe, and Youngjoon Yoo. "	O	O	Review	143
Cutmix: Regularization strategy to train strong classifiers with localizable features."	O	O	Review	143
ICCV (2019).	O	O	Review	143
<sep> <sep> [3] Goyal, Priya, Piotr Doll√°r, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He. "	O	O	Review	143
Accurate, large minibatch sgd: Training imagenet in 1 hour."	O	O	Review	143
arXiv preprint arXiv:1706.02677 (2017).	O	O	Review	143
<sep> <sep> [4] Zhang, Hongyi, Moustapha Cisse, Yann N. Dauphin, and David Lopez-Paz. "	O	O	Review	143
mixup: Beyond empirical risk minimization."	O	O	Review	143
ICLR (2018).	O	O	Review	143
Thank you for your detailed review.	O	O	Reply	143
We are glad you liked the method and hope that you will champion our paper.	O	O	Reply	143
<sep> <sep> 1.	O	O	Reply	143
We trained the AllConvNet and Wide ResNet for 100 epochs since we used a cosine learning rate schedule and not a waterfall learning rate schedule; the latter schedule usually requires 200 epochs, but the former requires fewer epochs for these architectures.	B-Reply	B-1	Reply	143
On CIFAR-10-C, we observed that training a Wide ResNet for 200 epochs instead of 100 decreased the AugMix error rate by ~0.5%, so AugMix can provide some amount of additional training robustness when trained for longer.	I-Reply	I-1	Reply	143
However, training with Cutmix for 200 epochs on CIFAR-10-C increases the error rate by 2%.	I-Reply	I-1	Reply	143
You are correct to note that our AutoAugment run was trained for 90 epochs on ImageNet, and we have updated the results with a 180 epoch run.	I-Reply	I-1	Reply	143
180 epochs gives similar performance to 270 epochs, according to a recent correspondence with the authors of AutoAugment.	I-Reply	I-1	Reply	143
The clean accuracy of AutoAugment is nearly that of the accuracy in the original paper, even though we disable a few operations so as to maintain separation from ImageNet-C test corruptions.	I-Reply	I-1	Reply	143
<sep> <sep> 2.	O	O	Reply	143
We have added new hyperparameter analysis experiments in Appendix A. This section includes an experiment to analyze the Jensen-Shannon loss.	B-Reply	B-2	Reply	143
One possible explanation for the performance gain realized by JS(Porig;Paugmix1;Paugmix2) over JS(Porig;Paugmix1) is that the former reduces the variance of the estimate of the true mixture distribution.	I-Reply	I-2	Reply	143
<sep> <sep> 3.	B-Reply	B-3	Reply	143
It is difficult to directly compare Patch Uniform to numbers from the Patch Gaussian paper since we follow convention and evaluate on 224x224 images not 299x299 images, while the Patch Gaussian paper evaluates on 299x299 images.	I-Reply	I-3	Reply	143
In a footnote on page 4, the authors note that they will update their paper with results on 224x224 images, after which we will be able to directly compare against a well-tuned tuned form of Patch Gaussian.	I-Reply	I-3	Reply	143
<sep> <sep> 4.	O	O	Reply	143
We note in Table 2 that AugMix also improves clean accuracy on ImageNet, though we are primarily interested in improving robustness.	B-Reply	B-4	Reply	143
While it is plausible that this field may encounter a (possibly small) tradeoff between robustness and accuracy, our simultaneous improvements in both directions show that we are not at that point yet for corruption and perturbation robustness.	I-Reply	I-4	Reply	143
As we limited ourselves to the set of augmentation operators used in AutoAugment, expanding the pool of label-preserving data augmentations would be a straightforward extension of AugMix that would likely yield additional improvement.	I-Reply	I-4	Reply	143
Our experiments on AugMix+SIN show that AugMix may be combined in alongside other robustness methods without additional tuning.	I-Reply	I-4	Reply	143
<sep> <sep> 5.	O	O	Reply	143
Your suggestion is incorporated in the new version of the paper.	B-Reply	B-5	Reply	143
Thank you.	I-Reply	I-5	Reply	143

*Summary*	O	O	Review	85
This paper proposes to use convolutional networks for image annotation.	O	O	Review	85
Great care is given to the selection of an appropriate loss function as well as the comparison with reasonable baselines over the NUS/Flickr dataset.	O	O	Review	85
The paper reads well, gives enough context and references to related work.	O	O	Review	85
It	O	O	Review	85
reports improvement with respect to the state of the art.	O	O	Review	85
In my opinion, this is a good paper, with the only drawback that the evaluation is conducted over a single dataset, with a vocabulary of only 80	O	O	Review	85
tags, which is small compared to realistic application.	O	O	Review	85
<sep> <sep> *Detailed review*	O	O	Review	85
I would like to clarify only two points regarding (i) small tag vocabulary in NUS, (ii) relationship with imageNET classification.	B-Review	B-2	Review	85
<sep> <sep> (i) the vocabulary of NUS/Flickr is only 80 different tags.	B-Review	B-1	Review	85
This is very  small compare to web annotation or even personal photo gallery annotation.	I-Review	I-1	Review	85
In particular, the fact that your network has 80 outputs make the evaluation of the output score of every tag for every forward/backward step very	I-Review	I-1	Review	85
inexpensive (compared to evaluating the rest of the network).	I-Review	I-1	Review	85
This is very different from the initial conditions in which the WARP loss was introduced.	I-Review	I-1	Review	85
Loss functions which does not rely on sampling can perfectly be used and might be better.	I-Review	I-1	Review	85
I notably think at  T. Joachims, A Support Vector Method	I-Review	I-1	Review	85
for Multivariate Performance Measures, Proceedings of the International Conference on Machine Learning (ICML), 2005 or Ranking with ordered weighted pairwise classification from Usunier et al 2009.	I-Review	I-1	Review	85
More fundamentally, I feel that focussing on 80 tags hides most of the interesting challenges in real tasks: reasonable 10k vocabularies implies greater perplexity and therefore require greater performance for the CNN.	I-Review	I-1	Review	85
They also suggest giving greater importance on tag coocurences and language modeling to understand unlikely predictions like ocean and lake tag in the same image from your example.	I-Review	I-1	Review	85
<sep> <sep> (ii) I appreciate that you highlight the difference between annotation and classification, and that you want a model trained from scratch for fair comparisons (Section 2.1).	B-Review	B-2	Review	85
However, the CNN trained over ImageNET of [20] or subsequent work has spurred hopes for a universal vision machine.	I-Review	I-2	Review	85
If large	I-Review	I-2	Review	85
CNNs trained over 1k and 20k imagenet were available to you, it might be interesting to evaluate how a NUS model initialized from those would perform.	I-Review	I-2	Review	85
This would be an additional result which would not replace the network trained from scratch but rather analyze the reusability of the	I-Review	I-2	Review	85
imageNET network and give perspective on the importance of the imageNET breakthrough.	I-Review	I-2	Review	85
<sep> <sep> *Comments along the text*	O	O	Review	85
Page 2. '	B-Review	B-3	Review	85
parametric model might not be sufficient to capture the complex distribution of the data' this sentence should be removed.	I-Review	I-3	Review	85
Parametric model can model complex distribution for non linear problems.	I-Review	I-3	Review	85
Use a different wording to introduce that nearest neighbor approaches are competitive.	I-Review	I-3	Review	85
<sep> Page 3. '	B-Review	B-4	Review	85
staircase weight-decay' I am not familiar with this name, which is rather explicit though.	I-Review	I-4	Review	85
You might want to sprincke references over neural net specific terms to allow other ML and core vision people to read your paper.	I-Review	I-4	Review	85
E.g. references after momentum, asynchronous SGD, staircase weight	I-Review	I-4	Review	85
decay might help.	I-Review	I-4	Review	85
<sep> Page 3 'posterior probability of an image x_i and class j' the wording is wrong, it should read posterior of class j given image x_i.	B-Review	B-5	Review	85
<sep> Page 5 'weight kNN' should read 'weighted kNN'	B-Review	B-6	Review	85
Thanks for the comments.	O	O	Reply	85
<sep> <sep> 'Comment 1 about tag dictionary size'	B-Reply	B-1	Reply	85
<sep> The NUS-WIDE dataset is the largest publicly available annotated multilabel dataset we have access to.	I-Reply	I-1	Reply	85
We agree with the reviewer that the power of Wsabie is not fully explored for this dictionary size, however, our goal is to show that the weighted ranking formulation can effectively improve multilabel annotation accuracy.	I-Reply	I-1	Reply	85
The reason we use WARP is because it is easy to implement, and potentially scales well to large dictionary size.	I-Reply	I-1	Reply	85
<sep> <sep> <sep> 'Comment 2 about reuse ImageNet model'	B-Reply	B-2	Reply	85
<sep> As mentioned in our response to reviewer 2, we have tried to initialize the model with ImageNet pretrained model, and have further obtained around 2% improvement for all methods.	I-Reply	I-2	Reply	85
However, our goal is to evaluate which loss is the best for multilabel prediction problems, so we directly trained the model from scratch to provide the cleanest experimental setting.	I-Reply	I-2	Reply	85

- Are there some labels more important than others, or shouldn‚Äôt we employ taxonomic distances ?	B-Review	B-1	Review	85
<sep> - How make model to decide on number of output labels ?	B-Review	B-2	Review	85
<sep> - It would be nice to have experiments comparing it to the network pretrained on imagenet.	B-Review	B-3	Review	85
'Are there some labels more important than others, or shouldn‚Äôt we employ taxonomic distances'	O	O	Reply	85
<sep> The standard evaluation protocol described in [25] is used in our work, and we have evaluated different methods by 5 different protocols (which is more comprehensive than [25]).	B-Reply	B-1	Reply	85
The overall precision and overall recall emphasis on frequent tags, and per-class recall and per-class precision emphasis on infrequent tags.	I-Reply	I-1	Reply	85
So we believe the evaluation is thorough.	I-Reply	I-1	Reply	85
The point raised by the reviewer is definitely interesting, however we believe it is orthogonal to this paper.	I-Reply	I-1	Reply	85
<sep> <sep> <sep> 'How make model to decide on number of output labels ?'	O	O	Reply	85
<sep> <sep> We follow the standard practice in most previous works [25,14,26] to fix the number of output labels for each image to 3 or 5.	B-Reply	B-2	Reply	85
<sep> <sep> <sep> 'It would be nice to have experiments comparing it to the network pretrained on imagenet.'	O	O	Reply	85
<sep> <sep> We have tested it before and found using pretrained weights can further improve the performance for around 2% for all methods.	B-Reply	B-3	Reply	85
However, our goal is to perform a clear comparison between different loss functions for multilabel annotation, and want to use the simplest experimental setting, so we did not includ the pretrained results.	I-Reply	I-3	Reply	85

This paper proposes to use deep convolutional neural network (DCNN)combined with ranking training criteria to attack the multi-label image annotation problem.	O	O	Review	85
DCNN is now widely used in image classification (annotation) problems.	O	O	Review	85
Applying it to multi-label image annotation problem is a natural extension of prior arts.	O	O	Review	85
The combination of DCNN with the ranking training criteria to solve the multi-label annotation problem, however, is new and is the main contribution of the paper.	O	O	Review	85
<sep> <sep> The authors evaluated the proposed approach on the NUS-WIDE dataset, which is considered the largest multi-label image dataset available.	O	O	Review	85
They compared the proposed approach with baselines that use manually designed image features and showed that the proposed approach outperforms the baseline by 10%.	O	O	Review	85
They claim that this is mostly due to the features learned from DCNN.	O	O	Review	85
They also compared several different ranking criteria and demonstrated that the weighted Approximate Ranking (WARP) criterion performs the best.	O	O	Review	85
<sep> <sep> While their results are not surprising given the recent success of DCNN on image classification tasks, this paper does show a novel usage of the DCNN on the multi-label image annotation problem.	B-Review	B-1	Review	85
<sep> <sep> If the paper is to be improved, I would suggest to include published results on the same task as part of the baselines.	B-Review	B-2	Review	85
This allows readers to understand better the position of the proposed approach.	I-Review	I-2	Review	85
Thank you for the comments!	O	O	Reply	85
<sep> <sep> Since most previous work on this dataset use a smaller subset of this whole dataset (such as NUS-light), or use their own training/testing split, directly comparing the numbers seem to be hard.	B-Reply	B-2	Reply	85
However, we included a baseline recognition system [11] which is published in IJCV 2013.	I-Reply	I-2	Reply	85
This baseline is based on a combination of 9 different visual features, and can be considered to be a quite strong baseline.	I-Reply	I-2	Reply	85

This paper investigated how two conflicting learning objectives; supervised and self-play updates could be combined with a focus on visual-grounded language tasks.	O	O	Review	85
With a different set of their combinations, the authors empirically found that alternating two learning updates may result in the best equilibrium state; consistency with samples in the supervised dataset and optimal state with high rewards in the task environment.	O	O	Review	85
<sep> <sep> The paper is very well-written, and I really enjoyed reading it overall.	B-Review	B-8	Review	85
There are some typos, presentation issues, and minor format issues (e.g., wrong naming) though.	I-Review	I-8	Review	85
I do like this kind of simple but insightful result with enough empirical observations and discussions.	O	O	Review	85
Even though there is not that novel method proposed, the overall message found from the experiments, their interpretation by the authors, and meaningful comparisons to the past works in emergent communication are fair enough to learn high scientific values from it.	O	O	Review	85
The design of the experiment is again very simple (e.g., changing the size of data, switching two setups in different ways) but clear to understand.	O	O	Review	85
This work is a good example of how well-designed hypotheses and their empirical validation could contribute to the field.	O	O	Review	85
I also appreciate the large spectrum of literature surveys including from the recent advances (Lewis et al 2017, Lee et al 17) to the past literature in emergent communications such as Littman (1994) and (Farrell &amp; Rabin, 1996).	O	O	Review	85
<sep> <sep> One of my concerns is the lack of applications, especially on the tasks using more natural language.	B-Review	B-1	Review	85
The two tasks; OR and IBR, seem to be very limited settings to evaluate how self-play operates with data supervision.	I-Review	I-1	Review	85
As pointed out by the authors, supervision from the training data itself may include most of the unexplored cases of the task, leading a less chance to learn policies from the high rewards.	I-Review	I-1	Review	85
I think more realistic tasks using natural language need to be considered: negotiation (e.g., Lewi‚Äôs task, ‚ÄúDecoupling strategy and generation in negotiation dialogues‚Äù), recommendation (e.g., ‚ÄúRecommendation as a Communication Game: Self-Supervised Bot-Play for Goal-oriented Dialogue‚Äù), and more.	I-Review	I-1	Review	85
I agree with the point made by the authors that this work mainly focuses on investigation rather than exploitation.	I-Review	I-1	Review	85
But, then it would be adding another emergent task where the self-play can learn many more policies than one in the supervised dataset.	I-Review	I-1	Review	85
<sep> <sep> Adding to the point, I was expecting to see non-task related metrics to measure the effectiveness of their appropriate combinations.	B-Review	B-2	Review	85
For example, it would be better to add language-side metrics (e.g., perplexity, fluency, consistency) to measure how language degeneration varies by the different combinations.	I-Review	I-2	Review	85
This issue is not addressed in the paper, and I guess this is mainly because of the limited usage of language in the two limited tasks.	I-Review	I-2	Review	85
If the paper is only focusing on emergent language which is related to specific tasks, it would be better to tone-down a little bit and state the major difference of it with natural language.	I-Review	I-2	Review	85
<sep> <sep> The population-based S2P seems to be a bit incremental and unrelated to the main theme of the paper.	B-Review	B-3	Review	85
To me, the motivation of adding POP into S2P based on the policy variability is somewhat different from the original claim about the combination of supervised and selfplay.	I-Review	I-3	Review	85
Also, the improvements on IBR in Figure 7 are incremental, making the major claim of this work little divergent.	I-Review	I-3	Review	85
<sep> <sep> In terms of presentation, if you like to show how performance changes over the different sizes of data, it would be better to show it by graphs over different variations instead of the bar charts only with 10k and 50k sizes.	B-Review	B-4	Review	85
In addition, the figures and captions need to be improved for better interpretation.	I-Review	I-4	Review	85
I think they are written in a hurry or changed a lot in the last minutes.	I-Review	I-4	Review	85
Please see some minor formatting issues below.	I-Review	I-4	Review	85
<sep> <sep> <sep> Minor comments:	O	O	Review	85
Duplicate reference of (Lewis et al 2017)	B-Review	B-6	Review	85
Some names defined in Section 3.3 and Section 5 are not exactly matched.	B-Review	B-7	Review	85
<sep> Figures and fonts in Figures 4 and 7 are a little difficult to understand.	B-Review	B-5	Review	85
Especially, I can‚Äôt understand the two upper figures in Figure 4a	I-Review	I-5	Review	85
Captions in Figure 4 are not matched with the sub-figures.	I-Review	I-5	Review	85
<sep> Figure r4b -&gt; Figure 4b	I-Review	I-5	Review	85
<sep> Thank you for your kind and insightful review!	O	O	Reply	85
<sep> <sep> &gt; Considering other natural language tasks, e.g. negotiation or recommendation	O	O	Reply	85
<sep> We agree that there are other tasks in NLP that have more direct applications than the OR and image-based referential (IBR) games.	B-Reply	B-1	Reply	85
The reason we selected the IBR game is because it‚Äôs the most common game with natural language that has been used in previous work on emergent communication (e.g. [1, 2, 3]).	I-Reply	I-1	Reply	85
Thus, it makes sense to compare various supervised and self-play schedules on this task.	I-Reply	I-1	Reply	85
We agree that a strong step for future work would be expanding to other complex natural language tasks such as negotiation (note that the suggested ‚Äòlanguage recommendation‚Äô paper came out on arXiv only two weeks before the ICLR submission deadline, and was accepted only after the deadline).	I-Reply	I-1	Reply	85
<sep> <sep> &gt; Adding non-task related metrics to study the language.	O	O	Reply	85
<sep> <sep> This is an interesting suggestion.	B-Reply	B-2	Reply	85
To help understand the difference in language generation policies for different S2P schedules, we will add qualitative examples to the Appendix, and investigate which other metrics we could add to compare the generated languages (most likely perplexity on the validation set, as it‚Äôs unclear how one would automatically measure ‚Äòfluency‚Äô and ‚Äòconsistency‚Äô).	I-Reply	I-2	Reply	85
In our experience, adding self-play usually results in a decrease in perplexity (because you are adding an objective that‚Äôs not maximum likelihood), in exchange for better performance on the task.	I-Reply	I-2	Reply	85
<sep> <sep> &gt; Population-based S2P is incremental and unrelated	O	O	Reply	85
<sep> Yes, we agree that introducing population-based S2P is somewhat orthogonal to the main theme of our paper.	B-Reply	B-3	Reply	85
We think population-based approaches have a lot of potential for improving grounded language learning with self-play especially when language tasks become more complex.	I-Reply	I-3	Reply	85
This is because, for more complex language tasks, we hypothesize that self-play will result in larger deviations from natural language, and population-based approaches can help alleviate this.	I-Reply	I-3	Reply	85
While our current distilled Pop-S2P result doesn‚Äôt yet reach the ensemble result, the S2P ensemble results in Figure 6 have an improvement at least as large over the single-agent S2P result (8.8% for 1k samples, and 4.1% for 10k samples), than single-agent S2P has over the supervised learning baseline without self-play (7.8% for 1k samples, and 4.4% for 10k samples).	I-Reply	I-3	Reply	85
Also, population-based methods help with some parts of our analysis (for example, generating Figure 4c: the ‚Äòperfect emcomm baseline‚Äô wouldn‚Äôt be as intuitive without having the distiller trained on a population of such languages ‚Äî see our response to Reviewer #2).	I-Reply	I-3	Reply	85
With this being said, we agree that the presentation of this result could be changed in our paper to de-emphasize it, and will work on this in the final version.	I-Reply	I-3	Reply	85
We‚Äôd love to hear if the reviewer has recommendations for this.	I-Reply	I-3	Reply	85
<sep> <sep> &gt; Test on more variations of data size for better visualization	O	O	Reply	85
<sep> We did run experiments with 2k and 5k samples and show the training curves for different S2P methods in the Appendix.	B-Reply	B-4	Reply	85
Due to space constraints, we chose to show results on only 1k and 10k in the main text of the paper.	I-Reply	I-4	Reply	85
However, we can go ahead and add another graph showing performance vs. # samples to the final version of the paper.	I-Reply	I-4	Reply	85
<sep> <sep> &gt; Figures and captions need to be improved	O	O	Reply	85
<sep> We thank the reviewer for these observations, and will make the changes in our final version.	B-Reply	B-5	Reply	85
<sep> <sep> <sep> References:	O	O	Reply	85
[1] Multi-agent communication and the emergence of (natural) language, Lazaridou et al, 2016.	O	O	Reply	85
<sep> [2] Compositional obverter communication learning from raw visual input, Choi et al, 2018.	O	O	Reply	85
<sep> [3] Emergent communication in a multi-step, multi-modal referential game, Evtimova et al, 2017.	O	O	Reply	85

<sep> Summary	O	O	Review	85
---	O	O	Review	85
<sep> (motivation)	O	O	Review	85
To develop language speaking agents we can teach them to mimic human language	O	O	Review	85
or to solve tasks that require communication.	O	O	Review	85
The latter is efficient, but	O	O	Review	85
the former enables interpretability.	O	O	Review	85
Thus we combine the two in an attempt	O	O	Review	85
to take advantage of both advantages.	O	O	Review	85
This paper studies a variety of ways to	O	O	Review	85
combine these approaches to inform future work that needs to make this tradeoff.	O	O	Review	85
<sep> <sep> (approach)	O	O	Review	85
The trade-off is studied using reference games between a speaker and a	O	O	Review	85
listener.	O	O	Review	85
Goal oriented _self-play_ and human _supervision_ are considered two contraints one	O	O	Review	85
can put on a network during learning.	O	O	Review	85
This work considers algorithms that vary	O	O	Review	85
when self-play and supervision are used (e.g., training with self-play then supervision,	O	O	Review	85
or supervision then self-play, or alternating back and forth between the two).	O	O	Review	85
<sep> Additional variations freeze the speaker or distill an ensemble of agents into one agent.	B-Review	B-12	Review	85
<sep> <sep> (experiments)	O	O	Review	85
A synthetic Object Reference game (OR) and a Image-Base Reference game (IBR) with real images are used for evaluation.	O	O	Review	85
Performance is accuracy at image/object guessing.	O	O	Review	85
<sep> 1. (	O	O	Review	85
OR) Like previous work, this work finds that emergent languages are imperfect at supporting their goals and cannot be understood by agents that only understand a human language like English.	B-Review	B-1	Review	85
<sep> 2. (	O	O	Review	85
OR) Pre-training with supervision then fine-tuning with self-play is superior to pre-training with self-play then fine-tuning with supervision.	O	O	Review	85
This is presented as surprising from the perspective of language emergence literature, which is though of as pre-training with self-play.	O	O	Review	85
<sep> 3. (	O	O	Review	85
IBR) Distilling an agent from an ensemble of 50 independently trained agents outperforms training single agents from scratch, but is still not as good as the whole ensemble.	B-Review	B-12	Review	85
<sep> <sep> Self-play vs supervision schedules:	O	O	Review	85
4. (	O	O	Review	85
IBR) Supervision (using image captions) followed by self-play performs much worse than all other approaches.	O	O	Review	85
<sep> 5. (	O	O	Review	85
IBR) Alternating between supervision and self play (e.g., randomly choosing supervision or self-play every iteration) performs best.	O	O	Review	85
<sep> <sep> <sep> <sep> Strengths	O	O	Review	85
---	O	O	Review	85
<sep> The curricula considered by this paper seem to have a sigificant impact on performance.	O	O	Review	85
These are new and could be important for future work on language learning, which may have considered the sup2sp setting from figure 7a without considering the sched setting.	O	O	Review	85
<sep> <sep> The diversity of experiments provided and the analysis help the reader get a better sense for how emergent communication models work.	O	O	Review	85
<sep> <sep> It's nice to see experiments on both a toy setting and a setting with realistic images.	O	O	Review	85
<sep> <sep> Future directions suggested throughout the paper are interesting.	O	O	Review	85
<sep> <sep> <sep> Weaknesses	O	O	Review	85
---	O	O	Review	85
<sep> <sep> * The 3rd point of section 5 is presented as a major conclusion of this paper, but it is not very surprising and I don't see how it's very useful.	B-Review	B-1	Review	85
The perspective of language emergence literature is presented a bit strangely.	I-Review	I-1	Review	85
The self-play to supervision baseline seems to be presented as an approach from the language emergence literature.	I-Review	I-1	Review	85
I don't think this is what any of that literature promotes exactly, though it is close.	I-Review	I-1	Review	85
Generally, I (and likely others) don't think it's too surprising that trying to fine-tune a self-play model with language supervision data doesn't work very well, for the same reasons cited in this paper (point 3 of section 5).	I-Review	I-1	Review	85
I think the general strategy when trying to gain practical benefits from self-play pre-training is a translation approach where the learned language is translated into a known language like English rather than trying to directly align it to English as does the supervision approach in this paper.	I-Review	I-1	Review	85
This particular baseline would be more useful if the paper considered learning some kind of translation layer on top of the self-play pre-trained model.	I-Review	I-1	Review	85
<sep> <sep> * How significant are the performance differences in figure 7a, especially those between the frozen and non-frozen models?	B-Review	B-2	Review	85
Is the frozen model really better or this performance difference just due to noise?	I-Review	I-2	Review	85
<sep> <sep> * I'm somewhat skeptical that these trends will generalize to other tasks/models.	B-Review	B-3	Review	85
The main goal of this paper is to inform future work.	I-Review	I-3	Review	85
That makes it even more important than normal that the trends identified here are likely to generalize well.	I-Review	I-3	Review	85
Are these trends likely to generalize well?	I-Review	I-3	Review	85
Does the paper address when these trends are expected to hold anywhere?	I-Review	I-3	Review	85
<sep> <sep> <sep> Minor Presentation Weaknesses:	O	O	Review	85
<sep> * Figure 4: I think the sub-figures are mis-labeled in the caption.	B-Review	B-4	Review	85
<sep> <sep> * In the related work I'm not sure the concept of generations is right.	B-Review	B-5	Review	85
I think it should refer to different languages of different agents across time rather than different languages of the same agent across time.	I-Review	I-5	Review	85
<sep> <sep> <sep> Missing details / clarification questions:	O	O	Review	85
<sep> * What exactly does Figure 4c compare?	B-Review	B-6	Review	85
Are both methods distilled from ensembles or is the blue line normal S2P while the other is distilled from an ensemble of compositional languages?	I-Review	I-6	Review	85
It's not clear since point (3) in section 5 refers to the S2P result (not Pop-S2P) in that plot.	I-Review	I-6	Review	85
I'm also assuming that PB-S2P means the same thing as Pop-S2P, but that's not made clear anywhere.	I-Review	I-6	Review	85
Does PB stand for Population Based?	I-Review	I-6	Review	85
<sep> <sep> * In the rand setting how is convergence defined?	B-Review	B-7	Review	85
Do both objectives need to converge or just one?	I-Review	I-7	Review	85
<sep> <sep> * In the sched_rand_frz setting what is r?	B-Review	B-8	Review	85
<sep> <sep> * In the IBR how are the distractor images picked?	B-Review	B-9	Review	85
<sep> <sep> <sep> Suggestions:	O	O	Review	85
<sep> * Can't both self-play and supervision be used at the same time (just use a weighted combination of the two objectives)?	B-Review	B-10	Review	85
I don't think the paper ever did this but it seems like a very useful variation to consider.	I-Review	I-10	Review	85
<sep> <sep> <sep> Preliminary Evaluation	O	O	Review	85
---	O	O	Review	85
<sep> Clarity: The writing is fairly clear, though some details are lacking.	B-Review	B-11	Review	85
<sep> Significance: This work could help inspire some future models in the language emergence literature.	I-Review	I-11	Review	85
<sep> Quality: Experiments are aligned with the paper's goals and support its conclusions.	I-Review	I-11	Review	85
<sep> Originality: The distillation approach and curricula are novel.	I-Review	I-11	Review	85
<sep> <sep> Overall the work could prove to be an interesting and useful reference point inside the language emergence literature so I recommend it for acceptance.	O	O	Review	85
<sep> <sep> <sep> Clarification questions	O	O	Reply	85
<sep> &gt; What exactly does Figure 4c compare?	O	O	Reply	85
Are both methods distilled from ensembles or is the blue line normal S2P while the other is distilled from an ensemble of compositional languages?	O	O	Reply	85
It's not clear since point (3) in section 5 refers to the S2P result (not Pop-S2P) in that plot.	O	O	Reply	85
I'm also assuming that PB-S2P means the same thing as Pop-S2P, but that's not made clear anywhere.	O	O	Reply	85
Does PB stand for Population Based?	O	O	Reply	85
<sep> <sep> Figure 4c compares two distilled policies.	B-Reply	B-6	Reply	85
One is distilled from S2P populations (trained with X samples), and one is distilled from ‚Äòperfect emergent communication languages‚Äô (defined in the text) and fine-tuned on X samples.	I-Reply	I-6	Reply	85
So both are population-based.	I-Reply	I-6	Reply	85
We apologize for the naming error, by PB-S2P we indeed mean Pop-S2P.	I-Reply	I-6	Reply	85
<sep> &gt; In the rand setting how is convergence defined?	O	O	Reply	85
Do both objectives need to converge or just one?	O	O	Reply	85
<sep> <sep> For the rand setting, both the objectives need to converge since we define convergence based on the performance of the listener on.	B-Reply	B-7	Reply	85
Fig 9 in Appendix shows that they indeed converge after certain number of train steps.	I-Reply	I-7	Reply	85
<sep> <sep> &gt; In the sched_rand_frz setting what is r?	O	O	Reply	85
<sep> <sep> We define r as the probability of freezing the speaker parameters as mentioned in Section 3.3.	B-Reply	B-8	Reply	85
The actual number was mistakenly commented out in the submitted version.	I-Reply	I-8	Reply	85
For reference, we use l=50 and m=50 for sched, r=0.5 for sched_rand_frz, and q=0.75 for rand.	I-Reply	I-8	Reply	85
We will update this in the final version.	I-Reply	I-8	Reply	85
<sep> <sep> &gt; In the IBR how are the distractor images picked?	O	O	Reply	85
<sep> <sep> They are picked using a uniform random distribution over all the images available in the dataset.	B-Reply	B-9	Reply	85
<sep> <sep> &gt; Can't both self-play and supervision be used at the same time (just use a weighted combination of the two objectives)?	O	O	Reply	85
I don't think the paper ever did this but it seems like a very useful variation to consider.	O	O	Reply	85
<sep> <sep> Yes this can indeed be done, by mixing gradient updates from both self-play and supervision in a single batch.	B-Reply	B-10	Reply	85
This is quite close to the ‚Äòrandom‚Äô schedule (which alternates every example), and we don‚Äôt expect to see much difference, although it could indeed be tried.	I-Reply	I-10	Reply	85

This paper explores the effect of ordering supervised learning and self-play on the resultant language learnt between agents.	O	O	Review	85
The topic is of high relevance to the ICLR community and makes several interesting insights useful to anyone learning control of a multi-agent system where communication amongst agents is applicable.	O	O	Review	85
I have several suggestions for improvements below, but all I believe are feasible to make within the time period of the rebuttal with the most necessary being:	O	O	Review	85
<sep> 1) The naming of methods in Section 5 is not consistent with those introduced in section 3.3.	B-Review	B-1	Review	85
For example, in the first paragraph ec2supervised is presumably sp2sup and sched is presumably sup2sp?	I-Review	I-1	Review	85
Similarly, on page 7 (S2P and Pop-S2P) and Figure 4.	I-Review	I-1	Review	85
Please revise and ensure consistency throughout.	I-Review	I-1	Review	85
<sep> <sep> 2) Figures 4b, 6 and 7 only present single values.	B-Review	B-2	Review	85
Are these average values from repeated runs?	I-Review	I-2	Review	85
If so please quantify variance.	I-Review	I-2	Review	85
<sep> <sep> 3) The conclusion in Section 7 at the bottom of page 8 that "S2P performs much worse than the other options" is contrary to previous results.	B-Review	B-3	Review	85
Can the authors please comment on what features of the environment caused this difference?	I-Review	I-3	Review	85
<sep> <sep> 4) Appendix A includes details of hyperparameters, but some details remain unclear.	B-Review	B-4	Review	85
Specifically, hyperparameter ranges swept over are shown but how were they then chosen from?	I-Review	I-4	Review	85
Are they optimised for each environment and algorithm?	I-Review	I-4	Review	85
What does the bold text in the table represent?	I-Review	I-4	Review	85
If it is chosen values, why do only some parameters have chosen values?	I-Review	I-4	Review	85
These are important details to enable reproduction of the paper.	I-Review	I-4	Review	85
<sep> <sep> Minor Comments:	O	O	Review	85
In Section 3.3, if all these methods are "well known ways to combine self-play and supervised learning" can all be supported by an (or preferably multiple) exemplar publications that used these method previously.	B-Review	B-6	Review	85
Directly linking each to the previous work will further clarify the contribution this specific paper makes and help readers new to the area gain insight across the multiple papers this work builds upon.	I-Review	I-6	Review	85
<sep> <sep> Figure 3b, colour is representative of performance.	B-Review	B-5	Review	85
Is this mean accumulated reward?	I-Review	I-5	Review	85
Please clarify to increase how informative this visualisation is, as currently it is unclear if yellow or blue is the desired value.	I-Review	I-5	Review	85
<sep> <sep> Page 5, small typo "introduced in the Lee et al (2017)" should be "introduced in Lee et al (2017)".	B-Review	B-7	Review	85
<sep> <sep> Figure 4b, the legend is blocking two bars and their corresponding value.	I-Review	I-7	Review	85
It looks like moving to the bottom right may help, or placing above the plot.	I-Review	I-7	Review	85
<sep> <sep> Figure 4 caption refers to a subfigure (d) that is not included.	I-Review	I-7	Review	85
<sep> <sep> On Page 6, the reference to babbling equilibrium should include a citation for interested readers to learn more about this well established concept.	I-Review	I-7	Review	85
<sep> <sep> On Page 7 there is a reference to Figure r4b, is this intended to be a reference to Figure 4b right?	I-Review	I-7	Review	85
<sep> <sep> Figure 6 appears after Figure 7.	I-Review	I-7	Review	85
Maintaining ordered numbering would be preferable.	I-Review	I-7	Review	85
<sep> <sep> On Page 9 it is noted some experimental results are in the Appendix but as there is a page and a half of space remaining before the 10 page limit, I would encourage to include all results in the main body of the paper.	B-Review	B-8	Review	85
<sep> <sep> Multiple references do not list a publication venue (e.g. Evtimova et al Lazaridou et al 2018, Tieleman et al 2018) or cite Arxiv versions when the work has been later published (e.g. Jacques et al 2018 was published at ICML 2018).	B-Review	B-9	Review	85
<sep> <sep> Figure 9 caption should state the environment.	B-Review	B-10	Review	85
We thank the reviewer for the kind and insightful review.	O	O	Reply	85
<sep> <sep> &gt; Naming not consistent	O	O	Reply	85
<sep> Yes, we indeed mean ec2supervised as sp2sup and sched as sup2sp in the first paragraph of Section 5.	B-Reply	B-1	Reply	85
Thanks for pointing this out, we will correct all the naming errors and ensure consistency throughout in the final version.	I-Reply	I-1	Reply	85
<sep> <sep> &gt; Adding error bars	O	O	Reply	85
<sep> Yes, the current values are the mean over runs from 5 different seeds.	B-Reply	B-2	Reply	85
We will add error bars to show variance in the final version.	I-Reply	I-2	Reply	85
<sep> <sep> &gt; The conclusion in Section 7 that ‚ÄòS2P performs much worse than the other options‚Äô is contrary to previous results.	O	O	Reply	85
<sep> <sep> In this Section, we are referring to the ‚Äúpoor performance of the *sup2sp* method‚Äù.	B-Reply	B-3	Reply	85
The sup2sp method is defined in Figure 2 and Section 3.3, and refers to one of the many instantiations of the (more general) S2P framework.	I-Reply	I-3	Reply	85
So what we are saying is not that S2P performs worse, but that sup2sp performs worse than other methods of S2P. This is shown in Figure 7a (not Figure 6, as we mistakenly wrote in the text).	I-Reply	I-3	Reply	85
The reason for this is that, since self-play is a form of regularizer (see Figure 7b), doing self-play updates often leads to worse performance on the task (until more supervised updates are done).	I-Reply	I-3	Reply	85
So, if you finish training with self-play updates without performing supervised updates, your performance will be quite low.	I-Reply	I-3	Reply	85
We will clarify this in the final version.	I-Reply	I-3	Reply	85
<sep> <sep> &gt; Add more hyperparameter details	O	O	Reply	85
<sep> Thank you for pointing this out, we will indeed update and clarify this in the final version.	B-Reply	B-4	Reply	85
<sep> <sep> &gt; Figure 3b, colour is representative of performance.	O	O	Reply	85
Is this mean accumulated reward?	O	O	Reply	85
Please clarify to increase how informative this visualisation is, as currently it is unclear if yellow or blue is the desired value.	O	O	Reply	85
<sep> <sep> Yes, it shows the performance (mean accumulated reward) over 50 pairs of speakers and listeners, so a higher value (yellow) is desirable.	B-Reply	B-5	Reply	85
It shows that the performance of both the speakers and listeners when paired randomly is found to be quite variable, although we do observe a slight preference towards their own partner (yellow diagonal).	I-Reply	I-5	Reply	85
Due to space constraints, we chose to omit this but we will clarify this in the final version.	I-Reply	I-5	Reply	85
<sep> <sep> &gt; if all these methods are "well known ways to combine self-play and supervised learning" can all be supported by an (or preferably multiple) exemplar publications that used these method previously.	O	O	Reply	85
<sep> <sep> We do refer to Lewis et al 2017 published at EMNLP‚Äô17 (oral) and Lazaridou et al 2016 published at ICLR‚Äô17 (oral) for two S2P methods, sched_frz and rand respectively.	B-Reply	B-6	Reply	85
The sup2sp and sp2sup are the baseline models which we use for comparing other sophisticated approaches, and which we compare to show that supervised learning before self-play generally improves performance (Section 5).	I-Reply	I-6	Reply	85
The sched_rand_frz is a novel extension to the sched_frz method which we found was more stable and sometimes performed slightly better.	I-Reply	I-6	Reply	85
<sep> <sep> &gt; Reference errors, fig refs/naming errors	O	O	Reply	85
Thanks for pointing out these, we will add references to the published versions of these papers and fix the references/naming to the figures in the text.	B-Reply	B-7	Reply	85

The paper describes a clipping method to improve the performance of one particular type of quantization method that is naive clipping to closest "bins".	B-Review	B-1	Review	683
The contribution of the paper is the (possibly incorrect) derivation of the clipping value that causes the least quantization error IF assumptions can be made about the distribution of the parameters (in a non-bayesian sense).	I-Review	I-1	Review	683
Thus, the significance is low due to both reasons.	I-Review	I-1	Review	683
<sep> <sep> One conceptual issue is the assumed relationship between quantization error and classification accuracy.	B-Review	B-2	Review	683
The literature has shown that high quantization error does not necessarily mean low classification accuracy when using non-uniform quantization.	I-Review	I-2	Review	683
The proposed clipping does not account for classification accuracy (on training set), but I understand the motivation being that the training set is not available.	I-Review	I-2	Review	683
<sep> <sep> 1.	O	O	Review	683
There seems to be an error in derivation of Eq (3), the first term should be for negative.	B-Review	B-3	Review	683
Please comment on this.	I-Review	I-3	Review	683
<sep> <sep> 2.	B-Review	B-4	Review	683
When solving the integrals, the authors simply pull the solution "out of the hat" and show that the derivative is the integrand.	I-Review	I-4	Review	683
This is a very opaque presentation that we cannot see how you solved the integral.	I-Review	I-4	Review	683
What is C in?	I-Review	I-4	Review	683
<sep> <sep> 3.	O	O	Review	683
The assumptions on the parameters are only valid for the particular model/dataset/precision.	B-Review	B-5	Review	683
The assumption does not generalize arbitrarily.	I-Review	I-5	Review	683
For example, models with quantized weights have bi-modal distributions.	I-Review	I-5	Review	683
How would you clip the  activations after e.g. a ReLu?	I-Review	I-5	Review	683
This is without going in to the weaknesses of the K-S test.	I-Review	I-5	Review	683
<sep> <sep> 4.	O	O	Review	683
Experiments do not show any comparison to the large body of prior work in this area.	B-Review	B-6	Review	683
<sep> <sep> 5.	O	O	Review	683
Page 4, para below (3), what is "common additive orthogonal noise"?	B-Review	B-7	Review	683
You should explain or give intuition instead of simply referring to a different paper.	I-Review	I-7	Review	683
<sep> <sep> 6.	O	O	Review	683
In the uniform case, one would think f(x)=1/<range of the interval>=2\alpha.	B-Review	B-8	Review	683
Why is it 1/\Delta?	I-Review	I-8	Review	683
<sep> <sep> 6.	B-Review	B-9	Review	683
Section 4, range should be [-\alpha, \alpha] instead of [\alpha, -\alpha]?	I-Review	I-9	Review	683
Since \alpha is positive.	I-Review	I-9	Review	683
We conduct synthetic experiments showing analysis is in a very good agreement with synthetic simulations when distributions of tensor elements are either Laplace or Normal (see figure 2 in our new submission).	B-Reply	B-10	Reply	683
The code to replicate these sanity checks appears here: <a href="https://github.com/submission2019/AnalyticalScaleForIntegerQuantization."	I-Reply	I-10	Reply	683
target="_blank" rel="nofollow">https://github.com/submission2019/AnalyticalScaleForIntegerQuantization.</a> We also improved the presentation of section 4 and provide a new figure to make the analysis easier to understand.	I-Reply	I-10	Reply	683
<sep> <sep> As noted by many prior arts, neural network distributions, are near Gaussian in practice, sometimes further controlled by procedures such as batch normalization.	I-Reply	I-10	Reply	683
See for example here:	I-Reply	I-10	Reply	683
1.	I-Reply	I-10	Reply	683
<a href="https://arxiv.org/pdf/1804.10969.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1804.10969.pdf</a>	I-Reply	I-10	Reply	683
2.	I-Reply	I-10	Reply	683
<a href="https://openreview.net/pdf?id=B1IDRdeCW" target="_blank" rel="nofollow">https://openreview.net/pdf?id=B1IDRdeCW</a>	I-Reply	I-10	Reply	683
3.	I-Reply	I-10	Reply	683
<a href="https://papers.nips.cc/paper/5269-expectation-backpropagation-parameter-free-training-of-multilayer-neural-networks-with-continuous-or-discrete-weights."	I-Reply	I-10	Reply	683
target="_blank" rel="nofollow">https://papers.nips.cc/paper/5269-expectation-backpropagation-parameter-free-training-of-multilayer-neural-networks-with-continuous-or-discrete-weights.</a>	I-Reply	I-10	Reply	683
In addition, we were able to see these bell-shaped distributions through both statistical tests (KS-test at section 3) and the visual appearance of the histograms (see appendix).	I-Reply	I-10	Reply	683
<sep> <sep> The connection between quantization error and classification accuracy has been investigated through the preservation of the direction of the quantized tensor.	B-Reply	B-2	Reply	683
See for example here:	I-Reply	I-2	Reply	683
1.	I-Reply	I-2	Reply	683
<a href="https://arxiv.org/pdf/1805.11046.pdf#page=9&zoom=100,0,96" target="_blank" rel="nofollow">https://arxiv.org/pdf/1805.11046.pdf#page=9&zoom=100,0,96</a> (section 5.1)	I-Reply	I-2	Reply	683
2.	I-Reply	I-2	Reply	683
<a href="https://arxiv.org/pdf/1705.07199.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1705.07199.pdf</a> (section 3.1)	I-Reply	I-2	Reply	683
We have added a detailed explanation about the connection between power of the quantization error and accuracy drop (see paragraph #5 in the introduction).	I-Reply	I-2	Reply	683
<sep> <sep> Detailed comments:	O	O	Reply	683
1.	B-Reply	B-3	Reply	683
Typo corrected.	B-Reply	B-9	Reply	683
<sep> 2.	B-Reply	B-4	Reply	683
For correctness, we believe it is enough to provide the primitive functions of these integrals (since this can be verified by differentiation).	I-Reply	I-4	Reply	683
The direct derivations are long unnecessary tedious calculations.	I-Reply	I-4	Reply	683
Also, C in is the standard constant of integration for indefinite integrals.	I-Reply	I-4	Reply	683
To avoid unclarity we removed this constant now from the text.	I-Reply	I-4	Reply	683
<sep> 3.	O	O	Reply	683
We disagree with this comment.	B-Reply	B-5	Reply	683
We have validated our work on six different models and improvement was dramatic with respect to gemmlowp for the quantization of activation tensors.	I-Reply	I-5	Reply	683
Weight tensors are kept at 8 bit of precision so the bi-modal distribution of weights does not apply to our work.	I-Reply	I-5	Reply	683
The activations are clipped before the ReLU as we clarify now in Section 5 (second paragraph).	I-Reply	I-5	Reply	683
<sep> 4.	O	O	Reply	683
Since submission, we made a comparison against the only previous method we are aware of: the Kullback-Leibler Divergence (KLD) clipping method suggested by NVIDIA (see update for table 1).	B-Reply	B-6	Reply	683
Our approach runs 4000 times faster compared to KLD and, excluding ResNet-101, outperforms KLD in terms of validation accuracy.	I-Reply	I-6	Reply	683
<sep> 5.	B-Reply	B-7	Reply	683
We provide now a better intuition for the analysis in section 4.	I-Reply	I-7	Reply	683
<sep> 6.	B-Reply	B-8	Reply	683
For the uniform case, f(x) = 1/(2*alpha).	I-Reply	I-8	Reply	683
We explicitly mention that in the paper now (just before equation 5).	I-Reply	I-8	Reply	683
<sep> 7.	O	O	Reply	683
Typo corrected.	O	O	Reply	683

This paper derives a formula for finding the minimum and maximum clipping values for uniform quantization which minimize the square error resulting from quantization, for either a Laplace or Gaussian distribution over pre-quantized value.	O	O	Review	683
This seems like too small a contribution to warrant a paper.	O	O	Review	683
I wasn't convinced that appropriate baselines were used in experiments.	O	O	Review	683
There were a number of statements that I believed to be technically slightly incorrect.	O	O	Review	683
There were also some small language problems (though these didn't hinder understanding).	O	O	Review	683
<sep> <sep> more specific comments:	O	O	Review	683
<sep> abstract:	B-Review	B-1	Review	683
"derive exact expressions" -- these expressions aren't exact.	I-Review	I-1	Review	683
they turn out to be based on a piecewise zeroth order Taylor approximation to the density.	I-Review	I-1	Review	683
<sep> <sep> main paper:	B-Review	B-2	Review	683
"allow fit bigger networks into" -> "allow bigger network to fit into"	I-Review	I-2	Review	683
"that we are need" -> "that need"	I-Review	I-2	Review	683
"introduces an additional" -> "introduces additional"	I-Review	I-2	Review	683
clippig -> clipping	I-Review	I-2	Review	683
<sep> it's not clear a-priori that information loss is the property to minimize that maximizes performance of the quantized network.	B-Review	B-3	Review	683
<sep> <sep> "distributions of tensors" -> "distribution of tensor elements"	B-Review	B-4	Review	683
this comment also applies in a number of other places, where the writing refers to the marginal distribution of values taken on by entries in a tensor as the distribution over the tensor.	I-Review	I-4	Review	683
note that a distribution over tensors is a joint distribution over all entries in a tensor.	I-Review	I-4	Review	683
e.g. it would capture things like eigenvalues, entry-entry covariance, rather than just marginal statistics.	I-Review	I-4	Review	683
<sep> <sep> "than they could have by working individually" -> "than could have been achieved by each individually"	B-Review	B-5	Review	683
<sep> Why the focus on small activation bit depth?	B-Review	B-6	Review	683
I would imagine weight bit-depth was more important than activation bit depth.	I-Review	I-6	Review	683
Especially since you're using ?	I-Review	I-6	Review	683
32-bit?	I-Review	I-6	Review	683
precision in the weight/activations multiplications, so activations are computed at a high bit depth anyways.	I-Review	I-6	Review	683
<sep> <sep> Table 1: Give absolute accuracies too!	B-Review	B-7	Review	683
Improvement relative to what baseline?	I-Review	I-7	Review	683
<sep> <sep> sec 2:	B-Review	B-8	Review	683
sufficeint -> sufficient	I-Review	I-8	Review	683
\citep often used when it should instead be \citet.	I-Review	I-8	Review	683
<sep> "As contrast" -> "In contrast"	I-Review	I-8	Review	683
<sep> section 3:	B-Review	B-9	Review	683
uniformity -> uniformly	I-Review	I-9	Review	683
<sep> I don't believe the notion of p-value is being used correctly here w.r.t.the Kolmogorov-Smirnov test.	B-Review	B-10	Review	683
<sep> <sep> Figure 1: The mean square error should never go to 0.	B-Review	B-11	Review	683
This suggests something is wrong.	I-Review	I-11	Review	683
If it's just a scaling issue, consider a semilogy plot.	I-Review	I-11	Review	683
<sep> <sep> Figure 2: I'm unclear what baseline (no clipping) refers to in terms of clipping values.	B-Review	B-12	Review	683
For uniform quantization there needs to be some min and max value.	I-Review	I-12	Review	683
The paper indeed provides a formula for optimal quantization when the distribution of tensor elements is either laplace or gauss.	O	O	Reply	683
The paper also shows the relevance of these derivations to a very attractive use-case i.e., the conversion of full precision network to low precision network without time-consuming re-training or the availability of the full datasets.	O	O	Reply	683
Our approach is shown to have significant advantages over previous approaches (as summarized in Table 1).	O	O	Reply	683
<sep> Response to more specific comments:	O	O	Reply	683
Language problems: We have incorporated all typos and paraphrasing suggestions	O	O	Reply	683
<sep> 1.‚Äúit's not clear a-priori that information loss is the property to minimize that maximizes performance of the quantized network.	O	O	Reply	683
‚Äù  The connection between quantization error and classification accuracy has been investigated through the preservation of the direction of the quantized tensor.	B-Reply	B-3	Reply	683
See for example here:	I-Reply	I-3	Reply	683
a.<tab><a href="https://arxiv.org/pdf/1805.11046.pdf#page=9&zoom=100,0,96" target="_blank" rel="nofollow">https://arxiv.org/pdf/1805.11046.pdf#page=9&zoom=100,0,96</a> (section 5.1)	I-Reply	I-3	Reply	683
b.<tab><a href="https://arxiv.org/pdf/1705.07199.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1705.07199.pdf</a> (section 3.1)	I-Reply	I-3	Reply	683
We have added a detailed explanation about the connection between power of the quantization error and accuracy drop (see paragraph #5 in the introduction).	I-Reply	I-3	Reply	683
<sep> <sep> 2.‚ÄúGive absolute accuracies too!	O	O	Reply	683
Improvement relative to what baseline?‚Äù We now provide the baselines we use in our experiments (see Table 1).	B-Reply	B-7	Reply	683
<sep> 3. ‚	O	O	Reply	683
ÄúThe mean square error should never go to 0.	O	O	Reply	683
This suggests something is wrong.	O	O	Reply	683
If it's just a scaling issue, consider a semilogy plot.	O	O	Reply	683
‚Äù: This was indeed a scale issue only.	B-Reply	B-11	Reply	683
It is not relevant anymore (the figure was removed and replaced by the synthetic experiments showing that analysis and simulations are in a good agreement).	I-Reply	I-11	Reply	683
<sep> <sep> 4.	O	O	Reply	683
<tab>‚ÄúI'm unclear what baseline (no clipping) refers to in terms of clipping values.	O	O	Reply	683
For uniform quantization there needs to be some min and max‚Äù: we improved the explanation of this issue in the introduction (see beginning of paragraph 9), where we explain that the traditional method that avoids clipping uniformly quantize the values between the largest and smallest tensor elements.	B-Reply	B-12	Reply	683

This paper empirically finds that the distribution of activations in quantized networks follow  Gaussian or Laplacian distribution, and proposes to determine the optimal clipping factor by minimizing the quantization error based on the distribution assumption.	O	O	Review	683
<sep> <sep> The pros of the work are its simplicity, the proposed clipping and quantization does not need additional re-training.	B-Review	B-1	Review	683
However, while the key of this paper is to determine a good clipping factor, the authors use uniform density function to represent the middle part of both Gaussian and Laplacian distributions where the majority of data points lie in, but exact computation for the tails of the distributions at both ends.	I-Review	I-1	Review	683
Thus the computation of quantization error is not quite convincing.	I-Review	I-1	Review	683
Moreover, the authors do not compare with the other recent works that also clip the activations, thus it is hard to validate the efficacy of the proposed method.	B-Review	B-2	Review	683
<sep> <sep> For the experiments, the authors mention that a look-up table can be pre-computed for fast retrieval of clipping factors given the mean and sigma of a distribution.	B-Review	B-3	Review	683
However, the mean and sigma are continuous numbers, how is the look-up table made?	I-Review	I-3	Review	683
Moreover, how is the mean and std estimated for each weight tensor and what is  the complexity?	I-Review	I-3	Review	683
<sep> <sep> Reviewer  addressed three concerns:	O	O	Reply	683
<sep> 1.	O	O	Reply	683
It has been observed by many prior arts that quantization error can be assumed to be uniformly distributed (e.g., <a href="http://daniel-marco.com/Academic%20Files/Additive%20Noise%20Model.pdf)."	B-Reply	B-1	Reply	683
target="_blank" rel="nofollow">http://daniel-marco.com/Academic%20Files/Additive%20Noise%20Model.pdf).</a> Our expression estimates the MSE as a combination of the MSE that results from the quantization error in the ‚Äúmiddle part‚Äù (i.e., uniformly distributed) and the MSE that results from the clipping error at the tails of the distribution (i.e., laplacian/gaussian).	I-Reply	I-1	Reply	683
We verify this assumptions using synthetic simulations that clearly show that this type of approximation is accurate in practice (see figure 2).	I-Reply	I-1	Reply	683
We also provide the code for this simple synthetic experiment here: <a href="https://github.com/submission2019/AnalyticalScaleForIntegerQuantization" target="_blank" rel="nofollow">https://github.com/submission2019/AnalyticalScaleForIntegerQuantization</a> .	I-Reply	I-1	Reply	683
Finally, we now have a more general expression that estimates the MSE of any density function at the middle part using a piece wise linear approximation, enabling to use not only uniform distributions at the middle part.	I-Reply	I-1	Reply	683
<sep> <sep> 2.	O	O	Reply	683
Since submission, we made a comparison against the only previous method we are aware of: the Kullback-Leibler Divergence (KLD) clipping method suggested by NVIDIA (see update for table 1).	B-Reply	B-2	Reply	683
Our approach runs 4000 times faster compared to KLD and, excluding ResNet-101, outperforms KLD in terms of validation accuracy.	I-Reply	I-2	Reply	683
<sep> <sep> 3.	O	O	Reply	683
We agree that the mean and sigma are continuous numbers.	B-Reply	B-3	Reply	683
But the correct clipping value can be calculated by scaling the optimal clipping value for the standard gaussian distribution N(0,1) by sigma.	I-Reply	I-3	Reply	683
We use this trick in our simulations.	I-Reply	I-3	Reply	683
We improved the explanation of this issue (see Section 5  - end of the second paragraph)	I-Reply	I-3	Reply	683

The authors propose here a method for off-policy policy evaluation (OPPEval), to use the reinforcement reinforcement learning on infinite horizon problems from previously-collected trajectories.	O	O	Review	686
<sep> <sep> The authors frame their work that much of the focus in the OPPEval field has been on, as they call, "policy-aware" methods that use information from the policy  to improve estimates  to cope with the mismatch between then behaviour and the estimated target policy (such as IS, WIS, etc) when computing state stationary distribution.	O	O	Review	686
These contrast "policy agnostic" methods (DualDICE, Nachum et al, 2019) that suffer from the curse of dimensionality in estimating the much higher dimensional state-action stationary distributions but do not depend on policy information.	O	O	Review	686
<sep> The manuscripts novelty rests in a comparing and relating  these agnostic/aware approaches and propose a partially policy-agnostic method (EMP) that strives to combine advantages from both approaches by following a mixture approach (effectively a mixture of weighted policies).	O	O	Review	686
The authors provide a derivation of their methods bounds and show that their method outperforms policy-aware methods as well as policy-agnostic methods.	B-Review	B-1	Review	686
In the comprehensive experiments they compare recent methods by Liu et al (BCH) and WIS (I suppose they mean weighted importance sampling following Prenup et al 2000, as no citation given) ), as well a a new policy-agnostic method they propose here (SADL).	I-Review	I-1	Review	686
In all cases the results  favour the proposed new method (EMP).	I-Review	I-1	Review	686
The results advance the field by providing a pathway to improved estimation results (lower uncertainty) by using policy mixtures.	I-Review	I-1	Review	686
While I have not checked the derivations line-by-line the results are consistent and interesting, although not entirely clear to me why this is an important contribution to a representational learning conference.	B-Review	B-3	Review	686
<sep> <sep> A key question to this paper (and the OPPEval field) is to evaluate their methods  more consistently in closed-loop agent experiments - after training on the historical data.	B-Review	B-2	Review	686
Perhaps for a representational learning conference this would be more appropriate way to convince one of the strength of the results.	I-Review	I-2	Review	686
<sep> <sep> - We have added the missing citation Prenup et al 2000.	B-Reply	B-1	Reply	686
<sep> <sep> -  To certain extend, our method shows the performance improvement of OPPEval algorithm by using certain representation model (especially in continuous case) to learn the specific information about the underlying behavior policies from data.	B-Reply	B-2	Reply	686
Besides, there are applications where policy evaluation is the ultimate goal in itself [1]. Policy evaluation algorithms are also important to study because they are often key parts of larger algorithms where the ultimate goal is to find an optimal policy (one such example is the class of actor-critic algorithms, see [2] for a survey).	I-Reply	I-2	Reply	686
We feel that ICLR seems to be expanding its scope and covering more general topics in ML and the topic of this paper fits this trend.	I-Reply	I-2	Reply	686
<sep> <sep> [1] P. Balakrishna, R. Ganesan, and L. Sherry, ‚ÄúAccuracy of reinforcement learning algorithms for predictingaircraft taxi-out times: A case-study of tampa bay departures,‚ÄùTransportation Research Part C: EmergingTechnologies, vol.18, no.	O	O	Reply	686
6, pp.950‚Äì962, 2010.	O	O	Reply	686
<sep> <sep> [2]I. Grondman, L. Busoniu, G. A. Lopes, and R. Babuska, ‚ÄúA survey of actor-critic reinforcement learning:Standard and natural policy gradients,‚ÄùIEEE Transactions on Systems, Man, and Cybernetics, Part C(Applications and Reviews), vol.42, no.	O	O	Reply	686
6, pp.1291‚Äì1307, 2012	O	O	Reply	686

After rebuttal:	O	O	Review	686
Thank author for the clarification.	O	O	Review	686
The new version looks better and I tend to accept the paper in the current version.	O	O	Review	686
<sep> =========	O	O	Review	686
This paper provides a algorithm to solve infinite horizon off policy evaluation with multiple behavior policies by estimate a mixed policy under regression, and follows the same method of BCH.	O	O	Review	686
The intuition of using an estimated policy comes from Hanna et al (2019) which shows that an estimated policy ratio can reduce variance even it introduces additional bias.	O	O	Review	686
The authors provide theoretical proof on that and arguing that their method is not worse than BCH one.	O	O	Review	686
Empirical results show that in general their method performs as good as previous baseline.	O	O	Review	686
I believe this method is novel and natural and worth investigating.	O	O	Review	686
<sep> <sep> Technical Concerns:	O	O	Review	686
The major concern I have is in continuous case, it is almost impossible to pre-assume a model for learning the mixed policy.	B-Review	B-1	Review	686
For example, if the sample policies are all Gaussians, then according to equation (4) would be a complicated mixture distribution (not even a Gaussian mixture since it involves ratio of which is hard to compute).	I-Review	I-1	Review	686
If the model is not precise, we cannot achieve the bias/variance tradeoff where the bias introduce by model mismatching can be arbitrarily large.	I-Review	I-1	Review	686
<sep> And according to the experimental details in appendix E, I didn't find any useful model assumption to address that issue.	I-Review	I-1	Review	686
So my question would be: what model are you using when doing regression for?	I-Review	I-1	Review	686
<sep> <sep> Clarity Concern:	O	O	Review	686
The written of the paper is not satisfactory.	B-Review	B-2	Review	686
The major contribution should be highlight in section 4, which from my first time reading is very unclear.	I-Review	I-2	Review	686
The key observation of equation (4) uses a recursive definition, where we define using an undefined.	I-Review	I-2	Review	686
I think you should rewrite as the weighted summation of.	I-Review	I-2	Review	686
And you should avoid repeating similar equation like (2) (3) (6) and (7) where you can cite equation (2) in general or use a short notation for that equation, otherwise it is hard to contract the contribution of the paper.	B-Review	B-3	Review	686
<sep> The experiment part is also unclear.	B-Review	B-4	Review	686
Here's some questions: 1) How many repetitions you apply for each figure?	B-Review	B-5	Review	686
It seems not smooth enough.	I-Review	I-5	Review	686
2) Which estimator you use for you regression?	B-Review	B-6	Review	686
Maximum Likelihood Estimation?	I-Review	I-6	Review	686
Which model you are using for each environment (I know for tabular MLE is count based)?	I-Review	I-6	Review	686
3) What is in section E.3 equation (12)?	B-Review	B-7	Review	686
How do you compute KL divergence in this equation for empirical distribution?	I-Review	I-7	Review	686
<sep> <sep> Some minor issues:	O	O	Review	686
1.	B-Review	B-8	Review	686
You should replace 'for all' to when writing equation, like equation before (2), equation (6) and equation in proposition 4.	I-Review	I-8	Review	686
<sep> 2.	O	O	Review	686
You'd better to separate legend with figure in order to make the legend larger and figure clearer.	B-Review	B-9	Review	686
<sep> <sep> Overall, I think this work is very novel and natural, but should give more consideration on the model selection.	O	O	Review	686
I tend to reject the paper by the current version and encourage the authors to submit to another conference after the revision.	O	O	Review	686
Response to Technical Concerns:	O	O	Reply	686
In our experiment, we use a neural network to approximate the mixture policy in continuous case and estimate the model by MLE.	B-Reply	B-1	Reply	686
We have added a paragraph explaining this for the general algorithm in Section 4.2 and for the numerical experiment in Appendix D.2.	I-Reply	I-1	Reply	686
We agree with the reviewer that when model is not precise, the bias will overwhelmed the variance reduction.	I-Reply	I-1	Reply	686
We explicitly explained that the performance of EMP relies on the accuracy of policy learning in the introduction part.	I-Reply	I-1	Reply	686
We think the problem of model uncertainty is interesting and more challenging, and probably requires a different theoretic framework, such as robust optimization, so we will leave this for further study.	I-Reply	I-1	Reply	686
Therefore, in most part of the paper, to study the effect of policy learning on OPPE performance, we would like to focus on the cases that the policy can be well approximated by some parametric model, especially for theoretic analysis.	I-Reply	I-1	Reply	686
<sep> <sep> Response to Clarity Concerns:	O	O	Reply	686
- We have modified Section 4 according to the comments of the reviewers.	B-Reply	B-2	Reply	686
We added a subsection to more formally define the mixture policy pi_M and the mixture distribution d_M (to better distinguish from the single-behavior policy, we have also changed the notation.)	I-Reply	I-2	Reply	686
We also provided additional theoretic properties of \pi_M and d_M to provide more intuition behind the algorithm design.	I-Reply	I-2	Reply	686
<sep> - We have removed equation (3) and (6).	B-Reply	B-3	Reply	686
But we keep equation (7) (now becomes (6)) to make the description of EMP algorithm more self-contained.	I-Reply	I-3	Reply	686
<sep> - We have also modified the experiment part.	B-Reply	B-4	Reply	686
First, we added new comparison results to the state-of-art policy-agnostic method DualDICE.	I-Reply	I-4	Reply	686
Second, we reorganized experiment part to make it more consistent with the theoretic analysis, hope this could convey clearer messages of the numerical experiments.	I-Reply	I-4	Reply	686
<sep> <sep> Response to Questions:	O	O	Reply	686
1)How many repetitions you apply for each figure?	O	O	Reply	686
It seems not smooth enough.	O	O	Reply	686
<sep> -we have increased the number of repetitions by 3 times and updated the numerical results.	B-Reply	B-5	Reply	686
<sep> 2)Which estimator you use for you regression?	O	O	Reply	686
Maximum Likelihood Estimation?	O	O	Reply	686
Which model you are using for each environment (I know for tabular MLE is count based)?	O	O	Reply	686
<sep> - For the three discrete environment, we used count-frequency to estimate the policy.	B-Reply	B-6	Reply	686
For the continuous environment, we used a neural network to model the policy and MLE to estimate the model parameters.	I-Reply	I-6	Reply	686
We have added a paragraph explaining our model and estimation methods in Appendix D.2. (	I-Reply	I-6	Reply	686
E.2 in the previous version).	I-Reply	I-6	Reply	686
<sep> 3)What is in section E.3 equation (12)?	O	O	Reply	686
How do you compute KL divergence in this equation for empirical distribution?	O	O	Reply	686
<sep> - Equation (12) is used to defined the adjusted proportion of data from each policy.	B-Reply	B-7	Reply	686
It involves the KL-divergence, which is computed by estimating the behavior policy by a parametric model.	I-Reply	I-7	Reply	686
We have added some explanation in Section D.3 (E.3 in the previous version.)	I-Reply	I-7	Reply	686
<sep> <sep> Response to Minor Issues:	O	O	Reply	686
1.You should replace 'for all' to when writing equation, like equation before (2), equation (6) and equation in proposition 4.	O	O	Reply	686
<sep> - We have replaced ‚Äòfor all‚Äô with ‚Äò\forall‚Äô in the equations.	B-Reply	B-8	Reply	686
<sep> 2.You'd better to separate legend with figure in order to make the legend larger and figure clearer.	O	O	Reply	686
<sep> - We have changed the format of figures accordingly.	B-Reply	B-9	Reply	686

*Synopsis*:	O	O	Review	686
The main contribution of this paper is the development of estimated mixture policy (EMP), which takes ideas from the new off-policy policy evaluation infinite horizon estimators (i.e. Liu) and from a recent development in more traditional importance weight approaches using regression importance sampling (i.e. Hannah).	O	O	Review	686
This new method provides a nice extension of Liu's algorithm to many policies, and to when the policy is unknown.	O	O	Review	686
The paper provides some nice analysis inspired by Hannah.	O	O	Review	686
Finally, they provide empirical results.	O	O	Review	686
<sep> <sep> <sep> *Review*:	O	O	Review	686
<sep> While I think the method has potential interest to the community, I found the empirical results lacking (particularly in missing competitors).	O	O	Review	686
I also have some concerns about the theory as there seems to be many typos and consistency issues making much of it hard to follow.	O	O	Review	686
Overall, I think this paper is not quite up for publication, but if the authors address my consistency/missing proofs issues and provide a comparison to DualDice I will increase my score.	O	O	Review	686
<sep> <sep> 1.	B-Review	B-1	Review	686
I don't find the reason provided for not including DualDICE compelling and think it is an important competitor here, as there are many similarities between the two methods.	I-Review	I-1	Review	686
<sep> - It would also be interesting to reproduce the results provided by Liu et al with the model based approach, and the on-policy oracle.	I-Review	I-1	Review	686
I don't think these are as pressing as DualDice but still interesting.	I-Review	I-1	Review	686
<sep> <sep> 2.	O	O	Review	686
There are many consistency issues with respect to notation, and some odd notation choices as compared to the rest of the literature:	B-Review	B-2	Review	686
- What is script \epsilon in the equation in 2.1?	I-Review	I-2	Review	686
It looks like it should be an expectation over d_\pi, but I've never seen this notation before.	I-Review	I-2	Review	686
<sep> - The indicies of sums and sets often change between one based and zero based indexing.	I-Review	I-2	Review	686
This should be unified (preferably to one based).	I-Review	I-2	Review	686
For example, section 2.1 \pi_j(j=0,1,2,...,m) and m=1 for one policy doesn't work.	I-Review	I-2	Review	686
Either \pi_j(j=0,1,2,...m-1) or m=0.	I-Review	I-2	Review	686
This occurs throughout the proofs in the appendix as well.	I-Review	I-2	Review	686
<sep> - What is script \Epsilon_\theta?	I-Review	I-2	Review	686
Do you mean script F_\theta?	I-Review	I-2	Review	686
And then what does it mean for \theta_0 \in E_1?	I-Review	I-2	Review	686
There seems to be many definitions missing.	I-Review	I-2	Review	686
<sep> <sep> 2.5.	O	O	Review	686
There are also some issues with the presentation of the theory over the consistency issues already mentioned.	B-Review	B-3	Review	686
<sep> - The assumptions and conditions for the theorems presented in the main text should be clearly specified in the theory statement.	I-Review	I-3	Review	686
<sep> - The proof to theorem 2 (i.e. in the appendix) should be provided.	B-Review	B-3	Review	686
<sep> - The proof of proposition 4 seems to be missing as well.	B-Review	B-3	Review	686
<sep> <sep> *Questions*	O	O	Review	686
Q1 What are the properties of SADL?	B-Review	B-4	Review	686
Why was this used instead of DualDICE in the comparison?	I-Review	I-4	Review	686
<sep> <sep> Q2 How would BCH do if we used the mixture policy as the behavior policy in the multiple behavior policy case?	B-Review	B-5	Review	686
How would it compare to your method?	I-Review	I-5	Review	686
This could be an interesting comparison, just to test if the lower MSE argument holds up in the multiple behavior policy case.	I-Review	I-5	Review	686
<sep> <sep> Q3 What is the meaning of partially-policy-agnostic?	B-Review	B-6	Review	686
It is unclear to me how it is different from the policy-agnostic approaches.	I-Review	I-6	Review	686
If all that is different is you are estimating the behavior to use in the usual infinite-horizon approach, should this be in a separate category from policy-agnostic approaches? (	I-Review	I-6	Review	686
I would say probably not, but I think you could make a case for it).	I-Review	I-6	Review	686
<sep> <sep> Q4 "Then, a single (s,a,s') tuple simply follows the marginal distribution...".	B-Review	B-7	Review	686
Is this trivially true?	I-Review	I-7	Review	686
<sep> <sep> *Minor comments not taken into account in the review*	B-Review	B-8	Review	686
- section 2.1 "target policy \pi via a pre-collected..." -&gt; remove "a"	I-Review	I-8	Review	686
- The layout of the related works section is a bit hard to follow.	I-Review	I-8	Review	686
<sep> - "Recently, Nachum et al (2019) proposes DualDice": proposes-&gt;proposed	I-Review	I-8	Review	686
- "by their estimated values in two folds": do you mean in two ways?	I-Review	I-8	Review	686
This is unclear.	I-Review	I-8	Review	686
<sep> - Section 3.1: "notation abusion" -&gt; notation abuse	I-Review	I-8	Review	686
- Equation right after equation 1: "d_\pi_0(s)\pi(a|s)" -&gt; "d_\pi_0(s)\pi_0(a|s)"	I-Review	I-8	Review	686
- "The derivation of kernel method are put in..." -&gt; "The derivation of the kernel method is put in..."	I-Review	I-8	Review	686
- "we need introduce more notation" -&gt; "we need to introduce more notation"	I-Review	I-8	Review	686
- Section 4: "detailed description on the data sample": "on"-&gt;"of"	I-Review	I-8	Review	686
- "In this light by pooling the data together...." These two sentences should be put together.	I-Review	I-8	Review	686
<sep> - I would like if your theorems were restated in the appendix, for ease of reading.	I-Review	I-8	Review	686
<sep> <sep> -----------	O	O	Review	686
Post Rebuttal	O	O	Review	686
<sep> I'd like to thank the author for their thorough response!	O	O	Review	686
Given the major additions to the paper including empirical comparisons and clarity for the theory I've decided to update my score to reflect my new feelings (i.e. to a 6).	O	O	Review	686
I think this paper is well worth accepting in its current form.	O	O	Review	686
<sep> <sep> Response to Major Comments:	O	O	Reply	686
1.	O	O	Reply	686
- We got the released code and carried out a comparison study with DualDICE.	B-Reply	B-1	Reply	686
<sep> - We implemented  a variation of BCH method by Liu et al for mutliple-behavior-policy cases, called BCH (pooled), using the exact value of all behavior policies.	B-Reply	B-1	Reply	686
We now report the comparison results of our method EMP, BCH and DualDICE in both single- and multi-behavior-policy settings.	I-Reply	I-1	Reply	686
<sep> - We use the estimation results by on-policy oracle with large trajectory length and number as the ‚Äútrue-value‚Äù.	B-Reply	B-1	Reply	686
This is how we compute the MSE for EMP and other benchmark OPPE methods.	I-Reply	I-1	Reply	686
<sep> <sep> 2.	O	O	Reply	686
<sep> - We have correct this typo on page 2.	B-Reply	B-2	Reply	686
<sep> - We have unified the notation so that all indicies start from 1.	I-Reply	I-2	Reply	686
<sep> - We have correct these typos.	I-Reply	I-2	Reply	686
is the correct notation for parameter space.	I-Reply	I-2	Reply	686
<sep> - We also went through the mathematical part of the paper and corrected the typos we have found.	I-Reply	I-2	Reply	686
<sep> <sep> 2.5	O	O	Reply	686
- We now cite the assumptions in the statement of the theorems.	B-Reply	B-3	Reply	686
The detailed assumptions are stated and explained in Appendix B. We didn‚Äôt directly include the full assumptions in the statement of the theorem mainly because of the space limit.	I-Reply	I-3	Reply	686
Most of the assumptions actually involve technical details about the kernel method that solves the min-max problems, and they need space of half to one page.	I-Reply	I-3	Reply	686
<sep> - We have removed the SADL algorithm in the revision, as it was used as an substitute of DualDICE in the previous version of the paper.	B-Reply	B-3	Reply	686
So we also removed (the original) Theorem 2, which follows a very similar proof as the kernel-method derivation in Liu et al	I-Reply	I-3	Reply	686
- Proposition 4 (now 3) has been proved in Veach &amp; Guibas (1995).	B-Reply	B-3	Reply	686
We include it mainly for self-containedness and refer to the original paper for the proof.	I-Reply	I-3	Reply	686
We now cite Veach &amp; Guibas (1995) more explicitly in the statement of Proposition 3.	I-Reply	I-3	Reply	686
<sep> <sep> Response to Questions:	O	O	Reply	686
Q1 What are the properties of SADL?	O	O	Reply	686
Why was this used instead of DualDICE in the comparison?	O	O	Reply	686
<sep> - We are not aware of the DualDICE code releasing when we first submitted this paper.	B-Reply	B-4	Reply	686
So we use SADL as a substitute of DualDICE.	I-Reply	I-4	Reply	686
They are both policy-agnoistic and learn the state-action joint distribution correction.	I-Reply	I-4	Reply	686
<sep> <sep> Q2 How would BCH do if we used the mixture policy as the behavior policy in the multiple behavior policy case?	O	O	Reply	686
How would it compare to your method?	O	O	Reply	686
This could be an interesting comparison, just to test if the lower MSE argument holds up in the multiple behavior policy case.	O	O	Reply	686
<sep> - We implemented a multiple-behavior-policy version of Liu et al, using the information of all behavior policies.	B-Reply	B-5	Reply	686
We call it BCH (pooled) and report the comparison results of our method EMP, BCH (pooled) and DualDICE.	I-Reply	I-5	Reply	686
<sep> <sep> Q3 What is the meaning of partially-policy-agnostic?	O	O	Reply	686
It is unclear to me how it is different from the policy-agnostic approaches.	O	O	Reply	686
If all that is different is you are estimating the behavior to use in the usual infinite-horizon approach, should this be in a separate category from policy-agnostic approaches? (	O	O	Reply	686
I would say probably not, but I think you could make a case for it).	O	O	Reply	686
<sep> -We call EMP a partially policy-agnostic method in the sense that, although EMP does not require any information on the ‚Äúphysical‚Äù behavior policies, it learns a ‚Äúvirtual‚Äù policy, which is the mixture policy, defined formally in Section 4.1, and contains aggregated information about the ‚Äúphysical‚Äù behavior polices.	B-Reply	B-6	Reply	686
As a consequence, the accuracy of the ‚Äúvirtual‚Äù policy learning (conceptually, whether the algorithm can effectively extract the aggregated information about the behavior policies) will affect the performance of EMP.	I-Reply	I-6	Reply	686
We now add this explanation to the introduction part.	I-Reply	I-6	Reply	686
<sep> <sep> Q4 "Then, a single (s,a,s') tuple simply follows the marginal distribution...".	O	O	Reply	686
Is this trivially true?	O	O	Reply	686
<sep> - We added a new Subsection 4.1 to more formally state our assumptions on the sample data collected from different behavior policies and the relevant distributions.	B-Reply	B-7	Reply	686
<sep> <sep> Response to Minor Comments:	O	O	Reply	686
- We have corrected all the typos accordingly.	B-Reply	B-8	Reply	686
As to the related work part, we added a few sentences of explanation at several places to improve the logic flow.	I-Reply	I-8	Reply	686

Hi,	O	O	Review	5
<sep> This looks a whole lot like the semi-supervised recursive autoencoder that we introduced at EMNLP 2011 [1] and the unfolding recursive autoencoder that we introduced at NIPS 2011.	B-Review	B-1	Review	5
<sep> <sep> These models also have a reconstruction + cross entropy error at every iteration and hence do not suffer from the vanishing gradient problem.	O	O	Review	5
<sep> <sep> The main (only?)	B-Review	B-2	Review	5
differences are the usage of a rectified linear unit instead of tanh and restricting yourself to have a chain structure which is just a special case of a tree structure.	I-Review	I-2	Review	5
<sep> <sep> [1] <a href="http://www.socher.org/index.php/Main/Semi-SupervisedRecursiveAutoencodersForPredictingSentimentDistributions" target="_blank" rel="nofollow">http://www.socher.org/index.php/Main/Semi-SupervisedRecursiveAutoencodersForPredictingSentimentDistributions</a>	O	O	Review	5
Thank you very much for your constructive comments.	O	O	Reply	5
<sep> <sep> There are indeed similarities between discriminative recurrent auto-encoders and the semi-supervised recursive autoencoders of Socher, Pennington, Huang, Ng, & Manning (2011a); we will add the appropriate citation to the paper.	B-Reply	B-1	Reply	5
However, the networks of Socher et al (2011a) are very similar to RAAMs (Pollack, 1990), but with a dynamic, greedy recombination structure and a discriminative loss function.	B-Reply	B-2	Reply	5
As a result, they differ from DrSAE as outlined in our response to Jurgen Schmidhuber.	I-Reply	I-2	Reply	5
Like the work of Socher et al (2011a), DrSAE is based on an recursive autoencoder that receives input on each iteration, with the top layer subject to a discriminative loss.	I-Reply	I-2	Reply	5
However, Socher et al (2011a), like Pollack (1990), iteratively adds new information on each iteration, and then reconstructs both the new information and the previous hidden state from the resulting hidden state (Socher, Huang, Pennington, Ng, & Manning, 2011 reconstructs the entire history of inputs).	I-Reply	I-2	Reply	5
The discriminative loss function is also applied at every iteration.	I-Reply	I-2	Reply	5
In contrast, the input to DrSAE is the same on each iteration, and only the reconstruction and classification based upon the final state is optimized.	I-Reply	I-2	Reply	5
The entire recursive LISTA stack constitutes a single encoder, which is decoded in a single (linear) step.	I-Reply	I-2	Reply	5
Whereas Socher et al (2011a) performs discriminative compression of a variable-length, structured input using a zero-hidden-layer encoder, our goal is static autoencoding using a deep (recursive) encoder.	I-Reply	I-2	Reply	5
<sep> Moreover, the main contribution of our paper is the demonstration of a novel and interesting hidden representation (based upon prototypes and their deformations along the data manifold), along with a network that naturally learns this representation.	B-Reply	B-2	Reply	5
The hierarchical refinement of categorical-units from part-units that we observe seems unlikely to evolve in the networks of Socher et al (2011a), since the activity of the part-units cannot be maintained across iterations by continuous input.	I-Reply	I-2	Reply	5
The KL-divergence used for discriminative training in Socher et al (2011a) is only identical to the logistic loss if the target distributions have no uncertainty (i.e., they are one-hot).	I-Reply	I-2	Reply	5
Our ongoing work suggests that this difference is likely to be important for the differentiation of categorical-units and part-units.	I-Reply	I-2	Reply	5

The paper describes the following variation of an autoencoder: An encoder (with relu nonlinearity) is iterated for 11 steps, with observations providing biases for the hiddens at each step.	O	O	Review	5
Afterwards, a decoder reconstructs the data from the last-step hiddens.	O	O	Review	5
In addition, a softmax computes class-labels from the last-step hiddens.	O	O	Review	5
The model is trained on labeled data using the sum of reconstruction and classification loss.	O	O	Review	5
To perform unsupervised pre-training the classification loss can be ignored initially.	O	O	Review	5
<sep> <sep> It is argued that training the architecture causes hiddens to differentiate into two kinds of unit (or maybe a continuum): part-units, which mainly try to perform reconstruction, and categorical units, which try to perform classification.	B-Review	B-1	Review	5
Various plots are shown to support this claim empirically.	I-Review	I-1	Review	5
<sep> <sep> The idea is interesting and original.	I-Review	I-1	Review	5
The work points towards a direction that hasn't been explored much, and that seems relevant in practice and from the point of view of how classification may happen in the brain.	I-Review	I-1	Review	5
Some anecdotal evidence is provided to support the part-categorical separation claim.	I-Review	I-1	Review	5
The evidence seems interesting.	I-Review	I-1	Review	5
Though I'm pondering still whether there may be other explanations for those plots.	I-Review	I-1	Review	5
Training does seem to rely somewhat on finely tuned parameter settings like individual learning rates and weight bounds.	I-Review	I-1	Review	5
<sep> <sep> It would be nice to provide some theoretical arguments for why one should expect the separation to happen.	B-Review	B-2	Review	5
A more systematic study would be nice, too, eg.measuring how many recurrent iterations are actually required for the separation to happen.	I-Review	I-2	Review	5
To what degree does that separation happen with only pre-training vs. with the classification loss?	I-Review	I-2	Review	5
And in the presence of classification loss, could it happen with shallow model, too?	I-Review	I-2	Review	5
The writing and organization of the paper seems preliminary and could be improved.	I-Review	I-2	Review	5
For example, it is annoying to jump back-and-forth to refer to plots, and some plots could be made more informative (see also comments below).	I-Review	I-2	Review	5
<sep> <sep> The paper seems to suggest that the model gradually transforms an input towards a class-template.	B-Review	B-3	Review	5
I'm not sure if I agree, that this is the right view given that the input is clamped (by providing biases via E) so it is available all the time.	I-Review	I-3	Review	5
Any comments?	I-Review	I-3	Review	5
<sep> <sep> It may be good to refer to 'Learning continuous attractors in recurrent networks', Seung, NIPS 1998, which also describes a recurrent autoencoder (though that model is different in that it iterates encoder+decoder not just encoder with clamped data).	B-Review	B-4	Review	5
<sep> <sep> <sep> Questions/comments:	O	O	Review	5
<sep> - It would be much better to show the top-10 part units and the top-10 categorical units instead of figure 2, which shows a bunch of filters for which it is not specified to what degree they're which (except for pointing out in the text that 3 of them seem to be more like categorical units).	B-Review	B-5	Review	5
<sep> <sep> - What happens if the magnitude of the rows of E is bounded simply by 1/T instead of 1.25/(T-1) ? (	B-Review	B-6	Review	5
page 3 sentence above Eq.4) Are learning and classification results sensitive to that value?	I-Review	I-6	Review	5
<sep> <sep> - Last paragraph of section 1: 'through which the prototypes of categorical-units can be reshaped into the current input': Don't you mean the other way around?	B-Review	B-7	Review	5
<sep> <sep> - Figure 4 seems to suggest that categorical units can have winner-takes-all dynamics that disfavor other categorical units from the same class.	B-Review	B-8	Review	5
Doesn't that seem strange?	I-Review	I-8	Review	5
<sep> <sep> - Section 3.2 (middle) mentions why S-I is plotted but S-I is shown and referred to before (section 3.1) and the explanation should instead go there.	B-Review	B-9	Review	5
<sep> <sep> - What about the 2-step model result with 400 hiddens (end of section 4)?	B-Review	B-10	Review	5
*Anonymous dd6a	O	O	Reply	5
<sep> Thank you very much for your helpful comments.	O	O	Reply	5
<sep> <sep> P2: Both the categorical-units and the part-units participate in reconstruction.	B-Reply	B-1	Reply	5
Since the categorical-units become more active than the part-units (as per figure 7), they actually make a larger contribution to the reconstruction (evident in figure 9(b,c), where even the first step of the progressive reconstruction is strong).	I-Reply	I-1	Reply	5
<sep> <sep> P4: The differentiation into part-units and categorical-units does occur even with only two ISTA iterations (one pass through the explaining-away matrix), the shallowest architecture in which categorical-units can aggregate over part-units, as noted at the end of section 4.	B-Reply	B-2	Reply	5
Without the classification loss, the network is an instance of (non-negative) LISTA, and categorical-units do not develop at all.	I-Reply	I-2	Reply	5
Thus, only one recurrent iteration is required for categorical-units to emerge, and the classification loss is essential for categorical-units to emerge.	I-Reply	I-2	Reply	5
We have added plots to figure 3 demonstrating these phenomena.	I-Reply	I-2	Reply	5
<sep> With regards to the theoretical cause of the differentiation into categorical-units and part-units, please see part 1 of our response to Yoshua Bengio.	I-Reply	I-2	Reply	5
<sep> <sep> The three plots at the end were intended to serve as supplementary materials.	I-Reply	I-2	Reply	5
However, as you point out, these figures are important for the analysis presented in the text, so they have been moved into the main text.	I-Reply	I-2	Reply	5
<sep> <sep> P5: The network decomposes the input into a prototype and a sparse set of perturbations; we refer to these perturbations, encoded in the part-units, as the signal that 'transforms' the prototype into the input.	B-Reply	B-3	Reply	5
That is, categorical + part ~ input.	I-Reply	I-3	Reply	5
The input itself is not (and need not be) modified in the process of constructing this decomposition.	I-Reply	I-3	Reply	5
The clamping of the input does not affect this interpretation.	I-Reply	I-3	Reply	5
<sep> P6: Thank you for the reference; we have included it in the paper.	B-Reply	B-4	Reply	5
Of course, since Seung (1998) does not include a discriminative loss function, there is no reason to believe that categorical-units differentiated from part-units in his model.	I-Reply	I-4	Reply	5
<sep> <sep> Q1: We have made the suggested change to figure 2.	B-Reply	B-5	Reply	5
Filters sorted by categoricalness are also shown in figures 5, 6, 7, and 10.	I-Reply	I-5	Reply	5
<sep> <sep> Q2: We have not yet undertaken a rigorous or extensive search of hyperparameter space.	B-Reply	B-6	Reply	5
We expect the results with with the rows of E bounded by 1/T will be similar to those with a bound of 1.25/T.  The (T-1) in the denominator of this bound in the paper was a typo, which we have corrected.	I-Reply	I-6	Reply	5
<sep> <sep> Q3: The assertion that 'the prototypes of categorical-units are reshaped into the current input' is mathematically equivalent to 'the current input is reshaped into the prototypes of categorical-units.'	B-Reply	B-7	Reply	5
In one case, categorical + part = input; in the other, input - part = categorical.	I-Reply	I-7	Reply	5
Both interpretations are actively enforced by the reconstruction component of the loss function L^U in equation 1.	I-Reply	I-7	Reply	5
Since the inputs are clamped, we find it most intuitive to think of the reconstruction due to the prototypes of the categorical-units being reshaped by the part-units to match the fixed input.	I-Reply	I-7	Reply	5
<sep> <sep> Q4: When a chosen categorical-unit suppresses other categorical-units of the same class, it corresponds to the selection of a single prototype, which is both natural and desirable.	B-Reply	B-8	Reply	5
It is easy to imagine that there may be classes with multiple prototypes, for which arbitrary linear combinations of the prototypes are not members of the class.	I-Reply	I-8	Reply	5
For example, the sum of a left-leaning 1 and a right-leaning 1 is an X, rather than a 1.	I-Reply	I-8	Reply	5
<sep> Q5: Indeed, the ISTA-mediated relationship between S-I and D^t*D is first discussed in the second paragraph of section 3.	B-Reply	B-9	Reply	5
This is the clearest explanation for the use of S-I.  We have removed other potentially-confusing, secondary justifications, and further clarified the intuitive basis of this primary justification.	I-Reply	I-9	Reply	5
<sep> <sep> Q6: We have added the requested result on the 2-step model with 400 hiddens at the end of section 4.	B-Reply	B-10	Reply	5
The trend is the same with 400 units as with 200 units.	I-Reply	I-10	Reply	5
If the number of recurrent iterations is decreased from eleven to two, MNIST classification error in a network with 400 hidden units increases from 1.08% to 1.32%.	I-Reply	I-10	Reply	5
With only 200 hidden units, MNIST classification error increases from 1.21% to 1.49%, although the hidden units still differentiate into part-units and categorical-units.	I-Reply	I-10	Reply	5

SUMMARY:	O	O	Review	5
<sep> The authors describe a discriminative recurrent sparse auto-encoder, which is essentially a recurrent neural network with a fixed input and linear rectifier units.	O	O	Review	5
The auto-encoder is initially trained to reproduce digits of MNIST, while enforcing a sparse representation.	O	O	Review	5
In a later phase it is trained in a discriminative (supervised) fashion to perform classification.	O	O	Review	5
<sep> The authors discuss their observations.	O	O	Review	5
Most prominently they describe the occurrence of two types of nodes: part-units, and categorical units The first are units that encode low-level features such as pen-strokes, whereas the second encode specific digits within the MNIST set.	O	O	Review	5
It is shown that before the discriminative training, the image reconstruction happens mostly by combining pen-strokes, whereas after the discriminative training, image reproduction happens mainly by the combination of a prototype digit of the corresponding class, which is subsequently transformed by adding pen-stroke-like features.	O	O	Review	5
The authors state that this observation is consistent with the underlying hypothesis of auto-encoders that the data lies on low-dimensional manifolds, and the auto-encoder learns to split the representation of a digit into a categoric prototype and a set of transformations.	O	O	Review	5
<sep> <sep> GENERAL OPINION	O	O	Review	5
<sep> The paper and the suggested network architecture is interesting and, as far as I know, quite original.	O	O	Review	5
It is also compelling to see the unique ways in which the unsupervised and supervised training contribute to the image reconstruction.	O	O	Review	5
Overall I believe this paper is a suited contribution to this conference.	O	O	Review	5
I have some questions and remarks that I will list here.	O	O	Review	5
<sep> <sep> QUESTIONS	O	O	Review	5
<sep> - From figure 5 I get the impression that the states dynamics are convergent; for sufficiently large T, the internal state of the nodes (z) will no longer change.	B-Review	B-1	Review	5
This begs the question: is the ideal situation that where T goes to infinity?	I-Review	I-1	Review	5
If so, could you consider the following scenario: We somehow compute the fixed, final state (maybe this can be performed faster than by simply iterating the system).	I-Review	I-1	Review	5
Once we have it, we can perform backpropagation-through-time on a sequence where each step in time, the states are identical (the fixed-point state).	I-Review	I-1	Review	5
This would be an interesting scenario, as you might be able to greatly accelerate the training process (all Jacobians are identical, error backpropagation has an analytical solution), and you explicitly train the system to perform well on this fixed point, transient effects are no longer important.	I-Review	I-1	Review	5
<sep> Perhaps I'm missing some crucial detail here, but it seems like an interesting scenario to discuss.	I-Review	I-1	Review	5
<sep> <sep> - On a related note: what happens if - after training - the output (image reconstruction and classification) is constructed using the state from a later/earlier point in time?	B-Review	B-2	Review	5
How would performance degrade as a function of time?	I-Review	I-2	Review	5
<sep> <sep> REMARKS	O	O	Review	5
<sep> - In both the abstract and the introduction the following sentence appears: 'The depth implicit in the temporally-unrolled form allows the system to exhibit all the power of deep networks, while substantially reducing the number of trainable parameters'.	B-Review	B-3	Review	5
I believe this is an dangerous statement, as tied weights will also impose a severe restriction on representational power (so they will not have 'all the power of deep networks').	I-Review	I-3	Review	5
I would agree with a rephrasing of this sentence that says something along the lines of: 'The depth implicit in the temporally-unrolled form allows the system to exhibit far more representational power, while keeping the number of trainable parameters fixed'.	I-Review	I-3	Review	5
<sep> - I agree with the Yoshua's remark on the vanishing gradient problem.	B-Review	B-4	Review	5
Tied weights cause every change in parameter space to be exponentially amplified/dampened (save for nonlinear effects), making convergence harder.	I-Review	I-4	Review	5
The authors should probably rewrite this sentence.	I-Review	I-4	Review	5
<sep> <sep> - I deduce from the text that the system is only trained to provide output (image reconstruction and classification) at the T-th iteration.	B-Review	B-5	Review	5
As such, the backpropagated error only is 'injected' at this point in time.	I-Review	I-5	Review	5
This is distinctly different form the 'common' BPTT setup, where error is injected at each time step, and the authors should maybe explicitly mention this.	I-Review	I-5	Review	5
Apparently reviewer 'Anonymous 8ddb' has interpreted the model as if it was to provide output at each time step ('the reconstruction cost found at each step which provide additional error signal'), so definitely make this more clear.	I-Review	I-5	Review	5
<sep> <sep> - The authors mention that they trained the DrSAE with T=11, so 11 iterations.	B-Review	B-6	Review	5
I suspect this number emerges from a balance between computational cost and the need for a sufficient amount of iterations?	I-Review	I-6	Review	5
Please explicitly state this in your paper.	I-Review	I-6	Review	5
<sep> <sep> - As a general remark, the comparison to ISTA and LISTA is interesting, but the authors go to great lengths to finding detailed analogies, which might not be that informative.	B-Review	B-7	Review	5
I am not sure whether the other reviewers would agree with me, but maybe the distinction between categorical and part-units can be deduced without this complicated and not easy-to-understand analysis.	I-Review	I-7	Review	5
It took me some time to figure out the content of paragraphs 3.1 and 3.2.	I-Review	I-7	Review	5
<sep> <sep> - I also agree with other reviewers that it is unfortunate that only MNIST has been considered.	B-Review	B-8	Review	5
Results on more datasets, and especially other kinds of data (audio, symbolic?)	I-Review	I-8	Review	5
might be quite informative	I-Review	I-8	Review	5
* Anonymous bc93:	O	O	Reply	5
<sep> We offer our sincere thanks for your thoughtful comments.	O	O	Reply	5
<sep> <sep> Q1: The dynamics are indeed smooth, as shown in figure 5.	B-Reply	B-1	Reply	5
However, there is no reason to believe that the dynamics will stabilize beyond the trained interval.	I-Reply	I-1	Reply	5
In fact, simulations past the trained interval show that the most active categorical unit often seems to grow continuously.	I-Reply	I-1	Reply	5
<sep> <sep> Q2: The image reconstruction is small for the first iteration or two, but thereafter is stable throughout the trained interval and beyond.	B-Reply	B-2	Reply	5
Classification is more sensitive to the exact balance between part-units and categorical-units, and is less reliable as one moves away from the trained iteration T.	I-Reply	I-2	Reply	5
<sep> R1: Any multilayer network (say with L layers of M units) can be seen as a recurrent network with M*L units, unrolled for L time steps, which is sparsely connected (e.g. with a block upper triangular matrix).	B-Reply	B-3	Reply	5
Admittedly, this would be a computationally inefficient way to run the multilayer network.	I-Reply	I-3	Reply	5
But the representational power of the two networks are identical.	I-Reply	I-3	Reply	5
Hence recurrent nets are not intrinsically less powerful than multilayer ones, if one is willing to make them large.	I-Reply	I-3	Reply	5
DrSAE leaves it up to the learning algorithm to decide which hidden units will act as 'lower-layer' or 'upper-layer' units.	I-Reply	I-3	Reply	5
<sep> <sep> R2: The reference to the vanishing gradients problem was tangential and, given its contentious nature, has been removed from the paper.	B-Reply	B-4	Reply	5
Nevertheless, please see our comments on the matter to the other reviewers.	I-Reply	I-4	Reply	5
<sep> <sep> R3: The loss functions are indeed only applied to the last iteration of the hidden units.	B-Reply	B-5	Reply	5
We have added an explicit mention of this in the text to avoid confusion.	I-Reply	I-5	Reply	5
Future work will explore the use of a reconstruction cost summed over time.	I-Reply	I-5	Reply	5
This may have the effect of quickening the convergence of the inference and making the classification and reconstruction more stable past the training interval.	I-Reply	I-5	Reply	5
<sep> <sep> R4: The T=11 could more appropriately called T'=10, since there are 10 applications of the explaining-away matrix S, although T=11 represents the number of applications of the non-lineaity.	B-Reply	B-6	Reply	5
Experiments were conducted for T=2, T=6, and T=11.	I-Reply	I-6	Reply	5
The paper focuses mostly on T=11.	I-Reply	I-6	Reply	5
We have added a note to this effect.	I-Reply	I-6	Reply	5
<sep> <sep> R5: While the existence of a dichotomy between part-units and categorical-units is certainly identifiable without recourse to ISTA, as is evident from figures 8 and 10, the understanding of the part-units is best framed in terms of ISTA, which predicts the learned parameters with considerable accuracy.	B-Reply	B-7	Reply	5
Were it not for the fact that our network architecture is derived from ISTA, it would be remarkable that the part-units spontaneously learn parameters that so closely match with ISTA.	I-Reply	I-7	Reply	5
<sep> While perhaps unfamiliar to some readers, ISTA is simple and intuitive; we suspect that the difficulty you allude to is primarily an issue of nomenclature.	I-Reply	I-7	Reply	5
With non-negative units, ISTA is just projected gradient descent on the loss function of equation 1 (the projection is onto the non-negativity constraint).	I-Reply	I-7	Reply	5
We have added a note to this effect in paragraph 3.1, which we hope will make this analysis easier to follow for readers unfamiliar with ISTA.	I-Reply	I-7	Reply	5
<sep> R6: Please see our response to the other reviewers.	B-Reply	B-8	Reply	5

I reviewed the same paper last year.	O	O	Review	1254
I am appending a few lines based on the changes made by authors.	O	O	Review	1254
<sep> <sep> The authors propose k-DPP as an open loop (oblivious to the evaluation of configurations) method for hyperparameter optimization and provide its empirical study and comparison with other methods such as grid search, uniform random search, low-discrepancy Sobol sequences, BO-TPE (Bayesian optimization using tree-structured Parzen estimator) by Bergstra et al (2011).	B-Review	B-1	Review	1254
The k-DPP sampling algorithm and the concept of k-DPP-RBF over hyperparameters are not new, so the main contribution here is the empirical study.	I-Review	I-1	Review	1254
<sep> <sep> The first experiment by the authors shows that k-DPP-RBF gives better star discrepancy than uniform random search while being comparable to low-discrepancy Sobol sequences in other metrics such as distance from the center or an arbitrary corner (Fig.1).	B-Review	B-7	Review	1254
<sep> <sep> The second experiment shows surprisingly that for the hard learning rate range, k-DPP-RBF performs better than uniform random search, and moreover, both of these outperform BO-TPE (Fig.2, column 1).	B-Review	B-8	Review	1254
<sep> <sep> The third experiment shows that on good or stable ranges, k-DPP-RBF and its discrete analog slightly outperform uniform random search and its discrete analog, respectively.	B-Review	B-9	Review	1254
<sep> <sep> I have a few reservations.	B-Review	B-2	Review	1254
First, I do not find these outcomes very surprising or informative, except for the second experiment (Fig.2, column 1).	I-Review	I-2	Review	1254
Second, their study only applies to a small number like 3-6 hyperparameters with a small k=20.	B-Review	B-3	Review	1254
The real challenge lies in scaling up to many hyperparameters or even k-DPP sampling for larger k. Third, the authors do not compare against some relevant, recent work, e.g., Springenberg et al (<a href="http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf)" target="_blank" rel="nofollow">http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf)</a> and Snoek et al (<a href="https://arxiv.org/pdf/1502.05700.pdf)" target="_blank" rel="nofollow">https://arxiv.org/pdf/1502.05700.pdf)</a> that is essential for this kind of empirical study.	B-Review	B-4	Review	1254
<sep> <sep> COMMENTS ON THE CHANGES SINCE THE LAST YEAR	O	O	Review	1254
<sep> I am not convinced by the comparison with Spearmint added by the authors since the previous version.	B-Review	B-5	Review	1254
It is unclear to me if the comparison of wall clock time and accuracy holds for larger number of hyperparameters or against Spearmint with more parallelization.	I-Review	I-5	Review	1254
<sep> <sep> In addition the authors do not compare against more recent work, e.g.,	B-Review	B-6	Review	1254
<sep> @INPROCEEDINGS{falkner-bayesopt17,	I-Review	I-6	Review	1254
author    = {S. Falkner and A. Klein and F. Hutter},	I-Review	I-6	Review	1254
title     = {Combining Hyperband and Bayesian Optimization},	I-Review	I-6	Review	1254
booktitle = {NIPS 2017 Bayesian Optimization Workshop},	I-Review	I-6	Review	1254
year      = {2017},	I-Review	I-6	Review	1254
month     = dec,	I-Review	I-6	Review	1254
}	I-Review	I-6	Review	1254
<sep> @InProceedings{falkner-icml-18,	I-Review	I-6	Review	1254
title =        {{BOHB}: Robust and Efficient Hyperparameter Optimization at Scale},	I-Review	I-6	Review	1254
author =       {Falkner, Stefan and Klein, Aaron and Hutter, Frank},	I-Review	I-6	Review	1254
booktitle =    {Proceedings of the 35th International Conference on Machine Learning (ICML 2018)},	I-Review	I-6	Review	1254
pages =        {1436--1445},	I-Review	I-6	Review	1254
year =         {2018},	I-Review	I-6	Review	1254
month =        jul,	I-Review	I-6	Review	1254
}	I-Review	I-6	Review	1254
We greatly appreciate both rounds of review that you've provided for our paper.	O	O	Reply	1254
We took the first review quite seriously, and it seems that you missed some of the changes we made in response to your review and others.	O	O	Reply	1254
Specifically, addressing items that have changed that were mentioned in your first review:	O	O	Reply	1254
The first experiment actually shows dispersion, not discrepancy.	B-Reply	B-7	Reply	1254
While we include star discrepancy in the appendix (in Figure 5, not Figure 1), we argue in section 3 that dispersion is a better measure of the quality of a point set for optimization (though discrepancy has been the tool of choice for previous work).	I-Reply	I-7	Reply	1254
We include a theorem which bounds the optimization error with dispersion, a connection which discrepancy lacks, and show our approach outperforms the Sobol sequence and uniform sampling.	I-Reply	I-7	Reply	1254
We believe this connection will encourage future work to move away from evaluating open loop methods with discrepancy, and to use dispersion instead.	I-Reply	I-7	Reply	1254
<sep> The third experiment does not address discretization error.	B-Reply	B-9	Reply	1254
Instead, it is another hyperparameter optimization experiment on a different search space, again showing that samples from a K-DPP outperform uniform samples, the Sobol sequence, and BO-TPE.	I-Reply	I-9	Reply	1254
<sep> <sep> We believe our method for defining a K-DPP over tree-structured, mixed discrete-continuous spaces is novel, as is the sampling algorithm we introduce in Algorithm 2.	B-Reply	B-1	Reply	1254
We know of no other approach that can draw K-DPP samples from tree-structured, mixed discrete-continuous domains.	I-Reply	I-1	Reply	1254
Previous work using K-DPPs for hyperparameter optimization (Kathuria et al 2016, Wang et al 2017) discretize continuous domains, then use a known algorithm to sample from a discrete (non-tree structured) base set.	I-Reply	I-1	Reply	1254
Your first review mentions a plot which showed the error from discretizing the search space, empirically motivating this contribution.	I-Reply	I-1	Reply	1254
<sep> <sep> To address the listed reservations: we do find it surprising that samples from a K-DPP match or outperform the Sobol sequence in our synthetic measures, as the Sobol sequence was designed specifically to perform well.	B-Reply	B-2	Reply	1254
Additionally, it has become perhaps the most frequently used approach (e.g. without function evaluation results, Spearmint returns the Sobol sequence, while our results indicate that it should return K-DPP samples instead).	I-Reply	I-2	Reply	1254
<sep> <sep> We agree that scaling into large K and D is important, but that isn't the focus of this work, and there is a large body of work on improving space and time complexity of GPs which is directly applicable to our approach.	B-Reply	B-3	Reply	1254
<sep> <sep> When considering which pieces of recent work to compare against, we emphasize that our work is not trying to answer the question, "Is active learning helpful?"	B-Reply	B-4	Reply	1254
by comparing active learning approaches against our open loop approach; instead, we focus on comparing against other non-active learning approaches.	I-Reply	I-4	Reply	1254
For example, Hyperband starts by uniformly sampling K hyperparameter assignments, then (partially) training and evaluating models with those assignments.	I-Reply	I-4	Reply	1254
This work does not advocate replacing Hyperband with a single draw from a K-DPP (i.e., replacing an active learning strategy with a non-active learning strategy), but it does argue that the uniform sampling step in Hyperband be replaced with a draw from a K-DPP (replacing an open loop strategy with another, better one).	I-Reply	I-4	Reply	1254
All of your suggested comparisons are against active learning approaches.	I-Reply	I-4	Reply	1254
<sep> <sep> We do include experiments comparing against Spearmint (an active learning approach), though this is meant to illustrate the large cost in optimization time that active learning entails.	B-Reply	B-5	Reply	1254
We appreciate the suggestion to compare against Spearmint with more parallelization, but note that in our experiments we compared against the most parallel possible Spearmint configuration (as well as a number of others).	I-Reply	I-5	Reply	1254
Any active learning strategy (excluding Hyperband-style evaluations of partially trained models) will take at least twice as long in expectation as a fully-parallel non-active learning strategy like a K-DPP to train and evaluate models with a set of hyperparameter assignments, so we expect the results in Figure 4 to hold for any number of hyperparameters.	I-Reply	I-5	Reply	1254
<sep> <sep> Thank you again for your review, we look forward to further discussion.	O	O	Reply	1254

The authors propose to use k-DPP to select a set of diverse parameters and use them to search for a good a hyperparameter setting.	O	O	Review	1254
<sep> <sep> This paper covers the related work nicely, with details on both closed loop and open loop methods.	O	O	Review	1254
The rest of the paper are also clearly written.	O	O	Review	1254
However, I have some concerns about the proposed method.	O	O	Review	1254
<sep> - It is not clear how to define the kernel, the feature function and the quality function for the proposed method.	B-Review	B-1	Review	1254
The choices of those seem to have a huge impact on the performance.	I-Review	I-1	Review	1254
How was those functions decided and how sensitive is the result to hyperparameters of those functions?	I-Review	I-1	Review	1254
<sep> - If the search space is continuous, what is the mixing rate of Alg.	B-Review	B-2	Review	1254
2?	I-Review	I-2	Review	1254
In practice, how is "mixed" decided?	I-Review	I-2	Review	1254
What exactly is the space and time complexity?	I-Review	I-2	Review	1254
I'm not sure where k log(N) comes from in page 7.	I-Review	I-2	Review	1254
- Alg.	B-Review	B-3	Review	1254
2 is a straight forward extension of Alg.	I-Review	I-3	Review	1254
1, just with L not explicitly computed.	I-Review	I-3	Review	1254
I think it would have more novelty if some theoretical analyses can be shown on the mixing rate and how good this optimization algorithm is.	I-Review	I-3	Review	1254
<sep> <sep> Other small things:	O	O	Review	1254
- citation format problems in, for example, Sec.4.1.	B-Review	B-4	Review	1254
It should be \citep instead of \cite.	I-Review	I-4	Review	1254
<sep> - it would be good to mention Figure 2 in the text first before showing it.	B-Review	B-5	Review	1254
<sep> <sep> [Post rebuttal]	O	O	Review	1254
I would like to thank the authors for their clarifications.	O	O	Review	1254
However, I am still concerned with the novelty.	B-Review	B-6	Review	1254
The absence of provable mixing rate is also a potential weakness.	I-Review	I-6	Review	1254
I think a clearer emphasis on the novelty, e.g. current algorithm with mixing rate analyses or more thorough empirical comparisons will make the paper stronger for resubmission.	I-Review	I-6	Review	1254
We thank AnonReviewer3 for their review, and address their points in order.	O	O	Reply	1254
<sep> <sep> We experimented with a number of different kernels, including cosine similarity (the most common approach used with K-DPPs), a kernel built using Levenshtein distance, and the RBF kernel.	B-Reply	B-1	Reply	1254
We found our results to be quite robust to the choice of the kernel -- we saw the K-DPP outperform the other approaches on our hyperparameter optimization experiments for all three.	I-Reply	I-1	Reply	1254
Similarly, we experimented with a number of different bandwidths for the RBF kernel, and found that as long as the bandwidth was large enough that the points interacted each other, it performed well.	I-Reply	I-1	Reply	1254
Our experiments focused on the presented feature function, as it was the most natural, but we expect any feature function which allows the points to be repulsed from one another (through the kernel) would behave similarly.	I-Reply	I-1	Reply	1254
In this work, we set the quality function to be 1, and have left learning the quality function to future work.	I-Reply	I-1	Reply	1254
<sep> <sep> If the search space is continuous, the mixing rate of Alg.	B-Reply	B-2	Reply	1254
2 is not known.	I-Reply	I-2	Reply	1254
In practice, the MCMC algorithm is quite fast (a small fraction of the expense of training the models) so we ran the algorithm for 10x as long as the expected mixing rate if the space had been discrete, though our synthetic and real experimental results indicated that it was mixed significantly earlier.	I-Reply	I-2	Reply	1254
<sep> The k log(N) term appears when analyzing the difference between Algorithm 1 and Algorithm 2: computation and storage of the NxN kernel matrix L. In the discrete case, Algorithm 1 requires computing all of L, which has time and space complexity of O(N^2).	I-Reply	I-2	Reply	1254
Algorithm 2, instead of constructing L directly, only uses a submatrix of L computed on the fly.	I-Reply	I-2	Reply	1254
It runs for O(N log(N)) steps, and at each step computes and stores at most O(k) additional distances, leading to a total of O(Nk log(N)) time and space complexity (with a max of O(N^2) once it computes all of L).	I-Reply	I-2	Reply	1254
Therefore, Algorithm 2 has better complexity when O(Nk log(N)) < O(N^2), or when k log(N) < N. Otherwise, Algorithm 1 and 2 have the same time and space complexity.	I-Reply	I-2	Reply	1254
We will include a clarification in the paper, please let us know if this is still unclear.	I-Reply	I-2	Reply	1254
<sep> <sep> While we agree Algorithm 2 is a straightforward extension, it is an important one for the community.	B-Reply	B-3	Reply	1254
Other work that has used K-DPPs for hyperparameter optimization (Kathuria et al 2016, Wang et al 2017) has been restricted to non-tree structured domains, and has discretized continuous spaces to be discrete so they could use existing sampling algorithms, which we experimentally found to hurt performance.	I-Reply	I-3	Reply	1254
We introduce the ability to sample from more realistic hyperparameter spaces.	I-Reply	I-3	Reply	1254
<sep> <sep> Thank you for pointing out the small changes, they will be updated.	O	O	Reply	1254
<sep> <sep> The title of your review mentions worries about novelty, but as we mentioned in a reply to another review, we believe this approach (drawing samples from tree-structured, mixed discrete and continuous spaces in the open loop regime) and analysis (including dispersion calculation) are novel.	B-Reply	B-6	Reply	1254
We welcome further discussion, especially of more specific novelty concerns that may arise, and look forward to further suggestions on how to improve our paper or clarifications we can provide.	I-Reply	I-6	Reply	1254

Value-Driven Hindsight Modelling proposes a method to improve value function learning.	O	O	Review	20319
The paper introduces the hindsight value function which estimates the expected return at a state conditioned on the future trajectory of the agent.	O	O	Review	20319
How use this hindsight value function is not obvious, since an agent does not have access to the future states needed in order to take actions (for Q-Learning) and the hindsight value function is a biased gradient estimator for training policy gradient methods.	O	O	Review	20319
<sep> <sep> The authors train the standard value function (which does not have access to future information) to predict the features which the highsight value function learns to summarize the value relevant parts of the future trajectory.	O	O	Review	20319
These predicted features can then be used in place of the actual hindsight value function, circumventing the issues discussed above.	O	O	Review	20319
The authors argue that this auxiliary objective provides a richer training signal to the normal value function, helping it to better learn what information in a given state is relevant to predicting future rewards.	O	O	Review	20319
<sep> <sep> The paper is well structured and written, flowing from high level motivation and review into the core of the method, followed by analysis of the approach, and then proceeds through three experiments.	O	O	Review	20319
The first two are toy / crafted experiments which build intuition and probe the behavior of the method and finally a large scale test on the Atari 57 benchmark demonstrating improvements when augmenting a state-of-the-art method with HiMo.	O	O	Review	20319
<sep> <sep> This reviewer recommends acceptance (I would give a 7 given more granularity) based on the contribution of a new auxiliary objective for value functions and the strength of the experimental suite.	O	O	Review	20319
The Portal Choice environment is well crafted and instrumented with the graphs of figure 5b and 5c to show the behavior of the approach and the clean demonstration of an improvement over a previously SOTA method for Atari 57 is encouraging (the same architecture and the ablation simply sets the auxiliary objective‚Äôs weight to 0).	O	O	Review	20319
However, the reviewer has some caution and concerns as follows:	O	O	Review	20319
<sep> 1) The lack of a large scale experiment demonstrating improvement with an actor-critic method.	B-Review	B-1	Review	20319
While the Portal Choice experiments are informative and use Impala, it is a bit toy, and it would increase the reviewer‚Äôs confidence in the generality and robustness of the approach if improvements were also demonstrated for an actor-critic method on a large environment suite.	I-Review	I-1	Review	20319
Atair 57 could work but ideally a different setting such as DMLab 30 or continuous control from pixels.	I-Review	I-1	Review	20319
Demonstrating improvements in one of these additional settings would raise the reviewer to a strong acceptance.	I-Review	I-1	Review	20319
<sep> <sep> 2) The potential sensitivity of the approach to the two important hyperparameters that the authors mention, the dimensionality of the hindsight feature space (to reduce approximation error) and the # of future states it conditions on (to avoid just observing the full return directly).	B-Review	B-2	Review	20319
The very low dimensionality of the hindsight feature space (d=3 for Atari) seems a bit at odds with the explanation that the hindsight features provide a strong training signal for learning to better extract value relevant information from the state.	I-Review	I-2	Review	20319
Experiments that studied sensitivity to these would provide better perspective on the robustness of HiMo.	I-Review	I-2	Review	20319
<sep> <sep> Questions and suggestions for improving the paper:	O	O	Review	20319
<sep> For Figure 6 the dynamic range gets squashed by a few games with relatively large performance improvements or regressions.	B-Review	B-3	Review	20319
Changing to a log-scale on the y-axis could be more informative?	I-Review	I-3	Review	20319
For instance, I find it pretty difficult to eyeball the ~1 human normalized score median improvement according to Table 1 from the chart.	I-Review	I-3	Review	20319
<sep> <sep> Figure 3 could also be improved.	B-Review	B-4	Review	20319
It requires significant context from definitions in the paper in order to understand.	I-Review	I-4	Review	20319
It could be reworked into a stand alone expository overview of HiMo that helps readers quickly grok the idea of the paper such that abstract + figure is enough.	I-Review	I-4	Review	20319
<sep> <sep> Could the authors consider showing / adding full learning curves (median human normalized score?)	B-Review	B-5	Review	20319
for HiMO vs the baseline on Atari 57?	I-Review	I-5	Review	20319
This would help readers get a qualitative feel for the learning dynamics of the algorithm instead of only having a final scalar measure at the end of training.	I-Review	I-5	Review	20319
Thank you for taking the time to review our paper.	O	O	Reply	20319
<sep> <sep> 1- Re: large-scale experiment	O	O	Reply	20319
We ran a control experiment on the bowling Atari game using Impala (see Figure 7-c)  that tested whether the gains using R2D2 were not specific to Q-value based methods.	B-Reply	B-1	Reply	20319
These results suggest the benefits at scale are not limited to the value-based R2D2 setting.	I-Reply	I-1	Reply	20319
Testing the approach more broadly (on dmlab or challenging continuous control tasks as you suggested) is certainly something we want to look at in the future.	I-Reply	I-1	Reply	20319
<sep> <sep> 2- RE:sensitivity:	O	O	Reply	20319
Yes this is a good point.	B-Reply	B-2	Reply	20319
It is not overly sensitive to these exact values (a dimension of 16 for \phi does fine for example) but much larger values did tend to perform worse when we were tuning the architecture.	I-Reply	I-2	Reply	20319
One hypothesis is that a \phi with small dimensionality regularize the representation to only include relevant features, while larger dimensional \phi may contain less relevant information that will distract the modeling effort on phi.	I-Reply	I-2	Reply	20319
We plan to investigate that aspect more in future work.	I-Reply	I-2	Reply	20319
<sep> <sep> Thank you for the suggestions regarding the figures.	B-Reply	B-5	Reply	20319
We‚Äôll include the learning curves for all the games in the appendix.	I-Reply	I-5	Reply	20319
<sep> <sep> We take your point about Figure 3, we‚Äôll think about a way to make it more useful without relying too much on the text.	B-Reply	B-4	Reply	20319

Summary:	O	O	Review	20319
<sep> The paper proposes a way to learn better representation for RL by employing a hindsight model-based approach.	O	O	Review	20319
The reasoning is that during training, we can observe the future trajectory and use features from it to better predict past values/returns.	O	O	Review	20319
However to make this practical, the proposed approach fits an approximator to predict these features of the future trajectory from the current state and then subsequently, use them to predict the value.	O	O	Review	20319
The authors claim that this extra information can be used to learn a better representation in some problems and lead to faster learning of good policies (or optimal value functions)	O	O	Review	20319
<sep> Decision:	O	O	Review	20319
Weak Accept	O	O	Review	20319
My decision is influenced by the following two key reasons	O	O	Review	20319
<sep> (1) I like the idea of hindsight modeling a lot.	B-Review	B-1	Review	20319
It is true that a trajectory gives much more information than just a weak scalar signal indicating return from each state in the trajectory.	I-Review	I-1	Review	20319
Identifying a way to make use of all the extra information in the trajectory to aid in value prediction is useful.	I-Review	I-1	Review	20319
The proposed approach is a step towards that, and I think the community should be made aware of that for sake of future research in this direction.	I-Review	I-1	Review	20319
<sep> <sep> (2) Having said that, I am not super satisfied with the way the authors have presented their approach.	B-Review	B-2	Review	20319
The explanation is jumbled and confusing, at times.	I-Review	I-2	Review	20319
The paper needs careful rewriting to communicate ideas better and notation needs to be standardized earlier.	I-Review	I-2	Review	20319
Some of the sections are either redundant or lack insights.	I-Review	I-2	Review	20319
Even if they do have insights, they are not highlighted leaving the reader to search for them.	I-Review	I-2	Review	20319
The experimental setup is not clear and the authors could have spent more space in the paper dedicated to how the hindsight modeling approach can be implemented within an existing RL method.	I-Review	I-2	Review	20319
<sep> <sep> Comments:	O	O	Review	20319
<sep> (1) The line in abstract "but this approach is usually not sensitive to reward function" doesn't make sense.	B-Review	B-3	Review	20319
Isn't reward function part of the model?	I-Review	I-3	Review	20319
So you are learning the reward function, so how is it not sensitive to it?	I-Review	I-3	Review	20319
I think I understand what the authors are saying but it took me until the end of Sec 3.2 to get that.	I-Review	I-3	Review	20319
<sep> <sep> (2) How does this work relate to Value-aware model learning works from Farahmand (AISTATS 2017, NeurIPS 2018).	B-Review	B-4	Review	20319
The premise seems to be similar: learn a model taking into account the underlying decision-making problem to be solved and the structure of the value function.	I-Review	I-4	Review	20319
The paper needs a discussion of these set of works	I-Review	I-4	Review	20319
<sep> (3) In Section 3.3, \phi_{\theta_2} has conflicting function parameters in eq (2) and (3).	B-Review	B-5	Review	20319
<sep> <sep> (4) Section 3.4 is very confusing.	B-Review	B-6	Review	20319
I understood the setup of the problem and it seemed like it was very illustrative of an example where proposed approach will excel.	I-Review	I-6	Review	20319
However, Fig 1 and its caption are unclear and I found it hard to understand what the figure is conveying.	I-Review	I-6	Review	20319
The paragraph underneath the figure had no explanation for the Fig 1, and instead directly jumped to the results in Fig 2.	I-Review	I-6	Review	20319
The paper could use a better explanation of Fig 1.	I-Review	I-6	Review	20319
and explain why the proposed approach can learn the structure of s' and better predict value at s	I-Review	I-6	Review	20319
<sep> (5) Section 3.5 partially answers the question "when is it advantageous to model in hindsight?"	B-Review	B-7	Review	20319
In cases, where L_model is low, of course its advantageous to model in hindsight!	I-Review	I-7	Review	20319
But the real question that needs to be answered is buried in the last paragraph.	I-Review	I-7	Review	20319
What if learning a good \phi is as hard as predicting the return?	I-Review	I-7	Review	20319
In this case, do we still gain any advantage?	I-Review	I-7	Review	20319
I am not sure how having a limited view of future observations and low dimensional \phi helps.	I-Review	I-7	Review	20319
If the feature that decides future return lies beyond the limited view of future observations, does it still not give any advantage?	I-Review	I-7	Review	20319
Questions like these might be useful in aiding the reader to understand why hindsight modeling is better	I-Review	I-7	Review	20319
<sep> (6) Section 4 needs more text to explain what components of the architecture are learnt using what losses, and provide intuitions for why that is the case.	B-Review	B-7	Review	20319
It seems like that is very crucial to ensure that \phi doesn't learn something trivial and non-useful.	I-Review	I-7	Review	20319
I am surprised section 4 is so small, and Fig 3 is not useful.	I-Review	I-7	Review	20319
Maybe, you can combine section 3.4, 3.5 and condense them, and using the obtained space in expanding sec 4.	I-Review	I-7	Review	20319
<sep> <sep> (7) The experiments section immediately dives into the problem setup and results.	B-Review	B-7	Review	20319
It will be useful to have a subsection explaining how the proposed hindsight model is implemented within an RL algorithm.	I-Review	I-7	Review	20319
Currently, it is hard for the reader to connect what he/she has read until Section 4 with what's presented in Section 5.	I-Review	I-7	Review	20319
<sep> <sep> (8) The results are convincing.	B-Review	B-8	Review	20319
However, my biggest concern is the experiments were not designed carefully to analyze how much the hindsight modeling contributed in the increase of performance?	I-Review	I-8	Review	20319
Are the number of parameters in the value function approximator the same between the hindsight RL algorithm and the baseline?	I-Review	I-8	Review	20319
Can we have a simplistic example that is amenable to isolate the influence of hindsight modeling from other factors?	I-Review	I-8	Review	20319
Fig.2 does a reasonable job at it but I think the hindsight modeling approach can achieve improvement in more diverse problems.	I-Review	I-8	Review	20319
In a way, the proposed feature is doing state space augmentation so that value can be easily predicted from the features of the augmented state.	I-Review	I-8	Review	20319
So, identifying the characteristics of the problems where this can be done is very useful to the RL practictioner.	I-Review	I-8	Review	20319
Thank you for taking the time to review our paper and the detailed and specific feedback.	O	O	Reply	20319
<sep> <sep> 1-  Even when the model also predicts the reward, the observation model is usually asked to indifferently predict all of the high-dimensional observation, even if some aspects are not relevant to the task (i.e. to the rewards).	B-Reply	B-3	Reply	20319
The transition model does not focus on what is most important for the task, so it may not be data-efficient to learn (and it may be limited by capacity).	I-Reply	I-3	Reply	20319
<sep> <sep> Nonetheless, we‚Äôll attempt to clarify that specific sentence in the abstract.	I-Reply	I-3	Reply	20319
<sep> <sep> 2-  Thanks for pointing out this work, it is indeed relevant but the method is quite different.	B-Reply	B-4	Reply	20319
In the value-aware model learning work (iterative Value-Aware Model Learning), the model loss minimizes some form of value consistency: the difference between the value at some next state and the expected value from starting in the previous state, applying the model and computing the value.	I-Reply	I-4	Reply	20319
While this makes the model sensitive to the value, it only exploits the future real state through V as a learning signal (just like in bootstrapping).	I-Reply	I-4	Reply	20319
In contrast, our model is both sensitive to the value and can exploit a richer signal from the future observations.	I-Reply	I-4	Reply	20319
We‚Äôll discuss that work in the related work section.	I-Reply	I-4	Reply	20319
<sep> <sep> 3-  This is a typo, the state shouldn‚Äôt be part of \phi_{\theta_2}‚Äôs arguments in Eq 3.	B-Reply	B-5	Reply	20319
<sep> <sep> 4-  Thanks for the feedback.	B-Reply	B-6	Reply	20319
We will update the legend of Fig 1 and the example description to make it clearer.	I-Reply	I-6	Reply	20319
<sep> <sep> 5-7 We are sorry you found the current exposition of the work in these sections to not be ideal.	B-Reply	B-7	Reply	20319
We will attempt to improve the balance between certain sections and especially expand the discussion of the architecture.	I-Reply	I-7	Reply	20319
<sep> <sep> 8- In all our experiments, the number of parameters and the computational cost  of evaluating the network is the same in HiMo and the baseline because we use the exact same network architecture and only set some of the extra losses to 0 to obtain the baseline.	B-Reply	B-8	Reply	20319
We proposed two domains (the illustrative task and the portal example) where we have isolated some problem features where hindsight modelling is particularly relevant.	I-Reply	I-8	Reply	20319
We thought it was also important to test it in domains that were not specially conceived to test the idea and we chose the 57 Atari games for that.	I-Reply	I-8	Reply	20319
Of course, more extensive empirical investigations is always desirable but we believe this is sufficient to establish that this novel idea can be successful in practice.	I-Reply	I-8	Reply	20319

This paper presents a new model-based reinforcement learning method, termed hindsight modelling.	O	O	Review	20319
The method works by training a value function which, in addition to depending on information available at the present time is conditioned on some learned embedding of a partial future trajectory.	O	O	Review	20319
A model is then trained to predict the learned embedding based on information available at the current time-step.	O	O	Review	20319
This predicted value is fed in place of the actual embedding to the same value model, to generate a value prediction for the current time-step.	O	O	Review	20319
So instead of just learning a value function based on future returns, the method uses a two-step process of learning an embedding of value relevant information from the future and then learns to predict that embedding.	O	O	Review	20319
<sep> <sep> The paper gives some motivating examples of why and when such an approach could yield an advantage over standard value learning methods like Monte-Carlo or temporal difference learning.	O	O	Review	20319
The basic idea is that when the returns obey some causal structure like X-&gt;Y-&gt;Z it may be easier to learn P(Y|X) and P(Z|Y) than to learn P(Z|X) directly.	O	O	Review	20319
In particular, the authors point out that in the discrete case when Y takes relatively few values the size of the respective probability tables can be smaller in the former case than the latter.	O	O	Review	20319
This motivates the approach of discovering a set of future variables to predict which are themselves predictive of return, rather than predicting the expected future return directly.	O	O	Review	20319
<sep> <sep> On a high level, I like the idea of specifically learning to model relevant aspects of the environment.	O	O	Review	20319
However, I lean toward rejecting this work in its current form because I feel the motivation for when this particular method would be useful is unclear.	O	O	Review	20319
<sep> <sep> In particular, I don't really understand how this method could, in general, be expected to improve on regular bootstrapping.	B-Review	B-1	Review	20319
Why learn a prediction of the return at time t based on future information when we could just use the value function at a later time to improve the prediction at time t?	I-Review	I-1	Review	20319
It seems to me that the future value function itself concisely summarizes the information in the future state that is relevant for predicting the past return, while better exploiting the structure of the problem.	I-Review	I-1	Review	20319
Of course in cases like partial observability, it could be that the future value function lacks information from the past that is important for accurately predicting the return (for example in the portal example of this paper).	I-Review	I-1	Review	20319
However, if partial observability is really the case of interest, the method presented in this paper seems like a rather roundabout solution method.	I-Review	I-1	Review	20319
For example, instead of conditioning v+ on a future hidden state h_{t+k} (as the authors do in the experiments) perhaps one could simply condition the value function on a past hidden state h_{t-k} and obtain similar benefit from bootstrapping?	I-Review	I-1	Review	20319
<sep> <sep> Aside from partial observability, for which I feel there are better approaches, the only situation I can understand the method having an advantage is when later states contain information which helps to predict earlier rewards.	B-Review	B-2	Review	20319
This is essentially the situation presented in the illustrative example.	I-Review	I-2	Review	20319
However, currently I feel such situations are rather contrived and unintuitive so I would need more supporting evidence to accept these situations as a good motivation.	I-Review	I-2	Review	20319
<sep> <sep> On a deeper level, I don't see how the probability table motivation given in the introduction applies when what is being learned is an expectation (i.e. a value function) and not a distribution.	B-Review	B-3	Review	20319
<sep> <sep> The approach also suffers from well-known issues with using the output of an expectation model of a variable as the input to a nonlinear function approximator in place of the variable itself.	B-Review	B-4	Review	20319
Namely, there is no guarantee that the expectation value of a variable is a possible value for the variable so giving it as input to a predictor trained on the variable itself could easily yield nonsense output in the stochastic case.	I-Review	I-4	Review	20319
As far as I can tell the method does nothing to mitigate this (please correct me if I'm wrong), so there is no reason to assume the method is generally applicable in settings with nontrivial stochasticity.	I-Review	I-4	Review	20319
<sep> <sep> Despite these concerns, I feel the experiments are for the most part quite well thought out and executed.	B-Review	B-5	Review	20319
The paper is also quite well written, motivation issues aside, so I would not be upset if it was accepted with the hope that it leads to future work addressing the above-mentioned concerns.	I-Review	I-5	Review	20319
<sep> <sep> If possible I think this paper would benefit significantly from a detailed explanation of how and when the proposed approach should be expected to improve on bootstrapping, including bootstrapping off a value function which uses an analogous architecture to v+.	B-Review	B-6	Review	20319
<sep> <sep> Questions for authors:	O	O	Review	20319
Given the hyper-parameters of R2D2 deviate somewhat from those used in the original paper, and nothing is said about how they were chosen, how confident can we be that the observed advantage of hindsight modelling is not simply due to hyper-parameters being selected which are more favourable for the proposed method?	B-Review	B-7	Review	20319
<sep> <sep> Given that you are not learning distributions but expectations in the form of value functions, how pertinent is the motivation of learning P(Y|X) and P(Z|Y) instead of P(Z|X) directly described in the introduction?	B-Review	B-8	Review	20319
<sep> <sep> How much of the benefit observed in the portal example an ATARI could also be gained from simply providing the value function approximation with h_{t-k} as input to help span larger time-gaps?	B-Review	B-9	Review	20319
<sep> <sep> Update:	O	O	Review	20319
<sep> While I still feel the exposition could be improved to make the underlying idea clearer, I feel the authors did a good job of addressing my major concerns in their reply, hence I have raised my score to a weak accept.	O	O	Review	20319
<sep> <sep> I have to admit I missed the point that v^+ and v^m were using entirely different parameter sets.	B-Review	B-3	Review	20319
In light of this, I agree that the expectation model issue I mentioned is not a major concern.	I-Review	I-3	Review	20319
<sep> <sep> I also appreciate the clarification of the hyperparameters, if they were really tuned to improve the baseline then this detail should be added to the paper and would negate my concern there.	B-Review	B-7	Review	20319
<sep> <sep> Finally, I thank the authors for providing the value-function oriented example.	O	O	Review	20319
I found this example to be more illustrative than the one in the introduction of the paper, and I now feel that I have a better grasp of the motivation.	B-Review	B-6	Review	20319
I still have doubts about the general benefit of the approach over bootstrapping but since it is not entirely clear to me one way or the other I feel the idea at least warrants further exploration, and it would be reasonable to accept the paper to make the community aware of it.	I-Review	I-6	Review	20319
<sep> <sep> Thank you for taking the time to review our paper.	O	O	Reply	20319
<sep> <sep> Let us clarify the two major concerns first:	O	O	Reply	20319
<sep> RE: About bootstrapping:	O	O	Reply	20319
<sep> We tried to convey the difference in Section 3.1 but we will add more clarification there since this is an important and subtle point.	B-Reply	B-1	Reply	20319
<sep> <sep> Bootstrapping only helps to provide potentially better value targets from a trajectory (e.g., to reduce variance or deal with off-policyness), but it does not give a richer training signal.	I-Reply	I-1	Reply	20319
It does not communicate more information about the future than a return statistic.	I-Reply	I-1	Reply	20319
Here is a simple example to make this concrete, consider a policy evaluation problem in a deterministic scenario where we want to estimate v(s_0) (value at time 0), and v_theta(s_t) = v(s_t) for t &gt; 0 (i.e., all subsequent values are perfect).	I-Reply	I-1	Reply	20319
Then Monte-Carlo returns g from start states and n-step returns are equal: G = R_0 + \gamma v_theta(s_1) = R_0 + \gamma R_1 + \gamma^2 v_(s_2) = ‚Ä¶	I-Reply	I-1	Reply	20319
So whether you choose to bootstrap or not has no consequence in this scenario (the value target will be the same), yet there might still be some useful information in the trajectory, say in s_2, which if we could predict from s_0 would accelerate the learning of v_theta(s_0).	I-Reply	I-1	Reply	20319
HiMo is capable of leveraging this information because these features in s_2 would be useful for the hindsight value function.	I-Reply	I-1	Reply	20319
<sep> <sep> This effect is not restricted to deterministic problems.	I-Reply	I-1	Reply	20319
In fact, the illustrative example (section 3.4) also conveys that point and it is stochastic.	I-Reply	I-1	Reply	20319
There, the MDP is just composed of a single transition, so bootstrapping is not applicable.	I-Reply	I-1	Reply	20319
Yet hindsight modeling can still extract valuable information from that single transition and learn V faster, as we show in Figure 2.	I-Reply	I-1	Reply	20319
<sep> <sep> <sep> RE: About expectation (and prob.	O	O	Reply	20319
Table example):	O	O	Reply	20319
<sep> The probability table was meant to be understood at some intuitive level as a motivational statement since it is easy to understand the counting argument, and we thought was appropriate therefore in the introduction.	B-Reply	B-3	Reply	20319
A very similar argument for a deterministic mapping can be made which then applies more directly to a value function.	I-Reply	I-3	Reply	20319
Consider the following chain:	I-Reply	I-3	Reply	20319
<sep> (X, X‚Äô) -&gt; (X,Y‚Äô) -&gt; Z	I-Reply	I-3	Reply	20319
<sep> Z is to be interpreted as the expected return.	I-Reply	I-3	Reply	20319
Here the start state (X,X‚Äô) is sampled randomly but the rest of the chain has deterministic transition, and Y‚Äô is independent of X given X‚Äô.	I-Reply	I-3	Reply	20319
Let N = number of possible values of X, M = number of possible values of X‚Äô, and suppose the number of possible values of Y‚Äô is 2.	I-Reply	I-3	Reply	20319
In a tabular setting, learning the start state value function ‚Äúmodel-free‚Äù (mapping (X,X‚Äô) directly to Z) requires observing returns Z for all NM entries.	I-Reply	I-3	Reply	20319
In contrast, if we estimate the mappings X‚Äô-&gt;Y‚Äô and (X,Y‚Äô)-&gt;Z separately this requires M + 2N entries, which is better than NM (for N,M &gt; 4).	I-Reply	I-3	Reply	20319
<sep> <sep> Regarding the more general point about using an expectation model.	I-Reply	I-3	Reply	20319
It‚Äôs true that in the stochastic case there will be some irreducible model error, but the expected \phi is still a valid and potentially useful statistic of the future.	I-Reply	I-3	Reply	20319
Moreover, we want to emphasize that we use a different parametrization for the hindsight (v^+) and model-augmented (v^m) value networks in the experiments (that is \theta_1 !	I-Reply	I-3	Reply	20319
= \eta_1).	I-Reply	I-3	Reply	20319
So even if v^m is conditioned on the expected estimate of the hindsight feature \phi, the network can learn to interpret that statistic (and therefore we don‚Äôt run into the issue you mention).	I-Reply	I-3	Reply	20319
That being said, the more general idea we are putting forward in this paper is not incompatible with having a stochastic model.	I-Reply	I-3	Reply	20319
<sep> <sep> RE: the hyperparameters	O	O	Reply	20319
<sep> R2D2 with the parameters from the original paper perform less well, so these parameters are advantageous to both methods (Parameters had been selected to improve the baseline R2D2 performance).	B-Reply	B-7	Reply	20319
The control experiment runs exactly the same architecture with some losses set to 0 to control for capacity and speed, so we believe this is a fair controlled experiment.	I-Reply	I-7	Reply	20319
<sep> <sep> RE: the proposal of giving h_{t-k} as input	O	O	Reply	20319
<sep> The network in our experiments is recurrent, so providing past information as additional input would only help if there was some memory requirement that the network is not able to satisfy.	B-Reply	B-4	Reply	20319
<sep> In the portal task, the important decision doesn‚Äôt require any memory (everything is observed in the portal room to select the portal), but there is a memory demand when in the reward room.	I-Reply	I-4	Reply	20319
We ran an extra experiment where we gave h_{t-k} as an additional input to the policy and value for the baseline and it did not perform better than what is reported in Figure 5a for the actor-critic baseline.	I-Reply	I-4	Reply	20319

This is an emergency review.	O	O	Review	10246
<sep> <sep> This work proposes a novel method to use pre-trained topic embeddings and pre-trained word embeddings obtained from various corpora in the transfer learning framework.	O	O	Review	10246
<sep> <sep> Their model architecture is based on DocNADE, unsupervised neural-network based topic model, and the authors propose two strategies to use pre-trained topic embeddings and pre-trained word vectors.	O	O	Review	10246
<sep> 1) Addition of a weighted sum of pre-trained word embeddings and the hidden vector of DocNADE.	O	O	Review	10246
<sep> 2) L2-Regularization term between topic embedding of DocNADE and pre-trained topic embeddings.	O	O	Review	10246
They propose to align these two embeddings by multiplying align matrix "A" to the topic embedding of DocNADE.	O	O	Review	10246
<sep> <sep> They show the transfer learning performance of their model on various source/target domain datasets, including medical target corpora, and verify that their model outperforms on a short text and small document collection.	O	O	Review	10246
<sep> <sep> Strengths.	O	O	Review	10246
<sep> 1.	O	O	Review	10246
Comparison with the data augmentation baseline shows the performance gain is not only from bigger training data.	O	O	Review	10246
Even though comparison with the naive baseline (data augmentation) seems too obvious, I think the results clearly show their claim about the importance of using transfer learning in neural topic modeling domain.	O	O	Review	10246
<sep> 2.	O	O	Review	10246
As the first approach that introduces a novel transfer learning framework with pre-trained topic embeddings, they show tons of experimental results with various datasets and metrics to show the specification of their method.	O	O	Review	10246
Their experimental setting is well designed.	O	O	Review	10246
<sep> <sep> Weaknesses and comments:	O	O	Review	10246
Their method to combine pre-trained word embeddings and pre-trained topic embeddings is too simple.	B-Review	B-1	Review	10246
Since this is the first approach to use topic embedding in the transfer learning field, the simplicity of the proposed method is somewhat necessary.	I-Review	I-1	Review	10246
However, a weighted sum of pre-trained topic/word vectors seems not enough to transfer multisource knowledge.	I-Review	I-1	Review	10246
For instance, word vectors obtained from individual training processes do not share embedding vector space.	I-Review	I-1	Review	10246
As you apply the alignment method to topic embeddings from various sources, you should align word embeddings too.	I-Review	I-1	Review	10246
Thanks for your (emergency) reviews.	O	O	Reply	10246
<sep> <sep> Thanks for your positive comments on experimental setup and acknowledging that our transfer learning approaches introduced in neural topic modeling clearly outperform several baselines.	O	O	Reply	10246
<sep> <sep> &gt;&gt; "Word Embedding Alignment"	O	O	Reply	10246
Yes, we do.	B-Reply	B-1	Reply	10246
<sep> Please see section 3, page 6 in "Reproducibility" paragraph (line 3).	I-Reply	I-1	Reply	10246
Also, mentioned in caption of figure 6 as well as in Appendix C.4 (the last paragraph).	I-Reply	I-1	Reply	10246
<sep> <sep> We perform the word embeddings alignment in all the "+Glove" settings (Table 6) to	I-Reply	I-1	Reply	10246
(1) overcome the DocNADEe (baseline topic model) limitation (word-embedding size must be same as the number of topics), and	I-Reply	I-1	Reply	10246
(2) align vector spaces of word-embeddings obtained from several sources as well as from several different training processes, e.g., from Glove, FastText and word embeddings from topic models.	I-Reply	I-1	Reply	10246
<sep> <sep> The focus of our work is to demonstrate the joint word and topic embeddings transfer in neural topic models from one or many sources.	I-Reply	I-1	Reply	10246

The paper proposes a multi-source and multi-view transfer learning for neural topic modelling with the pre-trained topic and word embedding.	O	O	Review	10246
The method is based on NEURAL AUTOREGRESSIVE TOPIC MODELs --- DocNADE (Larochelle&amp;Lauly,2012).	O	O	Review	10246
DocNADE learns topics using language modelling framework.	O	O	Review	10246
DocNADEe (Gupta et al 2019) extended DocNADE by incorporating word embeddings, the approach the authors described as a single source extension of the existing method.	O	O	Review	10246
<sep> <sep> In this paper, the proposed method adds a regularizer term to the DocNADE loss function to minimize the overall loss whereas keeping the existing single-source extension.	O	O	Review	10246
The authors claimed that incorporating the regularizer will facilitate learning the (latent) topic features in the trainable parameters simultaneously and inherit relevant topical features from each of the source domains and generate meaningful representations for the target domain.	O	O	Review	10246
The analysis and evaluation were presented to show the effectiveness of the proposed method.	O	O	Review	10246
However, the results are not significantly improved than the based line model DocNADE.	B-Review	B-1	Review	10246
<sep> <sep> Overall, the paper is written well.	I-Review	I-1	Review	10246
However, it is not clear to me that the improved results are resulted due to multi-source multi-view transfer learning or for the better leaning of the single-source model due to the incorporation of the regularizer.	I-Review	I-1	Review	10246
<sep> <sep> <sep> <sep> As far we we know, we have covered all the experimental settings, where we have clearly/individually shown contributions of each of the components.	B-Reply	B-1	Reply	10246
<sep> <sep> See Table 5, 6 and 7, where the scores are reported due to:	I-Reply	I-1	Reply	10246
(1) only single-source word embedding transfer, i.e., LVT,	I-Reply	I-1	Reply	10246
(2) multi-source word embedding transfer, i.e., MST+LVT,	I-Reply	I-1	Reply	10246
(3) only single-source topic embedding transfer, i.e., GVT,	I-Reply	I-1	Reply	10246
(4) multi-source topic embedding transfer, i.e., MST+GVT,	I-Reply	I-1	Reply	10246
(5) single-source joint word and topic embeddings transfers, i.e., MVT=LVT+GVT, and	I-Reply	I-1	Reply	10246
(6) multi-source joint word and topic embeddings transfers, i.e., MST+ MVT.	I-Reply	I-1	Reply	10246
<sep> <sep> Notice that the topic-embedding transfer is performed via the regulalrization term.	I-Reply	I-1	Reply	10246
Also, mentioned in algorithm #1.	I-Reply	I-1	Reply	10246
<sep> <sep> We are happy to answer if something is still not clear.	O	O	Reply	10246
Please point out precisely.	O	O	Reply	10246

On the basis of existing topic modelling approaches, the authors apply a transfer learning approach to incorporate additional knowledge to topic models, using both word embeddings and topic models.	O	O	Review	10246
The underlying idea is that topic models contain a global view that differs on a thematic level, while word embeddings contain a local, immediate contextual view.	O	O	Review	10246
The combination of both local and global view transfer to enhance a topic model is the main contribution of this paper, especially when using multiple sources (therefore the title: multi-source multi-view transfer).	O	O	Review	10246
Given a document collection, DocNADE is used to generate the topic-word matrix.	O	O	Review	10246
In the local view transfer step, the pre-trained WordPool is used, from which knowledge is transferred on the target document.	O	O	Review	10246
The global view transfer is done by transferring knowledge from the pre-trained TopicPool to the target.	O	O	Review	10246
As described in Algorithm 1 in the paper, both Word- and TopicPool are jointly used in the transfer learning process.	O	O	Review	10246
For evaluation, three different measures are taken into account: Perplexity, Topic Coherence and Precision (Information Retrieval).	O	O	Review	10246
In comparison to a DocNADE only approach, all values are better in the settings that use the transfer learning approach.	O	O	Review	10246
Compared to DocNADE + word embeddings, the results are competitive as well.	O	O	Review	10246
In both experiments, the multi-source setting evaluates best overall.	O	O	Review	10246
In conclusion, the paper shows that exploiting multiple sources and views in transfer learning leads to an overall improvement in the given tasks.	O	O	Review	10246
The main contribution is the usage topic models in a transfer learning framework.	O	O	Review	10246
Additionally the use of multi-source word embeddings is novel too, especially in the joint setting with the topic model transfer.	O	O	Review	10246
The paper shows how the DocNADE approach is enhanced to make use of both local and global view transfer and how this enhancement leads to improved performance on various related tasks.	O	O	Review	10246
Still, the overall contribution is mostly in combining existing methods and can be judged as rather incremental.	O	O	Review	10246
Minor note: A small mistake has been found in Table 5.	O	O	Review	10246
The best perplexity value in the first column is not the bold 638, but the 630 in the local-view transfer setting.	O	O	Review	10246
Edit after rebuttal: In my review I did not value the contribution of the transfer learning approach enough.	O	O	Review	10246
So, when also considering the extensive evaluation I am now leaning towards accept.	O	O	Review	10246
Thanks for increasing your rating and leaning towards accept!	O	O	Reply	10246
Thanks for acknowledging contribution of our proposed transfer learning approaches in topic modeling.	O	O	Reply	10246

Updated review:	O	O	Review	671
Thank you for addressing the comments and making relevant edits.	O	O	Review	671
Additionally, the HIT section provides a lot more insights into the data collection process.	O	O	Review	671
I've updated my score based on the responses/edits made.	O	O	Review	671
<sep> <sep> ------	O	O	Review	671
<sep> This paper is about a dataset (TABFACT) aimed at promoting research for fact-verification using semi-structured data as evidence.	O	O	Review	671
The paper highlights how the existing fact-verification studies have been restricted to work with unstructured evidence, and hence lack generalization to use-cases where the evidence is in a structured format (eg.databases).	O	O	Review	671
The paper also highlights how fact-verification with semi-structured evidence is challenging, since it involves both linguistic reasoning (for paraphrasing, entailment etc.)	O	O	Review	671
and symbolic reasoning (for operations like count, min, max etc.).	O	O	Review	671
To tackle this, the authors suggest two approaches as baselines on the dataset - one uses off-the-shelf BERT model for NLI; the other one focuses on symbolic reasoning and is based on program execution - which primarily uses lexical matching and a set of predefined operations (like count/max/min) to construct a program.	O	O	Review	671
<sep> <sep> Apart from a few issues (mentioned below), the paper is well written.	O	O	Review	671
The authors have provided a detailed overview of their data collection/verification pipeline and related model/experiments.	O	O	Review	671
Overall, it seems like an interesting dataset and I'm inclined towards accepting the paper.	O	O	Review	671
<sep> <sep> A few remarks/concerns are:	O	O	Review	671
1.	O	O	Review	671
Usefulness of the dataset:	O	O	Review	671
It seems limiting for a fact-verification dataset to restrict itself to a binary space i.e. entailed vs refuted.	B-Review	B-1	Review	671
It is often the case, that statements are not completely true or false.	I-Review	I-1	Review	671
For example, the 3rd refuted statement in Figure 1 is partially true (‚Äòthere are five candidates in total‚Äô).	I-Review	I-1	Review	671
With a binary space for supervision, we don‚Äôt really know if the system is actually able to capture the linguistic and symbolic nuances present in the task.	I-Review	I-1	Review	671
It is entirely possible for the system to ‚Äúdo well‚Äù without ‚Äúlearning well‚Äù, if the learning/output space is this coarse (as opposed to a dataset like Vlachos and Riedel, 2014).	I-Review	I-1	Review	671
<sep> 2.	O	O	Review	671
Related work:	O	O	Review	671
The paper talks about introducing a new ‚Äòformat‚Äô of evidence (structured text) and talks about ‚Äòunstructured text‚Äô as the only ‚Äòother‚Äô format of evidence.	B-Review	B-2	Review	671
It misses out on a highly related task that uses image as evidence (notable datasets being: CLEVR-Humans, NLVR/2, GQA).	I-Review	I-2	Review	671
Either these should be included in the related work, or the authors should make it explicit that this work only deals with ‚Äòtextual‚Äô evidence.	I-Review	I-2	Review	671
<sep> 3.	O	O	Review	671
The dataset statistics in Table 1 don‚Äôt seem to add up (train+dev+test = (92,283 + 12,792 + 12,779) = 117,854 !	B-Review	B-3	Review	671
= 118,275 (=Total #Sentence)).	I-Review	I-3	Review	671
<sep> 4.	O	O	Review	671
Page 3, Section 2.3: ‚Äúwe further perform quality control‚Äù -&gt; a line or two to explain quality control?	B-Review	B-4	Review	671
<sep> 5.	O	O	Review	671
Appendix C: No data/statistics have been provided to support the conclusion of the ablation study.	B-Review	B-5	Review	671
<sep> <sep> Minor remarks:	B-Review	B-6	Review	671
- Page 2: Section 2:	I-Review	I-6	Review	671
1.	I-Review	I-6	Review	671
overtly -&gt; overly	I-Review	I-6	Review	671
2.	I-Review	I-6	Review	671
huge tables(e.g.	I-Review	I-6	Review	671
-&gt; huge tables (e.g.	I-Review	I-6	Review	671
<sep> - Page 3: Section 2.3	I-Review	I-6	Review	671
1.	I-Review	I-6	Review	671
to filter 18% entailed of entailed statements -&gt; to filter 18% entailed statements	I-Review	I-6	Review	671
<sep> - Page 4:	I-Review	I-6	Review	671
1.	I-Review	I-6	Review	671
candidate) .	I-Review	I-6	Review	671
we need to  -&gt; candidate), we need to	I-Review	I-6	Review	671
Thanks for your constructive feedback, here are the answers to your questions:	O	O	Reply	671
1.	O	O	Reply	671
Usefulness of the dataset: we follow the standard NLI/Fact-Checking setting to divide the label into entailed/refuted, where a given claim with ‚Äúany part of the claim containing misinformation‚Äù is viewed as refuted.	B-Reply	B-1	Reply	671
In order to deal with the coarse space of output label, we propose to analyze the accuracy/F1/HITS@K score of entity linking/search/discriminator to further evaluate the fine-grained performance of the model.	I-Reply	I-1	Reply	671
To encourage automatic evaluation, we plan to annotate a smaller amount of gold data for these components to enrich the evaluation metric.	I-Reply	I-1	Reply	671
<sep> 2.	O	O	Reply	671
Missing reference: I added some references and talked about their relatedness in the revision.	B-Reply	B-2	Reply	671
Among the listed datasets, NLVR/2 is especially related to our task.	I-Reply	I-2	Reply	671
<sep> 3.	O	O	Reply	671
Mismatch Set size: We filtered roughly 400 sentences from some abnormal tables (which contains special tokens/hyperlink/mathematical formula, etc) after merging simple/complex channels and divide the 117,854 into train/val/test.	B-Reply	B-3	Reply	671
<sep> 4.	O	O	Reply	671
Quality Control: We added a Section 2.2 ‚Äúquality control‚Äù to talk about the details of our quality control strategy, which is very critical during collection.	B-Reply	B-4	Reply	671
We distribute the quality control workload to 8 different experts, where each one spent over 50 hours to ensure the data quality.	I-Reply	I-4	Reply	671
<sep> 5.	O	O	Reply	671
w/ vs. w/o caption ablation: We performed a user study before the collection, where we randomly match 50 pairs from two annotation tasks (w/ title and w/o title) and distribute them to our 8 experts to measure the language fluency and informativeness without telling them their sources.	B-Reply	B-5	Reply	671
The user study indicates that the 8 experts consistently agree to favor the statements annotated with Wikipedia title/caption.	I-Reply	I-5	Reply	671
The gap is significant and we immediately made the decision to provide workers with table titles as context.	I-Reply	I-5	Reply	671

This work proposes the problem of fact verification with semi-structured data source such as tables.	O	O	Review	671
Specifically, the authors created a new dataset TabFact and evaluated two baseline models with different variations.	O	O	Review	671
They applied two criteria and different rewards for workers to collect two subsets of different levels (‚Äúsimple‚Äù and ‚Äúcomplex‚Äù).	O	O	Review	671
They also applied a negative rewriting strategy to avoid exploitable cues or patterns in the annotations.	O	O	Review	671
They evaluated two baselines models: (1) latent program algorithm (LPA), which makes use of simple string match entity linking and systematic search and trains a neural network discriminator, and (2) Table-BERT, which linearize the table into a sequence through concatenation or template, and treat it as a classfication problem.	O	O	Review	671
Both showed reasonable accuracy (~68%), but still below human performance (92.1%) on a held out test set.	O	O	Review	671
<sep> <sep> I would like to see the paper accepted because:	O	O	Review	671
(1) it proposes an interesting task (table fact verification) with a clean dataset, and the experiments evaluated the ability of the current neural network models, such as BERT, or hybrid models, such as the LPA baseline, to perform (symbolic) reasoning;	O	O	Review	671
(2) special care is done to ensure the dataset doesn't contain simple cues or patterns, which is a common pitfall in dataset collection, and the dataset is also validated through two reasonable baseline models.	O	O	Review	671
<sep> <sep> Some weakness and concerns are:	O	O	Review	671
(1) some error analysis of the baseline models are missing.	B-Review	B-1	Review	671
For example, what types questions are hard/simple for table-BERT and what are hard/simple for LPA, and some comparison between them.	I-Review	I-1	Review	671
This helps point out where the difficulty come from, for example, whether the difficulty is language understanding or symbolic reasoning.	I-Review	I-1	Review	671
<sep> (2) "To focus on statement verification against the table, we do not feed the caption to the model and simply mask the phrases in the statements which links to the caption with placeholders."	B-Review	B-2	Review	671
<sep> I am not sure this is the right thing to do since even the human annotators requires the caption to understand the context, why not also feed the caption into the model?	I-Review	I-2	Review	671
<sep> (3) Although the Figure 2 showed that the higher order operations are indeed used in a majority of questions, which measures the breadth of the reasoning, it is unclear about the depths of the required reasoning, i.e., how many operations / steps are required to achieve the correct answer.	B-Review	B-3	Review	671
It would help if the average number of steps / operations required for answering the questions are shown.	I-Review	I-3	Review	671
<sep> <sep> If the above concerns are addressed, I will be willing to raise my score.	O	O	Review	671
<sep> <sep> <sep> Minor comments:	B-Review	B-4	Review	671
<sep> The paper, especially the Appendix, requires some proof reading, for example, I believe the caption for Figure 5 in Appendix A is misplaced.	I-Review	I-4	Review	671
<sep> <sep> "... they are explicitly banned bring ..." -&gt; "banned from bringing"	I-Review	I-4	Review	671
<sep> ‚ÄúAs illustrated in Figure 6, the title only acts as a placeholder in the statements to make it sound more natural.	I-Review	I-4	Review	671
‚Äù -&gt; From the example, it seems the name of the player is kept unchanged in the sentence, which is different from a placeholder.	I-Review	I-4	Review	671
<sep> <sep> Suggestions:	O	O	Review	671
<sep> I understand this might require some works, but it would be really helpful to add more comments and maybe examples for the functions shown in Figure 5 (you might need to split the table into two pages or have another table for examples), so that it can be used by works that follows the LPA approach.	B-Review	B-5	Review	671
<sep> <sep> ‚ÄúDuring the annotation, the workers are explicitly guided to modify the words, phrases or sentence structures but retain the sentence style/length to prevent from artificial cues‚Äù	B-Review	B-6	Review	671
Avoiding simple cues or patterns are important, so it will be good if more details can be shared (for example, the instructions/guidelines you showed to the workers).	I-Review	I-6	Review	671
<sep> <sep> ==================================	O	O	Review	671
<sep> Post rebuttal update:	O	O	Review	671
<sep> Thanks for the update to the paper.	O	O	Review	671
I think this work provides a good dataset and some reasonable baselines, thus should be accepted.	O	O	Review	671
<sep> <sep> However, I am still a bit concerned about the categorization of questions and the analysis on reasoning depth, because they are all based on the programs generated by LPA, while systematic search's recall is just 77% and the programs potentially contains a lot of spurious ones.	B-Review	B-3	Review	671
So the categorization of the questions in Figure 11 and the number of reasoning steps in Figure 12 has to be taken with a grain of salt.	I-Review	I-3	Review	671
It is worth annotating a few hundred, say 100-300 questions, manually with the ground truth programs for question distribution analysis or reasoning depth analysis, and confirm the numbers estimated using programs from LPA.	I-Review	I-3	Review	671
Those manually annotated examples would also be a great addition to the dataset to aid the researchers for better analysis.	I-Review	I-3	Review	671
A good example is the WikiTableQuestions dataset <a href="https://github.com/ppasupat/WikiTableQuestions/releases," target="_blank" rel="nofollow">https://github.com/ppasupat/WikiTableQuestions/releases,</a> which contains 300 manually annotated examples (annotated-all.examples), and they are used to analyze the distribution of the questions in the paper.	I-Review	I-3	Review	671
Thanks for your constructive feedback, here are the answers to your questions:	O	O	Reply	671
1.	O	O	Reply	671
Error Analysis: We have put the detailed error analysis in Appendix C (Error Analysis) in the revision.	B-Reply	B-1	Reply	671
Specifically, we first qualitatively discussed the bottlenecks of LPA and BERT model.	I-Reply	I-1	Reply	671
Then we held-out some data from the validation set to analyze the performance difference between the two models.	I-Reply	I-1	Reply	671
It turns out that the linguistic inference case is much better handled by BERT while max/min/argmax/argmin/count cases are better handled by LPA.	I-Reply	I-1	Reply	671
<sep> 2.	O	O	Reply	671
Feeding Caption to model: During annotation, we have given special notice to the worker not to rewrite the part copied from the Wikipedia table title during the phase of annotation for refuted statements.	B-Reply	B-2	Reply	671
It implies that the captions shouldn‚Äôt be regarded as evidence for verification.	I-Reply	I-2	Reply	671
Thus, we masked them out in the experiments.	I-Reply	I-2	Reply	671
However, we did do some auxiliary experiments to provide the caption as an additional input to the discriminator for the LPA method.	I-Reply	I-2	Reply	671
We found that the performance is roughly the same without much change, we added the exact numbers to Table 2.	I-Reply	I-2	Reply	671
For Table-BERT, the title is already given in the template linearization.	I-Reply	I-2	Reply	671
<sep> 3.	O	O	Reply	671
Reasoning Depth: We have added Appendix D (Reasoning Depth) in the revision, which aims to visualize the reasoning depth of LPA method.	B-Reply	B-3	Reply	671
As can be seen from the figure therein, the reasoning steps are concentrated between 4-7 steps.	I-Reply	I-3	Reply	671
It implies the difficulty and compositionality of the statements in TabFact.	I-Reply	I-3	Reply	671
<sep> 4.	O	O	Reply	671
Minor comments: 1) I have replaced the original table with a detailed version.	B-Reply	B-4	Reply	671
Thanks for your reminder.	I-Reply	I-4	Reply	671
2) regarding the sentence ‚Äúas illustrated in ‚Ä¶‚Äù, I would like to clarify that the annotators can only rely on the title to gain background knowledge.	I-Reply	I-4	Reply	671
They cannot rewrite information about the title to create a ‚Äúrefuted‚Äù statement.	I-Reply	I-4	Reply	671
<sep> 5.	O	O	Reply	671
Function Description: We added detailed function description and input/output examples in Appendix A and also list the function triggers we adopted to shrink the search space.	B-Reply	B-5	Reply	671
<sep> 6.	O	O	Reply	671
Instruction to workers: The detailed guidelines are added to Appendix H, which is the HIT interface we used for the workers to follow during annotation.	B-Reply	B-6	Reply	671

This paper proposes a new dataset for table-based fact verification and introduces a couple of methods for the task.	O	O	Review	671
I think that the dataset would be a useful resource (see some comments nevertheless on its construction), however the methods proposed are not particularly interesting, and the contributions to ML and NLP are overstated in my opinion.	B-Review	B-3	Review	671
In addition the paper needs proof reading as there are many typos, some of which make comprehension problematic.	I-Review	I-3	Review	671
In detail:	O	O	Review	671
<sep> - The dataset is the main contribution of this paper.	O	O	Review	671
Its size is great.	O	O	Review	671
However I have some concerns on its construction.	B-Review	B-4	Review	671
The guidelines described for constructing simple and complex claims are rathe vague, e.g. how does one define "too much symbolic reasoning" and explain it to crowdworkers?	I-Review	I-4	Review	671
How was the linguistic complexity difference between the two channels measured?	I-Review	I-4	Review	671
How were the claims sanity checked?	I-Review	I-4	Review	671
In the beginning of section 2.3 it is stated that quality control filtered a substantial proportion of the statements.	I-Review	I-4	Review	671
How was this done?	I-Review	I-4	Review	671
<sep> <sep> - A troublesome aspect in my opinion of the dataset is that it only allows for evaluation of the Entailed/Refuted binary classification task, but not on whether the model used the right evidence to reach its conclusion.	B-Review	B-5	Review	671
Thus it will always be possible for models to score highly without doing the right thing.	I-Review	I-5	Review	671
Avoiding trivial re-writes helps, but it is unlikely to be enough as human crowd workers will try to optimize their earnings.	I-Review	I-5	Review	671
<sep> <sep> - The two models discussed are OK as baselines, but not particularly interesting or appropriate.	B-Review	B-6	Review	671
Both require substantial rule-based processing (named entity linking, latent program construction.	I-Review	I-6	Review	671
templates) and eventually linearize structured data (the program or the table).	I-Review	I-6	Review	671
I understand that this is not the main contribution of the paper, but given the substantial amount of work on semantic parsing and question answering I was expecting more appropriate baselines taking previous work into account.	I-Review	I-6	Review	671
The performance of the model is not great either, especially if we consider that they are only evaluated on returning a binary label, not the correct evidence from the table.	I-Review	I-6	Review	671
<sep> <sep> - While it is true that most of the fact verification work has focus on textual sources, the challenge of combining reasoning over continuous and discrete representations is not new.	B-Review	B-1	Review	671
The various QA works mentioned in the related work section address this, as well as work on theorem proving: <a href="https://arxiv.org/abs/1705.11040" target="_blank" rel="nofollow">https://arxiv.org/abs/1705.11040</a> Furthermore, there has been at least one more previous work on table based verification against  FreeBase tables: <a href="https://www.aclweb.org/anthology/D15-1312/." target="_blank" rel="nofollow">https://www.aclweb.org/anthology/D15-1312/.</a> Thus I believe the discussion of the challenges posed by this dataset should be re-framed, especially given that the kinds of programs that need to be constructed are of similar complexity to previous work like the WikiTableQuestions.	I-Review	I-1	Review	671
<sep> <sep> - writing: "the model is expected to excel... but to fall short", "we follow the human subject research protocols" (which ones?), "	B-Review	B-2	Review	671
in case of obvious stylistic patterns" (which ones).	I-Review	I-2	Review	671
On the whole it is understandable, but the writing should be improved.	I-Review	I-2	Review	671
<sep> <sep> ---- Post author response	O	O	Review	671
<sep> I have responded to the author response and I have revised my score.	O	O	Review	671
6.	O	O	Reply	671
Relatedness to other QA datasets: We have updated the ‚Äúrelated work‚Äù section to include more comprehensive comparisons with question answering/semantic parsing and other references suggested by the reviewers.	B-Reply	B-1	Reply	671
Our proposed dataset is distinguished in the following aspects: 1) From the linguistic reasoning side, the existing QA dataset like WikitableQuestion is mostly dealing with surface-level linguistic phenomena like paraphrase/abbreviation/etc.	I-Reply	I-1	Reply	671
In TabFact, since workers are making statements or conclusions, they tend to involve deeper linguistic reasoning like inference, commonsense.	I-Reply	I-1	Reply	671
2) From the symbolic side, the statement in TabFact tends to contain compound facts, all of them need to be verified to predict the verdict.	I-Reply	I-1	Reply	671
It normally increases the complexity and length of the reasoning chain.	I-Reply	I-1	Reply	671
These two major challenges have greatly distinguished TabFact from the known QA datasets and provide a new research direction for the community to explore.	I-Reply	I-1	Reply	671
<sep> 7.	B-Reply	B-2	Reply	671
We have corrected the minor issues in the revision, the minimum payment protocol is listed in <a href="https://en.wikipedia.org/wiki/Minimum_wage_in_the_United_States" target="_blank" rel="nofollow">https://en.wikipedia.org/wiki/Minimum_wage_in_the_United_States</a> (cited in the revised version).	I-Reply	I-2	Reply	671
<sep> <sep> [Lu 2008]: A generative model for parsing natural language to meaning representations	O	O	Reply	671
[Artzi 2014]: Learning Compact Lexicons for CCG Semantic Parsing	O	O	Reply	671
[Dong 2016]: Language to Logical Form with Neural Attention	O	O	Reply	671
[Yin 2016]: A syntactic neural model for general-purpose code generation	O	O	Reply	671
[Zhong 2017]: Seq2sql: Generating structured queries from natural language using reinforcement learning	O	O	Reply	671
[Luke 2013]: Weakly supervised learning of semantic parsers for mapping instructions to actions	O	O	Reply	671
[Liang 2013]: Learning dependency-based compositional semantics	O	O	Reply	671
[Berant 2014]: Semantic parsing via paraphrasing	O	O	Reply	671
[Wang 2015]: Building a semantic parser overnight.	O	O	Reply	671
<sep> [Pasupat 2015]: Compositional semantic parsing on semi-structured tables.	O	O	Reply	671
<sep> [Liang 2017]: Neural Symbolic Machines: Learning Semantic Parsers on Freebase with Weak Supervision	O	O	Reply	671
[Rishabh 2019]: Learning to Generalize from Sparse and Underspecified Rewards	O	O	Reply	671

The paper proposes to use Contrastive Predictive Coding (CPC), an unsupervised learning approach, to learn representations for further image classification.	O	O	Review	20258
The authors show that using CPC for representation learning allows to achieve better results than other self-supervised methods.	O	O	Review	20258
Moreover, CPC is shown to be useful for semi-supervised learning (on par with SOTA method), and transfer learning.	O	O	Review	20258
All results are very impressive and is in-line with current trends of using a linear classifier on top of a deep feature extractor (e.g., Nalisnick et al "Hybrid Models with Deep and Invertible Features").	O	O	Review	20258
The paper is rather well written and the results are convincing.	O	O	Review	20258
However, The whole idea of the paper is based on the original paper:	O	O	Review	20258
* Oord, Aaron van den, Yazhe Li, and Oriol Vinyals. "	O	O	Review	20258
Representation learning with contrastive predictive coding."	O	O	Review	20258
arXiv preprint arXiv:1807.03748 (2018).	O	O	Review	20258
<sep> Technically speaking, the paper is outstanding, but it lacks novelty in terms of new ideas.	O	O	Review	20258
I highly appreciate new results and new architectures, but it is not enough for a full conference paper.	O	O	Review	20258
<sep> <sep> Remarks	O	O	Review	20258
- In Section 2.1, the problem statement for Contrastive Predictive Coding (CPC) is unclear.	B-Review	B-1	Review	20258
For instance, the authors explain CPC by mentioning about masked convolutional layers that is unnecessary at this point.	I-Review	I-1	Review	20258
I understand that from engineering perspective it is crucial information, but it does not help to understand CPC.	I-Review	I-1	Review	20258
As a result, without knowing the original paper on CPC, Section 2.1 is hard to follow.	I-Review	I-1	Review	20258
<sep> <sep> - The paper can be treated as an uptaded version of the original CPC paper.	B-Review	B-2	Review	20258
I really appreciate all new results and implementation of the idea.	I-Review	I-2	Review	20258
The paper is well written and it is technically correct.	I-Review	I-2	Review	20258
However, I do not find much novelty compared to the original paper.	I-Review	I-2	Review	20258
This would be a perfect workshop contribution, but I am afraid that it is not enough for a full paper.	I-Review	I-2	Review	20258
<sep> <sep> ==== AFTER REBUTTAL ====	O	O	Review	20258
I would like to thank the reviewers for their rebuttal.	B-Review	B-2	Review	20258
It was not my intention to dismiss your effort in providing new technical results.	I-Review	I-2	Review	20258
Please forgive me if you read it in this way.	I-Review	I-2	Review	20258
My point is that the paper presents exactly the same idea as the original paper of CPC, but with new, very interesting results.	I-Review	I-2	Review	20258
However, I doubt if this is enough for a full conference paper.	I-Review	I-2	Review	20258
This point is debatable and I would be happy to further discuss it with other reviewers and the AC.	I-Review	I-2	Review	20258
At this point, I keep my original score, but of I am open for a discussion.	I-Review	I-2	Review	20258
We would like to thank the reviewer for their comments on the manuscript.	B-Reply	B-2	Reply	20258
However, we find the decision to dismiss a ‚Äútechnically outstanding‚Äù paper simply because it does not introduce a new mathematical formalism to be rather mystifying.	I-Reply	I-2	Reply	20258
Rather than making ever more complex objectives, there is value in reminding the community of the sobering reality that implementation details are hugely important.	I-Reply	I-2	Reply	20258
Dissecting and highlighting the contributions of these details (as we do) will also facilitate the comparison of different self-supervised objectives in future work.	I-Reply	I-2	Reply	20258
To that end, our work makes a number of contributions, both methodological and experimental, which we think will be very impactful to the community.	I-Reply	I-2	Reply	20258
<sep> <sep> On the methodological side, we identify a number of axes which enable the performance of CPC: network scale, local data augmentation, amount of self-supervision, etc.	B-Reply	B-1	Reply	20258
These insights are sufficiently general for them to inform other contrastive methods, and other modalities (e.g. audio and video have analogous forms of data-augmentation).	I-Reply	I-1	Reply	20258
Furthermore, it is an important experimental point to notice just how much these ‚Äúimplementation details‚Äù matter.	I-Reply	I-1	Reply	20258
Without them, one might dismiss contrastive learning altogether.	I-Reply	I-1	Reply	20258
With them, they appear to be one of the most promising methods for representation learning.	I-Reply	I-1	Reply	20258
We will open-source our implementation and pre-trained models to make these techniques widely accessible.	I-Reply	I-1	Reply	20258
<sep> <sep> Moreover, we believe our empirical results to represent a landmark in representation learning: we have shown it to enable substantial gains in data-efficiency for all amounts of available data (as opposed to in only the low-data regime).	I-Reply	I-1	Reply	20258
For the first time, it appears beneficial to train supervised networks on top of learned representations rather than pixel lattices.	I-Reply	I-1	Reply	20258
Going further, our results in transfer learning (which approach that of supervised transfer) raise the possibility of removing the need for large-scale labeled datasets altogether.	I-Reply	I-1	Reply	20258

Title: DATA-EFFICIENT IMAGE RECOGNITION	O	O	Review	20258
[Summary]	O	O	Review	20258
-This paper introduces Contrastive Predictive Coding (CPC) image recognition in the data-efficient regime.	O	O	Review	20258
Concretely, the authors improve CPC in terms of its architecture and training strategy.	O	O	Review	20258
The extensive experiments show that CPC enables data-efficient image classification and surpassed other unsupervised approaches.	O	O	Review	20258
<sep> <sep> [Pros]	O	O	Review	20258
- Although the CPC was proposed and evaluated in vision task in [1], a new implementation of CPC with dramatically-improved ability is presented in this paper.	O	O	Review	20258
<sep> - The CPC is utilized to enhance spatially predictable representations which benefits a lot data-efficient image recognition.	O	O	Review	20258
<sep> <sep> [Cons]	O	O	Review	20258
- In Sec.4.1, four axes are identified to upgrade CPC v1 to CPC v2.	B-Review	B-1	Review	20258
But they are not well motivated.	I-Review	I-1	Review	20258
More discussions about why this four axes are investigated in image recognition.	I-Review	I-1	Review	20258
<sep> <sep> -The core idea is motivated by a critical hypothesis that good representations should make spatio-temporal variability in natural signals more predictable.	B-Review	B-2	Review	20258
However, this hypothesis is not well verified.	I-Review	I-2	Review	20258
The concept of amount of ‚Äòpredictability‚Äô in page 7 is not clear.	I-Review	I-2	Review	20258
It would be great if you provide more evidence that the improvement in low-data classification results from the increased ‚Äòpredictability‚Äô.	I-Review	I-2	Review	20258
<sep> <sep> - The comparison in Sec.4.3 seems unfair.	B-Review	B-3	Review	20258
The pretrain model trained with different methods should be the same.	I-Review	I-3	Review	20258
For example, the Faster RCNN trained on CPC v2 uses ResNet-101 as backbone but Local Aggregation method uses ResNet-50.	I-Review	I-3	Review	20258
<sep> <sep> [Summary]	O	O	Review	20258
- This work extends CPP to data-efficient image recognition by simply adjusting network architectures and training strategies, which makes it less interesting.	B-Review	B-4	Review	20258
Besides, the major hypothesis is not well validated.	I-Review	I-4	Review	20258
<sep> - The experimental results are convincing and encouraging.	B-Review	B-3	Review	20258
Some minor flaws such as unfair comparison should be fixed.	I-Review	I-3	Review	20258
<sep> - I want to see how the four axes in Sec.4.1 are related to core motivation (more predictable) since they are major adjustments from CPP v1 to CPP v2.	B-Review	B-1	Review	20258
If the author provides a profound explanation of the problem, I would consider changing the rating.	I-Review	I-1	Review	20258
<sep> <sep> We thank the reviewer for their comments.	O	O	Reply	20258
Regarding the first point ‚ÄúMore discussions about why this four axes are investigated in image recognition,‚Äù we agree that a better explanation of the relationship between the new training protocol and our original hypothesis is warranted.	B-Reply	B-1	Reply	20258
Our modifications to the original CPC model can be grouped into 3 categories.	I-Reply	I-1	Reply	20258
Increasing the network scale and ease of optimization both contribute to the representational capacity of the network and its ability to make the complex transformations across space more predictable.	I-Reply	I-1	Reply	20258
The next crucial modification, patch-based augmentation, allows us to control which features of the data will be made more predictable.	I-Reply	I-1	Reply	20258
By making low-level features (such as brightness, color, and contrast) less predictable, we ensure the network capacity is spent on making other features (including the more semantic ones of interest) more predictable.	I-Reply	I-1	Reply	20258
Finally, increasing the number of spatial directions used in the training task amplifies this learning signal.	I-Reply	I-1	Reply	20258
We will update the discussion of these points in section 4.1 to share these intuitions.	I-Reply	I-1	Reply	20258
<sep> <sep> Our original hypothesis stated that spatially predictable representations should better enable low-data classification.	B-Reply	B-2	Reply	20258
Through our ablation, we are able to titrate the amount of ‚Äúpredictability‚Äù in the representation by changing the number of spatial directions included in the prediction task.	I-Reply	I-2	Reply	20258
For example, one model only attempts to predict patches from top to bottom.	I-Reply	I-2	Reply	20258
The next makes predictions in both vertical directions.	I-Reply	I-2	Reply	20258
The third in all four (horizontal and vertical) spatial directions.	I-Reply	I-2	Reply	20258
These models therefore learn to be ‚Äúpredictable‚Äù along more and more axes of the data.	I-Reply	I-2	Reply	20258
In line with our hypothesis, representations which are more ‚Äúpredictable‚Äù also enable better low-data classification.	I-Reply	I-2	Reply	20258
However, since these models also improve linear classification accuracy, we asked whether these two metrics were necessarily related to each other.	I-Reply	I-2	Reply	20258
This was not the case (they are uncorrelated across other model specifications, a novel finding in itself), and we therefore take this as evidence that more spatially predictable representations enable efficient classification.	I-Reply	I-2	Reply	20258
<sep> <sep> Finally, we agree that it would be interesting to re-evaluate the CPC model with architectures used in other works.	B-Reply	B-3	Reply	20258
Most of the methods we compare to in Table 3 use a ResNet-101, which is why we opted for that architecture.	I-Reply	I-3	Reply	20258
Nevertheless we will include results for ResNet-50 as you suggest in the final version, and report the architecture used by each method.	I-Reply	I-3	Reply	20258
<sep> <sep> To conclude, we respectfully disagree with the assessment that this work is ‚Äúsimply adjusting network architectures and training strategies, which makes it less interesting‚Äù.	B-Reply	B-4	Reply	20258
Firstly, it is unexpected that the same objective, given a new training protocol, can result in dramatically better performance (from 48.7% to 70.6% linear classification accuracy).	I-Reply	I-4	Reply	20258
Without these results, one might tend to dismiss contrastive learning as impractical or ill-suited to downstream tasks.	I-Reply	I-4	Reply	20258
Furthermore, these modifications are sufficiently general to be applied to a variety of different methods and modalities, and our detailed ablations provide actionable recommendations to the community.	I-Reply	I-4	Reply	20258
We will open-source our implementation and pre-trained models to make these experimental insights widely accessible.	I-Reply	I-4	Reply	20258

The authors augment contrastive predictive coding (CPC), a recent representation learning technique organized around making local representations maximally useful for predicting other nearby representations, and evaluates their augmented architecture in several image classification problems.	O	O	Review	20258
Although the modifications to CPC aren't particularly original, the authors show first that these yield a significant improvement in linear classification accuracy.	O	O	Review	20258
They then use this improved model to obtain impressive performance in classification within semi-supervised and transfer learning settings, giving strong support for the use of such methods within image processing applications.	O	O	Review	20258
<sep> <sep> Pros:	O	O	Review	20258
Owing to its generality (CPC assumes only a weak spatial prior in the input data), and cheap computational cost relative to earlier generative approaches, CPC is already a promising unsupervised representation learning technique.	O	O	Review	20258
The paper gives more evidence of this usefulness for image data, yielding leading performance on several different image classification benchmarks.	O	O	Review	20258
<sep> <sep> The authors also make the observation that linear separability, the standard benchmark for evaluating unsupervised representations, correlates poorly with efficient prediction in the presence of limited labeled data.	O	O	Review	20258
This observation should be of interest in the broader community, and points to the need for more diverse metrics for unsupervised representations.	O	O	Review	20258
<sep> <sep> Cons:	O	O	Review	20258
The improvements given in the paper are quite useful within their stated domain (image data), but aren't directly applicable to other types of input data.	B-Review	B-1	Review	20258
Although the authors make a point of emphasizing the relevance of CPC for other problem domains, they don't currently provide any suggestions for how this current work could be generalized to handle these other cases.	I-Review	I-1	Review	20258
In this sense, I think it is a bit deceptive to refer to their model as "CPC v2", as the majority of their changes have no bearing on the intrinsic CPC algorithm itself.	I-Review	I-1	Review	20258
<sep> <sep> I am sure that some of the methods used here could lead to improvements in the use of CPC for other types of data, but the authors currently don't provide any insight on this issue.	I-Review	I-1	Review	20258
In line with that, I think their work would be improved by some commentary on this, in particular by any concrete suggestions they have about how similar augmentations to CPC could be carried out in text, audio, and/or video data.	I-Review	I-1	Review	20258
<sep> <sep> Verdict:	O	O	Review	20258
Owing to the reasons given above, I recommend acceptance.	O	O	Review	20258
<sep> <sep> Minor suggestions:	B-Review	B-2	Review	20258
Please use a different color scheme for your figures that is still meaningful if the paper is printed in greyscale.	I-Review	I-2	Review	20258
We thank the reviewer for their comments.	B-Reply	B-1	Reply	20258
We agree that the modifications we bring to the CPC method are general enough to be applied to a variety of other modalities.	I-Reply	I-1	Reply	20258
For one, the observation that increasing the network depth and ease of optimization can strongly impact performance directly translates to other types of data.	I-Reply	I-1	Reply	20258
Data-augmentation has also become a standard technique in supervised learning, with a considerable amount of domain knowledge being accumulated regarding which techniques are useful for which modalities.	I-Reply	I-1	Reply	20258
Our observation that patch-level augmentation dramatically improves the performance of CPC applied to images could therefore be straightforwardly extended (using analogous augmentation techniques) to audio segments, video cubes, and natural language atoms.	I-Reply	I-1	Reply	20258
Similarly, increasing the number of predictions can easily be applied to other data.	I-Reply	I-1	Reply	20258
As such, since our modifications to the CPC methodology are general enough to be applied to all the modalities for which CPC was originally designed, we think calling it ‚ÄúCPC v2‚Äù is valid and warranted, but are curious to hear your suggestions in this matter.	I-Reply	I-1	Reply	20258
<sep> <sep> We will make sure to make the figures printer-friendly in the final version.	B-Reply	B-2	Reply	20258

This paper improves Contrastive Predictive Coding method and reaches a good performance in several downstream tasks.	O	O	Review	20258
However, the novelty and technical contributions are limited.	O	O	Review	20258
<sep> <sep> Strengths:	O	O	Review	20258
+ The experimental results seem good.	O	O	Review	20258
The reimplemented CPC v2 performs much better than the original version.	O	O	Review	20258
And the performance of down-stream tasks is comparable or better than the state-of-the-art methods.	O	O	Review	20258
<sep> + The paper is well written.	O	O	Review	20258
The paper structure is clear and figures are well illustrated.	O	O	Review	20258
<sep> + Figure 3 shows clearly the performance improvements of a series of incremental modifications to the original CPC methods.	O	O	Review	20258
<sep> <sep> Weaknesses:	O	O	Review	20258
- The novelty and technical contributions are limited.	B-Review	B-1	Review	20258
This paper only proposes some minor improvements based on the original CPC method and use a deeper network to get better performance.	I-Review	I-1	Review	20258
The proposed method lacks of important insights for the research community.	I-Review	I-1	Review	20258
<sep> - The capacity of network architecture is crucial for self-supervised learning.	B-Review	B-2	Review	20258
But in Table 1,2,3, the network architecture of the proposed method is deeper than that in the comparison methods, which is unfair for the comparison methods.	I-Review	I-2	Review	20258
Meanwhile, the network architectures of many compared methods are not listed in the tables, which may be misleading.	I-Review	I-2	Review	20258
For example, Unsupervised Data Augmentation (Xie et al 2019) in table 2 and Instance Discrimination (Wu et al 2018) in table 3 use ResNet50, which is much more shallow than ResNet-161 in this paper.	I-Review	I-2	Review	20258
<sep> - In section 2.1, the paper doesn't describe clearly what's the input of masked convolutional network and how to calculate.	B-Review	B-3	Review	20258
<sep> <sep> <sep> We thank the reviewer for their comments.	B-Reply	B-1	Reply	20258
We respectfully disagree with the assessment that the ‚Äúnovelty and technical contributions are limited‚Äù.	I-Reply	I-1	Reply	20258
Although the learning objective we use is the same as in (van den Oord, 2018), we make a number of changes to the training methodology without which the final performance would be uncomparable to the one we arrive at (70.6% Top-1 linear classification accuracy vs 48.7%).	I-Reply	I-1	Reply	20258
We ablate all of these changes and show how important they are for achieving state of the art results.	I-Reply	I-1	Reply	20258
This, combined with the fact that these modifications are very general (and could be straightforwardly applied to audio, video, and text; see footnote), make these technical contributions readily re-usable by the research community.	I-Reply	I-1	Reply	20258
We will open-source our implementation and pre-trained models to make these experimental insights widely accessible.	I-Reply	I-1	Reply	20258
<sep> <sep> We agree that it would be interesting to re-evaluate the CPC model with architectures used in other works.	B-Reply	B-2	Reply	20258
These tend to differ widely across papers: (Tian, 2019) use ResNet-101, (Donahue &amp; Simonyan, 2019) use RevNet-50 with 4x width, (Xie, 2019) use ResNet-50 whereas (Zhai, 2019) use ResNet-50 with 4x width.	I-Reply	I-2	Reply	20258
It is therefore difficult to chose a single architecture that will enable comparison to all prior works.	I-Reply	I-2	Reply	20258
Nonetheless, we will systematically list the architectures used by each method and include results from ResNet-50.	I-Reply	I-2	Reply	20258
<sep> <sep> The inputs to the masked convolutional network are the feature vectors z_{i,j}. We will make this clear in the text, and provide a reference to the appendix in which this is made explicit.	B-Reply	B-3	Reply	20258

A cool improvement on previous partial computation works that allows to change amount of computation at test time rather than during training.	O	O	Review	63
<sep> <sep> One downside is that empirical comparisons with previous approaches are lacking.	B-Review	B-1	Review	63
Is it better to train for the worst case (previous methods) or to train for the general case with a test-time precision knob? (	I-Review	I-1	Review	63
knob that controls computational resource allocation).	I-Review	I-1	Review	63
Thank you for your review!	O	O	Reply	63
<sep> <sep> I think your question is answered by figure 2.	O	O	Reply	63
You can interpret the left and right edges of the green curve as a situation where you are training for the worst case or best case, respectively.	B-Reply	B-1	Reply	63
At the left end, the green curve represents always using the most resource-constrained model (worst case) and at the right end it represents always using the most resource-hungry model (best case).	I-Reply	I-1	Reply	63
It seems that if you know ahead of time that you need to operate exclusively in the worst case setting then it is better to train a model specifically for that task, as indicated by the green line crossing over the blue.	I-Reply	I-1	Reply	63
The result is similar for the best case scenario although the performance gain is not as clear in that case.	I-Reply	I-1	Reply	63
The main benefit of our model comes from the in-between cases when the model can choose per-instance how much of its 'budget' to expend.	I-Reply	I-1	Reply	63

Pros	O	O	Review	20134
+ This work provided a good summary of observations and network properties that worth studying during the early stage of network‚Äôs training.	O	O	Review	20134
<sep> + The authors conducted extensive and detailed experiments to study the statistics of weights and their gradients.	O	O	Review	20134
Ablation studies also considered network‚Äôs accuracy under perturbation of weight signs, weight shuffling, and different standard deviations.	O	O	Review	20134
<sep> + The authors also verified the effectiveness of weak labels used in self-supervised learning.	O	O	Review	20134
<sep> <sep> Cons	O	O	Review	20134
- The work itself did not propose any new network properties or any new metric to measure.	B-Review	B-1	Review	20134
Most experiments are designed for previous observations and mostly for verification purpose.	I-Review	I-1	Review	20134
I am concern about the core motivation of this work, like to identify or solve any new problems, in addition to experimentally verify the observations during network‚Äôs training.	I-Review	I-1	Review	20134
<sep> - The conclusion in this work is still very empirical: it remains uncertain whether in other vision tasks and with more complex networks (e.g. multi-branch network) these conclusions would hold.	B-Review	B-2	Review	20134
We thank the reviewer for their comments.	O	O	Reply	20134
Our response to their concerns is below:	O	O	Reply	20134
<sep> While the reviewer is correct that our work does not propose any strictly new metrics, we would like to emphasize that discovering new metrics was not the goal of this work.	B-Reply	B-1	Reply	20134
Rather, our aim was to rigorously and exhaustively measure a number of network properties as they change over the initial portion of training in order to better understand why this period of learning is so critical and to elucidate the precise factors responsible for these changes.	I-Reply	I-1	Reply	20134
This is best done using existing metrics that are already meaningful to the reader.	I-Reply	I-1	Reply	20134
<sep> <sep> While novel algorithms and metrics are of course important, careful empirical work aiming to better understand these metrics and algorithms are equally important.	I-Reply	I-1	Reply	20134
This style of work is increasingly being recognized and sought by the community, as evidenced by several recent workshops and talks emphasizing rigorous empirical studies [1, 2, 3].	I-Reply	I-1	Reply	20134
<sep> Moreover, we note that we have developed an entirely new scientific application for the lottery ticket framework as a means to investigate the early phase of training, and our experiments have several clear implications for a number of downstream investigations, including better pruning strategies and initializations.	I-Reply	I-1	Reply	20134
First, we found that, in contrast to previous work on smaller networks [4], reinitializing networks with random weights but maintained signs is not in fact sufficient for more commonly used deeper networks, such as ResNets.	I-Reply	I-1	Reply	20134
Second, we found that even after only a small number of iterations, the weight distributions are highly non-i.i.d.,	I-Reply	I-1	Reply	20134
suggesting that approximating such a distribution to sample from for initialization, as was implied by initial work into the lottery ticket hypothesis, is unlikely to succeed (at least without jointly modeling the weights).	I-Reply	I-1	Reply	20134
Finally, we demonstrated that the changes which take place over the initial course of training *can* in fact be approximated by unsupervised pretraining, which suggests several avenues for improving training of compressed networks.	I-Reply	I-1	Reply	20134
We believe that all of these conclusions will likely be important for future investigations into ways to improve training.	I-Reply	I-1	Reply	20134
Reviewer 2 agreed that these conclusions will likely have impact on future network improvements, stating that ‚Äú...[our study] may motivate new neural network compression methods to be proposed.	I-Reply	I-1	Reply	20134
‚Äù	I-Reply	I-1	Reply	20134
<sep> While the reviewer is correct to note that our experiments were only performed on CIFAR-10, primarily due to compute limitations (each line on each plot represents approximately 100 individual model trainings, making equally rigorous experiments on larger datasets prohibitively expensive), we emphasize that our conclusions were robust across five distinct network architectures: ResNet-20, ResNet-56, ResNet-18, Wide-ResNet-16-8, and VGG-13.	B-Reply	B-2	Reply	20134
While we were only able to include ResNet-20 in the main text due to space limitations, we have included plots for the other four networks for all experiments in the appendix section C. We were glad to see all three reviewers recognize the breadth of experiments, calling them ‚Äúextensive and detailed‚Äù (R1), ‚Äúcarefully designed‚Äù (R2), and ‚Äúexhaustive‚Äù (R3).	I-Reply	I-2	Reply	20134
Therefore, while we agree with the reviewer that further work for other task types would be interesting, we believe it is beyond the scope of the present work.	I-Reply	I-2	Reply	20134
<sep> <sep> [1] Identifying and Understanding Deep Learning Phenomena, ICML 2019 workshop, <a href="http://deep-phenomena.org/" target="_blank" rel="nofollow">http://deep-phenomena.org/</a>	O	O	Reply	20134
<sep> [2] Science meets Engineering of Deep Learning, NeurIPS 2019 workshop, <a href="https://sites.google.com/view/sedl-neurips-2019/main" target="_blank" rel="nofollow">https://sites.google.com/view/sedl-neurips-2019/main</a>	O	O	Reply	20134
<sep> [3] Ali Rahimi, Test of Time award talk, NeurIPS 2017, <a href="https://www.youtube.com/watch?v=Qi1Yry33TQE" target="_blank" rel="nofollow">https://www.youtube.com/watch?v=Qi1Yry33TQE</a>	O	O	Reply	20134
<sep> [4] Hattie Zhou, Janice Lan, Rosanne Liu, and Jason Yosinski.	O	O	Reply	20134
Deconstructing lottery tickets: Zeros, signs, and the supermask.	O	O	Reply	20134
NeurIPS, 2019.	O	O	Reply	20134

This paper aims at exploring the properties of neural network training during the early phase.	O	O	Review	20134
By some studies on the lottery ticket hypothesis, something important happens during the early phase of training so rewinding the network should go to these early phases instead of the initial phase.	O	O	Review	20134
So, what is important during training?	O	O	Review	20134
The paper explores this problem from four aspects through empirical studies:	O	O	Review	20134
1.	O	O	Review	20134
By showing the various statistics through different training iterations, especially the gradient magnitude, the training phase is divided into three parts, and each part has different behaviors.	O	O	Review	20134
<sep> 2.	O	O	Review	20134
The paper explores what is more important for the early phase of training: signs of the weights or magnitude of the weights.	O	O	Review	20134
<sep> 3.	O	O	Review	20134
The paper explores what is more important for the early phase of training if we redistribute the weights, signs or magnitudes.	O	O	Review	20134
<sep> 4.	O	O	Review	20134
The paper explores how training depends on data.	O	O	Review	20134
Giving weak information such as self-supervised information may work but giving wrong information such as random labels will hurt the performance.	O	O	Review	20134
<sep> <sep> This paper studies the properties of deep neural networks.	O	O	Review	20134
Through a series of carefully designed experiments, the paper shows what is important for the weights (magnitude or signs), and what is important for the data (weak information or random information).	O	O	Review	20134
It enables a deep understanding of neural networks and may motivate new neural network compression methods to be proposed.	O	O	Review	20134
Generally, the paper is well-written, although some parts can be improved.	O	O	Review	20134
I would vote for acceptance of the paper.	O	O	Review	20134
<sep> <sep> Some questions/suggestions to make the paper clearer:	O	O	Review	20134
1.	B-Review	B-1	Review	20134
It is better to have a table summarizing various results of the paper, to give readers an overall impression after going through so many detailed experimental results.	I-Review	I-1	Review	20134
<sep> 2.	O	O	Review	20134
The results of Fig.4 and Fig.6 can be inconsistent.	B-Review	B-2	Review	20134
In Figure 4, it says that signs are less important than magnitudes.	I-Review	I-2	Review	20134
In Figure 6, it says that signs are more important than magnitudes if shuffling filters and keep signs.	I-Review	I-2	Review	20134
Any explanation on the inconsistency?	I-Review	I-2	Review	20134
<sep> 3.	O	O	Review	20134
There is no explanation of the ‚Äúweight trace‚Äù in Figure 3.	B-Review	B-3	Review	20134
<sep> 4.	O	O	Review	20134
It is not clear what is the difference between ‚ÄúInit‚Äù and ‚ÄúFinal‚Äù in ‚ÄúL2 Dist‚Äù and ‚ÄúCosine Similarity‚Äù in Figure 3.	B-Review	B-4	Review	20134
<sep> <sep> Finally,  it is said in the ‚Äúcall for papers‚Äù, ‚ÄúReviewers will be instructed to apply a higher standard to papers in excess of 8 pages‚Äù.	B-Review	B-5	Review	20134
This paper is nearly nine pages, and higher standards should be applied.	I-Review	I-5	Review	20134
<sep> <sep> --------------------------------------	O	O	Review	20134
I am satisfied with the rebuttal.	O	O	Review	20134
Since the paper is now within the 8 pages limit, I would not apply a high standard and increase my score.	O	O	Review	20134
<sep> <sep> We thank the reviewer for the helpful suggestions to improve the clarity of our paper.	O	O	Reply	20134
We have addressed all stated concerns except for the table suggestion in the present revision.	O	O	Reply	20134
We intend to add a table summarizing results before the end of the discussion period.	O	O	Reply	20134
Below, we describe the changes we have made to the paper in detail.	O	O	Reply	20134
<sep> <sep> 1.	O	O	Reply	20134
We are working on adding a summary table of results as ‚ÄúAppendix A‚Äù that will summarize each of the experiments we ran, each of the dependent variables, and the key takeaways.	B-Reply	B-1	Reply	20134
We agree that this will be very helpful for readers.	I-Reply	I-1	Reply	20134
We are still determining how exactly to structure this table as there are many experiments, and we will update the paper again once it is ready.	I-Reply	I-1	Reply	20134
<sep> <sep> 2.	O	O	Reply	20134
While we understand why Figures 4 and 6 may seem at odds with one another, their relationship to one another is more nuanced based on which rewinding iteration is analyzed.	B-Reply	B-2	Reply	20134
We clarify the relationship below, and we have updated the second paragraph of Section 5.2 to make clear the differences.	I-Reply	I-2	Reply	20134
<sep> <sep> For rewinding iteration 500, the magnitudes from iteration 500 are more important than the signs.	I-Reply	I-2	Reply	20134
In Figure 4 (left), having the magnitudes alone leads to improved performance (purple line), while having the signs alone leads to bad performance (green and red lines).	I-Reply	I-2	Reply	20134
In every experiment in Figure 6 (left), the magnitudes have been shuffled and performance correspondingly drops, even when fixing the signs.	I-Reply	I-2	Reply	20134
The sole exception is ‚ÄúShuffle Filters,‚Äù which, as Figure 8 shows, is a relatively weak perturbation.	I-Reply	I-2	Reply	20134
<sep> <sep> For rewinding iteration 2000, the magnitudes from iteration 2000 are sufficient for improved performance, but the signs only lead to improved performance in limited settings.	I-Reply	I-2	Reply	20134
Namely, we only see this behavior when the signs are paired with the original initialization (red line in Figure 4 right) or with magnitudes from iteration 2000 (red and green lines in Figure 6 right).	I-Reply	I-2	Reply	20134
When paired with a random initialization (green line in Figure 4 right), performance is poor.	I-Reply	I-2	Reply	20134
<sep> <sep> Our interpretation is that the signs at iteration 2000 only lead to improved performance when the magnitudes are similar to their values in 2000, whether distributionally (the shuffle experiments) or in the values themselves (using the original initialization, whose values will be more similar than random values).	I-Reply	I-2	Reply	20134
<sep> <sep> 3.	B-Reply	B-3	Reply	20134
The ‚Äúweight trace‚Äù graph plots the values of ten randomly-selected weights over the first ten epochs of training.	I-Reply	I-3	Reply	20134
Some weights remain roughly constant while others vary wildly; since there was no general behavior, we did not analyze this graph in the text.	I-Reply	I-3	Reply	20134
We have updated the caption of Figure 3 to clarify the data that is presented in this graph.	I-Reply	I-3	Reply	20134
<sep> <sep> 4.	B-Reply	B-4	Reply	20134
The ‚Äúinit‚Äù and ‚Äúfinal‚Äù referred to the L2 and cosine distance from the weights at each iteration to the initialization and to the final weights at the end of training.	I-Reply	I-4	Reply	20134
In other words, these metrics show how far the network has moved from its starting point (‚Äúinit‚Äù) and how far it still has to move to reach its converged point (‚Äúfinal‚Äù).	I-Reply	I-4	Reply	20134
We have updated the caption of Figure 3 to clarify the meaning of these terms.	I-Reply	I-4	Reply	20134
<sep> <sep> Finally, we have reduced the length of our paper so that it fits within 8 pages by moving the  experiments where we pretrain already-sparse networks from Section 6.4 to the appendix.	B-Reply	B-5	Reply	20134

Overview:	O	O	Review	20134
<sep> This paper is dedicated to examining the changes that networks undergo during the early phase of the network training.	O	O	Review	20134
The author conducts extensive measurements of the network state and its updates during the early iterations of training.	O	O	Review	20134
Based on the observations, they find that: i) deep network is not robust to reinitialization with random weights, but maintained signs; ii) the distribution is highly non-i.i.d after the early phase of network training.	O	O	Review	20134
This is why permuting weight dramatically harms performance.	O	O	Review	20134
iii) the changes in the supervised networks are label-agnostic.	O	O	Review	20134
The author claims these results can play an important role in explaining the network changes in the initial critical period.	O	O	Review	20134
<sep> <sep> Strength Bullets:	O	O	Review	20134
<sep> 1.	O	O	Review	20134
The paper performs exhaustive experiments in the early phase of network training.	O	O	Review	20134
And it has some interesting implications for lottery tickets.	O	O	Review	20134
i.e. to some extent, then signs from the rewinding iteration are sufficient to recover the damage caused by permutation.	O	O	Review	20134
<sep> 2.	O	O	Review	20134
I am very like the analysis of whether weight distributions are i.i.d.. The results in the paper are aligned with my intuition that the weights in the early stage are highly dependent and they share some similarities in the distribution level.	O	O	Review	20134
And weight in different training stages supposes in a different distribution.	O	O	Review	20134
Networks aren't robust to these permutations.	O	O	Review	20134
They also show that the perturbations can be roughly be approximated by adding Gaussian noise to network weights.s	O	O	Review	20134
3.	O	O	Review	20134
The author offers detailed results to analysis the data-dependence of the early phase of network training.	O	O	Review	20134
The experiment organization is complete and convincing.	O	O	Review	20134
<sep> <sep> Weakness Bullets:	O	O	Review	20134
<sep> 1.	O	O	Review	20134
Although the paper gives extensive measurements and observations about the early phase about network training, it doesn't provide useful and efficient guidance for the lottery tickets hypothesis.	B-Review	B-1	Review	20134
In other words, the observation is interesting but the novelty is arguable.	I-Review	I-1	Review	20134
How can we use these "implications" to find better tickets?	I-Review	I-1	Review	20134
I mean it should be efficient.	I-Review	I-1	Review	20134
It is not reasonable cost more the find the best weight magnitude point or sign point for a better initialization.	I-Review	I-1	Review	20134
<sep> 2. [	O	O	Review	20134
Minor] The legend in figure 9 is missing.	B-Review	B-2	Review	20134
I guess it may be the same as the upper left.	I-Review	I-2	Review	20134
But it is still confusing and hard to read.	I-Review	I-2	Review	20134
<sep> <sep> Recommendation:	O	O	Review	20134
<sep> I think this paper provides plenty of insightful observations.	O	O	Review	20134
I still hope the author can solve the above weakness bullets.	O	O	Review	20134
This is a weak accept.	O	O	Review	20134
We thank the reviewer for their helpful suggestions, and have updated our paper in response to their feedback and questions.	O	O	Reply	20134
We answer specific questions below:	O	O	Reply	20134
<sep> Regarding how our results can be used to find better lottery tickets, we argue that our results do in fact provide useful and efficient guidance for the lottery ticket hypothesis.	B-Reply	B-1	Reply	20134
However, this guidance tells us where *not* to look, rather than how to directly improve lottery tickets.	I-Reply	I-1	Reply	20134
Notably, our finding that weight distributions are highly non-i.i.d.	I-Reply	I-1	Reply	20134
after a small number of iterations suggests that approaches to approximate rewound winning tickets through sampling from an i.i.d.	I-Reply	I-1	Reply	20134
distribution are unlikely to bear fruit, and that future explorations of improvements to the lottery ticket hypothesis should focus on early pruning approaches.	I-Reply	I-1	Reply	20134
Furthermore, our finding that the early phase of training can be approximated by training without supervision by training on rotation prediction tasks (though at the cost of longer training times) suggests that a strategy to derive winning tickets using pretraining with less supervision may be possible.	I-Reply	I-1	Reply	20134
We included a paragraph discussing these implications at the end of Section 7.	I-Reply	I-1	Reply	20134
<sep> <sep> Regarding the legend in Figure 9, we thank the reviewer for catching this error!	B-Reply	B-2	Reply	20134
We have added legends to all graphs in Figure 9 (and in Figures A8-A11, which contain the same data for our other networks).	I-Reply	I-2	Reply	20134
The legend was indeed the same for all of the graphs, but we agree that including the legend on each plot improves readability.	I-Reply	I-2	Reply	20134

The paper describes a mid-level representation for videos that can be faster than existing representations and yields similar performance.	O	O	Review	59
The idea is to train many SVMs to detect predefined action instances on sub-blocks from the video, and then to aggregate the SVM responses into a representation for the whole video.	O	O	Review	59
<sep> <sep> This work seems like a fairly straightforward extension of previous similar work that was done on images (Malisiewicz et al), but there are some technical differences like the use of an integral video trick to compute SVM responses fast, which seems nice.	B-Review	B-5	Review	59
<sep> <sep> I don't really understand the mining of negative examples for training the exemplar SVMs.	B-Review	B-1	Review	59
Why is it not possible to train the SVM, say with stochastic gradient descent, on all or many negative examples?	I-Review	I-1	Review	59
<sep> <sep> The method relies on extra, intermediate labels for training which are not used by bag-of-words.	O	O	Review	59
This makes it hard to judge the performance differences between the two and seems to be unfair towards bag-of-words.	O	O	Review	59
<sep> <sep> 3.3: Rather than learning to scale svm confidences within a sigmoid, why not train a regularized logistic regression classifier in the first place, instead of the svm?	B-Review	B-2	Review	59
<sep> <sep> The feature extraction time is reported as the total on the whole UT-I dataset.	B-Review	B-3	Review	59
It would be much better to report it in frames per second to make it comparable with other datasets without having to dig up the description of this dataset.	I-Review	I-3	Review	59
If I am not mistaken it amounts to approximately 5 frames (with more or less standard resolution) per second?	I-Review	I-3	Review	59
If correct, this means that despite the improvement over action bank, the bottleneck is really feature exctraction not classification.	I-Review	I-3	Review	59
So the speed up due to the linear classifier will be swamped by the feature extraction and is not really that relevant, unless I'm missing something.	I-Review	I-3	Review	59
<sep> <sep> pro:	O	O	Review	59
- Well-written, uses some nice engineering tricks like the integral video for computing SVM responses.	O	O	Review	59
<sep> <sep> <sep> neg:	O	O	Review	59
- The paper seems like a slightly strange fit for this conference as it describes a vision system rather than investigating the learning of representations.	B-Review	B-4	Review	59
That intermediate labels are useful on this data is well-known (and unsurprising).	I-Review	I-4	Review	59
The paper does propose a faster way to use them, which is probably worthwhile.	I-Review	I-4	Review	59
We thank the reviewer for the thoughtful suggestions.	O	O	Reply	59
We would like to comments on a few points of the review.	O	O	Reply	59
<sep> <sep> - We believe that it is quite apparent that our approach is not a straightforward extension of [Malisiewicz et al2011]. This prior work has not been applied to videos, just to object detection in still images.	B-Reply	B-5	Reply	59
A naive application of [Malisiewicz et al2011] to videos is simply not feasible because of the prohibitive cost.	I-Reply	I-5	Reply	59
In our paper we describe how to adapt it to work efficiently on videos so that it can scale to large datasets.	I-Reply	I-5	Reply	59
This is not a trivial contribution, as partly acknowledged by the reviewer.	I-Reply	I-5	Reply	59
<sep> <sep> - The mining of hard negatives is a standard strategy in the learning of exemplar SVMs.	B-Reply	B-1	Reply	59
Having said this, the reviewer makes an excellent suggestion in proposing the use of stochastic gradient descent on the entire negative set.	I-Reply	I-1	Reply	59
This is definitely an interesting experiment for future work.	I-Reply	I-1	Reply	59
However, our expectation is that results would be quite similar as those obtained with iterative hard negative mining since only examples violating the margin (i.e., the hard negatives) would contribute to refining the parameters in stochastic gradient descent.	I-Reply	I-1	Reply	59
<sep> <sep> - We agree with the reviewer that regularized logistic regression may be a sensible alternative to the two-step learning of the SVMs and the sigmoids.	B-Reply	B-2	Reply	59
Again, we opted for the simple two-step solution as it has been proven to work effectively in several prior systems (e.g., [Malisiewicz et al 2011; Deng et al CVPR 2011, Bergamo and Torresani, CVPR 2012]).	I-Reply	I-2	Reply	59
<sep> <sep> - As suggested by the reviewer, we will make sure to report the feature extraction time also in frames per second in order to make this number more easily interpretable.	B-Reply	B-3	Reply	59
We recognize that, despite the significant speedup enabled by our approach, feature extraction remains more costly than recognition.	I-Reply	I-3	Reply	59
However, we note that there are many practical scenarios where a feature extraction time of 5 frames per second (as opposed to the 4 frames per *minute* of Action Bank) would enable application of action recognition in large-scale datasets.	I-Reply	I-3	Reply	59
For example, consider the motivating application of interactive content-based video search where the user may query a system by providing an example sequence in order to find videos containing the same action in the database.	I-Reply	I-3	Reply	59
In such scenario the search index (containing the features) can be built offline while the training of the action classifier and the recognition itself must be done at query time.	I-Reply	I-3	Reply	59
Our system can be directly used in such scenarios, in principle even for YouTube-size datasets, while prior mid-level descriptors are simply too costly to be computed for large databases.	I-Reply	I-3	Reply	59
<sep> <sep> - We disagree with the final conclusion of the reviewer that this paper 'describes a vision system rather than investigating the learning of representations.'	B-Reply	B-4	Reply	59
Our entire work centers around the learning of a novel intermediate representation for action recognition.	I-Reply	I-4	Reply	59
While it is true that it shares similarities with prior high-level descriptors (which we discuss in the paper), it should also be acknowledged that our new representation model introduces significant advantages in terms of computational cost and recognition accuracy over the most closely related prior system.	I-Reply	I-4	Reply	59

This paper explores a computationally efficient way to learn an intermediate representation for action recognition.	O	O	Review	59
The technique is somewhat inspired by the approach of ‚Äòaction bank‚Äô but focuses on a much more computationally efficient way to achieve a similar effect.	O	O	Review	59
The technique takes advantages of ‚Äòintegral videos‚Äô and has the flavor of a modern day Viola & Jones type of technique for recognizing activities in a way similar to the classic technique for face detection.	O	O	Review	59
I really like the fact that the authors have taken the issue of computational complexity seriously here.	O	O	Review	59
While some might argue that once the community has found techniques that work very well, one could focus on optimizing them for faster run-time performance.	B-Review	B-1	Review	59
However, some choices imply complexity differences that would be very difficult to address in practical working systems and this paper starts by using a technique as a building block that is pretty close to practical right now.	I-Review	I-1	Review	59
<sep> <sep> The work here is also capable of learning intermediate representations with a particularly small amount of data, i.e. single exeamples of classes of interest and lots of negative examples, due to the use of Malisiewicz et al,‚Äôs exemplar-SVM technique.	O	O	Review	59
This could have advantages in a number of practical situations.	O	O	Review	59
<sep> <sep> I think this paper is both fairly well presented and executed in terms of the experiment work.	B-Review	B-2	Review	59
Importantly, it addresses some key practical issues that deserve more attention.	I-Review	I-2	Review	59
The results are not absolutely at the state of the art, but the value added by this work is quite good, especially for those working in the area of action recognition where data processing considerations are particularly challenging.	I-Review	I-2	Review	59
We thank the reviewer for highlighting the two main contributions of our approach over prior work: computational efficiency and manual annotation parsimony.	B-Reply	B-4	Reply	59

This paper attempts to formalize a notion of creativity in generative models.	O	O	Review	59
The idea is to see if a generative model trained on one dataset can be used to generate novel samples that resemble elements of another dataset.	O	O	Review	59
In this case, it is examined whether a generative model trained on digits could be used to generate samples that look like alphabetical characters.	O	O	Review	59
Several metrics for determining the alphabetical nature of the generated samples are given; this is used as a proxy for novelty.	O	O	Review	59
It is shown that these can be useful in choosing models that generate novel samples outside of the classes the model was initially trained on.	O	O	Review	59
<sep> <sep> I can agree with the premise that when it comes to out-of-class novelty, likelihood is probably not a good measure since it will penalize models that generate samples that are too far outside of the data distribution.	B-Review	B-1	Review	59
However, I'm not  yet convinced that the conclusions drawn here would generalize beyond the specific examples given in the paper.	I-Review	I-1	Review	59
It would be good in a future iteration to see this same analysis on another dataset, or perhaps even to reverse the existing experiment (train on alphabetical characters, evaluate on digits).	I-Review	I-1	Review	59
Another possibility would be to test on several different alphabets, like those found in Omniglot.	I-Review	I-1	Review	59
<sep> <sep> Although I think this particular analysis is limited (it is a workshop submission), I do think it proposes an interesting direction for measuring the novelty of samples from a generative model.	O	O	Review	59
I could see this being a potentially useful direction for measuring interesting properties of generative models in terms of creativity.	O	O	Review	59
<sep> <sep> How are the panagrams (a)-(d) generated?	B-Review	B-2	Review	59
Are letters chosen based on Euclidean distance to some reference characters?	I-Review	I-2	Review	59
Thank you for your comments and suggestions.	O	O	Reply	59
We definitely want	B-Reply	B-1	Reply	59
to redo the same experiments and analysis on other settings or	I-Reply	I-1	Reply	59
datasets like Omniglot for which the availability of a large	I-Reply	I-1	Reply	59
number of classes will be helpful.	I-Reply	I-1	Reply	59
<sep> Regarding your question about how the pangrams were generated,	O	O	Reply	59
we took the set of images generated by a given model, then	B-Reply	B-2	Reply	59
we selected manually one character from the top 16 in every letter,	I-Reply	I-2	Reply	59
where the top 16 was selected automatically according to the predicted	I-Reply	I-2	Reply	59
probability of the letter according to the discriminator which was	I-Reply	I-2	Reply	59
trained on digits and letters.	I-Reply	I-2	Reply	59

<sep> This paper attempts to formalize the notion of 'computational creativity' from a machine learning perspective, in order for machine learning researchers to make better progress on this problem.	O	O	Review	59
In particular, the authors propose measuring the 'computational creativity' of a model by several metrics intending to capture whether the model can generate new objects from classes unseen during training.	O	O	Review	59
<sep> <sep> I think this is an interesting paper and a good first step in this area.	B-Review	B-1	Review	59
Indeed, absent proper definitions and metrics for vague concepts such as 'creativity', it is difficult to make progress on related computational problems.	I-Review	I-1	Review	59
While the proposed metrics are not perfect,* they seem reasonable enough to warrant future investigation, and thus I think this paper is worthy of acceptance as an ICLR workshop paper.	I-Review	I-1	Review	59
<sep> <sep> *Further thoughts: I'm not convinced that these metrics are selecting for the "right" models from a creativity point of view.	B-Review	B-2	Review	59
If Figure 1 is really a random sample of digits generated by one of the 'most creative' models according to the proposed metrics, it seems like it is mostly just good at capturing lower-level correlations in the data, while generating random high-level details.	I-Review	I-2	Review	59
Thus it seems like a 'creative' model is one that has been artificially limited in order to poorly model high-level features of the data.	O	O	Review	59
This seems intuitively to contrast with creativity as we perceive it in humans -- creative humans are still capable of modeling the world around them, they are just able to combine what they've learned in new and interesting ways.	O	O	Review	59
Perhaps 'true creativity' is out of the reach of current generative models? (	B-Review	B-1	Review	59
Or, perhaps the word 'creativity' is not really meaningful from a computational perspective?)	I-Review	I-1	Review	59
However, I'm not an expert in this area, and I still think the idea is worthwhile presenting, as it may generate interesting discussions.	O	O	Review	59
In future work, I'd like to see a more thorough analysis of what model settings lead to  the most 'creative behaviour' according to these metrics.	O	O	Review	59
Thank you for your comments and suggestions.	O	O	Reply	59
<sep> We are working on a more detailed analysis to understand under	B-Reply	B-1	Reply	59
which conditions we obtain a model that generates novelty.	I-Reply	I-1	Reply	59

The authors evaluate disentangled representations of the dSprites data learned with Wasserstein auto-encoders to those learned with a Œ≤-VAE.	O	O	Review	59
They find that that WAEs yield lower reconstruction errors when at similar levels of accuracy of the disentanglement metric proposed by Higgins et al	O	O	Review	59
<sep> This seems like a completely reasonable workshop submission to me.	B-Review	B-1	Review	59
My only point of criticism would be that the authors could do a better job of comparing to related (and in some cases very recent) related work.	I-Review	I-1	Review	59
There have been a relatively large number of recent proposals for modifications of the VAE objective aid learning of disentangled representations.	I-Review	I-1	Review	59
Many of these objectives incorporate terms that depend on the aggregated posterior.	I-Review	I-1	Review	59
This includes objectives that minimize the total correlation between latent variables such as proposed by Kim and Mnih, as well as (more recently) Chen et al and Gao et al	I-Review	I-1	Review	59
<sep> Perhaps the most closely related example is the InfoVAE by Zhao et al, which if I understand correctly is equivalent to the WAE when c is the cross entropy and D_Z is the KL divergence (although admittedly I was not immediately able to figure out from the Wasserstein VAE paper whether there is some optimal transport stuff that factors into the WAE objective in a way that I don't understand).	B-Review	B-2	Review	59
Assuming this method is not equivalent to the InfoVAE, then it would be interesting to see a direct comparison between these two methods.	I-Review	I-2	Review	59
In other words, do we get better disentangled relative to the Œ≤-VAE because we regularize using a D_Z(Q_Z, P_Z) that compares the aggregate posterior to the prior (which is also the case in the InfoVAE) or is it the case that WAEs also outperform the InfoVAE?	I-Review	I-2	Review	59
<sep> <sep> On a related note, I was not able to find what the divergence measure D_Z(Q_Z, P_Z) the authors use.	B-Review	B-3	Review	59
Is this a GAN-style objective, the MMD, or simply the KL divergence?	I-Review	I-3	Review	59
Note in this context that Kim & Mnih also use a GAN-style discriminator to minimize the total correlation.	I-Review	I-3	Review	59
<sep> <sep> Minor	O	O	Review	59
<sep> - What is the difference between P_G(X | Z) and G(Z) here?	B-Review	B-4	Review	59
<sep> <sep> References	O	O	Review	59
<sep> 1.	O	O	Review	59
Hoffman, M. D. & Johnson, M. J. Elbo surgery: yet another way to carve up the variational evidence lower bound.	O	O	Review	59
in Workshop in Advances in Approximate Bayesian Inference, NIPS (2016).	O	O	Review	59
<sep> <sep> 2.	O	O	Review	59
Zhao, S., Song, J. & Ermon, S. InfoVAE: Information Maximizing Variational Autoencoders.	O	O	Review	59
arXiv:1706.02262 [cs, stat] (2017).	O	O	Review	59
<sep> <sep> 3.	O	O	Review	59
Kim, H. & Mnih, A. Disentangling by factorising.	O	O	Review	59
arXiv preprint arXiv:1802.05983 (2018).	O	O	Review	59
<sep> <sep> 4.	O	O	Review	59
Chen, T. Q., Li, X., Grosse, R. & Duvenaud, D. Isolating Sources of Disentanglement in Variational Autoencoders.	O	O	Review	59
arXiv:1802.04942 [cs, stat] (2018).	O	O	Review	59
<sep> <sep> 5.	O	O	Review	59
Gao, S., Brekelmans, R., Steeg, G. V. & Galstyan, A. Auto-Encoding Total Correlation Explanation.	O	O	Review	59
arXiv:1802.05822 [cs, stat] (2018).	O	O	Review	59
<sep> <sep> Many thanks for your review.	O	O	Reply	59
<sep> <sep> We were aware of some (but not all) of the related works you mentioned, so many thanks for pointing them out.	B-Reply	B-1	Reply	59
We look forward to these works being accepted for publication so that in future work we can thoroughly compare them with our work.	I-Reply	I-1	Reply	59
<sep> <sep> InfoVAE is indeed essentially the same as WAE, though derived in a different way with a different motivation.	B-Reply	B-2	Reply	59
The relationship is discussed in the latest arxiv version of the Wasserstein Auto-Encoders paper: <a href="https://arxiv.org/pdf/1711.01558.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1711.01558.pdf</a>	I-Reply	I-2	Reply	59
<sep> The divergence measure we used was the MMD.	B-Reply	B-3	Reply	59
<sep> <sep> P_G(X|Z) and G(z): There was a typo, we should have written P_G(X|X=z) rather than G(z).	B-Reply	B-4	Reply	59
Thank you for noticing this.	I-Reply	I-4	Reply	59

<sep> The work shows some preliminary results that suggest that Wasserstein autoencoders could be used for finding disentangled representations.	O	O	Review	59
The method performs comparable (or better) than the beta-VAE on a toy but illustrative example.	O	O	Review	59
<sep> <sep> The experimental evaluation is limited and comparisons only include beta-VAE, which is of course a key baseline.	O	O	Review	59
The paper would be stronger if other real datasets were evaluated (say some simple image datasets, like CelebA or 3D faces, as in beta-VAE), and other baselines were included.	B-Review	B-1	Review	59
<sep> <sep> How do results vary with lambda?	B-Review	B-2	Review	59
Results in the 5-variable sprites seem to be very good only for a small set of the examples.	I-Review	I-2	Review	59
<sep> <sep> How much does the variance regularization term term contribute to the results?	B-Review	B-3	Review	59
<sep> <sep> Other minor comments:	B-Review	B-4	Review	59
<sep> - The affiliation footnote is on page 2 rather than page 1.	I-Review	I-4	Review	59
<sep> - It would be helpful if the plots in Figure 1 where on the same scale.	I-Review	I-4	Review	59
Many thanks for your review.	O	O	Reply	59
<sep> <sep> The problem with using real datasets such as CelebA for evaluating levels of disentanglement in the learned representation is that since there is not a one-one correspondence between labels and images, evaluation of disentanglement typically has to be done by plotting walks along different axes and visually inspecting the output.	B-Reply	B-1	Reply	59
While there is nothing in principle wrong with this, it makes objective comparison between different algorithms difficult.	I-Reply	I-1	Reply	59
Though we thank you for pointing out that including such plots would improve the paper.	I-Reply	I-1	Reply	59
<sep> <sep> How do results vary with lambda?	O	O	Reply	59
We did not thoroughly investigate the role of lambda (the weighting of the D(P_Z, Q_Z) term) on disentanglement.	B-Reply	B-2	Reply	59
We simply fixed a value for this for which we observed good performance of WAEs on benchmark tasks not related to disentanglement.	I-Reply	I-2	Reply	59
<sep> <sep> We agree that results in the 5-variable sprites seem to be good only for a small set of the parameters we searched over.	B-Reply	B-2	Reply	59
There is still progress to be made, even in this simple problem.	I-Reply	I-2	Reply	59
<sep> <sep> How much does the variance regularization term contribute to the results?	O	O	Reply	59
This is the key to our results.	B-Reply	B-3	Reply	59
We show that tuning this parameters makes the difference between very poor and very good performance.	I-Reply	I-3	Reply	59

The authors explore how well model extraction works on recent BERT-based NLP models.	O	O	Review	20468
The question is: how easy is it for an adversary model to learn to imitate the victim model, only from novel inputs and the corresponding outputs?	O	O	Review	20468
Importantly, the adversary is supposed to not have access to the original training set.	O	O	Review	20468
The authors state that this is problematic because such techniques could be used in order to gain information about (potentially private!)	O	O	Review	20468
training data of the victim model.	O	O	Review	20468
<sep> <sep> In the experiments, two different settings are studied: one where the output probabilities are known and one where only predicted classes (by the victim model) are available.	O	O	Review	20468
In either case, the adversary model achieves high agreement with the victim model.	O	O	Review	20468
One interesting finding is that random queries (i.e., inputs to the victim model) work well, too.	O	O	Review	20468
So, the main conclusion is that the possibility of such attacks is a problem for natural language processing.	O	O	Review	20468
<sep> <sep> Finally, the authors study two methods to help against the problem of potential model extraction: one that helps avoiding it and one that detects model copies.	O	O	Review	20468
<sep> <sep> This paper is technically not very novel, but asks interesting questions.	B-Review	B-1	Review	20468
The methodology seems sound.	O	O	Review	20468
Thank you for the comments.	O	O	Reply	20468
<sep> <sep> &gt;&gt; This paper is technically not very novel, but asks interesting questions.	O	O	Reply	20468
<sep> <sep> We would like to re-emphasize our novel contributions here.	B-Reply	B-1	Reply	20468
<sep> <sep> 1.	I-Reply	I-1	Reply	20468
Our work shows (surprisingly) that model extraction is possible even with nonsensical text --- randomly sampled words concatenated to form sequences (with no human interpretability).	I-Reply	I-1	Reply	20468
Prior work [1] has used random i.i.d noise to extract SVMs and 1-layer neural networks, but we are the first to scale this idea to deep neural networks.	I-Reply	I-1	Reply	20468
More specifically, we extract models based on a large pre-trained language model (BERT), which is a critical component in modern state-of-the-art NLP systems.	I-Reply	I-1	Reply	20468
<sep> <sep> 2.	O	O	Reply	20468
Our paper is among the first studies of model extraction on NLP models.	B-Reply	B-1	Reply	20468
The only prior work studying model extraction in NLP is Pal et al 2019 [2]. Our work has several differences from Pal et al 2019.	I-Reply	I-1	Reply	20468
First, we study large-scale state-of-the-art NLP models based on BERT.	I-Reply	I-1	Reply	20468
In contrast, Pal et al 2019 limited their study to text classifiers based on 1-layer CNNs.	I-Reply	I-1	Reply	20468
Second, we study NLP tasks with complex pairwise input spaces (like question answering and natural language inference).	I-Reply	I-1	Reply	20468
Pal et al 2019 limited their study to single input classification.	I-Reply	I-1	Reply	20468
Pairwise inputs are significantly more challenging since it‚Äôs harder to find naturally occurring text pairs close to the input distribution.	I-Reply	I-1	Reply	20468
Finally, Pal et al 2019 used natural text from Wikipedia as queries.	I-Reply	I-1	Reply	20468
We show extraction is possible even with nonsensical text.	I-Reply	I-1	Reply	20468
<sep> <sep> 3.	B-Reply	B-1	Reply	20468
Finally, we present an extensive analysis of our model extraction setup.	I-Reply	I-1	Reply	20468
Our analysis shows (1) some queries are more representative than others and these can be identified with access to several victim models trained with different random seeds; (2) humans struggle to interpret the nonsensical queries which were used to train our models; (3) language model pre-training is critical for extraction --- publicly available language models are increasing the risk of model extraction; and (4) defense against model extraction is a hard and open problem --- the mitigation strategies we present will only work against a class of naive adversaries who do not adapt to the attacks.	I-Reply	I-1	Reply	20468
<sep> <sep> [1] - Florian Tramer, Fan Zhang, Ari Juels, Michael K Reiter, and Thomas Ristenpart. ‚	O	O	Reply	20468
ÄúStealing machine learning models via prediction apis.	O	O	Reply	20468
‚Äù (USENIX 2016)	O	O	Reply	20468
[2] - Soham Pal, Yash Gupta, Aditya Shukla, Aditya Kanade, Shirish Shevade, and Vinod Ganapathy. "	O	O	Reply	20468
A framework for the extraction of deep neural networks by leveraging public data." (	O	O	Reply	20468
arXiv:1905.09165, 2019)	O	O	Reply	20468

This authors introduce a novel approach to successful modern extraction.	O	O	Review	20468
The paper is well written and easy to follow (the two exceptions/oddities are Figure 1 &amp; Table 1, which appear one page before they are refered, which makes them initially hard to understand because they are out of context).	O	O	Review	20468
The experimental evaluation is both well-thought and convincing.	O	O	Review	20468
<sep> <sep> Given the "unreasonable effectiveness" of the proposed approach, one is left to wonder whether/how it is possible to systematically close the performance gap between the extracted model and the victim one.	B-Review	B-1	Review	20468
Would well formed queries help?	B-Review	B-2	Review	20468
how about random/smartly chosen training examples from the training/tuning set of the victim model?	B-Review	B-3	Review	20468
or anything else?	I-Review	I-3	Review	20468
Thank you for the comments.	O	O	Reply	20468
<sep> <sep> &gt;&gt; how about random/smartly chosen training examples from the training/tuning set of the victim model?	O	O	Reply	20468
<sep> <sep> You are correct that if the attacker had access to the victim‚Äôs training or tuning set, this would help bridge the gap in performance observed in our experiments between the victim and extracted models.	B-Reply	B-3	Reply	20468
However, in our setting we assume the attacker has no access to the training or tuning set of the victim model, which is a more realistic threat model: this makes our attack more widely applicable.	I-Reply	I-3	Reply	20468
<sep> <sep> &gt;&gt; Would well formed queries help?	O	O	Reply	20468
<sep> <sep> In our experiments (Table 2) we do see the WIKI setting is consistently outperforming the RANDOM setting.	B-Reply	B-2	Reply	20468
Our general observation is that proximity between the input query distribution and the victim's training set distribution is a critical factor in determining the success of model extraction attacks.	I-Reply	I-2	Reply	20468
However, in our setting, the attacker does not have access to the victim's training set distribution.	I-Reply	I-2	Reply	20468
Collecting queries close to the victim's distribution might be hard for tasks with complex input spaces (natural language inference, question answering).	I-Reply	I-2	Reply	20468
<sep> In initial experiments (Footnote 2), we did try query-synthesis active learning setups motivated by prior work in model extraction.	I-Reply	I-2	Reply	20468
However, we observed only marginal improvements in extraction performance.	I-Reply	I-2	Reply	20468
A major technical hurdle is the discrete nature of the textual input space.	I-Reply	I-2	Reply	20468
A prior work using pool-based active learning [1] did not work well in settings with complex input spaces (natural language inference, question answering).	I-Reply	I-2	Reply	20468
<sep> <sep> &gt;&gt; how it is possible to systematically close the performance gap between the extracted model and the victim one	O	O	Reply	20468
<sep> From our analysis, the most promising direction to improve model extraction is based on the experiments in Section 5.1 (under "Do different victim models agree on the answers to nonsensical queries?"	B-Reply	B-1	Reply	20468
and "Are high-agreement queries closer to the original data distribution?").	I-Reply	I-1	Reply	20468
Our experiments in Section 5.1 show that the agreement between an ensemble of victim models (trained on the same training set) is a good indicator of a query's closeness to the input distribution.	I-Reply	I-1	Reply	20468
Related to this observation, prior work [2] has shown that an ensemble of classifiers leads to more accurate uncertainty estimates compared to a single overconfident classifier.	I-Reply	I-1	Reply	20468
<sep> <sep> The dominant paradigm in improving model extraction accuracy is active learning, where queries are selected based on the current state of the extracted model.	I-Reply	I-1	Reply	20468
Such model extraction setups typically use the uncertainty of a single extracted model as an objective for query construction.	I-Reply	I-1	Reply	20468
Our observations in 5.1 motivate an alternative objective --- construct queries which have high agreement among an ensemble of victim models and low agreement among an ensemble of extracted models.	I-Reply	I-1	Reply	20468
However, the first term in this objective will need to be approximated in practice since only a single victim model is available to an attacker.	I-Reply	I-1	Reply	20468
<sep> <sep> [1] - Soham Pal, Yash Gupta, Aditya Shukla, Aditya Kanade, Shirish Shevade, and Vinod Ganapathy. "	O	O	Reply	20468
A framework for the extraction of deep neural networks by leveraging public data." (	O	O	Reply	20468
arXiv:1905.09165, 2019)	O	O	Reply	20468
[2] - Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. "	O	O	Reply	20468
Simple and scalable predictive uncertainty estimation using deep ensembles." (	O	O	Reply	20468
NIPS 2017)	O	O	Reply	20468

This paper studies the effectiveness of model extraction techniques on large pretrained language models like BERT.	O	O	Review	20468
The core hypothesis of the paper is that using pretrained language models, and pretrained contextualized embeddings, has made it easier to reconstruct models using model stealing/extraction methods.	O	O	Review	20468
Furthermore, this paper demonstrates that an attacker needn't have access to queries from the training set, and that using random sequences of words as a query to the "victim" model is an effective strategy.	O	O	Review	20468
They authors also show that their model stealing strategies are very cost effective (based on Google Cloud compute cost).	O	O	Review	20468
<sep> <sep> The basic set up of their experiments has a fine-tuned BERT model as the victim model, and a pre-trained BERT model as a the attacker model.	O	O	Review	20468
The attacker model is assumed to not have access to the training set distribution and the queries are randomly generated.	O	O	Review	20468
There are 2 strategies for query generation (with additional task specific heuristics): 1) randomly selecting words from WikiText-103, and 2) randomly selecting sentences or paragraphs from WikiText-103.	O	O	Review	20468
The victim model is passed a generated query and the attacker model is fine-tuned using the output from the victim model.	O	O	Review	20468
Overall, this paper find that this simple strategy for query generation is effective on 4 different datasets: SST2, MNLI, SQuAD 1.1 and BooolQ. The method is also cost-effective, a few hundred dollars depending on the dataset and the number of queries used to train the attacker model.	O	O	Review	20468
<sep> <sep> The paper also present some analysis.	B-Review	B-1	Review	20468
They find that queries with higher agreement across victim models (5 BERTs with different random seeds) also leda to better results for the attacker model.	I-Review	I-1	Review	20468
The authors also run some experiments with humans to test the interpretability of the queries they generated.	I-Review	I-1	Review	20468
They collect annotations on SQuAD using questions that were generated with the WIKI and RANDOM strategies (they also compare highest agreement and lowest agreement queries), and also collect a control with the original SQuAD questions.	I-Review	I-1	Review	20468
While this is an interesting analysis to present, showing that most of the generated queries are nonsensical to humans and there is low inter-annotator agreement, I have an issue with the experimental procedure here: the victim model is fine-tuned on the original data, therefore it has picked up some of the data heuristics used to generate the queries, the annotators are not trained on, or shown any of the original examples (there is a control run, but these are presumably a separate set of annotators).	I-Review	I-1	Review	20468
Through interviews, the authors learn that the annotators were using word overlap heuristics, but perhaps training the annotators on a small set of the original data would draw a closer example to the victim model.	I-Review	I-1	Review	20468
Either way, while this is an interesting result, it seems a bit misplaced in this paper.	I-Review	I-1	Review	20468
I'm not sure this human annotation experiment is contributing in any real way to the core thesis of the paper.	I-Review	I-1	Review	20468
<sep> <sep> The authors also test the results of having a mismatch between the victim and attacker model.	B-Review	B-2	Review	20468
They consider the mismatch of BERT-base and BERT-large models.	I-Review	I-2	Review	20468
They conclude that "attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern."	I-Review	I-2	Review	20468
This conclusion feels like a bit of a stretch.	I-Review	I-2	Review	20468
I would suggest that the authors add another few rows of experiments comparing less similar model architectures.	I-Review	I-2	Review	20468
<sep> <sep> The paper's finding that  a model trained from scratch, QANet on SQuAD, suffers significantly without access to the training set inputs is strong supportive evidence for their hypothesis that using pretrained language models has made model extraction easier.	O	O	Review	20468
<sep> <sep> The authors also present a few defense strategies, membership inference, implicit membership classification, and watermarking.	O	O	Review	20468
They also discuss the limitations of these strategies and do not claim to have solved the problem at hand.	O	O	Review	20468
<sep> <sep> Overall, I think this paper makes a useful  contribution to the field and I would accept this paper.	O	O	Review	20468
While I have a couple of issues with some of the experiments (human evaluation and architecture mismatch), I think this paper is thorough and the experiments are well presented.	O	O	Review	20468
This is the first paper, to the best of my knowledge, showing the efficacy of model extraction of large pretrained language models using rubbish/nonsensical inputs.	O	O	Review	20468
<sep> <sep> Thank you for the detailed summary and comments.	O	O	Reply	20468
<sep> <sep> &gt;&gt; the victim model is fine-tuned on the original data, therefore it has picked up some of the data heuristics used to generate the queries, the annotators are not trained on, or shown any of the original examples (there is a control run, but these are presumably a separate set of annotators)	O	O	Reply	20468
<sep> Yes, the control run used a different set of annotators.	B-Reply	B-1	Reply	20468
We don't believe showing the annotators original SQuAD examples would have made a significant difference due to the following reasons --- 1) while all annotators were unfamiliar with the specifics of our research goals, we chose only NLP/ML graduate students as annotators who had a good understanding of reading comprehension tasks in NLP 2) despite not seeing any original examples, performance on the control experiment is close to the human performance reported in the original SQuAD paper [1]. We obtain an estimate of 85 F1 using the single ground truth answer in the SQuAD training set; the original estimates are 87 F1 on the test set and 91 F1 on the dev set, after using *two ground-truth answers* per example.	I-Reply	I-1	Reply	20468
<sep> <sep> &gt;&gt; "attackers can maximize their accuracy by fine-tuning more powerful language models, and that matching architectures is a secondary concern".	O	O	Reply	20468
I would suggest that the authors add another few rows of experiments comparing less similar model architectures.	O	O	Reply	20468
<sep> <sep> We agree that more experiments are needed to verify this hypothesis.	B-Reply	B-2	Reply	20468
We run experiments on XLNET [2] to reinforce this claim. (	I-Reply	I-2	Reply	20468
Empirically it has been shown that XLNET is a strong language model compared to BERT)	I-Reply	I-2	Reply	20468
<sep> Our preliminary results (below) show that fine-tuning XLNET-large indeed does leads to better model extraction, even with a BERT-large victim model (controlling the number of queries).	I-Reply	I-2	Reply	20468
We will add this along with more experiments in the next version of the paper.	I-Reply	I-2	Reply	20468
<sep> <sep> |-------------------------------------------------------------------------------------------------------------	I-Reply	I-2	Reply	20468
| Extracted Model   Dataset                                                                        Performance	I-Reply	I-2	Reply	20468
|-------------------------------------------------------------------------------------------------------------	I-Reply	I-2	Reply	20468
| BERT-large             original SQuAD                                                            90.6 F1	I-Reply	I-2	Reply	20468
| XLNET-large           original SQuAD                                                            92.8 F1	I-Reply	I-2	Reply	20468
|-------------------------------------------------------------------------------------------------------------	I-Reply	I-2	Reply	20468
| BERT-large             WIKI queries, BERT-large victim's labels               86.1 F1	I-Reply	I-2	Reply	20468
| XLNET-large           WIKI queries, BERT-large victim's labels               89.2 F1	I-Reply	I-2	Reply	20468
|-------------------------------------------------------------------------------------------------------------	I-Reply	I-2	Reply	20468
| BERT-large             RANDOM queries, BERT-large victim's labels       79.1 F1	I-Reply	I-2	Reply	20468
| XLNET-large           RANDOM queries, BERT-large victim's labels       80.9 F1	I-Reply	I-2	Reply	20468
|-------------------------------------------------------------------------------------------------------------	I-Reply	I-2	Reply	20468
<sep> [1] - Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. "	O	O	Reply	20468
Squad: 100,000+ questions for machine comprehension of text." (	O	O	Reply	20468
EMNLP, 2016)	O	O	Reply	20468
[2] - Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, and Quoc V. Le. "	O	O	Reply	20468
XLNet: Generalized Autoregressive Pretraining for Language Understanding." (	O	O	Reply	20468
NeurIPS 2019)	O	O	Reply	20468

<sep> I have mixed feelings about this paper.	O	O	Review	1628
On one hand, it‚Äôs a thorough and well-written experimental paper, something which is really important but is also clearly underappreciated in the machine learning community.	O	O	Review	1628
On the other, it was not really obvious to me why some of objectives tested here are interesting: LM objectives like ELMo have seen a lot of uptake in the NLP community (and this is definitely an NLP paper), but most of the others‚Äîlike skip-thought, MT, and autoencoders‚Äîhave not.	B-Review	B-1	Review	1628
So the basic research question doesn‚Äôt seem like an especially burning one.	I-Review	I-1	Review	1628
The trends in Fig.2 show that these alternatives underperform an LM objective, which suggests that the NLP community can keep using that objective without worry‚Äîand everything else in the figure seems as we would expect.	O	O	Review	1628
<sep> <sep> In short, I think the paper is a well-done study on a hypothesis of perhaps minor interest.	B-Review	B-2	Review	1628
The results are sensible but confirm what we already strongly suspected, and they seem unlikely to strongly influence other research, since they confirm that everyone has been the right thing all along.	I-Review	I-2	Review	1628
I‚Äôm not entirely sure what I learned from this.	I-Review	I-2	Review	1628
<sep> <sep> To me, the most interesting experiment is the final one in Section 6.	O	O	Review	1628
This experiment seems like it could be the germ for a far more interesting paper getting at how these pretraining objectives help with downstream tasks.	O	O	Review	1628
As it stands, it feels like an interesting nugget tacked on to an otherwise complete (and much less interesting) paper.	O	O	Review	1628
<sep> <sep> Presentational comments:	O	O	Review	1628
<sep> Fig.1: really nitpicky, but the typography of the POS tags and CCG categories is all wrong.	B-Review	B-3	Review	1628
These aren‚Äôt mathematical symbols!	I-Review	I-3	Review	1628
<sep> <sep> Fig 2.	B-Review	B-4	Review	1628
Slightly confused why these are broken up into two separate plots.	I-Review	I-4	Review	1628
<sep> <sep> Fig 4.	B-Review	B-5	Review	1628
is hard to read due to the lurid colors and patterns, which require a lot of cross-referencing with the legend.	I-Review	I-5	Review	1628
I wonder if this would be better as simply a table.	I-Review	I-5	Review	1628
I also found it very confusing at first since the y-axes are out of sync between the two figures‚Äîinitially it looked as if the legend was overlaid on a set of bars in the left figure that had the same baseline as the right figure.	I-Review	I-5	Review	1628
<sep> <sep> Our contribution is a thorough examination of several different pretraining tasks, controlling for the domain, amount of data, and training procedure.	B-Reply	B-2	Reply	1628
When CoVe was released at NIPS last year, it achieved SoTA numbers on several prominent NLP tasks.	I-Reply	I-2	Reply	1628
Although ELMo compares to CoVe in their paper and outperforms CoVe, since CoVe was trained on WMT English-German and ELMo was trained on the One Billion Word Benchmark, it was unclear if the performance gain of ELMo was primarily due to the increased amount of training data.	I-Reply	I-2	Reply	1628
Moreover, without a direct comparison we can‚Äôt even be sure that language modeling is better because ELMo could have just been more carefully tuned.	I-Reply	I-2	Reply	1628
Our finding that language modeling, an unsupervised task, outperformed translation models trained on the *same* data is still surprising because the translation models are given the source sentence in a different language and thus have strictly more information than language models.	I-Reply	I-2	Reply	1628
We also agree that the results of our analysis of the randomly-initialized encoder in Section 6 are surprising, and could form the basis for a larger study.	I-Reply	I-2	Reply	1628
<sep> <sep> Fig 1: You are right.	B-Reply	B-3	Reply	1628
We just fixed the typography in our most recent revision.	I-Reply	I-3	Reply	1628
<sep> <sep> Fig 2: The upper plot is for POS tagging and the bottom for CCG supertagging.	B-Reply	B-4	Reply	1628
Each of those plots are then split into three columns corresponding to different amounts of classifier training data.	I-Reply	I-4	Reply	1628
Each column has two plots because when we tried plotting all ten lines into one figure it was difficult to read, so we split up the models into two groups: models with attention (plus BiLMs) and models without attention (plus forward LM).	I-Reply	I-4	Reply	1628
We welcome further suggestions for improving our presentation.	I-Reply	I-4	Reply	1628
<sep> <sep> Fig 4: We included the patterns and bright colors in order to make it easier for the visually impaired to read.	B-Reply	B-5	Reply	1628

This paper tests various pretraining objectives (language modeling, machine translation, skip-thought, and autoencoding) on two syntactic tasks: POS tagging and CCG tagging.	O	O	Review	1628
It finds that language modeling outperforms the other pretraining objectives; additionally, randomly-initializing an encoder achieves decent performance when given a large amount of labeled data for the tagging task.	O	O	Review	1628
The experiments in this paper are very thorough and explained well.	O	O	Review	1628
By controlling for pretraining data size, the authors are able to reasonably claim that language modeling is superior to translation as a syntactic transfer learning task.	B-Review	B-1	Review	1628
On the other hand, I have some concerns regarding the significance of the paper's contributions, and as such I am borderline on its acceptance.	I-Review	I-1	Review	1628
<sep> <sep> comments:	O	O	Review	1628
- the experiments in the paper feel biased towards language modeling.	B-Review	B-2	Review	1628
Language modeling is the only token-level prediction task of the four objectives here, but both of the two downstream tasks are at the token level.	I-Review	I-2	Review	1628
It is perhaps unsurprising then that language modeling performs best; perhaps the authors could have considered some sentence-level downstream tasks as well to properly control for this?	I-Review	I-2	Review	1628
Or added some more word-level pretraining objectives?	I-Review	I-2	Review	1628
<sep> <sep> - sort of relatedly, the authors do not provide any explanations as to *why* language modeling is a better pretraining objective than translation.	B-Review	B-3	Review	1628
What kinds of examples do the tagging models using LM pretraining get right that the translation models do not?	I-Review	I-3	Review	1628
Such an analysis could help provide more concrete insights into what kind of information each objective is encoding.	I-Review	I-3	Review	1628
<sep> <sep> - the claim that LMs > translation is not a new finding.	B-Review	B-4	Review	1628
The authors cite Blevins et al, who find the same result on the task of dependency arc prediction.	I-Review	I-4	Review	1628
Similarly, the surprisingly good performance of random encoders was also found in Conneau et al ACL 2018.	I-Review	I-4	Review	1628
As the main contribution of this paper seems to be a more controlled study of Blevins et al on different syntactic tasks, I don't think there is enough here for an ICLR submission.	I-Review	I-4	Review	1628
<sep> <sep> - what is the effect of the specific dataset and architecture on the results?	B-Review	B-5	Review	1628
Here we just look at a couple translation datasets (all news data) and LSTM models.	I-Review	I-5	Review	1628
Do things change when we move to transformers or more diverse domains?	I-Review	I-5	Review	1628
- All the tasks use the same training data.	B-Reply	B-5	Reply	1628
The data each model is trained on was pre-processed in the same way, word-level tokenization.	I-Reply	I-5	Reply	1628
All the training objectives we compare all have the same loss: average negative log likelihood of the target sequence	I-Reply	I-5	Reply	1628

This is nicely written paper analyzing the effect of various pre-training methods and shows that language models are very effective on sequence tagging tasks (POS, CCG).	O	O	Review	1628
The experiments are well motivated and well described.	O	O	Review	1628
<sep> <sep> Regarding Table 1: which one of the "LM forward" models was used in the subsequent experiments?	B-Review	B-1	Review	1628
<sep> <sep> Are the input embeddings for the random init LSTM pre-trained or are they also randomly initialized?	B-Review	B-2	Review	1628
Thank you!	O	O	Reply	1628
<sep> <sep> We used both ‚ÄúLM Forward‚Äù models - the larger forward LM we examined on its own and the small forward LM was combined with the small backward LM into the bidirectional LM.	B-Reply	B-1	Reply	1628
<sep> <sep> The input embeddings for the randomly initialized LSTMs are also randomly initialized.	B-Reply	B-2	Reply	1628
<sep> <sep> Let us know if you have further feedback!	O	O	Reply	1628

The authors find 2 issues with Adversarial Imitation Learning-style algorithms: I) implicit bias in the reward functions and II) despite abilities of coping with little data, high interaction with the environment is required.	O	O	Review	317
The authors suggest "Discriminator-Actor-Critic" - an off-policy Reinforcement Learning reducing complexity up to 10 and being unbiased, hence very flexible.	O	O	Review	317
Several standard tasks, a robotic, and a VR task are used to show-case the effectiveness by a working implementation in TensorFlow Eager.	O	O	Review	317
The paper is well written, and there is practically no criticism.	O	O	Review	317
We thank the reviewer for the feedback and appreciate the strong recommendation.	O	O	Reply	317

The paper suggests to use TD3 to compute an off-policy update instead of the TRPO/PPO updates in GAIL/AIRL in order to increase sample efficiency.	O	O	Review	317
<sep> The paper further discusses the problem of implicit step penalties and survival bias caused by absorbing states, when using the upper-bounded/lower-bounded reward functions log(D) and -(1-log(D)) respectively.	O	O	Review	317
To tackle these problem, the paper proposes to explicit add a unique absorbing state at the end of each trajectory, such that its rewards can be learned as well.	O	O	Review	317
<sep> <sep> Pro:	O	O	Review	317
The paper is well written and clearly presented.	O	O	Review	317
<sep> <sep> Using a more sample efficient RL method for the policy update is sensible and turned out effective in the experiments.	O	O	Review	317
<sep> <sep> Properly handling simulator resets in MDPs is a well known problem in reinforcement learning that I think is insufficiently discussed in the context of IRL.	B-Review	B-11	Review	317
<sep> <sep> <sep> Cons:	O	O	Review	317
The contributions seem rather small.	O	O	Review	317
<sep> a) Replacing the policy update is trivial, since the rl methods are used as black-box modules for the discussed AIL methods.	B-Review	B-1	Review	317
<sep> <sep> b) Using importance weighting to reuse old trajectories for the discriminator update hardly counts as a contribution either--especially when the importance weights are simply omitted in practice.	B-Review	B-2	Review	317
I also think that the reported problems due to the high variance have not been sufficiently investigated.	I-Review	I-2	Review	317
There should be a better solution than just pretending that the replay buffer corresponds to roll-outs of the current policy.	I-Review	I-2	Review	317
Would it maybe help to use self-normalized importance weights?	I-Review	I-2	Review	317
The paper does also not analyze how such assumption/approximation affects the theoretical guarantees.	I-Review	I-2	Review	317
<sep> <sep> c) The problem with absorbing states is in my opinion the most interesting contribution of the paper.	O	O	Review	317
However, the discussion is rather shallow and I do not think that the illustrative example is very convincing.	B-Review	B-3	Review	317
Section 4.1.1.	I-Review	I-3	Review	317
argues that for the given policy roll-out, the discriminator reward puts more reward on the policy trajectory than the expert trajectory.	I-Review	I-3	Review	317
However, it is neither surprising nor problematic that the discriminator reward does not produce the desired behavior during learning.	I-Review	I-3	Review	317
By assigning more cumulative reward for s2_a1->s1 than for s2_a2->g, the policy would (after a few more updates) choose the latter action much less frequently than with probability 0.5 and the corresponding reward would grow towards infinity until at some point Q(s2,a2) > Q(s2,a1)--when the policy would match the expert exactly.	I-Review	I-3	Review	317
The illustrative example also uses more policy-labeled transitions than agent-labeled ones for learning the classifier, which may also be problematic.	I-Review	I-3	Review	317
The paper further argues that a strictly positive reward function always rewards a policy for avoiding absorbing states, which I think is not true in general.	I-Review	I-3	Review	317
A strictly positive reward function can still produce arbitrary large reward for any action that reaches an absorbing state.	I-Review	I-3	Review	317
Hence, the immediate reward for choosing such action can be made larger than the discounted future reward when not ending the episode (for any gamma < 1).	I-Review	I-3	Review	317
Even for state-only reward functions the problem does not persist when reseting the environment after reaching the absorbing state such that the training trajectories contain states that are only reached if the simulator gets reset.	I-Review	I-3	Review	317
Hence, I am not convinced that adding a special absorbing state to the trajectory is necessary if the simulation reset is correctly implemented.	I-Review	I-3	Review	317
This may be different for resets due to time limits that can not be predicted by the last state-action tuple.	I-Review	I-3	Review	317
However, issues relating to time limits are not addressed in the paper.	I-Review	I-3	Review	317
I also think that it is strange that the direct way of computing the return for the terminal state is much less stable than recursively computing it and think that the paper should include a convincing explanation.	I-Review	I-3	Review	317
<sep> <sep> ---------------	O	O	Review	317
Update 21.11.2018	O	O	Review	317
<sep> I think my initial assessment was too positive.	B-Review	B-4	Review	317
During the rebuttal, I noticed that the discussion of reward bias was not only shallow but also wrong in some aspects and very misleading, because problems arising from hacky implementations of some RL toolboxes were discussed as theoretical shortcoming of AIL algorithms.	I-Review	I-4	Review	317
Hence, I think the initial submission should be clearly rejected.	I-Review	I-4	Review	317
However, the authors submitted a revised version that presents the root of the observed problem much more accurately.	I-Review	I-4	Review	317
I think that the revised version is substantially better than the original submission.	I-Review	I-4	Review	317
However, I think that my initial rating is still valid (better: became valid), because the main issues that I raised for the initial submission still apply to the current revision, namely:	O	O	Review	317
- The technical contributions are minor.	B-Review	B-1	Review	317
<sep> - The theoretical discussion (in particular regarding absorbing states) is quite shallow.	B-Review	B-3	Review	317
<sep> <sep> The merits of the paper are:	O	O	Review	317
- Good results due to off-policy learning	O	O	Review	317
- Raising awareness and providing a fix for a common pitfall	O	O	Review	317
<sep> I think that the problems arising from incorrectly treated absorbing states needs to be discussed more profoundly.	B-Review	B-3	Review	317
<sep> Some suggestions:	O	O	Review	317
<sep> Section 3.1	O	O	Review	317
"As we discuss in detail in Section 4.2 [...]"	B-Review	B-5	Review	317
I think this should refer to section 4.1.	I-Review	I-5	Review	317
Also the discussion should in section 4.1 should be a bit more detailed.	I-Review	I-5	Review	317
How do common implementations implicitly assign zero rewards?	B-Review	B-10	Review	317
Which implementations are affected?	I-Review	I-10	Review	317
Which papers published inferior results due to this bug?	I-Review	I-10	Review	317
I think it is also important to note, that absorbing states are hidden from the algorithm and that the reward function is thus only applied to non-absorbing states.	I-Review	I-10	Review	317
<sep> <sep> "We will demonstrate empirically in Section 4.1 [...]"	B-Review	B-6	Review	317
The demonstration is currently missing.	I-Review	I-6	Review	317
I think it would be nice to illustrate the problem on a simple example.	I-Review	I-6	Review	317
The original example might actually work, as shown by the code example of the rebuttal, however the explanation was not convincing.	I-Review	I-6	Review	317
Maybe it would be easier to argue with a simpler algorithm (e.g MaxEnt-IRL, potentially projecting the rewards to positive values)?	I-Review	I-6	Review	317
<sep> <sep> Section 3.1 seems to focus too much on resets that are caused by time limits.	B-Review	B-7	Review	317
Such resets are inherently different from terminal states such as falling down in locomotion tasks, because they can not be modelled with the given MDP formulation unless time is considered part of the state.	I-Review	I-7	Review	317
Indeed, I think that for infinite horizon MDPs without time-awareness, time limits can not be modelled using absorbing states (I think the RL book misses to mention that time needs to be part of the state such that the policy remains Markovian, which is a bit misleading).	I-Review	I-7	Review	317
Instead those resets are often handled by returning an estimate of the future return (bootstrapping).	I-Review	I-7	Review	317
This treatment of time limits is already part of the TD3 implementation and as far as I understood not the focus of the paper.	I-Review	I-7	Review	317
Instead section 3.1.	I-Review	I-7	Review	317
should focus on resets caused by task failure/completion, which can actually be modelled with absorbing states, because the agent will always transition to the absorbing state when a terminal state is reached which is in line with Markovian dynamics.	I-Review	I-7	Review	317
<sep> <sep> Section 4.2 should also add a few more details.	B-Review	B-8	Review	317
Did I understand correctly, that when computing the return R_T the sum is indeed finite and stopped after a fixed horizon?	I-Review	I-8	Review	317
If yes, this should be reflected in the equation, and the horizon should be mentioned in the paper.	I-Review	I-8	Review	317
The paper should also better explain how  the proposed fix enables the algorithm to learn the reward of the absorbing state.	I-Review	I-8	Review	317
For example, section 4.2.	I-Review	I-8	Review	317
does not even mention that the state s_a was added as part of the solution.	I-Review	I-8	Review	317
<sep> <sep> <sep> -------------	O	O	Review	317
Update 22.11.2018	O	O	Review	317
By highlighting the difference between termination due to time-limits and termination due to task completion, and by better describing how the proposed fix addresses the problem of reward bias that is present in common AIL implementations, the newest revision further improves the submission.	O	O	Review	317
<sep> I think that the submission can get accepted and I adapted my rating accordingly.	O	O	Review	317
<sep> <sep> Minor:	B-Review	B-9	Review	317
Conclusion should also squeeze in somehow that the reward biases are caused by the implementations.	I-Review	I-9	Review	317
<sep> Typo in 4.2: "Thus, when sample[sic] from the replay buffer AIL algorithms will be able to see absorbing states there[sic]	I-Review	I-9	Review	317
were previous hidden, [...]"	I-Review	I-9	Review	317
<sep> We again would like to emphasize that we appreciate your patience and valuable feedback that helps us to improve our submission.	O	O	Reply	317
<sep> <sep> We have updated the paper to try to address your suggestions.	O	O	Reply	317
In particular:	O	O	Reply	317
<sep> 1) As per your suggestion, we extended the last paragraph of Section 3.1 in order to clarify our discussion on episode termination because of time limits.	B-Reply	B-7	Reply	317
We believe that it adds clarity to the paper because it discusses  termination  states in more detail.	I-Reply	I-7	Reply	317
It also  explains the difference between absorbing states and rollout breaks.	I-Reply	I-7	Reply	317
For a detailed discussion on implementation specific biases in algorithms (GAIL/AIRL) please refer section 4.1.	I-Reply	I-7	Reply	317
<sep> <sep> 2) In Section 4.1, we enumerate  papers affected by this problem, with specific instances.	B-Reply	B-10	Reply	317
For each paper that we cite in this section, we consider the official implementations provided by the authors.	I-Reply	I-10	Reply	317
In the same section, we further elaborate on how exactly these algorithms  are affected by the issue.	I-Reply	I-10	Reply	317
<sep> <sep> 3) In section 4.2, we assume infinite horizon for R_T since the series converges ( assuming reward bounded by r_max, the series is bounded by gamma/(1-gamma) r_max and thus can be computed either analytically or will converge in the limit using TD updates, section 3.1 now also includes a clarification of this point).	B-Reply	B-8	Reply	317
We also extended Section 4.2 to clarify how absorbing states can be used by the AIL algorithms and how the corresponding transitions affect estimations of returns.	I-Reply	I-8	Reply	317
Please see the second paragraph of Section 4.2.	I-Reply	I-8	Reply	317
<sep> <sep> 4) Regarding revisiting the illustrative example, we agree that the same reasoning might apply to Inverse RL algorithms in general and we appreciate your suggestion regarding the analysis of this simple example for MaxEnt-IRL.	B-Reply	B-6	Reply	317
We unfortunately will not be able to add such an experiment before the end of the revision period, but we have added some discussion in Section 4 that the basic principle applies also to other IRL methods.	I-Reply	I-6	Reply	317
This can be considered as an interesting direction of future work.	I-Reply	I-6	Reply	317
e will attempt to add a better illustrative example in the final version (we just have not had time to do so), and will make sure to update the reviewers about it.	I-Reply	I-6	Reply	317
<sep> <sep> 5) We fixed the wrongly referenced section.	B-Reply	B-5	Reply	317
Thanks for catching this.	I-Reply	I-5	Reply	317
<sep> <sep> We hope that this revision of our submission will address your concerns.	O	O	Reply	317

This paper investigates two issues regarding Adversarial Imitation Learning.	O	O	Review	317
They identify a bias in commonly used reward functions and provide a solution to this.	O	O	Review	317
Furthermore they suggest to improve sample efficiency by introducing a off-policy algorithm dubbed "Discriminator-Actor-Critic".	O	O	Review	317
They key point here being that they propose a replay buffer to sample transitions from.	O	O	Review	317
<sep> <sep> It is well written and easy to follow.	O	O	Review	317
The authors are able to position their work well into the existing literature and pointing the differences out.	O	O	Review	317
<sep> <sep> Pros:	O	O	Review	317
<tab>* Well written	O	O	Review	317
<tab>* Motivation is clear	O	O	Review	317
<tab>* Example on biased reward functions	O	O	Review	317
<tab>* Experiments are carefully designed and thorough	O	O	Review	317
Cons:	O	O	Review	317
<tab>* The analysis of the results in section 5.1 is a bit short	B-Review	B-1	Review	317
<sep> Questions:	O	O	Review	317
<tab>* You provide a pseudo code of you method in the appendix where you give the loss function.	B-Review	B-2	Review	317
I assume this corresponds to Eq.2.	I-Review	I-2	Review	317
Did you omit the entropy penalty or did you not use that termin during learning?	I-Review	I-2	Review	317
<sep> <sep> <tab>* What's the point of plotting the reward of a random policy?	B-Review	B-3	Review	317
It seems your using it as a lower bound making it zero.	I-Review	I-3	Review	317
I think it would benefit the plots if you just mention it instead of plotting the line and having an extra legend	I-Review	I-3	Review	317
<sep> <tab>* In Fig.4 you show results for DAC, TRPO, and PPO for the HalfCheetah environment in 25M steps.	B-Review	B-4	Review	317
Could you also provide this for the remaining environments?	I-Review	I-4	Review	317
<sep> <sep> <tab>* Is it possible to show results of the effect of absorbing states on the Mujoco environments?	B-Review	B-5	Review	317
<sep> <sep> Minor suggestions:	O	O	Review	317
In Eq. (1) it is not clear what is meant by pi_E. From context we can assume that E stands for expert policy.	B-Review	B-6	Review	317
Maybe add that.	I-Review	I-6	Review	317
Figures 1 and 2 are not referenced in the text and their respective caption is very short.	I-Review	I-6	Review	317
Please reference them accordingly and maybe add a bit of information.	I-Review	I-6	Review	317
In section 4.1.1 you reference figure 4.1 but i think your talking about figure 3.	I-Review	I-6	Review	317
We thank the reviewer for the positive and constructive feedback.	O	O	Reply	317
<sep> <sep> We have extended the section 5.1 of the manuscript as suggested by the reviewer.	B-Reply	B-1	Reply	317
<sep> <sep> Below are detailed answers for the reviewer‚Äôs concerns:	O	O	Reply	317
<sep> 1) To simplify the exposition we omitted the entropy penalty as it does not contribute meaningfully to the algorithm performance in our experimentation.	B-Reply	B-2	Reply	317
Similar findings were observed in the GAIL paper, where the authors disregarded the entropy coefficient for every tested environment, except for the Reacher environment.	I-Reply	I-2	Reply	317
<sep> <sep> 2) We added the performance of a random policy to the graph to be consistent with the original GAIL paper.	B-Reply	B-3	Reply	317
We believe that it improves readability of the plot by providing necessary scaling.	I-Reply	I-3	Reply	317
<sep> <sep> 3) We already started working on additional experimentation as requested.	B-Reply	B-4	Reply	317
We will update the manuscript as soon as we gather these results.	I-Reply	I-4	Reply	317
<sep> <sep> 4) We observed the same effect of having absorbing states in the Kuka arm tasks (Fig.6), as in the MuJoCo environments.	B-Reply	B-5	Reply	317
Also, we evaluated absorbing states within the AIRL framework for Walker-2D and Hopper environments (Fig.7).	I-Reply	I-5	Reply	317
We demonstrate that proper handling of absorbing states is critical for effectively imitating the expert policy.	I-Reply	I-5	Reply	317
<sep> <sep> In addition, we updated the paper to accommodate the minor suggestions proposed by the reviewer.	O	O	Reply	317

I started reading the paper with high hopes.	O	O	Review	317
The abstract and the introduction were set up nicely and I was quite intrigued to see a theoretical analysis and practical implementation of a neural network using analogue hardware.	B-Review	B-1	Review	317
However, as I read through the paper carefully multiple times, I realized that the expository opening description fails to live up to the standard it sets.	I-Review	I-1	Review	317
<sep> <sep> To be more specific, I did not enjoy the elaborate description of noisy analogue conductances as the noise models analyzed in the paper are not tested on any of such devices.	B-Review	B-2	Review	317
The noise model introduced is fairly simplistic and arguably, the real-world systems are much more complex compared to such simplistic assumptions.	I-Review	I-2	Review	317
The authors could have presented the paper as an analysis of knowledge distillation in neural network training.	I-Review	I-2	Review	317
Even if the paper were presented that way, I would have doubted its chance of acceptance due to the incrementality of the theoretical contribution.	I-Review	I-2	Review	317
<sep> <sep> All in all, I believe this is a very promising direction to invest, but the paper is not quite ready for ICLR.	O	O	Review	317
Many thanks for taking the time to review our paper and the constructive comments.	O	O	Reply	317
<sep> <sep> - Q1 Noise models	O	O	Reply	317
We believe that the simple Gaussian noise model used in the paper is a good approach to modeling real analog hardware systems, which has been confirmed previously in "Accurate deep neural network inference using computational phase-change memory"(<a href="https://arxiv.org/abs/1906.03138)" target="_blank" rel="nofollow">https://arxiv.org/abs/1906.03138)</a>  by Joshi et al Their experiments show (Fig 3c in Joshi et al) that very similar measured accuracy can be achieved when weights trained with the Gaussian noise model are transferred to the actual hardware.	B-Reply	B-2	Reply	317
And in fact, we are already considering modeling of key circuit blocks such as digital-to-analog and analog-to-digital converters within our formulation of weight and activation quantization, which we've emphasized in Section 3, paragraph 2.	I-Reply	I-2	Reply	317
<sep> <sep> We have also expanded the results by adding experiments with time-varying (temperature fluctuation) and spatially-varying (manufacturing process variation) noise models in Table 1 of Section 5.2 to broaden this aspect of the work.	I-Reply	I-2	Reply	317
In summary, we have found no significant deviation in these new experiments.	I-Reply	I-2	Reply	317
The improvement from our proposed retraining method is quite consistent.	I-Reply	I-2	Reply	317
<sep> <sep> - Q2 Practical implementation	O	O	Reply	317
Sadly, there is currently no publicly available hardware to test our models on.	B-Reply	B-1	Reply	317
Instead of waiting for practical analog hardware to become available, we think that research in the ML community can advance the practicality of analog neural networks.	I-Reply	I-1	Reply	317
We've also noticed that this topic falls between the ML and hardware communities, but think that the ML community can contribute significantly in this area.	I-Reply	I-1	Reply	317
As other reviewers have remarked, this is a new area for the ML community and many are probably unaware of the interesting ML challenges posed by analog neural networks.	I-Reply	I-1	Reply	317
We hope to motivate other ML work in this direction.	I-Reply	I-1	Reply	317
Analog deep learning hardware is a complex system level challenge and requires a system level solution.	I-Reply	I-1	Reply	317
We don't claim to solve all the challenges in this one paper but rather we have carved out a well-defined ML problem from the broader challenge and presented a novel solution to it, we hope this paper can be a first step in building understanding and interest in the topic amongst the broader ML community.	I-Reply	I-1	Reply	317

The manuscript illustrates how a noisy neural network can reduce the learning capacity.	O	O	Review	317
To mitigate this loss, the authors propose a method that combines the method of "noise injection and "knowledge distillation".	O	O	Review	317
However, from a conceptual point of view,  their contribution (i.e. (10) in Section 5,) is unclear to me.	B-Review	B-1	Review	317
Specifically,  the authors are not precise about how do they merge the aforementioned previous ideas and come up with the new loss function (10).	I-Review	I-1	Review	317
<sep> <sep> Minor comment: Please correct (7).	B-Review	B-2	Review	317
<sep> <sep> <sep> <sep> Many thanks for taking the time to review our paper.	O	O	Reply	317
<sep> <sep> We note that, in the reviewer's own words, this review should be considered a "quick assessment".	O	O	Reply	317
<sep> <sep> Regarding (10), (10) is the usual loss function for distillation.	B-Reply	B-1	Reply	317
The novelty of our work is in combining knowledge distillation and noise injection as other reviewers have remarked.	I-Reply	I-1	Reply	317
We have included a schematic of our retraining method in Figure 5 of the Appendix to make things more clear.	I-Reply	I-1	Reply	317
<sep> <sep> Thanks for catching the typo in (7), we have corrected it.	B-Reply	B-2	Reply	317

The authors of the manuscript study how inherent noise in the analog neural networks affects its accuracy.	O	O	Review	317
This is a very important topic as neural network based inference becomes uobiqutous and is required to run with very low power consumption and latency.	O	O	Review	317
<sep> <sep> The manuscipt considers a system where the values of the neural network weights and biases are experiencing i.i.d Gaussian noise, which is a pretty good assumptions.	O	O	Review	317
However, in heavy use the system may warm up, and then there could be an effect that is correlated accross different weights.	B-Review	B-1	Review	317
The noise model used would not be able to ensure proper inference in these conditions.	I-Review	I-1	Review	317
I would like to see a discussion on the effect of correlations in the injected noise.	I-Review	I-1	Review	317
<sep> <sep> The mutual information is considered and evaluated for a the "noisy" and "clean" versions and the result is according to expectations.	B-Review	B-2	Review	317
The some degree, I do not see this part very valuable, as it does not bring any particular insights on the analog neural network operation.	I-Review	I-2	Review	317
Rather I woudl like to see how, the analog performance under noise scales as the neural has  more layers.	I-Review	I-2	Review	317
Also, the noise behavior of an analog RNN woudl be very interesting.	I-Review	I-2	Review	317
<sep> <sep> The authors have detected that even, if the neural network trainded without noise is not robust when the weigths fluctuate, the trained network is a good starting point for transfer learning.	B-Review	B-3	Review	317
To some degree I do not find this to be a very inventive step as transfer learning has shown to able to cross much larger training data set alterations.	I-Review	I-3	Review	317
<sep> <sep> Good solid work, but lacking non-obvious results, and I do not see manuscript adressing the the harder challenges.	B-Review	B-4	Review	317
However, the quantified results may have a notable practical importance.	O	O	Review	317
<sep> <sep> <sep> <sep> Author Response:	O	O	Reply	317
<sep> Many thanks for taking the time to review our paper and the constructive comments.	O	O	Reply	317
We've added additional experimental results and reworked the relevant sections of the paper in response to the reviewer feedback.	O	O	Reply	317
<sep> <sep> - Q1 Correlated noise models	O	O	Reply	317
The question of changes in the noise model as the system warms up is a good one and another reviewer was also interested in this.	B-Reply	B-1	Reply	317
It is our understanding that system warming up is less likely to result in statistical correlation between weight noise but rather spatially inhomogeneous noise levels.	I-Reply	I-1	Reply	317
For example, if the center of an analog chip heats up more than its edges, the NVM cells at the center may have a higher noise level than the ones close to the edges.	I-Reply	I-1	Reply	317
<sep> <sep> We have expanded the discussion of these non-idealities in Section 3, and we have also expanded the results in this regard by adding experiments with time-varying (temperature or supply voltage fluctuation) and spatially-varying (manufacturing process variation or temperature inhomogeneity due to warming up) noise models in Table 1 of Section 5.2 to broaden this aspect of the work.	I-Reply	I-1	Reply	317
The spatially-varying noise model is effective non i.i.d.	I-Reply	I-1	Reply	317
<sep> <sep> In summary, we have found no significant deviation in these new experiments.	I-Reply	I-1	Reply	317
The improvement from our proposed retraining method remains quite consistent.	I-Reply	I-1	Reply	317
Nonetheless, we would like to thank the reviewer for suggesting these experiments which have strengthened the results of our paper.	I-Reply	I-1	Reply	317
<sep> <sep> - Q2 Analog performance scaling with network depth	O	O	Reply	317
We also thought this was interesting and, again, another reviewer (#1) asked about this too.	B-Reply	B-2	Reply	317
<sep> Following the reviewer's suggestion, we have added further experiments in Section 4.2 (Figure 2) to better understand the mutual information / model accuracy decay over both wider and deeper neural network architectures.	I-Reply	I-2	Reply	317
We have also added more results in the Appendix (Figure 6) showing how our method compares to pure noise injection on different network architectures.	I-Reply	I-2	Reply	317
We're grateful for the feedback, as these additional experiments have increased our understanding of the impact of analog noise on neural network performance.	I-Reply	I-2	Reply	317
<sep> We are also interested in the performance of analog RNNs, but we feel this is beyond the scope of this paper, but we are planning to look at this for future work.	I-Reply	I-2	Reply	317
<sep> <sep> - Q3 Lacking non-obvious results	O	O	Reply	317
Finally, regarding non-obvious results, we think that this paper is a first step in starting to understand the behavior of analog neural networks.	B-Reply	B-4	Reply	317
As other reviewers have remarked, this is a new area for the ML community, and we think that many are probably not aware of the interest around analog hardware for neural networks.	I-Reply	I-4	Reply	317
Therefore, this paper serves an important role, not only in introducing the ML community to the challenges of designing and training models that are robust to analog noise, but at the same time outlining an approach that achieves state-of-the-art results.	I-Reply	I-4	Reply	317
Additionally, our retraining approach of combining noise injection and distillation is indeed novel as other reviewers have remarked.	I-Reply	I-4	Reply	317
We have also broadened the experiments around the noise model, providing results to support our choice of noise modeling.	I-Reply	I-4	Reply	317
We believe this line of work could really make deployment of analog neural network hardware possible and hope to motivate other ML work in this direction.	I-Reply	I-4	Reply	317
In that regard, we hope this paper can be a first step in building understanding and interest in the topic amongst the broader ML community.	I-Reply	I-4	Reply	317

* Summary *	O	O	Review	317
The article on "Noisy Machines" addresses the issue of implementing deep neural network inference on a noisy hardware computing substrate, e.g. analog accelerators.	O	O	Review	317
This is an important topic because analog devices allow fast and energy efficient inference, which is crucial for inference at the edge.	O	O	Review	317
Because of their analog nature such devices suffer from noisy computations, and in this article the case of noisy weights is studied.	O	O	Review	317
<sep> <sep> The main contributions of this article are the following:	O	O	Review	317
- an analysis of the performance loss in noisy networks by means of information theory and empirical results	O	O	Review	317
- the idea of combining noise injection during training with knowledge distillation	O	O	Review	317
- experimental evidence for a LeNet5 on MNIST, CIFAR10, and ResNet-50 on ImageNet	O	O	Review	317
<sep> It has been shown in the literature that noise injection during training is an effective way to increase the noise robustness of neural networks.	O	O	Review	317
Relevant literature in this domain is cited.	O	O	Review	317
The novelty of the approach is to combine noise injection with distillation, by using the noise-free network as a teacher for the noisy network, which is initialized with the weights of the teacher.	O	O	Review	317
This is a novel variant of distillation and sounds like a simple to implement trick with beneficial results for increasing noise resiliency of networks.	O	O	Review	317
It is also proposed and shown that the method works for quantized networks.	O	O	Review	317
<sep> <sep> The experimental results show that the combination of distillation and noise injection outperforms pure noise injection on all networks, as well as noisy inference without retraining.	O	O	Review	317
The effect is even more pronounced for quantized networks.	O	O	Review	317
<sep> <sep> * Evaluation *	O	O	Review	317
Overall I like this paper and think it is suitable to accept for ICLR, because it addresses an important practical problem of implementing deep networks on efficient hardware.	O	O	Review	317
The paper is well written and simple to understand and should be easy to implement (it would really help here providing code for the examples though).	O	O	Review	317
To the best of my knowledge I have not seen precisely this combination of noise injection and distillation, although there is a lot of literature about each individual approach.	O	O	Review	317
I appreciate that the authors made an effort to not just show empirical results but also motivate their findings by theory, although the argumentation stays a bit superficial.	O	O	Review	317
<sep> <sep> What I am mainly missing are two points:	O	O	Review	317
1.	O	O	Review	317
The assumed noise model of i.i.	B-Review	B-1	Review	317
D. Gaussian weights is the simplest possible, and might deviate quite a bit in actual analog hardware.	I-Review	I-1	Review	317
I would have liked to see a noise model that is derived from actual hardware observations, or maybe even a prototype implementation in hardware, such as was done e.g. in Binas et al 2016.	I-Review	I-1	Review	317
At the very least I would suggest to test the model on other noise models, including temporally changing noise levels, which could be a realistic scenario due to temperature fluctuations or other events.	I-Review	I-1	Review	317
<sep> <sep> 2.	O	O	Review	317
The experimental results focus on MNIST, CIFAR10, and later briefly on ImageNet.	B-Review	B-2	Review	317
While the results are quite convincing on MNIST and CIFAR, these are easier datasets with usually well separable classes, so the effect of noisy inference might not be as pronounced, as in datasets with more confusion even in the clean case.	I-Review	I-2	Review	317
In the case of ImageNet (Table 1) it looks like the difference to pure noise injection is not as big as it was in the CIFAR case, but here also only lower noise levels were tested.	I-Review	I-2	Review	317
I would recommend testing also the same noise range as for CIFAR to understand whether distillation always shows the desired benefits, or if this is a diminishing effect for larger networks.	I-Review	I-2	Review	317
Overall it would help to understand how the effect scales with network depth, e.g. by comparing the information loss for different ResNet depths.	I-Review	I-2	Review	317
<sep> <sep> I'm giving weak accept and would change to accept if there could be clarification on how the approach scales to different network architectures and noise models closer to actual hardware.	B-Review	B-3	Review	317
I also recommend publishing some example code for this approach.	I-Review	I-3	Review	317
Author Response:	O	O	Reply	317
<sep> Many thanks for taking the time to review our paper and the constructive comments.	O	O	Reply	317
We've added additional experimental results and reworked the relevant sections of the paper in response to the reviewer feedback.	O	O	Reply	317
<sep> <sep> - Q1 Noise model	O	O	Reply	317
We believe that the simple Gaussian noise model used in the paper is a good approach to modeling real analog hardware systems, which has been confirmed previously in "Accurate deep neural network inference using computational phase-change memory"(<a href="https://arxiv.org/abs/1906.03138)" target="_blank" rel="nofollow">https://arxiv.org/abs/1906.03138)</a>  by Joshi et al Their experiments show (Fig 3c in Joshi et al) that very similar measured accuracy can be achieved when weights trained with the Gaussian noise model are transferred to the actual hardware.	B-Reply	B-1	Reply	317
And in fact, we are already considering modeling of key circuit blocks such as digital-to-analog and analog-to-digital converters within our formulation of weight and activation quantization, which we've emphasized in Section 3, paragraph 2.	I-Reply	I-1	Reply	317
<sep> <sep> Nonetheless, we do agree that robustness to spatially-varying or even time-varying noise models is a very interesting question.	I-Reply	I-1	Reply	317
Therefore we have expanded the results in this regard by adding experiments with time-varying (temperature fluctuation) and spatially-varying (manufacturing process variation) noise models in Table 1 of Section 5.2 to broaden this aspect of the work.	I-Reply	I-1	Reply	317
<sep> <sep> In summary, we have found no significant deviation in these new experiments.	I-Reply	I-1	Reply	317
The improvement from our proposed retraining method is quite consistent.	I-Reply	I-1	Reply	317
We would like to thank the reviewer for suggesting these experiments which have strengthened the results of our paper.	I-Reply	I-1	Reply	317
In addition to the new experimental results, we've also extended the discussion of some of the general challenges and considerations in modeling analog hardware non-idealities (Section 3).	I-Reply	I-1	Reply	317
<sep> <sep> - Q2 Scaling of results over different network architectures	O	O	Reply	317
We also think this is an interesting question, so we expanded our results to provide some data.	B-Reply	B-2	Reply	317
Following the reviewer's suggestion, we have added further experiments in Section 4.2 (Figure 2) to better understand the mutual information decay over both wider and deeper neural network architectures.	I-Reply	I-2	Reply	317
We have also added more results in the Appendix (Figure 6) showing how our method compares to pure noise injection on different network architectures.	I-Reply	I-2	Reply	317
Our results suggest that the improvement does not diminish for larger networks given the same dataset.	I-Reply	I-2	Reply	317
Larger networks can be either more susceptible to noise or less so, depending on their architectures (see discussion in Section 4.2).	I-Reply	I-2	Reply	317
To obtain the same amount of uplift from our method, one may need to go to lower or higher noise levels depending on the architectures.	I-Reply	I-2	Reply	317
<sep> <sep> The reviewer's observation that the benefit is less pronounced on ImageNet than on CIFAR10 is likely due to the nature of the dataset itself.	I-Reply	I-2	Reply	317
As the reviewer has pointed out, ImageNet is a more difficult task, even without noise.	I-Reply	I-2	Reply	317
The reason we reported relatively low noise levels on ImageNet experiments is because the accuracy degradation is already quite significant compared to the CIFAR10 cases.	I-Reply	I-2	Reply	317
From a practical application point of view, pushing to even higher noise levels is arguably less interesting.	I-Reply	I-2	Reply	317
Nevertheless, we understand the request for higher noise levels on ImageNet experiments.	I-Reply	I-2	Reply	317
We are currently running more experiments on ImageNet.	I-Reply	I-2	Reply	317
Given the short time-frame of rebuttal, we don't have the results quite yet (also more training epochs are needed for higher noise levels).	I-Reply	I-2	Reply	317
We will incorporate the results in our paper as they come out.	I-Reply	I-2	Reply	317
<sep> <sep> - Q3 Open sourcing code examples	O	O	Reply	317
Finally, we do plan to open source code used in the paper.	B-Reply	B-3	Reply	317
<sep> We are currently working through an internal legal approval process to do so, but are confident we will be able to have it online before the conference.	I-Reply	I-3	Reply	317

The paper has a double aim.	O	O	Review	317
First, it is a survey on saliency maps used in explaining deep reinforcement learning models.	O	O	Review	317
Second, it is a proposal of a method that should overcome limitations of the current approaches described in the survey.	O	O	Review	317
<sep> This double aim makes the paper hard to understand as the survey is not complete and the model is not well explained.	B-Review	B-1	Review	317
<sep> The main limitations the novel model aims to solve seems to be the production of "falsifiable" hypothesis in the explaination with saliency maps.	I-Review	I-1	Review	317
However, experiments are really hard to follow and it is not clear why this is the case.	I-Review	I-1	Review	317
We appreciate Reviewer 3‚Äôs comments.	O	O	Reply	317
The review has several main points that we address below:	O	O	Reply	317
<sep> Double aim of the paper ‚Äî Our principal contribution is a new method for empirical evaluation of explanations generated from saliency maps about the behavior of deep RL agents.	B-Reply	B-1	Reply	317
We intentionally structured our paper to include both a survey of current practice and an application of our proposed approach.	I-Reply	I-1	Reply	317
Both elements were intended to aid reader understanding.	I-Reply	I-1	Reply	317
The survey describes the inferences that require evaluation, and the application demonstrates the surprising conclusions supported by the evaluation method.	I-Reply	I-1	Reply	317
We have attempted to improve our description of this approach (see ‚ÄúClarity‚Äù below).	I-Reply	I-1	Reply	317
<sep> <sep> Completeness of the survey ‚Äî As we note in section 3, we surveyed 90 papers, each of which cited one or more key papers that described one of four saliency map methods.	B-Reply	B-1	Reply	317
We would be happy to include additional papers in our survey, expand our survey criteria, or consider additional updates to the survey, if Reviewer 3 could provide specific suggestions.	I-Reply	I-1	Reply	317
<sep> <sep> Clarity ‚Äî We have added additional details to Section 4 on how saliency is measured.	B-Reply	B-1	Reply	317
We have also added more quantitative results from the experiments to Section 5 and Appendix E (see Tables 3, 6, 7 and 8), and more details on the model used for training in Section 5 and Appendix B. We hope these additions make the paper more clear, and we welcome additional recommendations.	I-Reply	I-1	Reply	317

Abstract:	O	O	Review	317
The author suggests that saliency maps should be viewed as exploratory tools rather than explanation.	O	O	Review	317
The explore this idea in the context of a game.	O	O	Review	317
<sep> <sep> Here is my main issue:	O	O	Review	317
Although I believe there is a value in studies like this.	O	O	Review	317
I am not sure ICLR is the right venue for it.	B-Review	B-1	Review	317
The paper is well written but it reads like a long opinion/blog-post.	O	O	Review	317
There is no overarching theory or generalizable observation not to mention a solution.	B-Review	B-2	Review	317
<sep> Yes, I agree that the method of interpreting the black box has a lot of issues and the counterfactual approach/causal approach is probably the right way to go but this is hardly news to the community.	B-Review	B-3	Review	317
<sep> <sep> In short: what the generalizable contribution of the paper?	B-Review	B-4	Review	317
<sep> <sep> I am open to change my mind if the discussion is convincing.	O	O	Review	317
We appreciate Reviewer 1‚Äôs comments, and address the main points of the review below:	O	O	Reply	317
<sep> Generalizable contribution ‚Äî The paper makes several contributions: (1) a survey of how saliency maps are currently used to explain the behavior of deep RL agents; (2) a new method to empirically evaluate the inferences made from saliency maps; and (3) an experimental evaluation that uses our proposed method to measure how well saliency maps correspond to the semantic-level inferences of humans.	B-Reply	B-4	Reply	317
Each of these contributions applies to any use of common saliency-map methods to understand the behavior of deep RL agents learned using feed-forward architectures.	I-Reply	I-4	Reply	317
<sep> <sep> Overarching theory ‚Äî As we describe in section 2, our proposed method is based on a formal theory of counterfactual intervention.	B-Reply	B-2	Reply	317
Though the graphical model in Figure 2 represents an Atari game environment, researchers can reason about interventions in different vision-based RL domains by substituting different content for the state and pixels.	I-Reply	I-2	Reply	317
We added a specific graphical model for Breakout in the Appendix (Figure 6) to clarify how the generalized causal graphical model in Figure 2 can be specified to a given domain.	I-Reply	I-2	Reply	317
Section 6 contains additional points on the generalization of the proposed methodology.	I-Reply	I-2	Reply	317
<sep> ICLR as a venue for this paper ‚Äî ICLR is a nearly ideal venue for this work.	B-Reply	B-1	Reply	317
The paper that first introduced saliency maps was published in a 2014 ICLR workshop (Simonyan et al 2014).	I-Reply	I-1	Reply	317
Subsequent ICLR papers have introduced new saliency map methods (e.g., Zintgraf et al 2017) and analyzed these methods (e.g., Ancona et al 2018).	I-Reply	I-1	Reply	317
Many studies have critiqued the use of saliency maps in computer vision (Adebayo et al 2018; Samek et al 2018; Kindermans et al 2019), but we are the first to analyze the utility  of saliency maps for understanding the behavior of deep RL agents.	I-Reply	I-1	Reply	317
Finally, while methodological papers are relatively uncommon in machine learning conferences (including ICLR), effective evaluation of learned representations is vital to progress in the field.	I-Reply	I-1	Reply	317
Saliency maps have become one of the primary methods to visualize the representations learned by deep neural networks, and better understanding the utility of saliency maps is central to understanding their proper role in research.	I-Reply	I-1	Reply	317
<sep> <sep> Adebayo et al "Sanity checks for saliency maps."	O	O	Reply	317
NeurIPS 2018.	O	O	Reply	317
<sep> <sep> Ancona et al ‚ÄúTowards better understanding of gradient-based attribution methods for deep neural networks.	O	O	Reply	317
‚Äù ICLR 2018.	O	O	Reply	317
<sep> <sep> Kindermans et al "The (un) reliability of saliency methods."	O	O	Reply	317
Explainable AI: Interpreting, Explaining and Visualizing Deep Learning 2019.	O	O	Reply	317
<sep> <sep> Samek et al "Evaluating the visualization of what a deep neural network has learned."	O	O	Reply	317
IEEE Transactions on Neural Networks and Learning Systems 2017.	O	O	Reply	317
<sep> <sep> Simonyan et al ‚ÄúDeep inside convolutional networks: visualising image classification models and saliency maps.	O	O	Reply	317
‚Äù ICLR Workshop 2014.	O	O	Reply	317
<sep> <sep> Zintgraf et al ‚ÄúVisualizing deep neural network decisions: prediction difference analysis.	O	O	Reply	317
‚Äù ICLR 2017.	O	O	Reply	317

[score raised from weak accept to accept due to rebuttal/improvements]	O	O	Review	317
<sep> Summary	O	O	Review	317
The paper investigates the practice of using pixel-level saliency maps in deep RL to ‚Äúexplain‚Äù agent behavior in terms of semantics of the scene.	O	O	Review	317
The main problem, according to the paper, is that pixel-level saliency maps often correlate with semantic objects, however turning these correlations into explanations would require counterfactual analysis / interventions, which are almost never performed in practice.	O	O	Review	317
The paper highlights this issue with an extensive literature survey, and proposes a simple method to formulate ‚Äúexplanations‚Äù found via saliency maps into falsifiable hypotheses.	O	O	Review	317
Three experiments show how to apply the methodology in practice - in all three cases pixel-level correlations cannot be easily mapped to semantic-level explanations that hold (counterfactual) validation.	O	O	Review	317
<sep> <sep> Contributions	O	O	Review	317
The paper nicely summarizes the main contributions, namely: (i) a literature survey on pixel-saliency methods in deep RL and their use to ‚Äúexplain‚Äù agent behavior, (ii) a detailed description of the problem with the latter and a proposal to mitigate the main issues, and (iii) three experimental case-studies to illustrate the problem further and show how the proposed method can help.	O	O	Review	317
<sep> <sep> Quality, Clarity, Novelty, Impact	O	O	Review	317
The paper addresses a highly important issue in the field of interpretable deep learning.	B-Review	B-1	Review	317
The main message is that a lack of scientific rigor, namely stating falsifiable hypotheses and validation of claimed hypotheses, can easily lead to misinterpretation of deep RL systems.	I-Review	I-1	Review	317
This is a somewhat disenchanting message, but I personally think it is important to ensure that this message is heard in the field of interpretable ML in particular, and in the wider deep learning community in general.	I-Review	I-1	Review	317
It is tempting to give simple answers to complex problems, and while I think saliency maps will play a large role in interpreting deep network decisions, I am also convinced that we need causal explanations, which salience maps (currently) cannot provide on a semantic level.	I-Review	I-1	Review	317
The paper is well written and clear, the literature survey is quite extensive and valuable.	I-Review	I-1	Review	317
The experimental results are nice, however they currently crucially lack quantitative statements that back up the qualitative results (see improvements below).	I-Review	I-1	Review	317
While the latter must be included for publication, I am fairly confident that this can be rectified during the rebuttal phase and therefore (tentatively) vote for acceptance.	I-Review	I-1	Review	317
<sep> <sep> Improvements	O	O	Review	317
a) Mandatory for publication!	B-Review	B-2	Review	317
Back the results-plots up by numbers!	I-Review	I-2	Review	317
In particular: visually estimating densities / correlations from scatter plots is often impossible and misleading - while the plots are nice to have, the claims regarding Figure 5, 8, 9 (b) and (c) must be backed up by reporting actual correlations / statistical tests.	I-Review	I-2	Review	317
For instance, it is impossible to judge visually whether there‚Äôs any trend in 5 (c).	I-Review	I-2	Review	317
Please report correlations for 5, 8, 9 (b) and perform suitable statistical tests for measuring increase/decrease in correlation for 5, 8, 9 (c).	I-Review	I-2	Review	317
<sep> Similarly, please report an appropriate metric to quantitatively judge the difference between the curves in 4, 6, 7 (c).	I-Review	I-2	Review	317
It‚Äôs fine to include tables reporting the quantitative results in the appendix, they don‚Äôt necessarily have to be in the main paper.	I-Review	I-2	Review	317
<sep> <sep> b) Experimental details.	B-Review	B-3	Review	317
Please report the details required to reproduce the experiments.	I-Review	I-3	Review	317
In particular, what was the precise architecture for A2C and the hyper-parameter settings (particularly since the reference that is cited is not a paper, but a GitHub repo).	I-Review	I-3	Review	317
For the figures, please report how saliency was measured exactly (was there a bounding-box around saliency/enemies?	I-Review	I-3	Review	317
What was its size?	I-Review	I-3	Review	317
Were intensities somehow normalized, were distances to enemies measured between centers of bounding-boxes, ‚Ä¶?)	I-Review	I-3	Review	317
<sep> <sep> c) (Optional).	B-Review	B-4	Review	317
It would be nice to see an example where the method is used but the original hypothesis is not rejected (i.e. there‚Äôs now stronger evidence for the original hypothesis due to the counterfactual analysis).	I-Review	I-4	Review	317
I understand that this is beyond the scope of the rebuttal, and feel free to completely ignore this.	I-Review	I-4	Review	317
<sep> <sep> <sep> Major Comments	O	O	Review	317
I) Please state whether the paper was written with feed-forward deep RL agents only in mind, or whether the paper is intended to also include recurrent deep RL agents (it would also be helpful to know whether the experiments used a feed-forward, or a recurrent version of A2C).	B-Review	B-5	Review	317
While I think that many aspects carry over from feedforward architectures to recurrent ones, I personally think that some issues with counterfactual analysis could become more intricate with recurrent agents.	I-Review	I-5	Review	317
For instance, on page 6, the described invariance in the first paragraph under ‚ÄòCounterfactual Evaluation of Claims‚Äô is fine for feed-forward agents, but could be debatable with recurrent agents.	I-Review	I-5	Review	317
If you agree, please make this distinction clear in the paper (where appropriate) or state that the paper only applies to feedforward agents.	I-Review	I-5	Review	317
If you disagree please indicate this during the rebuttal discussion.	I-Review	I-5	Review	317
<sep> <sep> II) Page 6, just above Sec.5: ‚ÄúSince the learned policies should be semantically invariant under manipulations of the RL environment...‚Äù.	B-Review	B-6	Review	317
I agree that they should ideally be invariant, for the semantic interventions to make sense, but please comment on whether this is a trivial assumption, how this assumption could (in principle) be verified and the potential consequences of this assumption being violated.	I-Review	I-6	Review	317
I personally think that there‚Äôs a fair chance that the semantic space carved up by the agent (that potentially overfits a task/family of tasks) might be quite different from the semantic space given by the latent factors of the environment.	I-Review	I-6	Review	317
This mismatch and its potential interference with the method should be discussed as a current shortcoming.	I-Review	I-6	Review	317
<sep> <sep> Minor Comments	O	O	Review	317
I)  A potential subtlety (which I don‚Äôt expect you to resolve/discuss in the paper) is that feed-forward agents in an MDP environment can behave like recurrent agents by offloading memory into the environment.	B-Review	B-7	Review	317
E.g. a breakout agent could ‚Äúmemorize‚Äù that it is in ‚Äútunnel-digging mode‚Äù by moving the paddle by a few pixels - this could then potentially shift it‚Äôs saliency away from the actual tunnel to the corresponding pixels around the paddle.	I-Review	I-7	Review	317
Such cases might be very hard to interpret via saliency maps or interventional analysis, but I acknowledge that this is perhaps a more exotic case, given the current state of interpretable deep RL.	I-Review	I-7	Review	317
Just a thought for future work perhaps...	I-Review	I-7	Review	317
We greatly appreciate Reviewer 2's extensive comments and suggested improvements.	O	O	Reply	317
We have incorporated the suggested improvements to the best of our ability during the response period, and we summarize those revisions in a separate official comment.	O	O	Reply	317
Specifically, we have provided statistics that quantify experimental effects, run and reported the results of hypothesis tests, and provided additional experimental details.	O	O	Reply	317
Below are some additional notes on specific comments from the review:	O	O	Reply	317
<sep> Application to recurrent deep RL agents ‚Äî As Reviewer 2 notes, the paper was written with feed-forward deep RL agents in mind.	B-Reply	B-5	Reply	317
That said, the proposed methodology is post-hoc (i.e., not model-dependent), so aspects of the approach will carry over to recurrent RL agents.	I-Reply	I-5	Reply	317
Our proposed methodology would not work for repeated interventions on recurrent RL agents due to their capacity for memorization.	I-Reply	I-5	Reply	317
We have noted this distinction in Section 6.	I-Reply	I-5	Reply	317
<sep> <sep> Semantic Invariance ‚Äî We completely agree that the semantic space devised by the agent might be quite different from the semantic space given by the latent factors of the environment.	B-Reply	B-6	Reply	317
It is crucial to note that this mismatch is one aspect of what plays out when researchers create hypotheses about agent behavior, and the methodology we provide in this work demonstrates how to evaluate hypotheses that reflect that mismatch.	I-Reply	I-6	Reply	317
<sep> <sep> Positive Example ‚Äî We agree it would have been ideal to provide an example where the original hypothesis was not rejected.	B-Reply	B-4	Reply	317
Unfortunately, we exhausted the set of obvious hypotheses for the two games we considered, and all were rejected.	I-Reply	I-4	Reply	317
We were surprised by these results, but they support the idea that saliency maps are easily misinterpreted.	I-Reply	I-4	Reply	317
<sep> <sep> Memory in feed-forward agents ‚Äî The subtlety that Reviewer 2 points about feed-forward agents behaving like recurrent agents by offloading memory into the environment is extremely interesting.	B-Reply	B-7	Reply	317
Assessing whether memorization leads to different saliency behavior is a fascinating direction for future work.	I-Reply	I-7	Reply	317

