The author studies the quantization strategy of CNNs in terms of Pareto Efficiency.	O	O	Review	20107
Through a series of experiments with three standard CNN models (ResNet, VGG11, MobileNetV2), the authors demonstrated that lower precision value can be better than high precision values in term of Pareto efficiency under the iso-model size scenario.	O	O	Review	20107
They also study cases with and without depth-wise convolution, and propose a new quantization method, DualPrecision.	O	O	Review	20107
DualPrecision empirically outperformed 8-bit quantization and flexible quantization methods on ImageNet.	O	O	Review	20107
<sep> <sep> Comment:	O	O	Review	20107
I am not at all familiar with quantization methods, therefore no knowledge of relevant related works.	B-Review	B-1	Review	20107
If, however, the authors did a thorough job of surveying related works and chose sensible baselines, I think the experiments demonstrate the usefulness of the new DualPrecision technique.	I-Review	I-1	Review	20107
We thank the reviewer for your feedback and for appreciating our work.	O	O	Reply	20107
<sep> <sep> We have updated our manuscript so that it states our contributions explicitly.	B-Reply	B-1	Reply	20107
While our proposed DualPrecision is simple yet effective, we would like to emphasize that it is only one of our contributions.	I-Reply	I-1	Reply	20107
For the reviewer‚Äôs convenience, we re-iterate our main contributions below:	I-Reply	I-1	Reply	20107
Overall, we systematically analyze the model size and accuracy trade-offs considering both weight precision values and the number of channels for various modern networks architectures (variants of ResNet, VGG, and MobileNet) and datasets (CIFAR and ImageNet) and have the following non-trivial and novel contributions:	I-Reply	I-1	Reply	20107
-<tab>We are the first to show that lower precision weight values outperform higher precision weight values in a Pareto sense (accuracy vs. model size) for networks with standard convolutions.	I-Reply	I-1	Reply	20107
This is intriguing since it implies that scaling up (in terms of model size) along the channel count dimension is more effective for accuracy than the precision value dimension.	I-Reply	I-1	Reply	20107
This finding can lead to follow-up works trying to understand or exploit this phenomenon.	I-Reply	I-1	Reply	20107
<sep> <sep> -<tab>We are the first to show that the fan-in channel counts per output filter for a convolution layer determine the effectiveness of accuracy improvement along the weight precision dimension and provide both theoretical and empirical reasoning for this.	B-Reply	B-1	Reply	20107
This finding is useful for future works that are interested in optimizing the neural architecture regarding both channel counts and weight precision as we show what might affect the effectiveness of weight precision scaling.	I-Reply	I-1	Reply	20107
<sep> <sep> -<tab>We are the first to show that with a simple scaling rule, one can achieve a more accurate model (given the same model size) even compared to mixed-precision prior art that uses DRL to search for layer-wise weight precision values.	B-Reply	B-1	Reply	20107
Moreover, the results are validated on the large-scale dataset, i.e., ImageNet.	I-Reply	I-1	Reply	20107
This is a manifestation of our two previous findings.	I-Reply	I-1	Reply	20107
<sep> <sep> We hope the reviewer can take into account the above-listed contributions and their potential impacts when making the final recommendation.	I-Reply	I-1	Reply	20107

<sep> This paper studies the accuracy vs model-size trade-off of quantized CNNs under different channel width multipliers.	O	O	Review	20107
The authors demonstrated that while all-to-all convolution works well under low bit settings, depthwise conv needs a different sweet spot.	O	O	Review	20107
The authors then proceed to use the insight to design quantized cnns that have two different schemes for depthwise and normal conv.	O	O	Review	20107
<sep> <sep> <sep> Strength	O	O	Review	20107
<sep> The paper is well written and motivated.	O	O	Review	20107
By adding network width to the search space,  using the simple heuristics, the authors provide a better results than previously DRL based search method.	O	O	Review	20107
<sep> <sep> Weakness	O	O	Review	20107
<sep> One of my main concerns is the direct usage of total number of bits as an equivalent measurement between models.	B-Review	B-1	Review	20107
While it is useful to measure the storage cost for weights.	I-Review	I-1	Review	20107
The choices of bit width will likely affect the computing cost in a non-trivial way, depending on the target hardware platform.	I-Review	I-1	Review	20107
It is unclear whether equal model size would mean equal inference latency in practice (most likely they would not be).	I-Review	I-1	Review	20107
Providing empirical implementations of these models will shed light into this question.	I-Review	I-1	Review	20107
<sep> <sep> These weakness makes it a borderline paper.	O	O	Review	20107
<sep> <sep> Question:	O	O	Review	20107
<sep> How do you handle batchnorm layer, do you use floating points?	B-Review	B-2	Review	20107
<sep> <sep> How many bits did you use for accumulating the results?	B-Review	B-3	Review	20107
<sep> <sep> Update after rebuttal:	O	O	Review	20107
<sep> I have read the authors' response.	O	O	Review	20107
I would like to keep my current review as it is.	O	O	Review	20107
Also note that the authors uses floating pt for batchnorm and 32 bit for accumulation, such additional cost might out-weights the benefit of choosing ultra low bits in the low bits regime, making the study less relevant for practice reasons	B-Review	B-2	Review	20107
<sep> <sep> <sep> We thank the reviewer for their feedback and for finding our paper well-written and motivated.	O	O	Reply	20107
<sep> <sep> Regarding your main concern, we agree that it is non-trivial to see if equal model size reflects compute (in terms of latency and/or energy) since it depends on the application scenario and software/hardware implementation.	B-Reply	B-1	Reply	20107
However, our insights and good results from the model size standpoint set a strong motivation for future study to target a specific application scenario and research on hardware acceleration.	I-Reply	I-1	Reply	20107
We argue that this does not constitute a weakness for our paper since there are scenarios where model sizes is important.	I-Reply	I-1	Reply	20107
From the perspective of information theory and Minimum Description Length (MDL) principle [1,2], our results show that by trading weight precision values with the number of channels, one can achieve a smaller description length for the model with equal accuracy, which is more preferable based on the MDL principle.	I-Reply	I-1	Reply	20107
Moreover, considering edge devices that are deployed for streaming inference scenarios (single image per batch), our analyses in the updated manuscript (Appendix F and Figure 6) show lower memory footprint is needed for the proposed model to achieve equally accurate results compared to the baseline.	I-Reply	I-1	Reply	20107
We argue that for streaming inference applications that run on IoT devices, model size is an important factor due to their limited RAM.	I-Reply	I-1	Reply	20107
<sep> <sep> Beyond the above argument for the efficacy of DualPrecision, we would like to re-iterate that our contributions are more than the proposed DualPrecision method.	I-Reply	I-1	Reply	20107
Specifically, the following three contributions are non-trivial, novel, and can be built upon for future study:	I-Reply	I-1	Reply	20107
-<tab>We are the first to show that lower precision weight values outperform higher precision weight values in a Pareto sense (accuracy vs. model size) for networks with standard convolutions.	I-Reply	I-1	Reply	20107
This is intriguing since it implies that scaling up (in terms of model size) along the channel count dimension is more effective for accuracy than the precision value dimension.	I-Reply	I-1	Reply	20107
This finding can lead to follow-up works trying to understand or exploit this phenomenon.	I-Reply	I-1	Reply	20107
<sep> <sep> -<tab>We are the first to show that the fan-in channel counts per output filter for a convolution layer determine the effectiveness of accuracy improvement along the weight precision dimension and provide both theoretical and empirical reasoning for this.	I-Reply	I-1	Reply	20107
This finding is useful for future works that are interested in optimizing the neural architecture regarding both channel counts and weight precision as we show what might affect the effectiveness of weight precision scaling.	I-Reply	I-1	Reply	20107
<sep> <sep> -<tab>We are the first to show that with a simple scaling rule, one can achieve a more accurate model (given the same model size) even compared to mixed-precision prior art that uses DRL to search for layer-wise weight precision values.	I-Reply	I-1	Reply	20107
Moreover, the results are validated on the large-scale dataset, i.e., ImageNet.	I-Reply	I-1	Reply	20107
This is a manifestation of our two previous findings.	I-Reply	I-1	Reply	20107
<sep> <sep> We hope the reviewer can take into account the above-listed contributions and their potential impacts when making the final recommendation.	I-Reply	I-1	Reply	20107
<sep> <sep> Regarding the questions, we use floating-point for batch norm.	B-Reply	B-2	Reply	20107
The accumulation of results is done in 32 bits (We simulate the quantization process in PyTorch according to Figure C.4 in [3]).	I-Reply	I-2	Reply	20107
<sep> <sep> [1] Blier, L√©onard, and Yann Ollivier. "	O	O	Reply	20107
The description length of deep learning models."	O	O	Reply	20107
NeurIPS 2018.	O	O	Reply	20107
<sep> [2] Havasi, Marton, Robert Peharz, and Jos√© Miguel Hern√°ndez-Lobato. "	O	O	Reply	20107
Minimal Random Code Learning: Getting Bits Back from Compressed Model Parameters."	O	O	Reply	20107
ICLR 2019.	O	O	Reply	20107
<sep> [3] Benoit Jacob, Skirmantas  Kligys,  Bo  Chen,  Menglong  Zhu,  Matthew  Tang,  Andrew  Howard,Hartwig Adam, and Dmitry Kalenichenko.	O	O	Reply	20107
Quantization and training of neural networks for effi-cient integer-arithmetic-only inference.	O	O	Reply	20107
InThe IEEE Conference on Computer Vision and PatternRecognition (CVPR), June 2018.	O	O	Reply	20107

This paper presents a generic unbiased low-rank stochastic approximation to full rank matrices that makes it possible to do online RNN training without the O(n^3) overhead of real-time recurrent learning (RTRL).	O	O	Review	474
This is an important and long-sought-after goal of connectionist learning and this paper presents a clear and concise description of why their method is a natural way of achieving that goal, along with experiments on classic toy RNN tasks with medium-range time dependencies for which other low-memory-overhead RNN training heuristics fail.	O	O	Review	474
My only major complaint with the paper is that it does not extend the method to large-scale problems on real data, for instance work from the last decade on sequence generation, speech recognition or any of the other RNN success stories that have led to their wide adoption (eg Graves 2013, Sutskever, Martens and Hinton 2011 or Graves, Mohamed and Hinton 2013).	B-Review	B-1	Review	474
However, if the paper does achieve what it claims to achieve, I am sure that many people will soon try out UORO to see if the results are in any way comparable.	I-Review	I-1	Review	474
Thank you for the constructive feedback.	O	O	Reply	474
At the moment, we haven't	B-Reply	B-1	Reply	474
succeeded in scaling UORO up to the state of the art with results competitive with backpropagation on large scale benchmarks.	I-Reply	I-1	Reply	474
This may be due to the additional constraints borne by UORO, namely, both	I-Reply	I-1	Reply	474
memorylessness and unbiasedness at all time scales.	I-Reply	I-1	Reply	474
Such datasets (notably next-character or next-word predictions) contain difficult short-term dependencies: Truncated BPTT with relatively small truncation is expected to learn those dependencies better than an algorithm like UORO, which must consider all time ranges at once.	I-Reply	I-1	Reply	474

Post-rebuttal update:	O	O	Review	474
I am happy with the rebuttal and therefore I will keep the score of 7.	O	O	Review	474
<sep> <sep> This is a very interesting paper.	O	O	Review	474
Training RNN's in an online fashion (with no backpropagation through time) is one of those problems which are not well explored in the research community.	O	O	Review	474
And I think, this paper approaches this problem in a very principled manner.	O	O	Review	474
The authors proposes to use forward approach for the calculation of the gradients.	O	O	Review	474
The author proposes to modify RTRL by maintaining a rank one approximation of jacobian matrix (derivative of state w.r.t parameters)  which was done in NoBackTrack Paper.	O	O	Review	474
The way I think this paper is different from NoBackTrack Paper is that this version can be implemented in a black box fashion and hence easy to implement using current DL libraries like Pytorch.	O	O	Review	474
<sep> <sep> Pros.	O	O	Review	474
<sep> <sep> - Its an interesting paper, very easy to follow, and with proper literature survey.	O	O	Review	474
<sep> <sep> Cons:	O	O	Review	474
<sep> - The results are quite preliminary.	B-Review	B-1	Review	474
I'll note that this is a very difficult problem.	I-Review	I-1	Review	474
<sep> - "The proof of UORO‚Äôs convergence to a local optimum is soon to be published Masse & Ollivier (To appear)."	B-Review	B-2	Review	474
I think, paper violates the anonymity.	I-Review	I-2	Review	474
So, I'd encourage the authors to remove this.	I-Review	I-2	Review	474
<sep> <sep> Some Points:	O	O	Review	474
<sep> - I find the argument of stochastic gradient descent wrong (I could be wrong though).	B-Review	B-3	Review	474
RNN's follow the markov property (wrt hidden states from previous time step and the current input) so from time step t to t+1, if you change the parameters, the hidden state at time t (and all the time steps before) would carry stale information unless until you're using something like eligibility traces from RL literature.	I-Review	I-3	Review	474
I also don't know how to overcome this issue.	I-Review	I-3	Review	474
<sep> <sep> - I'd be worried about the variance in the estimate of rank one approximation.	B-Review	B-4	Review	474
All the experiments carried out by the authors are small scale (hidden size = 64).	I-Review	I-4	Review	474
I'm curious if authors tried experimenting with larger networks, I'd guess it wont perform well due to the high variance in the approximation.	I-Review	I-4	Review	474
I'd like to see an experiment with hidden size  = 128/256/512/1024.	I-Review	I-4	Review	474
My intuition is that because of high variance it would be difficult to train this network, but I could be wrong.	I-Review	I-4	Review	474
I'm curious what the authors had to say about this.	I-Review	I-4	Review	474
<sep> <sep> - If the variance of the approximation is indeed high, can we use something to control the dynamics of the network which can result in less variance.	B-Review	B-5	Review	474
Have authors thought about this ?	I-Review	I-5	Review	474
<sep> <sep> - I'd also like to see experiments on copying task/adding task (as these are standard experiments which are done for analysis of long term dependencies)	B-Review	B-6	Review	474
<sep> - I'd also like to see what effect the length of sequence has on the approximation.	B-Review	B-7	Review	474
As small errors in approximation on each step can compound giving rise to chaotic dynamics. (	I-Review	I-7	Review	474
small change in input => large change in output)	I-Review	I-7	Review	474
<sep> - I'd also like to know how using UORO changes the optimization as compared to Back-propagation through time in the sense, does the two approaches would reach same local minimum ?	B-Review	B-8	Review	474
or is there a possibility that the former can reach "less" number of potential local minimas as compared to BPTT.	I-Review	I-8	Review	474
<sep> <sep> <sep> I'm tempted to give high score for this paper( Score - 7) , as it is unexplored direction in our research community, and I think this paper makes a very useful contribution to tackle this problem in a very principled way.	O	O	Review	474
But I'd like some more experiments to be done (which I have mentioned above), failing to do those experiments, I'd be forced to reduce the score (to score - 5)	O	O	Review	474
Thank you for your insights, questions and suggestions.	O	O	Reply	474
We have tried to attend your concerns in the revised version of the paper.	O	O	Reply	474
<sep> <sep> 1/ As you pointed out, the results are indeed preliminary.	B-Reply	B-1	Reply	474
As pointed out in the answer to Reviewer 2, it is difficult to obtain results competitive with BPTT on large scale benchmarks given the additional constraints on UORO (namely, no storage of past data, and good convergence properties, which is not the case of truncated backpropagation if dependencies exceed its truncation range).	I-Reply	I-1	Reply	474
<sep> <sep> 2/ About the variance of UORO for large networks: We have added an experiment to test this.	B-Reply	B-4	Reply	474
The variance of UORO does increase with netowrk size (probably sublinearly), and larger networks will require smaller learning rates.	I-Reply	I-4	Reply	474
<sep> <sep> 3/ About the effect of length on the quality of the approximation: We have added an experiment to test the evolution of UORO variance when time increases along the input sequence.	B-Reply	B-7	Reply	474
The variance of UORO does not explode over time, and is stationary.	I-Reply	I-7	Reply	474
A key point of UORO is the whole renormalization process (variable rho), designed precisely for this.	I-Reply	I-7	Reply	474
An independent, theoretical proof for the similar case of NoBackTrack is in (Masse 2017).	I-Reply	I-7	Reply	474
Thus UORO is applicable to unbounded sequences (notably, in the experiments, datasets are fed as a single sequence, containing 10^6-10^7 characters).	I-Reply	I-7	Reply	474
<sep> <sep> 4/ About the stochastic gradient descent argument: indeed one has to be careful.	B-Reply	B-3	Reply	474
If UORO is used to process a number of finite training sequences, and gradient steps are performed at the end of each sequence only, then this is a fully standard SGD argument: UORO computes, in a streaming fashion, an unbiased estimate of the same gradient as BPTT for each training sequence.	I-Reply	I-3	Reply	474
However, if the gradients steps are performed at every time step, as we do here, then you are right that an additional argument is needed.	I-Reply	I-3	Reply	474
The difference between applying gradients at each step and applying gradients only at the end of each sequence is at *second order* in the learning rate: if the learning rate is small, applying gradients at each time does not change the computations too much, and the SGD argument applies up to second-order terms.	I-Reply	I-3	Reply	474
This is fully formalized in (Masse 2017).	I-Reply	I-3	Reply	474
If moreover, only one infinite training sequence is provided, then an additional assumption of ergodicity (decay of correlations) is needed.	I-Reply	I-3	Reply	474
But in any case unbiasedness is the central property.	I-Reply	I-3	Reply	474
<sep> <sep> 5/ About the optima reached by UORO vs BPTT: in the limit of very small learning rates, UORO, RTRL, and BPTT with increasing truncation lengths will all produce the same limit trajectories.	B-Reply	B-8	Reply	474
The theory from (Masse 2017) proves local convergence to the *same* set of local optima for RTRL and UORO (if starting close enough to the local optimum).	I-Reply	I-8	Reply	474
On the other hand, for large learning rates, we are not aware of theoretical results for any recurrent algorithm.	I-Reply	I-8	Reply	474
<sep> <sep> 6/ Regarding reference (Masse 2017): this reference is now publically	B-Reply	B-2	Reply	474
available and we provide a link in the bibliography.	I-Reply	I-2	Reply	474
We were indeed aware of Masse's work a bit before it was put online, but that still covers many people, so we do not believe this breaks anonymity.	I-Reply	I-2	Reply	474
Our paper is disjoint from (Masse 2017), as can be directly checked by comparing the texts.	I-Reply	I-2	Reply	474

The authors introduce a novel approach to online learning of the parameters of recurrent neural networks from long sequences that overcomes the limitation of truncated backpropagation through time (BPTT) of providing biased gradient estimates.	O	O	Review	474
<sep> <sep> The idea is to use a forward computation of the gradient as in Williams and Zipser (1989) with an unbiased approximation of Delta s_t/Delta theta to reduce the memory and computational cost.	O	O	Review	474
<sep> <sep> The proposed approach, called UORO, is tested on a few artificial datasets.	O	O	Review	474
<sep> <sep> The approach is interesting and could potentially be very useful.	B-Review	B-1	Review	474
However, the paper lacks in providing a substantial experimental evaluation and comparison with other methods.	I-Review	I-1	Review	474
<sep> Rather than with truncated BPTT with smaller truncation than required, which is easy to outperform, I would have expected a comparison with some of the other methods mentioned in the Related Work Section, such as NBT, ESNs, Decoupled Neural Interfaces, etc.	B-Review	B-1	Review	474
Also the evaluation should be extended to other challenging tasks.	B-Review	B-2	Review	474
<sep> <sep> I have increased the score to 6 based on the comments and revisions from the authors.	O	O	Review	474
Thank you for your comments and suggestions.	O	O	Reply	474
<sep> <sep> 1/ Regarding comparison to other online methods such as NoBackTrack and Echo State Networks.	B-Reply	B-1	Reply	474
For plain, fully connected RNNs, NoBackTrack and UORO turn out to be mathematically identical (though implemented quite differently), so they will perform the same.	I-Reply	I-1	Reply	474
On the contrary, for LSTMs, NoBackTrack is extremely difficult to implement (to our knowledge, it has never been done); this was one of the motivations for UORO, but it makes the comparison difficult.	I-Reply	I-1	Reply	474
<sep> <sep> For Echo State Networks: ESNs amount in great part to not learning the internal weights, only the output weights (together with a carefully tuned initialization).	I-Reply	I-1	Reply	474
As much as we are aware, they are not known to fare particularly well on the kind of task we consider, but we may have missed relevant references.	I-Reply	I-1	Reply	474
<sep> <sep> 2/ We have included a few more tasks and tests, although this remains relatively small-scale.	B-Reply	B-2	Reply	474

This paper proposes a method for lossless image compression consisting of a VAE and using a bits-back version of ANS.	O	O	Review	474
The results are very impressive on a ImageNet (but maybe not so impressive on the other benchmarks).	O	O	Review	474
The authors also discuss how to speed up inference and present some frightening runtime numbers for the serial method, and some better numbers for the vectorized version, though they're nowhere close to being practical.	O	O	Review	474
<sep> <sep> I think this paper should be accepted.	O	O	Review	474
It has a better description of the BB ANS algorithm than I have read before, and it's a truly interesting direction for the field, despite the lack of immediate applicability.	O	O	Review	474
<sep> <sep> If we are to accept this paper, I suggest the authors put a full description of the neural network used (it's barely mentioned).	B-Review	B-2	Review	474
I think the authors also need to disclose how long it took to compress an average imagenet image (looking at the runtime numbers for 128x128 pixels is scary, but at least we'd get a better picture on the feasability).	I-Review	I-2	Review	474
<sep> <sep> Overall, due to the fact that the authors pledge to open source the framework, I think some of the details will be found in the code, once released.	B-Review	B-3	Review	474
I think this is an important step because there are so many details in this paper that one cannot reasonably reproduce the work by simply reading the text of this paper.	I-Review	I-3	Review	474
Thank you for your review.	O	O	Reply	474
To address the points you raised:	O	O	Reply	474
<sep> &gt; ... put a full description of the neural network used	O	O	Reply	474
<sep> We have now added a detailed description of the VAE that we used, in Appendix E.	B-Reply	B-1	Reply	474
<sep> &gt; the authors also need to disclose how long it took to compress an average ImageNet image	O	O	Reply	474
<sep> We‚Äôve found the encode/decode times are roughly linear in the number of pixels, and you can extrapolate from the graph.	B-Reply	B-2	Reply	474
To demonstrate this point, we‚Äôve timed compressing ImageNet images with dimension 500x374, which is slightly over the average size.	I-Reply	I-2	Reply	474
The compression takes 29s.	I-Reply	I-2	Reply	474
We agree that it's important to disclose this and we‚Äôve added this information to the paper near the end of Section 4.	I-Reply	I-2	Reply	474
We also agree that these times are slow, and mean that the method is not yet practical.	I-Reply	I-2	Reply	474
However, we have improved significantly over existing work, and we see plenty of scope for further optimizing the runtime of the algorithm.	I-Reply	I-2	Reply	474
In particular, quite a lot of code is still running in the Python interpreter, which could be written in another, compiled language.	I-Reply	I-2	Reply	474
Also the hierarchical VAE that we used was mainly chosen to demonstrate the scalability of the method and to ensure an excellent compression rate, and not for its practicality.	I-Reply	I-2	Reply	474
A smaller model would almost certainly be more appropriate in the long run, and distillation could be used to minimize runtime whilst maintaining similar compression performance.	I-Reply	I-2	Reply	474

The authors propose a method for lossless image compression based on using	O	O	Review	474
fully convolutional VAE models.	O	O	Review	474
These models are shown to generalize well when	O	O	Review	474
they are trained on small images (e.g. 32x32 and 64x64) and then applied to	O	O	Review	474
much larger images.	O	O	Review	474
The method is based on a fully vectorized implementation of	O	O	Review	474
bits back with asymetric numeral systems coding which is much faster than	O	O	Review	474
previous non-vertorized implementations.	O	O	Review	474
An improvement with respect to similar	O	O	Review	474
methods is to use a dynamic discretization of the latent variables which avoids	O	O	Review	474
having to callibrate a static discretization (as in previous methods).	O	O	Review	474
<sep> Finally, the authors initialize the bis back process with information about a	O	O	Review	474
few initial images which are coded using a different codec.	O	O	Review	474
The experiments	O	O	Review	474
performed illustrate the gains of the method in terms of compression ratio and	O	O	Review	474
speed.	O	O	Review	474
<sep> <sep> Clarity:	O	O	Review	474
<sep> The paper is extremelly well writen and it is very easy to read.	O	O	Review	474
The athors	O	O	Review	474
indicate that they will release open-source code to implement all their	O	O	Review	474
results, which is very wellcome to improve reproducibility.	O	O	Review	474
However, I have to	B-Review	B-1	Review	474
say that the part describing the vectorized implementation of their method was	I-Review	I-1	Review	474
rather confusing and the paper could benefit a lot from clarifying this part.	I-Review	I-1	Review	474
<sep> <sep> Quality:	O	O	Review	474
<sep> The experiments performed are sound and illustrate the gains produced by their	O	O	Review	474
method (although they do not achieve state of the art results).	O	O	Review	474
In particular,	O	O	Review	474
the experiments show the speed up gain by the proposed vectorization and the gains	O	O	Review	474
produced by the dynamic discretization.	O	O	Review	474
The experiments also show how the methods	O	O	Review	474
trained on smaller images generalize well to larger images.	O	O	Review	474
<sep> <sep> Novelty:	O	O	Review	474
<sep> The proposed approach is novel up to my knowledge.	O	O	Review	474
Although the methodological	O	O	Review	474
innovations are not that advanced, the vectorization in the specific	O	O	Review	474
application considered is novel, as well as the dynamic discretization.	O	O	Review	474
<sep> <sep> Significance:	O	O	Review	474
<sep> The proposed contributions are significant in my opinion.	B-Review	B-2	Review	474
The vectorization	I-Review	I-2	Review	474
approach can be very useful in practice and the dynamic discretization can also	I-Review	I-2	Review	474
be useful as shown by the experiments.	I-Review	I-2	Review	474
One criticism could be that the authors	I-Review	I-2	Review	474
do not achieve state of the art results, but I consider this a minor thing.	I-Review	I-2	Review	474
Thank you for your review.	O	O	Reply	474
We address the following point:	O	O	Reply	474
<sep> &gt; However, I have to say that the part describing the vectorized implementation of their method was rather confusing and the paper could benefit a lot from clarifying this part.	O	O	Reply	474
<sep> <sep> It‚Äôs difficult to give a proper description of this without going into a lot more detail about ANS implementation.	B-Reply	B-1	Reply	474
To aid readers who are confused and/or curious, we‚Äôve added a recommendation, in the second paragraph of Section 3.2, to refer to our code and to Giesen (2015) for more detail.	I-Reply	I-1	Reply	474

Summary:	O	O	Review	474
This paper focuses on lossless source compression with bits back coding for hierarchical fully convolutional VAEs.	O	O	Review	474
The focus/contribution is three-fold: 1.	O	O	Review	474
Improve the compression rate performance by adapting the discretization of latent space required for the entropy coder ANS.	O	O	Review	474
The newly proposed discretization scheme allows for a dependency structure that is not restricted to a Markov chain structure in the encoder model q(z|x) and in the generative part of the model p(x,z).	O	O	Review	474
This is in contrast with bit-swap[1], which requires a markov chain structure.	O	O	Review	474
The dependency structure that is allowed in the proposed method is widely known to perform better than a markov chain structure, which can explain why it improves significantly over Bit-swap [1] (another hierarchical VAE compression algorithm that uses bits back coding.)	O	O	Review	474
2.	O	O	Review	474
Increasing compression speed by implementing a vectorized version of ANS, and heaving an ANS head in the shape of a pair of arrays matching that of the latent variable and the observed variable.	O	O	Review	474
The latter allows for simultaneous encoding of the latent with the prior distribution and the image with the decoder distribution.	O	O	Review	474
3.	O	O	Review	474
Showing that a model trained on a low-resolution imagenet 32 dataset can generalize its compression capabilities to higher resolution datasets with convincing results.	O	O	Review	474
<sep> <sep> Decision: Accept.	O	O	Review	474
<sep> This paper is clearly written, makes clear claims and supports these claims with convincing experiments.	O	O	Review	474
The contributions are of practical use and I expect future work to benefit from this paper.	O	O	Review	474
<sep> <sep> <sep> Supporting arguments for decision:	O	O	Review	474
The paper is well motivated; off the shelf compression algorithms such as PNG are also not trained on every dataset separately, and cross-dataset generalization is important if this model should be used in practice for many different images from different datasets and of different resolutions.	O	O	Review	474
<sep> The paper clearly supports the main claims.	O	O	Review	474
It improves upon the previous bits-back coding-based hierarchical VAE [1]. The only hypothesis that is not checked is the one that hypothesizes that the lower bpd for higher resolution images is due to the lower ratio of edge pixels versus non-edge pixels, but this is not a dealbreaker from my point of view.	O	O	Review	474
<sep> <sep> I would like the authors to revise their statement of state of the art compression performance on page 7 directly below table 2. ‚	B-Review	B-1	Review	474
ÄúThe fact that HiLLoC achieves state of the art compression rates relative to the baselines even under a change of distribution is striking, and provides strong evidence of its efficacy as a general method for lossless compression of natural images‚Äù.	I-Review	I-1	Review	474
This is sentence should be made more nuanced as the proposed model only improves on Bit-Swap, but is still significantly outperformed by Local bits back coding (LBB [2]), and in the case of cifar-10 also by integer discrete flows (IDF [3]).	I-Review	I-1	Review	474
On the other hand, it would be useful to still state that LBB is trained on every dataset separately, as well as IDF.	I-Review	I-1	Review	474
Note also that in [3], a model that is trained on Imagenet32 and evaluated on the other datasets is also reported (see table 1 in [3]).	I-Review	I-1	Review	474
It would be beneficial for the author to include the scores of this model, as the proposed method seems to perform slightly better at generalizing to new datasets.	I-Review	I-1	Review	474
<sep> <sep> Because of the buffer of initial bits required by bit-back coding, the compression/decompression of several data points has to be sequential if one wants to amortize this cost over several data points.	B-Review	B-2	Review	474
Compression methods that don‚Äôt rely on bits-back coding, such as IDF [3], do not have this issue and can compress/decompress data points in parallel.	I-Review	I-2	Review	474
Since this influences the practical usability of the model, it would be transparent to mention this.	I-Review	I-2	Review	474
<sep> <sep> My final main question is on the equivalence of evaluation methods of Bit-Swap and Hilloc on imagenet.	B-Review	B-3	Review	474
The Bit-Swap paper states: ‚ÄúFor MNIST, CIFAR-10 and Imagenet (32 √ó 32) we report the bitrates, shown in Table 5, as a result of compressing 100 datapoints in sequence (averaged over 100 experiments)...‚Äù.	I-Review	I-3	Review	474
This means that Bit-Swap is not evaluated on the full test set of Imagenet 32 (as this contains 50000 images), as opposed to Hilloc.	I-Review	I-3	Review	474
Do the authors think this is a problem?	I-Review	I-3	Review	474
<sep> Furthermore, in the case of ‚Äúfull‚Äù Imagenet, Bit-swap uses a subset of 100 images for evaluation and crops them to a multiple of 32 pixels in height and width, so that bit-swap can compress patches and the result is the average of patches for on image.	B-Review	B-4	Review	474
Hilloc appears to take 500 random images and does not state anything about cropping.	I-Review	I-4	Review	474
Could the authors comment on this?	I-Review	I-4	Review	474
<sep> <sep> <sep> <sep> Additional feedback to improve paper (not part of decision assessment):	O	O	Review	474
- In the introduction, first paragraph: ‚Äú the method can achieve an expected message length equal to the variational free energy, often referred to as the evidence lower bound (ELBO) of the model. ‚	B-Review	B-5	Review	474
Äú ‚Üí ‚Äú the method can achieve an expected message length equal to the variational free energy, often referred to as the negative evidence lower bound (ELBO) of the model. ‚	I-Review	I-5	Review	474
Äú	I-Review	I-5	Review	474
- Section 3.2, last paragraph: It is not clear if in practice the latent and image are actually encoded in parallel as the author states that this is ‚Äúin theory‚Äù possible.	B-Review	B-6	Review	474
<sep> - Page 4: ‚Äú... we found that most of the compute time for our compression was spent in neural net inference, ‚Ä¶‚Äù I assume you mean ‚Äúinference‚Äù in any part of the encoder or decoder, and not specifically approximate inference of the encoder network.	B-Review	B-7	Review	474
Perhaps clarify this to avoid confusion?	I-Review	I-7	Review	474
<sep> - Section 4: When referring to the ResnetVAE by Kingma et al, it would be appropriate to also cite [4], as this is very similar to resnetVAE‚Äôs and was released earlier.	B-Review	B-8	Review	474
<sep> <sep> <sep> <sep> [1] F. H. Kingma, P. Abbeel, and J. Ho.	O	O	Review	474
Bit-Swap: recursive bits-back coding for lossless compression with hierarchical latent variables.	O	O	Review	474
In International Conference on Machine Learning (ICML), 2019.	O	O	Review	474
<sep> [2] Jonathan Ho, Evan Lohn, and Pieter Abbeel.	O	O	Review	474
Compression with Flows via Local Bits-Back Coding.	O	O	Review	474
arXiv e-prints, 2019.	O	O	Review	474
<sep> [3] Emiel Hoogeboom, Jorn W. T. Peters, Rianne van den Berg, and Max Welling.	O	O	Review	474
Integer Discrete Flows and Lossless Compression.	O	O	Review	474
arXiv e-prints, 2019.	O	O	Review	474
<sep> [4] C. K. S√∏nderby, T. Raiko, L. Maal√∏e, S. K. S√∏nderby, and O. Winther.	O	O	Review	474
Ladder variational autoencoders.	O	O	Review	474
In Advances in Neural Information Processing Systems (NIPS), 2016.	O	O	Review	474
<sep> <sep> Thank you for your review.	O	O	Reply	474
To address the points you raised:	O	O	Reply	474
<sep> &gt;I would like the authors to revise their statement of state of the art compression performance on page 7 directly below table 2. ...	O	O	Reply	474
It would be beneficial for the author to include the scores of [IDF generalization].	O	O	Reply	474
<sep> We have revised the statement below Table 2 to more accurately reflect the data in the table.	B-Reply	B-1	Reply	474
We have also added the results for IDF generalization to the table.	I-Reply	I-1	Reply	474
<sep> <sep> &gt;Because of the buffer of initial bits required by bit-back coding, the compression/decompression of several data points has to be sequential if one wants to amortize this cost over several data points.	O	O	Reply	474
Compression methods that don‚Äôt rely on bits-back coding, such as IDF [3], do not have this issue and can compress/decompress data points in parallel.	O	O	Reply	474
Since this influences the practical usability of the model, it would be transparent to mention this.	O	O	Reply	474
<sep> <sep> We have added mention of these models to the last paragraph of the Discussion section, where we felt this point fitted.	B-Reply	B-2	Reply	474
<sep> <sep> &gt;My final main question is on the equivalence of evaluation methods of Bit-Swap and Hilloc on imagenet.	O	O	Reply	474
The Bit-Swap paper states: ‚ÄúFor MNIST, CIFAR-10 and Imagenet (32 √ó 32) we report the bitrates, shown in Table 5, as a result of compressing 100 datapoints in sequence (averaged over 100 experiments)...‚Äù.	O	O	Reply	474
This means that Bit-Swap is not evaluated on the full test set of Imagenet 32 (as this contains 50000 images), as opposed to Hilloc.	O	O	Reply	474
Do the authors think this is a problem?	O	O	Reply	474
<sep> <sep> This implies that the Bit-Swap results may be noisier than ours.	B-Reply	B-3	Reply	474
They also give ‚Äòaverage net bitrate‚Äô values in tables 2-4, which are close to the values in their table 5.	I-Reply	I-3	Reply	474
We presume that the error bounds that they give are 2 standard deviations, from the empirical distribution of the ‚Äò100 experiments‚Äô they ran.	I-Reply	I-3	Reply	474
We think it‚Äôs likely that the figures they give are accurate enough to reasonably compare to ours.	I-Reply	I-3	Reply	474
<sep> <sep> &gt;Furthermore, in the case of ‚Äúfull‚Äù Imagenet, Bit-swap uses a subset of 100 images for evaluation and crops them to a multiple of 32 pixels in height and width, so that bit-swap can compress patches and the result is the average of patches for on image.	O	O	Reply	474
Hilloc appears to take 500 random images and does not state anything about cropping.	O	O	Reply	474
Could the authors comment on this?	O	O	Reply	474
<sep> <sep> We have updated our results after benchmarking on a larger subset of 2000 (not 500) images, and have updated the paper to reflect this.	B-Reply	B-4	Reply	474
The Bit-Swap result here may be affected by noise due to the smaller scale of their experiment, however again we have assumed that it is accurate enough for comparison.	I-Reply	I-4	Reply	474
The BitSwap images are indeed cropped so that the side lengths are multiples of 32.	I-Reply	I-4	Reply	474
For HiLLoC this was not necessary.	I-Reply	I-4	Reply	474
We think the comparison still makes sense even with this slight difference, and we have added a footnote to explain the difference between our full size ImageNet experiment and the one in Bit-Swap.	I-Reply	I-4	Reply	474

This paper proposes the idea of having an agent learning a policy that resets the agent's state to one of the states drawn from the distribution of starting states.	O	O	Review	374
The agent learns such policy while also learning how to solve the actual task.	O	O	Review	374
This approach generates more autonomous agents that require fewer human interventions in the learning process.	O	O	Review	374
This is a very elegant and general idea, where the value function learned in the reset task also encodes some measure of safety in the environment.	O	O	Review	374
<sep> <sep> All that being said, I gave this paper a score of 6 because two aspects that seem fundamental to me are not clear in the paper.	O	O	Review	374
If clarified, I'd happily increase my score.	O	O	Review	374
<sep> <sep> 1) *Defining state visitation/equality in the function approximation setting:* The main idea behind the proposed algorithm is to ensure that "when the reset policy is executed from any state, the distribution over final states matches the initial state distribution p_0".	B-Review	B-1	Review	374
This is formally described, for example, in line 13 of Algorithm 1.	I-Review	I-1	Review	374
<sep> The authors "define a set of safe states S_{reset} \subseteq S, and say that we are in an irreversible state if the set of states visited by the reset policy over the past N episodes is disjoint from S_{reset}." However, it is not clear to me how one can uniquely identify a state in the function approximation case.	I-Review	I-1	Review	374
Obviously, it is straightforward to apply such definition in the tabular case, where counting state visitation is easy.	I-Review	I-1	Review	374
However, how do we count state visitation in continuous domains?	I-Review	I-1	Review	374
Did the authors manually define the range of each joint/torque/angle that characterizes the start state?	I-Review	I-1	Review	374
In a control task from pixels, for example, would the exact configuration of pixels seen at the beginning be the start state?	I-Review	I-1	Review	374
Defining state visitation in the function approximation setting is not trivial and it seems to me the authors just glossed over it, despite being essential to your work.	I-Review	I-1	Review	374
<sep> <sep> 2) *Experimental design for Figure 5*: This setup is not clear to me at all and in fact, my first reaction is to say it is wrong.	B-Review	B-2	Review	374
An episodic task is generally defined as: the agent starts in a state drawn from the distribution of starting states and at the moment it reaches the goal state, the task is reset and the agent starts again.	I-Review	I-2	Review	374
It doesn't seem to be what the authors did, is that right?	I-Review	I-2	Review	374
The sentence: "our method learns to solve this task by automatically resetting the environment after each episode, so the forward policy can practice catching the ball when initialized below the cup" is confusion.	I-Review	I-2	Review	374
When is the task reset to the "status quo" approach?	I-Review	I-2	Review	374
Also, let's say an agent takes 50 time steps to reach the goal and then it decides to do a soft-reset.	I-Review	I-2	Review	374
Are the time steps it is spending on its soft-reset being taken into account when generating the reported results?	I-Review	I-2	Review	374
<sep> <sep> <sep> Some other minor points are:	O	O	Review	374
<sep> - The authors should standardize their use of citations in the paper.	B-Review	B-3	Review	374
Sometimes there are way too many parentheses in a reference.	I-Review	I-3	Review	374
For example: "manual resets are necessary when the robot or environment breaks (e.g. Gandhi et al (2017))", or "Our methods can also be used directly with any other Q-learning methods ((Watkins & Dayan, 1992; Mnih et al 2013; Gu et al 2017; Amos et al 2016; Metz et al 2017))"	I-Review	I-3	Review	374
<sep> - There is a whole line of work in safe RL that is not acknowledged in the related work section.	B-Review	B-4	Review	374
Representative papers are:	I-Review	I-4	Review	374
[1] Philip S. Thomas, Georgios Theocharous, Mohammad Ghavamzadeh: High-Confidence Off-Policy Evaluation.	I-Review	I-4	Review	374
AAAI 2015: 3000-3006	I-Review	I-4	Review	374
[2] Philip S. Thomas, Georgios Theocharous, Mohammad Ghavamzadeh: High Confidence Policy Improvement.	I-Review	I-4	Review	374
ICML 2015: 2380-2388	I-Review	I-4	Review	374
<sep> - In the Preliminaries Section the next state is said to be drawn from s_{t+1} ~ P(s'| s, a).	B-Review	B-5	Review	374
However, this hides the fact the next state is dependent on the environment dynamics and on the policy being followed.	I-Review	I-5	Review	374
I think it would be clearer if written: s_{t+1} ~ P(s'| s, \pi(a|s)).	I-Review	I-5	Review	374
<sep> <sep> - It seems to me that, in Algorithm 1, the name 'Act' is misleading.	B-Review	B-6	Review	374
Shouldn't it be 'ChooseAction' or 'EpsilonGreedy'?	I-Review	I-6	Review	374
If I understand correctly, the function 'Act' just returns the action to be executed, while the function 'Step' is the one that actually executes the action.	I-Review	I-6	Review	374
<sep> <sep> - It is absolutely essential to depict the confidence intervals in the plots in Figure 3.	B-Review	B-7	Review	374
Ideally we should have confidence intervals in all the plots in the paper.	I-Review	I-7	Review	374
We thank Reviewer 4 for the comments and for finding our paper a ‚Äúvery elegant and general idea.	O	O	Reply	374
‚Äù The main comments had to do with clarity - we have addressed these in the revised version.	O	O	Reply	374
We would appreciate of the reviewer would reevaluate the paper given the new clarifications.	O	O	Reply	374
<sep> <sep> 1. (	O	O	Reply	374
State visitation) We implement our algorithm in a way that avoids having to test whether two states are equal (indeed, a challenging problem).	B-Reply	B-1	Reply	374
In Equation 4, we define the set of safe states S_{reset} implicitly using the reset reward function r_r(s).	I-Reply	I-1	Reply	374
In particular, we say a state is safe if the the reset reward is greater than some threshold (0.7 in our experiments).	I-Reply	I-1	Reply	374
For example, in the pusher task, the reset reward is the distance from a certain (x, y, z) point, so S_{reset} is the set of points within some distance of this point.	I-Reply	I-1	Reply	374
We added a comment to line 13 of the algorithm clarifying how we test if a state is in S_{reset}.	I-Reply	I-1	Reply	374
<sep> 2. (	O	O	Reply	374
Figure 5) We clarified our description of the environments in Section 6 paragraph 1 to note that the episode is not terminated when the agent reaches a goal state.	B-Reply	B-2	Reply	374
For the experiment in Figure 5, the ‚Äòforward-only‚Äô baseline and our method are non-episodic - the environment is never reset and no hard resets are used (Section 6.1).	I-Reply	I-2	Reply	374
The ‚Äòstatus quo‚Äô baseline is episodic, doing a hard reset every T time steps (for ball in cup, T = 200 steps).	I-Reply	I-2	Reply	374
We reworded the confusing sentence about our method as follows: ‚ÄúIn contrast, our method learns to solve this task by automatically resetting the environment after each attempt, so the forward policy can practice catching the ball without hard resets.	I-Reply	I-2	Reply	374
‚Äù All results in the paper include time steps for both the forward task and the reset task.	I-Reply	I-2	Reply	374
We clarified this in Section 6.1 paragraph 1.	I-Reply	I-2	Reply	374
This highlights a strength of our method: even though the agent spends a considerable amount of time learning the reset task, it still learns to do the forward task in roughly the same number of total steps (steps for forward task + steps for reset task).	I-Reply	I-2	Reply	374
<sep> <sep> <sep> Minor points:	O	O	Reply	374
<sep> 1.	O	O	Reply	374
Citations.	O	O	Reply	374
We‚Äôve removed the extra parenthesis for the Q-learning references.	B-Reply	B-3	Reply	374
Generally, we use ‚Äúe.g.	I-Reply	I-3	Reply	374
‚Äù in citations when the citation is an example of the described behavior.	I-Reply	I-3	Reply	374
<sep> <sep> 2.	B-Reply	B-4	Reply	374
Thanks for the additional references!	I-Reply	I-4	Reply	374
We‚Äôve included them in Section 2 paragraph 1.	I-Reply	I-4	Reply	374
<sep> <sep> 3.	O	O	Reply	374
We chose to separate out the policy from the transition dynamics.	B-Reply	B-5	Reply	374
Action a_{t} is sampled from \pi(a_{t} | s_{t}) and depends on the policy; next state s_{t} is sampled from P(s_{t+1} | s_{t}, a_{t}) and depends on the transition dynamics.	I-Reply	I-5	Reply	374
<sep> <sep> 4.	O	O	Reply	374
Good idea.	B-Reply	B-6	Reply	374
We‚Äôve  changed ‚ÄúAct()‚Äù to ‚ÄúChooseAction()‚Äù in Algorithm 1.	I-Reply	I-6	Reply	374
<sep> <sep> 5.	B-Reply	B-7	Reply	374
For Figure 3, we agree confidence intervals would be helpful.	I-Reply	I-7	Reply	374
We can‚Äôt regenerate the plot in the next 24 hours before the rebuttal deadline, but will include confidence intervals in the camera-ready version.	I-Reply	I-7	Reply	374

(This delayed review is based on the deadline version of the paper.)	O	O	Review	374
<sep> <sep> This paper proposes to learn by RL a reset policy at the same time that we learn the forward policy, and use the learned reset Q-function to predict and avoid actions that would prevent reset ‚Äî an indication that they are "unsafe" in some sense.	O	O	Review	374
<sep> <sep> This idea (both parts) is interesting and potentially very useful, particularly in physical domains where reset is expensive and exploration is risky.	O	O	Review	374
While I'm sure the community can benefit from ideas of this kind, it really needs clearer presentations of such ideas.	B-Review	B-10	Review	374
I can appreciate the very intuitive and colloquial style of the paper, however the discussion of the core idea would benefit from some rigor and formal definitions.	I-Review	I-10	Review	374
<sep> <sep> Examples of intuitive language that could be hiding the necessary complexities of a more formal treatment:	O	O	Review	374
<sep> 1.	B-Review	B-1	Review	374
In the penultimate paragraph of Section 1, actions are described as "reversible", while a stochastic environment may be lacking such a notion altogether (i.e. there's no clear inverse if state transitions are not deterministic functions).	I-Review	I-1	Review	374
<sep> <sep> 2.	B-Review	B-2	Review	374
It's not clear whether the authors suggest that the ability to reset is a good notion of safety, or just a proxy to such a notion.	I-Review	I-2	Review	374
This should be made more explicit, making it clearer what this proxy misses: states where the learned reset policy fails (whether due to limited controllability or errors in the policy), that are nonetheless safe.	I-Review	I-2	Review	374
<sep> <sep> 3.	B-Review	B-3	Review	374
In the last paragraph of Section 3, a reset policy is defined as reaching p_0 from *any* state.	I-Review	I-3	Review	374
This is a very strong requirement, which isn't even satisfiable in most domains, and indeed the reset policies learned in the rest of the paper don't satisfy it.	I-Review	I-3	Review	374
<sep> <sep> 4.	B-Review	B-4	Review	374
What are p_0 and r_r in the experiments?	I-Review	I-4	Review	374
What is the relation between S_{reset} and p_0?	I-Review	I-4	Review	374
Is there a discount factor?	I-Review	I-4	Review	374
<sep> <sep> 5.	B-Review	B-5	Review	374
In the first paragraph of Section 4.1, states are described as "irreversible" or "irrecoverable".	I-Review	I-5	Review	374
Again, in a stochastic environment a more nuanced notion is needed, as there may be policies that take a long time to reset from some states, but do so eventually.	I-Review	I-5	Review	374
<sep> <sep> 6.	O	O	Review	374
A definition of a "hard" reset would make the paper clearer.	B-Review	B-6	Review	374
<sep> <sep> 7.	B-Review	B-7	Review	374
After (1), states are described as "allowed".	I-Review	I-7	Review	374
Again, preventing actions that are likely to hinder reset cannot completely prevent any given state in a stochastic environment.	I-Review	I-7	Review	374
It also seems that (2) describes states where some allowed action can be taken, rather than states reachable by some allowed action.	I-Review	I-7	Review	374
For both reasons, Algorithm 1 does not prevent reaching states outside S*, so what is the point of that definition?	I-Review	I-7	Review	374
<sep> <sep> 8.	B-Review	B-8	Review	374
The paper is not explicit about the learning dynamics of the reset policy.	I-Review	I-8	Review	374
It should include a figure showing the learning curve of this policy (or some other visualization), and explain how the reset policy can ever gain experience and learn to reset from states that it initially avoids as unsafe.	I-Review	I-8	Review	374
<sep> <sep> 9.	B-Review	B-9	Review	374
Algorithm 1 is unclear on how a failed reset is identified, and what happens in such case ‚Äî do we run another forward episode?	I-Review	I-9	Review	374
Another reset episode?	I-Review	I-9	Review	374
Thank you for the comments!	O	O	Reply	374
It seems that all the concerns have to do with the writing in the paper and are straightforward to fix.	O	O	Reply	374
We have addressed all the concerns raised about the paper in this review.	O	O	Reply	374
Given that all issues have been addressed, we would appreciate if the reviewer could take another look at the paper.	O	O	Reply	374
<sep> <sep> 1.	B-Reply	B-1	Reply	374
We have clarified our definition of reversible action in Section 1 paragraph 4.	I-Reply	I-1	Reply	374
For deterministic MDPs, we say an action is reversible if it leads to a state from which there exists a reset policy that can return to a state with high density under the initial state distribution.	I-Reply	I-1	Reply	374
For stochastic MDPs, we say an action is reversible if the probability that an oracle reset policy that can reset from the next state is greater than some safety threshold.	I-Reply	I-1	Reply	374
Note that definition for deterministic MDPs is a special case of the definition for stochastic MDPs.	I-Reply	I-1	Reply	374
<sep> <sep> 2.	O	O	Reply	374
The ability of an oracle reset policy to reset is a good notion of safety.	B-Reply	B-2	Reply	374
In our algorithm, we approximate this notion of safety, assuming that whether our learned reset policy can reset in N episodes is a good proxy for whether an oracle reset policy can reset.	I-Reply	I-2	Reply	374
We have clarified Section 1 paragraph 4 to make this distinction clear.	I-Reply	I-2	Reply	374
We also added Appendix B to discuss handling errors in Q value estimation.	I-Reply	I-2	Reply	374
In this section, we describe how Leave No Trace copes with overestimates and underestimates of Q values.	I-Reply	I-2	Reply	374
<sep> <sep> 3.	B-Reply	B-3	Reply	374
We have corrected this technical error in Section 3 paragraph 2 by redefining the reset policy as being able to reach p_0 from any state reached by the forward policy.	I-Reply	I-3	Reply	374
That our learned reset policy only learns to reset from states reached by the forward policy is indeed a limitation of our method.	I-Reply	I-3	Reply	374
However, note that early aborts help the forward policy avoid visiting states from which the reset policy is unable to reach p_0.	I-Reply	I-3	Reply	374
<sep> <sep> 4.	B-Reply	B-4	Reply	374
For the continuous control environments, the initial state distribution p_0 is uniform distribution centered at a ‚Äústart pose.	I-Reply	I-4	Reply	374
‚Äù  We use a discount factor \gamma = 0.99.	I-Reply	I-4	Reply	374
Both details have been noted in Appendix F.3 paragraph 2.	I-Reply	I-4	Reply	374
The reset reward r_r is a hand-crafted approximation to p_0.	I-Reply	I-4	Reply	374
For example, in the Ball in Cup environment, r_r is proportional to the negative L2 distance from the ball to the origin (below the cup).	I-Reply	I-4	Reply	374
For cliff cheetah, r_r includes one term that is proportional to the distance of the cheetah to the origin, and another term indicating whether the cheetah is standing.	I-Reply	I-4	Reply	374
S_{reset} is the set of states where r_r(s) is greater than 0.7 (Appendix C.3 paragraph 2)	I-Reply	I-4	Reply	374
<sep> 5.	B-Reply	B-5	Reply	374
We have clarified Section 4.1 paragraph 1 to explain how our proposed algorithm handles both cases: states from which it is impossible to reset and states from which resetting would take prohibitively many steps.	I-Reply	I-5	Reply	374
In both cases, the cumulative discounted reward (and hence the value function) will be low.	I-Reply	I-5	Reply	374
By performing an early abort when the value function is low, we avoid both cases.	I-Reply	I-5	Reply	374
<sep> <sep> 6.	B-Reply	B-6	Reply	374
We added a definition of ‚Äúhard reset‚Äù to Section 4.2 paragraph 1: A hard reset is an action that resamples that state from the initial state distribution.	I-Reply	I-6	Reply	374
Hard resets are available to an external agent (e.g. a human) but not the learned agent.	I-Reply	I-6	Reply	374
<sep> <sep> 7.	B-Reply	B-7	Reply	374
We acknowledge that the proposed algorithm does not guarantee that we never visit unsafe states.	I-Reply	I-7	Reply	374
In Appendix A, we have added a proof that Leave No Trace would only visit states that are safe in expectation if it had access to the true Q values.	I-Reply	I-7	Reply	374
Appendix A.3 discusses the approximations we make in practice that can cause Leave No Trace to visit unsafe states.	I-Reply	I-7	Reply	374
Finally, Appendix B discusses how Leave No Trace handles errors incurred by over/under-estimates of Q values.	I-Reply	I-7	Reply	374
<sep> <sep> 8.	B-Reply	B-8	Reply	374
Newly added Appendix D visualizes the training dynamics by plotting the number of time steps in each episode before an early abort.	I-Reply	I-8	Reply	374
Initially, early aborts occur near the initial state distribution, so the forward episode lengths are quite short.	I-Reply	I-8	Reply	374
As the reset policy improves, early aborts occur further from the initial state, as indicated by longer forward episode lengths.	I-Reply	I-8	Reply	374
Newly added Appendix B discusses how Leave No Trace handles errors incurred by over/under-estimates of Q values.	I-Reply	I-8	Reply	374
It describes how Leave No Trace learns that an ‚Äúunsafe‚Äù state is actually safe.	I-Reply	I-8	Reply	374
<sep> <sep> 9.	B-Reply	B-9	Reply	374
We detect failed resets in line 12 of Algorithm 1.	I-Reply	I-9	Reply	374
We have added a comment to help clarify this.	I-Reply	I-9	Reply	374
When a failed reset is detected, a hard reset occurs (line 13).	I-Reply	I-9	Reply	374

The paper solves the problem of how to do autonomous resets, which is an important problem in real world RL.	O	O	Review	374
The method is novel, the explanation is clear, and has good experimental results.	O	O	Review	374
<sep> Pros:	O	O	Review	374
1.	O	O	Review	374
The approach is simple, solves a task of practical importance, and performs well in the experiments.	O	O	Review	374
<sep> 2.	O	O	Review	374
The experimental section performs good ablation studies wrt fewer reset thresholds, reset attempts, use of ensembles.	O	O	Review	374
<sep> <sep> Cons:	O	O	Review	374
1.	O	O	Review	374
The method is evaluated only for 3 tasks, which are all in simulation, and on no real world tasks.	B-Review	B-1	Review	374
Additional tasks could be useful, especially for qualitative analysis of the learned reset policies.	I-Review	I-1	Review	374
<sep> 2.	O	O	Review	374
It seems that while the method does reduce hard resets, it would be more convincing if it can solve tasks which a model without a reset policy couldnt.	B-Review	B-2	Review	374
Right now, the methods without the reset policy perform about equally well on final reward.	I-Review	I-2	Review	374
<sep> 3.	O	O	Review	374
The method wont be applicable to RL environments where we will need to take multiple non-invertible actions to achieve the goal (an analogy would be multiple levels in a game).	B-Review	B-3	Review	374
In such situations, one might want to use the reset policy to go back to intermediate ‚Äústart‚Äù states from where we can continue again, rather than the original start state always.	I-Review	I-3	Review	374
<sep> <sep> Conclusion/Significance: The approach is a step in the right direction, and further refinements can make it a significant contribution to robotics work.	O	O	Review	374
<sep> <sep> Revision: Thanks to the authors for addressing the issues I raised, I revise my review to 7	O	O	Review	374
We thank AnonReviewer3 for recognizing the importance of the problem we aim to solve, and for noting that our simple method is supported with ‚Äúgood ablation studies.	O	O	Reply	374
‚Äù We have addressed the issues raised by the reviewer, as discussed below:	O	O	Reply	374
<sep> 1.	B-Reply	B-1	Reply	374
We have run experiments on two additional environments (ball in cup and peg insertion), so the revised version of the paper shows experiments on 5 simulated environments (Section 6, paragraph 1).	I-Reply	I-1	Reply	374
Videos of the learned policies visualize the learned forward + reset policies are available on the project website: <a href="https://sites.google.com/site/mlleavenotrace/" target="_blank" rel="nofollow">https://sites.google.com/site/mlleavenotrace/</a>	I-Reply	I-1	Reply	374
Experimental evaluation of five distinct domains compares favorably to most RL papers that have appeared in ICLR in the past.	I-Reply	I-1	Reply	374
While we agree that real-world evaluation of our method would be excellent, this is going substantially beyond the typical evaluation for ICLR RL work.	I-Reply	I-1	Reply	374
<sep> <sep> 2.	B-Reply	B-2	Reply	374
We ran additional environments that show that, in certain difficult situations, our method can solve tasks which a model without a reset policy cannot.	I-Reply	I-2	Reply	374
Newly-added Sections 6.1 and 6.6 demonstrate this result in two settings.	I-Reply	I-2	Reply	374
We summarize these results below in a separate post entitled ‚ÄúAdditional Experiments.	I-Reply	I-2	Reply	374
‚Äù	I-Reply	I-2	Reply	374
<sep> 3.	B-Reply	B-3	Reply	374
We expanded Section 4 paragraph 2 to clarify our assumption that there exists a reversible goal state.	I-Reply	I-3	Reply	374
This is indeed a limitation of our approach, which we note in the paper (Section 4 paragraph 2).	I-Reply	I-3	Reply	374
We show experimentally that our method can be applied to a number of realistic tasks, such as locomotion and manipulation.	I-Reply	I-3	Reply	374
Extending our work to tasks with irreversible goal states by resetting to intermediate goals is a great idea, and would make for interesting future work.	I-Reply	I-3	Reply	374

If one is committed to doing value-function or policy-based RL for an episodic task on a real physical system, then one has to come up with a way of resetting the domain for new trials.	O	O	Review	374
This paper proposes a good way of doing this:  learn a policy for resetting at the same time as learning a policy for solving the problem.	O	O	Review	374
As a side effect, the Q values associated with the reset policy can be used to predict when the system is about to enter an unrecoverable state and "forbid" the action.	O	O	Review	374
<sep> <sep> It is, of course, necessary that the domain be, in fact, reversible  (or, at least, that it be possible to reach a starting state from at least one goal state--and it's better if that goal state is not significantly harder to reach than other goal states.	B-Review	B-4	Review	374
<sep> <sep> There were a couple of places in the paper that seemed to be to be not strictly technically correct.	O	O	Review	374
<sep> <sep> It says that the reset policy is designed to achieve a distribution of final states that is equivalent to a starting distribution on the problem.	B-Review	B-1	Review	374
This is technically fairly difficult, as a problem, and I don't think it can be achieved through standard RL methods.	I-Review	I-1	Review	374
Later, it is clearer that there is a set of possible start states and they are all treated as goal states from the perspective of the reset policy.	I-Review	I-1	Review	374
That is a start set, not a distribution.	I-Review	I-1	Review	374
And, there's no particular reason to think that the reset policy will not, for example, always end up returning to a particular state.	I-Review	I-1	Review	374
<sep> <sep> Another point is that training a set of Q functions from different starting states generates some kind of an ensemble, but I don't think you can guarantee much about what sort of a distribution on values it will really represent.	B-Review	B-2	Review	374
Q learning + function approximation can go wrong in a variety of ways, and so some of these values might be really gross over or under estimates of what can be achieved even by the policies associated with those values.	I-Review	I-2	Review	374
<sep> <sep> A final, higher-level, methodological concern is that, it seems to me, as the domains become more complex, rather than trying to learn two (or more) policies, it might be more effective to take a model-based approach, learn one model, and do reasoning to decide how to return home (and even to select from a distribution of start states) and/or to decide if a step is likely to remove the robot from the "resettable" space.	B-Review	B-3	Review	374
<sep> <sep> All this aside, this seems like a fairly small but well considered and executed piece of work.	O	O	Review	374
I'm rating it as marginally above threshold, but I indeed find it very close to the threshold.	O	O	Review	374
We thank AnonReviewer1 for noting the main goal of our paper and recognizing how we incorporate safety using the learned reset policy, and further thank the reviewer for finding our paper a ‚Äúwell considered and executed piece of work.	O	O	Reply	374
‚Äù We‚Äôve addressed the concerns raised by the reviewer with clarifications in the main text, which we detail below.	O	O	Reply	374
<sep> <sep> Assumption that environment is reversible - This assumption is indeed a limitation of our approach, which we note in the paper (Section 4 paragraph 2).	B-Reply	B-4	Reply	374
We have expanded this section to clarify this detail.	I-Reply	I-4	Reply	374
We show experimentally that our method can be applied to a number of realistic tasks, such as locomotion and manipulation.	I-Reply	I-4	Reply	374
Extending our work to tasks with irreversible goal states is a great idea, and would make for interesting future work.	I-Reply	I-4	Reply	374
<sep> <sep> Initial state distribution - You correctly note that the reset policy might always reset to the same state, thus failing to sample from the full initial state distribution.	B-Reply	B-1	Reply	374
We have corrected this technical error in the revised version of the paper (Section 4, paragraph 2) by adding the additional assumption that the initial state distribution be unimodal and have narrow support.	I-Reply	I-1	Reply	374
We also expanded the discussion of ‚Äúsafe sets‚Äù in Section 4.2 paragraph 1 to clarify the difference between the initial state distribution, the reset policy‚Äôs reward, and the safe set.	I-Reply	I-1	Reply	374
We also describe a method to detect if there is mismatch between the the initial state distribution and the reset policy final state distribution.	I-Reply	I-1	Reply	374
<sep> <sep> Q functions - We learn an ensemble of Q functions, each of which is a sampled from the posterior distribution over Q functions given the observed data.	B-Reply	B-2	Reply	374
We expanded Section 4.4 paragraph 1 to note how this technique has been established in previous work (‚ÄúDeep Exploration via Bootstrapped DQN‚Äù [Osband 2016] and ‚ÄúUCB Exploration via Q-Ensembles‚Äù [Chen 2017]).	I-Reply	I-2	Reply	374
In general, we are not guaranteed that samples from a distribution are close to its mean.	I-Reply	I-2	Reply	374
However, our experiments on ensemble aggregation (taking the min, mean or max over the Q functions) had little effect on policy reward.	I-Reply	I-2	Reply	374
If ‚Äúgross under/over-estimation‚Äù had occurred, taking the min/max over the ensemble would have resulted in markedly lower reward.	I-Reply	I-2	Reply	374
We expanded Appendix A paragraph 2 to explain this finding.	I-Reply	I-2	Reply	374
<sep> <sep> Model-based alternative - We appreciate the comment regarding a potential model-based alternative to our method.	B-Reply	B-3	Reply	374
However, we are not aware of any past model-based methods for solving this task.	I-Reply	I-3	Reply	374
We would be happy to attempt a comparison or add a discussion if the reviewer has a particular prior method in mind.	I-Reply	I-3	Reply	374
The early aborts in our method provide one method of identifying irreversible states.	I-Reply	I-3	Reply	374
A model-based alternative could also serve this function.	I-Reply	I-3	Reply	374
We believe that our early aborts, which only require learning a single reset policy, are simpler than learning a model of the environment dynamics and hypothesize that our approach will scale better to complex environments.	I-Reply	I-3	Reply	374

Summary of the paper	O	O	Review	374
The authors benchmark 11 model-based and 4 model-free RL algorithms on 18 environments, based on OpenAI Gym.	O	O	Review	374
<sep> The performance in each case is averaged across 4 different seeds.	O	O	Review	374
Computation time is also reported.	O	O	Review	374
<sep> Furthermore, the authors analyze the performance hit incurred from adding noise to the observations and to the actions	O	O	Review	374
Finally, the authors propose to characterize what hinders the performance of model-based methods, ie.,	O	O	Review	374
what they call the dynamics bottlenecks, the planning horizon dilemma, and the early termination dilemma.	O	O	Review	374
<sep> As a conclusion, it turns out no clear winner stands out, which motivates further development of model-based approaches.	O	O	Review	374
<sep> <sep> Strong and weak points	O	O	Review	374
This is a very interesting empirical study, especially since	O	O	Review	374
- it includes a comparison with model-free algorithms,	O	O	Review	374
- it considers computational aspects and indicates what algorithms can be run in real-time,	O	O	Review	374
- the authors use open-source software (PyBullet) as simulators, which makes the study more reproducible (although the code has not been shared yet)	O	O	Review	374
<sep> But,	O	O	Review	374
- 4 seeds averaged across is clearly low, given the well-known variance of RL algorithms.	B-Review	B-1	Review	374
In fact, the std values in the tables prove this point.	I-Review	I-1	Review	374
I understand the benchmark is heavy on computation, however, this would only have delayed the output of the numbers without requiring more work (and admittedly, been even more harmful for the ecology...).	I-Review	I-1	Review	374
<sep> - Not as a criticism but rather a suggestion, it would have been useful to summarize the table 2 by comparing the algorithms using normalized values (mean = 0, std = 1) averaged across the environments.	B-Review	B-2	Review	374
<sep> - One the (strongest) weak points for me remains the assumption of the given differentiable reward function, as learning the reward function might be challenging for the model, for instance when it is sparse.	B-Review	B-3	Review	374
<sep> - It is also surprising that the authors did not benchmark against nor cite (Ha, David, and J√ºrgen Schmidhuber. ‚	B-Review	B-4	Review	374
ÄúRecurrent world models facilitate policy evolution.	I-Review	I-4	Review	374
‚Äù NeurIPS 2018), especially since the code is open-source.	I-Review	I-4	Review	374
<sep> - I would have made the same remark for (Learning Latent Dynamics for Planning from Pixels,  Hafner et al) but the paper does not seem to be not peer-reviewed.	B-Review	B-5	Review	374
Edit: the paper is indeed published at ICML 2019.	I-Review	I-5	Review	374
So the remark holds.	I-Review	I-5	Review	374
<sep> <sep> Question:	O	O	Review	374
- could the author elaborate on the early termination?	B-Review	B-6	Review	374
it is not precisely defined anywhere and yet, seems to be an important point.	I-Review	I-6	Review	374
<sep> <sep> Minor	B-Review	B-7	Review	374
- page 3, parentheses around Finn et al (2017)	I-Review	I-7	Review	374
- page 3, ILQG, ‚Äúis an model‚Äù	I-Review	I-7	Review	374
We thank the reviewer for the acknowledgement and suggestions for the project.	O	O	Reply	374
And we address the following questions.	O	O	Reply	374
<sep> <sep> - Q1: 4 seeds averaged across is clearly low, given the well-known variance of RL algorithms.	O	O	Reply	374
I understand the benchmark is heavy on computation, however, this would only have delayed the output of the numbers without requiring more work (and admittedly, been even more harmful for the ecology...).	O	O	Reply	374
<sep> <sep> We thank again for your consideration and understanding!	B-Reply	B-1	Reply	374
Ideally we hope we can run much more random seeds, but some of the algorithms take quite a long time to run and are expensive economically and ecologically.	I-Reply	I-1	Reply	374
And while the std value is big, the mean values for many MBRL algorithms are relatively stable across different seeds, compared with MFRL algorithms.	I-Reply	I-1	Reply	374
<sep> Therefore we decided to trade-off here and release the code for future researchers.	I-Reply	I-1	Reply	374
<sep> <sep> - Q2: it would have been useful to summarize the table 2 by comparing the algorithms using normalized values (mean = 0, std = 1) averaged across the environments.	O	O	Reply	374
<sep> <sep> We thank the reviewer for the advice.	B-Reply	B-2	Reply	374
We now show the mean values and the std of different algorithms across environments in appendix C Table 18.	I-Reply	I-2	Reply	374
<sep> <sep> - Q3: One (strongest) weak points for me remains the assumption of the given differential reward function, as learning the reward function might be challenging for the model, for instance when it is sparse.	O	O	Reply	374
<sep> <sep> We are hoping we can summarize and evaluate the majority of existing MBRL algorithms by making this assumption.	B-Reply	B-3	Reply	374
<sep> Some of the algorithms such as iLQG can only be evaluated under this assumption.	I-Reply	I-3	Reply	374
<sep> We agree that tasks with sparse / unknown reward function is very important for the future of MBRL and but we leave it for future research.	I-Reply	I-3	Reply	374
<sep> <sep> - Q4: Comparison and citation to worldmodel (David Ha, etc.)	O	O	Reply	374
and PlaNet (Danijar etc.).	O	O	Reply	374
<sep> <sep> We added citation and comparison of the two algorithms in the latest revision.	B-Reply	B-4	Reply	374
<sep> Our benchmark consists of tasks with observation from the states.	I-Reply	I-4	Reply	374
Both worldmodel and PlaNet are algorithms for tasks with images as observation, which are harder problems but essentially  they have the same RL formulation.	I-Reply	I-4	Reply	374
<sep> Worldmodel can be regarded as a special case of Dyna algorithm, and PlaNet can be regarded as a special case of PETS-CEM algorithm, with both of them designing an elegant framework to learn representations from images.	I-Reply	I-4	Reply	374
Therefore we didn‚Äôt benchmark them in the paper.	I-Reply	I-4	Reply	374

This paper presents a systematic empirical evaluation of model-based RL algorithms on (mostly) continuous control environments from OpenAI Gym, with comparison to popular model-free algorithms.	O	O	Review	374
It identifies three challenges for model-based RL, learning the dynamics, selecting the planning horizon, and applying early termination to guide learning.	O	O	Review	374
<sep> <sep> A systematic comparison of model-based RL algorithms is missing from the literature, and I believe that this paper does a fairly thorough job of providing such a comparison.	B-Review	B-1	Review	374
A wide range of algorithms are selected, and the environments are representative of those commonly used in the literature.	I-Review	I-1	Review	374
The first two challenges identified have been recognized in the literature.	I-Review	I-1	Review	374
For example, Vemula et al (2019) [1] discuss the planning horizon in random search RL algorithms.	I-Review	I-1	Review	374
<sep> <sep> However, I would like to see some results on the policy search algorithms such as PILCO in Section 4.5, even if they are on the simpler environments.	B-Review	B-2	Review	374
Currently they are not represented in Table 4.	I-Review	I-2	Review	374
<sep> <sep> Minor comment:	O	O	Review	374
1.	O	O	Review	374
There are several instances where the writing should be clarified, e.g. acronyms are not explained before they are used.	B-Review	B-3	Review	374
For example, it would be helpful to the reader to define GT-CEM and GT-RS in Section 3, especially as Table 1 (page 6) comes before the text discussing those two algorithms (page 7).	I-Review	I-3	Review	374
<sep> 2.	O	O	Review	374
Table 1 is a bit difficult to parse.	B-Review	B-4	Review	374
Maybe it could be split up, or some algorithms/environments deferred to the appendix.	I-Review	I-4	Review	374
<sep> <sep> [1] Vemula, Anirudh, Wen Sun, and J. Bagnell. "	O	O	Review	374
Contrasting Exploration in Parameter and Action Space: A Zeroth-Order Optimization Perspective."	O	O	Review	374
The 22nd International Conference on Artificial Intelligence and Statistics.	O	O	Review	374
2019.	O	O	Review	374
<sep> <sep> We would like to apologize for the writing of the paper.	O	O	Reply	374
We updated the paper and hope it has increased its clarity.	O	O	Reply	374
<sep> We thank the reviewer for the acknowledgement and suggestions for the project, and we address the following questions.	O	O	Reply	374
<sep> <sep> - Q1: The first two challenges identified have been recognized in the literature.	O	O	Reply	374
For example, Vemula et al (2019) [1] discuss the planning horizon in random search RL algorithms.	O	O	Reply	374
<sep> <sep> We would like to thank the reviewer for the reference and we have updated them in the latest revision.	B-Reply	B-1	Reply	374
<sep> <sep> - Q2: However, I would like to see some results on the policy search algorithms such as PILCO in Section 4.5, even if they are on the simpler environments.	O	O	Reply	374
Currently they are not represented in Table 4.	O	O	Reply	374
<sep> <sep> We didn‚Äôt include the performance of PILCO as PILCO is very expensive to train in terms of the time and computation resources (potentially 120 hours for 200k time-steps for 1 random seed).	B-Reply	B-2	Reply	374
<sep> For simple environments, PILCO can usually solve the task within a few episodes, but can not solve high dimensional problems regardless of the training efforts, which can also be shown in Appendix C.	I-Reply	I-2	Reply	374
We updated the results for SVG in the appendix.	I-Reply	I-2	Reply	374
<sep> For HalfCheetah, Ant, Walker2D and Hopper, the performances of SVG are respectively	I-Reply	I-2	Reply	374
|      HalfCheetah     |          Ant           |        Walker2D         |        Hopper          |	I-Reply	I-2	Reply	374
|     578.7¬±239.1       |    472.0¬±48.1     |    -1168.2¬±537.2      |    -753.4¬±580.8      |	I-Reply	I-2	Reply	374
<sep> -  Q3: There are several instances where the writing should be clarified. -.	O	O	Reply	374
Table 1 is a bit difficult to parse.	O	O	Reply	374
<sep> We thank the reviewer for the suggestions and updated the paper accordingly.	B-Reply	B-4	Reply	374
<sep> We fixed missing references and clarified the definition of acronyms before they are referred to.	I-Reply	I-4	Reply	374
<sep> <sep> <sep> We hope that our response has addressed the main concerns, and we also refer to general response for other updates.	O	O	Reply	374
<sep> <sep> [1] Vemula, Anirudh, Wen Sun, and J. Bagnell. "	O	O	Reply	374
Contrasting Exploration in Parameter and Action Space: A Zeroth-Order Optimization Perspective."	O	O	Reply	374
The 22nd International Conference on Artificial Intelligence and Statistics.	O	O	Reply	374
2019.	O	O	Reply	374

# Summary	O	O	Review	374
<sep> This paper presents a BERT-inspired pretraining/finetuning setup for source code tasks.	O	O	Review	374
It collects a corpus of	O	O	Review	374
unlabeled Python files for BERT pretraining, designs or adopts 5 tasks on established smaller-scale Python corpora, and	O	O	Review	374
adjusts the BERT model to tokenize and encode source code snippets appropriately.	O	O	Review	374
<sep> <sep> # Strengths	O	O	Review	374
<sep> * The idea of applying the pretraining/finetuning paradigm to program analysis tasks makes sense, and has been	O	O	Review	374
informally attempted by multiple groups in the community in 2019.	O	O	Review	374
This is the first high-quality submission to a	O	O	Review	374
top-tier ML conference I've seen on the subject, though.	O	O	Review	374
<sep> * The authors exercised commendable care and diligence in preparing the training data, adopting BERT to source code	O	O	Review	374
inputs, and ensuring correctness of the experimental setup.	O	O	Review	374
I appreciated all the provided details on tokenization	O	O	Review	374
(Section 3.3), deduplication (Sections 3.1-3.2), and task setup (Section 3.5).	O	O	Review	374
This should become a technical standard	O	O	Review	374
in the community.	O	O	Review	374
<sep> * The paper is written clearly and concisely, and is generally a pleasure to read.	O	O	Review	374
<sep> <sep> # Weaknesses	O	O	Review	374
<sep> I have a gripe with the authors' choice to ignore program structure (e.g. abstract syntax trees) or features (e.g.	B-Review	B-1	Review	374
types) in their program representation.	I-Review	I-1	Review	374
Without this extra information (easily available from a compiler/interpreter	I-Review	I-1	Review	374
API) the pipeline is not substantially different from the original NLP pipeline of BERT et al The main program-related	I-Review	I-1	Review	374
representation insight comes in tokenization (Section 3.3) and the definition of "sentences".	I-Review	I-1	Review	374
To repeat, I appreciate	I-Review	I-1	Review	374
the effort the authors put in making tokenization appropriate for BERT processing of source code, but this is a drop in	I-Review	I-1	Review	374
the bucket compared to the all the other program-related features the work is leaving off the table.	I-Review	I-1	Review	374
Programs are not	I-Review	I-1	Review	374
natural language.	I-Review	I-1	Review	374
<sep> The argument that source code analysis would "pass on the burden ... to downstream tasks" (Page 3) is odd.	B-Review	B-2	Review	374
First, most	I-Review	I-2	Review	374
downstream tasks of interest occur in the settings where this analysis is already available: IDEs, code review	I-Review	I-2	Review	374
assistants, linters, etc.	I-Review	I-2	Review	374
Second, one often needs program analysis to even define downstream tasks in the first place --	I-Review	I-2	Review	374
for example, determining whether function arguments are swapped required detecting a function call and boundaries of its	I-Review	I-2	Review	374
arguments, thus parsing the program!	I-Review	I-2	Review	374
<sep> <sep> This work obtains (and nicely analyzes) impressive results obtained by applying CuBERT.	B-Review	B-3	Review	374
However, it does not put the	I-Review	I-3	Review	374
results in context with prior work based on structured program representations.	I-Review	I-3	Review	374
Without this, it is difficult to say	I-Review	I-3	Review	374
whether the improvement comes from pretraining or from the language model simply learning a better "parsed"	I-Review	I-3	Review	374
representation of an input program from all the unlabeled corpus.	I-Review	I-3	Review	374
If it's the latter, one might argue that supplying the	I-Review	I-3	Review	374
model with structured program features explicitly might eliminate much of the need for the unlabeled corpus.	I-Review	I-3	Review	374
<sep> I personally think that there will still be a gap between pretraining and finetuning even with structured program	I-Review	I-3	Review	374
features simply due to the sheer volume of available data, which, as the authors showed, is crucial for good	I-Review	I-3	Review	374
generalization of Transformer.	I-Review	I-3	Review	374
However, this still needs to be shown empirically.	I-Review	I-3	Review	374
<sep> <sep> The "Function-Docstring Mismatch" task, as presented, seems too easy.	B-Review	B-4	Review	374
If the distractors (negative examples) are truly	I-Review	I-4	Review	374
chosen at random, most of them are going to use obviously different vocabulary from the original function signature (as	I-Review	I-4	Review	374
Figure 4 demonstrates).	I-Review	I-4	Review	374
A well designed task would somehow bias the sampling toward subtle distractors such as `get` vs.	I-Review	I-4	Review	374
`set` docstrings, but this seems challenging.	I-Review	I-4	Review	374
<sep> This also explains why the task is not influenced as much by reduction of training data (Table 3).	I-Review	I-4	Review	374
<sep> <sep> The Next Sentence Prediction pretraining task, as adapted for CuBERT, seems too difficult, in contrast.	B-Review	B-5	Review	374
If the paired	I-Review	I-5	Review	374
sentences (i.e. code lines) are chosen at random, the model would lack most of the context required to make a decision	I-Review	I-5	Review	374
about the logical relationship between them, such as which variables are defined and available in context, which	I-Review	I-5	Review	374
functionality is being implemented, etc.	I-Review	I-5	Review	374
I wonder, can the authors experiment with pretraining CuBERT only with the	I-Review	I-5	Review	374
Masked Language Model task?	I-Review	I-5	Review	374
Will it worsen the results substantially or at all?	I-Review	I-5	Review	374
<sep> <sep> # Questions	O	O	Review	374
<sep> Section 3.2: "similar files according to the same similarity metric..."	B-Review	B-6	Review	374
What are these metrics?	I-Review	I-6	Review	374
<sep> <sep> What is the fraction of positive/negative examples in the constructed finetuning datasets?	B-Review	B-7	Review	374
<sep> <sep> What is the motivation for making Variable Misuse and Wrong Operator/Operand into a simple classification tasks instead	B-Review	B-8	Review	374
of the original (more useful) correction task?	I-Review	I-8	Review	374
<sep> <sep> We thank the reviewer for the helpful comments and suggestions.	O	O	Reply	374
<sep> <sep> &gt;&gt; Choice to ignore program structure (e.g. abstract syntax trees) or features (e.g. types)	O	O	Reply	374
<sep> Natural languages are also endowed with structure (e.g., different types of parse trees, phrase structures, etc.).	B-Reply	B-1	Reply	374
However, the prevailing pre-training methods in NLP such as BERT do not make explicit use of such structure, and still attain state-of-the-art results.	I-Reply	I-1	Reply	374
The task of learning useful (structural) features is left to the self-attention mechanism of the Transformer model.	I-Reply	I-1	Reply	374
In this work, we apply the same approach to program-understanding tasks.	I-Reply	I-1	Reply	374
We recognize that it may be possible to extend CuBERT with explicitly provided structural information using approaches like relation-aware Transformers (see "Self-attention with relative position representations", <a href="https://www.aclweb.org/anthology/N18-2074.pdf)" target="_blank" rel="nofollow">https://www.aclweb.org/anthology/N18-2074.pdf)</a> in place of the usual Transformers based on sinusoidal positional encodings, and hope to try this in future work; this submission will provide a strong baseline to evaluate such future work.	I-Reply	I-1	Reply	374
We thank the reviewer for raising this point.	I-Reply	I-1	Reply	374
We now include this possibility as a future extension in Section 5, which we rename from ‚ÄúConclusions‚Äù to ‚ÄúConclusions and Future Work‚Äù.	I-Reply	I-1	Reply	374
<sep> <sep> With regard to types, we do not assume that the source code is written in a statically typed language and hence, do not use types as features.	I-Reply	I-1	Reply	374
We train CuBERT for Python code, which is dynamically typed.	I-Reply	I-1	Reply	374
We leave exploring type information for statically-typed languages for future work.	I-Reply	I-1	Reply	374
<sep> <sep> &gt;&gt; Burden of program analysis	O	O	Reply	374
<sep> The reviewer‚Äôs point is well taken.	B-Reply	B-2	Reply	374
We have reworded our relevant text in the paper.	I-Reply	I-2	Reply	374
To recap, our goal is to understand and evaluate a BERT-like pre-training approach (i.e., purely on lexical information) for program-understanding tasks, without exposing to the pre-training model additional information gleaned through program analysis.	I-Reply	I-2	Reply	374
<sep> <sep> &gt;&gt; Simplicity of the Function-Docstring Mismatch task	O	O	Reply	374
<sep> We agree with the reviewer‚Äôs observation.	B-Reply	B-4	Reply	374
Nevertheless, the inherent ability of Transformer to relate every pair of tokens through self-attention plays a crucial role in CuBERT getting +7.5% improvement over the baseline model even on this relatively simple task.	I-Reply	I-4	Reply	374
<sep> <sep> &gt;&gt; Utility of Next Sentence Prediction task	O	O	Reply	374
<sep> A recent work has argued that using only the Masked Language Model objective (coupled with more training on larger datasets) can improve the performance of BERT (see "RoBERTa: An optimized method for pretraining self-supervised NLP systems", <a href="https://arxiv.org/abs/1907.11692)."	B-Reply	B-5	Reply	374
target="_blank" rel="nofollow">https://arxiv.org/abs/1907.11692).</a> It will take more experimentation to check how inclusion/exclusion of next-sentence-prediction affects CuBERT.	I-Reply	I-5	Reply	374
<sep> <sep> &gt;&gt; Explanation of similarity metric	O	O	Reply	374
<sep> Two files are considered similar to each other if the Jaccard similarity between the sets of tokens (identifiers and string literals) is above 0.8 and in addition, it is above 0.7 for multi-sets of tokens.	B-Reply	B-6	Reply	374
This is based on the criteria used in Allamanis (2018).	I-Reply	I-6	Reply	374
We have added this explanation in the revised version.	I-Reply	I-6	Reply	374
<sep> <sep> &gt;&gt; Fraction of positive/negative examples in the finetuning tasks	O	O	Reply	374
<sep> We have provided these details in Appendix A now.	B-Reply	B-7	Reply	374
To summarize, all classification tasks except Exception Type classification, and the new pointer task (Section 4.7), have a 50-50 split of buggy/bug-free examples.	I-Reply	I-7	Reply	374
The per-class counts for the Exception Type classification task are shown in the (new) Table 6.	I-Reply	I-7	Reply	374
<sep> <sep> &gt;&gt; Motivation for making Variable Misuse and Wrong Operator/Operand as classification tasks instead of correction tasks	O	O	Reply	374
<sep> We have now included experimentation for the joint task of classification, localization and repair of variable misuse errors from Vasic et al (2019).	B-Reply	B-8	Reply	374
Please see Section 4.7 for the results.	I-Reply	I-8	Reply	374
The original Wrong Operator and Swapped Operand tasks from (Pradel &amp; Sen 2018) are binary classification tasks similar to ours.	I-Reply	I-8	Reply	374
They were not error correction tasks.	I-Reply	I-8	Reply	374

The paper proposes a transformer based approach to address a number of problems for machine learning from code.	O	O	Review	374
Then, the paper adds BERT-based pretraining to significantly improve on the results.	O	O	Review	374
The paper is nicely written and easy to follow, but with relatively thin contributions besides the large amount of experiments.	O	O	Review	374
<sep> <sep> Initially, I was quite positive on the entire paper, but as I read it in more details, I got less convinced that this is something I want to see at ICLR.	O	O	Review	374
First, there are no good baselines.	B-Review	B-1	Review	374
BiLSTM gets quite high accuracy on most of the tasks, which is unexpected because most prior works show that the tasks benefit from some semantic understanding of code.	I-Review	I-1	Review	374
I cannot relate any of the numbers with a previous work.	I-Review	I-1	Review	374
Right now, I even have reduced confidence that the authors do not have bugs in the tasks or the reported numbers.	I-Review	I-1	Review	374
Then, for the Operator and Operand tasks, BiLSTM is also doing impressively well (these tasks were done differently in prior works).	I-Review	I-1	Review	374
Interestingly, things get reversed on the last two tasks.	I-Review	I-1	Review	374
Given that most of the experiments are not the same as in any previous paper, I would strongly appreciate if much more details are given in the appendix.	I-Review	I-1	Review	374
In fact, the appendix right now does not have much useful information besides praising how good job the attention is doing.	I-Review	I-1	Review	374
What would be needed is information on how many samples were generated, how large were they, was any data thrown out?	I-Review	I-1	Review	374
Table 1 is a good start, but it actually raises questions.	I-Review	I-1	Review	374
You split the Python dataset into separate functions like Vasic et al and the number of functions 2x higher (counting the artificial samples, I guess), did you put a limit on how large functions you consider?	I-Review	I-1	Review	374
250 tokens was the limit of Vasic et al To which of the tasks in the Vasic et al paper can I relate?	I-Review	I-1	Review	374
Is the BiLSTM on the level of that work or it is substantially worse or better?	I-Review	I-1	Review	374
Also, are the results coming from the paper SOTA or uncomparable to other works?	I-Review	I-1	Review	374
<sep> <sep> Five tasks are evaluated, which is impressive.	O	O	Review	374
This is one reason I want to see the results published.	O	O	Review	374
The problem is also quite important.	B-Review	B-2	Review	374
The experiments that show the effect on reduced labelled data are quite important and interesting - in fact, for many tasks, we can start curating datasets and having model working on small data will be crucial.	I-Review	I-2	Review	374
However, I think the paper needs more work before it is something to present, cite or build upon.	I-Review	I-2	Review	374
<sep> <sep> We thank the reviewer for the helpful comments and suggestions.	O	O	Reply	374
<sep> <sep> &gt;&gt; Lack of good baselines	O	O	Reply	374
<sep> Though we consider a variety of tasks from the literature, the associated datasets came from different languages and varied sources.	B-Reply	B-1	Reply	374
Due to the importance of keeping the pre-training corpus distinct from the finetuning corpus, we decided to set up all our finetuning tasks on the ETH Py150 corpus and constructed strong and suitable baselines.	I-Reply	I-1	Reply	374
As baselines, we use multi-layered BiLSTMs and Transformers, both of which are widely-used architectures for sequential data.	I-Reply	I-1	Reply	374
Since we study the transferability of pre-trained contextual embeddings, we have also trained and used 4 variants of (non-contextual) Word2Vec word embeddings.	I-Reply	I-1	Reply	374
To our knowledge, these Word2Vec embeddings also constitute the only word embeddings trained for source code at a massive scale.	I-Reply	I-1	Reply	374
As a result, we compare with not only strong architectures but with also pre-trained word embeddings of source code.	I-Reply	I-1	Reply	374
<sep> <sep> &gt;&gt; Justification for high accuracy of BiLSTM models	O	O	Reply	374
<sep> There is certainly work in the literature that shows that results can be improved by incorporating additional annotations in the program representations.	B-Reply	B-1	Reply	374
However, there is also a large body of work that shows impressive results with only tokenized source code representation.	I-Reply	I-1	Reply	374
In the absence of systematic benchmarking and comparisons, we shy away from claiming either of them to be superior in general.	I-Reply	I-1	Reply	374
For this work, we have put in extensive efforts to ensure that the baseline models are not at a disadvantage when compared to CuBERT.	I-Reply	I-1	Reply	374
In particular, we have purposefully chosen bidirectional LSTMs since the Transformer encoder underlying CuBERT uses bidirectional context.	I-Reply	I-1	Reply	374
Another potential reason for our BiLSTM models doing well is that many existing works in the literature use token-level vocabularies whose size is capped.	I-Reply	I-1	Reply	374
This can result in out-of-vocabulary words and hampers the learning.	I-Reply	I-1	Reply	374
We use a subword vocabulary (the same one that we use for CuBERT) which avoids this.	I-Reply	I-1	Reply	374
Further, we use well-trained Word2Vec embeddings in our BiLSTM models.	I-Reply	I-1	Reply	374
<sep> <sep> &gt;&gt; Variation in the performance of the BiLSTM models	O	O	Reply	374
<sep> Note that compared to the other classification tasks, the Exception Type classification task is a multi-class problem with 20 classes and has a much smaller dataset (21K training examples).	B-Reply	B-1	Reply	374
So the BiLSTMs do not perform that well on this task.	I-Reply	I-1	Reply	374
In general, the model performance is subject to idiosyncrasies of the problem and dataset.	I-Reply	I-1	Reply	374
<sep> <sep> &gt;&gt; Comparison to previous work	O	O	Reply	374
<sep> For reasons discussed above (under ‚ÄúLack of good baselines‚Äù), we had to design baselines ourselves.	B-Reply	B-1	Reply	374
Nevertheless, we now present an additional pointer prediction task (Variable Misuse Localization and Repair), in which we compare CuBERT against the model proposed in Vasic et al (2019) on our dataset.	I-Reply	I-1	Reply	374
<sep> <sep> &gt;&gt; Appendix explaining details of design of finetuning tasks	O	O	Reply	374
<sep> Thank you for the suggestion to add more details about the design of the finetuning tasks in the appendix.	B-Reply	B-1	Reply	374
We have added an appendix (Appendix A) with the requisite details and additional discussion.	I-Reply	I-1	Reply	374
<sep> <sep> &gt;&gt; Comparison with Vasic et al (2019)	O	O	Reply	374
<sep> To facilitate direct comparison between Vasic et al (2019) and our work, we have now added the joint classification, localization and repair task proposed in Vasic et al (2019).	B-Reply	B-1	Reply	374
The results are presented in Section 4.7.	I-Reply	I-1	Reply	374
The results are consistent with the results of our other finetuning tasks, in the sense that CuBERT outperforms the model from Vasic et al (2019).	I-Reply	I-1	Reply	374
For fair comparison, the results are obtained on the same dataset for both CuBERT and Vasic et al‚Äôs model (a unidirectional LSTM with two pointers).	I-Reply	I-1	Reply	374
In their paper, they had done the evaluation only on a random sample of 12,218 test examples (Section 4, Benchmarks, from their paper), whereas we provide results on all of 430K test examples (Table 1, from our paper).	I-Reply	I-1	Reply	374
We also use the same subword vocabulary for both models, whereas they had used a word-level fixed-size vocabulary.	I-Reply	I-1	Reply	374
<sep> <sep> &gt;&gt; Are the results from the paper SOTA?	O	O	Reply	374
<sep> <sep> Our finetuning tasks are motivated by the tasks in the literature.	B-Reply	B-1	Reply	374
The reason we do not have one-to-one comparison with existing works is because the existing works use different languages, datasets, tokenizations, etc. (	I-Reply	I-1	Reply	374
Section 3.4).	I-Reply	I-1	Reply	374
For example, Pradel &amp; Sen (2018) use limited surrounding context for classification, whereas we do classification at the level of function bodies.	I-Reply	I-1	Reply	374
Therefore, even though our results are consistently high (&gt;90% accuracy except for the Exception Type task), there are no references that we can appeal to for comparison.	I-Reply	I-1	Reply	374
However, we now also have results on Variable Misuse Localization and Repair task (Section 4.7) where we evaluate against the model from Vasic et al (2019) on our dataset, where CuBERT attains the highest accuracies.	I-Reply	I-1	Reply	374

This paper describes a BERT-based pre-training for source code related task.	O	O	Review	374
By pre-training on BERT-like models on source code and finetuning on a set of 5 tasks, the authors show good performance improvements over non-pretrained models.	O	O	Review	374
The authors make a series of ablation studies showing that pre-training is indeed useful.	O	O	Review	374
<sep> <sep> Overall, I find this work relevant and interesting, albeit somewhat unsurprising.	O	O	Review	374
Nevertheless, I see no reason to reject this paper.	O	O	Review	374
To make my "weak accept" to a "strong accept" I would like to see experiments on more tasks, preferably more complex tasks.	B-Review	B-1	Review	374
For example, such tasks could include (a) variable naming (b) method naming (c) docstring prediction/summarization (d) language modeling/autocompletion.	I-Review	I-1	Review	374
I believe it's unclear to the reader if pre-training is also helpful for any of those tasks too and adding such experiments would significantly strengthen the paper.	I-Review	I-1	Review	374
<sep> <sep> Some clarifications comments/questions to the authors:	O	O	Review	374
<sep> * I would insist that the authors rename the "Variable Misuse" task to "Variable Misuse Localization".	B-Review	B-2	Review	374
To my understanding the current model points to the misused variable (if any), but does not attempt to suggest a fix.	I-Review	I-2	Review	374
This tackles only a part of the task discussed in Vasic et al (2019), Allamanis et al (2018) and this might confuse readers who want to compare with those works.	I-Review	I-2	Review	374
<sep> <sep> * For the Function-Docstring Mismatch task (Section 3.4):	B-Review	B-3	Review	374
* It's unclear to me which dataset is used.	I-Review	I-3	Review	374
Is it the Py150 dataset or the Barone &amp; Sennrich (2017)?	I-Review	I-3	Review	374
<sep> * I believe that the citations [a], [b] would be appropriate here.	I-Review	I-3	Review	374
<sep> <sep> * Overall, for the all the tasks except from "Exception Type", there is a replicability issue: Since the authors manually mutate the code (e.g. introduce a variable misuse, swap an operand), for anyone to compare directly, they would need access to the mutated samples.	B-Review	B-5	Review	374
I would strongly encourage the authors to provide more details on how they create mutated samples and (eventually) the source code that achieves that.	I-Review	I-5	Review	374
<sep> <sep> * For the Variable Misuse, Wrong Binary Operator, Swapped Operand tasks.	B-Review	B-4	Review	374
There are a few things that need to be clarified:	I-Review	I-4	Review	374
* How long is each code snippet?	I-Review	I-4	Review	374
One would expect that the longer the code snippet the harder the task.	I-Review	I-4	Review	374
Do the authors pass a whole function?	I-Review	I-4	Review	374
<sep> * What is the proportion of positive/negative examples in each task?	I-Review	I-4	Review	374
<sep> <sep> <sep> <sep> [a] Cambronero, Jose, et al "When Deep Learning Met Code Search."	O	O	Review	374
arXiv preprint arXiv:1905.03813 (2019).	O	O	Review	374
<sep> [b] Louis, Annie, et al "Deep learning to detect redundant method comments."	O	O	Review	374
arXiv preprint arXiv:1806.04616 (2018).	O	O	Review	374
We thank the reviewer for the helpful comments and suggestions.	O	O	Reply	374
<sep> <sep> &gt;&gt; Addition of more complex task	O	O	Reply	374
<sep> We have now added a more complex task (Section 4.7), that of joint classification, localization and repair of variable misuse errors as proposed in Vasic et al (2019).	B-Reply	B-1	Reply	374
This requires learning two pointers for localization and repair of variable misuse bugs, and is an extension of the variable misuse classification task we have already considered.	I-Reply	I-1	Reply	374
<sep> <sep> We had considered the variable and method naming tasks as candidate finetuning tasks.	I-Reply	I-1	Reply	374
The masked language modeling (MLM) pre-training task works by masking/replacing tokens (Section 3.5) and training the network to predict them.	I-Reply	I-1	Reply	374
Variable and method naming tasks would be very similar to MLM (wherein we mask the names and ask the network to predict the masked tokens) and hence, we decided not to include them in this submission.	I-Reply	I-1	Reply	374
<sep> <sep> Since CuBERT produces only a pre-trained encoder, the docstring prediction and language modeling/autocomplete tasks would require learning a decoder from scratch.	I-Reply	I-1	Reply	374
A recent work on transfer learning (‚ÄúExploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer‚Äù, <a href="https://arxiv.org/abs/1910.10683)" target="_blank" rel="nofollow">https://arxiv.org/abs/1910.10683)</a> recasts the BERT pre-training objective into a text-to-text setting, wherein both Transformer encoder and decoder are pre-trained.	I-Reply	I-1	Reply	374
We consider this reformulation of BERT to be a great future avenue to enable direct finetuning for generative tasks like docstring prediction and autocompletion.	I-Reply	I-1	Reply	374
<sep> <sep> &gt;&gt; Renaming the Variable Misuse task	O	O	Reply	374
<sep> The task we had described was a classification task where the model needs to identify if any of the variables in a function body is misused.	B-Reply	B-2	Reply	374
To avoid any misunderstanding, we have now renamed it to ‚ÄúVariable Misuse Classification‚Äù.	I-Reply	I-2	Reply	374
To also match the full task from Vasic et al (2019), we now also have the ‚ÄúVariable Misuse Localization and Repair‚Äù task (Section 4.7).	I-Reply	I-2	Reply	374
<sep> <sep> &gt;&gt; Dataset for the Function-Docstring Mismatch task and related references	O	O	Reply	374
<sep> The Py150 dataset is used in this task (and all other fine-tuning tasks).	B-Reply	B-3	Reply	374
We have updated the writeup to make this clear.	I-Reply	I-3	Reply	374
Thank you for the references, we have discussed them in the writeup now.	I-Reply	I-3	Reply	374
<sep> <sep> &gt;&gt; Details on reproducibility	O	O	Reply	374
<sep> We have added an appendix (Appendix A) with the details of the dataset generation for the finetuning tasks, including a discussion of the careful use of pseudorandomness to ensure reproducible dataset generation.	B-Reply	B-5	Reply	374
In addition, we plan to release the datasets for public use.	I-Reply	I-5	Reply	374
<sep> <sep> &gt;&gt; Details on data generation and proportion of positive/negative examples	O	O	Reply	374
<sep> We have included these details in Appendix A in the revised version.	B-Reply	B-4	Reply	374

This paper presents a method to learn an acoustic model for phoneme recognition with only the training input acoustic features and a pretrained phoneme LM.	O	O	Review	240
This is done by matching the output phoneme sequence distribution of the training set with the phoneme LM distribution.	O	O	Review	240
The cost function is proposed by extending a previously proposed unsupervised cost function (Empirical-ODM) to the segmental level, and integrating an intra-segment cost function to encourage the frame-wise output distribution to be similar to each other within a segment.	O	O	Review	240
The authors conducted thorough experiments on TIMIT phoneme recognition and demonstrated impressive results.	O	O	Review	240
<sep> <sep> The paper is technically sound and the presentation is generally clear.	O	O	Review	240
The idea is interesting and novel by extending a previous unsupervised sequence modeling approach to speech recognition and exploiting the segmental structure of the problem.	O	O	Review	240
Unsupervised learning is an important research topic, and its application to potentially save high cost of human labeling for developing ASR systems is important to the community.	O	O	Review	240
<sep> <sep> Here are a few general comments/questions:	O	O	Review	240
<sep> 1.	O	O	Review	240
It would be interesting to see whether and how much using a larger acoustic training set and a phoneme LM trained on more data can close the gap between unsupervised and supervised performance.	B-Review	B-1	Review	240
Also it would be great to see how well the learned acoustic model performs in a full ASR system together with the lexicon and LM to predict words, which could generate more accurate unsupervised transcript than the acoustic model itself for refining the model further.	I-Review	I-1	Review	240
These could be done in future work.	I-Review	I-1	Review	240
<sep> <sep> 2.	O	O	Review	240
The current cost function is based on matching the N-gram distribution in the phoneme LM and that in the DNN acoustic model output of the training set, where N is relatively small.	B-Review	B-2	Review	240
How could the framework be extended for the state-of-the-art LM and AM with RNNs where the history is arbitrarily long?	I-Review	I-2	Review	240
<sep> <sep> 3.	O	O	Review	240
Why can this paper just use a larger mini-batch size to alleviate the effect that SGD is intrinsically biased for the Empirical-ODM functional form, while Liu et al 2017 needed to propose the Stochastic Primal-Dual Gradient approach?	B-Review	B-3	Review	240
<sep> <sep> 4.	B-Review	B-4	Review	240
The paper compares the unsupervised cost function with the supervised cross-entropy function in terms of quality.	I-Review	I-4	Review	240
How about training time?	I-Review	I-4	Review	240
The computation looks expensive for the unsupervised case since it needs to go through all possible N-grams (which is approximated by the most frequent 10000 5-grams according to Appendix B but still a large space).	I-Review	I-4	Review	240
<sep> <sep> 5.	B-Review	B-5	Review	240
If the segmentation quality affects the learned acoustic model quality, why not also report the segmentation accuracy for all unsupervised systems and iterations, including the Wang et al 2017 system?	I-Review	I-5	Review	240
<sep> <sep> More specific comments:	O	O	Review	240
<sep> 7.	B-Review	B-6	Review	240
The outer summation in Eq(1) seems to indicate summing over all possible \tau, which is infeasible.	I-Review	I-6	Review	240
Please clarify how it is computed.	I-Review	I-6	Review	240
<sep> 8.	O	O	Review	240
Eq(5): "p(y_t | y_1 ... y_t)" should be "p(y_t | y_1 ... y_{t-1})".	B-Review	B-7	Review	240
<sep> 9.	B-Review	B-8	Review	240
Why are there periodic spikes in both self-validation loss and validation FER in Figure 2(a)?	I-Review	I-8	Review	240
What training stage do they correspond to?	I-Review	I-8	Review	240
<sep> 10.	O	O	Review	240
In Figure 2, "validation error" in the y-axis should probably be "validation FER".	B-Review	B-7	Review	240
In Figure 2(b), the number ranges on the left and right of the y-axis were probably swapped.	I-Review	I-7	Review	240
<sep> 11.	O	O	Review	240
Section 2.5: why is Eq(1) instead of Eq(3) used for the self-validation loss?	B-Review	B-9	Review	240
<sep> 12.	O	O	Review	240
Conclusion: "the a potential" -> "the potential".	B-Review	B-7	Review	240
We thank the reviewer for the constructive feedback!	O	O	Reply	240
<sep> <sep> [Future work] As suggested by the reviewer, in future work, we intend to extend our method to large-scale ASR tasks (e.g., Switchboard), and evaluate the performance in word error rate.	B-Reply	B-1	Reply	240
We will also evaluate how much a larger dataset could close the performance gap between the supervised and unsupervised methods.	I-Reply	I-1	Reply	240
<sep> <sep> [Extension to RNN LM & AM] We use N-gram phoneme LM because it is simple to implement and it achieves satisfactory performance.	B-Reply	B-2	Reply	240
To extend to RNN-LM, we need to develop an effective way of computing the sum over z (i.e., different N-grams) in (1).	I-Reply	I-2	Reply	240
For RNN-LM, the probability for each N-gram is not explicitly given.	I-Reply	I-2	Reply	240
Instead, we need to score it recursively: we can treat each N-gram as a length-N sequence and use RNN to score its log-likelihood, which, after taking the exponential, becomes the probability of the N-gram.	I-Reply	I-2	Reply	240
In addition, we may use beam search to pick a subset of N-grams with the corresponding probabilities scored by RNN to compute the sum in (1) approximately.	I-Reply	I-2	Reply	240
For RNN-AM, we could replace the current DNN acoustic model by RNN, which will generate output distribution at each frame, then we can apply the same objective function (1).	I-Reply	I-2	Reply	240
<sep> <sep> [SGD with large mini-batch] We use mini-batch SGD by dynamically increasing the batch-size.	B-Reply	B-3	Reply	240
We observe that this optimization strategy empirically converges much faster than the Stochastic Primal-Dual Gradient (SPDG) and reaches a better converging point in our experiments.	I-Reply	I-3	Reply	240
The reason that Liu et al cannot reach satisfactory result by SGD may be that they did not dynamically increase the batch size during training and the difference in dataset statistics.	I-Reply	I-3	Reply	240
<sep> <sep> [Training time] In Figure 2(a), we show a learning curve of the validation error over training time when the segmentation is given by a supervised oracle.	B-Reply	B-4	Reply	240
We can see that the total training could be completed in about an hour, which is similar to supervised learning.	I-Reply	I-4	Reply	240
With unsupervised segmentation boundaries, it takes a longer time to converge, which is usually 4-5 hours.	I-Reply	I-4	Reply	240
As pointed out by the reviewer, the computation complexity for estimating a stochastic gradient is O(10000) for the sum over z in (1).	I-Reply	I-4	Reply	240
However, since we use a very large mini-batch (about 20K), this computation complexity is amortized by a large mini-batch, i.e., the per sample complexity is low.	I-Reply	I-4	Reply	240
In addition, this computation could also be highly parallelized in GPU.	I-Reply	I-4	Reply	240
<sep> <sep> [Segmentation quality] As suggested by the reviewer, we evaluate the precision, recall, F-score and R-value of our refined boundaries and compare them to the baselines (including Wang et al 2017).	B-Reply	B-5	Reply	240
Please refer to Table 3 of our revised paper for the full results.	I-Reply	I-5	Reply	240
Below, we list the results of our method and the results from Wang et al 2017.	I-Reply	I-5	Reply	240
We can see that by refining the initial boundaries provided by (Wang et al 2017), we improve the quality of the segmentation boundaries, which leads to better PER.	I-Reply	I-5	Reply	240
<sep> <sep> <tab><tab>        Initial boundary (Wang et al)<tab><tab>Our refined boundaries	I-Reply	I-5	Reply	240
R-value<tab>        82.6<tab><tab><tab><tab><tab>                        84.8	I-Reply	I-5	Reply	240
F-score<tab>        80.1<tab><tab><tab><tab><tab>                        82.6	I-Reply	I-5	Reply	240
Recall<tab><tab>78.2<tab><tab><tab><tab><tab>                        80.9	I-Reply	I-5	Reply	240
Precision<tab>82.3<tab><tab><tab><tab><tab>                        84.3	I-Reply	I-5	Reply	240
<sep> [sum over \tau] Since we are learning our model by SGD, we estimate our stochastic gradient by sampling this sum over \tau.	B-Reply	B-6	Reply	240
Specifically, we will randomly sample one \tau at the beginning of each epoch during the training process.	I-Reply	I-6	Reply	240
<sep> <sep> [Periodic spikes in Figure 2(a)] We train the model according to a fixed schedule of hyperparameters.	B-Reply	B-8	Reply	240
In Figure 2(a), the mini-batch sizes gradually increase from 5000 to 20000 and the softmax temperature is decreased from 0.8 to 0.5 (i.e., gradually becomes sharper).	I-Reply	I-8	Reply	240
Furthermore, in each stage, the learning rate also decays from an initial value.	I-Reply	I-8	Reply	240
When the next stage begins (i.e., the position at the spikes in the figure), the learning rate will revert back to its initial value.	I-Reply	I-8	Reply	240
Therefore, we believe the spikes come from the sudden increase in the learning rate.	I-Reply	I-8	Reply	240
<sep> <sep> [Choice of self-validation loss] We use Eq (1) instead of Eq (3) as the self-validation loss because we will also need to tune the hyperparameter \lambda and the cost in (3) depends on \lambda.	B-Reply	B-9	Reply	240
<sep> <sep> [Typos] We have fixed the typos in Eq (5), Figure 2 and Conclusion.	B-Reply	B-7	Reply	240

This paper proposes fully unsupervised learning algorithm for speech recognition.	O	O	Review	240
It involves two alternating trained component, a phoneme classifier, and a boundary refining model.	O	O	Review	240
The experiment results demonstrate that it achieves first success on speech recognition that approaches the supervised learning performance.	O	O	Review	240
<sep> Pros:	O	O	Review	240
+ The paper propose to use a frame-wise smoothing term J_FS added on J_ODM cost.	O	O	Review	240
In the new cost function, J_ODM controls the coarse-grained inter-segment distribution using a prepared language model P_LM, while J_FS controls the fine-grained intra-segment distribution.	O	O	Review	240
It is actually benefit to take use of this hierarchical 2-level scopes than only 1-level scope on evaluate the distribution mismatch in the cost function.	O	O	Review	240
Because otherwise, if only focus on fine-grained frame level,  much larger number of frame labels and longer N-gram have to be considered to evaluate the distribution of phoneme.	O	O	Review	240
Consequently, the computation can be exploding.	O	O	Review	240
<sep> + The proposed unsupervised phoneme classification method is superior to the baseline (Liu et al 2018) because the baseline relies on a clustering which is upper-bounded by cluster purity.	O	O	Review	240
Directly optimize on \theta using an end-to-end scheme is preferred.	O	O	Review	240
<sep> + I like the idea to use an iterative training algorithm to jointly improve classifier parameter \theta and segment boundaries b.	O	O	Review	240
+ It is quite impressive that unsupervised learning system get close to performance of supervised system on speech recognition.	O	O	Review	240
The proposed system also outperforms state-of-the-art baseline with large margin.	O	O	Review	240
<sep> + The settings of experiments are rather comprehensive.	O	O	Review	240
Especially the ‚Äúnon-matching language model‚Äù, tests the case where language model cannot directly estimated from training set.	O	O	Review	240
<sep> Questions:	O	O	Review	240
1.	O	O	Review	240
<tab>In Appendix B you mentioned that for the N-gram you choose N=5.	B-Review	B-1	Review	240
So the original language model P_LM can be a high-dim matrix with exactly 39^5 elements.	I-Review	I-1	Review	240
How sparse is the original P_LM?	I-Review	I-1	Review	240
It describes that 10000 elements are chosen, which are only 0.001%(=10000/39^5) of elements in the original one.	I-Review	I-1	Review	240
How representative are they?	I-Review	I-1	Review	240
<sep> <sep> 2.	O	O	Review	240
<tab>I notice for the balance weight of J_FS in (3), you empirically take the best \lambda=1e-5 during experiment.	B-Review	B-2	Review	240
To me, the scale of optimal \lambda is such small value maybe because the order of J_FS is improperly determined.	I-Review	I-2	Review	240
My suggestion is, could you try using square root on the current J_FS, or using standard deviation of intra-segment outputs.	I-Review	I-2	Review	240
The reasons are, first, minimizing std is a more interpretable penalty on diversion in a same segment; second, since you have used mean of outputs in J_ODM, then it is better to use a same dimension statistics, such as std of outputs in J_FS rather than sum of squared differences, when you combine J_ODM and J_FS in a uniform cost.	I-Review	I-2	Review	240
<sep> <sep> 3.	O	O	Review	240
<tab>What is the time complexity of running a comparable supervised speech recognition task with unsupervised learning method?	B-Review	B-3	Review	240
<sep> <sep> Minor issues:	O	O	Review	240
Maybe it is a typo that the second term of Eqn (2) should be ‚Äú-p_\theta(y_(t+1)=y|x_(t+1))‚Äù instead?	B-Review	B-4	Review	240
Since the p_\theta is defined as posterior probability of the frame label given the corresponding input.	I-Review	I-4	Review	240
<sep> <sep> We thank the reviewer for the constructive feedback!	O	O	Reply	240
<sep> <sep> [Top-10000 of P_LM] We found that among the 48^5 elements in the P_LM only 69553 of them are non-zero.	B-Reply	B-1	Reply	240
We also found that the top 10000 elements of P_LM account for about 48.7% of the total probability in P_LM.	I-Reply	I-1	Reply	240
That is, this extremely small portion of the elements in P_LM occupy almost half of the total probability.	I-Reply	I-1	Reply	240
<sep> <sep> [Balance weight of J_FS] As suggested by the reviewer, we conducted experiments by taking the square root of J_FS and obtain results for different values of \lambda.	B-Reply	B-2	Reply	240
We found that the best value of \lambda becomes 1e-6, which is even smaller than the original value of 1e-5.	I-Reply	I-2	Reply	240
The possible reasons are explained below.	I-Reply	I-2	Reply	240
First, we observe that the value of J_FS is in fact much smaller than J_ODM  (e.g., 0.15 vs 6.21).	I-Reply	I-2	Reply	240
When taking the square root of J_FS, it becomes larger and we will need a smaller lambda to balance it.	I-Reply	I-2	Reply	240
Second, the reason that we do not need a large lambda for J_FS is that it mainly plays the role of regularization.	I-Reply	I-2	Reply	240
Ideally, if we sample all possible trajectories of \tau in (1) and match their predicted output distribution to P_LM, then the prediction within each segment would also be close to each other.	I-Reply	I-2	Reply	240
However, the number of all the possible trajectories \tau in S_1 x S_2 x ‚Ä¶ S_K is exponentially large, and we cannot sample all of them in our training.	I-Reply	I-2	Reply	240
Therefore, J_FS would play the role of a regularization that helps promote the consistency in the intro-segment predictions.	I-Reply	I-2	Reply	240
For this reason, the regularization term J_FS does not need to be too large in practice.	I-Reply	I-2	Reply	240
<sep> <sep> [Training time of unsupervised learning] In Figure 2(a), we show a learning curve of the validation error over training time when the segmentation is given by a supervised oracle.	B-Reply	B-3	Reply	240
We can see that the total training could be completed in about an hour, which is similar to supervised learning.	I-Reply	I-3	Reply	240
With unsupervised segmentation boundaries, it takes a longer time to converge, which is usually 4-5 hours.	I-Reply	I-3	Reply	240
<sep> <sep> [Typos and minor issues] We have fixed the typos in Eq (2).	B-Reply	B-4	Reply	240

Overview:	O	O	Review	240
<sep> This paper proposes a new approach to do unsupervised phoneme recognition by learning from unlabelled speech in combination with a trained phoneme language model.	O	O	Review	240
The proposed loss function is a combination of a term encouraging the language model of predicted phonemes to match the given language model distribution, and a term to encourage adjacent speech frames to be assigned to the same phoneme class.	O	O	Review	240
Phoneme boundaries are iteratively refined using a separate model.	O	O	Review	240
Experiments where a hidden Markov model is applied on top of the predicted phonemes are also performed.	O	O	Review	240
<sep> <sep> <sep> Main strengths:	O	O	Review	240
<sep> The paper is clear and addresses a very important research problem.	O	O	Review	240
The approach and losses proposed in Section 2 have also not been proposed before, and given that an external language model is available, are very natural choices.	O	O	Review	240
<sep> <sep> <sep> Main weaknesses:	O	O	Review	240
<sep> The main weakness of this paper is that it does not situate itself within the rich body of literature on this problem.	B-Review	B-1	Review	240
I give several references below, but I think the authors can include even more studies -- there are several studies around "zero-resource" speech processing, and I would encourage the authors to work through the review papers [1, 6].	I-Review	I-1	Review	240
<sep> Concretely, I do not think the authors can claim that "this is the first fully unsupervised speech recognition method that does not use any oracle segmentation or labels."	I-Review	I-1	Review	240
I think it could be argued that the system of [3] is doing this, and there are even earlier studies.	I-Review	I-1	Review	240
I also don't think this claim is actually necessary since the paper has enough merit to stand on its own, as long as the related work is discussed properly.	I-Review	I-1	Review	240
<sep> <sep> For instance, the proposed approach shares commonalities with several other approaches: [2] also used two separate steps for acoustic modelling and boundary segmentation; [4, 7, 8] builds towards the setting where non-matching text data is available (for language model training) together with untranscribed speech for model development; the approach of [5] uses a very similar refinement step to the one described in Section 3, where an HMM model is initialised and retrained on noisy predicted labels.	I-Review	I-1	Review	240
<sep> <sep> In the experiments (Section 4), it would also be useful to report more fine-grained metrics. [	B-Review	B-2	Review	240
6] gives an overview of several of the standard metrics used in this area, but at a minimum phoneme boundary recall, precision and F-scores should be reported in order to allow comparisons to other studies.	I-Review	I-2	Review	240
<sep> <sep> <sep> Overall feedback:	O	O	Review	240
<sep> Given that this paper is situated within the broader context of this research area, which already has a small community around it, I think the novelty in the approach is strong enough to warrant publication given that the additional metrics are reported in the experiments.	O	O	Review	240
<sep> <sep> <sep> Papers/links that should be reviewed and cited:	O	O	Review	240
<sep> 1.	O	O	Review	240
E. Dunbar et al "The Zero Resource Speech Challenge 2017," in Proc.	O	O	Review	240
ASRU, 2017.	O	O	Review	240
<sep> 2.	O	O	Review	240
H. Kamper, K. Livescu, and S. Goldwater.	O	O	Review	240
An embedded segmental k-means model for unsupervised segmentation and clustering of speech.	O	O	Review	240
in Proc.	O	O	Review	240
ASRU, 2017.	O	O	Review	240
<sep> 3.	O	O	Review	240
Lee, C.-y.	O	O	Review	240
and Glass, J. R. A nonparametric Bayesian approach to acoustic model discovery.	O	O	Review	240
ACL, 2012.	O	O	Review	240
<sep> 4.	O	O	Review	240
Ondel, Lucas, Luka≈° Burget, Jan ƒåernock√Ω, and Santosh Kesiraju. "	O	O	Review	240
Bayesian phonotactic language model for acoustic unit discovery."	O	O	Review	240
In Acoustics, Speech and Signal Processing (ICASSP), 2017 IEEE International Conference on, pp.5750-5754.	O	O	Review	240
IEEE, 2017.	O	O	Review	240
<sep> 5.	O	O	Review	240
Walter, O., Korthals, T., Haeb-Umbach, R., and Raj, B. (2013).	O	O	Review	240
A hierarchical system for word discovery exploiting DTW-based initialization.	O	O	Review	240
ASRU, 2013.	O	O	Review	240
<sep> 6.	O	O	Review	240
M. Versteegh, X. Anguera, A. Jansen, and E. Dupoux, "The Zero Resource Speech Challenge 2015: Proposed approaches and results,‚Äù in Proc.	O	O	Review	240
SLTU, 2016.	O	O	Review	240
<sep> 7.	O	O	Review	240
<a href="https://www.clsp.jhu.edu/wp-content/uploads/sites/75/2018/05/jsalt2016-burget-building-speech-recognition.pdf" target="_blank" rel="nofollow">https://www.clsp.jhu.edu/wp-content/uploads/sites/75/2018/05/jsalt2016-burget-building-speech-recognition.pdf</a>	O	O	Review	240
8.	O	O	Review	240
<a href="https://www.clsp.jhu.edu/workshops/16-workshop/building-speech-recognition-system-from-untranscribed-data/" target="_blank" rel="nofollow">https://www.clsp.jhu.edu/workshops/16-workshop/building-speech-recognition-system-from-untranscribed-data/</a>	O	O	Review	240
<sep> <sep> We thank the reviewer for the constructive feedback!	O	O	Reply	240
<sep> <sep> [Related works] Thanks for the suggestion, we will adjust the claim in our revised paper.	B-Reply	B-1	Reply	240
We have also incorporated these related works and discuss them thoroughly in our related work section.	I-Reply	I-1	Reply	240
However, the mentioned works (including [3]) have a different focus compared to our work on unsupervised speech recognition.	I-Reply	I-1	Reply	240
Specifically, they are focused on unsupervised acoustic unit discovery (AUD), i.e., finding the segmentation boundaries for the acoustic units (e.g., word and subword)  and clustering the discovered units.	I-Reply	I-1	Reply	240
They did not classify acoustic inputs into phoneme or word labels in an unsupervised manner during the inference stage.	I-Reply	I-1	Reply	240
In contrast, we are interested in directly learning a speech recognition model in an unsupervised manner without an intermediate clustering step; that is, our learned model will directly recognize acoustic features into phoneme labels.	I-Reply	I-1	Reply	240
The estimation of the segmentation boundaries in our work is to help the training of the recognition model.	I-Reply	I-1	Reply	240
In fact, although we use the segmentation boundaries generated by (Wang et al 2017) as our initial boundaries, we could also potentially use other acoustic unit discovery methods suggested by the reviewer to initialize our algorithm, just as (Wang et al 2017).	I-Reply	I-1	Reply	240
Regarding the work in [2], although it also iterates between acoustic modeling and boundary segmentation, their acoustic modeling is mainly for cluster assignment while our work directly learns the phoneme recognition model.	I-Reply	I-1	Reply	240
<sep> <sep> [Additional evaluation metrics] As suggested by the reviewer, we evaluate the precision, recall, F-score and R-value of our refined boundaries and compare them to the baselines (including Wang et al 2017).	B-Reply	B-2	Reply	240
Please refer to Table 3 of our revised paper for the full results, where our method outperforms all the other baselines by a significant margin.	I-Reply	I-2	Reply	240
Below, we list the results of our method and the results from Wang et al 2017.	I-Reply	I-2	Reply	240
We can see that by refining the initial boundaries provided by (Wang et al 2017), we improve the quality of the segmentation boundaries, which is consistent with the improved phoneme error rate (PER) in Table 2.	I-Reply	I-2	Reply	240
<sep> <sep> <tab><tab>        Initial boundary (Wang et al)<tab><tab>Our refined boundaries	I-Reply	I-2	Reply	240
R-value<tab>        82.6<tab><tab><tab><tab><tab>                        84.8	I-Reply	I-2	Reply	240
F-score<tab>        80.1<tab><tab><tab><tab><tab>                        82.6	I-Reply	I-2	Reply	240
Recall<tab><tab>78.2<tab><tab><tab><tab><tab>                        80.9	I-Reply	I-2	Reply	240
Precision<tab>82.3<tab><tab><tab><tab><tab>                        84.3	I-Reply	I-2	Reply	240
<sep> However, we emphasize that our method is designed towards unsupervised speech recognition rather than unsupervised phoneme segmentation.	I-Reply	I-2	Reply	240
Estimating the segmentation boundary only serves as an auxiliary subtask to help the training of the recognition model in an unsupervised manner.	I-Reply	I-2	Reply	240
And in the testing stage, we do not estimate the segmentation boundaries for the test data.	I-Reply	I-2	Reply	240
Instead, our trained model could be directly used with decoder just as any supervised recognition model would do.	I-Reply	I-2	Reply	240
For this reason, the most important evaluation metric for our method is the phoneme error rate (PER).	I-Reply	I-2	Reply	240
Nevertheless, the above boundary evaluation results do confirm that the improved segmentation quality indeed leads to better phoneme recognition performance (see Table 2), which also demonstrates the effectiveness of our iterative algorithm.	I-Reply	I-2	Reply	240

[Overview]	O	O	Review	477
<sep> In this paper, the authors proposed a model called SD-GAN, to decompose semantical component of the input in GAN.	O	O	Review	477
Specifically, the authors proposed a novel architecture to decompose the identity latent code and non-identity latent code.	O	O	Review	477
In this new architecture, the generator is unchanged while the discriminator takes pair data as the input, and output the decision of whether two images are from the same identity or not.	O	O	Review	477
By training the whole model with a conventional GAN-training regime, SD-GAN learns to take a part of the input Z as the identity information, and the other part of input Z as the non-identity (or attribute) information.	O	O	Review	477
In the experiments, the authors demonstrate that the proposed SD-GAN could generate images preserving the same identity with diverse attributes, such as pose, age, expression, etc.	O	O	Review	477
Compared with AC-GAN, the proposed SD-GAN achieved better performance in both automatically evaluation metric (FaceNet) and Human Study.	O	O	Review	477
In the appendix, the authors further presented ablated qualitative results in various settings.	O	O	Review	477
<sep> <sep> [Strengths]	O	O	Review	477
<sep> 1.	O	O	Review	477
This paper proposed a simple but effective generative adversarial network, called SD-GAN, to decompose the input latent code of GAN into separate semantical parts.	O	O	Review	477
Specifically, it is mainly instantiated on face images, to decompose the identity part and non-identity part in the latent code.	O	O	Review	477
Unlike the previous works such as AC-GAN, SD-GAN exploited a Siamese network to replace the conventional discriminator used in GAN.	O	O	Review	477
By this way, SD-GAN could generate images of novel identities, rather than being constrained to those identities used during training.	O	O	Review	477
I think this is a very good property.	O	O	Review	477
Due to this, SD-GAN consumes much less memory than AC-GAN, when training on a large number of identities.	O	O	Review	477
<sep> <sep> 2.	O	O	Review	477
In the experiment section, the authors quantitatively evaluate the generated images based on two methods, one is using a pre-trained FaceNet model to measure the verification accuracy and one is human study.	O	O	Review	477
When evaluated based on FaceNet, the proposed SD-GAN achieved higher accuracy and obtained more diverse face images, compared with AC-GAN.	O	O	Review	477
In human study, SD-GAN achieved comparable verification accuracy, while higher diversity than AC-GAN.	O	O	Review	477
The authors further presented ablated experiments in the Appendix.	O	O	Review	477
<sep> <sep> [Comments]	O	O	Review	477
<sep> This paper presents a novel model to decompose the latent code in a semantic manner.	O	O	Review	477
However, I have several questions about the model:	O	O	Review	477
<sep> 1.	B-Review	B-1	Review	477
Why would SD-GAN not generate images merely have a smaller number of identities or just a few identities?	I-Review	I-1	Review	477
In Algorithm 1, the authors trained the model by sampling one identity vector, which is then concatenated to two observation vectors.	I-Review	I-1	Review	477
In this case, the generator always takes the same identity vectors, and the discriminator is used to distinguish these fake same-identity pair and the real same-identity pair from training data.	I-Review	I-1	Review	477
As such, even if the generator generates the same identity, say mean identity, given different identity vectors, the generated images can still obtain a lower discrimination loss.	I-Review	I-1	Review	477
Without any explicite constraint to enforce the generator to generate different identity with different identity vectors, I am wondering what makes SD-GAN be able to generate diverse identities?	I-Review	I-1	Review	477
<sep> <sep> 2.	O	O	Review	477
Still about the identity diversity.	B-Review	B-2	Review	477
Though the authors showed the identity-matched diversity in the experiments, the diversity across identity on the generated images is not evaluated.	I-Review	I-2	Review	477
The authors should also evaluate this kind of identity.	I-Review	I-2	Review	477
Generally, AC-GAN could generate as many identities as the number of identities in training data.	I-Review	I-2	Review	477
I am curious about whether SD-GAN could generate comparable diverse identity to AC-GAN.	I-Review	I-2	Review	477
One simple way is to evaluate the whole generated image set using Inception Score based on a Pre-trained face identification network; Another way is to directly use the generated images to train a verification model or identification model and evaluate it on real images.	I-Review	I-2	Review	477
Though compared with AC-GAN, SD-GAN achieved better identity verification performance and sample diversity, I suspect the identity diversity is discounted, though SD-GAN has the property of generating novel identities.	I-Review	I-2	Review	477
Furthermore,  the authors should also compare the general quality of generated samples with DC-GAN and BEGAN as well (at least qualitatively), apart from the comparison to AC-GAN on the identity-matched generation.	I-Review	I-2	Review	477
<sep> <sep> 3.	O	O	Review	477
When making the comparison with related work, the authors mentioned that Info-GAN was not able to determine which factors are assigned to each dimension.	B-Review	B-3	Review	477
I think this is not precise.	I-Review	I-3	Review	477
The lack of this property is because there are no data annotations.	I-Review	I-3	Review	477
Given the data annotations, Info-GAN can be easily augmented with such property by sending the real images into the discriminator for classification.	I-Review	I-3	Review	477
Also, there is a typo in the caption of Fig.10.	I-Review	I-3	Review	477
It looks like each column shares the same identity vector instead of each row.	I-Review	I-3	Review	477
<sep> <sep> [Summary]	O	O	Review	477
<sep> This paper proposed a new model called SD-GAN to decompose the input latent code of GAN into two separete semantical parts, one for identity and one for observations.	O	O	Review	477
Unlike AC-GAN, SD-GAN exploited a Siamese architecture in discriminator.	O	O	Review	477
By this way, SD-GAN could not only generate more identity-matched face image pairs but also more diverse samples with the same identity,  compared with AC-GAN.	O	O	Review	477
I think this is a good idea for decomposing the semantical parts in the latent code, in the sense that it can imagine new face identities and consumes less memory during training.	O	O	Review	477
Overall, I think this is a good paper.	O	O	Review	477
However, as I mentioned above, I am still not clear why SD-GAN could generate diverse identities without any constraints to make the model do that.	B-Review	B-1	Review	477
Also, the authors should further evaluate the diversity of identity and compare it with AC-GAN.	B-Review	B-2	Review	477
<sep> Thank you for your detailed comments.	O	O	Reply	477
In addition to adding information about identity diversity to the manuscript (see general response above), we offer the following responses to your other inquiries:	O	O	Reply	477
<sep> 1) Why would SD-GAN not generate images merely have a smaller number of identities or just a few identities?	O	O	Reply	477
<sep> <sep> If SD-GANs always produced images depicting the same identity regardless of the identity vector, the discriminator would be able to easily label these samples as fake on the basis that they always depict the same subject.	B-Reply	B-1	Reply	477
This is the same reason that regular GANs are able to produce images that differ in subject identity.	I-Reply	I-1	Reply	477
<sep> <sep> 3) When making the comparison with related work, the authors mentioned that Info-GAN was not able to determine which factors are assigned to each dimension.	O	O	Reply	477
I think this is not precise.	O	O	Reply	477
<sep> <sep> Thank you for pointing out that our statement about InfoGAN was imprecise.	O	O	Reply	477
Our original purpose in making this claim was to indicate that there is no *obvious* way to hold identity fixed while varying contingent factors in vanilla InfoGAN, and hence no way to directly compare it to our SD-GAN algorithm.	B-Reply	B-3	Reply	477
However, as you pointed out, InfoGAN is fully unsupervised while SD-GAN is not.	I-Reply	I-3	Reply	477
We have updated our related work section to clarify the distinction between InfoGAN and SD-GAN.	I-Reply	I-3	Reply	477

Summary:	O	O	Review	477
<sep> This paper investigated the problem of controlled image generation.	O	O	Review	477
Assuming images can be disentangled by identity-related factors and style factors, this paper proposed an algorithm that produces a pair of images with the same identity.	O	O	Review	477
Compared to standard GAN framework, this algorithm first generated two latent variables for the pair images.	O	O	Review	477
The two latent variables are partially shared reflecting the shared identity information.	O	O	Review	477
The generator then transformed the latent variables into high-resolution images with a deconvolution decoder networks.	O	O	Review	477
The discriminator was used to distinguish paired images from database or paired images sampled by the algorithm.	O	O	Review	477
Experiments were conducted using DCGAN and BEGAN on portrait images and shoe product images.	O	O	Review	477
Qualitative results demonstrated that the learned style representations capture viewpoint, illumination and background color while the identity was well preserved by the identity-related representations.	O	O	Review	477
<sep> <sep> <sep> == Novelty & Significance ==	O	O	Review	477
Paired image generation is an interesting topic but this has been explored to some extent.	O	O	Review	477
Compared to existing coupled generation pipeline such as CoGAN, I can see the proposed formulation is more application-driven.	O	O	Review	477
<sep> <sep> == Technical Quality ==	O	O	Review	477
In Figure 3, the portrait images in the second row and fourth row look quite similar.	B-Review	B-1	Review	477
I wonder if the trained model works with only limited variability (in terms of identity).	I-Review	I-1	Review	477
<sep> In Figure 4, the viewpoint is quite limited (only 4 viewpoints are provided).	B-Review	B-2	Review	477
<sep> <sep> I am not very convinced whether SD-GAN is a generic algorithm for controlled image generation.	B-Review	B-3	Review	477
Based on the current results, I suspect it only works in fairly constrained settings.	I-Review	I-3	Review	477
<sep> It would be good to know if it actually works in more challenging datasets such as SUN bedroom, CUB and Oxford Flowers.	I-Review	I-3	Review	477
<sep> <sep> ‚Äúthe AC-DCGAN model cannot imagine new identities‚Äù	B-Review	B-4	Review	477
I feel the author of this paper made an unfair argument when comparing AC-DCGAN with the proposed method.	I-Review	I-4	Review	477
First, during training, the proposed SD-GAN needs to access the identity information and there is only limited identity in the dataset.	I-Review	I-4	Review	477
Based on the presentation, it is not very clear how does the model generate novel identities (in contrast to simply interpolating existing identities).	I-Review	I-4	Review	477
For example, is it possible to generate novel viewpoints in Figure 4?	I-Review	I-4	Review	477
<sep> <sep> Missing references on conditional image generation and coupled image generation:	B-Review	B-5	Review	477
-- Generative Adversarial Text-to-Image Synthesis.	I-Review	I-5	Review	477
Reed et al In ICML 2016.	I-Review	I-5	Review	477
<sep> -- Attribute2Image: Conditional Image Generation from Visual Attributes.	I-Review	I-5	Review	477
Yan et al In ECCV 2016.	I-Review	I-5	Review	477
<sep> -- Domain Separation Networks.	I-Review	I-5	Review	477
Bousmalis et al In NIPS 2016.	I-Review	I-5	Review	477
<sep> -- Unsupervised Image-to-Image Translation Networks.	I-Review	I-5	Review	477
Liu et al In NIPS 2017.	I-Review	I-5	Review	477
<sep> <sep> Overall, I rate this paper slightly above borderline.	O	O	Review	477
It showed some good visualization results on controlled image generation.	O	O	Review	477
But the comparison to AC-GAN is not very fair, since the identity pairs are fully supervised for the proposed method.	O	O	Review	477
As far as I can see, there are no clear-cut improvements quantitatively.	O	O	Review	477
Also, there is no comparison with CoGAN, which I believe is the most relevant work for coupled image generation.	B-Review	B-6	Review	477
<sep> <sep> <sep> Thank you for your response and for pointing out missing references.	O	O	Reply	477
We have added them to our related work section in the updated manuscript.	O	O	Reply	477
Please see our general response above with regard to identity diversity.	O	O	Reply	477
<sep> <sep> We did not quantitatively compare to CoGAN as their problem objectives are different from our own.	B-Reply	B-6	Reply	477
CoGANs learn to translate images between domains with binary attributes such as blond/brown hair or glasses/no-glasses without parallel data.	I-Reply	I-6	Reply	477
How one might extend CoGANs to learn a manifold over thousands of identities is non-obvious.	I-Reply	I-6	Reply	477
<sep> <sep> As you suggested, we would also like to run studies on other types of data (the Oxford Flowers dataset that you recommended is particularly enticing), but leave this as an avenue for our future explorations.	B-Reply	B-3	Reply	477

Quality	O	O	Review	477
The paper is well written and the model is simple and clearly explained.	O	O	Review	477
The idea for disentangling identity from other factors of variation using identity-matched image pairs is quite simple, but the experimental results on faces and shoes are impressive.	O	O	Review	477
<sep> <sep> Clarity	O	O	Review	477
The model and its training objective are simple and clearly explained.	O	O	Review	477
<sep> <sep> Originality	O	O	Review	477
There are now many, many papers on generative models with disentangled feature representations, including with GANs.	O	O	Review	477
However, to my knowledge this is the first paper showing very compelling results using this particular setup of identity-aligned images.	O	O	Review	477
<sep> <sep> Significance	O	O	Review	477
Disentangled generative models are an important line of work in my opinion.	O	O	Review	477
This paper presents a very simple but apparently effective way of disentangling identity from other factors, and implements in two of the more recent GAN architectures.	O	O	Review	477
<sep> <sep> Suggestion for an experiment - can you do few shot image generation?	B-Review	B-1	Review	477
A simple way to do it would be to train an encoder from image ‚Üí identity encoding.	I-Review	I-1	Review	477
Then, given one or a few images of a new person‚Äôs face or a new shoe, you could estimate the identity latent variable, and then generate many additional samples.	I-Review	I-1	Review	477
<sep> <sep> Pros	O	O	Review	477
- Very simple and effective disentangling technique for GANs.	O	O	Review	477
<sep> - Great execution, compelling samples on both faces and shoes.	O	O	Review	477
<sep> <sep> Cons	O	O	Review	477
- Only two factors of variations are disentangled in this model.	B-Review	B-2	Review	477
Could it be generalized to specify more than just two, e.g. lighting, pose, viewpoint, etc?	I-Review	I-2	Review	477
<sep> - Not much technically new or surprising compared to past work on disentangling generative models.	B-Review	B-3	Review	477
<sep> Thank you for your insights.	O	O	Reply	477
We are glad that you found our paper to be well-written and our method to be both simple and effective.	B-Reply	B-2	Reply	477
Your intuition is correct that SD-GAN could be extended to disentangle multiple factors of variation.	I-Reply	I-2	Reply	477
We are actively investigating this and plan to publish these results in future work.	I-Reply	I-2	Reply	477
You are also correct that SD-GAN could be modified for few-shot image generation; please see Appendix B (and the relevant Figure 8) for our preliminary investigation and results in this setting.	B-Reply	B-1	Reply	477

The authors present an algorithm for actively learning the nodes in a graph that should be sampled/labeled in order to improve classifier performance the most.	O	O	Review	477
The proposed techniques use both the graph structure, and the current classifier performance/accuracy into account while (actively) selecting the next node to be labeled.	O	O	Review	477
<sep> <sep> There seem to be two main contributions in the paper.	O	O	Review	477
1) The propose to sample nodes nodes based on "regional" uncertainty rather than node uncertainty 2) They use an variant of pagerank to determine nodes that are central, and hence most likely to affect subsequent classification in graph convolution classifiers.	O	O	Review	477
Both approaches seem to be interesting.	O	O	Review	477
There are experiments to show effectiveness of these techniques, and there are some interesting observations (for example, that the APR technique works better for smaller sample sizes, while the regional uncertainty methods do better for larger sampling fractions.).	O	O	Review	477
<sep> <sep> While both techniques seem straightforward extensions of previous approaches (and are well explained in the paper),  the experiments indicate that they work better than prior approaches.	O	O	Review	477
It would have been nice if the authors had also discussed ways in which one or more of these techniques could be combined though, or discussed how we could pick the right approach (in a more empirical way, since it is not clear what the threshold for high sampling rate/low sampling rate distinction is, or if it varies from problem to problem)	B-Review	B-1	Review	477
Reviewer 1 has one main critique, which is that there is no clear explanation of how to choose in advance a method.	O	O	Reply	477
This critique is also shared by the second reviewer.	O	O	Reply	477
Following both comments reviews, we now add a clear section on how to choose among the different algorithms that we propose.	O	O	Reply	477

The paper studies active learning in graph representations.	O	O	Review	477
To decide which nodes in a graph to label during the active labeling, the paper proposes two approaches.	O	O	Review	477
First it argues that one should consider region-based measures rather than single nodes.	O	O	Review	477
Second, it proposes to adapt the page rank algorithm (APR) to determine which nodes are far away from labeled nodes.	O	O	Review	477
<sep> <sep> Overall it remains unclear *how* to select the right strategy (before seeing the results for a dataset) i.e. which of the proposed approaches or variants should one select for a new dataset.	B-Review	B-1	Review	477
<sep> <sep> Strength:	O	O	Review	477
-<tab>One of the ideas of the paper, using region entropy over single node entropy makes sense to me.	O	O	Review	477
<sep> -<tab>The paper evaluates on 6 datasets and compares different variants as well to related work on 2 datasets.	O	O	Review	477
<sep> <sep> Weaknesses:	O	O	Review	477
1.	O	O	Review	477
<tab>The paper contains several confusing and contradicting statements or claims which are not supported by the experimental results:	B-Review	B-2	Review	477
For example:	I-Review	I-2	Review	477
1.1.	I-Review	I-2	Review	477
<tab>‚ÄúAPR outperforms all other methods at low sampling fractions‚Äù.	I-Review	I-2	Review	477
This is supported neither in Table 1 nor Table 2, where APR is frequently not highest performing	I-Review	I-2	Review	477
1.2.	O	O	Review	477
<tab> ‚ÄúWe have here shown that the accuracy of AL when uncertainty is computed regionally is much higher than when either local uncertainty or representative nodes are used‚Äù, this is not the case on CiteSeer in Table 1	B-Review	B-3	Review	477
1.2.1.	O	O	Review	477
<tab>Also e.g. ‚ÄúRegion Margin‚Äù is worse than random on 5% Email-EU; or ‚ÄúRegion Margin AE‚Äù on 3% SubeljCora (Table 2) [It is unclear how to select with or without AE]	B-Review	B-4	Review	477
1.3.	O	O	Review	477
<tab>‚ÄúWe outperform all existing methods in the Cora dataset, and get very similar results to the best accuracy obtained by Chang et al methods:‚Äù	B-Review	B-5	Review	477
1.3.1.	I-Review	I-5	Review	477
<tab>The difference to Cai et al on Cora is very small (improvement by only 0.002), while on Citeseer the performance is comparatively bigger (Cai et al is by 0.016 better)	I-Review	I-5	Review	477
1.3.2.	I-Review	I-5	Review	477
<tab>It should be ‚ÄúCai et al‚Äù	I-Review	I-5	Review	477
2.	O	O	Review	477
<tab>Clarity: I found the paper rather difficult to understand and follow:	B-Review	B-6	Review	477
Some specifics:	I-Review	I-6	Review	477
2.1.	I-Review	I-6	Review	477
<tab>The introduction could be more concisely discussing the motivation, the main idea of the paper, as well as contributions.	I-Review	I-6	Review	477
<sep> 2.2.	O	O	Review	477
<tab>Figure 1: according to the caption, APR should point to node 15, but in the figure it points to node 14.	B-Review	B-6	Review	477
From the example it makes much more sense to label node 14 to me.	I-Review	I-6	Review	477
<sep> 2.3.	O	O	Review	477
<tab>Page 6 mentions twice the ‚Äúratio between APR and PR‚Äù, is this is this used/evaluated in the results?	B-Review	B-7	Review	477
<sep> 2.4.	O	O	Review	477
<tab>The decision what is bold and what is not is not consistent throughout the table 2.	B-Review	B-8	Review	477
<sep> 2.5.	O	O	Review	477
<tab>‚ÄúThus, hybrid techniques, combining several approaches, outperform using only one approach have been proposed.	B-Review	B-9	Review	477
‚Äù It is not clear what this refers to and where the hybrid techniques have been evaluated.	I-Review	I-9	Review	477
<sep> <sep> Minor:	B-Review	B-10	Review	477
The paper contains many minor writing issues, e.g.	I-Review	I-10	Review	477
-<tab>missing spaces, e.g. ‚Äúdistribution,and‚Äù (page 2)	I-Review	I-10	Review	477
-<tab>Table 1: incomplete sentence: ‚Äú‚àó‚àó scores for smaller budget, since it was the‚Äù	I-Review	I-10	Review	477
-<tab>Table 2: unclear: ‚Äúaccuracy without content‚Äù	I-Review	I-10	Review	477
<sep> The paper‚Äôs incorrect claims (weakness 1) are highly concerning and strongly suggest rejecting the paper.	B-Review	B-11	Review	477
Furthermore, the clarity of the paper should be improved to follow the author arguments and make the paper easier to read.	I-Review	I-11	Review	477
<sep> <sep> <sep> Reviewer 2 has the same main comment as reviewer 1. ‚	O	O	Reply	477
ÄúOverall it remains unclear *how* to select the right strategy (before seeing the results for a dataset) i.e. which of the proposed approaches or variants should one select for a new dataset.	O	O	Reply	477
‚Äù.	O	O	Reply	477
Again, we added now such a section in the discussion.	O	O	Reply	477
<sep> <sep> Beyond that the main critiques of reviewer 2 are on clarity and some minor wording issues.	B-Reply	B-1	Reply	477
We have now edited all the issues mentioned by the reviewer, as well as other aspects of the paper that required extra clarity.	I-Reply	I-1	Reply	477
<sep> <sep> Following is a detailed answer to the reviewer	O	O	Reply	477
<sep> Review: The paper studies active learning in graph representations.	O	O	Reply	477
To decide which nodes in a graph to label during the active labeling, the paper proposes two approaches.	O	O	Reply	477
First it argues that one should consider region-based measures rather than single nodes.	O	O	Reply	477
Second, it proposes to adapt the page rank algorithm (APR) to determine which nodes are far away from labeled nodes.	O	O	Reply	477
<sep> <sep> Overall it remains unclear *how* to select the right strategy (before seeing the results for a dataset) i.e. which of the proposed approaches or variants should one select for a new dataset.	O	O	Reply	477
Strength: - One of the ideas of the paper, using region entropy over single node entropy makes sense to me. -	O	O	Reply	477
The paper evaluates on 6 datasets and compares different variants as well to related work on 2 datasets.	O	O	Reply	477
Weaknesses:	O	O	Reply	477
1.	O	O	Reply	477
The paper contains several confusing and contradicting statements or claims which are not supported by the experimental results: For example:	O	O	Reply	477
1.1. ‚	O	O	Reply	477
ÄúAPR outperforms all other methods at low sampling fractions‚Äù.	O	O	Reply	477
This is supported neither in Table 1 nor Table 2, where APR is frequently not highest performing	O	O	Reply	477
<sep> Answer.	O	O	Reply	477
This is only half the statement.	B-Reply	B-2	Reply	477
The full statement was ‚ÄúAs mentioned in multiple datasets, the APR outperforms all other methods at low sampling fractions(typically less than 5 %).‚Äù.	I-Reply	I-2	Reply	477
We were explicit about the fact that this was in only some dataset.	I-Reply	I-2	Reply	477
We have now further clarified that in case this was not clear enough.	I-Reply	I-2	Reply	477
<sep> <sep> 1.2. ‚	O	O	Reply	477
ÄúWe have here shown that the accuracy of AL when uncertainty is computed regionally is much higher than when either local uncertainty or representative nodes are used‚Äù, this is not the case on CiteSeer in Table 1	O	O	Reply	477
<sep> <sep> Answer.	B-Reply	B-3	Reply	477
Indeed, but it is true in all other datasets, for most sampling sizes.	I-Reply	I-3	Reply	477
We have stated that as a general statement, and have now clarified it to avoid any possible doubt.	I-Reply	I-3	Reply	477
<sep> <sep> 1.2.1.	O	O	Reply	477
Also e.g. ‚ÄúRegion Margin‚Äù is worse than random on 5% Email-EU; or ‚ÄúRegion Margin AE‚Äù on 3% SubeljCora (Table 2) [It is unclear how to select with or without AE]	O	O	Reply	477
<sep> <sep> Answer.	B-Reply	B-4	Reply	477
We now discuss clearly model choice.	I-Reply	I-4	Reply	477
<sep> <sep> 1.3. ‚	O	O	Reply	477
ÄúWe outperform all existing methods in the Cora dataset, and get very similar results to the best accuracy obtained by Chang et al methods:‚Äù	O	O	Reply	477
1.3.1.	O	O	Reply	477
The difference to Cai et al on Cora is very small (improvement by only 0.002), while on Citeseer the performance is comparatively bigger (Cai et al is by 0.016 better) 1.3.2.	O	O	Reply	477
It should be ‚ÄúCai et al‚Äù	O	O	Reply	477
<sep> <sep> Answer.	O	O	Reply	477
The statement was rephrased and the reference was corrected too.	B-Reply	B-5	Reply	477
<sep> <sep> Clarity: I found the paper rather difficult to understand and follow: Some specifics: 2.1.	O	O	Reply	477
The introduction could be more concisely discussing the motivation, the main idea of the paper, as well as contributions.	O	O	Reply	477
2.2.	O	O	Reply	477
Figure 1: according to the caption, APR should point to node 15, but in the figure it points to node 14.	O	O	Reply	477
From the example it makes much more sense to label node 14 to me.	O	O	Reply	477
<sep> <sep> Answer.	O	O	Reply	477
This was indeed a typo and it was corrected.	B-Reply	B-6	Reply	477
<sep> <sep> 2.3.	O	O	Reply	477
Page 6 mentions twice the ‚Äúratio between APR and PR‚Äù, is this is this used/evaluated in the results?	O	O	Reply	477
<sep> <sep> Answer.	B-Reply	B-7	Reply	477
The ratio between APR and PR is precisely what is used.	I-Reply	I-7	Reply	477
This is now clarified in the text.	I-Reply	I-7	Reply	477
<sep> <sep> 2.4.	O	O	Reply	477
The decision what is bold and what is not is not consistent throughout the table 2.	O	O	Reply	477
2.5.	O	O	Reply	477
<sep> <sep> Answer.	O	O	Reply	477
This was also corrected.	B-Reply	B-8	Reply	477
<sep> <sep> ‚ÄúThus, hybrid techniques, combining several approaches, outperform using only one approach have been proposed.	O	O	Reply	477
‚Äù It is not clear what this refers to and where the hybrid techniques have been evaluated.	O	O	Reply	477
<sep> <sep> Answer.	O	O	Reply	477
This referred to previous work and is now clarified.	B-Reply	B-9	Reply	477
<sep> <sep> Minor: The paper contains many minor writing issues, e.g. - missing spaces, e.g. ‚Äúdistribution,and‚Äù (page 2) - Table 1: incomplete sentence: ‚Äú‚àó‚àó scores for smaller budget, since it was the‚Äù - Table 2: unclear: ‚Äúaccuracy without content‚Äù	O	O	Reply	477
<sep> Answer.	O	O	Reply	477
These minor issues were corrected.	B-Reply	B-10	Reply	477
<sep> <sep> The paper‚Äôs incorrect claims (weakness 1) are highly concerning and strongly suggest rejecting the paper.	O	O	Reply	477
Furthermore, the clarity of the paper should be improved to follow the author arguments and make the paper easier to read.	O	O	Reply	477
<sep> <sep> As explained the claim that the reviewer claims to be incorrect was half a sentence, when the entire sentence is read, there were no incorrect claims.	B-Reply	B-11	Reply	477
We would thus appreciate a change of decision by the reviewer.	I-Reply	I-11	Reply	477

This paper proposes to use a GAN style approach for training a classifier that is robust to data poisoning and can achieve a pre-specified notion of group fairness.	O	O	Review	486
<sep> <sep> The contribution of this paper is incremental in the context of prior Adversarial Debasing (AD) approach using essentially same GAN for group fairness and prior work presenting ideas of utilizing clean validation data to defend against data poisoning.	B-Review	B-1	Review	486
This paper is proposing to add an additional discriminator to the AD approach that distinguishes training data and clean validation data.	I-Review	I-1	Review	486
If the training data is poisoned, such distinguishment may be possible and maximizing loss of this discriminator can help to robustify against poisoned samples.	I-Review	I-1	Review	486
<sep> <sep> Experimental results are insufficient to argue improvement over the AD.	B-Review	B-2	Review	486
There are no AD results in the equalized odds Adult experiment in the supplement.	I-Review	I-2	Review	486
I recommend more detailed comparison against the AD method (including results showing confusion matrices).	I-Review	I-2	Review	486
Also note that AD, as presented in the original paper, is optimizing for demographic parity, but can also be adjusted to other group fairness metrics.	I-Review	I-2	Review	486
Finally, in the context of Adult dataset, it is important to also report performance metrics such as balanced TPR since the labels are quite imbalanced.	I-Review	I-2	Review	486
<sep> <sep> Are there any real data examples where poisoning does not need to be introduced artificially and the proposed method helps to improve the fairness properties?	B-Review	B-3	Review	486
I think an interesting direction could be to consider data where labels are subjective.	I-Review	I-3	Review	486
For example, a dataset on loan decisions can be naturally "poisoned" with human biases, i.e. information that someone did not receive the loan may be due to an error or bias of a human in charge of the decision making.	I-Review	I-3	Review	486
<sep> <sep> Lastly I think that the discussion of the prior related work on fairness is incomplete.	B-Review	B-4	Review	486
This paper exclusively covers group fairness, which indeed has been shown to have some disadvantages.	I-Review	I-4	Review	486
For example, prior work [1] has shown that some group fairness notions can not be satisfied simultaneously in certain cases.	I-Review	I-4	Review	486
In this regard it is also important to report multiple group fairness metrics simultaneously in the experiments.	I-Review	I-4	Review	486
The other fairness definition, that has not been mentioned in this paper, is individual fairness [2]. It has legal and intuitive interpretations.	I-Review	I-4	Review	486
Multiple recent papers have explored the direction of individual fairness [3,4,5,6].	I-Review	I-4	Review	486
<sep> [1] Kleinberg, J., Mullainathan, S., &amp; Raghavan, M. (2016).	O	O	Review	486
Inherent trade-offs in the fair determination of risk scores.	O	O	Review	486
<sep> [2] Dwork, C., Hardt, M., Pitassi, T., Reingold, O., &amp; Zemel, R. (2012, January).	O	O	Review	486
Fairness through awareness.	O	O	Review	486
<sep> [3] Garg, S., Perot, V., Limtiaco, N., Taly, A., Chi, E. H., &amp; Beutel, A. (2019, January).	O	O	Review	486
Counterfactual fairness in text classification through robustness.	O	O	Review	486
<sep> [4] Yurochkin, M., Bower, A., &amp; Sun, Y. (2019).	O	O	Review	486
Learning fair predictors with Sensitive Subspace Robustness.	O	O	Review	486
<sep> [5] Kearns, M., Roth, A., &amp; Sharifi-Malvajerdi, S. (2019).	O	O	Review	486
Average Individual Fairness: Algorithms, Generalization and Experiments.	O	O	Review	486
<sep> [6] Jung, C., Kearns, M., Neel, S., Roth, A., Stapleton, L., &amp; Wu, Z. S. (2019).	O	O	Review	486
Eliciting and Enforcing Subjective Individual Fairness.	O	O	Review	486
Thanks for the insightful comments.	O	O	Reply	486
<sep> <sep> Q1-1.	O	O	Reply	486
Motivation and Contributions	O	O	Reply	486
<sep> A1-1.	O	O	Reply	486
<sep> We agree that the fairness part of FR-GAN is similar to Adversarial Debiasing (AD).	B-Reply	B-1	Reply	486
However, we believe that given that real data would increasingly become both biased and poisoned (this is what we expect in the big data era - see the next paragraph for details), our main contribution of providing an integrated solution for fair and robust training is likely to become important in the near future.	I-Reply	I-1	Reply	486
<sep> <sep> We contend that supporting robust training is just as critical as fair training.	I-Reply	I-1	Reply	486
Dataset searching is becoming mainstream as demonstrated by Google Dataset Search (Goods) [1] and its public version for searching scientific datasets [2]. While data lakes within companies  may consist of refined datasets, datasets in the public are easy to poison.	I-Reply	I-1	Reply	486
In our experiments, we could easily poison the Adult and COMPAS datasets using simple label flipping techniques.	I-Reply	I-1	Reply	486
And anyone can poison public datasets using attacks in the literature and share them.	I-Reply	I-1	Reply	486
We thus believe that it is essential to address both bias and poisoning as a preventive measure.	I-Reply	I-1	Reply	486
<sep> <sep> Regarding technical contributions, we strengthen the theoretical results of AD using information theory, and this motivates us to propose a novel robust training discriminator.	I-Reply	I-1	Reply	486
We agree that the key insight of using adversarial training to minimize mutual information between the prediction and sensitive attribute is the same for FR-GAN and AD.	I-Reply	I-1	Reply	486
Although, the end algorithms of FR-GAN and AD are also similar, our paper plays a role in providing systematic methodology not only for various fairness metrics, but also for the design of robust training.	I-Reply	I-1	Reply	486
As far as we know, no other validation-set-based approach (including Ren et.al.	I-Reply	I-1	Reply	486
2018) leverages the idea of adversarial training.	I-Reply	I-1	Reply	486
<sep> We reflected all of the points above in our revision (Sections 1 and 2, highlighted in blue).	I-Reply	I-1	Reply	486
<sep> <sep> [1] Goods: Organizing Google's Datasets, ACM SIGMOD 2017.	O	O	Reply	486
<sep> [2] Google Dataset Search: Building a search engine for datasets in an open Web ecosystem, WWW 2019.	O	O	Reply	486
<sep> <sep> <sep> Q1-2.	O	O	Reply	486
Experiments	O	O	Reply	486
<sep> A1-2.	O	O	Reply	486
<sep> As per your great comment, we now performed more detailed comparisons with AD.	B-Reply	B-2	Reply	486
In particular, we generated confusion matrices both for disparate impact and equalized odds.	I-Reply	I-2	Reply	486
As a result, we find FR-GAN performs better than AD under such measures, perhaps due to our robustness discriminator component (please see Appendix A.5 in the revised version of our paper, highlighted in blue).	I-Reply	I-2	Reply	486
The robustness discriminator successfully ignores the poisoned distribution in the training data, and FR-GAN's TPR is higher than AD with sanitization.	I-Reply	I-2	Reply	486
We may further refine our results later.	I-Reply	I-2	Reply	486
<sep> <sep> <sep> Q1-3.	O	O	Reply	486
Real-world examples	O	O	Reply	486
<sep> A1-3.	O	O	Reply	486
<sep> Unfortunately, there is no such public poisoned dataset in the context of fairness training.	B-Reply	B-3	Reply	486
We believe this is because: 1) the fair-&amp;-robust training of our focus is a new topic; and 2) no adversary would explicitly claim that s/he poisoned a dataset.	I-Reply	I-3	Reply	486
<sep> <sep> We fully agree that FR-GAN can be generalized to a setting where labels are subjective instead of being clean or poisoned.	I-Reply	I-3	Reply	486
Here the dataset without the undesirable human biases becomes the "clean" validation set.	I-Reply	I-3	Reply	486
Inspired by this idea, we would like to propose a new method for constructing a real dataset.	I-Reply	I-3	Reply	486
Suppose that we are indeed performing loan decisions where there is a high chance of human bias (i.e., poisoning) due to the high workload.	I-Reply	I-3	Reply	486
We can construct a clean validation set by selecting a few loans, assigning more evaluators, and taking a majority vote of the evaluations to minimize the bias.	I-Reply	I-3	Reply	486
While employing more evaluators can be expensive, constructing a small validation set is sufficient for robust training, which makes this method practical.	I-Reply	I-3	Reply	486
<sep> <sep> In general, given two datasets with different distributions where one of them is desirable, FR-GAN can train robustly against the other distribution.	I-Reply	I-3	Reply	486
<sep> <sep> We reflected all the points above in our revision (Section 6, highlighted in blue).	I-Reply	I-3	Reply	486
<sep> <sep> <sep> Q1-4.	O	O	Reply	486
Related work	O	O	Reply	486
<sep> A1-4.	O	O	Reply	486
<sep> We thank the reviewers for introducing papers on individual fairness.	B-Reply	B-4	Reply	486
We were actually aware of this literature, but since FR-GAN is solving a new problem, our first step was to use prominent measures for group fairness, just like the AD paper.	I-Reply	I-4	Reply	486
We mentioned all the individual fairness measures in our revision (Section 2, highlighted in blue) and will investigate them in a future work.	I-Reply	I-4	Reply	486

This paper combines adversarial fair training with adversarial robust training.	O	O	Review	486
The basic idea is that a classifier is combined with two adversaries: one tries to predict the sensitive attribute from the output of the classifier (essentially the approach by Edwards&amp;Storkey 2015) and the other adversary tries to recognize if a label was predicted or is from a clean hold-out dataset.	O	O	Review	486
The latter is intended to harden the classifier against data-poisoning of the training set.	O	O	Review	486
<sep> <sep> ---	O	O	Review	486
<sep> The paper is clearly written and technically sound.	O	O	Review	486
<sep> <sep> The fairness aspect of the proposed method is fairly standard and not very novel (going back to 2015).	B-Review	B-1	Review	486
The robustness aspect is an interesting addition and seems novel, but I'm not sure if it's enough to get the paper accepted.	I-Review	I-1	Review	486
If I understand it correctly, FR-GAN without the "R" part should just be equivalent to Adversarial Debiasing (Zhang et al 2018).	I-Review	I-1	Review	486
And if there is no data-poisoning, then the "R" part doesn't have any effect.	I-Review	I-1	Review	486
<sep> <sep> The fact that this is the first fairness-related method that additionally deals with robustness, makes it also difficult to judge the performance of the method.	B-Review	B-2	Review	486
I would wish for a more appropriate baseline; one that makes use of the clean validation set somehow.	I-Review	I-2	Review	486
<sep> <sep> There might be synergistic effects where the robustness aspects helps the fairness aspect but this comes at the cost of needing a clean validation set (and it only matters with poisoned data).	I-Review	I-2	Review	486
<sep> <sep> What is also missing is a motivating real-world example.	B-Review	B-3	Review	486
When would you encounter flipped labels in the training set, but also have access to a clean validation set?	I-Review	I-3	Review	486
<sep> <sep> Minor comments:	O	O	Review	486
<sep> - I did not understand what was meant by the phrase "so that the model accuracy is reduced the most."	B-Review	B-4	Review	486
in the first paragraph of section 3	I-Review	I-4	Review	486
Thanks for the insightful comments.	O	O	Reply	486
<sep> <sep> Q2-1.	O	O	Reply	486
Novelty and Motivation	O	O	Reply	486
<sep> A2-1.	O	O	Reply	486
<sep> We agree that the fairness part of FR-GAN is similar to Adversarial Debiasing (AD).	B-Reply	B-1	Reply	486
However, we believe that given that real data would increasingly become both biased and poisoned (this is what we expect in the big data era - see the next paragraph for details), our main contribution of providing an integrated solution for fair and robust training is likely to become important in the near future.	I-Reply	I-1	Reply	486
<sep> <sep> We contend that supporting robust training is just as critical as fair training.	I-Reply	I-1	Reply	486
Dataset searching is becoming mainstream as demonstrated by Google Dataset Search (Goods) [1] and its public version for searching scientific datasets [2]. While data lakes within companies may consist of refined datasets, datasets in the public are easy to poison.	I-Reply	I-1	Reply	486
In our experiments, we could easily poison the Adult and COMPAS datasets using simple label flipping techniques.	I-Reply	I-1	Reply	486
And anyone can poison public datasets using attacks in the literature and share them.	I-Reply	I-1	Reply	486
We thus believe that it is essential to address both bias and poisoning as a preventive measure.	I-Reply	I-1	Reply	486
<sep> <sep> Regarding technical contributions, we strengthen the theoretical results of AD using information theory, and this motivates us to propose a novel robust training discriminator.	I-Reply	I-1	Reply	486
We agree that the key insight of using adversarial training to minimize mutual information between the prediction and sensitive attribute is the same for FR-GAN and AD.	I-Reply	I-1	Reply	486
Although, the end algorithms of FR-GAN and AD are also similar, our paper plays a role in providing systematic methodology not only for various fairness metrics, but also for the design of robust training.	I-Reply	I-1	Reply	486
As far as we know, no other validation-set-based approach (including Ren et al 2018) leverages the idea of adversarial training.	I-Reply	I-1	Reply	486
<sep> We reflected all of the points above in our revision (Sections 1 and 2, highlighted in blue).	I-Reply	I-1	Reply	486
<sep> <sep> [1] Goods: Organizing Google's Datasets, ACM SIGMOD 2017.	O	O	Reply	486
<sep> [2] Google Dataset Search: Building a search engine for datasets in an open Web ecosystem, WWW 2019.	O	O	Reply	486
<sep> <sep> <sep> Q2-2.	O	O	Reply	486
Baseline	O	O	Reply	486
<sep> A2-2.	O	O	Reply	486
<sep> As Reviewer 2 mentioned, FR-GAN is one of the first works to address both fairness and robustness and that there are few baselines to compare with.	B-Reply	B-2	Reply	486
Hence, we employed one reasonable baseline, which first sanitizes the poisoned data using a well-known sanitization technique and then performs a fair training (see Tables 1 and 2, rows with +LD).	I-Reply	I-2	Reply	486
We clarified these points in our revision (Section 5.1, highlighted in blue).	I-Reply	I-2	Reply	486
<sep> <sep> <sep> Q2-3.	O	O	Reply	486
Motivating real-world example	O	O	Reply	486
<sep> A2-3.	O	O	Reply	486
<sep> Unfortunately, there is no such public poisoned dataset in the context of fairness training.	B-Reply	B-3	Reply	486
We believe this is because: 1) the fair-&amp;-robust training of our focus is a new topic; and 2) no adversary would explicitly claim that s/he poisoned a dataset.	I-Reply	I-3	Reply	486
<sep> <sep> We agree with Reviewer 1 that FR-GAN can be generalized to a setting where labels are subjective instead of being clean or poisoned.	I-Reply	I-3	Reply	486
Here the dataset without the undesirable human biases becomes the "clean" validation set.	I-Reply	I-3	Reply	486
Inspired by this idea, we would like to propose a new method for constructing a real dataset.	I-Reply	I-3	Reply	486
Suppose that we are indeed performing loan decisions where there is a high chance of human bias (i.e., poisoning) due to the high workload.	I-Reply	I-3	Reply	486
We can construct a clean validation set by selecting a few loans, assigning more evaluators, and taking a majority vote of the evaluations to minimize the bias.	I-Reply	I-3	Reply	486
While employing more evaluators can be expensive, constructing a small validation set is sufficient for robust training, which makes this method practical.	I-Reply	I-3	Reply	486
We reflected these points in our revision (Section 6, highlighted in blue).	I-Reply	I-3	Reply	486
<sep> <sep> <sep> Q2-4.	O	O	Reply	486
Minor comment	O	O	Reply	486
<sep> A2-4.	O	O	Reply	486
<sep> We rephrased "so that the model accuracy is reduced the most" in Section 3 to "To generate poisoned data, we measure accuracy degradation for a flipping of each Z. We then choose the top-10% of the Z values with the highest degradation and flip them." (	B-Reply	B-4	Reply	486
Section 3, highlighted in blue).	I-Reply	I-4	Reply	486
Thanks for pointing this out.	I-Reply	I-4	Reply	486

This paper introduces a new method for training a classifier that simultaneously optimizes for a fairness criterion and robustness to data poisoning.	O	O	Review	486
The method is shown to increase measures of fairness and reduce inaccuracy on poisoned data relative to classifiers that only consider accuracy or fairness.	O	O	Review	486
Extensive results are shown for both synthetic and real benchmark data sets.	O	O	Review	486
<sep> <sep> I would lean to reject for the following reasons: 1) the problem is not well-motivated.	B-Review	B-1	Review	486
I would like a more clear example of some problem with sensitive attributes in which the data is publicly available and the providers of the data are motivated to falsify it.	I-Review	I-1	Review	486
2) the contribution is very simple and the individual pieces do not seem to be significant contributions.	B-Review	B-2	Review	486
In particular, the use of GANs for fairness is previously done, and the use of the GAN for robustness here seems too simple to be broadly useful 3) the results are less convincing than they might otherwise be because none of the competing methods tested make use of a clean validation set 4) the paper is somewhat unpolished.	B-Review	B-4	Review	486
I find the results difficult to read, although the arrows are helpful, and it is not clear to me whether these results are on a test set or the training set.	I-Review	I-4	Review	486
<sep> <sep> Lack of convincing tests for robustness: It is disappointing that FR-GAN does not offer any promises to be robust in general.	B-Review	B-5	Review	486
Despite access to a clean validation set, the classifier is trained only to ignore the type of data poisoning that exists in the training set.	I-Review	I-5	Review	486
If the test set were out of distribution in a different way relative to the training set, I see no reason to believe FR-GAN would protect against this.	I-Review	I-5	Review	486
Furthermore, because it is not stated that these are test set results, I am not certain that they are not training set results, in which case some performance may be due to overfitting.	I-Review	I-5	Review	486
<sep> <sep> Minor notes:	O	O	Review	486
<sep> It would be nice for comparison if the charts had the same axes throughout.	B-Review	B-6	Review	486
<sep> <sep> What are the numbers of nodes used in the hidden layers?	I-Review	I-6	Review	486
Thanks for the insightful comments.	O	O	Reply	486
<sep> <sep> Q3-1. (	O	O	Reply	486
1) motivation	O	O	Reply	486
<sep> A3-1.	O	O	Reply	486
<sep> We believe that given that real data would increasingly become both biased and poisoned (this is what we expect in the big data era - see the next paragraph for details), our main contribution of providing an integrated solution for fair and robust training is likely to become important in the near future.	B-Reply	B-1	Reply	486
<sep> <sep> We contend that supporting robust training is just as critical as fair training.	I-Reply	I-1	Reply	486
Dataset searching is becoming mainstream as demonstrated by Google Dataset Search (Goods) [1] and its public version for searching scientific datasets [2]. While data lakes within companies may consist of refined datasets, datasets in the public are easy to poison.	I-Reply	I-1	Reply	486
In our experiments, we could easily poison the Adult and COMPAS datasets using simple label flipping techniques.	I-Reply	I-1	Reply	486
And anyone can poison public datasets using attacks in the literature and share them.	I-Reply	I-1	Reply	486
We thus believe that it is essential to address both bias and poisoning as a preventive measure.	I-Reply	I-1	Reply	486
We reflected these points in our revision (Section 1, highlighted in blue).	I-Reply	I-1	Reply	486
<sep> <sep> [1] Goods: Organizing Google's Datasets, ACM SIGMOD 2017.	O	O	Reply	486
<sep> [2] Google Dataset Search: Building a search engine for datasets in an open Web ecosystem, WWW 2019.	O	O	Reply	486
<sep> <sep> <sep> Q3-2. (	O	O	Reply	486
2) contributions	O	O	Reply	486
<sep> A3-2.	O	O	Reply	486
<sep> We agree that the fairness part of FR-GAN is similar to Adversarial Debiasing (AD) [3]. However, we strengthen the theoretical results of AD using information theory, and this motivates us to propose a novel robust training discriminator.	B-Reply	B-2	Reply	486
We agree that the key insight of using adversarial training to minimize mutual information between the prediction and sensitive attribute is the same for FR-GAN and AD.	I-Reply	I-2	Reply	486
Although, the end algorithms of FR-GAN and AD are also similar, our paper plays a role in providing systematic methodology not only for various fairness metrics, but also for the design of robust training.	I-Reply	I-2	Reply	486
As far as we know, no other validation-set-based approach (including Ren et al 2018) leverages the idea of adversarial training.	I-Reply	I-2	Reply	486
We reflected these points in our revision (Section 2, highlighted in blue).	I-Reply	I-2	Reply	486
<sep> <sep> [3] Mitigating Unwanted Biases with Adversarial Learning, AAAI 2018.	O	O	Reply	486
<sep> <sep> <sep> Q3-3. (	O	O	Reply	486
3) competing methods	O	O	Reply	486
<sep> A3-3.	O	O	Reply	486
<sep> As Reviewer 2 mentioned, FR-GAN is one of the first works to address both fairness and robustness and that there are few baselines to compare with.	B-Reply	B-3	Reply	486
Hence, we employed one reasonable baseline, which first sanitizes the poisoned data using a well-known sanitization technique and then performs a fair training (see Tables 1 and 2, rows with +LD).	I-Reply	I-3	Reply	486
We clarified these points in our revision (Section 5.1, highlighted in blue).	I-Reply	I-3	Reply	486
<sep> <sep> <sep> Q3-4. (	O	O	Reply	486
4) writeup	O	O	Reply	486
<sep> A3-4.	O	O	Reply	486
<sep> All of our results are on a separate test set.	B-Reply	B-4	Reply	486
We clarified this in our revision (Section 5, highlighted in blue) to avoid any confusion.	I-Reply	I-4	Reply	486
<sep> <sep> <sep> Q3-5.	O	O	Reply	486
Lack of convincing tests for robustness	O	O	Reply	486
<sep> A3-5.	O	O	Reply	486
<sep> We agree that generalizing to all poisoning attacks is important.	B-Reply	B-5	Reply	486
If we know all possible attacks, we can construct a training set containing these attacks.	I-Reply	I-5	Reply	486
In the more challenging case where we do not know which attacks even exist, there seems to be a fundamental limitation in protecting against the attacks.	I-Reply	I-5	Reply	486
Generalization is a universal problem in machine learning where a model trained on one dataset is not guaranteed to perform well in another dataset with a different distribution.	I-Reply	I-5	Reply	486
Although the generalization is a critical issue to address, we think it is beyond the scope of the current work.	I-Reply	I-5	Reply	486
We reflected these points in our revision (Section 6, highlighted in blue).	I-Reply	I-5	Reply	486
<sep> <sep> <sep> Q3-6.	O	O	Reply	486
Minor notes	O	O	Reply	486
<sep> A3-6.	O	O	Reply	486
<sep> We will display the figures with the same axes throughout in our revision.	B-Reply	B-6	Reply	486
We added the information about the number of nodes in the hidden layers in our revision (Appendix A.4, highlighted in blue).	I-Reply	I-6	Reply	486

This paper proposes using a hierarchical VAE to text generation to solve the two problems of long text generation and mode collapse where diversity in generated text is lost.	O	O	Review	1027
<sep> <sep> The paper does this by decoding the latent variable into sentence level latent codes that are then decoded into each sentence.	O	O	Review	1027
The paper shows convincing results on perplexity, N-gram based and human qualitative evaluation.	O	O	Review	1027
<sep> <sep> The paper is well written though some parts are confusing.	B-Review	B-1	Review	1027
For example, equation 4 refers to q as the prior distribution but this seems like it's the posterior distribution as it is described just below equation 5.	I-Review	I-1	Review	1027
p(z_1|z_2) is also not well defined.	I-Review	I-1	Review	1027
It would be clearer to specify the full algorithm in the paper.	I-Review	I-1	Review	1027
<sep> <sep> The work also mentions that words are generated for each sentence until the _END token is generated.	B-Review	B-2	Review	1027
Is this token always generated?	I-Review	I-2	Review	1027
What happens to a sentence if that token is not generated?	I-Review	I-2	Review	1027
<sep> <sep> The novelty of this paper is questionable given the significant amount of existing work in hierarchical VAEs.	B-Review	B-3	Review	1027
It's also unclear why a more direct comparison can't be made with Serban et al in terms of language generation quality and perplexity.	I-Review	I-3	Review	1027
If a downstream model is only able to make use of one latent variable, can't multiple variables simply be averaged?	I-Review	I-3	Review	1027
<sep> <sep> It's also unclear how this work is novel with regards to the works below.	B-Review	B-4	Review	1027
<sep> <sep> Hierarchical Variational Autoencoders for Music	I-Review	I-4	Review	1027
Roberts, et al	I-Review	I-4	Review	1027
NIPS 2017 creativity workshop	I-Review	I-4	Review	1027
This seems to have a similar hierarchical structure where there is an initial 16 step decoder that decodes the latent code for the lower level note level LSTMs to use during generation.	I-Review	I-4	Review	1027
<sep> <sep> Unsupervised Learning of Disentangled and Interpretable Representations from Sequential Data	I-Review	I-4	Review	1027
Hsu, et al	I-Review	I-4	Review	1027
NIPS 2017	I-Review	I-4	Review	1027
This proposes a factorized hierarchical variational autoencoder which also has a double latent variable hierarchical structure, one that is conditional on the other.	I-Review	I-4	Review	1027
<sep> <sep> Minor comments	B-Review	B-5	Review	1027
- Typo in page 3 under Hierarchical structures in NLP: characters "from" a word	I-Review	I-5	Review	1027
- Typo above section 4.3: hierarhical	I-Review	I-5	Review	1027
<sep> === After rebuttal ===	O	O	Review	1027
Thanks for the response.	O	O	Review	1027
<sep> <sep> I believe that Reviewer2's criticism about the similarity to Park et al isn't sufficiently addressed by the authors.	O	O	Review	1027
Even if the hierarchical structure is different it's unclear whether this alternative structure is superior to Park et al There appears to be no evidence that the latent variables contain more global information relative to VHCR (Park et al).	O	O	Review	1027
These claims aren't tested and the results in the paper aren't comparable since the authors don't evaluate on the same datasets as Park et al	O	O	Review	1027
<sep> In general, I think the claims of a superior hierarchical structure to models such as the factorized hierarchical VAE paper needed to be tested to show evidence of a more powerful representation for hier-VAE.	O	O	Review	1027
<sep> <sep> I will keep my score.	O	O	Review	1027
We would like to thank the reviewer for the detailed comments and suggestions for the manuscript.	O	O	Reply	1027
<sep> <sep> > The paper is well written though some parts are confusing.	O	O	Reply	1027
For example, equation 4 refers to q as the prior distribution but this seems like it's the posterior distribution as it is described just below equation 5.	O	O	Reply	1027
p(z_1|z_2) is also not well defined.	O	O	Reply	1027
It would be clearer to specify the full algorithm in the paper.	O	O	Reply	1027
<sep> <sep> Thanks for pointing out this confusing typo.	B-Reply	B-1	Reply	1027
In the revised version, we have corrected ‚Äòprior‚Äô to ‚Äòposterior‚Äô while describing equation 4.	I-Reply	I-1	Reply	1027
As to the specific configuration of p(z_1|z_2), it is actually described in the supplementary materials (due to the space limit).	I-Reply	I-1	Reply	1027
To avoid any confusions here, we added a 'Model specification‚Äô section, at the beginning of the 'Experiments' part in the revised version, to illustrate these details and hyperparameter choices.	I-Reply	I-1	Reply	1027
<sep> <sep> > The work also mentions that words are generated for each sentence until the _END token is generated.	O	O	Reply	1027
Is this token always generated?	O	O	Reply	1027
What happens to a sentence if that token is not generated?	O	O	Reply	1027
<sep> <sep> The reviewer brings up a good point about the end_token generation.	B-Reply	B-2	Reply	1027
In our training data, all sentences have an _END token (at the end of each sentence), and the word-level LSTM is able to learn that there will be an _END token after each sentence and generate that token.	I-Reply	I-2	Reply	1027
We should also note that, we constrained the model to generate a maximum number of words for each sentence.	I-Reply	I-2	Reply	1027
We use maximumly 20 words for the Yelp reviews dataset and 25 for the arXiv dataset.	I-Reply	I-2	Reply	1027
This part has been made more clear in the revised version.	I-Reply	I-2	Reply	1027
<sep> <sep> > It's also unclear how this work is novel with regards to the works below.	O	O	Reply	1027
<sep> <sep> We agree with the reviewer that there are similarities between our model and the VHRED model proposed by Serban et al, however our model is quite different in terms of the architecture and motivation.	B-Reply	B-3	Reply	1027
Firstly, the VHRED model infers a latent variable for each context/utterance, and the context is provided to the decoder while generating each response.	I-Reply	I-3	Reply	1027
In contrast, our model leverages a global latent variable to model the entire paragraph without any additional inputs (no contexts are provided).	I-Reply	I-3	Reply	1027
As a result, the latent variables in our model are designed to abstract globally meaningful features from the entire paragraph.	I-Reply	I-3	Reply	1027
<sep> <sep> Secondly, we have leveraged a hierarchy of latent variables to mitigate the ‚Äòposterior collapse‚Äô issue, which has given rise to promising empirical results.	B-Reply	B-3	Reply	1027
Specifically, the generative network has made better use of the latent variable information, indicated by a larger KL term (please refer to our response to Reviewer 2 for additional information).	I-Reply	I-3	Reply	1027
This strategy has not been employed and discussed in the ‚ÄòHierarchical Variational Autoencoders for Music‚Äô paper either.	I-Reply	I-3	Reply	1027
<sep> <sep> To further prove that our model can extract globally informative features, we conducted an additional experiment, in the revised paper, to visualize the learned latent variable.	B-Reply	B-3	Reply	1027
Specifically, from the arXiv dataset, we select the most frequent four classes/topics and re-train our hier-VAE-D model on the corresponding abstracts.	I-Reply	I-3	Reply	1027
We plot the bottom-level latent variable for our hier-VAE-D with t-SNE (which is supposed to contain the global features).	I-Reply	I-3	Reply	1027
The result is shown in Figure 2 of the revised manuscript.	I-Reply	I-3	Reply	1027
It can be observed that the latent codes of paragraphs from the same topic are indeed grouped together in the embedding space, indicating that the latent variables has encoded high-level features from the input paragraph.	I-Reply	I-3	Reply	1027
<sep> <sep> As to the factorized hierarchical VAE paper, although they utilize the hierarchical nature of sequential data, their VAE model only takes a sub-sequence (segment) of the entire sequence as the input (as illustrated in Figure 3 of the factorized hierarchical VAE paper).	B-Reply	B-3	Reply	1027
Therefore, their model can only be used to modify the style/attribute of a sub-sequence (short sentence), rather than generate/sample an entire sequence (long-form document).	I-Reply	I-3	Reply	1027
<sep> <sep> > Minor comments	O	O	Reply	1027
<sep> Thanks for pointing the typos out.	B-Reply	B-5	Reply	1027
We have corrected them accordingly in the revised paper.	I-Reply	I-5	Reply	1027

This paper proposes a hierarchical variational autoencoder for modeling paragraphs.	O	O	Review	1027
The model creates two levels of latent variables; one level of sentence-level latent variables and another single global latent.	O	O	Review	1027
This avoids posterior collapse issues and the authors show convincing results on a few different applications to two datasets.	O	O	Review	1027
<sep> <sep> Overall, it is an impressive result to be able to convincingly model paragraphs with a useful global latent variable.	O	O	Review	1027
Apart from some issues with confusing/incomplete notation (see below), my main criticism is that the authors fail to compare their approach to "A Hierarchical Latent Structure for Variational Conversation Modeling" by Park et al As far as I can tell, the approaches are extremely similar, except that Park et al may not learn the prior parameters and also use a hierarchical RNN encoder rather than a CNN (which may be irrelevant).	B-Review	B-1	Review	1027
They also are primarily interested in dialog generation, so the lower-level of their hierarchy models utterances in a conversation rather than sentences in general, but I don't see this as a major difference.	O	O	Review	1027
I'd encourage the authors to compare to this and potentially use it as a baseline.	O	O	Review	1027
More generally, it would have been nice to see more ablation experiments (e.g. convolutional vs. LSTM encoder).	B-Review	B-2	Review	1027
Finally, I know that space is tight, but other papers on global-latent-variable models tend to include more demonstrations that teh global variable is capturing meaningful information, e.g. with attribute vector arithmetic.	B-Review	B-3	Review	1027
The authors could include results of manipulating review sentiment via attribute vector arithmetic, for example.	I-Review	I-3	Review	1027
<sep> <sep> <sep> Specific comments:	O	O	Review	1027
<sep> - "The Kullback-Leibler (KL) divergence term ... which can be written in closed-form (Kingma & Welling, 2013), encourages the approximate posterior distribution qœÜ(z|x) to be close to the multivariate Gaussian prior p(z)."	B-Review	B-4	Review	1027
The prior is not always taken to be a multivariate Gaussian.	I-Review	I-4	Review	1027
You should add a sentence stating that the VAE prior is often taken to be a diagonal-covariance Gaussian for convenience.	I-Review	I-4	Review	1027
<sep> - 3.2 has a few things which are unclear.	B-Review	B-5	Review	1027
In the second paragraph, you define z as the sampled latent code which is fed through an MLP "to obtain the starting state of the sentence-level LSTM decoder".	I-Review	I-5	Review	1027
But then LSTM^{sent} appears to be fed z at every timestep.	I-Review	I-5	Review	1027
LSTM^{sent} is also not defined - am I to assume that its arguments are the previous state and current input, so that z is the input at every timestep?	I-Review	I-5	Review	1027
Also, you write "where h^s_0 is a vector of zeros" which makes it sound like the starting state of the sentence-level LSTM decoder is a vector of zeros, not the output of the MLP which takes z as input.	I-Review	I-5	Review	1027
In contrast, LSTM^{word} takes three arguments as input.	I-Review	I-5	Review	1027
Which are the "state" and which are the "input" to the LSTM?	I-Review	I-5	Review	1027
<sep> - I don't see any description of your CNN encoder (only the LSTM decoder in section 3.2, 3.3 only covers the hierarchy of latent variables, not the CNN architecture).	B-Review	B-6	Review	1027
What is its structure?	I-Review	I-6	Review	1027
Figure 1 shows a CNN encoder generating lower-level sentence embeddings and a high-level global embedding.	I-Review	I-6	Review	1027
How are those computed?	I-Review	I-6	Review	1027
It is briefly mentioned in 4.1 under "Datasets" but this seems insufficient.	I-Review	I-6	Review	1027
<sep> - p_\theta(x | z) is defined as the generating distribution, but also as a joint distribution of z_1 and z_2.	B-Review	B-7	Review	1027
Unless I am missing something I think you are overloading the notation for p_\theta.	I-Review	I-7	Review	1027
<sep> - I don't think enough information is given about the AAE and ARAE baselines.	B-Review	B-8	Review	1027
Are they the same as the flat-VAE, except with the KL term replaced by the an adversarial divergence between the prior and approximate posterior?	I-Review	I-8	Review	1027
Thanks for taking the time to provide such thorough comments and detailed feedback.	O	O	Reply	1027
<sep> <sep> > my main criticism is that the authors fail to compare their approach to "A Hierarchical Latent Structure for Variational Conversation Modeling" by Park et al	O	O	Reply	1027
<sep> Thanks for referring to this interesting paper.	B-Reply	B-1	Reply	1027
The VHCR model (as denoted in their paper) indeed bears close resemblance to our proposed method.	I-Reply	I-1	Reply	1027
However, there are two key differences that make our work unique:	I-Reply	I-1	Reply	1027
<sep> 1) To allow the model to make more use of the latent variable, this reference proposes to employ an ‚Äòutterance drop‚Äô strategy.	I-Reply	I-1	Reply	1027
Their goal is to weaken the autoregressive power of hierarchical RNNs by dropping the utterance encoder vector with a certain probability.	I-Reply	I-1	Reply	1027
Although the KL divergence term tends to get larger with this modification, the modeling capacity of the LSTM decoder may be sacrificed.	I-Reply	I-1	Reply	1027
Instead, we try to resolve the same issue from a different perspective (without weakening the decoder during training).	I-Reply	I-1	Reply	1027
Specifically, we propose to improve the flexibility and expressiveness of the prior distribution, by leveraging a hierarchy of latent variables.	I-Reply	I-1	Reply	1027
This setup endows the encoder/inference networks with stronger ability to extract high-level (global) features of a paragraph.	I-Reply	I-1	Reply	1027
Notably, the model proposed in [1] shares the same high-level idea of making the inference networks more expressive to resolve the ‚Äò‚Äôposterior collapse‚Äô‚Äô problem.	I-Reply	I-1	Reply	1027
<sep> <sep> To compare the effectiveness of the two different strategies (to mitigate the `posterior collapse‚Äô issue), we experiment the ‚Äòutterance drop‚Äô (u.d) method based upon our hier-VAE-S model on the Yelp dataset (note that to allow fair comparison, we use hier-VAE-S as the baseline to evaluate the two strategies).	I-Reply	I-1	Reply	1027
The corresponding language modeling results are shown as below:	I-Reply	I-1	Reply	1027
<sep> <tab><tab><tab>                    NLL        KL        PPL	I-Reply	I-1	Reply	1027
hier-VAE-S: <tab><tab>           160.8      3.6       46.6	I-Reply	I-1	Reply	1027
hier-VAE-S (with u.d):     161.3  <tab>  5.6       47.1	I-Reply	I-1	Reply	1027
hier-VAE-D: <tab><tab>           160.2      6.8       45.8	I-Reply	I-1	Reply	1027
<sep> As shown above, their u.d strategy allows better usage of the latent variable (indicated by a larger KL divergence value).	I-Reply	I-1	Reply	1027
However, the NLL of the language model becomes even worse with the u.d method, possibly due to the weakening of the decoder during training (similar observations have also been shown in Table 2 of the VHCR paper).	I-Reply	I-1	Reply	1027
In contrast, our ‚Äòhierarchical prior‚Äô strategy yields larger KL terms as well as lower NNL value, indicating the advantage of our strategy to mitigate the ‚Äòposterior collapse‚Äô issue.	I-Reply	I-1	Reply	1027
<sep> <sep> 2) The previous VHCR model considers a multi-turn dialogue generation scenario, where the dialog context is provided at each time step (in terms of the higher-level LSTM) and the model seeks to generate the corresponding response conditioned on the context.	B-Reply	B-1	Reply	1027
What is different in our hier-VAE model is that, we are interested in generating long and coherent units merely conditioned on the latent variable (no additional context information is provided to the decoder).	I-Reply	I-1	Reply	1027
As a result, the underlying data distribution of the entire paragraph is captured in the bottom-level latent variable.	I-Reply	I-1	Reply	1027
While in their setup, the responses are modeled/generated conditioned on both the latent variables and the contexts.	I-Reply	I-1	Reply	1027
In this sense, the problem we are trying to tackle is relatively more challenging.	I-Reply	I-1	Reply	1027
<sep> <sep> > More generally, it would have been nice to see more ablation experiments (e.g. convolutional vs. LSTM encoder)	O	O	Reply	1027
<sep> At the initial stage of this project, we found that the hierarchical CNN encoder employed here is important for the VAE model to work well (relative to a flat CNN encoder).	B-Reply	B-2	Reply	1027
Based on reviewer‚Äôs suggestion, we re-ran the language modeling experiments with a flat CNN encoder and a hierarchical LSTM encoder (on the Yelp dataset).	I-Reply	I-2	Reply	1027
The results are shown below:	I-Reply	I-2	Reply	1027
<sep> <tab><tab><tab><tab><tab>                          NLL        KL        PPL	I-Reply	I-2	Reply	1027
Flat CNN encoder:<tab><tab><tab>         164.6      2.3       50.2	I-Reply	I-2	Reply	1027
Hierarchical LSTM encoder:<tab><tab> 161.3<tab> 5.7       46.9	I-Reply	I-2	Reply	1027
Hierarchical CNN encoder:                 160.2      6.8       45.8	I-Reply	I-2	Reply	1027
<sep> It can be observed that the model with a flat CNN encoder yields worst (largest) perplexity, suggesting that it is beneficial to make the encoder hierarchical.	I-Reply	I-2	Reply	1027
Additionally, hierarchical CNN encoder exhibits slightly better results than hierarchical LSTM encoder according to our experiments.	I-Reply	I-2	Reply	1027

<sep> This paper considers the problem of obtaining an optimal regret algorithm in a distributed setting without incurring a large communication cost.	O	O	Review	20419
In the standard and linear MAB settings, the authors propose algorithms and show that they achieve optimal regret up to logarithmic factors with communication costs that are almost independent of the horizon T. In addition the authors establish interesting lower bounds on the communication cost to obtain sublunar regret.	O	O	Review	20419
<sep> <sep> Overall I found the paper very well motivated and clearly written.	O	O	Review	20419
I did not go through the proofs in the appendix carefully, but I did check a few sections and found them to be correct.	O	O	Review	20419
I did have a few concerns.	O	O	Review	20419
<sep> <sep> I found the discussion around load balancing very confusing.	B-Review	B-1	Review	20419
Perhaps the authors could provide a picture to explain the issue?	I-Review	I-1	Review	20419
In addition, there is a lack of experiments- it is always nice to see comparisons to baseline even though the theory implies you would do better.	B-Review	B-2	Review	20419
Finally, the algorithm doesn‚Äôt seem extremely practical from an applied point of view - for a linear amount of time all the bandits are pulling the same arms and there is no communication at all.	I-Review	I-2	Review	20419
I understand this repeated work doesn‚Äôt affect the regret - but it is an artifact of using elimination.	I-Review	I-2	Review	20419
In general optimism based approaches (such as UCB) tend to work significantly better than elimination-style methods.	B-Review	B-3	Review	20419
I‚Äôd be curious to hear the authors comment on whether they think a UCB style algorithm is possible in this setting.	I-Review	I-3	Review	20419
<sep> <sep> Overall I recommend the paper for acceptance.	O	O	Review	20419
<sep> <sep> <sep> <sep> We thank anonymous reviewer 2 for the review.	O	O	Reply	20419
<sep> <sep> Regarding the load balancing: The main issue of load balancing is that the length of each phase is determined by the agent with maximum number of remaining arms, since all agents run concurrently and need to synchronize at the end of each epoch.	B-Reply	B-1	Reply	20419
As a result, agents with too many arms need to donate arms to other agents if the numbers of arms remained in agents are not balanced.	I-Reply	I-1	Reply	20419
We will make it clearer in the final version.	I-Reply	I-1	Reply	20419
<sep> <sep> Regarding the experiments: We tested the algorithms for distributed linear bandits.	B-Reply	B-2	Reply	20419
We compared performance of our algorithms with two baselines: LinUCB with no communication (LinUCBnoComm) and adapted LinUCB with naive communication strategy (LinUCBnaiveComm), which means we allow agents to communicate their full information at some time steps.	I-Reply	I-2	Reply	20419
In our experiment, we enforced a communication budget of 200kb.	I-Reply	I-2	Reply	20419
The result shows that the regret of DELB protocol is 4 times smaller than that of LinUCBComm or LinUCBnaiveComm.	I-Reply	I-2	Reply	20419
In detail, we ran the algorithms using M = 100 agents on synthesized datasets with 1000 actions, d = 10.	I-Reply	I-2	Reply	20419
We used T ranging from 100 to 10000.	I-Reply	I-2	Reply	20419
We will update the final version accordingly.	I-Reply	I-2	Reply	20419
<sep> <sep> Regarding the UCB algorithm: In fact, for multi-armed bandits, the first protocol we designed with near-optimal regret and efficient communication is based on UCB approach.	B-Reply	B-3	Reply	20419
The main idea is to maintain global counts for pulling each arms and synchronize the average rewards for a certain arm only when the number of pulling that arm is doubled.	I-Reply	I-3	Reply	20419
However, the communication cost of this UCB-based protocol is, which is worse than DEMAB.	I-Reply	I-3	Reply	20419
For linear bandits, our DisLinUCB protocol is based on optimism principle, which also achieves near-optimal regret with efficient communication.	I-Reply	I-3	Reply	20419

The authors study a bandit problem where there are multiple agents (say, M) and each of the agents is playing a multi-armed bandit problem for T rounds.	O	O	Review	20419
The agents can communicate with each other in order to achieve small regret.	O	O	Review	20419
The problem is to design a strategy for arm-playing and communication so that the agents all combined can achieve a small regret w/o communicating a lot.	O	O	Review	20419
The authors study this bandit problem in 2 settings: 1.	O	O	Review	20419
multi-armed bandit setting and 2.	O	O	Review	20419
bandit linear optimization.	O	O	Review	20419
For both these settings, the authors establish elimination style algorithms with communication.	O	O	Review	20419
upon communication the sub-optimal arms are eliminated and the game continues with the remaining arms.	O	O	Review	20419
<sep> The authors establish regret guarantees as well as communication guarantees.	O	O	Review	20419
The interesting result is that with constant communication the regret scales as if full communication was available.	O	O	Review	20419
<sep> The results are interesting and I do not have any objections with the paper, except that ICLR might not be the right avenue for such work given that it lacks any ideas regarding representation learning.	B-Review	B-1	Review	20419
We thank anonymous reviewer 1 for the review.	O	O	Reply	20419
<sep> <sep> Regarding the ICLR venue: Our work focuses on parallelization and distributed learning, which is also a research topic in representation learning.	B-Reply	B-1	Reply	20419
We believe our results can bring insight to other distributed learning problems.	I-Reply	I-1	Reply	20419
Besides, the linear bandit studied in our paper is a special case of contextual bandit.	I-Reply	I-1	Reply	20419
We notice that several contextual bandit papers have been published on ICLR in the past a few years.	I-Reply	I-1	Reply	20419
Extending our work to contextual bandit is a future direction.	I-Reply	I-1	Reply	20419

The paper considers the problem of distributed multi-arm bandit, where M players are playing in the same stochastic environment.	O	O	Review	20419
The goal of the paper is to have small over-all regret for all the players without a significant amount of communication between the players.	O	O	Review	20419
<sep> <sep> <sep> <sep> The main contribution of this paper is obtaining regret ~root(M KT) with ~M bits of communication in MAB, and regret ~d*root(MT) with ~Md bits of communication in linear bandit setting.	O	O	Review	20419
<sep> <sep> The main intuition of the algorithms in this paper is to do "best arm identification" with epoching: At every epoch t, the central server sends the set of possible best arms to each player and each player pulls it for 2^t /M times, followed by a communication round.	O	O	Review	20419
Thus, the cumulative regret is comparable to having one player doing this epoch strategy for MT iterations, where the regret follows.	O	O	Review	20419
<sep> <sep> The problem considered in this paper is interesting and the result is new, the technique looks simple on paper but it requires a masterful combination of known tricks in (linear) MAB to obtain the best bound.	B-Review	B-3	Review	20419
<sep> <sep> It seems that in the MAB setting, the lower bound could be further strengthened with a log(K) factor, since removing this factor would ultimately require "dynamic epoching" which is not possible with limited communication.	B-Review	B-1	Review	20419
This would mostly complete the picture in the distributed MAB regime.	I-Review	I-1	Review	20419
<sep> <sep> <sep> Missing citation:	B-Review	B-2	Review	20419
The authors are missing citations relevant to distributed MAB with collisions, see for example	I-Review	I-2	Review	20419
"Non-Stochastic Multi-Player Multi-Armed Bandits: Optimal Rate With Collision Information, Sublinear Without"	I-Review	I-2	Review	20419
<sep> <sep> After Rebuttal: I have read the authors' responses and acknowledge the sensibility of the statement.	O	O	Review	20419
<sep> <sep> <sep> <sep> We thank anonymous reviewer 3 for the review.	O	O	Reply	20419
<sep> <sep> Regarding the lower bound: We greatly thank reviewer 3 for the comments on the lower bound.	B-Reply	B-1	Reply	20419
We are considering this and may improve the lower bound in the final version.	I-Reply	I-1	Reply	20419
<sep> <sep> Regarding the missing citation: Thanks for bringing this paper to our attention.	B-Reply	B-2	Reply	20419
We will add it to the references.	I-Reply	I-2	Reply	20419

This paper proposes to evaluate feature learning algorithms by using a low-level vision task, namely  image patch matching.	O	O	Review	33
The authors compare three feature learning algorithms, GRBM.	O	O	Review	33
spGRBM and mcRBM against engineered features like SIFT and others.	O	O	Review	33
<sep> The empirical results unfortunately show that the learned features are not very competitive for this task.	O	O	Review	33
<sep> <sep> Overall, the paper does not propose any new algorithm and does not improve performance on any task.	B-Review	B-1	Review	33
<sep> It does raise an interesting question though which is how to assess feature learning algorithms.	O	O	Review	33
This is a core problem in the field and its solution could help a) assessing which feature learning methods are better and b) designing algorithms that produce better features (because we would have better loss functions to train them).	O	O	Review	33
Unfortunately, this work is too preliminary to advance our understanding towards the solution of this problem (see below for more detailed comments).	B-Review	B-2	Review	33
<sep> Overall quality is fairly poor: there are missing references, there are incorrect claims, the empirical validation is insufficient.	B-Review	B-3	Review	33
<sep> <sep> Pros	O	O	Review	33
-- The motivation is very good.	O	O	Review	33
We need to improve the way we compare feature learning methods.	O	O	Review	33
<sep> -- The filters visualization is nice.	O	O	Review	33
<sep> <sep> Cons	O	O	Review	33
-- It is debatable whether the chosen task is any better for assessing the quality of feature learning methods.	B-Review	B-4	Review	33
The paper almost suggested a better solution in the introduction: we should compare across several tasks (from low level vision like matching to high level vision like object classification).	I-Review	I-4	Review	33
If a representation is better across several tasks, then it must capture many relevant properties of the input.	I-Review	I-4	Review	33
<sep> In other words, it is always possible to tweak a learning algorithm to give good results on one dataset, but it is much more interesting to see it working well across several different tasks after training on generic natural images, for instance.	I-Review	I-4	Review	33
<sep> -- The choice of the feature learning methods is questionable, why are only generative models considered here?	B-Review	B-5	Review	33
The authors do mention that other methods were tried and worked worse, however it is hard to believe that more discriminative approaches work worse on the chosen task.	I-Review	I-5	Review	33
In particular, knowing the matching task it seems that a method that trains using a ranking loss (learning nearby features for similar patches and far away features for distant inputs) should work better.	I-Review	I-5	Review	33
See:	I-Review	I-5	Review	33
H. Mobahi, R. Collobert, J. Weston.	I-Review	I-5	Review	33
Deep Learning from Temporal Coherence in Video.	I-Review	I-5	Review	33
ICML 2009.	I-Review	I-5	Review	33
<sep> -- The overall results are pretty disappointing.	B-Review	B-6	Review	33
Feature learning methods do not outperform the best engineered features.	I-Review	I-6	Review	33
They do not outperform even if the comparison is unfair: for instance the authors use 128 dimensional SIFT but much larger dimensionality for the learned features.	I-Review	I-6	Review	33
Besides, the authors do not take into account time, neither the training time nor the time to extract these features.	I-Review	I-6	Review	33
This would also be considered in the evaluation.	I-Review	I-6	Review	33
<sep> <sep> More detailed comments:	O	O	Review	33
-- Missing references.	B-Review	B-7	Review	33
<sep> It is not true that feature learning methods have never been assessed quantitatively without supervised fine tuning.	I-Review	I-7	Review	33
On a low level vision task, I would refer to:	I-Review	I-7	Review	33
Learning to Align from Scratch	I-Review	I-7	Review	33
Gary Huang, Marwan Mattar, Honglak Lee, Erik Learned-Miller.	I-Review	I-7	Review	33
<sep> In Advances in Neural Information Processing Systems (NIPS) 25, 2012.	I-Review	I-7	Review	33
<sep> Another missing reference is	I-Review	I-7	Review	33
2011 Memisevic, R.	I-Review	I-7	Review	33
Gradient-based learning of higher-order image features.	I-Review	I-7	Review	33
<sep> International Conference on Computer Vision (ICCV 2011).	I-Review	I-7	Review	33
<sep> and other similar papers where Memisevic trains features that relate pairs of image patches.	I-Review	I-7	Review	33
<sep> --ROC curves should be reported at least in appendix, if not in the main text.	B-Review	B-8	Review	33
<sep> -- I do not understand why SIFT results on tab 1 a) differs from those in tab.1 b).	B-Review	B-9	Review	33
Deare954,	O	O	Reply	33
thank you for your detailed feedback.	O	O	Reply	33
<sep> <sep> We don't argue that the chosen task should replace existing	B-Reply	B-4	Reply	33
benchmarks.	I-Reply	I-4	Reply	33
Instead, we think that it supplements these, because	I-Reply	I-4	Reply	33
it covers aspects of unsupervised feature learning that have been	I-Reply	I-4	Reply	33
ignored so far.	I-Reply	I-4	Reply	33
Note that by avoiding any subsequent supervision	I-Reply	I-4	Reply	33
we not only think of supervised fine tuning of the learnt architecture	I-Reply	I-4	Reply	33
but rather no supervised learning on the representations at all	I-Reply	I-4	Reply	33
(e.g. like it is still done in [R2]).	I-Reply	I-4	Reply	33
This is hopefully clearer in	I-Reply	I-4	Reply	33
version 3 of the paper, we removed words like 'refinement'	I-Reply	I-4	Reply	33
and 'fine tuning'.	I-Reply	I-4	Reply	33
<sep> <sep> Thank you for pointing out missing references [R1, R2, R3]. We	B-Reply	B-7	Reply	33
added [R2, R4, R5] to the paper in order to avoid the impression	I-Reply	I-7	Reply	33
we are not aware of these approaches (we think that R4 fits better	I-Reply	I-7	Reply	33
than R1 and R5 better than R3).	I-Reply	I-7	Reply	33
We were, but did not mention	I-Reply	I-7	Reply	33
these approaches because they are (i) relying on a supervised signal	I-Reply	I-7	Reply	33
and/or (ii) are concerned with high-level correspondences (we consider	I-Reply	I-7	Reply	33
faces as high-level entities).	I-Reply	I-7	Reply	33
Current work investigates some of these	I-Reply	I-7	Reply	33
methods, because utilizing the available pairing information should	I-Reply	I-7	Reply	33
be beneficial with respect to a good overall performance.	I-Reply	I-7	Reply	33
We are not	I-Reply	I-7	Reply	33
arguing that discriminative methods work worse on this dataset.	I-Reply	I-7	Reply	33
<sep> However, in this paper we are not striving to achieve state-of-the-art	I-Reply	I-7	Reply	33
results: We investigate a new benchmark for unsupervised learning and	I-Reply	I-7	Reply	33
test how good existing unsupervised methods do.	I-Reply	I-7	Reply	33
We tried to make the	I-Reply	I-7	Reply	33
analysis part in version 3 of the paper more clearer.	I-Reply	I-7	Reply	33
<sep> <sep> We don't think that our claims are incorrect: We manage to perform	B-Reply	B-6	Reply	33
comparable to SIFT when the size of the representation is free.	I-Reply	I-6	Reply	33
It is	I-Reply	I-6	Reply	33
not clear if for standard distance computations a bigger representations	I-Reply	I-6	Reply	33
(in particular a sparse one) is actually an advantage.	I-Reply	I-6	Reply	33
We also manage	I-Reply	I-6	Reply	33
to perform better than several well known compact descriptors when we	I-Reply	I-6	Reply	33
binarize the learnt representations.	I-Reply	I-6	Reply	33
<sep> <sep> We also don't think that the evaluation is insufficient.	B-Reply	B-6	Reply	33
The time to	I-Reply	I-6	Reply	33
extract the features will be clearly dominated by the SIFT keypoint	I-Reply	I-6	Reply	33
detector, because computing a new representation given a patch is a	I-Reply	I-6	Reply	33
sequence of matrix operations.	I-Reply	I-6	Reply	33
Training times are added to the new	I-Reply	I-6	Reply	33
version of the paper.	I-Reply	I-6	Reply	33
ROC curves will be in a larger technical	I-Reply	I-6	Reply	33
report that describes in more detail the performance of a bigger	I-Reply	I-6	Reply	33
number of feature learning algorithms (both supervised and unsupervised)	I-Reply	I-6	Reply	33
on this dataset.	I-Reply	I-6	Reply	33
<sep> <sep> Thank you for pointing out a missing experiment, training on general	B-Reply	B-5	Reply	33
natural image patches (not extracted around keypoints) and then	I-Reply	I-5	Reply	33
evaluating on the dataset.	I-Reply	I-5	Reply	33
We are trying to incorporate results for	I-Reply	I-5	Reply	33
this experiment in the final version of the paper.	I-Reply	I-5	Reply	33
It should also be	I-Reply	I-5	Reply	33
very interesting to experiment with the idea of unsupervised	I-Reply	I-5	Reply	33
alignment [R2], especially as every patch implicitly has already	I-Reply	I-5	Reply	33
some general alignment information from its keypoint.	I-Reply	I-5	Reply	33
<sep> <sep> In Table 1b, SIFT is not normalized and used as a 128 byte descriptor	B-Reply	B-9	Reply	33
(in Table 1a a 128 double descriptor (with normalized entries) is used).	I-Reply	I-9	Reply	33
<sep> <sep> A new version (arxiv version 3) of the paper is uploaded on March 11.	O	O	Reply	33
<sep> <sep> [R1] H. Mobahi, R. Collobert, J. Weston.	O	O	Reply	33
Deep Learning from Temporal Coherence in Video.	O	O	Reply	33
<sep> [R2] Gary Huang, Marwan Mattar, Honglak Lee, Erik Learned-Miller.	O	O	Reply	33
Learning to Align from Scratch.	O	O	Reply	33
<sep> [R3] Memisevic, R. Gradient-based learning of higher-order image features.	O	O	Reply	33
<sep> [R4] S. Chopra, R. Hadsell, and Y. LeCun.	O	O	Reply	33
Learning a similarity metric discriminatively, with application to face verification.	O	O	Reply	33
<sep> [R5] J. Susskind, R. Memisevic, G. Hinton, and M. Pollefeys.	O	O	Reply	33
Modeling the joint density of two images under a variety of transformations.	O	O	Reply	33

This paper is a survey of unsupervised learning techniques applied to the unsupervised task of descriptor matching.	O	O	Review	33
Various methods such as Gaussian RBMs, sparse RBMs, and mcRBMs were applied to image patches and the resulting feature vectors were used in a matching task.	O	O	Review	33
These methods were compared to standard hand-crafted descriptors such as SIFT, SURF, etc.	O	O	Review	33
<sep> <sep> Pros	O	O	Review	33
Provides a survey of descriptors for matching pairs of image patches.	O	O	Review	33
<sep> <sep> Cons	O	O	Review	33
It is not clear what the purpose of the paper is.	B-Review	B-2	Review	33
The paper compares several learning algorithms on the task of what essentially seems like clustering image patches to find their correspondences.	I-Review	I-2	Review	33
The ground truth correspondences of the dataset were found by clustering the image patches to find correspondences... In this paper, simple clustering methods were not compared to such as kmeans or sparse coding which are less complicated models than RBMs and are meant for finding correspondences.	B-Review	B-4	Review	33
Additionally, training in a supervised way makes much more sense for finding correspondences.	B-Review	B-5	Review	33
<sep> <sep> It is not clear from the paper alone what is considered at match between descriptors?	B-Review	B-6	Review	33
Is it the distance being below a threshold, the pair of descriptors being closer than any other pair of descriptors, etc.?	I-Review	I-6	Review	33
<sep> <sep> The preprocessing of the image patches seems different for each method.	B-Review	B-7	Review	33
This could lead to wildly different scales of the input pixels and thus the corresponding representations of the various methods.	I-Review	I-7	Review	33
<sep> <sep> In section 3.3 it is mentioned that it is surprising that L1 normalization works better because sparsity hurts classification typically.	B-Review	B-9	Review	33
However, the sparsity in the paper is directly before the distance calculation, and not before being fed as input to a classifier which is a different setup and would thus be expected to behave differently with sparsity.	I-Review	I-9	Review	33
This is the typical setup in which sparsity is found to hurt classification performance because information is being thrown away before the classifier is used.	I-Review	I-9	Review	33
<sep> <sep> Novelty and Quality:	O	O	Review	33
This paper is not novel in that it is survey of prior work applied to matching descriptors.	B-Review	B-10	Review	33
It is well written but does not appear to apply to a wide audience as other papers have done a comparison of unsupervised methods in the past, for example:	I-Review	I-10	Review	33
- A. Coates, H. Lee, and A. Ng.	I-Review	I-10	Review	33
An analysis of single-layer networks in unsupervised feature learning.	I-Review	I-10	Review	33
In Proc.	I-Review	I-10	Review	33
AISTATS, 2011.	I-Review	I-10	Review	33
<sep> - A. Coates and A. Ng.	I-Review	I-10	Review	33
The importance of encoding versus training with sparse coding and vector quanti- zation.	I-Review	I-10	Review	33
In Proc.	I-Review	I-10	Review	33
ICML, 2011.	I-Review	I-10	Review	33
Dear 3338,	O	O	Reply	33
Thank you for your feedback.	O	O	Reply	33
In order to give a comprehensive	O	O	Reply	33
answer, we quote sentences from your feedback and try to respond	O	O	Reply	33
appropriately.	O	O	Reply	33
<sep> <sep> > It is not clear what the purpose of the paper is.	O	O	Reply	33
<sep> We suggest that the way unsupervised feature learning	B-Reply	B-2	Reply	33
methods are evaluated should be extended: A more direct evalution	I-Reply	I-2	Reply	33
of the learnt representations without subsequent supervised algorithms,	I-Reply	I-2	Reply	33
and not tied to the task of high-level object classification.	I-Reply	I-2	Reply	33
<sep> <sep> > The ground truth correspondences of the dataset were found by	O	O	Reply	33
> clustering the image patches to find correspondences.	O	O	Reply	33
<sep> This is not how the description of [R1] with respect to the	B-Reply	B-3	Reply	33
Ground Truth Data (section II in [R1]) reads.	I-Reply	I-3	Reply	33
<sep> <sep> > In this paper, simple clustering methods were not	O	O	Reply	33
> compared to such as kmeans ...	O	O	Reply	33
We added a K-Means experiment to the new version of the paper.	B-Reply	B-4	Reply	33
<sep> We run K-Means (with a soft threshold function) [R2] on the dataset,	I-Reply	I-4	Reply	33
it performs worse than spGRBM. (	I-Reply	I-4	Reply	33
This is mentioned in the new version	I-Reply	I-4	Reply	33
3 of the paper).	I-Reply	I-4	Reply	33
<sep> <sep> > Additionally, training in a supervised way makes much more sense	O	O	Reply	33
> for finding correspondences.	O	O	Reply	33
<sep> This is not the question that we are asking.	B-Reply	B-5	Reply	33
We deliberately	I-Reply	I-5	Reply	33
avoid any supervised training because we want to investigate	I-Reply	I-5	Reply	33
purely unsupervised methods.	I-Reply	I-5	Reply	33
We are not trying to achieve any	I-Reply	I-5	Reply	33
state-of-the-art results.	I-Reply	I-5	Reply	33
<sep> <sep> > It is not clear from the paper alone what is considered at match	O	O	Reply	33
> between descriptors	O	O	Reply	33
We have added some text that describes how a false positive	B-Reply	B-6	Reply	33
rate for a fixed true positive rate is computed.	I-Reply	I-6	Reply	33
<sep> <sep> > The preprocessing of the image patches seems different for each	O	O	Reply	33
> method.	O	O	Reply	33
This could lead to wildly different scales of the input	O	O	Reply	33
> pixels and thus the corresponding representations of the various	O	O	Reply	33
> methods.	O	O	Reply	33
<sep> Could you elaborate why this is something to consider	B-Reply	B-7	Reply	33
in our setting?	I-Reply	I-7	Reply	33
<sep> <sep> > In section 3.3 it is mentioned that it is surprising that L1	O	O	Reply	33
> normalization works better because sparsity hurts classification	O	O	Reply	33
> typically.	O	O	Reply	33
<sep> We don't say that 'sparsity hurts classification typically'.	B-Reply	B-8	Reply	33
We say	I-Reply	I-8	Reply	33
the exact opposite (that sparse representations are beneficial	I-Reply	I-8	Reply	33
for classification) and give a reference to [R3], a paper that you	I-Reply	I-8	Reply	33
also reference.	I-Reply	I-8	Reply	33
We say that it is surprising that a sparse representation	I-Reply	I-8	Reply	33
('sparse' as produced by spGRBM, not by a normalization scheme)	I-Reply	I-8	Reply	33
performs better in a  distance calculation, because the general	I-Reply	I-8	Reply	33
understanding is (to our  knowledge) that sparse representations	I-Reply	I-8	Reply	33
suffer  more from the curse of dimensionality when considering	I-Reply	I-8	Reply	33
distances.	I-Reply	I-8	Reply	33
<sep> <sep> > However, the sparsity in the paper is directly before the distance	O	O	Reply	33
> calculation, and not before being fed as input to a classifier which	O	O	Reply	33
> is a different setup and would thus be expected to behave differently	O	O	Reply	33
> with sparsity.	O	O	Reply	33
This is the typical setup in which sparsity is found to	O	O	Reply	33
> hurt classification performance because information is being thrown	O	O	Reply	33
> away before the classifier is used.	O	O	Reply	33
<sep> We don't understand what is meant here.	B-Reply	B-9	Reply	33
Wasn't the gist of [R3] that	I-Reply	I-9	Reply	33
a sparse encoding is key for good classification results?	I-Reply	I-9	Reply	33
However, we	I-Reply	I-9	Reply	33
think that the main point that we wanted to convey in the referred part	I-Reply	I-9	Reply	33
of the paper was poorly presented.	I-Reply	I-9	Reply	33
We tried	I-Reply	I-9	Reply	33
to make the presentation of the analysis part better in the new version	I-Reply	I-9	Reply	33
(arxiv version 3) of the paper.	I-Reply	I-9	Reply	33
<sep> <sep> > ...does not appear to apply to a wide audience as other papers have	O	O	Reply	33
> done a comparison of unsupervised methods in the past'	O	O	Reply	33
Those comparisions are, as explained in the paper, done always in combination	B-Reply	B-10	Reply	33
with a subsequent supervised classification algorithm on a high-level	I-Reply	I-10	Reply	33
object classification task.	I-Reply	I-10	Reply	33
We want to avoid exactly this setting.	I-Reply	I-10	Reply	33
We think	I-Reply	I-10	Reply	33
that the paper is relevant for researchers working on	I-Reply	I-10	Reply	33
unsupervised (feature) learning methods and for researchers working in	I-Reply	I-10	Reply	33
Computer Vision.	I-Reply	I-10	Reply	33
<sep> <sep> A new version (arxiv version 3) of the paper is uploaded on March 11.	O	O	Reply	33
<sep> <sep> [R1] M. Brown, G. Hua, and S. Winder.	O	O	Reply	33
Discriminative learning of local image descriptors.	O	O	Reply	33
<sep> [R2] A. Coates, H. Lee, and A. Ng.	O	O	Reply	33
An analysis of single-layer networks in unsupervised feature learning.	O	O	Reply	33
<sep> [R3] A. Coates and A. Ng.	O	O	Reply	33
The importance of encoding versus training with sparse coding and vector quantization.	O	O	Reply	33

his paper proposes a dataset to benchmark the correspodence problem	O	O	Review	33
in computer vision.	O	O	Review	33
The dataset consists of image patches that have	O	O	Review	33
groundtruth matching pairs (using separate algorithms).	O	O	Review	33
Extensive	O	O	Review	33
experiments show that RBMs perform well compared to hand-crafted	O	O	Review	33
features.	O	O	Review	33
<sep> <sep> I like the idea of using itermediate evaluation metrics to measure the	B-Review	B-1	Review	33
progress of unsupervised feature learning and deep learning.	I-Review	I-1	Review	33
That	I-Review	I-1	Review	33
said, comparing the methods on noisy groundtruth (results of other	I-Review	I-1	Review	33
algorithms) may have some bias.	I-Review	I-1	Review	33
<sep> <sep> The experiments could be made stronger if algorithms such as	B-Review	B-2	Review	33
Autoencoders or Kmeans (Coates et al, 2011, An Analysis of	I-Review	I-2	Review	33
Single-Layer Networks in Unsupervised Feature Learning) are	I-Review	I-2	Review	33
considered.	I-Review	I-2	Review	33
<sep> <sep> If we can consider the groundtruth as clean, will supervised learning	B-Review	B-3	Review	33
a deep (convolutional) network using the groundtruth produce better	I-Review	I-3	Review	33
results?	I-Review	I-3	Review	33
Dear f716,	O	O	Reply	33
thank you for your feedback.	O	O	Reply	33
We evaluated more models	B-Reply	B-1	Reply	33
than shown in Table 1, but they perform not as good as	I-Reply	I-1	Reply	33
spGRBM so we decided to leave those out (from the Table) in order to	I-Reply	I-1	Reply	33
avoid clutter.	I-Reply	I-1	Reply	33
The models are mentioned in section 3.5	I-Reply	I-1	Reply	33
of the paper (the arxiv version 2 of the paper).	I-Reply	I-1	Reply	33
<sep> <sep> We are currently running experiments with deep convolutional	B-Reply	B-3	Reply	33
networks to determine how much improvement supervision	I-Reply	I-3	Reply	33
signals can achieve.	I-Reply	I-3	Reply	33
<sep> <sep> We uploaded a new version (on March 11) that changes some	B-Reply	B-2	Reply	33
bits of the presentation.	I-Reply	I-2	Reply	33
We also evaluated K-Means on the	I-Reply	I-2	Reply	33
dataset (it is mentioned under 'Other models', because its	I-Reply	I-2	Reply	33
performance is below the one frome spGRBM).	I-Reply	I-2	Reply	33

Collective matrix factorization (CMF) is a method for learning entity embeddings by jointly factorizing a collection of matrices, each of which describes a relationship between entities of two types.	O	O	Review	33
The set of rows/columns of a matrix corresponds to an entity type, while each row/column of the matrix corresponds to a different entity of the type.	O	O	Review	33
This approach assumes that all dimensions of the embeddings of entities of a particular type are relevant for modelling all the relationships they are involved in.	O	O	Review	33
This paper extends CMF by relaxing this assumption and allowing embeddings to have dimensions used for modelling only some of the relationships the entities are involved in.	O	O	Review	33
This is achieved by extending the model to include a separate precision for each embedding dimension of each type to encourage group-sparse solutions.	O	O	Review	33
The authors propose training the resulting models using a variational Bayes algorithm and show how to handle both Gaussian and non-Gaussian observations.	O	O	Review	33
The paper is nicely written and makes a small but novel extension to CMF.	O	O	Review	33
The resulting approach is simple, and seems scalable and widely applicable.	O	O	Review	33
The experiments are fairly small-scale but are sufficient for illustrating the advantages of the method.	O	O	Review	33
Corrections:	O	O	Review	33
In the section dealing non-Gaussian observations, the pseudo-data is referred to as Y instead of Z_m.	O	O	Review	33
The description of variational Bayes as 'minimizing the KL divergence between the observation probability and ...' is not quite right, as it seems to describe KL(P||Q) instead of KL(Q||P).	O	O	Review	33
Section 8: 'unability' -> 'inability'	O	O	Review	33
See the reply for Anonymous 9dec -- we addressed also your remarks in a joint response.	O	O	Reply	33

The manuscript articulates a problem with earlier solutions to the Collective Matrix Factorization (CMF) problem in multi-view learning formulations and proposes a novel solution to address the issue.	O	O	Review	33
The concern is that current CMF schemes ignore the potential for view-specific structure or noise by implicitly assuming that structure must be shared among all views.	O	O	Review	33
The authors solve this problem by putting group-sparse priors on the columns of the matrices.	O	O	Review	33
This allows private factors that can be specific to one or even a subset of the matrices.	O	O	Review	33
Also note that the use of variational Bayesian learning by the authors provides a large reduction in computational complexity relative to the MAP estimates used in some of the prior literature.	O	O	Review	33
<sep> <sep> I agree with the importance of the problem being addressed since, clearly, the need to accommodate view- or subset-specific structure is going to be important in many real-world problems.	O	O	Review	33
Also noted is the elimination of the need for tunable regularization parameters.	O	O	Review	33
<sep> <sep> There are a couple of typos in the first paragraph of section 4.2 (top right of page 4).	B-Review	B-1	Review	33
The manuscript is heavily dependent on several of its sources for implementation details of the complete algorithm.	B-Review	B-2	Review	33
This isn't a criticism, since the authors should not repeat details available elsewhere, but I think it is important to understand that this is necessitated by the complexity of the method, and this complexity is a small drawback and potentially an area for future improvement.	I-Review	I-2	Review	33
<sep> <sep> Another issue is that it would be valuable to see the proposed scheme compared to a wider variety of alternatives in the experimental section (mostly for context that elucidates the importance of CMF itself and therefore their improvement of it for certain applications).	B-Review	B-3	Review	33
However, given the scope of the paper in general, this is a minor point.	I-Review	I-3	Review	33
This is a joint response for both Anonymous 9dec and 75c5, since both  reviews address similar issues.	O	O	Reply	33
<sep> <sep> <sep> We thank both reviewers for pointing out the typos, and in particular the sloppy phrase used to describe basics of VB approximation.	O	O	Reply	33
We have submitted a revised version that fixes these mistakes, as well as addresses the two other issues described below.	O	O	Reply	33
It should be out by Feb 19th.	O	O	Reply	33
<sep> <sep> <sep> 1) Regarding complexity: While several recent advances were indeed needed to derive the model, the resulting algorithm is reasonably straightforward.	B-Reply	B-2	Reply	33
To address this issue we now added more detailed description of the algorithm in the Supplementary material.	I-Reply	I-2	Reply	33
Furthermore, we will later add a link to an open source implementation in R (the documentation still needs a bit of polishing).	I-Reply	I-2	Reply	33
<sep> <sep> <sep> 2) Regarding the scale of the experiments: The artificial data experiments are small mainly to emphasize the effects of jointly modelling multiple matrices.	B-Reply	B-3	Reply	33
Similarly to how e.g. multi-task learning helps most with small sample sizes, properly modeling the private factors is more important when (some of) the entity sets are small -- given enough data even incorrectly specified models often work reasonably well.	I-Reply	I-3	Reply	33
Having said that, scalable algorithms are needed especially in settings where we have few examples in important views (i.e. views we want to predict) and many examples for auxiliary data matrices.	I-Reply	I-3	Reply	33
<sep> <sep> Even though scalability has not been our main focus, the recommender system application in Section 7.3 briefly illustrates the efficiency.	I-Reply	I-3	Reply	33
In the revised version we now me mention that both of the recommender system data sets are in the order of 1 million observations and the results were obtained in a few minutes on a laptop; this is comparable to the computation time of the competing convex CMF (CCMF) method for a single set of regularization parameters, but CCMF needs cross-validation over two such parameters do be used in practice.	I-Reply	I-3	Reply	33
<sep> <sep> We have not tried the algorithm on massive collections, but we expect it could be scaled up fairly nicely with a bit of implementation effort.	I-Reply	I-3	Reply	33
The slowest part is the gradient computation that would parallelize easily, and switching to stochastic gradients would also be possible.	I-Reply	I-3	Reply	33
Note also that the time complexity of the proposed VB algorithm is effectively the same as the corresponding MAP problem: the small overhead is only due to the computation of the parameters of the diagonal covariance matrices, the updates of the mean being similar to the updates of the MAP algorithm.	I-Reply	I-3	Reply	33

# Summary	O	O	Review	33
<sep> This paper proposes a technique for synthesis of state machine policies for a simple continuous agent, with a goal of	O	O	Review	33
them being generalizable to out-of-distribution test conditions.	O	O	Review	33
The agent is modeled as a state machine with constant	O	O	Review	33
or proportional actions applied in each node (regime), and switching triggers between the regimes represented as	O	O	Review	33
length-2 boolean conditions on the observations.	O	O	Review	33
The technique is evaluated on 7 classic control environments, and found	O	O	Review	33
to outperform pure-RL baselines under "test" conditions in most of them.	O	O	Review	33
<sep> <sep> # Review	O	O	Review	33
<sep> I am not an expert in RL-based control, although I'm familiar with the recent literature that applies formal methods to	O	O	Review	33
these domains.	O	O	Review	33
I find the studied settings valuable albeit fairly limited, but the paper's method undeniably shows	O	O	Review	33
noticeable improvement on these settings.	O	O	Review	33
Inductive generalization is an important problem, and the authors' approach of	O	O	Review	33
limiting the agent structure to a particular class of state-machine policies is a reasonable solution strategy.	O	O	Review	33
<sep> <sep> That said, the complexity of synthesizing a state machine policy clearly caused the authors to limit their supported	B-Review	B-6	Review	33
action and condition spaces considerably (Figure 6).	I-Review	I-6	Review	33
That, I'm assuming, limits the set of applicable control	I-Review	I-6	Review	33
environments where optimization is still feasible.	I-Review	I-6	Review	33
The authors don't provide any analysis of complexity or empirical	B-Review	B-1	Review	33
runtime of the optimization process.	I-Review	I-1	Review	33
Breaking it down for each benchmark would allow me to appreciate the optimization	I-Review	I-1	Review	33
framework in Section 4 much more.	I-Review	I-1	Review	33
As it stands, Section 4 describes a complex optimization process with many moving	I-Review	I-1	Review	33
parts, some of which are approximated (q* and p(œÑ|œÄ,x‚ÇÄ)) or computed via EM iteration until convergence (œÄ*).	I-Review	I-1	Review	33
It is hard	I-Review	I-1	Review	33
to appreciate all this complexity without knowing where the challenges manifest on specific examples.	I-Review	I-1	Review	33
<sep> <sep> Section 4.2 needs an example, to link it to the introductory example in Figure 1.	B-Review	B-2	Review	33
The "loop-free" policies of the	I-Review	I-2	Review	33
teacher are, in programmatic terms, _traces_ of the desired state machine execution (if I understand correctly), but	I-Review	I-2	Review	33
this is not obvious from just the formal definition.	I-Review	I-2	Review	33
<sep> <sep> The EM optimization for the student policy makes significant assumptions on the action/condition grammars.	B-Review	B-3	Review	33
Namely, the	I-Review	I-3	Review	33
algorithm iterates over every possible discrete "sketch" of every program, and then numerically optimizes its continuous	I-Review	I-3	Review	33
parameters (Appendix A).	I-Review	I-3	Review	33
When the action/condition grammars grow, the number of possible programs there increases	I-Review	I-3	Review	33
combinatorially.	I-Review	I-3	Review	33
Is there a way to adapt the optimization process to handle more complex grammars, possibly with	I-Review	I-3	Review	33
decomposition of the problem following the program structure?	I-Review	I-3	Review	33
<sep> <sep> Section 5 needs a bit more details on the Direct-Opt baseline.	B-Review	B-4	Review	33
It's unclear how the whole state machine policy (which	I-Review	I-4	Review	33
includes both discrete and continuous parts) is learned end-to-end via numerical optimization.	I-Review	I-4	Review	33
Granted, the baseline	I-Review	I-4	Review	33
performs terribly, but would be great to understand how it models the learning problem in order to appreciate why it's	I-Review	I-4	Review	33
terrible.	I-Review	I-4	Review	33
<sep> <sep> Why were the "Acrobot" and "Mountain car" benchmarks removed from the main presentation of results?	B-Review	B-5	Review	33
Thank you for thoroughly reading the paper and your valuable comments.	O	O	Reply	33
We address your concerns below:	O	O	Reply	33
<sep> **** Complexity of the algorithm limits the set of applicable environments ****	O	O	Reply	33
<sep> We have added a new, more complex benchmark -- namely, the MuJoCo swimmer (extended to 4 segments instead of 3 to make the task more challenging) -- to our paper.	B-Reply	B-6	Reply	33
This benchmark has control inputs R^3 and observation space R^10.	I-Reply	I-6	Reply	33
The state-machine policy synthesized using our algorithm has 4 different modes. (	I-Reply	I-6	Reply	33
Section 5, Figure 10, Figure 20)	I-Reply	I-6	Reply	33
<sep> Overall, the focus of our paper is on addressing problems where a relatively simple behavior must be repeated a certain number of times to solve the given task.	I-Reply	I-6	Reply	33
We believe these problems are pervasive -- for example, many motor tasks such as walking, running, jumping, swimming, etc.	I-Reply	I-6	Reply	33
all rely on this kind of a policy.	I-Reply	I-6	Reply	33
Yet, neural network policies have difficulty solving these tasks in a generalizable way.	I-Reply	I-6	Reply	33
The key premise behind our approach is that compact state-machine policies can represent policies that both have good performance and are generalizable for this class of problems.	I-Reply	I-6	Reply	33
Indeed, our algorithm solves all of our benchmarks using state-machine policies with at most 4 modes and switching conditions of depth at most 2.	I-Reply	I-6	Reply	33
<sep> <sep> For example, consider the autonomous car example in Figure 1.	I-Reply	I-6	Reply	33
The task in Figure 1d (i.e. when the gap between cars is very small) is significantly complex that the neural network baseline was not able to solve (even when trained directly on those initial states; see Figure 3 rightmost).	I-Reply	I-6	Reply	33
However, a small state-machine policy with only 3 modes was able to solve this task.	I-Reply	I-6	Reply	33
<sep> <sep> We certainly agree with the reviewer that it will be interesting to see how the algorithm scales for larger state machines.	I-Reply	I-6	Reply	33
However, this problem is qualitatively different from the one we are solving, and different algorithms would be needed to solve it.	I-Reply	I-6	Reply	33
Overall, we believe that state-machines are most useful when only a few states are required.	I-Reply	I-6	Reply	33
When a large number of states are needed, then the number of possible transition structures grows exponentially, making it unlikely that we can learn the ‚Äútrue‚Äù structure without having an exponential amount of both training data and computation time.	I-Reply	I-6	Reply	33
For these cases, we believe recurrent neural network policies such as LSTMs may remain the better choice.	I-Reply	I-6	Reply	33
<sep> <sep> **** Empirical runtime analysis ****	O	O	Reply	33
<sep> We add runtime analysis in Appendix C.2 and Figure 11 in our paper.	B-Reply	B-1	Reply	33
We show the synthesis times for various benchmarks, the number of student-teacher iterations, and the time spent by the teacher and the student separately.	I-Reply	I-1	Reply	33
We hope this will give the reviewer a better perspective on the different parts of the algorithm	I-Reply	I-1	Reply	33
<sep> **** Scaling the algorithm with the complexity of the grammar ****	O	O	Reply	33
<sep> For the action functions, the user decides whether the action functions will be from a constant grammar or a proportional grammar.	B-Reply	B-3	Reply	33
Furthermore, for proportional grammar, the user specifies which observation the action should be proportional to.	I-Reply	I-3	Reply	33
There are no discrete choices in either of these two grammars.	I-Reply	I-3	Reply	33
We believe that this is usually not difficult for the user to choose the best grammar to use; for instance, a user can easily say that the control for y-acceleration will be proportional be y-velocity and not x-velocity.	I-Reply	I-3	Reply	33
An alternative would be to run the teacher‚Äôs algorithm with many different action function grammars and choose the grammar that resulted in high-reward loop-free policies.	I-Reply	I-3	Reply	33
<sep> <sep> For the switching conditions, the discrete choices in the grammar will be learned by the synthesis algorithm along with the continuous parameters.	B-Reply	B-3	Reply	33
We agree with the reviewer that the discrete enumeration involved here will quickly blow up with the size of the boolean expression.	I-Reply	I-3	Reply	33
For this reason, we have a greedy algorithm that scales quadratically with the size of the expression rather than exponentially.	I-Reply	I-3	Reply	33
We failed to mention this in the original paper, but updated it now (see Appendix A.3 in our paper for more details).	I-Reply	I-3	Reply	33
All the experiments use this greedy algorithm for learning the switching conditions.	I-Reply	I-3	Reply	33
<sep> <sep> **** Examples of loop-free policy ****	O	O	Reply	33
<sep> We added two examples of loop-free policies in Figure 13 in the context of the example in Figure 1.	B-Reply	B-2	Reply	33
We also show visualizations of trajectories learned by the teacher and the student for two different iterations of the algorithm in Figure 12.	I-Reply	I-2	Reply	33

This paper can be viewed as being related to two bodies of work:	O	O	Review	33
<sep> (A) The first is training programmatic policies (e.g., <a href="https://arxiv.org/abs/1907.05431)."	O	O	Review	33
target="_blank" rel="nofollow">https://arxiv.org/abs/1907.05431).</a>  The most popular idea is to use program synthesis &amp; imitation learning to distill from a programmatic policy from some oracle policy.	O	O	Review	33
<sep> (B) The second is training compact policies using a complex model-based controller (e.g., Guided Policy Search).	O	O	Review	33
The idea is to use a step-wise model-based controller to design a good trajectory that maximizes reward, while not deviating too far from the current policy.	O	O	Review	33
Then the new policy is learned from this trajectory.	O	O	Review	33
<sep> <sep> The authors contrast with (A) via "our student does not learn based on examples provided by the teacher, but is trained to mimic the internal structure of the teacher".	O	O	Review	33
The authors contrast with (B) in part by claiming that "the teacher must mirror the structure of the student", which is supposedly harder.	O	O	Review	33
<sep> <sep> Thus, it seems much of the intellectual merit &amp; novelty lies how the proposed method tackles this "structure" problem, from both the teacher and the student side.	O	O	Review	33
However, I'm having a hard time appreciating this aspect of the proposed approach.	B-Review	B-1	Review	33
I'm also confused by how the "student does not learn based on examples provided by the teacher" if it's doing imitation learning on trajectory-level demonstrations.	I-Review	I-1	Review	33
Can the authors elaborate on this point further?	I-Review	I-1	Review	33
<sep> <sep> The experiments seem ok.	O	O	Review	33
The idea of training programmatic polices that "inductively generalize" has been done before on arguably more difficult tasks (see Table 2 in <a href="https://arxiv.org/abs/1907.05431)."	O	O	Review	33
target="_blank" rel="nofollow">https://arxiv.org/abs/1907.05431).</a>   To contrast with this prior result, it seems the main point is that prior work relied on domain-specific program synthesizers.	B-Review	B-2	Review	33
Can the authors elaborate on this point further?	I-Review	I-2	Review	33
<sep> <sep> Minor comments:	B-Review	B-3	Review	33
<sep> -- Adaptive teaching is a pretty ambiguous term, and I think misleading within ML community (cf.	I-Review	I-3	Review	33
<a href="https://arxiv.org/abs/1802.05190)."	I-Review	I-3	Review	33
target="_blank" rel="nofollow">https://arxiv.org/abs/1802.05190).</a> I recommend a different algorithm name.	I-Review	I-3	Review	33
<sep> <sep> -- Deriving the variational objective is a lot of work to reduce it to just trajectory design.	I-Review	I-3	Review	33
Seems overkill.	I-Review	I-3	Review	33
<sep> <sep> <sep> <sep> ------------------------------------------------------------	O	O	Review	33
Updates after Author Response	O	O	Review	33
------------------------------------------------------------	O	O	Review	33
<sep> I increased my score to accept.	O	O	Review	33
I think this is a worthy contribution, and the authors did an excellent job addressing my concerns.	O	O	Review	33
Thank you for thoroughly reading the paper and your valuable comments.	O	O	Reply	33
We address your concerns below:	O	O	Reply	33
<sep> **** Importance of the state-machine structure and difference with prior work ****	O	O	Reply	33
<sep> Prior work in [1] and [2] has shown that programmatic policies achieve better interpretability and generalization over neural network policies.	B-Reply	B-2	Reply	33
For generalizability, they have shown that a policy learned for one particular track of the Torcs game can be easily transferred to a couple of other tracks.	I-Reply	I-2	Reply	33
In contrast, we focus on a different kind of generalization, namely, to performing a repetitive behavior arbitrarily many times.	I-Reply	I-2	Reply	33
We train on problem instances that only require a small number of repetitions of a behavior (e.g., 1 to 3), but the policies we learn generalize to problem instances where the behavior must be repeated an arbitrarily large number of times.	I-Reply	I-2	Reply	33
<sep> <sep> Prior work uses stateless programs, which makes learning generalizable repetitive behaviors hard, e.g., a stateless program cannot internally keep track of the progress made within each repetition and decide the next action based on that progress.	I-Reply	I-2	Reply	33
In contrast, we use state-machine based policies that have internal state.	I-Reply	I-2	Reply	33
With state-machine policies, the repetitive behavior in the tasks can be explicitly exposed (for ex, a set of modes that are connected in a cyclic order represents a loop), and the internal state (i.e. which mode the SM is in) can be used to keep track of the progress within a loop iteration.	I-Reply	I-2	Reply	33
<sep> <sep> Synthesizing state-machine policies is substantially more challenging than previous work, since it involves latent states that are unobserved.	I-Reply	I-2	Reply	33
A typical approach is to use a teacher such as a DNN to guide the search [1,2]; however, we found that DNNs are unable to learn the ‚Äúcorrect‚Äù latent states (i.e., the ones they learn do not generalize).	I-Reply	I-2	Reply	33
<sep> <sep> Our teacher is designed to avoid these problems.	I-Reply	I-2	Reply	33
First, our teacher also has an explicit notion of modes, and hence, it can discover the ‚Äúcorrect‚Äù modes that solve the task in a generalizable way, which the student will imitate.	I-Reply	I-2	Reply	33
Second, our representations also make it easy for the student to enforce the repetitive structure in the modes of the loop-free policies learned by the teacher.	I-Reply	I-2	Reply	33
<sep> <sep> In principle, the internal state can be replaced with the history of agent‚Äôs states.	I-Reply	I-2	Reply	33
However, for some environments, a long history might be needed to replicate the internal state.	I-Reply	I-2	Reply	33
Using such a long history would dramatically increase the dimension of the state space, making it very hard to generalize robustly.	I-Reply	I-2	Reply	33
<sep> <sep> <sep> **** Examples vs trajectory traces ****	O	O	Reply	33
<sep> We apologize for the confusion.	B-Reply	B-1	Reply	33
When we said that ‚Äúthe prior works assume a domain-specific program synthesizer that can learn programmatic policies given a supervised dataset‚Äù, we mean that they can learn a programmatic policy based on ‚Äústate-action pairs‚Äù sampled from the neural network.	I-Reply	I-1	Reply	33
<sep> <sep> On the other hand, the student in our algorithm needs to learn the state-machine policy from entire ‚Äútrajectory traces‚Äù to learn the internal state.	I-Reply	I-1	Reply	33
In particular, each trajectory trace consists of the sequence of states and actions from the initial state to the goal state visited by the teacher, but also encodes which states correspond to mode changes for the (loop-free) teacher.	I-Reply	I-1	Reply	33
In the teacher‚Äôs iteration, the teacher mode changes are regularized to align more closely with the possible student mode changes.	I-Reply	I-1	Reply	33
As a consequence, in the student‚Äôs iteration, it is easier for the student to mimic the teacher‚Äôs mode changes.	I-Reply	I-1	Reply	33
<sep> <sep> Leveraging this connection between the teacher structure and student structure is critical for us to be able to learn state-machine policies.	I-Reply	I-1	Reply	33
In contrast, existing approaches treat the teacher as a blackbox, and learn purely from the state-action examples obtained from the teacher.	I-Reply	I-1	Reply	33
They can do so since there is no latent information that the student needs to learn.	I-Reply	I-1	Reply	33
In contrast, in our setting, it is very hard to learn the latent mode transitions without supervision.	I-Reply	I-1	Reply	33
Using a teacher with mode changes alleviates this challenge.	I-Reply	I-1	Reply	33
<sep> <sep> <sep> [1] Abhinav Verma, Vijayaraghavan Murali, Rishabh Singh, Pushmeet Kohli, and Swarat Chaudhuri.	O	O	Reply	33
Programmatically interpretable reinforcement learning.	O	O	Reply	33
arXiv preprint arXiv:1804.02477, 2018.	O	O	Reply	33
<sep> [2] Abhinav Verma, Hoang Minh Le, Yisong Yue, and Swarat Chaudhuri.	O	O	Reply	33
Imitation-projected policy gradient for programmatic reinforcement learning.	O	O	Reply	33
CoRR, abs/1907.05431, 2019.	O	O	Reply	33
URL	O	O	Reply	33
http: //arxiv.org/abs/1907.05431.	O	O	Reply	33

This work proposes a framework for structuring policies using finite state machines, training a teacher-student setup using variational inference.	O	O	Review	33
The method is tested on a suite of standard control problems against PPO with / without memory and against simple numerical optimisation, analysing both performance and some degree of generalisation.	O	O	Review	33
<sep> <sep> <sep> Overall, I like both the problem setting (constraining / structuring policies using SMs), and the proposed modeling and optimisation.	O	O	Review	33
In particular, the teacher-student setup makes sense to me in the way it has been casted under VI, and I would like to see it explored further.	O	O	Review	33
<sep> <sep> I have however a few major issues that prevent me from recommending acceptance of the work:	O	O	Review	33
<sep> 1.	O	O	Review	33
The experiment section is generally lacking in terms of implementation details.	B-Review	B-1	Review	33
The authors don't specify anything about models structure or details about the employed state machines, and do not seem to have included details about their direct optimisation baseline, environment featurisation, hyperparameters used across their experiments, and so on.	I-Review	I-1	Review	33
I very much doubt I would be able to reproduce the results based only on the manuscript.	I-Review	I-1	Review	33
<sep> <sep> 2.	B-Review	B-2	Review	33
The quality of the policies depend heavily on how close the proposed state machine matches the underlying dynamics of each task.	I-Review	I-2	Review	33
Since - very often - complex tasks are hard to optimally describe without producing very large state machines, I would have liked to see the method tested against poor and/or adversarial specifications, to see whether empirically how well the student-teacher optimisation system can recover under such constraints.	I-Review	I-2	Review	33
<sep> <sep> 3.	O	O	Review	33
Casting the problem as a POMDP, while technically fine (and in most cases reasonable), doesn't seem to provide any significant advantage to the method, and seems to only be adding noise in the formalisms described across the paper.	B-Review	B-3	Review	33
Since the method introduces notation that a lot of RL researchers are not necessarily familiar with, I would suggest the author to try to simplify it where possible. [	I-Review	I-3	Review	33
Also please note that I haven't re-derived section 4.1 under this assumption, so correct me if I'm wrong on this.]	I-Review	I-3	Review	33
<sep> <sep> <sep> At this point, I am recommending a weak rejection, however I will be happy to significantly reconsider my overall assessment provided that at least point (1) is decently addressed (and ideally I get some response wrt.	B-Review	B-4	Review	33
points 2 and 3).	I-Review	I-4	Review	33
<sep> <sep> Thank you for thoroughly reading the paper and your valuable comments.	O	O	Reply	33
We address your concerns below:	O	O	Reply	33
<sep> **** Implementation details and direct opt baseline ****	O	O	Reply	33
<sep> We added details about the environments, state machines, hyper-parameters and the direct-opt baseline in Appendix B.3 in our paper.	B-Reply	B-1	Reply	33
We also show all synthesized state-machines in Figures 14 to 20.	I-Reply	I-1	Reply	33
<sep> <sep> **** Scaling to synthesizing large state machines ****	O	O	Reply	33
<sep> We have added a new, more complex benchmark -- namely, the MuJoCo swimmer (extended to 4 segments instead of 3 to make the task more challenging) -- to our paper.	B-Reply	B-2	Reply	33
This benchmark has control inputs R^3 and observation space R^10.	I-Reply	I-2	Reply	33
The state-machine policy synthesized using our algorithm has 4 different modes. (	I-Reply	I-2	Reply	33
Section 5, Figure 10, Figure 20)	I-Reply	I-2	Reply	33
<sep> Overall, the focus of our paper is on addressing problems where a relatively simple behavior must be repeated a certain number of times to solve the given task.	I-Reply	I-2	Reply	33
We believe these problems are pervasive -- for example, many motor tasks such as walking, running, jumping, swimming, etc.	I-Reply	I-2	Reply	33
all rely on this kind of a policy.	I-Reply	I-2	Reply	33
Yet, neural network policies have difficulty solving these tasks in a generalizable way.	I-Reply	I-2	Reply	33
The key premise behind our approach is that compact state-machine policies can represent policies that both have good performance and are generalizable for this class of problems.	I-Reply	I-2	Reply	33
Indeed, our algorithm solves all of our benchmarks using state-machine policies with at most 4 modes and switching conditions of depth at most 2.	I-Reply	I-2	Reply	33
<sep> <sep> For example, consider the autonomous car example in Figure 1.	I-Reply	I-2	Reply	33
The task in Figure 1d (i.e. when the gap between cars is very small) is significantly complex that the neural network baseline was not able to solve (even when trained directly on those initial states; see Figure 3 rightmost).	I-Reply	I-2	Reply	33
However, a small state-machine policy with only 3 modes was able to solve this task.	I-Reply	I-2	Reply	33
<sep> <sep> We certainly agree with the reviewer that it will be interesting to see how the algorithm scales for larger state machines.	I-Reply	I-2	Reply	33
However, this problem is qualitatively different from the one we are solving, and different algorithms would be needed to solve it.	I-Reply	I-2	Reply	33
Overall, we believe that state-machines are most useful when only a few states are required.	I-Reply	I-2	Reply	33
When a large number of states are needed, then the number of possible transition structures grows exponentially, making it unlikely that we can learn the ‚Äútrue‚Äù structure without having an exponential amount of both training data and computation time.	I-Reply	I-2	Reply	33
For these cases, we believe recurrent neural network policies such as LSTMs may remain the better choice.	I-Reply	I-2	Reply	33
<sep> <sep> **** Casting the problem as a POMDP ****	O	O	Reply	33
<sep> We use a POMDP formulation because our policies have internal state and some of our benchmarks (e.g., QuadPO) have different observation vectors and the state vectors.	B-Reply	B-3	Reply	33
We thought about focusing on MDPs to simplify notation, but concluded that it would not significantly help.	I-Reply	I-3	Reply	33
The aspect of our approach that complicates our formalization is that our policies keep internal state.	I-Reply	I-3	Reply	33
However, this aspect is central to our approach, since we are both positing that internal state is necessary, and that it is hard to learn programmatic policies with internal state.	I-Reply	I-3	Reply	33

This paper describes a first working approach for fully unsupervised neural machine translation.	O	O	Review	394
The core ideas being this method are: (1) train in both directions (French to English and English to French) in tandem; (2) lock the embedding table to bilingual embeddings induced from monolingual data; (3) share the encoder between two languages; and (3)  alternate between denoising auto-encoder steps and back-translation steps.	O	O	Review	394
The key to making this work seems to be using a denoising auto-encoder where noise is introduced by permuting the source sentence, which prevents the encoder from learning a simple copy operation.	O	O	Review	394
The paper shows real progress over a simple word-to-word baseline for WMT 2014 English-French and English-German.	O	O	Review	394
Preliminary results in a semi-supervised setting are also provided.	O	O	Review	394
<sep> <sep> This is solid work, presenting a reasonable first working system for unsupervised NMT, which had never been done before now.	O	O	Review	394
That alone is notable, and overall, I like the paper.	B-Review	B-1	Review	394
The work shares some similarities with He et al‚Äôs NIPS 2016 paper on ‚ÄúDual learning for MT,‚Äù but has more than enough new content to address the issues that arise with the fully unsupervised scenario.	I-Review	I-1	Review	394
The work is not perfect, though.	I-Review	I-1	Review	394
I feel that the paper‚Äôs abstract over-claims to some extent.	I-Review	I-1	Review	394
Also, the experimental section shows clearly that in getting the model to work at all, they have created a model with a very real ceiling on performance.	I-Review	I-1	Review	394
However, to go from not working to working a little is a big, important first step.	O	O	Review	394
Also, I found the paper‚Äôs notation and prose to be admirably clear; the paper was very easy to follow.	O	O	Review	394
<sep> <sep> Regarding over-claiming, this is mostly an issue of stylistic preference, but this paper‚Äôs use of the term ‚Äúbreakthrough‚Äù in both the abstract and the conclusion grates a little.	B-Review	B-1	Review	394
This is a solid first attempt at a new task, and it lays a strong foundation for others to build upon, but there is lots of room for improvement.	I-Review	I-1	Review	394
I don‚Äôt think it warrants being called a breakthrough - lots of papers introduce new tasks and produce baseline solutions.	I-Review	I-1	Review	394
I would generally advise to let the readers draw their own conclusions.	I-Review	I-1	Review	394
<sep> <sep> Regarding the ceiling, the authors are very up-front about this in Table 1, but it bears repeating here: a fully supervised model constrained in the same way as this unsupervised model does not perform very well at all.	B-Review	B-2	Review	394
In fact, it consistently fails to surpass the semi-supervised baseline (which I think deserved some further discussion in the paper).	I-Review	I-2	Review	394
The poor performance of the fully supervised model demonstrates that there is a very real ceiling to this approach, and the paper would be stronger if the authors were able to show to what degree relaxing these constraints harms the unsupervised system and helps the supervised one.	I-Review	I-2	Review	394
<sep> <sep> The semi-supervised experiment in Sections 2.3 and 4 is a little dangerous.	B-Review	B-3	Review	394
With BLEU scores failing to top 22 for English-French, there is a good chance that a simple phrase-based baseline on the same 100k sentence pairs with a large target language model will outperform this technique.	I-Review	I-3	Review	394
Any low-resource scenario should include a Moses baseline for calibration, as NMT is notoriously weak with small amounts of parallel data.	I-Review	I-3	Review	394
<sep> <sep> Finally, I think the phrasing in Section 5.1 needs to be softened, where it states, ‚Äú... it is not possible to use backtranslation alone without denoising, as the initial translations would be meaningless sentences produced by a random NMT model, ...‚Äù This statement implies that the system producing the sentences for back-translation must be a neural MT system, which is not the case.	B-Review	B-4	Review	394
For example, a related paper co-submitted to ICLR, called ‚ÄúUnsupervised machine translation using monolingual corpora only,‚Äù shows that one can prime back-translation with a simple word-to-word system similar to the word-to-word baseline in this paper‚Äôs Table 1.	I-Review	I-4	Review	394
Thanks for the insightful feedback.	O	O	Reply	394
Please find our answers below:	O	O	Reply	394
<sep> - Regarding over-claiming, it was not our intention to exaggerate our contribution, and we in fact share your view on this: we think that our work is a strong foundation for a new and exciting research direction in NMT, but we agree that it is only a first step and there is still a long way to go.	B-Reply	B-1	Reply	394
We understand that ‚Äúbreakthrough‚Äù might not be the most appropriate term for this, and we have removed it from the revised version of the paper.	I-Reply	I-1	Reply	394
<sep> <sep> - We find the discussion on the ceiling very interesting and relevant.	B-Reply	B-2	Reply	394
We agree on the following key observations: 1) the comparable supervised system can be seen as a ceiling for the unsupervised system, and 2) the comparable supervised system gets relatively poor results.	I-Reply	I-2	Reply	394
As such, one might conclude that our approach has a hard limit in this ceiling, as any eventual improvement in the proposed training method could at best close the gap with it.	I-Reply	I-2	Reply	394
However, this also assumes that the ceiling itself is fixed and cannot be improved, which we do not find to be the case.	I-Reply	I-2	Reply	394
In fact, we think that a very interesting research direction is to identify and address the factors that limited the performance of the comparable supervised system, which should also translate in an improvement for the unsupervised system.	I-Reply	I-2	Reply	394
We have the following ideas in this regard, which we have better described in the revised version of the paper:	I-Reply	I-2	Reply	394
<sep> 1) We did not perform any rigorous hyperparameter exploration, and we favored efficiency over performance in our experimental design.	B-Reply	B-2	Reply	394
As such, we think that there is a considerable margin to improve our results with some engineering effort, such as using larger models, longer training times, ensembling techniques and better decoding strategies (length/coverage penalty).	I-Reply	I-2	Reply	394
<sep> <sep> 2) While the constraints that we introduce to make our unsupervised system trainable might also limit its performance, one could design a multi-phase training procedure where these constraints are progressively relaxed.	B-Reply	B-2	Reply	394
For instance, a key aspect of our design is to use fixed cross-lingual embeddings in the encoder.	I-Reply	I-2	Reply	394
This is necessary in the early stages of training, as it forces the encoder to use a common word representation for both languages, but it might also limit what it can ultimately learn in the process.	I-Reply	I-2	Reply	394
For that reason, one could start to progressively update the weights of the encoder embeddings as training progresses.	I-Reply	I-2	Reply	394
Similarly, one could also decouple the shared encoder into two independent encoders at some point during training, or progressively reduce the noise level.	I-Reply	I-2	Reply	394
<sep> <sep> - Regarding the semi-supervised experiments, note that our point here was not to improve the state of the art under these conditions, but rather to prove that the proposed system can also exploit a (relatively) small parallel corpus, showing its potential interest beyond the strictly unsupervised scenario.	B-Reply	B-3	Reply	394
<sep> <sep> - Our statement that ‚Äúit is not possible to use backtranslation alone without denoising‚Äù was referring to our training procedure where backtranslation uses the model from the previous iteration.	B-Reply	B-4	Reply	394
It is true that it does not apply to the general case, as backtranslation could also be used in conjunction with other translation methods (e.g. embedding nearest neighbor), and we have consequently softened the statement in the revised version as suggested.	I-Reply	I-4	Reply	394

unsupervised neural machine translation	O	O	Review	394
<sep> This is an interesting paper on unsupervised MT.	O	O	Review	394
It trains a standard architecture using:	O	O	Review	394
<sep> 1) word embeddings in a shared embedding space, learned using a recent approach that works with only tens of bilingual word papers.	O	O	Review	394
<sep> <sep> 2) A encoder-decoder trained using only monolingual data (should cite <a href="http://www.statmt.org/wmt17/pdf/WMT15.pdf)."	O	O	Review	394
target="_blank" rel="nofollow">http://www.statmt.org/wmt17/pdf/WMT15.pdf).</a> Training uses a ‚Äúdenoising‚Äù method which is not new: it uses the same idea as contrastive estimation (<a href="http://www.aclweb.org/anthology/P05-1044," target="_blank" rel="nofollow">http://www.aclweb.org/anthology/P05-1044,</a> a well-known method which should be cited).	O	O	Review	394
<sep> <sep> 3) Backtranslation.	O	O	Review	394
<sep> <sep> All though none of these ideas are new, they haven‚Äôt been combined in this way before, and that what‚Äôs novel here.	O	O	Review	394
The paper is essentially a neat application of (1), and is an empirical/ systems paper.	O	O	Review	394
It‚Äôs essentially a proof-of-concept that it is that it‚Äôs possible to get anything at all using no parallel data.	O	O	Review	394
That‚Äôs surprising and interesting, but I learned very little else from it.	O	O	Review	394
The paper reads as preliminary and rushed, and I had difficulty answering some basic questions:	O	O	Review	394
<sep> * In Table (1), I‚Äôm slightly puzzled by why 5 is better than 6, and this may be because I‚Äôm confused about what 6 represents.	B-Review	B-1	Review	394
It would be natural to compare 5 with a system trained on 100K parallel text, since the systems would then (effectively) differ only in that 5 also exploits additional monolingual data.	I-Review	I-1	Review	394
But the text suggests that 6 is trained on much more than 100K parallel sentences; that is, it differs in at least two conditions (amount of parallel text and use of monolingual text).	I-Review	I-1	Review	394
Since this paper‚Äôs primary contribution is empirical, this comparison should be done in a carefully controlled way, differing each of these elements in turn.	I-Review	I-1	Review	394
<sep> <sep> * I‚Äôm very confused by the comment on p. 8 that ‚Äúthe modifications introduced by our proposal are also limiting‚Äù to the ‚Äúcomparable supervised NMT system‚Äù.	B-Review	B-2	Review	394
According to the paper, the architecture of the system is unchanged, so why would this be the case?	I-Review	I-2	Review	394
This comment makes it seem like something else has been changed in the baseline, which in turn makes it somewhat hard to accept the results here.	I-Review	I-2	Review	394
<sep> <sep> Comment:	O	O	Review	394
* The qualitative analysis is not really an analysis: it‚Äôs just a few cherry-picked examples and some vague observations.	B-Review	B-3	Review	394
While it is useful to see that the system does indeed generate nontrivial content in these cases, this doesn‚Äôt give us further insight into what the system does well or poorly outside these examples.	I-Review	I-3	Review	394
The BLEU scores suggest that it also produces many low-quality translations.	I-Review	I-3	Review	394
What is different about these particular examples? (	I-Review	I-3	Review	394
Aside: since the cross-lingual embedding method is trained on numerals, should we be concerned that the system fails at translating numerals?)	I-Review	I-3	Review	394
<sep> <sep> Questions:	O	O	Review	394
* Contrastive estimation considers other neighborhood functions (‚Äúrandom noise‚Äù in the parlance of this paper), and it‚Äôs natural to wonder what would happen if this paper also used these or other neighborhood functions.	B-Review	B-4	Review	394
More importantly, I suspect the the neighborhood functions are important: when translating between Indo-European languages as in these experiments, local swaps are reasonable; but in translating between two different language families (as would often be the case in the motivating low-resource scenario that the paper does not actually test), it seems likely that other neighborhood functions would be important, since structural differences would be much larger.	I-Review	I-4	Review	394
<sep> <sep> Presentational comments (these don‚Äôt affect my evaluation, they‚Äôre mostly observations but they contribute to a general feeling that the paper is rushed and preliminary):	I-Review	I-4	Review	394
<sep> * BPE does not ‚Äúlearn‚Äù, it‚Äôs entirely deterministic.	B-Review	B-5	Review	394
<sep> <sep> * This paper is at best tangentially related to decipherment.	B-Review	B-6	Review	394
Decipherment operates under two quite different assumptions: there is no training data for the source language ciphertext, only the ciphertext itself (which is often very small); and the replacement function is deterministic rather than probabilistic (and often monotonic).	I-Review	I-6	Review	394
The Dou and Knight papers are interesting, but they‚Äôre an adaptation of ideas rather than decipherment per se.	I-Review	I-6	Review	394
Since none of those ideas are used here this feels like hand-waving.	I-Review	I-6	Review	394
<sep> <sep> * Future work is vague: ‚Äúwe would like to detect and mitigate the specific causes‚Ä¶‚Äù ‚Äúwe also think that a better handling of rare words‚Ä¶‚Äù That‚Äôs great, but how will you do these things?	B-Review	B-7	Review	394
Do you have specific reasons to think this, or ideas on how to approach them?	I-Review	I-7	Review	394
Otherwise this is just hand-waving.	I-Review	I-7	Review	394
Thanks for the insightful review.	O	O	Reply	394
We have tried to make the paper more clear in the revised version taking these comments into account.	O	O	Reply	394
Please find the answers to each specific point below:	O	O	Reply	394
<sep> General:	O	O	Reply	394
<sep> - To clarify what the semi-supervised and supervised systems represents in Table 1: (5) is the same as (4), but in addition to training on monolingual corpora using denoising and backtransaltion, it is also trained in a subset of 100K parallel sentences using standard supervised cross-entropy loss (it alternates one mini-batch of denoising, one mini-batch of backtranslation and one mini-batch of  this supervised training). (	B-Reply	B-1	Reply	394
6) is the same as (5) except for two differences: 1) it uses the full parallel corpus instead of the subset of 100K parallel sentences, and 2) it does not use any monolingual corpora nor denoising or backtranslation.	I-Reply	I-1	Reply	394
We think that the main reason why (5) is better than (6) is related to the domain: the parallel corpus of (6) is general, whereas the subset of 100K parallel sentences and the monolingual corpus used for (5) are in the news domain just as the test set.	I-Reply	I-1	Reply	394
While these facts were already mentioned in the paper, the new version includes a more detailed discussion.	I-Reply	I-1	Reply	394
At the same time, we agree that the fact that the comparable system differs from the semi-supervised system in two aspects makes the comparison more difficult, and we are currently working to extend our experiments accordingly.	I-Reply	I-1	Reply	394
<sep> <sep> - Regarding the comment that ‚Äúthe modifications introduced by our proposal are also limiting‚Äù to the ‚Äúcomparable supervised NMT system‚Äù, note that, as discussed in the previous point, the comparable NMT system uses the exact same architecture and hyperparameters as the unsupervised system (number of layers, hidden units, attention model etc.)	B-Reply	B-2	Reply	394
and, as such, it also incorporates the non-standard variations in Section 3.1 (dual structure using a shared encoder with fixed embeddings).	I-Reply	I-2	Reply	394
These are what we were referring to as ‚Äúthe modification introduced by our proposal‚Äù, but the only difference between the unsupervised and the supervised systems is that, instead of training in monolingual corpora using denoising and backtranslation, we train in parallel corpora just as in standard NMT.	I-Reply	I-2	Reply	394
We have tried to make this more clear in the revised version of the paper.	I-Reply	I-2	Reply	394
<sep> <sep> Comment:	O	O	Reply	394
<sep> - We agree that the qualitative analysis in the current version is limited.	B-Reply	B-3	Reply	394
It was done mainly to check and illustrate that the proposed unsupervised NMT system generates sensible translations despite the lack of parallel corpora.	I-Reply	I-3	Reply	394
We believe that a more detailed investigation and analysis into the properties and characteristics of translation generated by unsupervised NMT must be conducted in the future.	I-Reply	I-3	Reply	394
<sep> <sep> - Note that we only use shared numerals to initialize the iterative embedding mapping method, so it is understandable that the system fails to translate numerals after the training of both the embedding mapping and the unsupervised NMT system itself.	B-Reply	B-3	Reply	394
While it would certainly be possible to perform an ad-hoc processing to translate numerals under the assumption that they are shared by different languages, our point was to show that the system has some logical adequacy issues for very similar concepts (e.g. different numerals or month names).	I-Reply	I-3	Reply	394
<sep> <sep> Questions:	O	O	Reply	394
<sep> - Thanks for pointing out the connection with contrastive estimation, which is now properly discussed in the revised version of the paper.	B-Reply	B-4	Reply	394
As for the role of neighborhood functions, we agree that there are many possible choices beyond local swaps, and the optimal choice could greatly depend on the typological divergences between the languages involved.	I-Reply	I-4	Reply	394
In this regard, we think that this is a very interesting direction to explore in the future, and we have tried to better discuss this matter in the revised version of the paper.	I-Reply	I-4	Reply	394
<sep> <sep> Having said that, please note that we have considered two language pairs (English-French and English-German) in our experiments.	B-Reply	B-4	Reply	394
Despite being indo-european, there are important properties that distinguish these language pairs, such as the verb-final construction and the prevalence of compounding in German in contrast to French.	I-Reply	I-4	Reply	394
In fact, English-German has often been studied in machine translation as a particularly challenging language pair.	I-Reply	I-4	Reply	394
For that reason, we believe that the experiments on these two distinct language pairs support the effectiveness of the proposed approach, despite the potential for future investigation on the effect of contrastive functions on the choice of language pairs.	I-Reply	I-4	Reply	394

The authors present a model for unsupervised NMT which requires no parallel corpora between the two languages of interest.	O	O	Review	394
While the results are interesting I find very few original ideas in this paper.	O	O	Review	394
Please find my comments/questions/suggestions below:	O	O	Review	394
<sep> 1) The authors mention that there are 3 important aspects in which their model differs from a standard NMT architecture.	B-Review	B-1	Review	394
All the 3 differences have been adapted from existing works.	I-Review	I-1	Review	394
The authors clearly acknowledge and cite the sources.	I-Review	I-1	Review	394
Even sharing the encoder using cross lingual embeddings has been explored in the context of multilingual NER (please see <a href="https://arxiv.org/abs/1607.00198)."	I-Review	I-1	Review	394
target="_blank" rel="nofollow">https://arxiv.org/abs/1607.00198).</a> Because of this I find the paper to be a bit lacking on the novelty quotient.	I-Review	I-1	Review	394
Even backtranslation has been used successfully in the past (as acknowledged by the authors).	I-Review	I-1	Review	394
Unsupervised MT in itself is not a new idea (again clearly acknowledged by the authors).	I-Review	I-1	Review	394
<sep> <sep> 2) I am not very convinced about the idea of denoising.	B-Review	B-2	Review	394
Specifically, I am not sure if it will work for arbitrary language pairs.	I-Review	I-2	Review	394
In fact, I think there is a contradiction even in the way the authors write this.	I-Review	I-2	Review	394
On one hand, they want to "learn the internal structure of the languages involved" and on the other hand they deliberately corrupt this structure by adding noise.	I-Review	I-2	Review	394
This seems very counter-intuitive and in fact the results in Table 1 suggest that it leads to a drop in performance.	I-Review	I-2	Review	394
I am not very sure that the analogy with autoencoders holds in this case.	I-Review	I-2	Review	394
<sep> <sep> 3) Following up on the above question, the authors mention that "We emphasize, however, that it is not possible to use backtranslation alone without denoising".	B-Review	B-3	Review	394
Again, if denoising itself leads to a drop in the performance as compared to the nearest neighbor baseline then why use backtranslation in conjunction with denoising and not in conjunction with the baseline itself.	I-Review	I-3	Review	394
<sep> <sep> 4) This point is more of a clarification and perhaps due to my lack of understanding.	B-Review	B-3	Review	394
Backtranslation to generate a pseudo corpus makes sense only after the model has achieved a certain (good) performance.	I-Review	I-3	Review	394
Can you please provide details of how long did you train the model (with denoising?)	I-Review	I-3	Review	394
before producing the backtranslations ?	I-Review	I-3	Review	394
<sep> <sep> 5) The authors mention that 100K parallel sentences may be insufficient for training a NMT system.	B-Review	B-4	Review	394
However, this size may be decent enough for  a PBSMT system.	I-Review	I-4	Review	394
It would be interesting to see the performance of a PBSMT system trained on 100K parallel sentences.	I-Review	I-4	Review	394
<sep> <sep> 6) How did you arrive at the beam size of 12 ?	B-Review	B-5	Review	394
Was this a hyperparameter?	I-Review	I-5	Review	394
Just curious.	I-Review	I-5	Review	394
<sep> <sep> 7) The comparable NMT set up is not very clear.	B-Review	B-6	Review	394
Can you please explain it in detail ?	I-Review	I-6	Review	394
In the same paragraph, what exactly do you mean by "the supervised system in this paper is relatively small?"	I-Review	I-6	Review	394
Thanks for the insightful comments.	O	O	Reply	394
Please find the answers to the specific points below, which were also addressed in the revised version of the paper:	O	O	Reply	394
<sep> 1) We are aware that the basic building blocks of our work come from previous work and, as you note, we try to properly acknowledge that in the paper.	B-Reply	B-1	Reply	394
However, we do not see this as a weakness, but rather an inherent characteristic of science as a collaborative effort.	I-Reply	I-1	Reply	394
Our contribution lies in combining these basic building blocks in a novel way to build the first fully unsupervised NMT system.	I-Reply	I-1	Reply	394
We believe that this is an important contribution on its own: NMT is a highly relevant field where the predominant approach has been supervised and, for the first time, we show that an unsupervised approach is also viable.	I-Reply	I-1	Reply	394
As such, we think that our work explores a highly original idea and opens a new and exciting research direction.	I-Reply	I-1	Reply	394
<sep> <sep> 2) This is a very interesting observation, but we think that, paradoxically, corrupting the structure of the language is necessary for the system to learn such structure.	B-Reply	B-2	Reply	394
Note that, without denoising, this training step would be reduced to a trivial copying task that admits degenerated solutions.	I-Reply	I-2	Reply	394
The intuition is that one can easily copy a sentence in any language even if they know nothing about that language.	I-Reply	I-2	Reply	394
In contrast, adding noise to the input makes the task of reconstructing the input non-trivial, and forces the system to learn about the structure of that language to be able to solve it.	I-Reply	I-2	Reply	394
The intuition in this case is that, if we are given a scrambled sentence in some language, it is not possible for us to recover the original sentence unless we have some knowledge of the language in question.	I-Reply	I-2	Reply	394
In other words, the idea of denoising is to corrupt the structure of the input, so the system needs to learn the correct structure in order to recover the original uncorrupted input (this is possible because the system does see the correct structure in the output during training).	I-Reply	I-2	Reply	394
Note that this has also been found to help extract good representations from natural language sentences by other authors (Hill et al 2016).	I-Reply	I-2	Reply	394
Regarding arbitrary language pairs, we think that this idea is particularly relevant for distant pairs: corrupting the word order of the input makes the shared encoder rely less in this word order, which is necessary for distant language pairs with more divergences in this regard.	I-Reply	I-2	Reply	394
<sep> <sep> 3/4) There seems to be some confusion here on how our training procedure works in relation to backtranslation.	B-Reply	B-3	Reply	394
Note that each training iteration performs one mini-batch of denoising and one mini-batch of backtranslation in each direction, and the bactranslation step at iteration i uses the model from iteration (i-1).	I-Reply	I-3	Reply	394
This way, denoising and backtranslation keep constantly improving the model, and backtranslation itself uses the most recent model at each time.	I-Reply	I-3	Reply	394
This is in contrast with traditional backtranslation, where a fixed model is used to backtranslate the entire corpus at one time.	I-Reply	I-3	Reply	394
In relation to point 3, while denoising alone is certainly weaker than the nearest neighbor baseline, the combination of denoising and backtransation eventually leads to a stronger model, which backtranslation itself takes advantage of in the following iterations as just described.	I-Reply	I-3	Reply	394
<sep> <sep> 5) The purpose of this experiment was to show that the proposed system can also benefit from small parallel corpora, making it suitable not only for the unsupervised scenario, but also for the semi-supervised scenario.	B-Reply	B-4	Reply	394
As such, our point was not to improve the state of the art under these conditions, but rather to show that our work has potential interest beyond the strictly unsupervised scenario.	I-Reply	I-4	Reply	394
<sep> <sep> 6) A beam size of 12 is very common in previous work (Sutskever et al 2014; Sennrich et al 2016a;b; He et al 2016), so we also adopted it for our experiments without any further exploration.	B-Reply	B-5	Reply	394
<sep> <sep> 7) The comparable NMT system uses the exact same architecture and hyperparameters as the unsupervised system (number of layers, hidden units, attention model etc.).	B-Reply	B-6	Reply	394
Furthermore, it incorporates the non-standard variations in Section 3.1 (dual structure using a shared encoder with fixed embeddings).	I-Reply	I-6	Reply	394
The only difference is that, instead of training it on monolingual corpora using denoising and backtranslation, it is trained on parallel corpora just as standard NMT.	I-Reply	I-6	Reply	394
<sep> <sep> When we say that "the supervised system in this paper is relatively small", we mean that the size of the model (number of layers, training time etc.)	I-Reply	I-6	Reply	394
is small compared to the state of the art, which explains in part why its results are also weaker.	I-Reply	I-6	Reply	394
However, note that this also applies to the unsupervised system, which uses the exact same settings.	I-Reply	I-6	Reply	394
We therefore believe that there is a considerable margin to improve our results by using a larger model.	I-Reply	I-6	Reply	394

This paper proposes a new training objective for generative models that combines the objectives of VAEs and GANs.	O	O	Review	20397
The objective is equivalent to minimizing the Jeffreys divergence (a type of f-divergence) between the true probability of the data and its probability under the model.	O	O	Review	20397
Furthermore, the objective comes with a knob to tradeoff the relative importance of each of the two terms.	O	O	Review	20397
In addition, the authors develop a implicit likelihood formulation which they claim and show empirically to outperform typical explicit formulations typically used in VAEs.	O	O	Review	20397
<sep> <sep> Overall, it is an interesting paper that reuses a few good ideas to develop a novel training objective.	O	O	Review	20397
The results show that using an implicit likelihood helps (Figure 2) and that it does relatively better than either GAN or VAE approaches.	O	O	Review	20397
I have detailed comments below about the organization of the paper, some of the experimental claims as well as a few other works which may be good to cite.	B-Review	B-11	Review	20397
<sep> <sep> <sep> - Paper organization: I would suggest moving the related work to after the background.	B-Review	B-1	Review	20397
<sep> <sep> - GANs and VAEs are not models per se but rather training frameworks for generative models.	B-Review	B-10	Review	20397
<sep> <sep> - While VAEs and GANs can work on many types of data (at the very least continuous), your model seems to be developed for images.	B-Review	B-3	Review	20397
Could you make it clear what changes would be needed to apply it to non-image data?	I-Review	I-3	Review	20397
<sep> <sep> - There are many minor grammatical errors throughout the text.	B-Review	B-9	Review	20397
<sep> <sep> - It would be useful to provide the full algorithm somewhere (e.g., using an algorithm "box")	B-Review	B-1	Review	20397
<sep> - Possible related work.	B-Review	B-2	Review	20397
It may be worth citing these two paper:	I-Review	I-2	Review	20397
- f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization, NIPS'16	I-Review	I-2	Review	20397
- Deep Generative Learning via Variational Gradient Flow, ICML'19	I-Review	I-2	Review	20397
- It would be useful to mention early that for IS higher is better and LPIPS lower is better.	B-Review	B-8	Review	20397
<sep> <sep> - Even though Figures 2 and 3 (to a certain extent) seem to show that results are somewhat robust to the exact value \lambda how would you propose to set it in practice?	B-Review	B-5	Review	20397
<sep> <sep> - Figure 3 Left (CIFAR 10), it's not absolutely clear to me that alpha-GAN and perhaps AGE isn't at least as good as your approach.	B-Review	B-7	Review	20397
The meaning of the units of the axes is a bit unclear.	I-Review	I-7	Review	20397
Do you have a particular reason to prefer your method over these in this case?	I-Review	I-7	Review	20397
<sep> <sep> Related: in Table 1, why are there no bolded results for CIFAR + Reconstruction?	B-Review	B-6	Review	20397
<sep> <sep> - In Figures 5 and 7 the reconstruction of IJAE sometimes seems to be pretty far from the original image (i.e., it's not that it's blurry as for VAEs, it's that the model seems to be reconstructing a completely different image).	B-Review	B-4	Review	20397
How do you explain these results?	I-Review	I-4	Review	20397
Dear reviewer,	O	O	Reply	20397
<sep> We would like to thank you for your thoughtful review and valuable suggestions.	O	O	Reply	20397
We will address each your question below:	O	O	Reply	20397
<sep> &gt; Figure 3 Left (CIFAR 10), it's not absolutely clear to me that alpha-GAN and perhaps AGE isn't at least as good as your approach.	O	O	Reply	20397
The meaning of the units of the axes is a bit unclear.	O	O	Reply	20397
Do you have a particular reason to prefer your method over these in this case?	O	O	Reply	20397
<sep> <sep> To make it more clear: on Figure 3 x-axis and y-axis correspond to Inception Score (IS) and LPIPS metrics respectively.	B-Reply	B-7	Reply	20397
From this plot we can see that alpha-GAN, AGE and IJAE have comparable LPIPS.	I-Reply	I-7	Reply	20397
However, the advantage of our method is that we can offer a model with significantly better IS by keeping LPIPS almost the same.	I-Reply	I-7	Reply	20397
Particularly, for CIFAR-10 in Table 1 we chose lambda = 0.3 for which IJAE achieves the best IS and comparable LPIPS (we can see from variance bars that differences in LPIPS are insignificant).	I-Reply	I-7	Reply	20397
So, the main reason to prefer our method over baselines is that it can provide a much better tradeoff between generation and reconstruction qualities.	I-Reply	I-7	Reply	20397
<sep> <sep> &gt; Related: in Table 1, why are there no bolded results for CIFAR + Reconstruction?	O	O	Reply	20397
<sep> <sep> The main reason is that most differences in LPIPS are insignificant due to large variance bars.	B-Reply	B-6	Reply	20397
In the next revision of our paper we can bold all results except ones which are significantly worse than others.	I-Reply	I-6	Reply	20397
<sep> <sep> &gt; Even though Figures 2 and 3 (to a certain extent) seem to show that results are somewhat robust to the exact value \lambda how would you propose to set it in practice?	O	O	Reply	20397
<sep> <sep> From Figures 2 and 3 we see that the reconstruction quality is robust to decreasing lambda and starts to degrade only when lambda goes below 0.2.	B-Reply	B-5	Reply	20397
While the generation quality is very sensitive to lambda and can be improved significantly by decreasing lambda.	I-Reply	I-5	Reply	20397
Therefore, in practice, we recommend setting lambda around 0.3 when IJAE has the best generation ability and acceptable reconstruction quality.	I-Reply	I-5	Reply	20397
<sep> <sep> &gt; In Figures 5 and 7 the reconstruction of IJAE sometimes seems to be pretty far from the original image (i.e., it's not that it's blurry as for VAEs, it's that the model seems to be reconstructing a completely different image).	O	O	Reply	20397
How do you explain these results?	O	O	Reply	20397
<sep> <sep> Such unfaithful reconstructions can be explained by the fact that we do not use an explicit pixel-wise reconstruction loss and our implicit loss can sometimes accept such reconstructions due to the underfitting of the discriminator on triples.	B-Reply	B-4	Reply	20397
<sep> <sep> &gt; While VAEs and GANs can work on many types of data (at the very least continuous), your model seems to be developed for images.	O	O	Reply	20397
Could you make it clear what changes would be needed to apply it to non-image data?	O	O	Reply	20397
<sep> <sep> It is a good question.	B-Reply	B-3	Reply	20397
It is true that in the paper we mostly focus on images and do not mention other types of data.	I-Reply	I-3	Reply	20397
However, the only thing we should change for non-image data is the implementation of the implicit conditional likelihood r(y|x) which encourages the set of faithful reconstructions for the object x. For example, for images, we chose the distribution over the shifted versions of x. If we consider sequence generating model, for example, and object x is a sequence of words, we can consider r(y|x) as a distribution over sequences that are equal to x up to synonym words.	I-Reply	I-3	Reply	20397
Other parts of IJAE model remain the same for non-image data.	I-Reply	I-3	Reply	20397
<sep> We will add clarification about the applicability of our model to non-image data in the next revision of our paper.	I-Reply	I-3	Reply	20397
<sep> <sep> &gt; Possible related work.	O	O	Reply	20397
It may be worth citing these two papers ‚Ä¶	O	O	Reply	20397
<sep> Thank you for pointing out these papers we missed to cite.	B-Reply	B-2	Reply	20397
We will add them to the related work and comment on each paper.	I-Reply	I-2	Reply	20397
<sep> <sep> &gt; Paper organization: I would suggest moving the related work to after the background.	O	O	Reply	20397
It would be useful to provide the full algorithm somewhere (e.g., using an algorithm "box").	O	O	Reply	20397
<sep> GANs and VAEs are not models per se but rather training frameworks for generative models.	B-Reply	B-1	Reply	20397
There are many minor grammatical errors throughout the text.	I-Reply	I-1	Reply	20397
It would be useful to mention early that for IS higher is better and LPIPS lower is better.	I-Reply	I-1	Reply	20397
<sep> <sep> Thank you for your valuable suggestions for improving paper text and organization quality.	O	O	Reply	20397
We will certainly follow them in the next revision of our paper.	O	O	Reply	20397

This paper introduces a model named lambda-IJAE, which combines the VAE and GAN training schemes to train a generative model achieving competitive performance.	O	O	Review	20397
The combination of VAE and GAN is justified by its theoretical interpretation as a an optimization of the lambda-Jeffreys divergence between the real data distribution and the generation distribution.	O	O	Review	20397
This work also introduces a reformulation of the reconstruction term of the VAE loss, allowing it to be estimated implicitly using an adversarial mechanism.	O	O	Review	20397
Finally, the latent space of the VAE is also modelled implicitly using an adversarial mechanism, following (Mescheder et al 2017).	O	O	Review	20397
<sep> <sep> I am ambivalent about this paper.	O	O	Review	20397
The proposed implicit likelihood mechanism is very interesting, but the paper contains several weaknesses that together make me unwilling to accept it.	O	O	Review	20397
<sep> <sep> First of all, the paper presents itself as centered on the notion of optimizing the lambda-Jeyffreys distribution, while the main contribution is actually clearly the formulation of the implicit likelihood.	B-Review	B-1	Review	20397
The use of a weighted sum of the forward &amp; KL divergences to train a generative model is hardly new, and has already been presented a few times (Larsen et al 2015, Dosovitskiy &amp; Brox 2016).	I-Review	I-1	Review	20397
<sep> <sep> In this context the paper does not present the impact of its main contribution alone.	B-Review	B-2	Review	20397
How would behave a VAE trained solely with this implicit likelihood, but a regular Gaussian latent space and without the GAN loss?	I-Review	I-2	Review	20397
This ought to be part of the ablation study in my opinion.	I-Review	I-2	Review	20397
<sep> <sep> Secondly, the paper discusses the issue of VAE generating unrealistic samples.	B-Review	B-4	Review	20397
This is indeed a very real issue of the VAE linked to it being trained by maximum-likelihood.	I-Review	I-4	Review	20397
However illustrating it by "blurry images" (like is done several times in the paper) is a common misconception, as while this is a very classical issue with VAEs, it is mostly unrelated to the MLE estimation.	I-Review	I-4	Review	20397
<sep> <sep> It is rather a simple consequence of the fact that using an unweighted squared error loss to model the reconstruction of the VAE is almost always a poor model.	I-Review	I-4	Review	20397
It is equivalent to modelling the observation with a Gaussian noise of variance 1/2, which is a huge noise when considering data normalized in [0;1] or [-1;1] like is traditional to do with images.	I-Review	I-4	Review	20397
Reducing this variance to a more sensible value (like a std of 0.1 for example) or allowing the model to learn it reveals the real failure mode of the VAE generating unrealistic images, which can hardly be described as "blurry".	I-Review	I-4	Review	20397
<sep> <sep> Similarly, the ablation study evaluates the use of L1 or L2 noise instead of the cyclic shift likelihood, but does not say what variance has been used for these, which would (as explained above) be an important parameter to take into account.	B-Review	B-3	Review	20397
If a variance of 1 was used, then the results of figure 2 are unsurprising and not insightful, as the discriminator would have merely learned to differentiate between images containing a visible Gaussian noise from images that do not.	I-Review	I-3	Review	20397
Dear reviewer,	O	O	Reply	20397
<sep> We would like to thank you for the thoughtful review.	O	O	Reply	20397
The main concern you raised is about the significance of two contributions: optimization of lambda-Jeffreys divergence and formulation of the implicit likelihood.	O	O	Reply	20397
We will address each of them below.	O	O	Reply	20397
<sep> <sep> About the optimization of lambda-Jeffreys divergence you wrote:	O	O	Reply	20397
&gt; The use of a weighted sum of the forward &amp; KL divergences to train a generative model is hardly new, and has already been presented a few times (Larsen et al 2015, Dosovitskiy &amp; Brox 2016).	O	O	Reply	20397
<sep> <sep> It is true that the idea of combining VAE and GAN objectives is not new.	B-Reply	B-1	Reply	20397
There are many approaches and we consider the closest works in related work.	I-Reply	I-1	Reply	20397
However, our contribution is that we do not only just propose to optimize the weighted sum of VAE and GAN losses but we provide a theoretical justification about the proposed objective and prove that under assumptions of optimal discriminators our model minimizes the lambda-Jeffreys divergence.	I-Reply	I-1	Reply	20397
To the best of our knowledge, there are no other papers about auto-encoder models which prove that it optimizes lambda-Jeffreys divergence.	I-Reply	I-1	Reply	20397
If we consider (Larsen et al 2015, Dosovitskiy &amp; Brox 2016) papers there were proposed to optimize the loss as a sum of VAE loss and GAN-like loss (in (Dosovitskiy &amp; Brox 2016) there was also feature matching loss).	I-Reply	I-1	Reply	20397
However, in these works GAN part is not equivalent to reverse KL divergence (because they do not optimize E_{p_{theta}(x)} log[D(x)/(1 - D(x))]), therefore their losses are not equivalent to lambda-Jeffreys divergence (and authors did not analyze theoretically the corresponded divergence for their objectives).	I-Reply	I-1	Reply	20397
<sep> <sep> Therefore, the main significance of this contribution consists in the theoretical justification of the proposed objective.	I-Reply	I-1	Reply	20397
<sep> <sep> About the formulation of the implicit likelihood you wrote:	I-Reply	I-1	Reply	20397
<sep> &gt; In this context the paper does not present the impact of its main contribution alone.	O	O	Reply	20397
How would behave a VAE trained solely with this implicit likelihood, but a regular Gaussian latent space and without the GAN loss?	O	O	Reply	20397
This ought to be part of the ablation study in my opinion.	O	O	Reply	20397
<sep> <sep> This experiment was a part of our ablation study.	B-Reply	B-2	Reply	20397
We are sorry if it was unclear from the text, we will better emphasize this experiment in the next revision of our paper.	I-Reply	I-2	Reply	20397
<sep> In experiments section you can find it in the Figure 3 and it corresponds to lambda=1 (light green circle).	I-Reply	I-2	Reply	20397
We see that it has good LPIPS but the worst IS compared to other values of lambda.	I-Reply	I-2	Reply	20397
For example, its IS is significantly worse than 0.3-IJAE which we report in Table 1.	I-Reply	I-2	Reply	20397
So, we can say that this implicit likelihood is beneficial when we combine it with the GAN part within lambda-Jeffreys objective.	I-Reply	I-2	Reply	20397
<sep> <sep> So, the significance of the implicit likelihood is that it allows us to successfully combine VAE and GAN parts in our objective in contrast to explicit likelihoods which give significantly worse results (see Figure 2).	I-Reply	I-2	Reply	20397
However, your second concern is about this ablation study which is illustrated in Figure 2.	I-Reply	I-2	Reply	20397
You wrote:	I-Reply	I-2	Reply	20397
<sep> &gt; the ablation study evaluates the use of L1 or L2 noise instead of the cyclic shift likelihood, but does not say what variance has been used for these, which would (as explained above) be an important parameter to take into account.	O	O	Reply	20397
If a variance of 1 was used, then the results of figure 2 are unsurprising and not insightful, as the discriminator would have merely learned to differentiate between images containing a visible Gaussian noise from images that do not.	O	O	Reply	20397
<sep> <sep> We are sorry that we did not write many details about this experiment, further we will add them in supplementary materials.	B-Reply	B-3	Reply	20397
For this experiment we considered 2 settings for learning VAE with Gaussian or Laplace conditional likelihood: 1) with constant variance; 2) with learnable variances for each pixel of the image.	I-Reply	I-3	Reply	20397
We observe that 2nd setting with learnable variances is unstable for lambda &lt; 1 and gives significantly worse results than 1st setting.	I-Reply	I-3	Reply	20397
The possible explanation is that learnable variances reweight the reconstruction loss dynamically during the training process and combined with additional weighting parameter lambda it can lead to instabilities in learning.	I-Reply	I-3	Reply	20397
Therefore, in Figure 2 we present results for 1 setting with constant variance.	I-Reply	I-3	Reply	20397
The exact value of variance used in likelihood also depends on the lambda parameter.	I-Reply	I-3	Reply	20397
Lambda in our experiments ranges from 0.1 to 1 with step 0.1, therefore, variance value ranges from 0.05 to 0.5 with step 0.05.	I-Reply	I-3	Reply	20397
<sep> <sep> So, we can say that our ablation study is fair and it can support the significance of the proposed implicit likelihood.	I-Reply	I-3	Reply	20397
<sep> <sep> You also claim that blurry images of VAE ‚Äúis mostly unrelated to the MLE estimation‚Äù.	I-Reply	I-3	Reply	20397
We want to clarify that we mention blurry images is only as one example of VAE unrealistic samples.	I-Reply	I-3	Reply	20397
Our main claim is that MLE estimation can lead to mass-covering behaviour when the model may generate from low probability regions where samples can be very unrealistic.	I-Reply	I-3	Reply	20397

The paper proposes to replace the KL-divergence in VAE training with the lambda-jeffreys divergence of which the symmetric KL-divergence is a special case.	O	O	Review	20397
The paper proposes a pure implicit likelihood approach that uses three discriminator models to estimate the KL-divergences.	O	O	Review	20397
Experiments are conducted on CIFAR-10 and TinyImageNet and several scores are reported to show that the proposed method performs as good if not better than current approaches.	O	O	Review	20397
<sep> ---------	O	O	Review	20397
I think the paper tries to achieve too much in too little space and foregoes scientific exactness for the sake of claiming SOTA.	O	O	Review	20397
Since there is a difference between claiming SOTA on a task and validating a new method, the small amount of space makes it difficult to substantiate both claims at the same time.	O	O	Review	20397
In the rest of the review i will try to substantiate the claim:	O	O	Review	20397
<sep> 1.	B-Review	B-1	Review	20397
The paper claims on page 2: "These models do not have a sound theoretical justification about what distance [...] they optimize".	I-Review	I-1	Review	20397
While the paper tries to substantiate its claims by showing theoretically that it does the right thing using the optimal discriminator, it leaves the question open what happens with any other discriminator.	I-Review	I-1	Review	20397
The theory does not justify non-optimal solutions.	I-Review	I-1	Review	20397
It is argued on page 6 that non-optimality of the discriminator serves as some form of regularization, but  this requires some justification.	I-Review	I-1	Review	20397
<sep> Moreover, the paper uses LPIPS to measure reconstruction quality - but this measure is a deep neural network.	B-Review	B-2	Review	20397
So if those measures are good enough to compare solutions with and the theoretical justification of the proposed method is shaky in practice - why not use LPIPS for training?	I-Review	I-2	Review	20397
<sep> <sep> 2.	B-Review	B-3	Review	20397
The paper proposes the discriminator in order to allow for an implicit likelihood.	I-Review	I-3	Review	20397
However, the r-function used in the experiments does not fulfill the property of a well defined likelihood, and Theorem 1 does not hold, since technically the KL-divergence is infinity.	I-Review	I-3	Review	20397
If we ignore this by adding a small amount of Gaussian noise around the sampled cyclical shifts - like the r' used in the experiments, we can easily write down the explicit likelihood function since:	B-Review	B-4	Review	20397
<sep> r(y|x)=\sum_i w_i N(y|Shift_i(x), \sigma)	I-Review	I-4	Review	20397
<sep> where Shift_i is the i-th shift in the set described in the paper and w_i its probability  p(y|q).	I-Review	I-4	Review	20397
So the explicit solution of theorem 1 can be written down and another ablation study would be training the method with the explicit formulation for this KL-term(i.e.	I-Review	I-4	Review	20397
only training two discriminator models).	I-Review	I-4	Review	20397
If the results are not equivalent, this implies that the discriminator does not reach the optimum.	I-Review	I-4	Review	20397
The implications of that should be discussed regarding 1.	I-Review	I-4	Review	20397
<sep> <sep> 3.	O	O	Review	20397
Existing ablation studies are a bit of a straw-man: the paper compares changing r(y|x) by standard Gaussian or Laplace.	B-Review	B-5	Review	20397
However, we know that a large variance does not make any sense and almost all papers use tiny variances (e.g. in beta-VAE the beta-values tend to be very small, which is equivalent to small variances here).	I-Review	I-5	Review	20397
<sep> <sep> <sep> ---------------------------	O	O	Review	20397
Smaller things	O	O	Review	20397
- Are the experimental results all with the same architecture for encoder/generator for all results you compared to?	B-Review	B-6	Review	20397
if not, the effect of that should also be tested.	I-Review	I-6	Review	20397
<sep> <sep> - my personal biased view on the generated images is: it looks worse than alpha-GAN.	B-Review	B-7	Review	20397
Every reconstructed image has a grey tone and the generated images also offer a strong grey palette.	I-Review	I-7	Review	20397
The details don't look better as well.	I-Review	I-7	Review	20397
<sep> <sep> - typo inroduce-&gt;introduce	B-Review	B-8	Review	20397
<sep> Dear reviewer,	O	O	Reply	20397
<sep> We would like to thank you for the thoughtful review.	O	O	Reply	20397
<sep> We address your concerns below.	O	O	Reply	20397
<sep> <sep> &gt; The theory does not justify non-optimal solutions.	O	O	Reply	20397
It is argued on page 6 that non-optimality of the discriminator serves as some form of regularization, but  this requires some justification.	O	O	Reply	20397
<sep> <sep> It is a fair question because in practice we do not have optimal discriminators and the theory does not justify this case.	B-Reply	B-1	Reply	20397
However, in adversarial learning it is a common practice to analyze the model under assumptions of optimal discriminators.	I-Reply	I-1	Reply	20397
The theoretical justification of the non-optimality case is an open question in GAN community and our paper is not aimed to solve this problem.	I-Reply	I-1	Reply	20397
<sep> We utilize the adversarial framework to learn density ratios by discriminators.	I-Reply	I-1	Reply	20397
When we write about the non-optimality of the discriminator as some form of regularization we follow the common assumption that non-optimal discriminator can learn smooth version of empirical density ratio.	I-Reply	I-1	Reply	20397
In practice, we always have finite training data and therefore the optimal discriminator will learn ratio of delta functions (because the empirical data distribution is a sum of delta functions centered in data points).	I-Reply	I-1	Reply	20397
So, the non-optimality of the discriminator allows us to estimate somehow the true density ratio in the case of finite data.	I-Reply	I-1	Reply	20397
<sep> <sep> &gt; why not use LPIPS for training?	O	O	Reply	20397
<sep> <sep> LPIPS metric initially was proposed as a good proxy for evaluation of visual quality of reconstructions.	B-Reply	B-2	Reply	20397
The first reason why it is not a good idea to train LPIPS directly is that it is as Inception Score (IS) based on the outputs of the deep neural network.	I-Reply	I-2	Reply	20397
For the IS it was shown [1] that if we train the generator by directly maximizing IS we will end up with large IS but very unnatural generated images.	I-Reply	I-2	Reply	20397
We can observe the same problem for the LPIPS.	I-Reply	I-2	Reply	20397
The second reason is that if we train the model using LPIPS then we will not be able to use this metric for a fair comparison with other methods.	I-Reply	I-2	Reply	20397
<sep> <sep> &gt; However, the r-function used in the experiments does not fulfill the property of a well defined likelihood, and Theorem 1 does not hold, since technically the KL-divergence is infinity.	O	O	Reply	20397
<sep> <sep> It is true that r-function is not a well defined likelihood.	B-Reply	B-3	Reply	20397
However, as we said before in the usual adversarial framework the data distribution is also not well defined density in practice.	I-Reply	I-3	Reply	20397
It does not prevent us from learning the smooth version of the density ratio by the non-optimal discriminator (which is always the case).	I-Reply	I-3	Reply	20397
<sep> <sep> &gt; If we ignore this by adding a small amount of Gaussian noise around the sampled cyclical shifts - like the r' used in the experiments, we can easily write down the explicit likelihood function‚Ä¶ So the explicit solution of theorem 1 can be written down and another ablation study would be training the method with the explicit formulation for this KL-term(i.e.	O	O	Reply	20397
only training two discriminator models).	O	O	Reply	20397
<sep> <sep> It is a good suggestion and we will add the comparison with this explicit likelihood in the next revision of our paper.	B-Reply	B-4	Reply	20397
However, this explicit r-function does not differ in principle from the standard Gaussian distribution and we are likely to obtain the same results.	I-Reply	I-4	Reply	20397
It is another argument why we utilize the non-optimal discriminator instead of the explicit distribution.	I-Reply	I-4	Reply	20397
It is similar to the standard adversarial framework that we use the discriminator to train the generator instead of the explicit distribution of the dataset which can be written down as a mixture of Gaussian distributions centered in data points and with small fixed variance.	I-Reply	I-4	Reply	20397
<sep> <sep> Good point.	I-Reply	I-4	Reply	20397
However, when we train the discriminator using r-distribution we do not expect that it will perfectly fit the density ratio of r(y|x) and r‚Äô(y|x) as in the standard GAN setting we do not expect the discriminator to exactly recover the empirical data distribution.	I-Reply	I-4	Reply	20397
The non-optimality of the discriminator can be thought of as a form of regularization and it allows us to learn the implicit likelihood of reconstructions defined by the non-optimal discriminator itself.	I-Reply	I-4	Reply	20397
We will add the comparison with the explicit likelihood you mention in the next revision of our paper to illustrate the benefits of using non-optimal discriminator.	I-Reply	I-4	Reply	20397

Authors propose to overcome the sparse reward problem using an exploration strategy that incentivizes the agent to visit different parts of the game screen.	O	O	Review	1626
This is done by building Q-maps, a 3D tensor that measures the value of the agent's current state (defined as the position of the agent) and action in reaching other (x, y) locations in the map.	O	O	Review	1626
Each 2D slice of the Q-map measures the value at different (x, y) locations for one action.	O	O	Review	1626
Such 2D slices (i.e. channels) are stacked together to form the Q-map.	O	O	Review	1626
Taking the max across the channels, thus, provides the Q-value for the optimal action.	O	O	Review	1626
<sep> <sep> A policy for maximizing the rewards is trained using DQN.	O	O	Review	1626
The Q-map based exploration is used as a replacement for \epsilon-greedy exploration.	O	O	Review	1626
<sep> <sep> The Q-map is used for exploration in the following way:	O	O	Review	1626
(a) Chose a random action with probability \epsilon_r.	O	O	Review	1626
<sep> (b) If neither a random action nor a "goal" is chosen, a new goal is chosen with probability \epislon_g.	O	O	Review	1626
The goal is a (x, y) location, chosen so that is not too hard or too easy to reach it (i.e. Q-map values are neither too high or low; intuitively [1 - Q-map(x, y, a)] (for normalized/clipped Q) is a measure of distance of the goal).	O	O	Review	1626
-- If a "goal" is chosen, the greedy action to go towards the goal is chosen.	O	O	Review	1626
<sep> (c) If neither a goal or random action is chosen, DQN is used to chose the greedy exploration.	O	O	Review	1626
<sep> <sep> Authors also bias the goal selection to match DQN's greedy action.	O	O	Review	1626
This is done as following -- from a set of goals that satisfy (b) above; chose the goal for which Q-map selected action matches the DQN's greedy action.	O	O	Review	1626
<sep> <sep> Results are presented on simple 2D maze environments, Mario and Montezuma's revenge.	O	O	Review	1626
<sep> <sep> I have multiple concerns with the papers:	O	O	Review	1626
(i) The writing is informal and the ideas are not well explained.	B-Review	B-1	Review	1626
It would really benefit -- if authors introduce an algorithm box or talk about the method as a sequence of points.	I-Review	I-1	Review	1626
Right now, the ideas are scattered throughout the paper.	I-Review	I-1	Review	1626
I am still confused by figure 3 -- when are random goals chosen?	I-Review	I-1	Review	1626
Do random goals correspond to (b) above?	I-Review	I-1	Review	1626
Also, when the Horde architecture, GVF and UVF are mentioned, the references are missing -- I would love for the authors to include the corresponding  references.	I-Review	I-1	Review	1626
<sep> (ii) The idea of reaching as many states as possible has been explored in count based visitation (Bellemare et al, Tang et al) ‚Äî but no comparisons have been made to any previous work.	B-Review	B-2	Review	1626
Its always good to put a new work in the perspective of old work with similar ideas.	I-Review	I-2	Review	1626
<sep> <sep> (iii) The authors propose biased and random goal sampling ‚Äî I would love to see how much improvement does biased goal sampling offer over random goal sampling.	B-Review	B-3	Review	1626
<sep> <sep> (iv) ‚Äú‚Ä¶compare the performance of our proposed agent and a baseline DQN with a similar proportion of exploratory actions‚Äù .. I don‚Äôt agree with this a metric ‚Äî I think the total number of steps is a good metric.	B-Review	B-4	Review	1626
Exploration is part of the agent‚Äôs algorithm to find the goal, we shouldn‚Äôt compare against DQN by matching the number of exploratory actions.	I-Review	I-4	Review	1626
<sep> <sep> (v) ‚ÄúThe Q-map is trained with transitions generated by randomly starting from any free locations in the environment and taking a random action.	B-Review	B-5	Review	1626
‚Äù Does this mean that when the agent is trained with Mario ‚Äî the game is reset after every episode and the agent is placed a random starting location?	I-Review	I-5	Review	1626
If yes, then this is not a realistic assumption.	I-Review	I-5	Review	1626
<sep> <sep> (vi) I would like to see ‚Äî how do Q-maps generalize across levels of Mario or Montezuma‚Äôs revenge?	B-Review	B-6	Review	1626
Does Q-map trained on level-1 help in good exploration on future levels without any further fine-tuning?	I-Review	I-6	Review	1626
<sep> <sep> Overall, I like the idea of incentivizing exploration without changing the reward function as is done in multiple prior works.	O	O	Review	1626
However, I think more thorough quantitative evaluation is required and it will be interesting to see transfer of Q-maps outside the 2D-domains.	B-Review	B-6	Review	1626
I am happy to increase my score if such evidence is provided.	O	O	Review	1626
<sep> <sep> Other references worth including:	B-Review	B-7	Review	1626
(a) Strategies for goal generation: Automatic Goal Generation for Reinforcement Learning Agents (<a href="https://arxiv.org/abs/1705.06366)" target="_blank" rel="nofollow">https://arxiv.org/abs/1705.06366)</a>	I-Review	I-7	Review	1626
First, we would like to clarify that this paper makes two main contributions: 1) Q-map: a way to simultaneously learn to reach coordinates and 2) DQN + Q-map: a way to use Q-map for exploration.	B-Reply	B-8	Reply	1626
Unfortunately the review‚Äôs points did not address 1).	I-Reply	I-8	Reply	1626
<sep> <sep> (ii) We do reference these works in section 3.1, however, as most of them still use epsilon-greedy as part of their algorithms, our proposed method can be directly integrated with them.	B-Reply	B-2	Reply	1626
To isolate the impact of taking multiple steps in the direction of a goal versus random actions, we chose to only use a standard DQN agent.	I-Reply	I-2	Reply	1626
<sep> <sep> (iii) We unfortunately do not have results with the exact same experimental setup without goal biasing but during preliminary experiments we found that a goal biasing of 50% gave a performance boost on Mario.	B-Reply	B-3	Reply	1626
The experiment with Montezuma's Revenge does not use any biasing however as no reward was used and thus no DQN was trained.	I-Reply	I-3	Reply	1626
<sep> <sep> (iv) By exploratory actions we mean individual actions that are not greedy for the task (completely random or goal-directed).	B-Reply	B-4	Reply	1626
To have a fair comparison between epsilon-greedy exploration and the proposed exploration using Q-map, we ensure that these exploratory actions are following the same schedule, linearly decaying through the training.	I-Reply	I-4	Reply	1626
<sep> <sep> (v) The quoted training method was specifically used for the gridworld environment that was designed to evaluate the training of the Q-map under ideal conditions with a nearly uniform coverage of all transitions.	B-Reply	B-5	Reply	1626
For the experiments with Mario and Montezuma's Revenge the goal was to evaluate the proposed exploration algorithm, we therefore used the original starting states at the beginning of the levels.	I-Reply	I-5	Reply	1626
<sep> <sep> (vi) We added a new experiment using a Q-map trained first on level 1.1 and then on level 2.1.	B-Reply	B-6	Reply	1626
We noticed faster training and some notions of generalization even though the two levels use different tilesets and backgrounds.	I-Reply	I-6	Reply	1626
The videos and code are available on the website.	I-Reply	I-6	Reply	1626

The main idea in the paper is to use on-screen locations as goals for an RL agent.	O	O	Review	1626
Using a de-convolutional network to parameterize the Q-function allows all goals to be updated at once and correlations between nearby or similar goal locations could be modelled.	O	O	Review	1626
The paper explores how this type of goal space can be used for better exploration showing modest improvement in scores on Super Mario.	O	O	Review	1626
<sep> <sep> Clarity - The paper is well written and easy to follow.	O	O	Review	1626
The Q-map architecture is well motivated and intuitive and the exploration strategy based on Q-maps is interesting.	O	O	Review	1626
<sep> <sep> Novelty - The idea of using spatial goals combined with a de-convolutional architecture is not new and goes back at least to ‚ÄúReinforcement Learning with Unsupervised Auxiliary Tasks‚Äù by Jaderberg et al.	B-Review	B-1	Review	1626
The UNREAL agent used the same type of de-convolutional ‚ÄúQ-map‚Äù to update a spatial grid of goals all at once.	I-Review	I-1	Review	1626
The main difference is that the UNREAL agent learns about spatial goals as an auxiliary task and does not execute/act on the goals like the Q-map agent.	I-Review	I-1	Review	1626
Nevertheless, the type of architecture and algorithm (called 3D Q-learning in this paper) is essentially the same.	I-Review	I-1	Review	1626
<sep> <sep> Significance - The Q-map architecture requires access to the position of the avatar on the screen at training time.	B-Review	B-2	Review	1626
I would expect that using such a significant part of the agent‚Äôs true state during training should lead to a significant improvement in performance at test time.	I-Review	I-2	Review	1626
Why not evaluate the proposed exploration strategy on well known hard exploration tasks?	I-Review	I-2	Review	1626
The results on Montezuma‚Äôs Revenge are only qualitative.	I-Review	I-2	Review	1626
There Q-map agent did outperform an epsilon-greedy DQN baseline on Super Mario but the improvement does not seem very significant given how much prior knowledge Q-map was given compared to the baseline.	I-Review	I-2	Review	1626
It is also not clear how much of the improvement comes from training the Q-map as an auxiliary task and how much of it comes from better exploration.	I-Review	I-2	Review	1626
<sep> <sep> Overall quality - Given that the architecture is not very novel and requires the avatar‚Äôs position to train I did not find the qualitative or quantitative results compelling enough.	B-Review	B-3	Review	1626
Perhaps the authors could show that the exploration strategy works well on several difficult exploration games.	I-Review	I-3	Review	1626
Another possibility would be to showcase other ways to use the Q-map, for example in an HRL setup.	I-Review	I-3	Review	1626
<sep> <sep> Minor comment - Some sections seem to be missing references.	B-Review	B-4	Review	1626
For example, the second paragraph of the introduction discusses GVFs and the Horde architecture without any references.	I-Review	I-4	Review	1626
We agree with some of the pointed similarities with UNREAL, and now reference it in the paper.	B-Reply	B-1	Reply	1626
The autoencoder architecture and Q-learning used for its pixel-control auxiliary task are indeed similar.	I-Reply	I-1	Reply	1626
However, the meaning of the review's use of the term "spatial goals" is not very clear to us, as the pixel-control auxiliary task's purpose is to maximize the on-screen pixel value change, and has no notion of goal-oriented RL.	I-Reply	I-1	Reply	1626
Furthermore, the learned values are not used in any practical manner.	I-Reply	I-1	Reply	1626
Q-map on the other hand, is trained to minimize the number of steps towards all goal coordinates which can be used for a variety of applications, such as exploration as shown in the paper, goal-oriented control (e.g. if the task is to reach some coordinates), or hierarchical RL.	I-Reply	I-1	Reply	1626
<sep> <sep> While we agree that the necessity to localize the agent or a target object in the environment is significant, we would like to point out that it is a common assumption in goal-oriented RL, and is not impractical for certain areas of research, such as robotics.	B-Reply	B-2	Reply	1626
We chose to use Montezuma‚Äôs Revenge and Mario for their complexity and their role in various previous papers on exploration.	I-Reply	I-2	Reply	1626
We do not believe it was worthwhile showing performance chart for Montezuma‚Äôs Revenge, as the baseline random exploration never reached the key and we did not use environmental rewards.	I-Reply	I-2	Reply	1626

Focus on navigation problems, this paper proposes Q-map, a neural network that estimates the number of steps (in terms of the discount factor gamma) required to reach any position on the observable screen/window.	O	O	Review	1626
Moreover, it is shown that Q-map can be applied for exploration, by trying to reach randomly selected goal.	O	O	Review	1626
<sep> <sep> Pros	O	O	Review	1626
1.	O	O	Review	1626
Novel goal-based exploration scheme	O	O	Review	1626
<sep> Cons	O	O	Review	1626
1.	O	O	Review	1626
Similar idea has been proposed before	B-Review	B-1	Review	1626
For example, Dayan (1993) estimates the number of steps to reach any position on the map using successor representations.	I-Review	I-1	Review	1626
Discussion about this field (successor representations/features) is completely missing in the paper.	I-Review	I-1	Review	1626
<sep> Ref:	O	O	Review	1626
- Peter Dayan.	O	O	Review	1626
Improving generalization for temporal difference learning: The successor representation.	O	O	Review	1626
Neural Computation, 5(4):613‚Äì624, 1993.	O	O	Review	1626
<sep> - Andre Barreto, Will Dabney, Remi Munos, Jonathan J Hunt, Tom Schaul, David Silver, and Hado van Hasselt.	O	O	Review	1626
Successor features for transfer in reinforcement learning.	O	O	Review	1626
In Advances in Neural Information Processing Systems, pp.4058‚Äì4068, 2017.	O	O	Review	1626
<sep> - Andre Barreto, Diana Borsa, John Quan, Tom Schaul, David Silver, Matteo Hessel, Daniel Mankowitz, Augustin Zidek, and Remi Munos.	O	O	Review	1626
Transfer in deep reinforcement learning using successor features and generalised policy improvement.	O	O	Review	1626
In International Conference on Machine Learning, pp.510‚Äì519, 2018.	O	O	Review	1626
<sep> <sep> 2.	O	O	Review	1626
Comparison to existing methods is only vaguely discussed	B-Review	B-2	Review	1626
For example, it is claimed multiple times that UVFA requires the goal coordinates, but Q-map also requires coordinates when doing the exploration.	I-Review	I-2	Review	1626
<sep> <sep> 3.	O	O	Review	1626
The network architecture is not clearly presented	B-Review	B-3	Review	1626
For example, the output of the network needs to be clipped, which suggests that there is no output transform.	I-Review	I-3	Review	1626
Since the predicted output is in [0,1], it would make sense to use Sigmoid transform for each pixel and use logistic loss.	I-Review	I-3	Review	1626
<sep> <sep> 4.	O	O	Review	1626
The proposed exploration scheme could be unnecessarily complicated	B-Review	B-4	Review	1626
Sec.3.1 provides lengthy discussion about the drawback of eps-greedy exploration.	I-Review	I-4	Review	1626
Then in Sec.3.2, \epsilon_r is basically the same as the eps-greedy algorithm, using to randomly select an action.	I-Review	I-4	Review	1626
Isn't this a "bad" thing as suggested in Sec.3.1?	I-Review	I-4	Review	1626
Moreover, the new exploration scheme requires two more hyper-parameters (min/max distance threshold), which will add more complication to the already very complicated deep RL learning procedure.	I-Review	I-4	Review	1626
<sep> <sep> 5.	O	O	Review	1626
Experiment results are limited	B-Review	B-5	Review	1626
For the toy experiment in Sec.2.3, the map are relatively simple.	I-Review	I-5	Review	1626
The example of Dayan (1993) with an agent surrounded by walls is an interesting scenario and should be included.	I-Review	I-5	Review	1626
The proposed Q-map (ConvNet) could fail because it is hard to learn geodesic distance with only local information.	I-Review	I-5	Review	1626
More importantly, there is no comparison to similar methods in Sec.3.	I-Review	I-5	Review	1626
UVFA can replace Q-map to do similar exploration.	I-Review	I-5	Review	1626
<sep> <sep> 6.	O	O	Review	1626
Writing can be greatly improved	B-Review	B-6	Review	1626
There are many grammar errors.	I-Review	I-6	Review	1626
To name a few, "agent capable to produce", "the gridworld consist of", "in the thrist level".	I-Review	I-6	Review	1626
<sep> <sep> Minors	B-Review	B-7	Review	1626
- UFV should be UVF in the introduction	I-Review	I-7	Review	1626
- Citation in Sec.3 is not consistent with the rest of the paper.	I-Review	I-7	Review	1626
Use \citep or \citet properly.	I-Review	I-7	Review	1626
1.	O	O	Reply	1626
Successor features, a generalization of Dayan‚Äôs successor representation, propose a framework for transfer learning when the reward function changes between tasks but not the environment‚Äôs dynamics.	B-Reply	B-1	Reply	1626
In Dyan (1993), the experiment shows how the successor representations predict the future state occupancy under the current policy when trained to reach a particular goal and describes how the learning is affected when the goal location is changed.	I-Reply	I-1	Reply	1626
We believe this literature is quite different from Q-map which directly and simultaneously learn how to reach every possible goals and is task-independent.	I-Reply	I-1	Reply	1626
<sep> <sep> 2.	B-Reply	B-2	Reply	1626
While UVFA requires a goal to be provided in input of the neural network, Q-map doesn't as it produces the Q-values towards all possible goals at once in output.	I-Reply	I-2	Reply	1626
This implies a few algorithmic differences between the two approaches when used for the proposed exploration: 1) During the goal-selection step or training, the values for all goals are queried or updated in one pass through the network while would require as many passes as there are goals with UVFA.	I-Reply	I-2	Reply	1626
2) When trying to reach a given goal, the Q-values at the proper location in output are used for Q-map while this goal would just be provided in input for UVFA.	I-Reply	I-2	Reply	1626
<sep> <sep> 3.	O	O	Reply	1626
We have tested regression with various non-linearities in output but have found them to perform worse.	B-Reply	B-3	Reply	1626
For example, sigmoids tend to squeeze values to either 0 (the goal can't be reached) or 1 (the goal can be reached in one step).	I-Reply	I-3	Reply	1626
Furthermore, clipping is only performed when creating the target Q-frames as always clipping the output of the network would not give any gradient for values outside of (0, 1).	I-Reply	I-3	Reply	1626
<sep> <sep> 4.	O	O	Reply	1626
We have retained a minimal amount of purely random actions for several reasons: 1) They are necessary for Q-map's own exploration 2) They allow DQN to discover actions which may not be helpful for navigating the environment, such as hitting blocks to gain coins in Mario 3) The proportion of random actions used is significantly smaller than what is used in the baseline, thus the drawbacks, such as ‚Äúwasteful‚Äù actions, are reduced.	B-Reply	B-4	Reply	1626
<sep> <sep> 5.	O	O	Reply	1626
We agree that such environments would have been an interesting test for the Q-map.	B-Reply	B-5	Reply	1626
Given the time available for the rebuttal we will have to consider these for future work.	I-Reply	I-5	Reply	1626
Yes, UVFA could be used instead of Q-map, but it would likely be computationally slower as every possible goal would need to be passed in input and have worse learning performance due to the lack of deconvolutional architecture to facilitate generalization.	I-Reply	I-5	Reply	1626
Such a comparison could also be worthwhile for future work.	I-Reply	I-5	Reply	1626

This paper addresses one of the major shortcomings of generative adversarial networks - their lack of mechanism for evaluating held-out data.	O	O	Review	237
While other work such as BiGANs/ALI address this by learning a separate inference network, here the authors propose to change the GAN objective function such that the optimal discriminator is also an energy function, rather than becoming uninformative at the optimal solution.	O	O	Review	237
Training this new objective requires gradients of the entropy of the generated data, which are difficult to approximate, and the authors propose two methods to do so, one based on nearest neighbors and one based on a variational lower bound.	O	O	Review	237
The results presented show that on toy data the learned discriminator/energy function closely approximates the log probability of the data, and on more complex data the discriminator give a good measure of quality for held out data.	O	O	Review	237
<sep> <sep> I would say the largest shortcomings of the paper are practical issues around the scalability of the nearest neighbors approximation and accuracy of the variational approximation, which the authors acknowledge.	B-Review	B-3	Review	237
Also, since entropy estimation and density estimation are such closely linked problems, I wonder if any practical method for EGANs will end up being equivalent to some form of approximate density estimation, exactly the problem GANs were designed to circumvent.	I-Review	I-3	Review	237
Nonetheless, the elegant mathematical exposition alone makes the paper a worthwhile contribution to the literature.	I-Review	I-3	Review	237
<sep> <sep> Also, some quibbles about the writing - it seems that something is missing in the sentence at the top of pg.5 "Finally, let's whose discriminative power".	B-Review	B-4	Review	237
I'm not sure what the authors mean to say here.	I-Review	I-4	Review	237
And the title undersells the paper - it makes it sound like they are making a small improvement to training an existing model rather than deriving an alternative training framework.	I-Review	I-4	Review	237
Thank you very much for the comments.	O	O	Reply	237
<sep> <sep> Firstly, we are really sorry about the writing problem at the top of page 5.	B-Reply	B-4	Reply	237
Due to some careless editing after submission, a paragraph that was originally in the paper was erratically deleted.	I-Reply	I-4	Reply	237
We have recovered that part and it should read clearly now.	I-Reply	I-4	Reply	237
<sep> <sep> We agree that a scalable entropy estimation method is the core to the proposed formulation.	B-Reply	B-3	Reply	237
Also, it is true the entropy estimation problem is closely related to density estimation, especially for the exponential families.	I-Reply	I-3	Reply	237
However, for the proposed formulation, what we really need is the estimation of entropy ‚Äúgradient‚Äù, which can be practically easier.	I-Reply	I-3	Reply	237
As shown by Equation (9) of the updated paper, it amounts to estimating the score function: d log p_gen(x) / d x. In this work, the nearest neighbors approximation is an example of thinking in this direction.	I-Reply	I-3	Reply	237
<sep> <sep> Another direction of thinking is that since we only need a proper gradient, is it possible to build another network to provide the gradient estimation.	B-Reply	B-3	Reply	237
Actually, this extra network can provide the gradient estimation by backward propagation, or even by forward propagation [1]. For now, the variational inference is an example of using the backward propagation to provide a gradient estimation.	I-Reply	I-3	Reply	237
More interestingly, as GANs were initially designed to bypass an explicit density estimation, it is conceptually tempting to think about using an adversarial process to get an implicit entropy estimation.	I-Reply	I-3	Reply	237
<sep> <sep> We believe all these ideas are worth exploring as future work.	B-Reply	B-3	Reply	237
<sep> <sep> In addition to these technical possibilities, another ‚Äúadvantage‚Äù here is that in theory, we can have infinite samples from the generator to estimate the entropy (gradient), which is usually impossible for normal density estimation based on empirical data.	B-Reply	B-3	Reply	237
<sep> <sep> [1] Jaderberg, Max, et al "Decoupled neural interfaces using synthetic gradients."	O	O	Reply	237
arXiv preprint arXiv:1608.05343 (2016).	O	O	Reply	237

The authors present a method for changing the objective of generative adversarial networks such that the discriminator accurately recovers density information about the underlying data distribution.	O	O	Review	237
In the course of deriving the changed objective they prove that stability of the discriminator is not guaranteed in the standard GAN setup but can be recovered via an additional entropy regularization term.	O	O	Review	237
<sep> <sep> The paper is clearly written, including the theoretical derivation.	O	O	Review	237
The derivation of the additional regularization term seems valid and is well explained.	O	O	Review	237
The experiments also empirically seem to support the claim that the proposed changed objective results in a "better" discriminator.	O	O	Review	237
There are only a few issues with the paper in its current form:	O	O	Review	237
- The presentation albeit fairly clear in the details following the initial exposition in 3.1 and the beginning of 3.2 fails to accurately convey the difference between the energy based view of training GANs and the standard GAN.	B-Review	B-1	Review	237
As a result it took me several passes through the paper to understand why the results don't hold for a standard GAN.	I-Review	I-1	Review	237
I think it would be clearer if you state the connections up-front in 3.1 (perhaps without the additional f-gan perspective) and perhaps add some additional explanation as to how c() is implemented right there or in the experiments (you may want to just add these details in the Appendix, see also comment below).	I-Review	I-1	Review	237
<sep> - The proposed procedure will by construction only result in an improved generator and unless I misunderstand something does not result in improved stability of GAN training.	B-Review	B-2	Review	237
You also don't make such a claim but an uninformed reader might get this wrong impression, especially since you mention improved performance compared to Salimans et al in the Inception score experiment.	I-Review	I-2	Review	237
It might be worth-while mentioning this early in the paper.	I-Review	I-2	Review	237
<sep> - The experiments, although well designed, mainly convey qualitative results with the exception of the table in the appendix for the toy datasets.	B-Review	B-3	Review	237
I know that evaluating GANs is in itself not an easy task but I wonder whether additional more quantitative experiments could be performed to evaluate the discriminator performance.	I-Review	I-3	Review	237
For example: one could evaluate how well the final discriminator does separate real from fake examples, how robust its classification is to injected noise (e.g. how classification accuracy changes for noised training data).	I-Review	I-3	Review	237
Further one might wonder whether the last layer features learned by a discriminator using the changed objective are better suited for use in auxiliary tasks (e.g. classifying objects into categories).	I-Review	I-3	Review	237
<sep> - Main complaint: It is completely unclear what the generator and discriminators look like for the experiments.	B-Review	B-4	Review	237
You mention that code will be available soon but I feel like a short description at least of the form of the energy used should also appear in the paper somewhere (perhaps in the appendix).	I-Review	I-4	Review	237
<sep> <sep> Thank you very much for the questions and suggestions.	O	O	Reply	237
We address your comments one by one as follows.	O	O	Reply	237
<sep> <sep> ====================================================================================	O	O	Reply	237
[Comment 1]: The presentation albeit fairly clear in the details following the initial exposition in 3.1 and the beginning of 3.2 fails to accurately convey the difference between the energy based view of training GANs and the standard GAN.	O	O	Reply	237
As a result it took me several passes through the paper to understand why the results don't hold for a standard GAN.	O	O	Reply	237
I think it would be clearer if you state the connections up-front in 3.1 (perhaps without the additional f-gan perspective) and perhaps add some additional explanation as to how c() is implemented right there or in the experiments (you may want to just add these details in the Appendix, see also comment below).	O	O	Reply	237
<sep> <sep> [Response]:	O	O	Reply	237
Thanks for pointing out this potentially confusing point.	B-Reply	B-1	Reply	237
In order to make it clearer, we have included some additional text following Equation (1) to describe the energy based view of adversarial training along with the intuitive interpretation of Equation (1).	I-Reply	I-1	Reply	237
Also, we have included architecture details in the appendix B.1.	I-Reply	I-1	Reply	237
We believe, however, stating that so early in the text that adding the calibrating term to GAN will not work will diverge the attention of readers, and add some unnecessary burden.	I-Reply	I-1	Reply	237
<sep> <sep> ====================================================================================	O	O	Reply	237
[Comment 2]: The proposed procedure will by construction only result in an improved generator and unless I misunderstand something does not result in improved stability of GAN training.	O	O	Reply	237
You also don't make such a claim but an uninformed reader might get this wrong impression, especially since you mention improved performance compared to Salimans et al in the Inception score experiment.	O	O	Reply	237
It might be worth-while mentioning this early in the paper.	O	O	Reply	237
<sep> <sep> [Response]:	O	O	Reply	237
- Firstly, we guess the first sentence in the comment actually reads ‚ÄúThe proposed procedure will by construction only result in an improved ‚Äòdiscriminator‚Äô‚Äù instead of ‚Äògenerator‚Äô.	B-Reply	B-2	Reply	237
Theoretically, under the non-parametric setting, both the original GAN and our proposed formulation guarantee that the generator distribution matches the data distribution, i.e., p_gen(x) = p_data(x).	I-Reply	I-2	Reply	237
Therefore, when training reaches the optimal, the generator obtained from the proposed formulation will be indistinguishable to that of the original GAN.	I-Reply	I-2	Reply	237
<sep> - However, when it comes to the question whether the proposed formulation will improve the training stability or not, we do not have theoretical analysis nor empirical results for verifying it currently.	B-Reply	B-2	Reply	237
But the fact that our model achieves better Inception score may suggest that there exist some additional advantages of the energy based training for GAN.	I-Reply	I-2	Reply	237
To faithfully verify or falsify this statement, much more work (both theoretical and empirical) will be needed.	I-Reply	I-2	Reply	237
Since it is not the focus of this work, we hope to leave it for future work.	I-Reply	I-2	Reply	237
Meanwhile, we will carefully add this discussion into the text, and make sure readers have a precise understanding of the content of our work.	I-Reply	I-2	Reply	237
Thanks for pointing this out.	I-Reply	I-2	Reply	237
<sep> <sep> ====================================================================================	O	O	Reply	237
[Comment 3]: The experiments, although well designed, mainly convey qualitative results with the exception of the table in the appendix for the toy datasets.	O	O	Reply	237
I know that evaluating GANs is in itself not an easy task but I wonder whether additional more quantitative experiments could be performed to evaluate the discriminator performance.	O	O	Reply	237
For example: one could evaluate how well the final discriminator does separate real from fake examples, how robust its classification is to injected noise (e.g. how classification accuracy changes for noised training data).	O	O	Reply	237
Further one might wonder whether the last layer features learned by a discriminator using the changed objective are better suited for use in auxiliary tasks (e.g. classifying objects into categories).	O	O	Reply	237
<sep> <sep> [Response]:	O	O	Reply	237
- For quantitative evaluation of the discriminator, we ran experiments on MNIST with the procedure you suggested, i.e., using the last layer features learned by a discriminator as fixed input to train a linear classifier, in order to evaluate the generalization quality of the learned features.	B-Reply	B-3	Reply	237
We report the result in appendix B.5.	I-Reply	I-3	Reply	237
The experiment results support the fact that the discriminator from our proposed formulation maintains more information than both GAN and EGAN-Const.	I-Reply	I-3	Reply	237
<sep> - Using the final discriminator to separate real from fake examples should not be a good evaluation metric, because	B-Reply	B-3	Reply	237
(1) At the optimal ‚Äúfake‚Äù samples are essentially real as p_gen(x) = p_data(x).	I-Reply	I-3	Reply	237
So, the discriminator will fail to distinguish the generator output (‚Äúfake‚Äù) from the real.	I-Reply	I-3	Reply	237
<sep> (2) On the other hand, being able to distinguish real and fake samples does not necessarily mean the discriminator is in a better shape.	I-Reply	I-3	Reply	237
Instead, it suggests the generator is not well trained.	I-Reply	I-3	Reply	237
<sep> - Generally speaking, the core difficulty of evaluating our discriminator lies in that an energy function is measuring the relative ‚Äúgoodness‚Äù among samples on the data manifold, rather than distinguishing whether samples are on the data manifold or not (fake vs. real).	B-Reply	B-3	Reply	237
To evaluate the relative goodness, it is most natural to think about ranking.	I-Reply	I-3	Reply	237
Unfortunately, we do not have the ground truth ranking for direct evaluation.	I-Reply	I-3	Reply	237

The submission explores several alternatives to provide the generator function in generative adversarial training with additional gradient information.	O	O	Review	237
The exposition starts by describing a general formulation about how this additional gradient information (termed K(p_gen) could be added to the generative adversarial training objective function (Equation 1).	O	O	Review	237
Next, the authors prove that the shape of the optimal discriminator does indeed depend on the added gradient information (Proposition 3.1), which is unsurprising.	O	O	Review	237
Finally, the authors propose three particular alternatives to construct K(p_gen): the negative entropy of the generator distribution, the L2 norm of the generator distribution, and a constant function (which resembles the EBGAN objective of Zhao et al, 2016).	O	O	Review	237
<sep> <sep> The exposition moves then to an experimental evaluation of the method, which sets K(p_gen) to be the approximate entropy of the generator distribution.	O	O	Review	237
At this point, my intuition is that the objective function under study is the vanilla GAN objective, plus a regularization term that encourages diversity (high entropy) in the generator distribution.	O	O	Review	237
The hope of the authors is that this regularization will transform the discriminator into an estimate of the energy landscape of the data distribution.	O	O	Review	237
<sep> <sep> The experimental evaluation proceeds by 1) showing the contour plots of the obtained generator distribution for a 2D problem, 2) studying the generation diversity in MNIST digits, and 3) showing some samples for CIFAR-10 and CelebA. The 2D problem results are convincing, since one can clearly observe that the discriminator scores translate into unnormalized values of the density function.	O	O	Review	237
The MNIST results offer good intuition also: the more prototypical digits are assigned larger scores (unnormalized densities) by the discriminator, and the less prototypical digits are assigned smaller scores.	O	O	Review	237
The sample experiments from Section 5.3 are less convincing, since no samples from baseline models are provided for comparison.	B-Review	B-1	Review	237
<sep> <sep> To this end, I would recommend the authors to clarify three aspects.	O	O	Review	237
First, we have seen that entropy regularization leads to a discriminator that estimates the energy landscape of the data distribution.	B-Review	B-2	Review	237
But, how does this regularization reshape the generator function?	I-Review	I-2	Review	237
It would be nice to see the mean MNIST digit according to the generator, and some other statistics if possible.	I-Review	I-2	Review	237
Second, how do the samples produced by the proposed methods compare (visually speaking) to the state-of-the art?	B-Review	B-3	Review	237
Third, what are the *shortcomings* of this method versus vanilla GAN?	B-Review	B-4	Review	237
Too much computational overhead?	I-Review	I-4	Review	237
What are the qualitative and quantitative differences between the two entropy estimators proposed in the manuscript?	I-Review	I-4	Review	237
<sep> <sep> Overall, a clearly written paper.	O	O	Review	237
I vote for acceptance.	O	O	Review	237
<sep> <sep> As an open question to the authors: What breakthroughs should we pursue to derive a GAN objective where the discriminator is an estimate of the data density function, after training?	B-Review	B-5	Review	237
<sep> <sep> <sep> Thank you very much for the questions and suggestions.	O	O	Reply	237
We address your comments one by one as follows.	O	O	Reply	237
<sep> <sep> ====================================================================================	O	O	Reply	237
[Comment 0]: The sample experiments from Section 5.3 are less convincing, since no samples from baseline models are provided for comparison.	O	O	Reply	237
<sep> <sep> [Response]:	O	O	Reply	237
- The primary purpose of Section 5.3 is to show that adding the calibrating term K(p_gen) does not degrade sample quality compared to existing convolutional GAN variants (see DCGAN <a href="https://arxiv.org/pdf/1511.06434v2.pdf)."	B-Reply	B-1	Reply	237
target="_blank" rel="nofollow">https://arxiv.org/pdf/1511.06434v2.pdf).</a>	I-Reply	I-1	Reply	237
- The reason we do not provide samples from baseline models is mostly a space issue.	B-Reply	B-1	Reply	237
We can add baseline samples in the appendix.	I-Reply	I-1	Reply	237
For now, a good visual reference is the improved GAN (<a href="https://arxiv.org/pdf/1606.03498v1.pdf)" target="_blank" rel="nofollow">https://arxiv.org/pdf/1606.03498v1.pdf)</a> as well as <a href="https://openai.com/blog/generative-models/" target="_blank" rel="nofollow">https://openai.com/blog/generative-models/</a> for CIFAR10 samples.	I-Reply	I-1	Reply	237
Note that the improved GAN uses many additional techniques to improve sample quality, including label information (which gives a big boost).	I-Reply	I-1	Reply	237
For celebA, the EBGAN (<a href="https://openreview.net/pdf?id=ryh9pmcee)" target="_blank" rel="nofollow">https://openreview.net/pdf?id=ryh9pmcee)</a> paper provides some samples for comparison (see Figure 6).	I-Reply	I-1	Reply	237
EBGAN also uses additional techniques to boost sample quality, including margin-based cost and a pulling-away term.	I-Reply	I-1	Reply	237
<sep> - As a proxy measure, the inception scores in Table 1 provide some supporting evidence to the statement of comparable quality.	B-Reply	B-1	Reply	237
<sep> <sep> ====================================================================================	O	O	Reply	237
[Comment 1]: First, we have seen that entropy regularization leads to a discriminator that estimates the energy landscape of the data distribution.	O	O	Reply	237
But, how does this regularization reshape the generator function?	O	O	Reply	237
It would be nice to see the mean MNIST digit according to the generator, and some other statistics if possible.	O	O	Reply	237
<sep> <sep> [Response]:	O	O	Reply	237
In theory, the optimal generator distribution p_gen(x) should match the true data distribution p_data(x) as stated by Proposition 3.1.	B-Reply	B-2	Reply	237
To verify that empirically, we can definitely provide more samples from the trained generator as well as the mean generator sample later in the appendix.	I-Reply	I-2	Reply	237
For now, from Figure 9, we can already see the generator samples (samples without the white frame) have great quality, and mix well with the real samples.	I-Reply	I-2	Reply	237
<sep> <sep> ====================================================================================	O	O	Reply	237
[Comment 2]: Second, how do the samples produced by the proposed methods compare (visually speaking) to the state-of-the-art?	O	O	Reply	237
<sep> <sep> [Response]	O	O	Reply	237
As mentioned above, we believe the sample quality of the proposed method is comparable with the state-of-the-art results, which are arguably either from GAN variants or from Pixel RNN and Pixel CNN (<a href="https://arxiv.org/pdf/1601.06759.pdf)."	B-Reply	B-3	Reply	237
target="_blank" rel="nofollow">https://arxiv.org/pdf/1601.06759.pdf).</a>	I-Reply	I-3	Reply	237
Samples from GAN variants usually have better global structure, while samples from Pixel RNN have better local details.	I-Reply	I-3	Reply	237
For state-of-the-art samples from GAN variants, please refer to the papers mentioned above.	I-Reply	I-3	Reply	237
<sep> <sep> ====================================================================================	O	O	Reply	237
[Comment 3]: Third, what are the *shortcomings* of this method versus vanilla GAN?	O	O	Reply	237
Too much computational overhead?	O	O	Reply	237
What are the qualitative and quantitative differences between the two entropy estimators proposed in the manuscript?	O	O	Reply	237
<sep> <sep> [Response]:	O	O	Reply	237
We think this is a good question worth some systematic future work.	O	O	Reply	237
For now, based on our empirical observations and some properties of the training objective, we make the following comments:	O	O	Reply	237
- Computational overhead is not a big issue.	B-Reply	B-4	Reply	237
For the KNN based approach, the heaviest computation is to compute the cross-term in the Euclidean distance, which requires a matrix-matrix multiplication of shape [BxD] x [DxB], where B is the mini-batch size and D is the feature size.	I-Reply	I-4	Reply	237
With a reasonable mini-batch size (we used 200), the computation overhead is equal to that of a fully-connected layer with a weight matrix of shape [DxB], which is quite common.	I-Reply	I-4	Reply	237
As for the VI based approach, the inference network is essentially a replica of the discriminator.	I-Reply	I-4	Reply	237
Thus, it requires strictly less than double the original computation.	I-Reply	I-4	Reply	237
<sep> - A potential issue of the proposed formulation is the quality of the approximate entropy gradient.	B-Reply	B-4	Reply	237
On the one hand, when the approximate entropy gradient (1) is not accurate, and (2) has a large magnitude, it can significantly slow down the training.	I-Reply	I-4	Reply	237
Basically, the inaccurate and large-magnitude entropy gradient will act like some chaotic noise, which dominates the discriminator gradient with its large magnitude, pushes the generator to wander around purposelessly, and thus makes the training very slow.	I-Reply	I-4	Reply	237
On the other hand, when the estimated entropy gradient is accurate, it can actually speed up the training by encouraging the generator to ‚Äúexplore‚Äù regions where p_gen(x) is currently low.	I-Reply	I-4	Reply	237
Thus, how to obtain a good entropy gradient estimate is an important topic under our formulation.	I-Reply	I-4	Reply	237
<sep> <sep> ====================================================================================	O	O	Reply	237
[Open question]: What breakthroughs should we pursue to derive a GAN objective where the discriminator is an estimate of the data density function, after training?	O	O	Reply	237
<sep> <sep> [Response]:	O	O	Reply	237
Generally speaking, in order to obtain a normalized density estimation, either the training procedure and the parameterization automatically guarantee a normalized result, or some proper post-normalization will be needed.	B-Reply	B-5	Reply	237
Actually, our current proposed formulation may potentially fall into the second case (see below).	I-Reply	I-5	Reply	237
<sep> <sep> For the first case, the question effectively becomes whether one can derive a GAN-type formulation where the discriminator is self-normalized at the optimum.	I-Reply	I-5	Reply	237
Intuitively, this self-normalization requirement sounds like posing an additional regularization on the discriminator.	I-Reply	I-5	Reply	237
However, it‚Äôs difficult to specify the form of the regularization, and it can be a set constraint on the allowed parameterization of the discriminator or some additional term in the training objective.	I-Reply	I-5	Reply	237
Either way, the high-level idea is to absorb the explicit normalization step into either the parameterization or the training process.	I-Reply	I-5	Reply	237
<sep> <sep> As for the second case (post normalization), our current proposed formulation offers some directions of exploration, though there are still many challenges as we will discuss in the following.	I-Reply	I-5	Reply	237
<sep> <sep> 1.	I-Reply	I-5	Reply	237
Because we have provided a case in Equation (6) where the discriminator recovers the negative density function plus some underdetermined terms, we can consider how to eliminate the ambiguity caused by the extra underdetermined terms and thus obtain an estimate of the (negative) data density.	I-Reply	I-5	Reply	237
For this, note that the true difficulty is in the weak support discriminator term, without which we can calculate the global bias using the normalization condition sum_x p(x) = 1.	I-Reply	I-5	Reply	237
Actually, there are two situations where is zero and can be dropped.	I-Reply	I-5	Reply	237
The first one is when the data distribution has infinite support.	I-Reply	I-5	Reply	237
However, since high-dimensional data usually resides on a low-dimensional manifold, this condition may not hold.	I-Reply	I-5	Reply	237
The second situation is that we have a clear idea about the boundary of the data support and thus we can only consider the region inside the data support.	I-Reply	I-5	Reply	237
But in general, without prior knowledge, identifying the boundary of data support from empirical data is an ill-posed problem.	I-Reply	I-5	Reply	237
<sep> <sep> 2.	I-Reply	I-5	Reply	237
One may also consider whether we can properly renormalize the obtained energy function into the data density.	I-Reply	I-5	Reply	237
To do the normalization properly, we will actually encounter the same data support problem as mentioned above.	I-Reply	I-5	Reply	237
In addition to that, another challenge is that the approximate entropy gradient may have an imprecise scale.	I-Reply	I-5	Reply	237
For example, in Equation (10), we normalize the gradient into unit norm and use the hyper-parameter to control the overall scale.	I-Reply	I-5	Reply	237
Effectively, the imprecise scale is equivalent to adding a multiplicative weight to the calibrating term in Equation (1), i.e. the objective becomes max_{c} min_{p_gen} E_{p_gen} [c(x)] - E_{p_data} [c(x)] + weight * K(p_gen).	I-Reply	I-5	Reply	237
Hence, the discriminator calibrated by negative entropy should converge to c(x) = - weight * log p_data(x) + lambda + mu(x).	I-Reply	I-5	Reply	237
Basically, the weight plays the same role as the ‚Äútemperature‚Äù hyper-parameter in a Gibbs distribution.	I-Reply	I-5	Reply	237
Although the temperature does not change the relative ranking of samples in terms of energy/density, it changes the absolute value of the density.	I-Reply	I-5	Reply	237
When the temperature is smaller than 1, it will flatten the distribution.	I-Reply	I-5	Reply	237
When the temperature is larger than 1, it will make the distribution spikier.	I-Reply	I-5	Reply	237
So, the quality of the entropy gradient is again a core issue here.	I-Reply	I-5	Reply	237
<sep> <sep> Finally, since the question is quite open and has different interpretations, if we've misinterpreted the question, we'd be glad to answer further clarifying questions.	I-Reply	I-5	Reply	237

In this paper, the authors consider solving three ML security related challenges that would primarily arise	O	O	Review	128
in the cloud based ML model.	O	O	Review	128
Namely, they consider the setting where a client wishes to obtain predictions	O	O	Review	128
from an ML model hosted on a server, while being sure that the server is running the model they believe is being run	O	O	Review	128
and without the server learning nothing about their input.	O	O	Review	128
Additionally, the server wishes for the user to learn	O	O	Review	128
nothing about the model other than its output on the user's input.	O	O	Review	128
To solve this problem, the authors introduce a	O	O	Review	128
new scheme for running ML algorithms in a trusted execution environment.	O	O	Review	128
The key idea is to oursource expensive	O	O	Review	128
computation involved with forwarding images through a model to an untrusted GPU in a way that still allows for	O	O	Review	128
the TEE to verify the integrity of the GPU's output.	O	O	Review	128
Because the authors' method is able to utilize GPU computing,	O	O	Review	128
they achieve substantial speed-ups compared to methods that run the full neural network in trusted hardware.	O	O	Review	128
<sep> <sep> Overall, I found the paper to be very well written and easy to digest, and the basic idea to be simple.	O	O	Review	128
The	O	O	Review	128
authors strike a nice balance between details left to the appendix and the high level overview explained in	O	O	Review	128
the paper.	O	O	Review	128
At the same time, the authors' proposed solution seems to achieve reasonably practicable performance	O	O	Review	128
and provides a simple high-throughput solution to some interesting ML security problems that seems readily	O	O	Review	128
applicable in the ML-as-a-cloud-service use case.	O	O	Review	128
I only have a few comments and feedback.	O	O	Review	128
<sep> <sep> I would recommend the authors use the full 10 pages available by moving key results from the appendix to the main	B-Review	B-1	Review	128
text.	I-Review	I-1	Review	128
At present, much of the experimental evaluation performed is done in the appendix (e.g., Figures 3 through	I-Review	I-1	Review	128
5).	I-Review	I-1	Review	128
<sep> <sep> The notation PR_{s \overset{s}{\gets}\mathbb{S}^{n}}[...] is not defined anywhere as far as I can tell	B-Review	B-2	Review	128
before its first usage in Lemma 2.1.	I-Review	I-2	Review	128
Does this just denote the probability over a uniform random draw of	I-Review	I-2	Review	128
s from \mathbb{S}?	I-Review	I-2	Review	128
If so, I might recommend just dropping the subscript: A, B, and C being deterministic	I-Review	I-2	Review	128
makes the sample space unambiguous. "	I-Review	I-2	Review	128
negl(\lambda)" is also undefined.	I-Review	I-2	Review	128
<sep> <sep> In section three you claim that Slalom could be extended to other architectures like residual networks.	B-Review	B-3	Review	128
<sep> Can you give some intuition on how straightforward it would be to implement operations like concatenation	I-Review	I-3	Review	128
(required for DenseNets)?	I-Review	I-3	Review	128
I would expect these operations could be implemented in the TEE rather than	I-Review	I-3	Review	128
on the coprocessor and then verified.	I-Review	I-3	Review	128
However, the basic picture on the left of Figure 1 may then change,	I-Review	I-3	Review	128
as the output of each layer may need to be verified before concatenation?	I-Review	I-3	Review	128
I think augmenting the right	I-Review	I-3	Review	128
of Figure 1 to account for these operations may be straightforward.	I-Review	I-3	Review	128
It would be interesting to see	I-Review	I-3	Review	128
throughput results on these networks, particularly because they are known to substantially outperform	I-Review	I-3	Review	128
VGG in terms of classification performance.	I-Review	I-3	Review	128
We thank the reviewer for the positive review and insightful comments.	O	O	Reply	128
<sep> <sep> We followed the suggestion to make use of 10 pages of content (we originally found the ICLR Call for Papers to be somewhat unclear in this regard).	B-Reply	B-1	Reply	128
We have moved parts of the Appendix into the main body, i.e., the SGX microbenchmarks as well as our discussion of challenges with extending Slalom to DNN training.	I-Reply	I-1	Reply	128
<sep> <sep> We agree that the notation PR_{s \overset{s}{\gets}\mathbb{S}^{n}}[...] is overly verbose and we have removed the redundant in our updated manuscript.	B-Reply	B-2	Reply	128
We have also added a definition for a negligible function.	I-Reply	I-2	Reply	128
<sep> We followed the great suggestion to apply Slalom to more complex architectures.	B-Reply	B-3	Reply	128
We have added experiments with ResNet models which make use of residual connections (handling concatenation layers would require similar changes to our framework).	I-Reply	I-3	Reply	128
Extending Slalom's integrity checks (the left part in Figure 1) is quite trivial.	I-Reply	I-3	Reply	128
The TEE simply applies Freivalds' algorithm to every linear operator and makes sure that it performs appropriate "book-keeping" of which layers' outputs correspond to which other layers' inputs.	I-Reply	I-3	Reply	128
For privacy (the right part in Figure 1), things can get a bit more complicated as the TEE and GPU have to interact for each linear layer.	I-Reply	I-3	Reply	128
For a residual layer, the TEE and GPU essentially run Slalom on both "paths" of the layer one after the other.	I-Reply	I-3	Reply	128
The TEE saves intermediate results in its memory and then merges the results.	I-Reply	I-3	Reply	128
The same would work for concatenation layers.	I-Reply	I-3	Reply	128
Our results with ResNets are on par with those obtained with VGG16 and MobileNet.	I-Reply	I-3	Reply	128
We tried different variants (18, 34, 50, 101 and 152 layers), and achieve 6.6-14.4x speedups for integrity and 4.4x-9.0x speedups with additional privacy.	I-Reply	I-3	Reply	128

The authors propose a new method of securely evaluating neural networks.	O	O	Review	128
The approach builds upon existing Trusted Execution Environments (TEE), a combination of hardware and software that isolates sensitive computations from the untrusted software stack.	O	O	Review	128
The downside of TEE is that it is expensive and slow to run.	O	O	Review	128
This paper proposes outsourcing the linear evaluation portions of the DNN to an untrusted stack that's co-located with the TEE.	O	O	Review	128
To achieve privacy (i.e., the input isn't revealed to the untrusted evaluator), the approach adds a random number r to the input vector x, evaluates f(x+r) on the untrusted stack, then subtracts off f(r) from the output.	O	O	Review	128
This limits the approach to be applicable to only linear functions.	O	O	Review	128
To achieve integrity (verify the correctness of the output), the paper proposes testing with random input vectors (an application of Freivalds theorem, which bounds the error probability).	O	O	Review	128
The techniques for integrity and privacy works only on integer evaluations, hence the network weights and inputs need to be quantized.	O	O	Review	128
The paper tries to minimize degradation in accuracy by quantizing as finely as numerically allowable, achieving <0.5% drop in accuracy on two example DNNs.	O	O	Review	128
Overall, compared to full evaluation in a TEE, this approach is 10x faster on one DNN, and 40x to 64x faster on another network (depending on how the network is formulated).	O	O	Review	128
<sep> <sep> Disclaimer: I am a complete outsider to the field of HW security and privacy.	O	O	Review	128
The paper is very readable, so I think I understand its overall gist.	O	O	Review	128
I found the approach to be novel and the results convincing, though I may be missing important context since I'm not familiar with the subject.	O	O	Review	128
<sep> <sep> To me, the biggest missing piece is a discussion of the limitations of the approach.	B-Review	B-1	Review	128
How big of a network can be evaluated this way?	I-Review	I-1	Review	128
Is it sufficient for most common applications?	I-Review	I-1	Review	128
What are the bottlenecks to scaling this approach?	I-Review	I-1	Review	128
<sep> <sep> It's also not clear why integrity checks are required.	B-Review	B-2	Review	128
Is there a chance that the outsourcing could result in incorrect values? (	I-Review	I-2	Review	128
It's not obvious why it would.)	I-Review	I-2	Review	128
<sep> <sep> Lastly, a question about quantization.	B-Review	B-3	Review	128
You try to quantize as finely as possible (to minimize quantization errors) by multiplying by the largest power of 2 possible without causing overflow.	I-Review	I-3	Review	128
Since quantization need to be applied to both input and network weights, does this mean that you must also bound the scale of the input?	I-Review	I-3	Review	128
Or do you assume that the inputs are pre-processed to be within a known scale?	I-Review	I-3	Review	128
Is this possible for intermediate outputs (i.e., after the input has been multiplied through a few layers of the DNN)?	I-Review	I-3	Review	128
<sep> <sep> Pros:	O	O	Review	128
- Simple yet effective approach to achieve the goals laid out in the problem statement	O	O	Review	128
- Clearly written	O	O	Review	128
- Thorough experiments and benchmarks	O	O	Review	128
- Strong results	O	O	Review	128
<sep> Cons:	O	O	Review	128
- No discussion of limitations	B-Review	B-1	Review	128
- Minor questions regarding quantization and size limits	B-Review	B-3	Review	128
<sep> Disclaimer: reviewer is generally knowledgeable but not familiar with the subject area.	O	O	Review	128
We thank the reviewer for the positive review and insightful comments.	O	O	Reply	128
It is encouraging to hear that our paper was easy to read for someone outside the field of HW security and privacy.	O	O	Reply	128
<sep> We have made some changes to our manuscript to better illustrate the limitations and scalability of our approach.	B-Reply	B-1	Reply	128
We have moved our micro-benchmarks from the Appendix to the main body, as suggested by the second reviewer.	I-Reply	I-1	Reply	128
These benchmarks show that as the computation performed in a layer gets larger (e.g., more channels in a convolution), the savings incurred by Slalom increase!	I-Reply	I-1	Reply	128
<sep> In principle, Slalom scales linearly with the number of layers added to a model, so long as all the pre-computed values do not exceed SGX's memory limits.	I-Reply	I-1	Reply	128
To illustrate, we have experimented with the family of ResNet architectures, that range from 18 to 152 layers (and 44MB to 230MB of weights).	I-Reply	I-1	Reply	128
For five different models (18, 34, 50, 101 and 152 layers), Slalom provides large savings in throughput (4.4x-14.4x) and the savings tend to be larger for larger networks.	I-Reply	I-1	Reply	128
We have added these results to our manuscript and we believe they illustrate Slalom's applicability and scalability to large models.	I-Reply	I-1	Reply	128
In particular, the 152-layer ResNet model is among the deepest and most accurate models trained on ImageNet to date.	I-Reply	I-1	Reply	128
<sep> Lastly, we have also moved a section from the Appendix to the main body wherein we discuss some limitations and challenges with extending Slalom to DNN training.	I-Reply	I-1	Reply	128
The main issues here are with weights changing during training which hinders quantization, pre-computation of Freivalds' checks, as well as pre-computed blinding factors for privacy.	I-Reply	I-1	Reply	128
<sep> Regarding the usefulness of integrity checks, these are also meant as a security guarantee.	B-Reply	B-2	Reply	128
The threat model we consider here is that the server might *intentionally* compute incorrect values and send these back to the client.	I-Reply	I-2	Reply	128
The SafetyNets paper by Ghodsi et al contains a good discussion of reasons why a client may want integrity guarantees from the server.	I-Reply	I-2	Reply	128
One example is a "model-downgrade attack", where the server runs a cheaper (i.e., smaller) model than advertised, to minimize costs.	I-Reply	I-2	Reply	128
More generally, it is commonly agreed upon in the cryptographic community that privacy without integrity is an insufficient guarantee (e.g., by tampering with a client's results and observing the side effects, a server might later learn something about the client's data).	I-Reply	I-2	Reply	128
<sep> <sep> For quantization, we simply assume that inputs are standard RGB images in the range [0, 255]. We then choose the quantization scales for inputs and weights so that none of the intermediate values in the network ever grow beyond p=2^23.	B-Reply	B-3	Reply	128
The inputs of all layers after the first one are simply assumed to lie in the interval [-p/2, p/2].	I-Reply	I-3	Reply	128

<sep> Given the growing interest in building trust worthy and privacy protecting AI systems, this paper demonstrates a novel approach to achieve these important goals by allowing a trusted, but slow, computation engine to leverage a fast but untrusted computation engine.	O	O	Review	128
For the sake of protecting privacy, this is done by establishing an additive secret share such that evaluation on one part of the share is performed offline and the computation on the other part of the share is performed on the untrusted engine.	O	O	Review	128
To verify the correctness of the computation on the untrusted server, a randomized algorithm is used to sample the correctness of the results.	O	O	Review	128
Using these techniques, the authors demonstrate an order of magnitude speedup compared to running only on the trusted engine and 3-4 orders of magnitude speedup compared to software-based solutions.	O	O	Review	128
<sep> <sep> Overall this is a strong paper which presents good ideas that have influence in ML and beyond.	O	O	Review	128
I appreciate the fact that the authors are planning to make their code publicly available which makes it more reproducible.	O	O	Review	128
Below are a few comments/questions/suggestions	O	O	Review	128
<sep> 1.	O	O	Review	128
<tab>This papers, and other papers too, propose mechanisms to protect the privacy of the data while outsourcing the computation on a prediction task.	B-Review	B-1	Review	128
However, an alternative approach would be to bring the computation to the data, which means performing the prediction on the client side.	I-Review	I-1	Review	128
In what sense is it better to outsource the computation?	I-Review	I-1	Review	128
Note that outsourcing the computation requires both complexity on the server side and additional computation on the client side (encryption & decryption).	I-Review	I-1	Review	128
<sep> 2.	O	O	Review	128
<tab>You present the limitations of the trust model of SGX only in the appendix while in the paper you compare to other techniques such as Gazzelle which have a different trust model and assumption.	B-Review	B-2	Review	128
It makes sense to, at least, hint the reader on these differences.	I-Review	I-2	Review	128
<sep> 3.	O	O	Review	128
<tab>In section 2.2: ‚Äúhas to be processed with high throughput when available‚Äù is it high throughput that is required or low latency?	B-Review	B-3	Review	128
<sep> 4.	O	O	Review	128
<tab>In Section 4.3: in one of the VGG experiment you computed only the convolution layers which, as you say, are commonly used to generate features.	B-Review	B-4	Review	128
In this case, however, doesn‚Äôt it make more sense that the feature generation will take place on the client side while only the upper layers (dense layers) will be outsourced?	I-Review	I-4	Review	128
<sep> 5.	O	O	Review	128
<tab>In section 4.3 ‚ÄúPrivate Inference‚Äù : do you include in the time reported also the offline preprocessing time?	B-Review	B-5	Review	128
As far as I understand this should take the same amount of time as computing on the TEE.	I-Review	I-5	Review	128
<sep> <sep> We thank the reviewer for the extremely positive review of our paper.	O	O	Reply	128
As noted in our responses to the other reviewers, we have made some editorial changes to the paper (mainly moving some experiments from the Appendix into the main body), and we have included additional results for ResNet architectures as suggested by the second reviewer.	O	O	Reply	128
<sep> <sep> To answer your insightful questions:	O	O	Reply	128
<sep> 1.	O	O	Reply	128
This is a great question, and such a system has recently been suggested in [1] (see below), which we now reference in our writeup.	B-Reply	B-1	Reply	128
Probably the main differentiator is that in such a system, every single user requires trusted hardware (e.g., a recent Intel CPU), whereas in the cloud-outsourcing scheme which we and others have considered, only the server requires specialized hardware.	I-Reply	I-1	Reply	128
<sep> Using Slalom's techniques in a client-side execution might work, but the downside is that our algorithm assumes that the untrusted host has knowledge of the computed model.	I-Reply	I-1	Reply	128
<sep> One client-side application where Slalom might come in useful is for guaranteeing integrity in Federated Learning.	I-Reply	I-1	Reply	128
Here, each client evaluates a model on their own data, and the server may need some guarantees that those computations were performed correctly.	I-Reply	I-1	Reply	128
<sep> <sep> 2.	O	O	Reply	128
We have added a note for this, thanks.	B-Reply	B-2	Reply	128
<sep> 3.	B-Reply	B-3	Reply	128
Our evaluation primarily focuses on throughput.	I-Reply	I-3	Reply	128
Low latency is also desirable of course, but this might require using a different untrusted processor as GPUs tend to be outperformed by CPUs when operating on single-element batches.	I-Reply	I-3	Reply	128
In our experiments, we evaluate batches of images (around 16 images) on the GPU, and then verify a single image at a time in the TEE.	I-Reply	I-3	Reply	128
By replacing the GPU with a high-end CPU, we could thus also achieve low latency using Slalom.	I-Reply	I-3	Reply	128
<sep> 4.	O	O	Reply	128
VGG16 has the particularity that the feature extraction part (i.e., without the dense layers) makes up roughly 95% of the model's computation, but uses only maybe 5% of the weights (simply because VGG16's first dense layer is huge).	B-Reply	B-4	Reply	128
So outsourcing only the dense layers would unfortunately leave the client to do most of the work.	I-Reply	I-4	Reply	128
<sep> What we had in mind here was the use of VGG16's features as a building block for other models (e.g., object detection with SSD).	I-Reply	I-4	Reply	128
We performed some preliminary experiments with SSD and a VGG16 backend and found that Slalom could also achieve around 10x speed improvements for such object-detection tasks.	I-Reply	I-4	Reply	128
<sep> <sep> 5.	B-Reply	B-5	Reply	128
Indeed, as you correctly note, the pre-computation takes the same time as the baseline computation in the TEE.	I-Reply	I-5	Reply	128
The results in Section 4.3 do not include this pre-computations as we would of course not obtain any savings by doing so.	I-Reply	I-5	Reply	128
<sep> A similar approach is taken by many Cryptographic approaches to secure outsourcing (of ML tasks or other computations).	I-Reply	I-5	Reply	128
The rationale is that the pre-computation is data-independent and can be performed offline (e.g., during periods of low system use) and thus doesn't count towards the cost of the online throughput (or latency as discussed above).	I-Reply	I-5	Reply	128
<sep> <sep> [1] MLCapsule: Guarded Offline Deployment of Machine Learning as a Service, Hanzlik et al <a href="https://arxiv.org/abs/1808.00590" target="_blank" rel="nofollow">https://arxiv.org/abs/1808.00590</a>	O	O	Reply	128

The paper was very well-written, and mostly clear, making it easy to follow.	O	O	Review	523
The originality of the main method was not immediately apparent to me.	O	O	Review	523
However, the authors clearly outline the tricks they had to do to achieve good performance on multiple domain adaptation tasks: confidence thresholding, particular data augmentation, and a loss to deal with imbalanced target datasets, all of which seem like good tricks-of-the-trade for future work.	O	O	Review	523
The experimentation was extensive and convincing.	O	O	Review	523
<sep> <sep> Pros:	O	O	Review	523
* Winning entry to the VISDA 2017 visual domain adaptation challenge competition.	O	O	Review	523
<sep> * Extensive experimentation on established toy datasets (USPS<>MNIST, SVHN<>MNIST, SVHN, GTSRB) and other more real-world datasets (including the VISDA one)	O	O	Review	523
<sep> Cons:	O	O	Review	523
* Literature review on domain adaptation was lacking.	B-Review	B-1	Review	523
Recent CVPR papers on transforming samples from source to target should be referred to, one of them was by Shrivastava et al Learning from Simulated and Unsupervised Images through Adversarial Training, and another by Bousmalis et al Unsupervised Pixel-level Domain Adaptation with GANs.	I-Review	I-1	Review	523
Also you might want to mention Domain Separation Networks which uses gradient reversal (Ganin et al) and autoencoders (Ghifary et al).	I-Review	I-1	Review	523
There was no mention of MMD-based methods, on which there are a few papers.	I-Review	I-1	Review	523
The authors might want to mention non-Deep Learning methods also, or that this review relates to neural networks,	I-Review	I-1	Review	523
* On p. 4 it wasn't clear to me how the semi-supervised tasks by Tarvainen and Laine were different to domain adaptation.	B-Review	B-2	Review	523
Did you want to say that the data distributions are different?	I-Review	I-2	Review	523
How does this make the task different.	I-Review	I-2	Review	523
Having source and target come in different minibatches is purely an implementation decision.	I-Review	I-2	Review	523
<sep> * It was unclear to me what  footnote a. on p. 6 means.	B-Review	B-3	Review	523
Why would you combine results from Ganin et al and Ghifary et al ?	I-Review	I-3	Review	523
<sep> * To preserve anonymity keep acknowledgements out of blind submissions. (	B-Review	B-4	Review	523
although not a big deal with your acknowledgements)	I-Review	I-4	Review	523
Thank you for your review.	O	O	Reply	523
We hope that our revision will address your concerns.	O	O	Reply	523
<sep> <sep> * Thanks for pointing out the shortcomings of our literature review.	B-Reply	B-1	Reply	523
We have stated that we are focusing on neural networks and we have cited the works that you mentioned.	I-Reply	I-1	Reply	523
We have briefly mentioned MMD based approaches, although not in detail as we do not have an in-depth familiarity with the mathematics behind it.	I-Reply	I-1	Reply	523
We have had to condense our literature review somewhat in order to not go too far over the page limit.	I-Reply	I-1	Reply	523
<sep> <sep> * We have made the distinction between semi-supervised learning and domain adaptation more clear, as the distributions of the source and target datasets are indeed different.	B-Reply	B-2	Reply	523
As for having separate source and target mini-batches, we have clarified how this fits in and was inspired by the work of Li et al (2016).	I-Reply	I-2	Reply	523
Time permitting, we may be able to run some experiments to quantify the effect this decision has and add the results to Table 1.	I-Reply	I-2	Reply	523
<sep> <sep> * It seems that Ghifary et al reimplemented Ganin's RevGrad approach.	B-Reply	B-3	Reply	523
Neither paper had results for all the small image benchmarks that we discuss, so we took results from both papers to get a complete set.	I-Reply	I-3	Reply	523
We have clarified the footnote.	I-Reply	I-3	Reply	523
<sep> <sep> * We have suppressed the acknowledgements for now.	B-Reply	B-4	Reply	523

The paper addresses the problem of domain adaptation: Say you have a source dataset S of labeled examples and you have a target dataset T of unlabeled examples and you want to label examples from the target dataset.	O	O	Review	523
<sep> <sep> The main idea in the paper is to train two parallel networks, a 'teacher network' and a 'student network', where the student network has a loss term that takes into account labeled examples and there is an additional loss term coming from the teacher network that compares the probabilities placed by the two networks on the outputs.	O	O	Review	523
This is motivated by a similar network introduced in the context of semi-supervised learning by Tarvainen and Valpola (2017).	B-Review	B-1	Review	523
The parameters are then optimized by gradient descent where the weight of the loss-term associated with the unsupervised learning part follows a Gaussian curve (with time).	I-Review	I-1	Review	523
No clear explanation is provided for why this may be a good thing to try.	I-Review	I-1	Review	523
The authors also use other techniques like data augmentation to enhance their algorithms.	I-Review	I-1	Review	523
<sep> <sep> The experimental results in the paper are quite nice.	O	O	Review	523
They apply the methodology to various standard vision datasets with noticeable improvements/gains and in one case by including additional tricks manage to better than other methods for VISDA-2017 domain adaptation challenge.	O	O	Review	523
In the latter, the challenge is to use computer-generated labeled examples and use this information to label real photographic images.	O	O	Review	523
The present paper does substantially better than the competition for this challenge.	O	O	Review	523
Thank you for your review.	O	O	Reply	523
<sep> <sep> We have clarified our discussion of the Gaussian curve based unsupervised loss scaling that was originally proposed by Laine et al Beyond stating that the scaling function must ramp up slowly they don't discuss their choice of scaling function, so we present it as is.	B-Reply	B-1	Reply	523
That said, we would propose replacing it with confidence thresholding, especially as it is more stable that Gaussian ramp-up in more challenging scenarios.	I-Reply	I-1	Reply	523
We have explicitly clarified this in section 3.2.	I-Reply	I-1	Reply	523

This paper presents a domain adaptation algorithm based on the self-ensembling method proposed by [Tarvainen & Valpola, 2017]. The main idea is to enforce the agreement between the predictions of the teacher and the student classifiers on the target domain samples while training the student to perform well on the source domain.	O	O	Review	523
The teacher network is simply an exponential moving average of different versions of the student network over time.	O	O	Review	523
<sep> Pros:	O	O	Review	523
+ The paper is well-written and easy to read	O	O	Review	523
+ The proposed method is a natural extension of the mean teacher semi-supervised learning model by [Tarvainen & Valpola, 2017]	O	O	Review	523
+ The model achieves state-of-the-art results on a range of visual domain adaptation benchmarks (including top performance in the VisDA17 challenge)	O	O	Review	523
<sep> Cons:	O	O	Review	523
- The model is tailored to the image domain as it makes heavy use of the data augmentation.	B-Review	B-1	Review	523
That restricts its applicability quite significantly.	I-Review	I-1	Review	523
I‚Äôm also very interested to know how the proposed method works when no augmentation is employed (for fair comparison with some of the entries in Table 1).	I-Review	I-1	Review	523
<sep> - I‚Äôm not particularly fond of the engineering tricks like confidence thresholding and the class balance loss.	B-Review	B-2	Review	523
They seem to be essential for good performance and thus, in my opinion, reduce the value of the main idea.	I-Review	I-2	Review	523
<sep> - Related to the previous point, the final VisDA17 model seems to be engineered too heavily to work well on a particular dataset.	B-Review	B-3	Review	523
I‚Äôm not sure if it provides many interesting insights for the scientific community at large.	I-Review	I-3	Review	523
<sep> <sep> In my opinion, it‚Äôs a borderline paper.	O	O	Review	523
While the best reported quantitative results are quite good, it seems that achieving those requires a significant engineering effort beyond just applying the self-ensembling idea.	O	O	Review	523
<sep> <sep> Notes:	O	O	Review	523
* The paper somewhat breaks the anonymity of the authors by mentioning the ‚Äúwinning entry in the VISDA-2017‚Äù.	B-Review	B-4	Review	523
Maybe it‚Äôs not a big issue but in my opinion it‚Äôs better to remove references to the competition entry.	I-Review	I-4	Review	523
<sep> * Page 2, 2.1, line 2, typo: ‚Äústanrdard‚Äù -> ‚Äústandard‚Äù	B-Review	B-5	Review	523
<sep> Post-rebuttal revision:	O	O	Review	523
After reading the authors' response to my review, I decided to increase the score by 2 points.	O	O	Review	523
I appreciate the improvements that were made to the paper but still feel that this work a bit too engineering-heavy, and the title does not fully reflect what's going on in the full pipeline.	B-Review	B-3	Review	523
Thank you for your review	O	O	Reply	523
<sep> * We agree that our work is tailored to the image domain.	B-Reply	B-1	Reply	523
With a view to addressing your concerns, we have run further experiments to quantify the effects of each part of our approach - including data augmentation - for all of the small image benchmarks.	I-Reply	I-1	Reply	523
We have therefore removed Table 2 as the information that it presented can be more compactly shown in Table 1, alongside everything else.	I-Reply	I-1	Reply	523
We have added further discussion of the effect of our affine augmentation to section 3.3 and demonstrated its effect on both domain adaptation and plain supervised experiments.	I-Reply	I-1	Reply	523
What we currently have is the same augmentation scheme used by Lain et al and Tarvainen at al, which consists of translations (all) and horizontal flips (CIFAR/STL only).	I-Reply	I-1	Reply	523
Experiments with minimal augmentation (gaussian noise added to the input only, therefore usable outside the image domain) are currently running; we will add them if the experiments complete on time.	I-Reply	I-1	Reply	523
<sep> <sep> Furthermore, we found that our model performs slightly better on the MNIST <-> SVHN experiments when using RGB images rather than greyscale, so we have replaced our greyscale results with RGB ones.	B-Reply	B-1	Reply	523
This represents a slightly bigger domain jump, so we hope that this increases your confidence in our work.	I-Reply	I-1	Reply	523
<sep> <sep> * We see what you mean concerning engineering tricks.	B-Reply	B-2	Reply	523
In defence of confidence thresholding, rather than being a new additional trick it replaces a time-dependent ramp-up curve used by Laine et al in their work.	I-Reply	I-2	Reply	523
We have made this a little more explicit in section 3.3.	I-Reply	I-2	Reply	523
As for class balancing loss, it is similar in purpose and implementation to the entropy maximisation loss used in the IMSAT model of Hu et al (an unsupervised clustering model that also uses data augmentation).	I-Reply	I-2	Reply	523
We have mentioned this in section 3.4.	I-Reply	I-2	Reply	523
We did not cite this paper in our original version as we were unaware of it at the time.	I-Reply	I-2	Reply	523
<sep> <sep> * We have run further VisDA experiments.	B-Reply	B-3	Reply	523
We found that pairing back our augmentation scheme improved performance on the validation set and made little different on the test set.	I-Reply	I-3	Reply	523
Our original complex augmentation scheme was tested on a very small subset (1280 samples) of the training and validation sets during the development of our model.	I-Reply	I-3	Reply	523
It turns out that these results did not generalise to the full set, so lesson learned (we were facing a tight competition deadline too).	I-Reply	I-3	Reply	523
Our new reduced augmentation scheme consists of random crops, random horizontal flips and random uniform scaling, thus bringing it in line with augmentation schemes commonly used in ImageNet networks, such as He et al's ResNets.	I-Reply	I-3	Reply	523
We have also performed 5 independent runs of each of our newer experiments and given a breakdown of the results.	I-Reply	I-3	Reply	523

Summary:	O	O	Review	523
GLUE is a benchmark consisting of multiple natural language understanding tasks	O	O	Review	523
that functions via uploading to a website and receiving a score based on	O	O	Review	523
privately held test set labels.	O	O	Review	523
<sep> Tasks include acceptability judgement, sentiment prediction, semantic equivalence	O	O	Review	523
detection, judgement of premise hypothesis entailment, question paragraph pair	O	O	Review	523
matching, etc..	O	O	Review	523
The benchmark also includes a diagnostic dataset with logical tasks such as	O	O	Review	523
lexical entailment and understanding quantifiers.	O	O	Review	523
<sep> <sep> In addition to presenting the benchmark itself, the paper also presents models	B-Review	B-2	Review	523
for performance baselines.	I-Review	I-2	Review	523
<sep> There is some brief analysis of the ability of Sentence2Vector vs. more complex	I-Review	I-2	Review	523
models with e.g. attention mechanisms and of single-task vs. multi-task training.	I-Review	I-2	Review	523
<sep> <sep> Evaluation:	O	O	Review	523
The GLUE benchmark seems like a well designed benchmark that could potentially	B-Review	B-1	Review	523
ignite new progress in the area of NLU.	I-Review	I-1	Review	523
<sep> But since I'm not an expert in the area of language modeling and know almost	O	O	Review	523
nothing about existing benchmarks I cannot validate the added benefit over	O	O	Review	523
existing benchmarks and the novelty of the suggested benchmarking approach.	O	O	Review	523
<sep> <sep> Details:	O	O	Review	523
The paper is well written, clear and easy to follow.	O	O	Review	523
<sep> <sep> The proposed benchmarks seem reasonable and illustrate the difficulty of	O	O	Review	523
benchmark tasks that involve logical structure.	O	O	Review	523
<sep> <sep> Page 5: showing showing (Typo)	B-Review	B-3	Review	523
<sep> Thank you for your review!	O	O	Reply	523
<sep> <sep> To clarify, GLUE is not a benchmark for language modeling (the task of modeling the probability of a piece of text) but rather (classification or regression based) natural language understanding.	B-Reply	B-1	Reply	523
<sep> <sep> Regarding previous work in this space, we mention in the paper what we believe are the two major comparable works: SentEval and DecaNLP, and highlight the benefits over these neighbors afforded by our design decisions.	B-Reply	B-2	Reply	523
As your review hints at, we believe that a major benefit of a well-designed benchmark is that it can more clearly distinguish models that make significant improvements and thereby incentivize researchers to work on it.	I-Reply	I-2	Reply	523
Early results on GLUE seem to suggest that we have been successful in that regard.	I-Reply	I-2	Reply	523

The paper proposes a new benchmark for natural language understanding: GLUE.	O	O	Review	523
Models will be evaluated based on a diverse set of existing language understanding tasks which encourages the models to learn shared knowledge across different tasks.	O	O	Review	523
The authors empirically show that models trained with multiple tasks in the dataset perform better than models that focused on one specific task.	O	O	Review	523
They also point out existing methods are not able achieve good performance in this dataset and request for more general natural language understanding system.	O	O	Review	523
The work also collects an expert evaluated diagnostic evaluation dataset for further examination for the models.	O	O	Review	523
<sep> <sep> Quality: borderline, clarity:good, originality: borderline, significance: good,	O	O	Review	523
<sep> Pros:	O	O	Review	523
- The benchmark is set up in a online platform with leaderboard which can be easily accessible to people.	O	O	Review	523
<sep> - The benchmark comes with a diagnostic evaluation dataset with coarse-grained and fine-grained categories that examine different aspect of language understanding abilities.	O	O	Review	523
<sep> - Baseline results for major existing models are provided	O	O	Review	523
<sep> Cons:	O	O	Review	523
- The author should provide more detailed analysis and interpretable explanations for the results as opposed to simply stating that the overall performance is better.	B-Review	B-1	Review	523
<sep> For example, why attention hurts performance in single task training?	I-Review	I-1	Review	523
Why multi-tasks training actually leads to worse performance on some of the dataset?	I-Review	I-1	Review	523
Do these phenomenons still exist if you train on a different subset of the dataset?	I-Review	I-1	Review	523
<sep> What are the samples that the models failed to perform well?	I-Review	I-1	Review	523
It would be nice to get some more insights and conclusions based on the results obtained from this benchmark to shed some lights on how to improve these models.	I-Review	I-1	Review	523
The results section should be seriously revised.	I-Review	I-1	Review	523
<sep> <sep> - The diagnostic evaluation dataset seems to be a way to better understand the model, however, it is hard to see the scope of the data (are the samples under each categories balanced?).	B-Review	B-2	Review	523
Besides, the examples in the dataset seems very confusing even for humans (Table 2).	I-Review	I-2	Review	523
The evaluation with NLP expert is also far from perfect.	I-Review	I-2	Review	523
I wonder how accurate is this dataset annotated (or even the sentences make sense or not), and how suitable it is for evaluating model‚Äôs language understanding abilities.	I-Review	I-2	Review	523
It would be nice if the authors can include some statistics about the dataset.	I-Review	I-2	Review	523
<sep> <sep> The paper proposes a useful benchmark that measures different aspects of language understanding abilities which would be helpful to the community.	O	O	Review	523
However, I feel the novelty or take away messages from the experiment section is limited.	O	O	Review	523
<sep> <sep> Thanks for your thoughtful review!	O	O	Reply	523
<sep> <sep> While we agree that more analysis would be nice, the central contribution of our paper is to motivate and introduce the benchmark.	B-Reply	B-1	Reply	523
Thus, our experiments are designed to give baseline numbers for a broad range of models and to highlight the benefits of our design decisions, in order to make the case that our benchmark offers useful improvements over previous evaluation standards like SentEval.	I-Reply	I-1	Reply	523
<sep> <sep> Regarding the diagnostic data, we do believe much of the information you mention is present in the paper.	B-Reply	B-2	Reply	523
For example, we explicitly give the class distribution for the entire dataset (including statistics by category is a good point - we will soon add the class distribution per coarse-grained category), expert annotator agreement (high, at \kappa = 0.73), and human performance (R_3 = 0.8 versus 0.28 for the best model).	I-Reply	I-2	Reply	523
The last statistic in particular indicates that these examples are understandable and solvable by humans and challenging for existing models.	I-Reply	I-2	Reply	523
These numbers are in-line with other semantic datasets that have been productively used by the community, for example SQuADv2 (humans get ~87 EM); SimLex-999 (0.67 correlation); WordSimilarity-353 (.61 correlation).	I-Reply	I-2	Reply	523
We agree that human annotations are not perfect, but perfect annotations don‚Äôt exist, and datasets can still be useful even when their human annotations are a little noisy, as in the previously mentioned examples.	I-Reply	I-2	Reply	523

This paper introduces the General Language Understanding Evaluation (GLUE) benchmark and platform, which aims to evaluate representations of language with an emphasis on generalizability.	O	O	Review	523
This is a timely contribution and GLUE will be an impactful resource for the NLP community.	O	O	Review	523
This is mitigated, perhaps, somewhat by the recent release of decaNLP.	O	O	Review	523
But, as discussed the authors, this has a different focus (re-framing all tasks as QQ) and further does not feature the practical tools released here (leaderboard, error analysis) that will help drive progress.	O	O	Review	523
<sep> <sep> Some comments below.	O	O	Review	523
<sep> <sep> - The inclusion of the small diagnostic dataset was a nice addition and it would be nice if future corpora included similar.	B-Review	B-1	Review	523
<sep> <sep> - Implicit in this and related efforts is the assumption that parameter sharing ought to be possible and fruitful across even quite diverse tasks.	B-Review	B-2	Review	523
While I do not object to this, it would be nice if the authors could make an explicit case here as to why should we believe this to be the case.	I-Review	I-2	Review	523
<sep> <sep> - The proposed platform is touted as one of the main contributions here, but not pointed to -- I assume for anonymity preserving reasons, but still would have been nice for this to be made explicit.	B-Review	B-3	Review	523
<sep> <sep> - I would consider pushing Table 5 (Appendix) into the main text.	B-Review	B-4	Review	523
<sep> <sep> Thank you for your review!	O	O	Reply	523
<sep> <sep> We agree that the diagnostic data is a key contribution of our work.	B-Reply	B-1	Reply	523
We wanted to not only have an application-driven measure of progress, but also a targeted measure of performance on specific natural language phenomena that we would expect a general-purpose NLU model to handle well.	I-Reply	I-1	Reply	523
<sep> <sep> Regarding parameter sharing, our intent was to include tasks with very little training data such that automated systems could not do well learning on just those tasks‚Äô data.	B-Reply	B-2	Reply	523
Competitive systems, then, would need to include some form of knowledge-sharing from outside data.	I-Reply	I-2	Reply	523
In only requiring model predictions to evaluate on test, we wanted to avoid restricting future research to any particular paradigm of knowledge sharing.	I-Reply	I-2	Reply	523
We use multi-task learning and parameter sharing because it is a straightforward baseline with lots of precedent (GenSen, Collobert and Weston, etc.),	I-Reply	I-2	Reply	523
so we thought it necessary to include.	I-Reply	I-2	Reply	523
<sep> <sep> Could you please clarify how a small *test* set would encourage few-shot learning?	I-Reply	I-2	Reply	523
To the best of our knowledge, few-shot learning is when you have a small *training* set for the target task.	I-Reply	I-2	Reply	523
<sep> <sep> Re: table 5, we agree!	B-Reply	B-4	Reply	523
We‚Äôll post an updated version of the paper shortly.	I-Reply	I-4	Reply	523

The authors address the problem of discovering and predicting with hierarchical structure in data sequences of relevance to planning.	O	O	Review	523
Starting with the kinds of data that have been used recently in video prediction, the authors aim at learning a sequence of keyframes (i.e., subsets of frames forming the overall sequence) that in a suitable sense "summarize" the overall trace.	O	O	Review	523
As they rightly note, many alternate models struggle with making good long term predictions in part because they focus on all levels of prediction equally.	O	O	Review	523
<sep> <sep> The technical approach is to pose the problem as one of inferring the temporal location of each of these key frames and then to interpolate with a model to generate intermediate frames.	O	O	Review	523
One could try to make either step sophisticated - the authors choose to make the keyframe selection more sophisticated and interpolation simpler.	O	O	Review	523
The paper first described the KeyIn model in terms of a probabilistic model of jointly finding the Ks and then the inpainted Is.	O	O	Review	523
This can become delicate, so the authors propose a relaxation that is more forgiving when the keyframe locations are being searched for.	O	O	Review	523
Learning is driven by a reconstruction loss of finding the approximate location, locally interpolating and then seeing if this accords with the training data.	O	O	Review	523
This is all implemented with an LSTM based NN architecture which seems sound to me.	O	O	Review	523
<sep> <sep> I feel the paper is taking on the right kinds of questions, looking for ways to inject the right kind of structure.	O	O	Review	523
I do have some concerns about the overall formulation:	O	O	Review	523
<sep> 1.	O	O	Review	523
Much of the paper is focussed on rather clean images where nothing extraneous is happening.	B-Review	B-1	Review	523
In reality, the backgrounds of real images is not so benign and other extraneous dynamics might interfere.	I-Review	I-1	Review	523
While I understand this is a step towards the long term goal, I wonder if the end result is a bit too incremental in the absence of some attempt to explore this source of (lack of) robustness.	I-Review	I-1	Review	523
<sep> <sep> 2.	B-Review	B-2	Review	523
In ¬ß6.3, the authors try to demonstrate that the number of keyframes parameter can be wrong by a little bit but these are still small ranges.	I-Review	I-2	Review	523
In realistic images it is likely that the total number of keyframes selected by such an algorithm is much larger due to extraneous events.	I-Review	I-2	Review	523
This is why a proper robustness study is crucial on more realistic input.	I-Review	I-2	Review	523
As it, in anything other than the trivial dot on black background, the precision-recall numbers are fairly modest.	I-Review	I-2	Review	523
This will likely degenerate into noise in most camera-based images of the kind seen by a real robot.	I-Review	I-2	Review	523
So, how much confidence should we expect to have in the approach's generality?	I-Review	I-2	Review	523
<sep> <sep> 3.	O	O	Review	523
For the baselines, the true good baseline might have been a human annotation that tells us how people really conceptualise the structure.	B-Review	B-3	Review	523
With data such as pushing, this might not be so different from the simple visual inspection, but again with real data this will vary.	I-Review	I-3	Review	523
The paper would really be much stronger if these were addressed.	I-Review	I-3	Review	523
<sep> <sep> <sep> We thank the reviewer for the helpful comments and suggestions.	O	O	Reply	523
We made the following changes to the submission to address the reviewer's remarks and answer the posed questions.	O	O	Reply	523
<sep> <sep> == robustness in noisy settings ==	O	O	Reply	523
We thank the reviewer for drawing attention to the importance of robustness to noise of the kind that exists in real-world domains.	B-Reply	B-1	Reply	523
We added an experiment (Tab.	I-Reply	I-1	Reply	523
7 and Fig 11) showing that KeyIn keyframe detection performance is robust to Gaussian image noise, a noise characteristic that is commonly found in real camera sensors [5]. We believe this experiment provides some initial evidence that KeyIn can learn representations that are robust to noise.	I-Reply	I-1	Reply	523
We note that comparable prior work uses environments with little noise and few distractors [1,2,3,4], but we hope that future work will be able to investigate this direction further once the video modeling community matures to the point of using complex real-world data with diverse background activity of the kind the reviewer suggests.	I-Reply	I-1	Reply	523
<sep> <sep> == Modest precision-recall numbers ==	O	O	Reply	523
The reported precision-recall numbers indeed look modest, however, this is largely due to the inherent ambiguity when defining ‚Äútrue‚Äù keyframes.	B-Reply	B-2	Reply	523
For example: in the grid-world environment, is the frame where the agent reaches an object or where it interacts with the object the better keyframe?	I-Reply	I-2	Reply	523
While we chose one definition of a keyframe, we find that the method often predicts keyframes consistent with another definition, leading to off-by-one errors that are severely penalized by precision-recall metrics.	I-Reply	I-2	Reply	523
To address this, we added an evaluation that measures minimum temporal distance to the true keyframe in Tab 4, which shows that KeyIn places keyframes closer to the annotated keyframes than all baselines.	I-Reply	I-2	Reply	523
We also point out that the planning experiments provide a more objective evaluation metric for the quality of keyframes, and we find that KeyIn improves planning performance over all baselines.	I-Reply	I-2	Reply	523
<sep> <sep> == Human annotation baseline ==	O	O	Reply	523
We thank the reviewer for this suggestion.	B-Reply	B-3	Reply	523
We agree that on the current environments the human annotations would not be much different from the ones used to evaluate the models.	I-Reply	I-3	Reply	523
However, for future work that extends KeyIn to more complex environments where it is even harder to define ‚Äúobjective‚Äù keyframes, crowdsourced human annotations will likely be necessary for proper evaluation.	I-Reply	I-3	Reply	523
<sep> <sep> [1] Time-Agnostic Prediction, Jayaraman et al ICLR 2019	O	O	Reply	523
[2] Stochastic Video Generation with a Learned Prior, Denton&amp;Fergus, ICML 2018	O	O	Reply	523
[3] Learning latent dynamics for planning from pixels, Hafner et al ICML 2019	O	O	Reply	523
[4] Robustness via Retrying: Closed-Loop Robotic Manipulation with Self-Supervised Learning, Ebert et al 2018	O	O	Reply	523
[5] <a href="https://en.wikipedia.org/wiki/Image_noise" target="_blank" rel="nofollow">https://en.wikipedia.org/wiki/Image_noise</a>	O	O	Reply	523

This paper introduces a variational objective to train a model which can jointly select keyframes of a video and generate the intervening frames to produce a resultant video.	O	O	Review	523
The model is provided an initial set of frames as context.	O	O	Review	523
At training time the model always learns to produce N*J frames, where N is the number of keyframes and J is a fixed number of frames to generate for each keyframe.	O	O	Review	523
The authors compare their method for selecting informative keyframes on a number of baselines and show an improvement over these baselines.	O	O	Review	523
The problem is interesting and well-motivated, but I have some concerns with the proposed approach and experiments.	O	O	Review	523
As such, I am a weak reject.	O	O	Review	523
<sep> <sep> comments / questions:	O	O	Review	523
- Equation 3 lacks context.	B-Review	B-1	Review	523
Initially, when looking at the authors' objective it seems that the inner expectation should be taken with respect to the joint time indices for the current and next keyframe.	I-Review	I-1	Review	523
Only later after equation 4 do they mention that they always predict a fixed number of frames J.	I-Review	I-1	Review	523
- The need for normalizing over the first T timesteps in equation 4 seems quite messy.	B-Review	B-2	Review	523
Is it guaranteed that all of the needed keyframes will actually be within the first T timesteps?	I-Review	I-2	Review	523
How does this work in practice?	I-Review	I-2	Review	523
<sep> - Many important details of the inference procedure are relegated to the appendix.	B-Review	B-3	Review	523
For example, there are no details for extracting which of the 60 keyframes that were trained for a sequence (due to the fixed length sequences) should be selected at test time.	I-Review	I-3	Review	523
Looking at the appendix, it is clear that the approach requires an extensive planning algorithm at inference time, which seems like an important component.	I-Review	I-3	Review	523
<sep> - The authors prominently highlight that their method is fully differentiable, yet they train in two stages while freezing weights.	B-Review	B-4	Review	523
Why isn't the model trained end-to-end?	I-Review	I-4	Review	523
The stated reason for doing so is that this "simple" two-stage procedure improves optimization.	I-Review	I-4	Review	523
What exactly happens if you don't do this two stage training process?	I-Review	I-4	Review	523
Does it fail to learn?	I-Review	I-4	Review	523
Some experimental numbers would be nice to see.	I-Review	I-4	Review	523
<sep> - The authors do not compare their method to any strong keyframe prediction baselines.	B-Review	B-5	Review	523
Considering there is existing work in keyframe prediction, it seems important to highlight the difference between other competing models, rather than relying on simple baselines.	I-Review	I-5	Review	523
Why don't they use self-information/surprisal as a baseline i.e., by training an autoregressive model on the frames and then picking the N frames with the largest -log(p)?	I-Review	I-5	Review	523
This is a metric that has been investigated frequently and has better interpretability than defining a new measure of surprise.	I-Review	I-5	Review	523
Note that Kipf et al (2019) uses this notion of surprisal as well.	I-Review	I-5	Review	523
<sep> - Sauer et al (BMVC 2019) should likely be cited as it does very similar keyframe analysis.	B-Review	B-6	Review	523
Also, as the ICML 2019 conference had already concluded by the ICLR submission deadline, is it really fair to state the work with Kipf et al (2019) was conducted in parallel?	I-Review	I-6	Review	523
<sep> - Why does the model trained to learn a fixed number of timesteps for the intermediate frames?	B-Review	B-7	Review	523
Did they investigate jointly predicting the indices for the current and next timesteps?	I-Review	I-7	Review	523
It seems like it would greatly simplify their inference scheme if they did this.	I-Review	I-7	Review	523
If they tried that approach and it failed, maybe that should be mentioned in the paper (with an explanation as to why it fails).	I-Review	I-7	Review	523
<sep> - In the literature review, when discussing hierarchical temporal structure, the authors state: "However, these models rely on autoregressive techniques for text generation and are not applicable to structured data, such as videos."	B-Review	B-8	Review	523
Autoregressive techniques have been investigated in relation to videos; in fact, the authors later describe papers that have used autoregressive techniques for modeling videos.	I-Review	I-8	Review	523
<sep> <sep> We thank the reviewer for the useful comments and suggestions.	O	O	Reply	523
We understand that the main concerns of the reviewer are that 1) we only predict J intermediate frames, 3) the inference procedure is unclear, and 5) the surprisal baseline is not the same as in Kipf‚Äô19.	O	O	Reply	523
There appear to be several critical points of misunderstanding, which we will try to clarify.	O	O	Reply	523
While we made our best attempt to address the reviewer‚Äôs concerns, we hope the reviewer can engage with us during the discussion period to clarify their concerns and help us understand how we can address them.	O	O	Reply	523
We updated and clarified parts of the technical section based on the reviewer‚Äôs feedback (updates in red).	O	O	Reply	523
<sep> <sep> We next address the reviewer‚Äôs concerns, numbered by the order in which they appear in the review, starting with the most crucial.	O	O	Reply	523
<sep> <sep> ==  1, 7.	O	O	Reply	523
Predict J intermediate frames?	O	O	Reply	523
==	O	O	Reply	523
The number of frames between two keyframes is not fixed - it is given by the variable tau as explained in Sec.3.1, eqs (1, 2).	B-Reply	B-7	Reply	523
However, in practice, the number of frames between the keyframes is indeed bounded by J (for computational reasons).	I-Reply	I-7	Reply	523
We note that at training time, we always generate all J frames as the timestep distribution tau in general has non-zero mass at each timestep.	I-Reply	I-7	Reply	523
However, at test time we only predict argmax(tau) intermediate frames.	I-Reply	I-7	Reply	523
<sep> <sep> == 3.	O	O	Reply	523
Missing details of inference?	O	O	Reply	523
Planning needed for inference?	O	O	Reply	523
==	O	O	Reply	523
We interpret the question as asking about the test time procedure of the model (rather than the variational inference procedure we use).	B-Reply	B-3	Reply	523
At test time, we can use our model in three different ways, to (1) generate a sequence given conditioning frames, as described in Sec 3.1, (2) infer the keyframes of a sequence, by using the inference network described in Sec 3.2, or (3) perform planning to reach a goal as described in Sec 6.4.	I-Reply	I-3	Reply	523
We suspect the reviewer‚Äôs question is about (1), which is performed as follows.	I-Reply	I-3	Reply	523
We sample the latents from the prior distribution p(z|I_co), generate the corresponding keyframes K and their indices tau, and use the inpainter network to generate the rest of the sequence.	I-Reply	I-3	Reply	523
We note that the planning algorithm described in the appendix is used for motion planning as part of (3) and is not a part of the training.	I-Reply	I-3	Reply	523
Planning is not required for (1) or (2).	I-Reply	I-3	Reply	523
<sep> <sep> == 5.	O	O	Reply	523
Why this surprisal metric?	O	O	Reply	523
==	O	O	Reply	523
As the reviewer points out, our original surprisal metric is not the same as the traditional log(p).	B-Reply	B-5	Reply	523
While a lower bound on log(p) can be computed by summing the reconstruction and the KL-divergence loss, we only used the KL-divergence part.	I-Reply	I-5	Reply	523
We have now added a version of the baseline that computes the full lower bound as well as the version from Denton&amp;Fergus‚Äô18 suggested by R1.	I-Reply	I-5	Reply	523
In Tabs.	I-Reply	I-5	Reply	523
3, 4, we find that these new versions of the surprise baseline perform comparably to the one we originally reported, and our method outperforms all of them.	I-Reply	I-5	Reply	523

The paper introduces a model trained for video prediction hierarchically: a series of significant frames called ‚Äúkeyframes‚Äù in the paper are first predicted and then intermediate frames between keyframes couples are generated.	O	O	Review	523
The training criterion is maximum likelihood with a variational approximation.	O	O	Review	523
Experiments are performed on 3 different video datasets and the evaluation is performed for 3 tasks: keyframe detection, frame prediction and planning in robot videos.	O	O	Review	523
<sep> The idea of generating an abstraction or a summary of a video via a sequence of important frames is attractive and could probably be used in different contexts.	O	O	Review	523
The proposed model is new and the authors introduce some clever ideas in order to train it.	O	O	Review	523
The evaluation work is important and the authors propose different settings for this evaluation.	O	O	Review	523
<sep> The paper also present weaknesses.	O	O	Review	523
First the motivation for keyframes generation should be better developed: the model does not perform better than baselines for video frames prediction so that keyframes generation should be motivated by other applications.	B-Review	B-1	Review	523
Planning as proposed by the authors could be one, but in this case it should be more developed.	I-Review	I-1	Review	523
The main weakness is however the technical presentation which is painful to follow.	B-Review	B-2	Review	523
When it is possible to get a general picture of what is done, it is quite difficult to figure out exactly how the model works.	I-Review	I-2	Review	523
A global rewriting and maybe a better focus are required for publication.	I-Review	I-2	Review	523
The probabilistic model (section 3.1) is relatively clear, even if it could be improved.	I-Review	I-2	Review	523
It seems that the generation of a keyframe and the prediction of the corresponding time (tau^n)  are independent (eq.3).	I-Review	I-2	Review	523
This could be commented.	I-Review	I-2	Review	523
Also it seems that in eq.3 the log(K|z..) term should be inside an expectation.	I-Review	I-2	Review	523
Section 4 was difficult to decipher for me.	I-Review	I-2	Review	523
My understanding is that instead of sampling from a multinomial during training, you bypass this non differentiable operation by using what you call ‚Äúsoft targets‚Äù thus obtaining a differentiable objective (eq.4).	I-Review	I-2	Review	523
Is that true?	I-Review	I-2	Review	523
In any case, the procedure should be made a lot clearer.	I-Review	I-2	Review	523
The ‚Äúintermediate frame‚Äù passage also remained confuse for me.	I-Review	I-2	Review	523
<sep> Considering the experiments, the authors make an important effort in order to evaluate different aspects of their model.	B-Review	B-3	Review	523
In a fisrt step, they evaluate the ability of the model to generate significant keyframes using a detection setting.	I-Review	I-3	Review	523
It is not clear how they define ground truth frames for this evaluation.	I-Review	I-3	Review	523
Those ground truth frames are defined as the frames where the movement in the image changes, which is easy on the Brownian movement dataset but what about the others?	I-Review	I-3	Review	523
Also the baselines used in this comparison are weak.	I-Review	I-3	Review	523
In the paper of Denton, they suggest some way to detect surprise and apparently this is not what you used.	I-Review	I-3	Review	523
This should be justified/ commented.	I-Review	I-3	Review	523
For keyframe modeling the proposed model behaves similarly to the baselines and even performs worse than the simpler ‚Äújumpy‚Äù model.	B-Review	B-4	Review	523
Concerni g the paragraph about the selection of the number of predicted keyframes, it is not clear what is the reference (ground truth) number of target keyframes.	I-Review	I-4	Review	523
<sep> The planning experiments are interesting, but difficult to follow at least from the main text.	O	O	Review	523
<sep> Overall, I think that there are several interesting ideas and realizations.	O	O	Review	523
They should be better put in perspective and explained.	O	O	Review	523
<sep> <sep> ----- post rebuttal -----------	O	O	Review	523
<sep> Thanks for the detailed answer.	O	O	Review	523
The paper is largely improved both for the style and the comparisons.	O	O	Review	523
But still requires further improvements.	O	O	Review	523
I will keep my score.	O	O	Review	523
<sep> <sep> We thank the reviewer for the helpful comments and suggestions.	O	O	Reply	523
We have made several changes to the presentation of the technical section as well as the description of the experiments and results to address the reviewer's concerns (updates in red).	O	O	Reply	523
We have also added comparisons to alternative ‚Äúsurprise‚Äù baselines as well as experiments on keyframe modeling.	O	O	Reply	523
We hope the responses below address the reviewer‚Äôs concerns and we are happy to make additional changes if those are required.	O	O	Reply	523
<sep> <sep> == Motivation should be better developed ==	O	O	Reply	523
We thank the reviewer for pointing out a possible confusion about the motivation of the paper.	B-Reply	B-1	Reply	523
We tried to highlight in the original submission that the goal of this work is not to improve video prediction quality but instead to discover meaningful temporal structure in sequences.	I-Reply	I-1	Reply	523
As the reviewer notes, one possible application for the temporal structure discovered by our model is predicting subgoals for efficient long-horizon planning, and we now expanded the introduction to discuss this.	I-Reply	I-1	Reply	523
We note that planning is known to be a challenging task [1-4] and we show that our model is able to outperform strong baselines using the learned temporal abstraction.	I-Reply	I-1	Reply	523
<sep> <sep> == Keyframe detection baseline weak, use Denton&amp;Fergus‚Äô18 ==	O	O	Reply	523
We thank the reviewer for proposing this alternative comparison.	B-Reply	B-3	Reply	523
In the original submission we used a measure of surprise based on the KL divergence (see Sec.F).	I-Reply	I-3	Reply	523
6.3, details in appendix, Sec.	I-Reply	I-3	Reply	523
To support the strength of this baseline we have now added two baseline evaluations using alternative definitions of surprise.	I-Reply	I-3	Reply	523
The first uses the method of Denton&amp;Fergus‚Äô18 that the reviewer proposed.	I-Reply	I-3	Reply	523
The second uses the lower bound on the log-likelihood -log(p) instead of just the KL divergence to measure surprise.	I-Reply	I-3	Reply	523
In Tab 3,4, we find that the KL-based baseline reported in the submission consistently performs on par with these alternative formulations, and that our method outperforms all baselines.	I-Reply	I-3	Reply	523
<sep> <sep> == No performance gain on keyframe modeling ==	O	O	Reply	523
We understand that the reviewer is referring to the results evaluating image sequence prediction quality (as opposed to keyframe prediction quality).	B-Reply	B-4	Reply	523
It is true that our method does not improve performance on video modeling, but we emphasize that it is able to perform on par with recent work (Denton&amp;Fergus‚Äô18) while additionally discovering the keyframe structure of the sequence.	I-Reply	I-4	Reply	523
Please refer to our answer to the first question about motivation.	I-Reply	I-4	Reply	523
We additionally performed an experiment showing that our model‚Äôs ability to model keyframes (i.e. the most important frames) is superior to the baseline methods that do not discover temporal structure in Tab.6.	I-Reply	I-4	Reply	523
We further clarified the emphasis of the paper with an additional sentence in Sec 6.2.	I-Reply	I-4	Reply	523
<sep> <sep> == Soft targets for obtaining differentiable objective?	O	O	Reply	523
==	O	O	Reply	523
This interpretation is correct: we introduce the relaxed formulation to bypass the sampling step from p(tau|z,I_co) and make the formulation fully differentiable.	B-Reply	B-2	Reply	523
The original submission stated this in Sec.4.	I-Reply	I-2	Reply	523
We thank the reviewer for pointing out the need for further clarifications.	I-Reply	I-2	Reply	523
We restructured Sec.4 to more clearly motivate and derive the soft relaxation objective.	I-Reply	I-2	Reply	523
We additionally improved Fig.3 to better illustrate the procedure.	I-Reply	I-2	Reply	523

# Review	O	O	Review	225
This paper proposes a quantitative evaluation for decoder-based generative models that use Annealed Importance Sampling (AIS) to estimate log-likelihoods.	O	O	Review	225
Quantitative evaluations are indeed much needed since for some models, like Generative Adversarial Networks (GANs) and Generative Moment Matching Networks (GMMNs), qualitative evaluation of samples is still frequently used to assess their generative capability.	O	O	Review	225
Even though, there exist quantitative evaluations like Kernel Density Estimation (KDE), the authors show how AIS is more accurate than KDE and how it can be used to perform fine-grained comparison between generative models (GAN, GMMs and Variational Autoencoders (VAE)).	O	O	Review	225
<sep> <sep> The authors report empirical results comparing two different decoder architectures that were both trained, on the continuous MNIST dataset, using the VAE, GAN and GMMN objectives.	B-Review	B-2	Review	225
They also trained an Importance Weighted Autoencoder (IWAE) on binarized MNIST and show that, in this case, the IWAE bound underestimates the true log-likelihoods by at least 1 nat (which is significant for this dataset) according to the AIS evaluation of the same model.	O	O	Review	225
<sep> <sep> <sep> # Pros	O	O	Review	225
Their evaluation framework is public and is definitely a nice contribution to the community.	O	O	Review	225
<sep> <sep> This paper gives some insights about how GAN behaves from log-likelihood perspective.	O	O	Review	225
The authors disconfirm the commonly proposed hypothesis that GAN are memorizing training data.	O	O	Review	225
The authors also observed that GANs miss important modes of the data distribution.	O	O	Review	225
<sep> <sep> <sep> # Cons/Questions	O	O	Review	225
It is not clear for me why sometimes the experiments were done using different number of examples (100, 1000, 10000) coming from different sources (trainset, validset, testset or simulation/generated by the model).	B-Review	B-1	Review	225
For instance, in Table 2 why results were not reported using all 10,000 examples of the testing set?	I-Review	I-1	Review	225
<sep> <sep> It is not clear why in Figure 2c, AIS is slower than AIS+encoder?	B-Review	B-2	Review	225
Is the number of intermediate distributions the same in both?	I-Review	I-2	Review	225
<sep> <sep> 16 independent chains for AIS seems a bit low from what I saw in the literature (e.g. in [Salakhutdinov & Murray, 2008] or [Desjardins etal.,	B-Review	B-3	Review	225
2011], they used 100 chains).	I-Review	I-3	Review	225
Could it be that increasing the number of chains helps tighten the confidence interval reported in Table 2?	I-Review	I-3	Review	225
<sep> <sep> I would have like the authors to give their intuitions as to why GAN50 has a BDMC gap of 10 nats, i.e. 1 order of magnitude compared to the others?	B-Review	B-4	Review	225
<sep> <sep> <sep> # Minor comments	O	O	Review	225
Table 1 is not referenced in the text and lacks description of what the different columns represent.	B-Review	B-5	Review	225
<sep> Figure 2(a), are the reported values represents the average log-likelihood of 100 (each or total?)	B-Review	B-6	Review	225
training and validation examples of MNIST (as described in Section 5.3.2).	I-Review	I-6	Review	225
<sep> Figure 2(c), I'm guessing it is on binarized MNIST?	B-Review	B-7	Review	225
Also, why are there fewer points for AIS compared to IWAE and AIS+encoder?	I-Review	I-7	Review	225
<sep> Are the BDMC gaps mentioned in Section 5.3.1 the same as the ones reported in Table2 ?	B-Review	B-8	Review	225
<sep> Typo in caption of Figure 3: "(c) GMMN-10" but actually showing GMMN-50 according to the graph title and subcaption.	B-Review	B-9	Review	225
Thank the reviewer for providing helpful comments.	O	O	Reply	225
<sep> <sep> Different number of examples:	O	O	Reply	225
We ran our experiments on academic scale infrastructure, so we didn‚Äôt have the resources to run the maximum number of examples in all conditions.	B-Reply	B-1	Reply	225
We will release an updated version where all experiments use the maximum number of test examples.	I-Reply	I-1	Reply	225
However, we reported confidence intervals for the results, and even with only 1000 examples for the training sets, the differences between models were still highly statistically significant.	I-Reply	I-1	Reply	225
<sep> <sep> AIS+encoder:	O	O	Reply	225
AIS works better when the initial distribution is a better match to the target (posterior) distribution.	B-Reply	B-2	Reply	225
In those cases where an encoder net is available, it ought to provide a better initial distribution than the prior (which is what we used in the rest of the experiments).	I-Reply	I-2	Reply	225
Therefore, AIS+encoder can reach comparable accuracy in a much smaller number of steps.	I-Reply	I-2	Reply	225
<sep> <sep> # of AIS chains:	O	O	Reply	225
We have tested different number of independent chains.	B-Reply	B-3	Reply	225
In our experiments we find that when the number of intermediate distribution goes beyond 1000, the evaluation does not vary much for different choices of number of chains.	I-Reply	I-3	Reply	225
16 chains are enough for evaluation.	I-Reply	I-3	Reply	225
<sep> <sep> Large gaps for GAN-50:	O	O	Reply	225
We speculate that the posterior distribution might be more complicated in the case of GAN-50.	B-Reply	B-4	Reply	225
However, the difference between GAN-50 and the other conditions is not necessarily surprising or interesting; there‚Äôs no reason that different models ought to have posterior distributions which are equally difficult to sample from.	I-Reply	I-4	Reply	225
We suspect the fact that the other five models have very similar BDMC gaps is just a coincidence.	I-Reply	I-4	Reply	225
<sep> <sep> <sep> Minor comments:	O	O	Reply	225
We have edited table 1 and the reference in the paper	B-Reply	B-5	Reply	225
They are average value.	B-Reply	B-6	Reply	225
<sep> Adding another point for AIS will either make the plot too large in y-axis or x-axis.	B-Reply	B-7	Reply	225
<sep> Yes the BDMC gap refer to the values in Table 2.	B-Reply	B-8	Reply	225
<sep> Thanks for pointing out this typo.	B-Reply	B-9	Reply	225

Summary:	O	O	Review	225
This paper describes how to estimate log-likelihoods of currently popular decoder-based generative models using annealed importance sampling (AIS) and HMC.	O	O	Review	225
It validates the method using bidirectional Monte Carlo on the example of MNIST, and compares the performance of GANs and VAEs.	O	O	Review	225
<sep> <sep> <sep> Review:	O	O	Review	225
Although this seems like a fairly straight-forward application of AIS to me (correct me if I missed an important trick to make this work), I very much appreciate the educational value and empirical contributions of this paper.	O	O	Review	225
It should lead to clarity in debates around the density estimation performance of GANs, and should enable more people to use AIS.	O	O	Review	225
<sep> <sep> Space permitting, it might be a good idea to try to expand the description of AIS.	B-Review	B-1	Review	225
All the components of AIS are mentioned and a basic description of the algorithm is given, but the paper doesn‚Äôt explain well ‚Äúwhy‚Äù the algorithm does what it does/why it works.	I-Review	I-1	Review	225
<sep> <sep> I was initially confused by the widely different numbers in Figure 2.	O	O	Review	225
On first glance my expectation was that this Figure is comparing GAN, GMMN and IWAE (because of the labeling at the bottom and because of the leading words in the caption‚Äôs descriptions).	B-Review	B-2	Review	225
Perhaps mention in the caption that (a) and (b) use continuous MNIST and (c) uses discrete MNIST. ‚	I-Review	I-2	Review	225
ÄúGMMN-50‚Äù should probably be ‚ÄúGMMN-10‚Äù.	I-Review	I-2	Review	225
<sep> <sep> <sep> Using reconstructions for evaluation of models may be a necessary but is not sufficient condition for a good model.	B-Review	B-3	Review	225
Depending on the likelihood, a posterior sample might have very low density under the prior, for example.	I-Review	I-3	Review	225
It would be great if the authors could point out and discuss the limitations of this test a bit more.	I-Review	I-3	Review	225
<sep> <sep> <sep> Minor:	O	O	Review	225
<sep> Perhaps add a reference to MacKay‚Äôs density networks (MacKay, 1995) for decoder-based generative models.	B-Review	B-4	Review	225
<sep> <sep> In Section 2.2, the authors write ‚Äúthe prior over z can be drastically different than the true posterior p(z|x), especially in high dimension‚Äù.	B-Review	B-5	Review	225
I think the flow of the paper could be improved here, especially for people less familiar with importance sampling/AIS.	I-Review	I-5	Review	225
I don‚Äôt think the relevance of the posterior for importance sampling is clear at this point in the paper.	I-Review	I-5	Review	225
<sep> <sep> In Section 2.3 the authors claim that is often more ‚Äúmeaningful‚Äù to estimate p(x) in log-space because of underflow problems. ‚	B-Review	B-6	Review	225
ÄúMeaningful‚Äù seems like the wrong word here.	I-Review	I-6	Review	225
Perhaps revise to say that it‚Äôs more practical to estimate log p(x) because of underflow problems, or to say that it‚Äôs more meaningful to estimate log p(x) because of its connection to compression/surprise/entropy.	I-Review	I-6	Review	225
We thank the reviewer for recognizing its educational value.	O	O	Reply	225
<sep> ‚ÄúHow AIS works?‚Äù -- We have edited the paper to include a short discussion on this.	B-Reply	B-1	Reply	225
<sep> ‚ÄúFigure 2‚Äù-- Thanks for pointing out the typo.	B-Reply	B-2	Reply	225
We changed the caption as the reviewer suggests.	I-Reply	I-2	Reply	225
<sep> ‚ÄúUsing reconstruction‚Äù -- We agree with the reviewer.	B-Reply	B-3	Reply	225
Visualizing reconstruction is a way to show one particular property of the model: whether it misses any important modes of the data distribution.	I-Reply	I-3	Reply	225
And we also agree that this is not a sufficient condition to be a good generative model.	I-Reply	I-3	Reply	225
‚ÄúDensity networks‚Äù -- We have added the citation.	B-Reply	B-4	Reply	225
<sep> ‚ÄúAIS/posterior‚Äù-- We edited the paper to show the relevance.	B-Reply	B-5	Reply	225
<sep> ‚ÄúMeaningful‚Äù-- We changed the phrasing.	B-Reply	B-6	Reply	225

The paper describes a method to evaluate generative models such as VAE, GAN and GMMN.	O	O	Review	225
This is very much needed in our community where we still eyeball generated images to judge the quality of a model.	O	O	Review	225
However, the technical increment over the NIPS 16 paper: ‚ÄúMeasuring the reliability of MCMC inference with bidirectional Monte Carlo‚Äù is very small, or nonexistent (but please correct me if I am wrong!).	B-Review	B-1	Review	225
(Grosse et al).	I-Review	I-1	Review	225
The relative contribution of this paper is the application of this method to generative models.	I-Review	I-1	Review	225
<sep> In section 2.3 the authors seem to make a mistake.	B-Review	B-2	Review	225
They write E[p‚Äô(x)] <= p(x) but I think they mean: E[log p‚Äô(x)] <= log E[p‚Äô(x)] = log p(x).	I-Review	I-2	Review	225
Also,  for what value of x?	I-Review	I-2	Review	225
If p(x) is normalized it can‚Äôt be true for all values of x. Anyways, I think there are typos here and there and the equations could be more precise.	I-Review	I-2	Review	225
<sep> On page 5 top of the page it is said that the AIS procedure can be initialized with q(z|x) instead of p(z).	B-Review	B-3	Review	225
However, it is unclear what value of x is then picked?	I-Review	I-3	Review	225
Is it perhaps Ep(x)[q(z|x)] ?	I-Review	I-3	Review	225
<sep> I am confused with the use of the term overfitting (p8 bottom).	B-Review	B-4	Review	225
Does a model A overfit relative to a another model B if the test accuracy of A is higher than that of B even though the gap between train and test accuracy is also higher for B than for A. I think not.	I-Review	I-4	Review	225
Perhaps the last sentence on page 8 should say that VAE-50 underfits less than GMMN-50?	I-Review	I-4	Review	225
<sep> The experimental results are interesting in that it exposes the fact that GANs and GMMNs seem to have much lover test accuracy than VAE despite the fact that their samples look great.	B-Review	B-5	Review	225
<sep> <sep> Thank the reviewer for providing helpful comments.	O	O	Reply	225
<sep> <sep> Relative contribution small:	O	O	Reply	225
It‚Äôs encouraging that our writing is clear enough that the ideas seem to flow naturally.	B-Reply	B-1	Reply	225
But the approach is obvious only in retrospect.	I-Reply	I-1	Reply	225
There has been a large amount of interest in the questions surrounding likelihoods of decoder-based models, including whether the models are missing modes or memorizing training examples.	I-Reply	I-1	Reply	225
Our submission is the first to quantitatively analyze these issues using accurate log-likelihood estimates.	I-Reply	I-1	Reply	225
Anecdotally, in our conversations with other researchers who cared about these questions and were familiar with the basic techniques, nobody suggested using a similar approach.	I-Reply	I-1	Reply	225
<sep> <sep> Here are some of our novel contributions: (1) formulating KDE as simple importance sampling, which shows that it gives a log-likelihood stochastic lower bound for a particular generative model (with Gaussian observations); this let us formulate the problem of estimating the log-likelihoods more accurately under this generative model; (2) using BDMC to validate the log-likelihood estimates in decoder-based models (a very different setting from where it was previously applied); (3) using the q network as the initial distribution, which makes the AIS estimator very efficient for VAEs, (4) using posterior samples as a way to diagnose missing modes.	I-Reply	I-1	Reply	225
<sep> <sep> Much progress in science comes about because someone designs and validates a new genetic technique and then uses it to measure phenomena that were previously inaccessible.	I-Reply	I-1	Reply	225
This is exactly what we wanted to achieve in this work: we engineered and validated a much improved log-likelihood estimator (orders of magnitude more accurate than the previous approach!),	I-Reply	I-1	Reply	225
and then used it to answer important questions about generative models which we previously didn‚Äôt have a way to answer.	I-Reply	I-1	Reply	225
<sep> <sep> <sep> Section 2.3: Thanks reviewer for pointing out the typo with missing ‚Äúlog‚Äù.	B-Reply	B-2	Reply	225
We have corrected it.	I-Reply	I-2	Reply	225
Note that the expectation is taken over the stochasticity of producing the estimate log p‚Äô(x).	I-Reply	I-2	Reply	225
Mathematically, the inequality holds for every x (not just on average w.r.t.x).	I-Reply	I-2	Reply	225
<sep> <sep> q(z|x): The approximate posterior, i.e., the recognition network is used as the initialization distribution for AIS chains.	B-Reply	B-3	Reply	225
The x refers to the given data to be evaluated.	I-Reply	I-3	Reply	225
<sep> <sep> overfitting:	O	O	Reply	225
What we mean by ‚Äúoverfitting‚Äù follows the standard usage in the field.	B-Reply	B-4	Reply	225
A model overfits if it models idiosyncrasies in the training set, thereby achieving a training likelihood much higher than its generalization (test) likelihood.	I-Reply	I-4	Reply	225
A model underfits if it fails to model the structure in the training set.	I-Reply	I-4	Reply	225
Despite the names, the two are not mutually exclusive, i.e. a given model can both overfit and underfit the data. (	I-Reply	I-4	Reply	225
For instance, if a network somehow memorized 50% of the training examples and ignored the other 50%, it would both overfit and underfit, as reflected in poor likelihood on the training set coupled with a large gap between training and test.)	I-Reply	I-4	Reply	225
<sep> <sep> You are correct that it‚Äôs not generally meaningful to compare the ‚Äúamount of overfitting‚Äù of two different models -- overfitting isn‚Äôt a quantity we can measure.	B-Reply	B-4	Reply	225
However, in our experiments, the size of the effect was large: the VAEs overfit substantially, whereas we saw no evidence of overfitting in the case of the GANs or GMMNs.	I-Reply	I-4	Reply	225

The paper tries to learn temporally stable representations for point-based data sets and focus on varying size and dynamic point sets, and demonstrate its usefulness in the context of super-resolution.	O	O	Review	225
To deal with a difficult target that dynamically moves and deforms over time with variable input and output size, they take a novel temporal loss function for temporally coherent point set generation and siamese network setup for temporal loss calculation.	O	O	Review	225
Their novel temporal loss is based on EMD to minimize differences between an estimated point cloud and a desired super-resolution point cloud.	O	O	Review	225
The discussion and evolution on multiple loss functions are mostly well done.	O	O	Review	225
Except spatial loss is considered, taking the ground truth acceleration and estimated velocity into account is beneficial to this task.	O	O	Review	225
Their main contribution is taking permutation invariant loss terms and a siamese training setup and generator architecture, enabling improved output variance by allowing for dynamic adjustments of the output size, and identifying a specialized form of mode collapse for temporal point networks.	O	O	Review	225
<sep> They perform an empirical study of their temporal loss function on the generated data set and apply the proposed method to some complex 3D models to conclude the superior performance of temporal loss formulation in contrast to previous work.	O	O	Review	225
<sep> Overall, this paper has some significant points on point cloud super-resolution, with the caveat for some clarifications on the theory and experiments.	O	O	Review	225
Given these clarifications in an author response, I would be willing to increase the score.	O	O	Review	225
<sep> When the input moves slowly enough, the point cloud can be considered static.	B-Review	B-1	Review	225
Can the proposed temporal loss outperform other works under this condition?	I-Review	I-1	Review	225
<sep> Only one previous work PU-Net based on PointNet++ is compared in the paper, I would like to see more discussion on applying the proposed temporal loss with other point-based algorithms.	B-Review	B-2	Review	225
<sep> I am very curious about the effect on different choices of weighting terms hyperparameters in temporal loss and predefined upsampling factor r.	B-Review	B-3	Review	225
<sep> <sep> We thank you for the positive review and feedback.	O	O	Reply	225
Below are our responses to the concerns mentioned in your review.	O	O	Reply	225
<sep> <sep> Slow input movement:	O	O	Reply	225
- When generating point clouds without temporal constraints, one of the biggest problems is a high frequency jittering that occurs due to accumulated small scale inference errors.	B-Reply	B-1	Reply	225
Especially with very small movements these jittering artifacts are very noticeable.	I-Reply	I-1	Reply	225
Thus a temporal constraint is also relevant for an almost static input.	I-Reply	I-1	Reply	225
<sep> <sep> Other point-based algorithms:	O	O	Reply	225
- That's a very interesting thought.	B-Reply	B-2	Reply	225
In theory, our method can be used with other point-based methods.	I-Reply	I-2	Reply	225
Only the training process would need to be updated, while the method for inference could stay the same.	I-Reply	I-2	Reply	225
We will add this as a discussion to our document.	I-Reply	I-2	Reply	225
<sep> <sep> Different choices of weighting terms:	O	O	Reply	225
- A larger temporal loss factor leads to central clusters of points.	B-Reply	B-3	Reply	225
The effects of the different ratios within the temporal loss (velocity and acceleration) are shown in the provided video starting from 0:26.	I-Reply	I-3	Reply	225
There one can clearly see how the additional acceleration loss term prevents flickering.	I-Reply	I-3	Reply	225
<sep> <sep> With an increased upsampling factor the memory utilization and the training time increases considerably, especially for the volumetric data.	I-Reply	I-3	Reply	225
As we primarily target temporal stability, we did not evaluate larger upsampling factors so far (smaller ones would be less problematic).	I-Reply	I-3	Reply	225

The paper addresses the task of learning temporally stable features for point clouds with an application to upsampling point clouds.	O	O	Review	225
Learning point-based descriptors has been a major topic of research in the recent vision and graphics meetings, where approaches have been proposed focusing semantic labeling, geometry-oriented tasks (e.g. normal estimation), and point-based graphics.	O	O	Review	225
However, as the paper states, and to the best of my knowledge, no methods have been proposed to learn features in fourth dimension in a temporally stable way.	O	O	Review	225
Thus, the very topic of research is significantly novel and promising.	O	O	Review	225
The authors consider a combination of loss functions and train a neural point-based network to learn the features.	O	O	Review	225
To stabilize training, the authors carefully study the effect of a series of loss functions, including well-known EMD, losses ensuring slow changes in positions, velocities, and accelerations, as well as a mingling loss to ensure a more uniform spatial point distribution on the output shape.	O	O	Review	225
The studied losses are very logical to implement as one aims to ensure that the output should satisfy a temporally smooth motion pattern.	O	O	Review	225
The experimental results provide a clear view of the proposed approach and demonstrate that combining the studied objectives function with a known point-based learning approach leads to a temporally stable feature representation per-point.	O	O	Review	225
An ablation study further helps to validate the proposed approaches step-by-step.	O	O	Review	225
To sum up, I believe paper should clearly be accepted, as (1) the work addresses a novel point-based learning task, (2) the research methodology is convincingly presented, and (3) the results provide a clear demonstration of the feasibility of the proposed task.	O	O	Review	225
We thank you for the positive comments and assessment of our work.	O	O	Reply	225

Summary:	O	O	Review	225
This paper proposed a deep network for point cloud sequence super-resolution/upsampling.	O	O	Review	225
Building on the basis of pointNet and PU-net, the main contribution of the paper is identifying the problem of temporal incoherence in the process of upsampling a point cloud shape representation as well as a training loss to encourage temporal coherence.	O	O	Review	225
In the cases showed in the paper, the proposed method seems effective comparing to previous work which is not done on sequence data.	O	O	Review	225
My main concern about the work is that the experimental evaluation is limited.	O	O	Review	225
<sep> <sep> Strengths:	O	O	Review	225
Interesting problem and novel idea.	O	O	Review	225
<sep> The proposed method is technically sound.	O	O	Review	225
From the provided results, the newly introduced training loss seems effective: the result sequences are visually more plausible and smooth.	O	O	Review	225
<sep> Weaknesses:	O	O	Review	225
Qualitative results are limited and in most cases seemingly simple.	B-Review	B-1	Review	225
In the paper as well as the companion video, there are very few examples provided.	I-Review	I-1	Review	225
The scale of the evaluation demonstration is not convincing enough for the readers that this work could be generalized to more complicated testing scenarios.	I-Review	I-1	Review	225
<sep> Quantitative results are also limited.	B-Review	B-2	Review	225
Since the method is handling the coherence of shape deformation over time, it would be much more convincing and helpful to introduce a dense-correspondence evaluation as a benchmark.	I-Review	I-2	Review	225
For example, one can create ground-truth correspondence from parametric morphable models and evaluate the coherence of the sequence by comparing the generated results with the ground truth.	I-Review	I-2	Review	225
<sep> <sep> We thank you for the positive assessment and feedback.	O	O	Reply	225
Below are our responses to the concerns mentioned in your review.	O	O	Reply	225
We will upload a revised version of our submission that extends the evaluation with respect to inputs with dense correspondences.	O	O	Reply	225
<sep> <sep> Regarding the qualitative results we provide:	O	O	Reply	225
<sep> - Each of our three scenarios contains between 60 and 200 frames.	B-Reply	B-1	Reply	225
In total we show outputs for 420 frames with up to half a million particles.	I-Reply	I-1	Reply	225
Thus the animations contain a much larger range of input configurations than most previous works.	I-Reply	I-1	Reply	225
They also contain a wide range of temporal configurations that highlight the stability of our generative model.	I-Reply	I-1	Reply	225
We have tested our method in other settings, and the performance of these 400+ frames is representative.	I-Reply	I-1	Reply	225
Furthermore, the network used for all 3D tests was trained only once, which illustrates how well our network generalizes.	I-Reply	I-1	Reply	225
<sep> <sep> It is also worth noting that due to the patch-based nature of our approach, the input data correlates only partially.	I-Reply	I-1	Reply	225
While the changes look simple to our eyes, the network has to deal with many non-trivial temporal changes in the inputs (the isolated patch examples in our videos illustrate this).	I-Reply	I-1	Reply	225
If the reviewers agree that additional examples are would strengthen the submission, we‚Äôd be happy to apply our network to additional input sequences.	I-Reply	I-1	Reply	225
<sep> <sep> Quantitative results in our submission:	O	O	Reply	225
<sep> - Thank you for this interesting suggestion.	O	O	Reply	225
We performed an evaluation based on your comments: we use an animated mesh as a basis to compute ground truth reference points over time, and project the generated point positions onto the mesh.	B-Reply	B-2	Reply	225
In this way we can establish a correlation between the generated point clouds, and calculate how much the change in position of the points corresponds to the ground-truth velocity and acceleration.	I-Reply	I-2	Reply	225
Additionally, we also evaluate the point density, which is a good indicator of temporal stability, as it should be as uniform as possible.	I-Reply	I-2	Reply	225
<sep> <sep> Velocity and acceleration are computed via the 1st and 2nd derivative of the predicted positions to the ground-truth position.	I-Reply	I-2	Reply	225
These derivatives are especially important to highlight discontinuous motions and other temporal instabilities.	I-Reply	I-2	Reply	225
For the density evaluation we also consider the variance of the 1st and 2nd derivative of the particle density.	I-Reply	I-2	Reply	225
The variance highlights especially well how much the particle distributions vary over time.	I-Reply	I-2	Reply	225
<sep> <sep> We list the resulting measurements averaged over 100 frames in the following table for a version of our network without temporal loss (‚Äúw/o‚Äù) and with our full temporal loss formulation (‚Äúwith‚Äù):	I-Reply	I-2	Reply	225
<sep> w/o          with	I-Reply	I-2	Reply	225
Velocity            |   0.043   |   0.024	I-Reply	I-2	Reply	225
Acceleration    |   0.078   |   0.043	I-Reply	I-2	Reply	225
<sep> And for the variances of density derivatives:	I-Reply	I-2	Reply	225
<sep> w/o            with	I-Reply	I-2	Reply	225
Var.	I-Reply	I-2	Reply	225
of 1st Deriv.	I-Reply	I-2	Reply	225
|  0.01600  |   0.00013	I-Reply	I-2	Reply	225
Var.	I-Reply	I-2	Reply	225
of 2nd Deriv.	I-Reply	I-2	Reply	225
|  0.03800  |   0.00017	I-Reply	I-2	Reply	225
<sep> Thus, in both cases, our temporal loss formulation leads to substantial improvements in terms of accuracy and stability.	I-Reply	I-2	Reply	225
This evaluation shows how well our algorithm approximates the ground-truth velocity, and that it generates very uniform and stable point clouds.	I-Reply	I-2	Reply	225
We will include these results in our revised paper (as Figure 9).	I-Reply	I-2	Reply	225

The paper introduces an approach, called ROLE, that extract symbolic structure from seq2seq networks.	O	O	Review	290
It also provides an interpretable symbolic structure and examines the causal information in the symbolic structure.	O	O	Review	290
<sep> <sep> The approach is inspired by the Tensor Product Encoder architecture.	O	O	Review	290
<sep> <sep> The scan role analysis part seemed the most hand-wavy with lots of positions in A.7.	O	O	Review	290
<sep> <sep> None of the accuracy results have variances attached to them.	B-Review	B-1	Review	290
<sep> <sep> I am not an expert on this topic (hence the weak accept), but I liked the paper.	O	O	Review	290
<sep> <sep> <sep> Hello, the current revision includes the mean accuracy across three runs, as well standard deviations.	B-Reply	B-1	Reply	290

In this paper, the authors study the problem of understanding the compositional generalization abilities of NNs.	O	O	Review	290
A new type of NN, called ROLE, is proposed to learns to approximate the representations of a target NN E by learning a symbolic constituent structure and an embedding of that structure intoE‚Äôs representational vector space.	O	O	Review	290
A number of tasks are conducted, including a simple fully-compositional task, a SCAN task, a partially-compositional NLP task.	O	O	Review	290
Multiple tasks.	O	O	Review	290
The experiment results show that the proposed approach can help to understand how NNs achieve strong generalization on partially-compositional tasks, and good performance on fully-compositional task.&nbsp;	O	O	Review	290
Pros:	O	O	Review	290
1.	O	O	Review	290
This work studies an important problem of&nbsp;fundamental AI.	O	O	Review	290
<sep> 2.	O	O	Review	290
Authors conduct experiments on multiple task to evaluate the effectiveness of the proposed technique and show how it helps to understand the generalization of NNs.	O	O	Review	290
<sep> 3.&nbsp;The overall paper is well written, except for some typos, e.g. in page 5, Table 1 Should "1.0" be "100%"?	B-Review	B-1	Review	290
Should "0.828 be ''82.80".&nbsp;&nbsp;	I-Review	I-1	Review	290
Cons:	O	O	Review	290
1.	O	O	Review	290
Regarding the Q2 raised in the paper, only simple suggestions are given.	B-Review	B-2	Review	290
It is suggested to evaluate its effectiveness on some real experiments.	I-Review	I-2	Review	290
Thank you for your helpful comments, which we incorporated into the revised paper we have  uploaded to OpenReview.	B-Reply	B-3	Reply	290
This contains a new Section A.8.2 of the Appendix, which makes several points of general importance in its substantial discussion of the algorithm ROLE implicitly uses to assign roles.	I-Reply	I-3	Reply	290
<sep> <sep> Please feel free to let us know if you spot any remaining unaddressed typos.	B-Reply	B-1	Reply	290
<sep> <sep> As for Table 1, the final column is the V-measure score, which ranges from 0 to 1.	I-Reply	I-1	Reply	290
This does have an interpretation similar to a percentage, but the literature tends to keep the value in this range of 0 to 1.	I-Reply	I-1	Reply	290
<sep> <sep> <sep> Because you raise a point also made by Reviewer 2, let us repeat our response here.	B-Reply	B-2	Reply	290
Regarding our suggestions for how improved understanding of the compositional structure of RNN representations might lead to improved future architectures, we agree that these were brief and tentative, so we have rephrased Sec.8 where we make more substantial suggestions for improving future models: ‚ÄúIn this work, we used ROLE to interpret the workings of a target encoder, and in future work, we plan to train ROLE in an end-to-end manner, either using it as the encoder itself, or using it to regularize a standard (e.g., RNN) encoder with a loss term that rewards learning compositional encodings, operationalized as encodings that ROLE can approximate well.	I-Reply	I-2	Reply	290
1 to focus the overview on the main issue addressed, a question of understanding: ‚ÄúHow do NNs achieve such strong generalization on partially-compositional tasks, and good performance on fully-compositional tasks?‚Äú We  have also expanded our concrete proposal for a ‚Äòfactorization bias‚Äô into a new Section A.11 of the Appendix, and have inserted additional text in Sec.	I-Reply	I-2	Reply	290
We will test whether such an explicit bias for compositionality allows networks to train faster, or with fewer parameters, and to achieve more systematic generalization.	I-Reply	I-2	Reply	290
Recent work showed improvements in compositionality by separating out syntax and semantics with attention (Russin et al 2019), and our results suggest that ROLE can also disentangle syntax and semantics.	I-Reply	I-2	Reply	290
‚Äù [p. 8]	I-Reply	I-2	Reply	290
<sep> Thank you for your review, which we believe has helped us to improve the paper considerably.	O	O	Reply	290
If you should have any further comments, they would be most welcome.	O	O	Reply	290

The authors proposed an interesting method for parameter-efficient transfer learning and multi-task learning.	O	O	Review	184
The authors show that in transfer learning fine-tuning the last layer plus BN layers significantly improve the performance of only fine-tuning the last layer.	O	O	Review	184
The results are surprisingly good and the authors also did analysis on the relationship between embedding space and biases.	O	O	Review	184
<sep> <sep> 1.	O	O	Review	184
The memory benefit is obvious, it would be interesting to know the training speed compared to fine-tuning methods (both the last layer and the entire network)?	B-Review	B-1	Review	184
<sep> 2.	O	O	Review	184
It seems that DW patch has limited effects compared to S/B patch.	B-Review	B-2	Review	184
It would be nice to have some analysis of this aspect.	I-Review	I-2	Review	184
<sep> <sep> We thank AnonReviewer3 for the review.	O	O	Reply	184
Below are our responses to specific comments.	O	O	Reply	184
<sep> <sep> > 1.	O	O	Reply	184
The memory benefit is obvious, it would be interesting to know the training speed compared to fine-tuning methods (both the last layer and the entire network)?	O	O	Reply	184
<sep> <sep> Generally, we did not see a large variation in training speed on the datasets that we tried.	B-Reply	B-1	Reply	184
All fine-tuning approaches needed 50-200K steps depending on the learning rate and the training method.	I-Reply	I-1	Reply	184
While different approaches definitely differ in the number of steps necessary for convergence, we find these changes to be comparable to changes in other hyper-parameters such as learning rate, and generally not providing a clear signal worth articulating in the paper.	I-Reply	I-1	Reply	184
<sep> <sep> > 2.	O	O	Reply	184
It seems that DW patch has limited effects compared to S/B patch.	O	O	Reply	184
It would be nice to have some analysis of this aspect.	O	O	Reply	184
<sep> <sep> Yes, DW patch seems to be less powerful than S/B patch.	B-Reply	B-2	Reply	184
Generally, DW patch resulted in about 5-10% percentage points lower accuracy than the S/B patch while having comparable number of parameters.	I-Reply	I-2	Reply	184
However, it does add a lot of value when used in conjunction with S/B patch.	I-Reply	I-2	Reply	184
For instance, from the top two figures in Figure 3, we see that fine-tuning the combination of DW and S/B patches (4% of the network parameters) closes the accuracy gap between S/B patch (1% of the network parameters) and fine-tuning the last layer (37% of the network parameters).	I-Reply	I-2	Reply	184
<sep> <sep> If the reviewer thinks that adding the performance of DW only patch would be a useful addition to Figure 3, we are happy to do that.	O	O	Reply	184
We had excluded it in the interest of not crowding the plots.	O	O	Reply	184

This paper explored the means of tuning the neural network models using less parameters.	O	O	Review	184
The authors evaluated the case where only the batch normalisation related parameters are fine tuned, along with the last layer, would generate competitive classification results, while using very few parameters comparing with fine tuning the whole network model.	O	O	Review	184
However, several questions are raised concerning the experiment design and analysis:	O	O	Review	184
1.	O	O	Review	184
Only MobilenetV2 and InceptionV3 are evaluated as classification model, while other mainstream models such as ResNet, DenseNet are not included.	B-Review	B-1	Review	184
Would it be very different regarding the conclusion of this paper?	I-Review	I-1	Review	184
<sep> 2.	O	O	Review	184
It seems that the only effective manner is by fine tuning the parameters of both batch normalisation related and lasts layer, while fine tuning last layer seems to be having the main impact on the final result.	B-Review	B-2	Review	184
In Table 4, authors do not even provide the results fine tuning last layer only.	I-Review	I-2	Review	184
<sep> 3.	O	O	Review	184
The organisation of the paper and the order of illustration is a bit confusing.	B-Review	B-3	Review	184
e.g. later sections are frequently referred in the earlier sections.	I-Review	I-3	Review	184
Personally I would prefer a plain sequence than keep turning pages for confirmation.	I-Review	I-3	Review	184
We thank AnonReviewer2 for the review.	O	O	Reply	184
Below is our detailed response.	O	O	Reply	184
<sep> <sep> > 1.	O	O	Reply	184
Only MobilenetV2 and InceptionV3 are evaluated as classification model, while the residual connection based models such as ResNet, DenseNet are not included.	O	O	Reply	184
Would it be very different regarding the conclusion of this paper?	O	O	Reply	184
<sep> <sep> We experimented extensively with multiple tasks (classification, detection, multi-task learning) and datasets instead of trying more models for the same task, as we intended to test the effectiveness of our method in various situations.	B-Reply	B-1	Reply	184
Further, MobileNetV2 has residual connections, which encouraged us to believe that the results on other residual connection based models would be similar.	I-Reply	I-1	Reply	184
<sep> <sep> We ran experiments with ResNet and got similar results.	I-Reply	I-1	Reply	184
For instance, transfer learning accuracy from ImageNet to Cars goes up from 61.4% (last layer fine-tuning) to 73% (S/B patch + last layer fine-tuning).	I-Reply	I-1	Reply	184
From ImageNet to Aircraft, accuracy goes up from 51.8% (last layer) to 62.5% (S/B patch + last layer).	I-Reply	I-1	Reply	184
In the interest of space, we did not think it added much to the experimental section of the paper.	I-Reply	I-1	Reply	184
<sep> <sep> > 2.	O	O	Reply	184
It seems that the only effective manner is by fine tuning the parameters of both batch normalisation related and lasts layer, while fine tuning last layer seems to be having the main impact on the final result.	O	O	Reply	184
In Table 4, authors do not even provide the results fine tuning last layer only.	O	O	Reply	184
<sep> <sep> Fine-tuning the last layer is not always required.	B-Reply	B-2	Reply	184
For instance, in domain adaptation (Sec 5.4), the model patch consists of only the batch normalization parameters, and the resulting accuracies match or exceed those of individually trained models.	I-Reply	I-2	Reply	184
<sep> <sep> From Figure 3 and Table 4, we see that fine-tuning scales, biases (S/B) and depthwise (DW) along with last layer causes an average 50% relative improvement in accuracy over fine-tuning only the last layer while being only a small (4%) increase in terms of number of parameters over the last layer.	I-Reply	I-2	Reply	184
<sep> <sep> When performing multi-task or transfer learning across different tasks (e.g. ImageNet ‚Üí Places365), it becomes necessary to have different last layers as the output spaces are different.	I-Reply	I-2	Reply	184
In Table 4, the second column corresponds to the case where only the last layer is separate for each task.	I-Reply	I-2	Reply	184
We apologize if this was not clear - we have now updated Table 4 headers to explicitly reflect this fact.	I-Reply	I-2	Reply	184
<sep> > 3.	O	O	Reply	184
The organisation of the paper and the order of illustration is a bit confusing.	O	O	Reply	184
<sep> <sep> We will be happy to modify the paper if the reviewer elaborates on this point.	B-Reply	B-3	Reply	184

Summary: the paper introduces a new way of fine-tuning neural networks.	O	O	Review	184
Instead of re-training the whole model or fine-tuning the last few layers, the authors propose to fine-tune a small set of model patches that affect the network at different layers.	O	O	Review	184
The results show that this way of fine-tuning is superior to above mentioned typical ways either in accuracy or in the number of tuned parameters in three different settings: transfer learning, multi-task learning and domain adaptation.	O	O	Review	184
<sep> <sep> Quality: the introduced way of fine-tuning is interesting alternative to the typical last layer re-training.	O	O	Review	184
I like that the authors present an intuition behind their approach and justify it by an illustrative example.	O	O	Review	184
The experiments are fair, assuming the authors explain the choice of hyper-parameters during the revision.	O	O	Review	184
<sep> <sep> Clarity: in general the paper is well-written.	O	O	Review	184
The discussion of multi-task and domain adaptation parts can be improved though.	O	O	Review	184
<sep> <sep> Originality: the contributions are novel to my best knowledge.	O	O	Review	184
<sep> <sep> Significance: high, I believe the paper may facilitate a further developments in the area.	O	O	Review	184
<sep> <sep> I ask the authors to address the following during the rebuttal stage:	O	O	Review	184
* explain the choice of the hyper-parameters of RMSProp (paragraph under Table 1).	B-Review	B-1	Review	184
<sep> * fix Figure 3, it's impossible to read in the paper-printed version	B-Review	B-2	Review	184
* explain how the average number of parameters per model in computed in Tables 4 and 5.	B-Review	B-3	Review	184
E.g. 700K params/model in the first column of Table 4 is misleading - I suppose the shared parameters are not taken into account.	I-Review	I-3	Review	184
The same holds for 0 in the second column, etc.	I-Review	I-3	Review	184
<sep> * add a proper discussion for domain adaptation part.	B-Review	B-4	Review	184
The simple "The results are shown in Table 5" is not enough.	I-Review	I-4	Review	184
<sep> * consider leaving the discussion of cost-efficient model cascades out.	B-Review	B-5	Review	184
The presented details are too condensed and do not add value to the paper.	I-Review	I-5	Review	184
<sep> * explain how different resolutions are managed by the same model in the domain adaptation experiments.	B-Review	B-6	Review	184
We thank AnonReviewer1 for the review.	O	O	Reply	184
Below are our responses inline.	O	O	Reply	184
<sep> <sep> > * explain the choice of the hyper-parameters of RMSProp (paragraph under Table 1).	O	O	Reply	184
<sep> <sep> The hyper-parameters are the same as those in the standard setup for MobilenetV2 or InceptionV3.	B-Reply	B-1	Reply	184
We have added a line in the experiments section mentioning this.	I-Reply	I-1	Reply	184
<sep> <sep> > * fix Figure 3, it's impossible to read in the paper-printed version	O	O	Reply	184
<sep> The four subfigures are now split into two rows and are now hopefully easily readable.	B-Reply	B-2	Reply	184
<sep> <sep> > * explain how the average number of parameters per model in computed in Tables 4 and 5.	O	O	Reply	184
E.g. 700K params/model in the first column of Table 4 is misleading - I suppose the shared parameters are not taken into account.	O	O	Reply	184
The same holds for 0 in the second column, etc.	O	O	Reply	184
<sep> <sep> Thank you for pointing this out.	B-Reply	B-3	Reply	184
We had mistakenly only counted the non-shared parameters in the models, and forgot to include the last layer parameters in the second column.	I-Reply	I-3	Reply	184
This has now been corrected to simply the total number of parameters trained.	I-Reply	I-3	Reply	184
<sep> <sep> > * add a proper discussion for domain adaptation part.	O	O	Reply	184
The simple "The results are shown in Table 5" is not enough.	O	O	Reply	184
<sep> <sep> Done.	B-Reply	B-4	Reply	184
<sep> <sep> > * consider leaving the discussion of cost-efficient model cascades out.	O	O	Reply	184
The presented details are too condensed and do not add value to the paper.	O	O	Reply	184
<sep> <sep> Makes sense.	B-Reply	B-5	Reply	184
We moved these results to the appendix to be included in the full version.	I-Reply	I-5	Reply	184
<sep> <sep> > * explain how different resolutions are managed by the same model in the domain adaptation experiments.	O	O	Reply	184
<sep> <sep> We added a line in the paper stating the images are brought to the right resolution using bilinear interpolation before passing as input to each model.	B-Reply	B-6	Reply	184

Summary:	O	O	Review	184
The authors take two tasks,sentiment analysis and natural language inference, and identify datasets for them which they counterfactually augment it by asking people over the Amazon Mechanical Turk Platform to change either the sentiment (in the case of sentiment analysis) or the nature of relationship in the NLI task by making minimal changes to the text that produce the targeted changes.	O	O	Review	184
<sep> <sep> Authors find that popular models trained on either fail on the other dataset while the models trained on both actually generalize much better.	O	O	Review	184
This is because the original sample and its counterfactual pair the label changed , has the difference in the text that matters to the change and this pair could reduce spurious correlations that models might find in the data distribution.	O	O	Review	184
<sep> <sep> Pros:	O	O	Review	184
This is a very interesting experiment and certainly the dataset that will be released would be extremely valuable to the community.	O	O	Review	184
The one part (I dont have much NLP background but I do have a causality background) that I like most is that the new text generated are counterfactual in some real sense with respect to a real world generating process - that is people modifying text with changed targets.	O	O	Review	184
<sep> <sep> A lot of existing work that claim to do counterfactual changes do not specify assumptions about the generating mechanism.	O	O	Review	184
For counterfactuals to be valid they have to be intervention on the actual generating mechanism (or an assumed one) acting on a given unit (latent) that produced the current sample.	O	O	Review	184
The paper in that respect (even if it does not explicitly specify relationship between counterfactuals and generating mechanisms) tries to be faithful to a "strict causal notion" by actually asking people to modify the text.	O	O	Review	184
<sep> <sep> Cons:	O	O	Review	184
- I think the authors want to make an explicit connection to counterfactuals as understood in the causality community.	B-Review	B-1	Review	184
Then they shy away from it saying they are inspired by it.	I-Review	I-1	Review	184
May be a formal exposition in the supplement about counterfactuals and generating mechanisms could help readers from other communities (NLP) even it means repeating standard/synthetic examples.	I-Review	I-1	Review	184
Its good to say what exactly in a counterfactual generation process, the "people" in amazon turk were substituting.	I-Review	I-1	Review	184
<sep> <sep> -  Is the romantic/ horror flips and their absence the only spurious thing in Figure 4 ?	B-Review	B-2	Review	184
<sep> -  In figure 6, it appears that BERT is sensitive to the domain - does it mean that it is bad ? -	B-Review	B-3	Review	184
Authors indicate that ideally it must not be so.	I-Review	I-3	Review	184
Because Table 3 results seem to indicate that BERT performs the best in almost all the cases .	I-Review	I-3	Review	184
<sep> -  Can the authors highlight the best performances in each case in the Tables by a bold face.	B-Review	B-4	Review	184
It helps easily eye ball the best performing model.	I-Review	I-4	Review	184
<sep> Thank you for the thoughtful review and positive assessment.	O	O	Reply	184
We are glad to see that you appreciate the genuine flavor of causality in our paper and support our paper‚Äôs acceptance.	O	O	Reply	184
<sep> <sep> We agree that a formal exposition introducing an NLP/deep learning audience to the basics of interventions and counterfactuals and expressing a toy DAG to explain the spurious associations between the review sentiment and the manifestation in text of other attributes of the review, including but not limited to the genre, actors, budget, etc.	B-Reply	B-1	Reply	184
We are actively working on preparing this exposition and while it is not yet in the draft we plan to have it prepared in advance of the camera-ready version.	I-Reply	I-1	Reply	184
<sep> <sep> We thank the reviewer for pointing out that we should have been more thorough in explaining that while genre is a clear example of such a spurious association, it is far from the only one captured in Figure 4.	B-Reply	B-2	Reply	184
Indeed, many other words, including ‚Äúwill‚Äù, ‚Äúmy‚Äù, ‚Äúhas‚Äù, ‚Äúespecially‚Äù, ‚Äúlife‚Äù, ‚Äúworks‚Äù, ‚Äúboth‚Äù, ‚Äúit‚Äù, ‚Äúits‚Äù, ‚Äúlives‚Äù, ‚Äúgives‚Äù, ‚Äúown‚Äù, ‚Äújesus‚Äù, ‚Äúcannot‚Äù, ‚Äúeven‚Äù, ‚Äúinstead‚Äù, ‚Äúminutes‚Äù, ‚Äúyour‚Äù, ‚Äúeffort‚Äù, ‚Äúscript‚Äù, ‚Äúseems‚Äù, and ‚Äúsomething‚Äù, appear to be spuriously associated with sentiment and are captured by the original-only and revised-only classifiers as highly-weighted features.,	I-Reply	I-2	Reply	184
Notably all of these features fall out from the highly-weighted features when our classifier is trained on counterfactually-augmented data.	I-Reply	I-2	Reply	184
<sep> <sep> Regarding the sensitivity of BERT models, Table 9 shows the ability of a model explicitly trained to differentiate between the original and the revised data.	B-Reply	B-3	Reply	184
This is to shed some insight on how much the two differ (on account of our intervention).	I-Reply	I-3	Reply	184
Because the two indeed are different, we expect that a model should be able to differentiate them to some degree.	I-Reply	I-3	Reply	184
We note that a model class‚Äôs ability to differentiate between the original and revised data when explicitly trained to do so may not necessarily be correlated with how susceptible that model is to breaking when evaluated out of sample.	I-Reply	I-3	Reply	184
<sep> <sep> We‚Äôre grateful for your comments on exposition and will continue to address these points as we improve the draft.	O	O	Reply	184

This paper addresses the problem of building models for NLP tasks that are robust against spurious correlations in the data by introducing a human-in-the-loop method: annotators are asked to modify data-points minimally in order to change the label.	O	O	Review	184
They refer to this process as counterfactual augmentation.	O	O	Review	184
The authors apply this method to the IMDB sentiment dataset and to SNLI and show (among other things) that many models cannot generalize from the original dataset to the counterfactually-augmented one.	O	O	Review	184
<sep> <sep> This contribution is timely and addresses a very important problem that needs to be addressed in order to build more robust NLP systems.	O	O	Review	184
<sep> <sep> Because, however, of a few limitations, I recommend weak acceptance.	O	O	Review	184
<sep> <sep> My main hesitation comes from a lack of clarity about the main lesson we have learned.	B-Review	B-1	Review	184
In particular, if the goal is to use this method to augment the data we use to train NLP systems in order to make them more robust, it seems that the time cost of the process will be prohibitive.	I-Review	I-1	Review	184
On the other hand, perhaps these methods could be used to identify the kind of spurious correlations that models tend to rely on, which could then be used in a more automated data augmentation process.	I-Review	I-1	Review	184
If that's the goal, however, a more detailed error analysis would need to be included.	I-Review	I-1	Review	184
<sep> <sep> A few small comments:	O	O	Review	184
<sep> * There was some analysis of the augmented IMDB dataset, but none of the SNLI dataset.	B-Review	B-2	Review	184
I would love to see a more detailed investigation of what annotators usually did.	I-Review	I-2	Review	184
For instance, a reason that hypothesis-only models do well is that certain words are very predictive of certain labels (e.g. "not" and contradiction).	I-Review	I-2	Review	184
Do people leave the negations in when modifying such examples for entailment or neutrality, thus breaking the simple correspondence?	I-Review	I-2	Review	184
That's a very simple kind of question; more generally, I'd like to see more analysis of the new dataset.	I-Review	I-2	Review	184
<sep> <sep> * The BiLSTM they use is very small (embedding and hidden dimension 50).	B-Review	B-3	Review	184
Given that BERT is most robust against their manipulation, it would be good to see a more powerful recurrent model for comparison.	I-Review	I-3	Review	184
It would be easy to use ELMo here, if the main question is about Transformers vs recurrent models.	I-Review	I-3	Review	184
<sep> <sep> <sep> Some very minor / typographic comments:	O	O	Review	184
<sep> * abstract: "with revise" should be "with revising"	B-Review	B-4	Review	184
* first paragraph page 2: some references to causality literature and definition of spuriousness as common cause	I-Review	I-4	Review	184
* page 2, "We show that..." I'd break this into two sentences to make it easier to parse.	I-Review	I-4	Review	184
<sep> * Table 3: I would make two columns for each model with accuracy on original versus revised.	I-Review	I-4	Review	184
With the current table, one has to compare cells in the top half of the table to those in the bottom half of the table, which is quite difficult to do.	I-Review	I-4	Review	184
Thanks for the detailed and thoughtful review.	O	O	Reply	184
We are glad that you think of this paper as a timely contribution addressing an important problem that must be addressed in order to build more robust NLP systems.	O	O	Reply	184
<sep> <sep> We agree with your point that it would be great to have a practical takeaway guiding practitioners for what to do in practice.	B-Reply	B-1	Reply	184
We believe that the first step here is to characterize the problem coherently and that having laid this groundwork, one immediate next step is, as you suggest, to develop a more practical solution that requires a less expensive/onerous annotation effort.	I-Reply	I-1	Reply	184
<sep> <sep> The key contribution of our paper is to provide a clear characterization of a variety of concerns in the language of interventions and to demonstrate that indeed, they can be addressed by acquiring interventional data.	I-Reply	I-1	Reply	184
The knowledge that (i) NLP models trained on counterfactually augmented data suffer less from these problems and (ii) transport better out of sample (see new results in the updated draft, per R3‚Äôs suggestion) validates this.	I-Reply	I-1	Reply	184
<sep> <sep> As you mentioned, our solution requires significant expenditure (both financial and human capital) compared to simply labeling data.	I-Reply	I-1	Reply	184
As a follow-up, for existing datasets, our next steps include investigating how to make these adjustments in a cost-effective way.	I-Reply	I-1	Reply	184
In preliminary work, we have been investigating how to use humans in the loop more effectively.	I-Reply	I-1	Reply	184
One approach involves using generative models to propose candidate substitutions and relying on humans only accept or reject the revisions (vs having to write them from scratch).	I-Reply	I-1	Reply	184
Our experience with crowdsourcing suggests that this feedback would be significantly cheaper to collect (provided that a reasonable fraction of suggestions were appropriate).	I-Reply	I-1	Reply	184
<sep> <sep> We additionally note that for some tasks, such as NLI, creating new datasets already requires annotators to synthesize examples de novo and the fractional increase for soliciting counterfactually-augmented data might not be as onerous as compared to tasks where the default is to rely on annotators only for tags.	B-Reply	B-2	Reply	184
<sep> <sep> We are also appreciative of your constructive suggestions to improve the paper, and have taken several steps to improve the draft.	B-Reply	B-4	Reply	184
These include updating the draft to include (i) a detailed analysis of edits performed on SNLI, (ii) results on various datasets using an ELMo based classifier; (iii) concerning your question about larger Bi-LSTMs, we had tried a large Bi-LSTM but it overfit badly.	I-Reply	I-4	Reply	184
We have updated the draft to include this detail.	I-Reply	I-4	Reply	184
<sep> <sep> Thanks also for catching several typographic errors.	O	O	Reply	184
We have addressed them in the new draft.	O	O	Reply	184

The authors propose a new way to augment textual datasets for the task of sentiment analysis, in order to help the learning methods to generalize better by concentrating on learning the different that makes a difference.	O	O	Review	184
The main idea of the paper is to augment existing datasets with minimally counteractual versions of them, that change the sentiment of the documents.	O	O	Review	184
In this way, all spurious factors will naturally cancel out.	O	O	Review	184
The authors use the newly created datasets and show that indeed, the retrained algorithms on the augmented datasets generalize much better.	O	O	Review	184
<sep> <sep> The main contribution of the paper is the introduction of the idea of counterfactual datasets for sentiment analysis.	O	O	Review	184
<sep> <sep> Overall, I find the idea of the paper quite interesting and I‚Äôm excited to use the datasets they have created.	B-Review	B-1	Review	184
However, I think the relative novelty of the paper does not meet ICLR standards, and it‚Äôs better suited as a whitepaper attached to an open dataset release.	I-Review	I-1	Review	184
We thank the reviewer for taking the time to consider our paper and appreciate that you are excited to use our counterfactually-augmented dataset.	O	O	Reply	184
<sep> <sep> While degrees of novelty and the relevant sorts of novelty are a matter of opinion we respectfully assert our view that new ideas, the new resource that we present, and the scientific insights derived from our experiments, are precisely the sorts of novelty that should be sought by conferences.	B-Reply	B-1	Reply	184
<sep> <sep> We respectfully disagree with the reviewer‚Äôs suggestion that a fundamentally distinct resource warrants only a whitepaper.	I-Reply	I-1	Reply	184
We politely point out that many conferences have entire dedicated tracks, and even best paper awards for resources, and that many seminal papers of pivotal importance to the field make precisely this sort of contribution (e.g. ImageNet).	I-Reply	I-1	Reply	184
<sep> <sep> Additionally we point out that the resource is not the only novel idea here.	I-Reply	I-1	Reply	184
Of chief importance here is the intellectual contribution casting the problem of learning ‚Äúsuperficial associations‚Äù coherently in the language of intervention, and producing a dataset that addresses counterfactuals in a real sense (as pointed out more eloquently by R1).	I-Reply	I-1	Reply	184
Moreover, our experiments shed insights about the price to be paid for relying less on spurious associations and our updated experiments (inspired by R3‚Äôs suggestions) show that our methods result in improved performance out-of-sample on a variety of datasets.	I-Reply	I-1	Reply	184
<sep> <sep> We hope that you might be willing to reconsider our contributions in light of the significance and uniqueness of the dataset, the insights of our experiments and the demonstrated out-of-domain robustness.	I-Reply	I-1	Reply	184

This paper seeks to separate "causal" features from ones with spurious correlations in the context of natural language machine learning tasks.	O	O	Review	184
The proposed approach is to ask human annotators to alter examples in a minimal way that changes the label.	O	O	Review	184
Thereby the humans separate out the causal features (those changed) from the spurious or irrelevant features (those left unchanged).	O	O	Review	184
<sep> <sep> Experiments show that classifiers trained on the original data perform poorly on the altered data and vice versa, but (unsurprisingly) training on the union of the two datasets results in a classifier that performs well in both cases.	O	O	Review	184
Furthermore, training an SVM on the original results in irrelevant attributes (such as movie genre) being weighted, whereas these weights are largely removed when training on the union of the datasets.	O	O	Review	184
This suggests that the augmented training data results in weighting the "right" features more.&nbsp;	O	O	Review	184
<sep> Overall, I think this paper should be accepted because it makes several interesting contributions: It proposes an interesting approach, shows intriguing experimental results, and produces an interesting dataset (size ~2k) that may be useful for future testing.	O	O	Review	184
<sep> <sep> The main limitation of the paper is that the evidence is largely circumstantial.	B-Review	B-1	Review	184
The method has intuitive appeal and the experimental results are suggestive, but the experiments do not conclusively show that the method achieves something that ordinary machine learning does not.	I-Review	I-1	Review	184
<sep> <sep> My suggestion for a further experiment would be to apply the movie review classifiers to, say, book reviews -- something where the task is fundamentally the same but the context is different.	B-Review	B-2	Review	184
If the classifier trained on the union of the original and altered datasets performs better than a classifier trained on only on dataset, then that is strong evidence that this approach yields better extrapolation.	I-Review	I-2	Review	184
<sep> <sep> We thank the reviewer for positive feedback and for championing our paper.	B-Reply	B-1	Reply	184
We are also grateful for your constructive suggestions to improve the paper and would like to report on how we have incorporated your feedback.	B-Reply	B-2	Reply	184
Inspired by your suggestion, we conducted additional experiments on Amazon Reviews, Yelp Reviews, and Semeval (Twitter) datasets, and found that the counterfactually-augmented data resulted in across-the-board gains.	I-Reply	I-2	Reply	184
These experiments are featured in the updated draft.	I-Reply	I-2	Reply	184

The authors present the interesting and important direction in searching better network architectures using the genetic algorithm.	B-Review	B-10	Review	773
Performance on the benchmark datasets seems solid.	O	O	Review	773
Moreover, the learned insights described in Section 4.4 would be very helpful for many researchers.	O	O	Review	773
<sep> <sep> However, the overall paper needs to be polished more.	B-Review	B-9	Review	773
There are two many typos and errors that imply that the manuscript is not carefully polished.	I-Review	I-9	Review	773
Explanations about some terms like growth rate, population, etc.	I-Review	I-9	Review	773
are necessary for broader audience.	I-Review	I-9	Review	773
<sep> <sep> More importantly, while some of step jumps in Figure 6~9 are suspicious, it turns out that all the step jumps happen at the same number of steps, which are identical to the change of learning rates described in Section 4.2.	B-Review	B-8	Review	773
Thee clear explanation about that phenomena is required.	I-Review	I-8	Review	773
<sep> <sep> * Details	O	O	Review	773
- Please represent the blocks (e.g. 1*1conv) better.	B-Review	B-1	Review	773
Current representation is quite confusing to read.	I-Review	I-1	Review	773
Maybe proper spacing and different style of fonts may help.	I-Review	I-1	Review	773
<sep> - In Page 5, "C_{m}ax" is a typo.	B-Review	B-2	Review	773
It should be "C_{max}".	I-Review	I-2	Review	773
<sep> - Regarding the C_max, does sum(C_max) represent (D * W)^2 where D is the total depth and W is the total indicies in each layer?	B-Review	B-3	Review	773
If so, specifying it will help.	I-Review	I-3	Review	773
Otherwise, please explain its meaning clearly.	I-Review	I-3	Review	773
<sep> - In Figure 4(a), it would be better if we reuse M_{d,w} notation instead of Module {d_w}.	B-Review	B-4	Review	773
- Please briefly explain or provide references to the terms like "growth rate", "population", and "individuals".	B-Review	B-5	Review	773
<sep> - Different mutations may favor different hyper-parameters.	B-Review	B-6	Review	773
How the authors control the hyperparameters other than the number of epochs will be useful to know.	I-Review	I-6	Review	773
<sep> - Even though the sparse connection is enforced for some reasons, overfitting, variance, or any other benefits that slim structure can bring in has not been evaluated.	B-Review	B-7	Review	773
They need to be presented to verify the hypothesis that the authors claim.	I-Review	I-7	Review	773
<sep> <sep> First of all, thank you very much for writing a detailed review of our paper!	O	O	Reply	773
<sep> We are excited with the positive and enthusiastic support of our core experiments.	O	O	Reply	773
<sep> <sep> We feel very sorry for the typos and grammar mistakes in our previous version.	B-Reply	B-9	Reply	773
After a long time of proofreading and revising, we believe that the current version is much better.	I-Reply	I-9	Reply	773
For instance, we have provided brief explanations with references of terms like ‚Äògrowth rate‚Äô and ‚Äòpopulation‚Äô in our current version as suggested by you.	I-Reply	I-9	Reply	773
<sep> <sep> Moreover, we have added a clear explanation about step jumps in Figures 6~9 in our experiment section.	B-Reply	B-8	Reply	773
Yes, these step jumps are caused by the change of learning rates.	I-Reply	I-8	Reply	773
As we use same learning-rate change strategy in all experiments, the step jumps of all experiments happen at the same epochs.	I-Reply	I-8	Reply	773
We originally thought it was a common phenomenon.	I-Reply	I-8	Reply	773
Thanks to your advice, we have added an explanation of this phenomenon in our experiment section.	I-Reply	I-8	Reply	773
<sep> As we have corrected all of the typos and errors that we can find, we believe that this paper is still worth being seen by more people.	O	O	Reply	773
<sep> <sep> Our direction is not merely using genetic algorithm to search network structure, but also is about the internal dense and external sparse network structures.	B-Reply	B-10	Reply	773
How to combine the trend of being dense and being sparse is an interesting area.	I-Reply	I-10	Reply	773
Moreover, the internal dense and external sparse structure also coincides with the modularity observed in human brain.	I-Reply	I-10	Reply	773
As such, we believe this paper together with its research insights might be helpful to those who want to build hierarchical network structures.	I-Reply	I-10	Reply	773
We really put a lot of work in this paper.	I-Reply	I-10	Reply	773
It might not be perfect right now, but we think it‚Äôs worth being seen by more people.	I-Reply	I-10	Reply	773
<sep> <sep> Problem:	O	O	Reply	773
<sep> "Please represent the blocks (e.g. 1*1conv) better.	O	O	Reply	773
Current representation is quite confusing to read.	O	O	Reply	773
Maybe proper spacing and different style of fonts may help"	O	O	Reply	773
<sep> Answer:	O	O	Reply	773
<sep> Thank you very much for this suggestion!	B-Reply	B-1	Reply	773
We have used a specific format and another font to improve the represents of blocks.	I-Reply	I-1	Reply	773
For example on page 5.	I-Reply	I-1	Reply	773
Section Long Distance Connections.	I-Reply	I-1	Reply	773
We‚Äôve corrected this part and updated the paper.	I-Reply	I-1	Reply	773
<sep> Problem:	O	O	Reply	773
<sep> "In Page 5, "C_{m}ax" is a typo.	O	O	Reply	773
It should be "C_{max}‚Äù."	O	O	Reply	773
<sep> <sep> Answer:	O	O	Reply	773
<sep> Thank you very much for pointing out the typo.	B-Reply	B-2	Reply	773
We‚Äôve corrected it and updated the paper accordingly.	I-Reply	I-2	Reply	773
<sep> Problem:	O	O	Reply	773
<sep> "Regarding the C_max, does sum(C_max) represent (D * W)^2 where D is the total depth and W is the total indicies in each layer?	O	O	Reply	773
If so, specifying it will help.	O	O	Reply	773
Otherwise, please explain its meaning clearly."	O	O	Reply	773
<sep> <sep> Answer:	O	O	Reply	773
<sep> The element of this matrix only denotes whether there is a connection or not, and sum (C_max) and sum (C_i) just denote the summation of all elements‚Äô values in the matrix.	B-Reply	B-3	Reply	773
<sep> For example, if the element C_i[M_11,M_21] equals to 1, it means M_11 and M_21 are connected to each other.	I-Reply	I-3	Reply	773
Our original thought is that sum(C_i) denotes the number of the connections in C_i, so it‚Äôs just simply the summation of all elements‚Äô value in the matrix.	I-Reply	I-3	Reply	773
In this case, density D is between 0 and 1, where D_max=sum(C_max)/sum(C_max) reaches value 1.	I-Reply	I-3	Reply	773
Thank you for the advice, we‚Äôve illustrated it more clearly and updated the paper.	I-Reply	I-3	Reply	773
<sep> <sep> Problem: "In Figure 4(a), it would be better if we reuse M_{d,w} notation instead of Module {d_w}."	O	O	Reply	773
<sep> Answer: We‚Äôve correct this part and updated the paper for all similar images.	B-Reply	B-4	Reply	773
<sep> <sep> Problem: "Please briefly explain or provide references to the terms like "growth rate", "population", and "individuals‚Äù."	O	O	Reply	773
<sep> <sep> Answer: Thank you very much for the advice!	B-Reply	B-5	Reply	773
We‚Äôve provided references to the concepts, ‚Äògrowth rate‚Äô, ‚Äòpopulation‚Äô and ‚Äòindividual‚Äô and updated the paper.	I-Reply	I-5	Reply	773
<sep> <sep> Growth rate k is a concept in the paper "Densely Connected Convolutional Neural networks".	I-Reply	I-5	Reply	773
The l_{th} layer has k0 + k √ó (l ‚àí 1) input feature-maps according to paper [1], where k0 is the number of channels in the input layer.	I-Reply	I-5	Reply	773
In that case growth rate k denotes how fast the feature maps will growth when the depth increases.	I-Reply	I-5	Reply	773
Population and individual are concepts in genetic algorithm.	I-Reply	I-5	Reply	773
Candidate solutions are called individuals or phenotypes.	I-Reply	I-5	Reply	773
A population of individuals is called ‚Äòpopulation‚Äô.	I-Reply	I-5	Reply	773
<sep> <sep> Problem: "Different mutations may favor different hyper-parameters.	O	O	Reply	773
How the authors control the hyperparameters other than the number of epochs will be useful to know."	O	O	Reply	773
<sep> <sep> Answer: We think different mutations may favor different hyper-parameters, too.	B-Reply	B-6	Reply	773
But we didn‚Äôt get a discipline of how different hyper-parameters will influence the model so far.	I-Reply	I-6	Reply	773
We keep the hyper parameters the same during the whole experiment section, and the hyper-parameters are presented in first paragraph of Section 4.2.	I-Reply	I-6	Reply	773
Our experiments show that weight decay 5*10^-4 is better than 1* 10^-4, so we suggested 5*10^-4 in our paper.	I-Reply	I-6	Reply	773

The problem is of increasing practical interest and importance.	O	O	Review	773
<sep> <sep> The ablation study on the contribution and effects of each constituent  part is a strong part of the experiment section and the paper.	O	O	Review	773
<sep> <sep> One major concern is about the novelty of the work.	B-Review	B-1	Review	773
There are many similar works under the umbrella of Neural Architecture search who are trying to connect different building blocks (modules) to build larger CNNs.	I-Review	I-1	Review	773
One example that explicitly makes sparse connections between them is [1]. Other examples of very similar works are [2,3,4].	I-Review	I-1	Review	773
<sep> The presentation of the paper can be improved a lot.	B-Review	B-3	Review	773
In the current setup it‚Äôs very similar to a collection of ideas and tricks and techniques combined together.	I-Review	I-3	Review	773
<sep> <sep> There are some typos and errors in the writing.	B-Review	B-2	Review	773
A thorough grammatical  proofreading is necessary.	I-Review	I-2	Review	773
<sep> <sep> In conclusion there is a claim about tackling overfitting.	B-Review	B-4	Review	773
It‚Äôs not well supported or discussed in the experiments.	I-Review	I-4	Review	773
<sep> <sep> [1] Shazeer, Noam, et al "Outrageously large neural networks: The sparsely-gated mixture-of-experts layer."	O	O	Review	773
arXiv preprint arXiv:1701.06538 (2017).	O	O	Review	773
<sep> [2] Xie, Lingxi, and Alan L. Yuille. "	O	O	Review	773
Genetic CNN."	O	O	Review	773
ICCV.	O	O	Review	773
2017.	O	O	Review	773
<sep> [3] Real, Esteban, et al "Large-scale evolution of image classifiers."	O	O	Review	773
arXiv preprint arXiv:1703.01041 (2017).	O	O	Review	773
<sep> [4] Liu, Hanxiao, et al "Hierarchical representations for efficient architecture search."	O	O	Review	773
arXiv preprint arXiv:1711.00436 (2017).	O	O	Review	773
<sep> <sep> We are very excited about the positive and enthusiastic support of our core idea.	O	O	Reply	773
Thank you for your feedback about our strong part.	O	O	Reply	773
We totally agree with you that our strong part is Section 4.4.	O	O	Reply	773
<sep> About your main concerns:	O	O	Reply	773
We belive we have enough novelty for our work.	O	O	Reply	773
<sep> Paper [2] claimed that they use a genetic algorithm for searching network structures.	B-Reply	B-1	Reply	773
As I understand, their work mostly concentrates on searching skip connections of layers.	I-Reply	I-1	Reply	773
As it is shown in Fig.2 in [2], the optimization object is only connections between layers, however, strictly speaking, they didn‚Äôt change the structure of the network.	I-Reply	I-1	Reply	773
Our focus is combining the locally dense and externally sparse property of the human brain into the neural network.	I-Reply	I-1	Reply	773
Our optimization object is sparse connections between dense modules.	I-Reply	I-1	Reply	773
In our paper, we figure out a method to achieve local density and global sparsity and demonstrate it with our solid experiments.	I-Reply	I-1	Reply	773
We have typical hierarchical structures, and our experiment figures out how different parts of the network will influence the final result.	I-Reply	I-1	Reply	773
Yes, many papers could use genetic algorithms, but they all have their own contributions.	I-Reply	I-1	Reply	773
Moreover, according to the experiment part in page 8 of [2], we acquire more solid experiment results.	I-Reply	I-1	Reply	773
As these two papers have different core ideas, we believe that our paper have enough novelty.	I-Reply	I-1	Reply	773
<sep> Paper [3] focuses on minimizing human participation as much as possible.	I-Reply	I-1	Reply	773
They search all parameters including learning rate, identity, reset weights, insert & remove convolutions.	I-Reply	I-1	Reply	773
We think paper [3] has the same motivation and idea as paper [2] that reduce human participation as much as possible.	I-Reply	I-1	Reply	773
We think paper [3] is even better than paper [2] as they are in the same direction.	I-Reply	I-1	Reply	773
<sep> Our motivation is different from these two papers.	I-Reply	I-1	Reply	773
Our focus is combining locally dense and globally sparse properties of network structures.	I-Reply	I-1	Reply	773
We do analysis about how different parts of the network or the different types of connections will influence the final performance in Section 4.4.	I-Reply	I-1	Reply	773
<sep> Paper [4] has a similar idea of hierarchical structures as our paper.	I-Reply	I-1	Reply	773
But our basic elements are modules which contain several dense layers.	I-Reply	I-1	Reply	773
We notice that in their paper, evolving algorithm could form cliques in the end.	I-Reply	I-1	Reply	773
We think it might have some interesting conclusions if they look into properties like density and which connections are important.	I-Reply	I-1	Reply	773
We think searching network structure is a big topic.	I-Reply	I-1	Reply	773
It worth many good papers on this topic.	I-Reply	I-1	Reply	773
But all of them have different contributions.	I-Reply	I-1	Reply	773
<sep> Different from their work, we focus on the implement of human-like locally dense but externally sparse structures in our paper.	I-Reply	I-1	Reply	773
And we make a detailed analysis of how each long-distance connection will influence the final result.	I-Reply	I-1	Reply	773
<sep> Paper [1] is a good NLP paper with special layers and searching strategy.	I-Reply	I-1	Reply	773
This paper is also under the network search topic.	I-Reply	I-1	Reply	773
But we focus on totally different aspects.	I-Reply	I-1	Reply	773
<sep> Thank you for mentioning some typos and grammar mistakes.	B-Reply	B-2	Reply	773
We apologize for this.	I-Reply	I-2	Reply	773
We spend a lot of time doing several rounds of proofreading and revising.	I-Reply	I-2	Reply	773
We hope this version may make you feel better.	I-Reply	I-2	Reply	773
<sep> In all, although there are some papers having similar topics to our paper (network searching, hierarchical network structures, network pruning), we think a good topic worth many good papers to contribute to it.	B-Reply	B-1	Reply	773
Also, we think we have enough novelty as present above.	I-Reply	I-1	Reply	773
In that case, we think it worth to be accepted.	I-Reply	I-1	Reply	773
Thank you very much.	I-Reply	I-1	Reply	773

The current paper proposes using Graph Convolutional Networks (GCN) to explicitly represent and use relational data in dialog modeling, as well an attention mechanism for combining information from multiple sources (dialog history, knowledge base, current utterance).	O	O	Review	1359
The work assumes that the knowledge base associated with the dialog task has en entity-to-entity-relationship format and can be naturally expressed as a graph.	O	O	Review	1359
The dependency tree of dialog utterances can also be expressed as a graph, and the dialog history as a set of graphs.	O	O	Review	1359
To utilize this structure, the proposed method uses GCNs whose lowest layer embeddings are initialized with the entity embeddings or via outputs of standard RNN-like models.	O	O	Review	1359
The main claim is that the proposed model outperforms the current state-of-the-art on a goal-oriented dialog task.	O	O	Review	1359
<sep> <sep> The idea of explicitly modeling the relational structure via GCNs is interesting.	B-Review	B-1	Review	1359
However, the use of GCNs independently per sentence and per knowledge-base is a bit disappointing, since it does not couple these sources of information in a structured way.	I-Review	I-1	Review	1359
Instead, from my current understanding, the approach merely obtains better representations for each of these sources of information, in the same way it is done in the related language tasks.	I-Review	I-1	Review	1359
For instance, have you considered passing information across the trees in the history as well?	I-Review	I-1	Review	1359
Or aligning the parsed query elements with the KB elements?	I-Review	I-1	Review	1359
<sep> <sep> The results are very good.	B-Review	B-2	Review	1359
That said, a source of concern is that the model is only evaluated as a whole, without showing which modification brought the improvements.	I-Review	I-2	Review	1359
The comparison between using/not using RNNs to initiate the first GCN layer is promising, but why not compare to using only RNN also?	I-Review	I-2	Review	1359
Why not compare the various encoders within an established framework (e.g. without the newly introduced attention mechanism)?	I-Review	I-2	Review	1359
Finally, the attention mechanism, stated as a contribution, is not motivated well.	I-Review	I-2	Review	1359
<sep> <sep> Clarity:	O	O	Review	1359
The notation is described well, but it's not terribly intuitive (the query embedding is denoted by c, the history embedding by a, etc.),	B-Review	B-3	Review	1359
making section 4.4.	I-Review	I-3	Review	1359
hard to follow.	I-Review	I-3	Review	1359
A figure would have made things easier to follow, esp.	I-Review	I-3	Review	1359
due to the complexity of the model.	I-Review	I-3	Review	1359
A clearer parallel with previous methods would also improve the paper: is the proposed approach adding GCN on top of an established pipeline?	I-Review	I-3	Review	1359
Why not?	I-Review	I-3	Review	1359
<sep> <sep> More discussion on code-mixed language, e.g. in section 4.6, would also improve clarity a bit (make the paper more self-contained).	B-Review	B-4	Review	1359
While the concept is clear from the context, it would be helpful to describe the level of structure in the mixed language.	I-Review	I-4	Review	1359
For instance, can dependency trees not be obtained code-mixed languages?	I-Review	I-4	Review	1359
Is there any research in this direction? (	I-Review	I-4	Review	1359
or is the concept very new?)	I-Review	I-4	Review	1359
Maybe I am just missing the background here, but it seems helpful in order to asses how appropriate the selected heuristic (based on the co-occurence matrix) is.	I-Review	I-4	Review	1359
<sep> <sep> Relevant Reference:	O	O	Review	1359
Learning Graphical State Transitions, Johnson, ICLR 2017 also uses graph representations in question answering, though in a somewhat different setting.	B-Review	B-5	Review	1359
<sep> <sep> Typos:	B-Review	B-6	Review	1359
Section 4: "a model with following components"	I-Review	I-6	Review	1359
Section 5: "the various hyperparameters that we conisdered"	I-Review	I-6	Review	1359
We would like to thank you for some great suggestions on strengthening the paper.	O	O	Reply	1359
We must confess that while we had some of these on our to-do list, there were a few that we hadn't actually thought of.	O	O	Reply	1359
We have now been able to add these experiments and we believe it has definitely helped us improve the quality of the paper.	O	O	Reply	1359
Below we give a pointwise update about the new experiments.	O	O	Reply	1359
<sep> <sep> 1)Passing information across the KB tree and query/history tree by aligning query/history elements with the KB elements: We were able to implement this and did a thorough hyperparameter tuning across all languages.	B-Reply	B-1	Reply	1359
We have included these results in the paper (RNN+CROSS-GCN-SeA in Tables 1, 2) but the short summary is that there was not much change in the BLEU, ROUGE and per response accuracy and only a marginal improvement in the Entity F1-score for En-DSTC2 and Ta-DSTC2.	I-Reply	I-1	Reply	1359
We had expected the entity F1-score to improve significantly across all languages since we are explicitly linking entities in the KB with entities in the query/history but unfortunately this was not the case.	I-Reply	I-1	Reply	1359
Initial analysis suggests that given that the task is relatively simple, even the base model, which does not explicitly pass information across the trees, is still able to capture the relevant information.	I-Reply	I-1	Reply	1359
<sep> <sep> 2)Ablation tests including comparisons with basic RNN based models and basic attention models: This was a bad miss on our part but now we have been able to do a thorough ablation study with the following experiments where we try to evaluate the (i) need for GCNs (ii) need for our sequential attention mechanism and (iii) need for combining RNNs with GCN:	B-Reply	B-2	Reply	1359
<sep> a)RNN with attention (the basic seq2seq+attention model of Bahdanau et al 2015)	I-Reply	I-2	Reply	1359
b)GCN with Bahdanau attention [does not use RNN or our sequential attention]	I-Reply	I-2	Reply	1359
c)RNN+GCN with Bahdanau attention [does not use our sequential attention]	I-Reply	I-2	Reply	1359
d)RNN with our sequential attention [does not use GCNs]	I-Reply	I-2	Reply	1359
e)RNN+GCN with our sequential attention [Our Final Model]	I-Reply	I-2	Reply	1359
<sep> We have included these results for all languages in the updated version of the paper (see Table 8 in Appendix D and ‚ÄúAblations‚Äù part of Section 6) and the main observations are summarized below:	I-Reply	I-2	Reply	1359
<sep> i)GCNs do not outperform RNNs independently: In general, the performance of GCN-Bahdanau attention < RNN-Bahdanau attention	I-Reply	I-2	Reply	1359
ii)Our sequential attention outperforms Bahdanau attention:  In general, the performance of GCN-Bahdanau attention < GCN-our_seq_attention, RNN-Bahdanau attention < RNN-our_seq_attention and RNN+GCN-Bahdanau attention < RNN+GCN-our_seq_attention.	I-Reply	I-2	Reply	1359
However, note that RNN-Bahdanau attention < RNN-our_seq_attention holds for BLEU and all ROUGE metrics but not for Entity F1 and exact match accuracy.	I-Reply	I-2	Reply	1359
We are analyzing this further and will hopefully be able to add some insights in the final version of the paper.	I-Reply	I-2	Reply	1359
<sep> iii)Combining GCNs with RNNs helps: In general, RNN-our_seq_attention < RNN+GCN-our_seq_attention	I-Reply	I-2	Reply	1359
<sep> Overall, the best results are always obtained by our final model which combines RNN, GCN and sequential attention.	I-Reply	I-2	Reply	1359
Also, the code for our model and these ablation studies will be made publicly available.	I-Reply	I-2	Reply	1359
<sep> <sep> 3)Motivation behind attention: The motivation behind using a sequential attention mechanism was as follows: The current utterance which we refer to as query sets the stage for what comes next (the response).	B-Reply	B-2	Reply	1359
Hence we use this query to attend to only important parts in the history (essentially, the history can be long and we just want to focus on things which are relevant for the last utterance).	I-Reply	I-2	Reply	1359
Once, we have identified relevant portions of the history and computed an attention weighted representation for the history we are now ready to identify the important concepts from the KB.	I-Reply	I-2	Reply	1359
To achieve this effect we use the sequential attention mechanism.	I-Reply	I-2	Reply	1359
<sep> <sep> 4)GCN on top of an established pipeline: experiment c in point 2 above.	B-Reply	B-3	Reply	1359
<sep> <sep> 5)Better notations and figures: Indeed, in hindsight, we agree that some of our choices were not very intuitive.	B-Reply	B-3	Reply	1359
We have added 2 diagrams which hopefully makes things clear.	I-Reply	I-3	Reply	1359
It would be great if you can give us a feedback on the diagrams.	I-Reply	I-3	Reply	1359
<sep> <sep> 6)Clarity on code-mixing: The statistics about the level of code mixing, level of structure, etc are mentioned in the original paper (Banerjee et al 2018) which introduced the dataset.	B-Reply	B-4	Reply	1359
As suggested, to make the paper self-contained we have added the important statistics in this paper and some examples of code mixed conversations from the dataset (Appendix A).	I-Reply	I-4	Reply	1359
Note that there is a lot of work on processing code mixed text (for example, POS tagging of code mixed text, sentiment analysis of code mixed text, information retrieval using code mixed queries, etc).	I-Reply	I-4	Reply	1359
However, there is not much work on code mixed dialogues because this dataset was only released recently (COLING 2018).	I-Reply	I-4	Reply	1359
To the best of our knowledge, there is no work on building parsers for code mixed languages which produce parse trees.	I-Reply	I-4	Reply	1359
<sep> <sep> 7)We have fixed the typos and added the relevant reference.	B-Reply	B-6	Reply	1359

The paper proposes a Graph Convolutional Network-based encoder-decoder model with sequential attention for goal-oriented dialogue systems, with the purpose of exploiting the graph structures in KB and sentences in conversation.	O	O	Review	1359
The model consists of three encoders for a query, dialogue history, and KB, respectively, and a decoder with a sequential attention mechanism.	O	O	Review	1359
The proposed model attains state-of-the-art performance on the modified DSTC2 dataset of (Bordes et al 2017).	O	O	Review	1359
For the experiments with graphs constructed from word co-occurrence matrix, code-mixed versions of modified DSTC2 released by (Banerjee et al 2018) are used.	O	O	Review	1359
<sep> <sep> Pros and Cons	O	O	Review	1359
(+) SOTA performance on the DSTC2 dataset.	O	O	Review	1359
<sep> (+) Without dependency parser when it is not possible	O	O	Review	1359
(-) Limited novelty	B-Review	B-1	Review	1359
(-) Limited convincing the advantage of GCN itself	B-Review	B-3	Review	1359
<sep> Detailed comments	O	O	Review	1359
The paper incorporates the graph structures in sentences and KB to make richer representations of conversation and achieves a state-of-the-art performance on the DSTC2 dataset.	B-Review	B-1	Review	1359
The paper is clearly written, and the results seem promising.	I-Review	I-1	Review	1359
However, as the paper combines existing mechanisms to design a model for dialog, the novelty seems to be relatively weak.	I-Review	I-1	Review	1359
<sep> In particular, I felt that some experimental results are required to verify some of the arguments put forward by the authors.	B-Review	B-2	Review	1359
We listed two issues as below.	I-Review	I-2	Review	1359
<sep> <sep> 1.	O	O	Review	1359
Effects of GCN	O	O	Review	1359
The authors show that RNN-GCN-SeA can make state-of-the-art performance, but not how much GCN makes effects on improving the performance on the dialog task.	B-Review	B-3	Review	1359
<sep> I think the authors need to compare the results of RNN-GCN-SeA with a model without GCN (i.e. RNN-SeA) in order to show that exploiting the structural information of dependency and contextual graphs do play an important role.	B-Review	B-4	Review	1359
<sep> The random graph experiments (Table 3) show the effect of good structure in GCN, but I felt that it is not enough to demonstrate an improvement by GCNs.	B-Review	B-5	Review	1359
<sep> <sep> 2.	O	O	Review	1359
Comparative Experiments	O	O	Review	1359
I think that some experiments, which is reported in the previous papers (including Mem2Seq), would make the author‚Äôs experimental argument strong.	B-Review	B-6	Review	1359
<sep> - Entity F1 score for the modified DSTC2 dataset	I-Review	I-6	Review	1359
- Results on bAbI dialog dataset (task1~5 and its OOV variants) and In-Car Assistant dataset	B-Review	B-6	Review	1359
<sep> Minor issues	O	O	Review	1359
1.	O	O	Review	1359
Authors described that Mem2Seq is one of the state-of-the-art models in this field, including in the abstract.	B-Review	B-7	Review	1359
However, Mem2Seq does not outperform seq2seq model in all experiments.	I-Review	I-7	Review	1359
From what point of view is this model state-of-the-art?	I-Review	I-7	Review	1359
<sep> 2.	O	O	Review	1359
Recent studies have focused on copy mechanism in task-oriented dialog systems.	B-Review	B-8	Review	1359
Could you explain how the copy mechanism could be incorporated into the proposed model?	I-Review	I-8	Review	1359
I am also interested in the comparative results between seq2seq + attn + copy (per-resp-acc of 47.3) and its entity F1 measure (Eric and Manning, 2017; Madotto et al 2018).	I-Review	I-8	Review	1359
<sep> <sep> <sep> We would like to thank you for suggesting additional experiments for improving the paper.	O	O	Reply	1359
We have been able to run these experiments and would like to update you about the results:	O	O	Reply	1359
<sep> 1) Effects of GCN: We have now added detailed ablation studies (please see Table 8 in Appendix D) including comparisons with basic RNN based models and basic attention models.	B-Reply	B-5	Reply	1359
In particular, we have now compared RNN+GCN-SeA with RNN-SeA. The results indeed suggest that adding GCNs on top of RNNs helps.	I-Reply	I-5	Reply	1359
Our analysis also shows that our sequential attention outperforms the basic (Bahdanau) attention.	I-Reply	I-5	Reply	1359
Please see ‚ÄúAblations‚Äù part of Section 6 and Table 8 in Appendix D. Also, the code for our model and these ablation studies will be made publicly available.	I-Reply	I-5	Reply	1359
<sep> <sep> 2) Comparative experiments: We have reported Entity F1 scores for all our experiments and again find that w.r.t this metric our model mostly outperforms existing approaches (including some new baselines that we have added for the ablation study).	B-Reply	B-6	Reply	1359
We were not very keen on the bAbI dataset since existing research ( Hybrid Code Networks, Williams et al, 2017 ) shows that it is possible to achieve 100% performance on this dataset using simple models (not surprising given that this is a synthetic dataset).	I-Reply	I-6	Reply	1359
Hence, there is not much scope for introducing more complex models such as the one proposed in this paper.	I-Reply	I-6	Reply	1359
We plan to include results on the In-Car dataset and we are hopeful that we will have these results ready in the final version of the paper.	I-Reply	I-6	Reply	1359
<sep> <sep> 3) Yes, indeed, Mem2Seq does not outperform seq2seq in all experiments.	B-Reply	B-7	Reply	1359
In that sense, you are correct in saying that it is not a SOTA model.	I-Reply	I-7	Reply	1359
By SOTA, we incorrectly meant that it is the most recent model published on this dataset.	I-Reply	I-7	Reply	1359
<sep> <sep> 4) Copy mechanism: In addition to the Mem2Seq model of (Madotto et al, 2018), we have now added the comparison with the model of (Eric and Manning, 2017) which uses copy mechanism.	B-Reply	B-8	Reply	1359
Our model outperforms both these models.	I-Reply	I-8	Reply	1359
In principle, we should be able to augment our model with a copy mechanism but this may be a non-trivial extension of our model.	I-Reply	I-8	Reply	1359
This is definitely worth trying but we are not sure if we will be able to add this to the current version of the paper.	I-Reply	I-8	Reply	1359
We apologize for this (we don't want to commit to something that we may not be able to deliver).	I-Reply	I-8	Reply	1359

This is a well-written paper (especially the introduction) with fairly extensive experimentation section.	O	O	Review	1359
It'a very possitive for me that you resort to more than one set of figures of merit.	O	O	Review	1359
<sep> <sep> My concerns are:	O	O	Review	1359
<sep> You mention that GCNs have been used for question-anwering already.	B-Review	B-1	Review	1359
It would be infomative to furhter describe this work and clearly state how you handle things differenclty, since a Q&A system is quite close to a dialogue one.	I-Review	I-1	Review	1359
<sep> <sep> There are some parts that could be made more clear.	B-Review	B-2	Review	1359
For example, when you mention that you collectively represent all trees as a single graph.	I-Review	I-2	Review	1359
How do you do that?	I-Review	I-2	Review	1359
<sep> <sep> The model has a great number of parameters.	B-Review	B-3	Review	1359
It is not clear to me how you concluded to the specific parameter values.	I-Review	I-3	Review	1359
<sep> <sep> It would be nice to add the complexity of the model and also be more specific about how you choose the parameter values.	B-Review	B-4	Review	1359
<sep> <sep> My proposals are:	O	O	Review	1359
<sep> I think that the paper would greatly benefit if you additionally to the equations you also presented the model in a graphical way as well.	B-Review	B-5	Review	1359
Additionally, although the paper is very well mathematically defined, is not so easy to follow from a practical perspective.	I-Review	I-5	Review	1359
For example, regarding section 5.3 I would prefer to see the 3 models you present in a graphical way as well.	I-Review	I-5	Review	1359
<sep> <sep> Maybe add the links to the datasets you are using?	B-Review	B-6	Review	1359
On a related subject, would your models be transferable accross datasets?	I-Review	I-6	Review	1359
<sep> <sep> Minor issues	O	O	Review	1359
PPMI abreviation is first used and then defined.	B-Review	B-7	Review	1359
<sep> There are also some typos, like conisdered (that I suppose was meant to be considered, for example)	B-Review	B-8	Review	1359
We would like to thank you for your comments and valuable suggestions on improving the clarity of the paper.	O	O	Reply	1359
Below, we provide updates on some of the improvements that we have been able to do:	O	O	Reply	1359
<sep> 1) Difference from QA:  To the best of our knowledge, the only work on using GCNs for QA (De Cao et al, 2018) uses Entity graphs as opposed to dependency graphs used in the work.	B-Reply	B-1	Reply	1359
An entity graph essentially draws an edge between same entities which appear in different sentences whereas a dependency graph contains semantic edges.	I-Reply	I-1	Reply	1359
Hence, the graph that we are operating on is very different from the entity graph used in the above paper.	I-Reply	I-1	Reply	1359
Further, in the case of QA, there is a query and a document whereas in our case there is a context/history in addition to the query and KB.	I-Reply	I-1	Reply	1359
This adds some more complexity to our model.	I-Reply	I-1	Reply	1359
For example, our sequential attention mechanism also considers the history while paying attention to the KB.	I-Reply	I-1	Reply	1359
Further, it also computes a query aware representation for the history.	I-Reply	I-1	Reply	1359
Finally, while producing the output, the decoder also pays attention to the history.	I-Reply	I-1	Reply	1359
These differences are not groundbreaking but we just mention them here to make the distinction between the two tasks clear and to highlight the additional components in our model.	I-Reply	I-1	Reply	1359
<sep> <sep> 2) How do we collectively represent all trees as a graph?	B-Reply	B-2	Reply	1359
This was in the context of computing a representation for the dialogue history.	I-Reply	I-2	Reply	1359
The history contains multiple sentences.	I-Reply	I-2	Reply	1359
We first create a dependency tree for each sentence.	I-Reply	I-2	Reply	1359
The final graph for the history is a simple collection of these individual (disconnected) trees.	I-Reply	I-2	Reply	1359
Just to be clear, currently we do not have any edges between words in two different sentences (hence all the individual sentence trees are disconnected from each other).	I-Reply	I-2	Reply	1359
<sep> <sep> 3) Regarding complexity and choosing parameter values: Our final model (RNN+GCN-SeA) has ~4M parameters as compared to the vanilla RNN+attention model which has ~2M parameters.	B-Reply	B-4	Reply	1359
These parameters were learned using ADAM, with a batch size of 32 and initial learning rate of 0.0006.	I-Reply	I-4	Reply	1359
We found that the model trains in ~30 epochs.	I-Reply	I-4	Reply	1359
In addition, we would like to clarify that the hyperparameters of the model were chosen using a validation set.	I-Reply	I-4	Reply	1359
<sep> <sep> 4) Clarity: Indeed, in hindsight and based on similar comments by Reviewer 1, we agree that we could have made things more clear by adding a diagram.	B-Reply	B-5	Reply	1359
We have included 2 diagrams in the updated version of the paper and we hope it clarifies things.	I-Reply	I-5	Reply	1359
Regarding the three models in Section 5.3, they would only differ in the type of parse tree edges (last edge type in the legend) shown in Figure 1.	I-Reply	I-5	Reply	1359
Please give us your feedback on the diagrams and if it can be improved to make things more clear.	I-Reply	I-5	Reply	1359
<sep> <sep> 5) Link to Dataset: We used the dataset released by Banerjee et al, 2018 which is available at the following URL: <a href="https://github.com/sumanbanerjee1/Code-Mixed-Dialog" target="_blank" rel="nofollow">https://github.com/sumanbanerjee1/Code-Mixed-Dialog</a> .	B-Reply	B-6	Reply	1359
We plan to include results on the In-Car dataset also.	I-Reply	I-6	Reply	1359
We are hopeful that we will have these results ready in the final version of the paper.	I-Reply	I-6	Reply	1359
<sep> <sep> 6) Thanks for pointing out the typos.	B-Reply	B-8	Reply	1359
We have fixed them in the updated version of the paper.	I-Reply	I-8	Reply	1359

This paper presents an simple and interesting idea to improve the performance for neural nets.	O	O	Review	511
The idea is we can reduce the precision for activations and increase the number of filters, and is able to achieve better memory usage (reduced).	O	O	Review	511
The paper is aiming to solve a practical problem, and has done some solid research work to validate that.	O	O	Review	511
In particular, this paper has also presented a indepth study on AlexNet with very comprehensive results and has validated the usefulness of this approach.	O	O	Review	511
<sep> In addition, in their experiments, they have demonstrated pretty solid experimental results, on AlexNet and even deeper nets such as the state of the art Resnet.	O	O	Review	511
The results are convincing to me.	O	O	Review	511
<sep> <sep> On the other side, the idea of this paper does not seem extremely interesting to me, especially many decisions are quite natural to me, and it looks more like a very empirical practical study.	B-Review	B-1	Review	511
So the novelty is limited.	I-Review	I-1	Review	511
<sep> <sep> So overall given limited novelty but the paper presents useful results, I would recommend borderline leaning towards reject.	O	O	Review	511
Thank you for the comments.	O	O	Reply	511
We defend the novelty aspect of this paper in our response below.	O	O	Reply	511
<sep> <sep> Novelty:	O	O	Reply	511
Our paper targets quantization at no accuracy loss.	B-Reply	B-1	Reply	511
We target network training on reduced precision hardware (H/W) considering a system-wide approach - system and on-chip memory footprint of activations is much more than weights.	I-Reply	I-1	Reply	511
<sep> For cloud-based inference deployments (where large batch-size is typical) and during training, reducing precision of activations speeds up end-to-end runtime much more than reducing the precision of weights (Fig.1).	I-Reply	I-1	Reply	511
<sep> However, as our paper shows, reducing activation precision hurts accuracy much more than reducing weight precision.	I-Reply	I-1	Reply	511
No prior work targets this aspect.	I-Reply	I-1	Reply	511
<sep> <sep> Most prior works on reduced precision DNNs sacrifice accuracy and many prior works target reducing precision of just the weights.	I-Reply	I-1	Reply	511
We show that there is no tradeoff in reducing precision - even during training - one can get the same accuracy as baseline by making the networks wider (yes, more raw compute operations, but still the compute cost is lower than baseline).	I-Reply	I-1	Reply	511
<sep> <sep> <sep> 1.	I-Reply	I-1	Reply	511
We believe lowering precision is one aspect (which is widely studied in literature) but it is important to lower precision without any loss in accuracy - no prior work has shown reduced-precision network (4-bits, 2-bits) training and inference without sacrificing accuracy.	I-Reply	I-1	Reply	511
<sep> Also, our results with binary networks are state-of-the art and close the gap significantly between binary and 32b precision (e.g. less than 1.2% for ResNet-34).	I-Reply	I-1	Reply	511
<sep> <sep> <sep> 2.	I-Reply	I-1	Reply	511
We believe widening networks is a simple technique (which works) that is easy for programmers to experiment with for recovering accuracy with reduced precision.	I-Reply	I-1	Reply	511
With WRPN: (a) model-size is smaller and, (b) run time and energy for end-to-end inference as well as training is lower than 32b networks.	I-Reply	I-1	Reply	511
<sep> <sep> With widening, the number of neurons in a layer increase.	I-Reply	I-1	Reply	511
Yet with reduced precision, we control overfitting and regularization.	I-Reply	I-1	Reply	511
We believe, this aspect has not been studied before.	I-Reply	I-1	Reply	511

This is a well-written paper with good comparisons to a number of earlier approaches.	O	O	Review	511
It focuses on an approach to get similar accuracy at lower precision, in addition to cutting down the compute costs.	O	O	Review	511
Results with 2-bit activations and 4-bit weights seem to match baseline accuracy across the models listed in the paper.	O	O	Review	511
<sep> <sep> Originality	O	O	Review	511
This seems to be first paper that consistently matches baseline results below int-8 accuracy, and shows a promising future direction.	O	O	Review	511
<sep> <sep> Significance	O	O	Review	511
Going down to below 8-bits and potentially all the way down to binary (1-bit weights and activations) is a promising direction for future hardware design.	O	O	Review	511
It has the potential to give good results at lower compute and more significantly in providing a lower power option, which is the biggest constraint for higher compute today.	O	O	Review	511
<sep> <sep> Pros:	O	O	Review	511
- Positive results with low precision (4-bit, 2-bit and even 1-bit)	O	O	Review	511
- Moving the state of the art in low precision forward	O	O	Review	511
- Strong potential impact, especially on constrained power environments (but not limited to them)	O	O	Review	511
- Uses same hyperparameters as original training, making the process of using this much simpler.	O	O	Review	511
<sep> <sep> Cons/Questions	O	O	Review	511
- They mention not quantizing the first and last layer of every network.	B-Review	B-1	Review	511
How much does that impact the overall compute?	I-Review	I-1	Review	511
<sep> - Is there a certain width where 1-bit activation and weights would match the accuracy of the baseline model?	B-Review	B-2	Review	511
This could be interesting for low power case, even if the "effective compute" is larger than the baseline.	I-Review	I-2	Review	511
<sep> <sep> Thank you for the comments and review.	O	O	Reply	511
<sep> <sep> Effect on compute of not quantizing first layer and last:	O	O	Reply	511
The total number of FMA operations in first and last layer is ~3% for ResNet-34 (and 1.5% for ResNet-50).	B-Reply	B-1	Reply	511
So the effect on overall compute is smaller for these layers if not negligible.	I-Reply	I-1	Reply	511
In our work, the first layer and last layer's weights and activations are not quantized and neither are these layers' width increased.	I-Reply	I-1	Reply	511
<sep> <sep> For the first and last layer, we find, we can quantize the weights to 8-bits (at most) without much loss in accuracy compared to keeping them at full-precision (~0.2% additional accuracy loss) while quantizing the other layers to 4bits activations and 2-bits weight.	I-Reply	I-1	Reply	511
So, in theory we can use integer compute for these layers if not 2-bits and 4-bits precision to speed up compute.	I-Reply	I-1	Reply	511
<sep> <sep> The primary reason we did not quantize the first and last layer is because - we wanted to fairly compare against prior proposals - the works we compared against in the paper do not quantize these layers.	I-Reply	I-1	Reply	511
<sep> <sep> At what widening factor does 1-bit come at-par with baseline full-precision?	O	O	Reply	511
<sep> Our very preliminary results tell us that this could probably happen at 3.5x-4x widening.	B-Reply	B-2	Reply	511
<sep> We run into experimental evaluation issues when doing these experiments -- making the layers wider blows up the device memory requirements (since we "emulate" the binary and other low-precision knobs with FP32 precision in GPUs).	I-Reply	I-2	Reply	511
We are working on performing these experiments with distributed TensorFlow set-up.	I-Reply	I-2	Reply	511
The other aspect is to lower the batch-size and still use a single node set-up but we have to change the learning rates then.	I-Reply	I-2	Reply	511

The paper studies the effect of reduced precision weights and activations on the performance, memory and computation cost of deep networks and proposes a quantization scheme and wide filters to offset the accuracy lost due to the reduced precision.	O	O	Review	511
The study is performed on AlexNet, ResNet and Inception on the Imagenet datasets and results show that accuracy matching the full precision baselines can be obtained by widening the filters on the networks.	O	O	Review	511
<sep> <sep> Positives	O	O	Review	511
- Using lower precision activations to save memory and compute seems new and widening the filter sizes seems to recover the accuracy lost due to the lower precision.	O	O	Review	511
<sep> <sep> Negatives	O	O	Review	511
- While the exhaustive analysis is extremely useful the overall technical contribution of the paper that of widening the networks is fairly small.	B-Review	B-1	Review	511
<sep> - The paper motivates the need for reduced precision weights from the perspective of saving memory footprint when using large batches.	B-Review	B-3	Review	511
However, the results are more focused on compute cost.	I-Review	I-3	Review	511
Also large batches are used mainly during training where memory is generally not a huge issue.	I-Review	I-3	Review	511
Memory critical situations such as inference on mobile phones can be largely mitigated by using smaller batch sizes.	I-Review	I-3	Review	511
It might help to emphasize the speed-up in compute more in the contributions.	I-Review	I-3	Review	511
Thank you for the comments and reviews.	O	O	Reply	511
They are useful to us.	O	O	Reply	511
<sep> <sep> Please see our response to AnonReviewer3 on the novelty aspect of our paper.	B-Reply	B-1	Reply	511
Overall we believe ours is a simple technique that works and that is easier for programmers to adopt.	I-Reply	I-1	Reply	511
<sep> <sep> We will clearly articulate the speed-up in compute for the final version of the paper.	B-Reply	B-2	Reply	511
Specializing the hardware (e.g. by adding compute components that implement 2-bits, 4-bits, binary, 8bits, etc.)	I-Reply	I-2	Reply	511
would definitely speed-up inference times.	I-Reply	I-2	Reply	511
Our ASIC and FPGA evaluations (Section-5.1) are an attempt to highlight this aspect.	I-Reply	I-2	Reply	511
Current hardware platforms are not optimized for 2-bits and 4-bits.	I-Reply	I-2	Reply	511
One other aspect of lowering memory footprint is that the working set size of the workload starts to fit on chip and by lowering accesses to DRAM memory, the compute core starts to see better performance and energy savings (DRAM accesses are expensive in latency and energy).	I-Reply	I-2	Reply	511

This work proposes a brand new dataset to fill in the vacancy of current conversational AI community, specifically the introduced dataset aims at providing a platform to perform large-scaled knowledge-grounded chit-chat.	O	O	Review	511
Overall, the dataset is well-motivated and well-designed, its existence will potentially benefit the community and inspire more effective methods to leverage external knowledge into dialog system.	O	O	Review	511
Besides, the paper also utilizes many trending models like Transformers, Memory Networks, etc to ensure the state-of-the-art performance.	O	O	Review	511
The clear structure and paragraphs also makes the paper easy to read and follow.	O	O	Review	511
<sep> <sep> Here are some questions I want to raise about the paper:	O	O	Review	511
<sep> 1.	B-Review	B-1	Review	511
First of all, the design of the conversation flow though looks reasonable, but it is pretty uncommon for a human to ground his/her every sentence on external knowledges.	I-Review	I-1	Review	511
Therefore, it would probably be better to introduce some random ungrounded turns into the conversation to make it more humanlike.	I-Review	I-1	Review	511
<sep> <sep> 2.	O	O	Review	511
Secondly, the whole framework is based on many modules and every one of them are prone to error.	B-Review	B-2	Review	511
I‚Äôm afraid that such cascaded errors will accumulate and lead to compromised performance in the end.	I-Review	I-2	Review	511
Have you thought about using REINFORCE	I-Review	I-2	Review	511
algorithm to alleviate this issue?	I-Review	I-2	Review	511
<sep> <sep> 3.	B-Review	B-3	Review	511
Finally, it would be better to introduce some noisy or adversarial apprentice to raise unrelated turns and see how the system react.	I-Review	I-3	Review	511
Have you thought about how to deal with such cases?	I-Review	I-3	Review	511
Thank you for your review and detailed feedback.	O	O	Reply	511
We address your 3 points below:	O	O	Reply	511
<sep> - ‚Äúit is pretty uncommon for a human to ground his/her every sentence on external knowledges‚Äù:	O	O	Reply	511
o  In fact in our task, at any time in the dialogue the Wizard can choose ‚Äúno sentence used instead‚Äù, as stated in the paper, but we have made this clearer (adding it in two places).	B-Reply	B-1	Reply	511
We do agree that the Wizard task is not completely natural for a human as we are trying to make the human conversationalist help to train our bot maximally by grounding their sentences so that we can learn how to ground ‚Äî for this reason we ask the human to read Wikipedia sentences and use them if possible rather than their own personal knowledge (which the model cannot retrieve).	I-Reply	I-1	Reply	511
It is this setup that we believe makes our dataset so useful for knowledge grounded dialogue model training compared to existing datasets.	I-Reply	I-1	Reply	511
<sep> <sep> - REINFORCE for learning the whole system:	O	O	Reply	511
o  Indeed our methods do use at least two modules: one for knowledge retrieval (searches over all of Wikipedia), and one that combines knowledge selection and generation/retrieval.	B-Reply	B-2	Reply	511
Training the parts of the system together, e.g. by REINFORCE is a great idea for future work.	I-Reply	I-2	Reply	511
We have added this to the future work section of the conclusion.	I-Reply	I-2	Reply	511
<sep> <sep> - Noisy or adversarial apprentice:	O	O	Reply	511
o  Again, making the systems more robust is also a good direction for future work.	B-Reply	B-3	Reply	511
Our task will be made publicly available for researchers to try such improved follow-up techniques.	I-Reply	I-3	Reply	511

This paper collects a new annotated dataset for knowledge grounded dialog task.	O	O	Review	511
The proposed models combine two recent neural networks, Memory Net and Transformer, for the purpose of the task.	O	O	Review	511
I highly appreciate the efforts to collect such a precious dialog dataset for the community.	O	O	Review	511
Also, the setup in data collection actually narrows down the scope of chitchat dialog into a specific topic by grounding it to a set of knowledge.	O	O	Review	511
<sep> <sep> Here are summaries of my concerns and questions about the paper.	O	O	Review	511
<sep> <sep> # applicability of the knowledgeable bot	O	O	Review	511
What is the basic motivation of this work?	B-Review	B-1	Review	511
Once you develop a chatbot that can produce a response grounded by knowledge, how could it be applied to real-world applications?	I-Review	I-1	Review	511
Are you trying to teach a student who is looking for more knowledge about a topic?	I-Review	I-1	Review	511
If so, you should be more careful about what knowledge the student (or apprentice in the paper) knows or don‚Äôt know about the topic and how their knowledge models dynamically change over the chat.	I-Review	I-1	Review	511
Otherwise, the proposed model seems a simple knowledge retrieval model given the dialog context.	I-Review	I-1	Review	511
Would you please provide motivations of the work?	I-Review	I-1	Review	511
<sep> <sep> # No explicit goal of a dialog makes the chat divergent and open-ended	O	O	Review	511
Without a specific goal given to the annotators or a restriction in the instruction, a dialog in the current setting might diverge beyond the context.	B-Review	B-2	Review	511
For example, if an apprentice says about her/his personal opinion about the topic (e.g., I hate the Gouda cheese) or past experience (e.g., I went to a music festival by Michael Jackson 23 years ago), then how do you control the chat between two annotators or how do you train a model not to pay much attention on out-of-topic utterances?	I-Review	I-2	Review	511
<sep> # Lack of further analysis of the dataset	O	O	Review	511
Data collection part itself seems to be the biggest contribution to this work.	B-Review	B-3	Review	511
Why don‚Äôt you bring one of real dialog example in Figure 3 to the main paper and say more about it?	I-Review	I-3	Review	511
For example, what other interesting applications can you develop on this dataset?	I-Review	I-3	Review	511
<sep> <sep> Compared to the Wizard, the role of apprentice seems unclear to me.	B-Review	B-4	Review	511
I found from the examples in Figure 3 that most of the apprentices‚Äô responses are a follow-up question about the knowledge, a personal agreement or feeling or their preference.	I-Review	I-4	Review	511
Do you have any post analysis on the types of responses from the apprentices so highlighting utilities of the dataset in a real application?	B-Review	B-5	Review	511
<sep> <sep> # Some questions on data collection	O	O	Review	511
Do you have any incentive mechanism to make annotators more engage in the dialog?	B-Review	B-6	Review	511
<sep> Did you filter out some bad dialogs?	I-Review	I-6	Review	511
Then, how did you measure the quality of a dialog?	I-Review	I-6	Review	511
<sep> How do you penalize bad annotators that often make aggressive words or don‚Äôt follow the instruction you set up?	I-Review	I-6	Review	511
<sep> <sep> # A question on the model	O	O	Review	511
Compared to previous works such as (Zhang at al.,	B-Review	B-7	Review	511
ACL18), the proposed model seems to have the only replacement with Transformer encoder and a loss term for knowledge selection.	I-Review	I-7	Review	511
Have you tried another way of dealing with the knowledge part?	I-Review	I-7	Review	511
For example, a ranking loss might be better than the attention.	I-Review	I-7	Review	511
<sep> <sep> # Questions on the Experiment section	O	O	Review	511
Any experiment to show the effect of different \lambda value in the loss of the generative model?	B-Review	B-8	Review	511
<sep> <sep> When you evaluate the generative model, have you also tried other automatic metrics such as BLEU instead of only PPL and Unigram-F1?	B-Review	B-9	Review	511
For this task, the possible response grounded by the topic+knowledge might be too diverse to measure though.	I-Review	I-9	Review	511
Could you possibly add some constraints to the annotators to do some clear tasks over the dialog so you can systematically evaluate the dialog w.r.t the constraint?	I-Review	I-9	Review	511
Otherwise, evaluation of this task seems to be mostly the same as chitchat systems.	I-Review	I-9	Review	511
<sep> <sep> In Table 5, human evaluators only measure the likeness of the dialog which seems very naive.	B-Review	B-10	Review	511
Why don‚Äôt you measure whether the apprentice gets new knowledge of which s/he didn‚Äôt know before, whether the knowledge provided from the model was informative, whether the dialog was fun and engaging or more?	I-Review	I-10	Review	511
The current human evaluation seems very weak though.	I-Review	I-10	Review	511
<sep> <sep> This might be an auxiliary question: have you tried to train the model for apprentice and make two models chat with each other?	B-Review	B-11	Review	511
How does the chat look like then?	I-Review	I-11	Review	511
<sep> <sep> Thank you for your review and detailed feedback, we appreciate the constructive comments.	O	O	Reply	511
We apologize if our answer is long, but you had a lot of questions!	O	O	Reply	511
We have tried to answer them all and make necessary changes to the paper.	O	O	Reply	511
<sep> <sep> - Real application:	O	O	Reply	511
o  This task is not meant to be solely a diagnostic dataset, but a basis for a knowledgeable conversational agent that can talk about any knowledge that is in Wikipedia.	B-Reply	B-1	Reply	511
We are interested in this task, because an agent that is both knowledgeable and can converse with humans in an engaging way is one of the goals of AI.	I-Reply	I-1	Reply	511
A successful system could engage with real people (not just paid crowdworkers).	I-Reply	I-1	Reply	511
In our work, the goal is to chat freely about the topic, i.e. a chitchat task.	I-Reply	I-1	Reply	511
No, we do not aim to make an educational tool as you mention, although others could use our work as a pre-training for such a task perhaps.	I-Reply	I-1	Reply	511
However, we respectfully disagree that our models are ‚Äúa simple knowledge retrieval model given the dialog context‚Äù.	I-Reply	I-1	Reply	511
Please see e.g. Figures 2 and 4 to show that in the best cases, where our modeling works very well,  particularly the E-book, toga party and Arnold Schwarzenegger examples the agent can be very conversationally engaging ‚Äî it both uses knowledge, but also clearly replies and follows the conversation of  the human partner, producing engaging conversations as measured in human evaluations.	I-Reply	I-1	Reply	511
<sep> <sep> - Test-bed for state-of-the-art dialogue models:	O	O	Reply	511
o  Separately, our task is also a challenging setup to develop models that can actually talk in a knowledgeable way to humans.	B-Reply	B-1	Reply	511
They must have a memory (and be able to retrieve knowledge from it), to be able to select that knowledge and converse convincingly with respect to the dialogue context.	I-Reply	I-1	Reply	511
This combines a lot of the current research threads into a single challenging task where grounded knowledge can clearly be leveraged, due to the way the data was collected.	I-Reply	I-1	Reply	511
<sep> <sep> - ‚ÄúNo explicit goal of a dialog makes the chat divergent and open-ended‚Äù:	O	O	Reply	511
o  Yes!	B-Reply	B-2	Reply	511
This is one of the challenges of real dialogue, and our dataset as well.	I-Reply	I-2	Reply	511
Because our data set collection involves an in-the-loop knowledge retrieval at every dialogue turn during both data collection (and for models working on our task) the human Wizard is able to ground their conversation with knowledge from Wikipedia.	I-Reply	I-2	Reply	511
That is, if they started talking about cheese, those topics will appear from the retrieval over Wikipedia, but if they switch to Michael Jackson, that will appear too.	I-Reply	I-2	Reply	511
They are not locked into the original topic, just as in a natural conversation.	I-Reply	I-2	Reply	511
This is what can make our models more feasibly useful for real chat in an application.	I-Reply	I-2	Reply	511
<sep> <sep> - Additional details about the Apprentice:	O	O	Reply	511
o  The Apprentice is a completely unconstrained human, playing the role of a curious learner, eager to chat.	B-Reply	B-4	Reply	511
Their stated goal is to go into depth about a chosen topic that interests themselves or their partner, while keeping the conversation engaging and fun.	I-Reply	I-4	Reply	511
We observed Apprentices saying statements, asking questions and answering questions, as shown in the examples in Appendix A.2.	I-Reply	I-4	Reply	511
Assuming that a question contains a question mark or begins with 'how', 'why', 'who', 'where', 'what' or 'when', in the dataset Apprentices ask questions in 13.9% of training set utterances, and answer questions (i.e., the Wizard has asked a question) 39.5% of the time, while saying new statements (neither asking nor answering a question) 49.3% of the time. (	I-Reply	I-4	Reply	511
Note those percentages don't add up to 100 because a question may be answered with another question.)	I-Reply	I-4	Reply	511
That is, overall, the Apprentice maintains a balanced set of dialogue acts.	I-Reply	I-4	Reply	511
We made this clearer in the main text, and added details to the appendix.	I-Reply	I-4	Reply	511
<sep> <sep> - ‚ÄúDo you have any post analysis on the types of responses from the apprentices so highlighting utilities of the dataset in a real application?‚Äù:	O	O	Reply	511
o  Please see the answer above which is now added to the paper.	B-Reply	B-5	Reply	511
We also note that we do provide an analysis of our models in Appendix C, which involves models talking to human Apprentices.	I-Reply	I-5	Reply	511
<sep> o  The dataset statistics are Table 1, examples from human-human conversations are in Fig 3 and examples dialogues of different models are in 2,4 & 5.	B-Reply	B-5	Reply	511
There is unfortunately little room left in the main paper for more, hence they are in the appendix.	I-Reply	I-5	Reply	511
We felt it was important to highlight the successes of the models, as to our knowledge there is scant evidence of models working this well in open-domain chitchat before.	I-Reply	I-5	Reply	511
Hence, the majority of our analysis has been on the modeling side (see Appendix C).	I-Reply	I-5	Reply	511

This paper introduces a new dataset and method for chatbots.	O	O	Review	511
In contrast to previous work, this paper specifically probes how well a dialogue system can use external unstructured knowledge.	O	O	Review	511
<sep> <sep> Quality:	O	O	Review	511
Overall, this is a very high-quality paper.	O	O	Review	511
The dataset is developed well, the experimental setup is well thought-through and the authors perform many ablation studies to test different model variants.	O	O	Review	511
The main criticism I have would be that the human evaluation is rather simple (rating 1-5), I would have expected more fine-grained categories, especially ones that relate to how much knowledge the system uses (I appreciate the "Wiki F1" metric, but that is an automatic metric).	B-Review	B-1	Review	511
As it is, the human evaluation shows that most of their contributions are not appreciated by human annotators.	I-Review	I-1	Review	511
Further, the paper ends a bit abruptly, I would have expected a more in-depth discussion of next steps.	B-Review	B-2	Review	511
<sep> <sep> Clarity:	O	O	Review	511
The description of the work is clear in most places.	O	O	Review	511
I particularly like the abstract and introduction, which set up the rest of the paper nicely.	O	O	Review	511
In some places, perhaps due to space restrictions, method descriptions are a bit too short.	B-Review	B-3	Review	511
<sep> <sep> Originality:	O	O	Review	511
The paper is fairly original, especially the aspect about specifically using external knowledge.	O	O	Review	511
The authors could have been more clear on how the work differs from other work on non-goal directed dialogue work though (last paragraph of related work section).	B-Review	B-4	Review	511
<sep> <sep> Significance:	O	O	Review	511
The dataset is really well-developed, hence I believe many working in the dialogue systems community will re-use the developed benchmark and build on this paper.	O	O	Review	511
<sep> <sep> More detailed comments:	O	O	Review	511
- Missing reference for goal-oriented dialogue datasets: Wen et al 2017, A Network-based End-to-End Trainable Task-oriented Dialogue System, <a href="https://arxiv.org/abs/1604.04562" target="_blank" rel="nofollow">https://arxiv.org/abs/1604.04562</a>	B-Review	B-6	Review	511
- How does the proposed dataset differ from the Reddit and Wikipedia datasets discussed in the last paragraph of the related work section?	B-Review	B-7	Review	511
This should be explained.	I-Review	I-7	Review	511
<sep> - Page 3, paragraph "Conversational Flow": what is the maximum number of turns, if the minimum is 5?	B-Review	B-8	Review	511
<sep> - Page 3, paragraph "Knowledge Retrieval": how were the top 7 articles and first 10 sentences choices made?	B-Review	B-9	Review	511
This seems arbitrary.	I-Review	I-9	Review	511
Also, why wasn't the whole text used?	I-Review	I-9	Review	511
<sep> - Page 3, paragraph "Knowledge Selection and Response Generation": how do you deal with co-reference problems if you only ever select one sentence at a time?	B-Review	B-10	Review	511
The same goes for the "Knowledge Attention" model described in Section 4.	I-Review	I-10	Review	511
<sep> - Page 3, paragraph "Knowledge Selection and Response Generation": how often do annotators choose "no sentence selected"?	B-Review	B-11	Review	511
It would be interesting to see more such statistics about the dataset	I-Review	I-11	Review	511
- Section 4.2: did you run experiments for BPE encoding?	B-Review	B-12	Review	511
Would be good to see as this is a bit of a non-standard choice.	I-Review	I-12	Review	511
<sep> - Section 4.2: it would be good to explain the Cer et al 2018 method directly in the paper	I-Review	I-12	Review	511
- Section 4.2: is there a reference for knowledge dropout?	I-Review	I-12	Review	511
Also, it would be good to show ablation results for this.	I-Review	I-12	Review	511
<sep> - Section 5.1: why did you choose to pre-train on the Reddit data?	B-Review	B-13	Review	511
There should be some more in-depth description of the Reddit dataset to motivate this choice.	I-Review	I-13	Review	511
<sep> - Section 5.1: what is the setup you use for multi-task learning on SQuAD?	I-Review	I-13	Review	511
Is it just a hard parameter sharing model, or?	I-Review	I-13	Review	511
<sep> - Section 5.3: as stated above, the human evaluation is a little bit underwhelming, both in terms of setup and results.	B-Review	B-14	Review	511
I'd expect a more fine-grained way of assessing conversations by humans, and also an explanation of why the retrieval performer without knowledge was assessed as being on par with the retrieval transformer memnet.	I-Review	I-14	Review	511
<sep> - Section 5.3: I assume higher=better for the human scores?	I-Review	I-14	Review	511
This should be made explicit.	I-Review	I-14	Review	511
<sep> - Section 5.3: Have others used the "F1 overlap score"?	I-Review	I-14	Review	511
If so, cite.	I-Review	I-14	Review	511
<sep> - Section 5.3: I don't understand the argument that the human evaluation shows that humans prefer more natural responses.	I-Review	I-14	Review	511
How does it show that?	I-Review	I-14	Review	511
<sep> - Section 5.3: The Wiki F1 score is kind of interesting because it shows to what degree the model uses knowledge.	I-Review	I-14	Review	511
But the side-by-side comparison with the human scores shows that humans don't necessarily prefer chatbot models that use a lot of knowledge.	I-Review	I-14	Review	511
I'd expect this to be discussed, and suggestions for future work to be made accordingly.	I-Review	I-14	Review	511
<sep> - Section 6: The paper ends a bit abruptly.	B-Review	B-15	Review	511
It's be nice to suggest future areas of improvement.	I-Review	I-15	Review	511
Thank you for your review and detailed feedback.	O	O	Reply	511
We apologize if our answer is long, but you had a lot of questions!	O	O	Reply	511
We have tried to answer them all and make necessary changes to the paper.	O	O	Reply	511
Thank you for your constructive comments.	O	O	Reply	511
<sep> <sep> - Missing reference for goal-oriented dialogue datasets: Wen et al 2017, A Network-based End-to-End Trainable Task-oriented Dialogue System, <a href="https://arxiv.org/abs/1604.04562:" target="_blank" rel="nofollow">https://arxiv.org/abs/1604.04562:</a>	B-Reply	B-6	Reply	511
o  Thank you, we have added this citation.	I-Reply	I-6	Reply	511
<sep> <sep> - How does the proposed dataset differ from the Reddit and Wikipedia datasets discussed in the last paragraph of the related work section?	O	O	Reply	511
This should be explained:	O	O	Reply	511
o  Compared to the related datasets we describe in Section 2, our dataset provides specific and high-quality grounding as we ask the Wizard to author dialogue based on the given knowledge (so we know what to ground to later when training models).	B-Reply	B-7	Reply	511
Further, we ask the Wizard to select which sentence the knowledge is from, giving even more fine-grained information.	I-Reply	I-7	Reply	511
In those existing tasks the data used to ground was not accessible during dialogue collection, and thus may or may not be related.	I-Reply	I-7	Reply	511
We believe this is why our task can lead to more successful models.	I-Reply	I-7	Reply	511
Moreover, our task provides easier analysis, e.g. we can measure knowledge selection metrics.	I-Reply	I-7	Reply	511
We have clarified this in the text.	I-Reply	I-7	Reply	511
<sep> <sep> - What is the maximum number of turns:	O	O	Reply	511
o  There is no maximum number of turns, the two human speakers can continue to speak (but the crowdworker pay is fixed, so typically they only do this when they are really enjoying it).	B-Reply	B-8	Reply	511
The maximum conversation length in the dataset is 23 utterances long.	I-Reply	I-8	Reply	511
This has been clarified in the paper.	I-Reply	I-8	Reply	511
<sep> <sep> - Page 3, paragraph "Knowledge Retrieval": how were the top 7 articles and first 10 sentences choices made?	O	O	Reply	511
This seems arbitrary.	O	O	Reply	511
Also, why wasn't the whole text used:	O	O	Reply	511
o  In order to keep crowdworkers from being overwhelmed, we chose for the worker to be exposed to no more than 15 different wikipedia articles at once (7 based on the Wizard's previous message, 7 based on the Apprentice's previous message, and 1 for the chosen topic), any higher was too much work to annotate.	B-Reply	B-9	Reply	511
The first ten sentences translated to roughly the first and second paragraphs of the wikipedia topic article, which we felt would be ample information for the conversations.	I-Reply	I-9	Reply	511
We did initially test varying amounts of sentences and articles, and we ultimately settled on these choices as they struck the best balance between keeping a conversation moving while also ensuring the Wizard had enough information to use in a response.	I-Reply	I-9	Reply	511
Note this does not necessarily limit a model using more, but was simply the sentences shown to crowdworkers at training time.	I-Reply	I-9	Reply	511
<sep> <sep> - Page 3, paragraph "Knowledge Selection and Response Generation": how do you deal with co-reference problems if you only ever select one sentence at a time?	O	O	Reply	511
The same goes for the "Knowledge Attention" model described in Section 4:	O	O	Reply	511
o  We do not handle coreference in any special way, but it is part of the task.	B-Reply	B-10	Reply	511
Annotators can read the sentences surrounding the one they click on, so they may make use of them.	I-Reply	I-10	Reply	511
Further, the crowdworkers and the model were both provided titles of the Wikipedia articles as well as their content for each of the potential knowledge sentences.	I-Reply	I-10	Reply	511
We observed that our generator model did learn to substitute this title in place of pronouns in certain cases.	I-Reply	I-10	Reply	511
Making use of further context is not addressed in our particular models, but could be in future work.	I-Reply	I-10	Reply	511
<sep> <sep> -  Page 3, paragraph "Knowledge Selection and Response Generation": how often do annotators choose "no sentence selected"?	O	O	Reply	511
It would be interesting to see more such statistics about the dataset:	O	O	Reply	511
o  The Wizards choose ‚Äúno sentence selected‚Äù around 6.2% of the time.	B-Reply	B-11	Reply	511
We have provided additional details about the human annotation interface, topic selection, and information about the data in the Appendix.	I-Reply	I-11	Reply	511

TDLR: The authors present a regularization method wherein they add noise to some representation space.	B-Review	B-5	Review	381
The paper mainly applies the technique w/ sequence autoencoders (Dai et al 2015) without the usage of attention (i.e., only using the context vector).	B-Review	B-7	Review	381
Experimental results show improvement from author's baseline on some toy tasks.	I-Review	I-6	Review	381
<sep> <sep> === Augmentation ===	O	O	Review	381
The augmentation process is simple enough, take the seq2seq context vector and add noise/interpolate/extrapolate to it (Section 3.2).	O	O	Review	381
This reviewer is very curious whether this process will also work in non seq2seq applications.	O	O	Review	381
<sep> <sep> This reviewer would have liked to see comparison with dropout on the context vector.	B-Review	B-8	Review	381
<sep> <sep> === Experiments ===	O	O	Review	381
Since the authors are experimenting w/ seq2seq architectures, its a little bit disappointing they didn't compare it w/ Machine Translation (MT), where there are many published papers to compare to.	B-Review	B-1	Review	381
<sep> <sep> The authors did compare their method on several toy datasets (that are less commonly used in DL literature) and MNIST/CIFAR.	B-Review	B-2	Review	381
The authors show improvement over their own baselines on several toy datasets.	I-Review	I-2	Review	381
The improvement on MNIST/CIFAR over the author's baseline seems marginal at best.	I-Review	I-2	Review	381
The author also didn't cite/compare to the baseline published by Dai et al 2015 for CIFAR -- here they have a much better LSTM baseline of 25% for CIFAR which beats the author's baseline of 32.35% and the author's method of 31.93%.	I-Review	I-2	Review	381
<sep> <sep> The experiments would be much more convincing if they did it on seq2seq+MT on say EN-FR or EN-DE.	B-Review	B-3	Review	381
There is almost no excuse why the experiments wasn't run on the MT task, given this is the first application of seq2seq was born from.	I-Review	I-3	Review	381
Even if not MT, then at least the sentiment analysis tasks (IMDB/Rotten Tomatoes) of the Dai et al 2015 paper which this paper is so heavily based on for the sequence autoencoder.	I-Review	I-3	Review	381
<sep> <sep> === References ===	O	O	Review	381
Something is wrong w/ your references latex setting?	B-Review	B-4	Review	381
Seems like a lot of the conference/journal names are omitted.	I-Review	I-4	Review	381
Additionally, you should update many cites to use the conference/journal name rather than just "arxiv".	I-Review	I-4	Review	381
<sep> <sep> Listen, attend and spell (should be Listen, Attend and Spell: A Neural Network for Large Vocabulary Conversational Speech Recognition) -> ICASSP	I-Review	I-4	Review	381
if citing ICASSP paper above, should also cite Bahandau paper "End-to-End Attention-based Large Vocabulary Speech Recognition" which was published in parallel (also in ICASSP).	I-Review	I-4	Review	381
<sep> <sep> Adam: A method for stochastic optimization -> ICLR	I-Review	I-4	Review	381
Auto-encoding variational bayes -> ICLR	I-Review	I-4	Review	381
Addressing the rare word problem in neural machine translation -> ACL	I-Review	I-4	Review	381
Pixel recurrent neural networks -> ICML	I-Review	I-4	Review	381
A neural conversational model -> ICML Workshop	I-Review	I-4	Review	381
<sep> Thanks for your feedback.	O	O	Reply	381
We wanted to point out a few simplifications in Reviewer 3‚Äôs TLDR statement which we thought unfairly represented the work:	O	O	Reply	381
- When R3 said ‚Äúthey add noise to some representation space‚Äù, this incorrectly represents what we did.	B-Reply	B-5	Reply	381
We experimented with noise injection, interpolation, and extrapolation in feature space and actually found that adding noise did not work well compared to extrapolation.	I-Reply	I-5	Reply	381
<sep> - When R3 said ‚ÄúExperimental results show improvement from author‚Äôs baseline on some toy tasks‚Äù, there are two errors here.	B-Reply	B-6	Reply	381
First, our Arabic Digits, Australian Sign Language Signs, and UCFKinect tests all include results that were not our own baselines; they were the best results reported by other groups that we could find on these datasets.	I-Reply	I-6	Reply	381
Second, while we completely agree that Arabic Digits, AUSLAN, UCFKinect, MNIST, and CIFAR-10 are not large-scale datasets, calling them toy seems unnecessarily punitive.	I-Reply	I-6	Reply	381
Our aim in choosing these datasets was breadth of modalities.	I-Reply	I-6	Reply	381
<sep> - We‚Äôre not sure why it was necessary to qualify ‚Äúwithout the usage of attention‚Äù in the TLDR statement as it does not seem relevant to what we are exploring.	B-Reply	B-7	Reply	381
<sep> <sep> We agree that it would be interesting to explore this approach on Machine Translation (or other text-based applications).	B-Reply	B-1	Reply	381
However, neither of the authors have experience in this domain and, to our understanding, most existing approaches require significant infrastructure (in terms of datasets and computational resources).	I-Reply	I-1	Reply	381
We weren't able to introduce such a pipeline in the time frame allotted by the review period, but we will certainly consider it in future work.	I-Reply	I-1	Reply	381
<sep> <sep> Dropout on the context vector can be seen as a specific case of our method; it‚Äôs a (severe) kind of noise applied to the feature-mapped inputs.	B-Reply	B-8	Reply	381
We performed some tests by applying dropout to the context vectors and found that it neither increased nor decreased performance significantly.	I-Reply	I-8	Reply	381
<sep> <sep> We acknowledge the discrepancy between the baseline published by Dai et al (26% error vs. our 32% error) and while we believe that we have exactly replicated their approach, we cannot explain the discrepancy.	B-Reply	B-2	Reply	381
We reached out to these authors requesting more detail but have yet to receive a response.	I-Reply	I-2	Reply	381
We have since tried more sophisticated classification (Wide ResNets), the details of which are in the response to Reviewer 1.	I-Reply	I-2	Reply	381
<sep> <sep> Thanks for catching the problem with the references; there was a serious error which we corrected.	B-Reply	B-4	Reply	381
We have updated the Arxiv papers that were subsequently published.	I-Reply	I-4	Reply	381
Thanks for taking the time to identify these.	I-Reply	I-4	Reply	381

The concept of data augmentation in the embedding space is very interesting.	O	O	Review	381
The method is well presented and also justified on different tasks such as spoken digits and image recognition etc.	O	O	Review	381
<sep> <sep> One comments of the comparison is the use of a simple 2-layer MLP as the baseline model throughout all the tasks.	B-Review	B-1	Review	381
It's not clear whether the gains maintain when a more complex baseline model is used.	I-Review	I-1	Review	381
<sep> <sep> Another comment is that the augmented context vectors are used for classification, just wondering how does it compare to using the reconstructed inputs.	B-Review	B-2	Review	381
And furthermore, as in Table 4, both input and feature space extrapolation improves the performance, whether these two are complementary or not?	I-Review	I-2	Review	381
Thank you for your positive feedback on the paper and your constructive suggestions.	O	O	Reply	381
<sep> <sep> With respect to the more complex baseline, since the reviews were received, we experimented with a more state-of-the-art architecture (Wide ResNets by Zagoruyko and Komodakis, 2016) for the CIFAR-10 task.	B-Reply	B-1	Reply	381
In all of our tests we held constant the  Wide Residual Network architecture (same as the one used in the Wide ResNets paper) and changed only the data.	I-Reply	I-1	Reply	381
We conducted tests on the following 6 setups:	I-Reply	I-1	Reply	381
Test 1 ‚Äì 32x32 input with no data augmentation (8.79% test error)	I-Reply	I-1	Reply	381
Test 2 - 24x24 center crops with no data augmentation (11.21% test error)	I-Reply	I-1	Reply	381
Test 3 - 24x24 center crops, reconstructed from context vectors of the original images, with no data augmentation (18.68% test error)	I-Reply	I-1	Reply	381
Test 4 - 24x24 center crops + extrapolation (14.11% test error)	I-Reply	I-1	Reply	381
Test 5 - 24x24 with simple data augmentation (shifting and horizontal flipping) (7.33% test error)	I-Reply	I-1	Reply	381
Test 6 - 24x24 with simple data augmentation + extrapolation (8.55% test error)	I-Reply	I-1	Reply	381
<sep> Overall performance improved greatly compared to our current sequence autoencoder + MLP results.	B-Reply	B-2	Reply	381
In the Test 4 and 6 described above, we used reconstructions of the extrapolated feature vectors (in addition to the original images) to train the classifier.	I-Reply	I-2	Reply	381
Although visual inspection of the reconstructions looked to us like valid training cases (i.e. objects maintained their class identity and we saw no visible artifacts) training with reconstructed extrapolated context vectors actually worsened performance.	I-Reply	I-2	Reply	381
We also trained a model on only reconstructions of the original examples mapped to context vectors (i.e. no extrapolation) for Test 3.	I-Reply	I-2	Reply	381
This test performed considerably worse compared to training on the original examples themselves (Test 2).	I-Reply	I-2	Reply	381
Therefore we believe that, at least for CIFAR-10, there is significant loss of fidelity of the examples (original or extrapolated) when mapping to and from context vectors.	I-Reply	I-2	Reply	381
We are currently investigating alternative methods that could be used to reduce the amount of error introduced during the reconstruction process,  such as static encoder-decoder architectures or performing extrapolation within the feature space of the classifier itself.	I-Reply	I-2	Reply	381
<sep> <sep> We‚Äôre still in the process of running these experiments, but will add the Wide ResNet results to the final version.	O	O	Reply	381

In this paper authors propose a novel data augmentation scheme where instead of augmenting the input data, they augment intermediate feature representations.	O	O	Review	381
Sequence auto-encoder based features are considered, and random perturbation, feature interpolation, and extrapolation based augmentation are evaluated.	O	O	Review	381
On three sequence classification tasks and on MNIST and CIFAR-10, it is shown that augmentation in feature space, specifically extrapolation based augmentation, results in good accuracy gains w.r.t.authors baseline.	O	O	Review	381
<sep> <sep> My main questions and suggestions for further strengthening the paper are:	O	O	Review	381
<sep> a) The proposed data augmentation approach is applied to a learnt auto-encoder based feature space termed ‚Äòcontext vector‚Äô in the paper.	B-Review	B-1	Review	381
The context vectors are then augmented and used as input to train classification models.	I-Review	I-1	Review	381
Have the authors considered applying their feature space augmentation idea directly to the classification model during training, and applying it to potentially many layers of the model?	I-Review	I-1	Review	381
Also, have the authors considered convolutional neural network (CNN) architectures as well for feature space augmentation?	I-Review	I-1	Review	381
CNNs are now the state-of-the-art in many image and sequence classification task, it would be very valuable to see the impact of the proposed approach in that model.	I-Review	I-1	Review	381
<sep> <sep> b) When interpolation or extrapolation based augmentation was being applied, did the authors also consider utilizing nearby samples from competing classes as well?	B-Review	B-2	Review	381
Especially in case of extrapolation based augmentation it will be interesting to check if the extrapolated features are closer to competing classes than original ones.	I-Review	I-2	Review	381
<sep> <sep> c) With random interpolation or nearest neighbor interpolation based augmentation the accuracy seems to degrade pretty consistently.	B-Review	B-3	Review	381
This is counter-intuitive.	I-Review	I-3	Review	381
Do the authors have explanation for why the accuracy degraded with interpolation based augmentation?	I-Review	I-3	Review	381
<sep> <sep> d) The results on MNIST and CIFAR-10 are inconclusive.	B-Review	B-4	Review	381
For instance the error rate on CIFAR-10 is well below 10% these days, so I think it is hard to draw conclusions based on error rates above 30%.	I-Review	I-4	Review	381
For MNIST it is surprising to see that data augmentation in the input space substantially degrades the accuracy (1.093% -> 1.477%).	I-Review	I-4	Review	381
As mentioned above, I think this will require extending the feature space augmentation idea to CNN based models.	I-Review	I-4	Review	381
Thank you for your valuable suggestions for improving the paper.	O	O	Reply	381
<sep> <sep> a) This is an interesting suggestion.	B-Reply	B-1	Reply	381
In the case where noise is the transformation, this would simply amount to noise injection in the hidden layer (which we know works well as a regularizer).	I-Reply	I-1	Reply	381
However, doing interpolation or extrapolation amounts to something that, to the best of our knowledge, hasn't been reported.	I-Reply	I-1	Reply	381
For this paper one of our aims was to keep the encoding architecture and transformation in feature space consistent, however, we are very interested in exploring this direction for the next paper.	I-Reply	I-1	Reply	381
<sep> <sep> b) Since the reviews were submitted we conducted some tests on utilizing samples from competing classes for extrapolation and interpolation, however we found that both approaches resulted in worse performance compared to the baseline.	B-Reply	B-2	Reply	381
<sep> <sep> c) We ran some additional synthetic data experiments where we could control the complexity of the class boundaries.	B-Reply	B-3	Reply	381
We found that extrapolation helped only in the case where there were complex class boundaries, not when the boundaries were simple (e.g. linearly separable, or one class encircling another).	I-Reply	I-3	Reply	381
However, interpolation did help in these simple cases.	I-Reply	I-3	Reply	381
Our best explanation at present is that interpolation tends to tighten class boundaries and unnecessarily increase confidence, leading to overfitting.	I-Reply	I-3	Reply	381
In essence, it may cause the model to ignore informative extremities that can describe a complex decision boundary and produce an unnecessarily smooth decision boundary.	I-Reply	I-3	Reply	381
High-dimensional, real datasets will typically have complex decision boundaries, and this is the case where we found extrapolation to shine.	I-Reply	I-3	Reply	381
We have added a discussion on this matter to the conclusion section in the most recent revision of the paper.	I-Reply	I-3	Reply	381
<sep> <sep> d) Please see our response to Reviewer 1 detailing the use of Wide ResNets.	B-Reply	B-4	Reply	381

There are many ways to reduce the memory footprint and increase speed of a neural network: weight quantisation, compression, coarse-to-fine, knowledge distillation, etc.	O	O	Review	381
The method proposed in this work is a specific case of knowledge distillation that focuses on the discrete-input-to-first-layer and output-layer-to-discrete-output transformations, which represent a large portion of the parameters.	O	O	Review	381
<sep> <sep> The authors propose to use a variant of SVD (which can be viewed as 2 linear transformation, with a middle dimension that represents an embedding), where the first transformation is linear with a ReLu, and the second is linear.	O	O	Review	381
By approximating the learned matrices of the model, the experiments show that using the proposed variant of SVD gives similar predictive performance compared to the original model, with a fraction of the parameters.	O	O	Review	381
<sep> <sep> However, it seems that the authors could have simply replaced the input by a 2-layer NN (first a linear+ReLu, then a Linear) to obtain the same parametrisation, but they could have learned the parameters in a end-to-end fashion.	B-Review	B-1	Review	381
It is not clear to me why using a surrogate L2 loss within the model should give better predictive performance than a fully end-to-end trained neural network.	I-Review	I-1	Review	381
Without this comparison, I do not think the proposed experiments are conclusive enough.	I-Review	I-1	Review	381
<sep> <sep> <sep> We sincerely thank the reviewer for their comments and suggestions to improve the paper.	O	O	Reply	381
<sep> <sep> We present the BLEU scores for the End-to-End 2 Layer NN (E2E-NN) approach and compare with SVD and our proposed solution below:	B-Reply	B-1	Reply	381
<sep> | Dataset | E2E-NN |  SVD  | Proposal |	I-Reply	I-1	Reply	381
|       ---     |      ---      |    ---   |       ---       |	I-Reply	I-1	Reply	381
|    En-Fr  |   37.23   | 37.44 |    37.78    |	I-Reply	I-1	Reply	381
|    En-De |   26.14   | 26.32 |    26.97    |	I-Reply	I-1	Reply	381
|    Pt-En  |   42.27   | 42.37 |    42.62    |	I-Reply	I-1	Reply	381
<sep> The end-to-end scheme does a little worse than SVD.	I-Reply	I-1	Reply	381
We think the performance improvement for SVD and our proposal both is due to a better initialization during offline training.	I-Reply	I-1	Reply	381
The difference between the End-to-End 2 layer NN and our proposal is that we initialize our method off-line and use the distillation term to regularize the embedding network.	I-Reply	I-1	Reply	381

The paper proposes to use low-rank matrix decomposition for embedding compression, with relu in the reconstruction layer to gain non-linearity.	O	O	Review	381
Experiments on machine translation task shows improvement compared with state-of-the-art methods with different compression rates.	O	O	Review	381
<sep> <sep> Detailed comments:	O	O	Review	381
1)<tab>The technical contribution seems to be a bit limited.	B-Review	B-1	Review	381
Using relu in the reconstruction function looks straightforward and adding reconstruction loss in objective function is also common practice.	I-Review	I-1	Review	381
Also, not much insight is provided on why such approach works better than other baselines.	I-Review	I-1	Review	381
<sep> <sep> 2)<tab>Experiments:	O	O	Review	381
a.<tab>It is good to see such simple approach outperforms several more sophisticated baseline methods.	B-Review	B-2	Review	381
Also, ablation study is also performed to show the effect of different components.	I-Review	I-2	Review	381
<sep> <sep> b.<tab>How does the time complexity and running time of the proposed method compared to the baselines?	B-Review	B-2	Review	381
<sep> <sep> c.<tab>The paper only evaluates distilled embedding on one task (i.e., machine translation).	B-Review	B-2	Review	381
The experiments would be more convincing if evaluated on more tasks as well.	I-Review	I-2	Review	381
<sep> <sep> d.<tab>It could be helpful to include some sensitivity analysis on the hyperparameters such as \alpha which controls the weight of reconstruction loss.	B-Review	B-2	Review	381
<sep> <sep> In conclusion, this paper seems to be below the bar and I would recommend a ‚Äòweak reject‚Äô for the paper.	O	O	Review	381
<sep> <sep> 1) We specifically chose RELU so that the model can learn to regularize certain embedding dimensions, which is useful when dealing with a high dimensional embedding space, further, since this will lead to a reduction in reconstruction performance, we introduce the reconstruction loss and hyper-parameter ‚Äòalpha‚Äô, to balance out regularization and reconstruction.	B-Reply	B-1	Reply	381
These were mentioned in the paper but you are right that they were not highlighted well.	I-Reply	I-1	Reply	381
<sep> 2) The reason we did not run experimental results for measuring the inference time is that the only accurate method to do it is either on edge device or in a simulated environment.	B-Reply	B-2	Reply	381
Secondly, more than inference speed, running memory reduction is also important that is where the SVD based techniques (including ours) are superior, as there is no need to reconstruct the entire embedding matrix.	I-Reply	I-2	Reply	381
We ran the experiment on inference speed and the results are shown below,	I-Reply	I-2	Reply	381
Experimental Setup: We used 1 P100 GPU (12GB), and measured the time for the forward graph on the validation dataset (size 7590), with a batch size of 1024.	I-Reply	I-2	Reply	381
We averaged this time for 30 runs and summarize are results below.	I-Reply	I-2	Reply	381
<sep> <sep> |              Model                        | Inference Time (Sec) |	I-Reply	I-2	Reply	381
| Distilled Embedding (ours) |           29.23                  |	I-Reply	I-2	Reply	381
| SVD                                         |           29.63                   |	I-Reply	I-2	Reply	381
| Structured Embedding        |           31.18                  |	I-Reply	I-2	Reply	381
| Base Model                           |           27.92                   |	I-Reply	I-2	Reply	381
We did not perform experiments on Group Reduce and Tensor Train, but they are likely to perform comparably to SVD and Our Method, or even slower.	I-Reply	I-2	Reply	381

<sep> <sep> This paper proposes a method for compressing embedding matrices of both encoder/decoder embeddings.	O	O	Review	381
<sep> The basic idea of the proposed method is to reconstruct the embedding matrix by what they called the ‚Äúfunneling decomposition‚Äù method, whose parameter shape is identical to the SVD (low-rank matrix) decomposition with additional non-linear function.	O	O	Review	381
<sep> Therefore, the idea itself is not so novel and innovative.	B-Review	B-3	Review	381
<sep> Moreover, their method requires the embedding matrix as the teacher signal for calculating the reconstruction loss.	I-Review	I-3	Review	381
<sep> We need to note that the memory requirement of the proposed method during training will increase.	I-Review	I-3	Review	381
<sep> One of the notable advantages of the proposed method is that their proposed method seems to successfully reduce the embedding matrix even if it shares the parameters with the output layer, which is a de-facto standard model architecture for NMT.	O	O	Review	381
<sep> As pointed out by the authors, this seems to be the first success of reducing the embedding matrix with a tied embedding setting.	O	O	Review	381
<sep> <sep> <sep> 1,	O	O	Review	381
The authors claim that ‚ÄúWe demonstrate that at the same compression rate our method outperforms existing state-of-the-art methods.	B-Review	B-1	Review	381
‚Äù at the end of the Introduction section.	I-Review	I-1	Review	381
<sep> However, according to Tables 1, 2, and 3, it seems that the performance gain is marginal compared with similar methods.	I-Review	I-1	Review	381
<sep> For example,	I-Review	I-1	Review	381
37.78 (proposed) &lt;=&gt; 37.78 (Shi &amp; Yu (2018))	I-Review	I-1	Review	381
26.97 (proposed) &lt;=&gt; 26.75 (Chen et al (2018)	I-Review	I-1	Review	381
and	I-Review	I-1	Review	381
42.62 (proposed) &lt;=&gt; 42.37 (SVD with rank 64),	I-Review	I-1	Review	381
which are the at most 0.25 BLEU gain.	I-Review	I-1	Review	381
<sep> I believe that most of MT researchers hardly say that BLEU 0.25 difference is a significant improvement.	I-Review	I-1	Review	381
Besides, the authors should perform a statistically significant test if they say ‚Äúour method outperforms existing state-of-the-art methods.	I-Review	I-1	Review	381
‚Äù	I-Review	I-1	Review	381
2	O	O	Review	381
I am a bit confused about the following inconsistency;	B-Review	B-2	Review	381
The authors say that ‚ÄúCompressing embedding matrices without sacrificing model performance is essential for successful commercial edge deployment‚Äù in the abstract.	I-Review	I-2	Review	381
<sep> However, according to Table 1, the number of parameters for embeddings is 16.3M, which is only 27% of the total number of parameters in Transformer base.	I-Review	I-2	Review	381
<sep> By this fact, compressing embedding matrices seems not essential for successful commercial edge deployment.	I-Review	I-2	Review	381
<sep> In Table 6, it is explicitly unclear what is the difference between	I-Review	I-2	Review	381
‚ÄúFunneling with Emb.	I-Review	I-2	Review	381
Distillation‚Äù, ‚ÄúFunneling (with non-linearity),‚Äù and ‚ÄúFunneling (with retraining all weights).‚Äù	I-Review	I-2	Review	381
Please give us a more precise explanation.	I-Review	I-2	Review	381
<sep> <sep> 1) We were careful not to use the word 'significantly' since we did not include any statistical significance tests.	B-Reply	B-1	Reply	381
We agree that it gives a better account of the improvement in performance but for these models, the computational cost for these analyses would be prohibitive.	I-Reply	I-1	Reply	381
We propose another way to compare the results of the proposed method against competing methods.	I-Reply	I-1	Reply	381
<sep> <sep> Proposed vs Shi &amp; Yu (2018):	I-Reply	I-1	Reply	381
<sep> En-Fr       37.78 (proposed) &lt;=&gt; 37.78	I-Reply	I-1	Reply	381
En-De      26.97 (proposed) &lt;=&gt; 26.34	I-Reply	I-1	Reply	381
Pt-En       42.62 (proposed) &lt;=&gt; 41.27	I-Reply	I-1	Reply	381
<sep> <sep> Proposed vs Chen et al (2018):	I-Reply	I-1	Reply	381
<sep> En-Fr       37.78 (proposed) &lt;=&gt; 37.63	I-Reply	I-1	Reply	381
En-De      26.97 (proposed) &lt;=&gt; 26.75	I-Reply	I-1	Reply	381
Pt-En       42.62 (proposed) &lt;=&gt; 42.13	I-Reply	I-1	Reply	381
<sep> <sep> Proposed vs SVD rank 64:	I-Reply	I-1	Reply	381
<sep> En-Fr       37.78 (proposed) &lt;=&gt; 37.44	I-Reply	I-1	Reply	381
En-De      26.97 (proposed) &lt;=&gt; 26.32	I-Reply	I-1	Reply	381
Pt-En       42.62 (proposed) &lt;=&gt; 42.37	I-Reply	I-1	Reply	381
<sep> Based on this we conclude that we are consistently better and .49 BLEU better on at least one dataset.	I-Reply	I-1	Reply	381
Our experimental philosophy was to use widely reported translation datasets, standard architectures and to re-train the models to convergence.	I-Reply	I-1	Reply	381
This meant that the performance of all competing methods was closer than previously anticipated and our proposed method scored consistently higher BLEU scores compared to the rest.	I-Reply	I-1	Reply	381
<sep> 2) We think that any commercial edge deployment of NLP models will combine a range of solutions including but not limited to weight quantization (depending on hardware), embedding compression, network weight reduction, parameter sharing and knowledge distillation.	B-Reply	B-2	Reply	381
Embedding matrices, in the experiments we presented, constitute  27% (En-Fr) to 74.45% (Pt-En) of the network parameters.	I-Reply	I-2	Reply	381
So depending on the rest of the model, embedding compression may help us shave 23% to 63% of the model (with our solution) without much loss of performance.	I-Reply	I-2	Reply	381
Any solution, other than quantization, which aims to reduce model size would need to compress or reduce the embedding size.	I-Reply	I-2	Reply	381
Quantization does not reduce the number of parameters but reduces the storage size.	I-Reply	I-2	Reply	381
However, it is hardware dependant and not always a viable option.	I-Reply	I-2	Reply	381
<sep> <sep> Moreover, embedding matrices are present in all NLP applications and constitute a majority of parameters for smaller models.	I-Reply	I-2	Reply	381
<sep> <sep> Regarding Table 6 we thank you for noticing.	I-Reply	I-2	Reply	381
We updated the formatting to make it clear.	I-Reply	I-2	Reply	381
We have revised the submission but briefly:	I-Reply	I-2	Reply	381
<sep> Model                                                         BLEU	I-Reply	I-2	Reply	381
Proposal                                                     42.60	I-Reply	I-2	Reply	381
- embedding dist.	I-Reply	I-2	Reply	381
42.44	I-Reply	I-2	Reply	381
- non-linearity                                       42.34	I-Reply	I-2	Reply	381
Proposal (Freeze non-emb weights)     33.34	I-Reply	I-2	Reply	381
Proposal (Freeze emb.	I-Reply	I-2	Reply	381
weights)            20.49	I-Reply	I-2	Reply	381
<sep> We compare the proposal against removing embedding distillation and removing embedding distillation and non-linearity.	I-Reply	I-2	Reply	381
We also show the effect of freezing the embedding weights during fine-tuning and freezing the non-embedding weights.	I-Reply	I-2	Reply	381

The authors demonstrate that it is possible to transfer across modalities (e.g., image-to-audio) by first abstracting the data with latent generative models and then learning transformations between latent spaces.	O	O	Review	1488
We find that a simple variational autoencoder is able to learn a shared latent space to bridge between two generative models in an unsupervised fashion, and even between different types of models (e.g., variational autoencoder and a generative adversarial network).	O	O	Review	1488
Some detailed comments are listed as follows,	O	O	Review	1488
1.	O	O	Review	1488
The technical parts are weak since the authors use the existing method with to some extent evolution.	B-Review	B-1	Review	1488
<sep> <sep> 2 The proposed method can transfer the positive knowledge.	B-Review	B-2	Review	1488
However, for the transfer learning, one concerned and important issue is that some negative knowledge information can be also transferred.	I-Review	I-2	Review	1488
So how to avoid the negative transferring?	I-Review	I-2	Review	1488
Some necessary discussions about this should be given in the manuscript.	I-Review	I-2	Review	1488
<sep> <sep> 2 There are many grammar errors in the current manuscript.	B-Review	B-3	Review	1488
The authors are suggested to improve the English writing.	I-Review	I-3	Review	1488
<sep> <sep> Thank you for your time and insight in your review.	O	O	Reply	1488
We‚Äôve done our best to address your key points below.	O	O	Reply	1488
<sep> <sep> > The technical parts are weak since the authors use the existing method with to some extent evolution.	O	O	Reply	1488
<sep> <sep> We would like to highlight that the problem this paper addresses (cross-modal domain transfer) is difficult and, to the best of our knowledge, relatively unexamined in the literature.	B-Reply	B-1	Reply	1488
We believe it is actually a desirable feature, and not a fault, that the proposed method is fairly straightforward and easy to implement.	I-Reply	I-1	Reply	1488
From a technical standpoint, the main contribution is not a single new model with which to perform domain transfer, but showing it is possible to ‚Äúglue together‚Äù the plethora of existing (and yet to be invented) models with small, simple, and efficient bridging models.	I-Reply	I-1	Reply	1488
While we have limited ourselves to several easily quantifiable problems for this paper, nothing about the proposed methods is limited to these models or datasets.	I-Reply	I-1	Reply	1488
<sep> <sep> > The proposed method can transfer the positive knowledge.	O	O	Reply	1488
However, for the transfer learning, one concerned and important issue is that some negative knowledge information can be also transferred.	O	O	Reply	1488
So how to avoid the negative transferring?	O	O	Reply	1488
Some necessary discussions about this should be given in the manuscript.	O	O	Reply	1488
<sep> <sep> <sep> Thank you for the suggestion.	B-Reply	B-2	Reply	1488
Transfer learning does indeed share some surface similarities to the proposed work in that it uses pretrained networks.	I-Reply	I-2	Reply	1488
We would like to highlight, however, that transfer learning is actually quite distinct from domain transfer in that the pretrained networks are used as feature extractors for a new task, while in this work the pretrained networks are used for the same task on which they were trained (generating samples from a given distribution).	I-Reply	I-2	Reply	1488
Since no information is passing between the pretrained networks, the features learned in one domain are not informing the solution of generation in the other domain.	I-Reply	I-2	Reply	1488
<sep> <sep> > There are many grammar errors in the current manuscript.	O	O	Reply	1488
The authors are suggested to improve the English writing.	O	O	Reply	1488
<sep> <sep> <sep> We agree with your assessment and apologize for the rushed condition of the initial submission.	B-Reply	B-3	Reply	1488
You will hopefully find that the updated draft has been extensively revised and restructured to improve the clarity of the writing and the arguments.	I-Reply	I-3	Reply	1488

In this paper, the authors study an interesting problem, i.e., heterogeneous domain transfer such as knowledge transfer between an image domain and a speech/audio domain.	O	O	Review	1488
In particular, the proposed solution contains two major steps: (i) pre-train each domain via VAE or GAN, and (ii) train a conditional VAE in semi-supervised manner in order to bridge two domains (see Section 2.2).	O	O	Review	1488
Experiments on three public datasets (including three cross-domain settings) show the effectiveness of the proposed two-step solution.	O	O	Review	1488
<sep> <sep> Some Comments/suggestions:	O	O	Review	1488
(i) The technical novelty (considering the two-step solution) is limited though the studied problem is very interesting.	B-Review	B-1	Review	1488
<sep> <sep> (ii) The authors are suggested to put the proposed solution in the context of transfer learning, which may better show the significance of this work.	B-Review	B-2	Review	1488
Currently, such a discussion and comparison is missing.	I-Review	I-2	Review	1488
<sep> <sep> (iii) There are many grammar errors throughout the whole paper.	B-Review	B-3	Review	1488
The authors are suggested to significantly improve the linguistic quality.	I-Review	I-3	Review	1488
<sep> <sep> (iv) A section of Conclusions is missing.	B-Review	B-4	Review	1488
<sep> <sep> Thank you for your time and expertise in your review, we've addressed the key points below:	O	O	Reply	1488
<sep> > (i) The technical novelty (considering the two-step solution) is limited though the studied problem is very interesting.	O	O	Reply	1488
<sep> <sep> We would like to highlight that the problem this paper addresses (cross-modal domain transfer) is difficult and, to the best of our knowledge, relatively unexamined in the literature.	B-Reply	B-1	Reply	1488
We believe it is actually a desirable feature, and not a fault, that the proposed method is fairly straightforward and easy to implement.	I-Reply	I-1	Reply	1488
<sep> <sep> Similarly, we believe the two-step training actually has some important advantages over end-to-end training.	I-Reply	I-1	Reply	1488
First, this approach allows us to combine models that use dramatically different training procedures.	I-Reply	I-1	Reply	1488
We demonstrate that in this paper by transferring between a maximum-likelihood trained VAE and an adversarial-trained GAN.	I-Reply	I-1	Reply	1488
Second, for large generative models that take weeks to train, it would be infeasible to retrain the entire model for each new domain mapping.	I-Reply	I-1	Reply	1488
As a small example from this paper, training the bridging autoencoder from MNIST->SC09 takes ~1 hour on a single gpu, while retraining the SC09 WaveGAN takes ~4 days.	I-Reply	I-1	Reply	1488
We have also restricted ourselves to intuitive class-level mappings for the purpose of quantitative comparisons in this paper, but in a creative application it is likely each user would prefer their own unique mapping between domains.	I-Reply	I-1	Reply	1488
<sep> <sep> > ‚ÄúThe authors are suggested to put the proposed solution in the context of transfer learning, which may better show the significance of this work.	O	O	Reply	1488
Currently, such a discussion and comparison is missing.	O	O	Reply	1488
‚Äù	O	O	Reply	1488
<sep> Thank you for the suggestion.	B-Reply	B-2	Reply	1488
Transfer learning does indeed share some surface similarities to the proposed work in that it uses pretrained networks.	I-Reply	I-2	Reply	1488
We would like to highlight, however, that transfer learning is actually quite distinct from domain transfer in that the pretrained networks are used as feature extractors for a new task, while in this work the pretrained networks are used for the same task on which they were trained (generating samples from a given distribution).	I-Reply	I-2	Reply	1488
Since no information is passing between the pretrained networks, the features learned in one domain are not informing the solution of generation in the other domain.	I-Reply	I-2	Reply	1488
<sep> <sep> > ‚ÄúThere are many grammar errors throughout the whole paper.	O	O	Reply	1488
The authors are suggested to significantly improve the linguistic quality.	O	O	Reply	1488
‚Äù	O	O	Reply	1488
> ‚ÄúA section of Conclusions is missing.	O	O	Reply	1488
‚Äù	O	O	Reply	1488
<sep> <sep> We agree with your assessment and apologize for the rushed condition of the initial submission.	B-Reply	B-4	Reply	1488
You will hopefully find that the updated draft has been extensively revised and restructured to improve the clarity of the writing and the arguments, including adding a conclusion section.	I-Reply	I-4	Reply	1488

In this paper, the authors have proposed a cross domain transferring methods, supervised by three category of losses.	O	O	Review	1488
The experiments somewhat demonstrate the effective of this method.	O	O	Review	1488
However, this paper still suffers from some drawbacks as below:	O	O	Review	1488
The paper is not well-organized, the structure of the paper need improving.	B-Review	B-1	Review	1488
For example, the related work is put almost at the end of the paper and the tables and figures are hard to follow sometimes.	B-Review	B-2	Review	1488
<sep> The technical implementation of the proposition is somewhat trivial.	B-Review	B-3	Review	1488
Why the generative model should be pre-trained.	I-Review	I-3	Review	1488
Why not try in the end-to-end way.	I-Review	I-3	Review	1488
<sep> The experiments are not convincing.	B-Review	B-4	Review	1488
The authors argue that CycleGAN suffers from some drawback.	I-Review	I-4	Review	1488
Why do not the authors compare with CycleGAN in this paper?	I-Review	I-4	Review	1488
By the way, the authors also need to compare with more state-of-the-art methods, such as StarGAN.	I-Review	I-4	Review	1488
<sep> Some implementation details are not clearly stated.	B-Review	B-5	Review	1488
For example, the authors say ‚ÄúOur goal can thus be stated as learning transformations that preserve locality and semantic alignment, while requiring as few labels from a user as possible.	I-Review	I-5	Review	1488
‚Äù So, how many labeled samples are used in Table 2?	I-Review	I-5	Review	1488
Thank you for your time and insight in your review.	O	O	Reply	1488
We've done our best to address your concerns with paper revisions and in the comments below:	O	O	Reply	1488
<sep> > ‚ÄúThe paper is not well-organized, the structure of the paper need improving.	O	O	Reply	1488
‚Äù	O	O	Reply	1488
<sep> We agree with your assessment and thank you for your helpful suggestions.	B-Reply	B-1	Reply	1488
The updated draft has been extensively revised and restructured.	I-Reply	I-1	Reply	1488
For example, following your advice, we have moved the new related work section to follow the methods, and added more details to the figure and table captions to make their explanations self contained.	I-Reply	I-1	Reply	1488
<sep> <sep> > ‚ÄúThe technical implementation of the proposition is somewhat trivial.	O	O	Reply	1488
Why the generative model should be pre-trained.	O	O	Reply	1488
Why not try in the end-to-end way. ‚	O	O	Reply	1488
Äú	O	O	Reply	1488
<sep> We would like to highlight that the problem this paper addresses (cross-modal domain transfer) is difficult and, to the best of our knowledge, relatively unexamined in the literature.	B-Reply	B-3	Reply	1488
We believe it is actually a desirable feature, and not a fault, that the proposed method is fairly straightforward and easy to implement.	I-Reply	I-3	Reply	1488
<sep> <sep> The point about end-to-end training is well-taken.	I-Reply	I-3	Reply	1488
For simpler problems, like MNIST <-> MNIST, and MNIST<-> Fashion MNIST, end-to-end training is indeed tractable.	I-Reply	I-3	Reply	1488
However, we would like to highlight some advantages of the multi-step approach.	I-Reply	I-3	Reply	1488
First, this approach allows us to combine models that use dramatically different training procedures.	I-Reply	I-3	Reply	1488
We demonstrate that in this paper by transferring between a maximum-likelihood trained VAE and an adversarial-trained GAN.	I-Reply	I-3	Reply	1488
Second, for large generative models that take weeks to train, it would be infeasible to retrain the entire model for each new domain mapping.	I-Reply	I-3	Reply	1488
As a small example from this paper, training the bridging autoencoder from MNIST->SC09 takes ~1 hour on a single gpu, while retraining the SC09 WaveGAN takes ~4 days.	I-Reply	I-3	Reply	1488
We have also restricted ourselves to intuitive class-level mappings for the purpose of quantitative comparisons in this paper, but in a creative application it is likely each user would prefer their own unique mapping between domains.	I-Reply	I-3	Reply	1488
<sep> <sep> <sep> > ‚ÄúThe authors argue that CycleGAN suffers from some drawback.	O	O	Reply	1488
Why do not the authors compare with CycleGAN in this paper?‚Äù	O	O	Reply	1488
<sep> Thank you for the observation that we could use better external baselines to compare against for domain transfer.	B-Reply	B-4	Reply	1488
We have added comparisons to pix2pix and CycleGAN for MNIST <-> Fashion MNIST.	I-Reply	I-4	Reply	1488
We find lower transfer accuracies and image quality (which we calculate with Frechet Inception Distance), which can be seen in Table 2 and Appendix C. The MNIST <-> MNIST scenario involved transferring between pretrained models with different initial conditions which is not directly comparable and has been omitted.	I-Reply	I-4	Reply	1488
In MNIST <-> SC09, the two domains were too distinct to provide any reasonable transfer with existing methods.	I-Reply	I-4	Reply	1488
<sep> <sep> As we mentioned in the paper, we also tried to train a CycleGAN between latent spaces, but weren‚Äôt unable to train the model at all, as the reconstruction loss was often trivially satisfied between models trained with the same Gaussian prior.	I-Reply	I-4	Reply	1488
This was an important finding for us, and gave us motivation to look at other methods for modeling transfer between latent spaces.	I-Reply	I-4	Reply	1488
<sep> <sep> > ‚Äúthe authors also need to compare with more state-of-the-art methods, such as StarGAN.‚Äù	O	O	Reply	1488
<sep> As mentioned above, thank you for pointing out the need for more baselines and we have now included comparisons to pix2pix and CycleGAN.	B-Reply	B-4	Reply	1488
We agree that StarGAN is an impressive model for multi-domain transfer, however, unlike the rest of the methods we compare, it requires additional target label information to be provided by the user at transfer time, which we feel makes CycleGAN a more natural comparison.	I-Reply	I-4	Reply	1488
Also, like CycleGAN, to the best of our knowledge these techniques still rely on structural similarities between domains and do not work as well for multi-modal transfer.	I-Reply	I-4	Reply	1488
<sep> <sep> > ‚ÄúSome implementation details are not clearly stated. ...	O	O	Reply	1488
how many labeled samples are used in Table 2?‚Äù	O	O	Reply	1488
<sep> As part of the paper revisions, we have done our best to make all the implementation details more explicit.	B-Reply	B-5	Reply	1488
For example, in the caption table 2, we discuss that we use all available labels (60k for MNIST<-> Fashion MNIST, 16k for MNIST <-> SC09).	I-Reply	I-5	Reply	1488
Table 3 then performs a comparison as the amount of data labels are reduced.	I-Reply	I-5	Reply	1488

This paper introduces an auxiliary cost function which forces the representation learnt in a particular layer to be useful for clustering.	O	O	Review	36
This can be added to any classification model or unsupervised model like autoencoder.	O	O	Review	36
Authors show that adding this loss helps in better clustering of examples in a binary classification task and auto-encoder task.	O	O	Review	36
The model does not have access to any cluster information and it learns to group examples based on their characteristics.	O	O	Review	36
<sep> <sep> The proposed objective function roughly maximizes the KL-Divergence between the probability distributions induced from the row vectors in a weight matrix.	O	O	Review	36
I like the idea of directly considering weights instead of considering the unit activations as done in DeCov.	O	O	Review	36
Also from experiments, proposed approach does better than DeCov.	O	O	Review	36
<sep> <sep> While this is an interesting idea, I encourage the authors to verify the benefits of the proposed loss in a variety of datasets.	B-Review	B-1	Review	36
Also it looks like one can combine both DeCov and the proposed loss.	I-Review	I-1	Review	36
They look complementary.	I-Review	I-1	Review	36
<sep> <sep> Can you also plot Figure 2 with DeCov loss?	B-Review	B-2	Review	36
<sep> <sep> Pros:	O	O	Review	36
+ New cost function for learning representations useful for clustering	O	O	Review	36
+ Proof of concept experiments that show the method works.	O	O	Review	36
<sep> <sep> Cons:	O	O	Review	36
- Needs benchmarking with several tasks and datasets.	B-Review	B-1	Review	36
<sep> <sep> Dear reviewer,	O	O	Reply	36
<sep> We have updated the paper with the figure for the DeCov loss.	B-Reply	B-2	Reply	36
The observed trend (a strong activation of one of the neurons in the penultimate layer) is even clearer in the case of DeCov, which corresponds to the lowest AMI score on the clustering task.	I-Reply	I-2	Reply	36

[Overview]	O	O	Review	721
<sep> In this paper, the authors proposed a compositional image generation methods that combines multiple objects and background into the final images.	O	O	Review	721
Unlike the counterpart which compose the images sequentially, the proposed method infer the relationships between multiple objects through a relational network before sending the hidden vectors to the generators.	O	O	Review	721
This way, the method can model the object-object interactions during the image generation.	O	O	Review	721
From the experimental results, the authors demonstrated that the proposed k-GAN can generate the images with comparable or slightly better FID compared with baseline GAN, and achieve plausible performance under the human study.	O	O	Review	721
<sep> <sep> [Strengthes]	O	O	Review	721
<sep> 1.	O	O	Review	721
This paper proposed an interesting method for compositional image generation.	O	O	Review	721
Unlike the counterparts like LR-GAN, which generate foreground objects recurrently, this method proposed to derive the relationships between objects in parallel simultaneously.	O	O	Review	721
This kind of relational modeling has been seen in many other domains.	O	O	Review	721
It would be nice to see it can be applied to the compositional image generation domain.	O	O	Review	721
<sep> <sep> 2.	O	O	Review	721
The authors tried multiple synthesized datasets, including multi-MNIST and its variants, CLEVR.	O	O	Review	721
From the visualization, it is found that the proposed k-GAN can learn to disentangle different objects and the objects from the background.	O	O	Review	721
This indicates that the proposed model indeed capture the hidden structure of the images through relational modeling.	O	O	Review	721
The human study on these generated images further indicate that the generated images based on k-GAN is better than those generated by baseline GAN.	O	O	Review	721
<sep> <sep> [Weaknesses]	O	O	Review	721
<sep> 1.	O	O	Review	721
The main contribution of this paper fall to the proposed method for modeling the relational structure for multiple objects in the images.	B-Review	B-1	Review	721
In the appendix, the authors presented the results for the ablated version which does not consider the relationships.	I-Review	I-1	Review	721
As the authors pointed out, these results are a bit counterintuitive and concluded that FID is not a good metrics for evaluating compositional generation.	I-Review	I-1	Review	721
However, as far as I know, the compositional generation can achieve much better Inception scores on CIFAR-10 in LR-GAN paper (Yang et al).	I-Review	I-1	Review	721
Combining the results on MNIST in LR-GAN paper, I would suspect that the datasets used in this paper are fairly simple and all methods can achieve good results without much efforts.	I-Review	I-1	Review	721
It would be good to show some results on more complicated datasets, such as face images with background, or cifar-10.	I-Review	I-1	Review	721
Also, the authors did not present the qualitative results for independent version of k-GAN.	I-Review	I-1	Review	721
Meanwhile, they missed an ablated human study when the relational modeling is muted.	I-Review	I-1	Review	721
I would like to see how the generated images without modeling relationships look like to humans.	I-Review	I-1	Review	721
<sep> <sep> 2.	O	O	Review	721
Following the above comment, I think the datasets used in this paper is relatively simpler.	B-Review	B-2	Review	721
In MM and CLEVR, the foreground objects are digits or simple cubes, spheres or cylinders.	I-Review	I-2	Review	721
Also, the background is also simpler for these two datasets.	I-Review	I-2	Review	721
Though CIFAR10+MM has a more complicated background, it is trivial for the model to distinguish the foregrounds from the backgrounds.	I-Review	I-2	Review	721
Again, the authors should try more complicated datasets.	I-Review	I-2	Review	721
<sep> <sep> 3.	O	O	Review	721
Though the proposed method can model the relationship between objects simultaneously, I doubt its ability to  really being able to disentangle the foregrounds from the backgrounds.	B-Review	B-3	Review	721
Since the background and foregrounds are both whole images, which are then combined with an alpha blending, the model cannot discover the conceptually different properties for foreground and background that foregrounds are usually small than background and scattered at various locations.	I-Review	I-3	Review	721
Actually, this has been partially demonstrated by Figure 4.	I-Review	I-3	Review	721
In the last row, we can find one sphere is in the background image.	I-Review	I-3	Review	721
I tend to think the proposed model performs similar to Kwak & Zhang's paper without a strong proof for the authors that the relational modeling plays an important role in the model.	I-Review	I-3	Review	721
<sep> <sep> 4.	B-Review	B-4	Review	721
It would be nice to perform more analysis on the trained k-GAN.	I-Review	I-4	Review	721
Given the training set, like MM or CLEVR, I am wondering whether k-GAN can learn some reasonable relationship from the datasets.	I-Review	I-4	Review	721
That is, whether it is smart enough to infer the right location for each objet by considering the others.	I-Review	I-4	Review	721
This analysis can be performed, how much occlusions the generated images have compared with the real images.	I-Review	I-4	Review	721
For example, on CLEVR, I noticed from the appendix that the generated CLEVR images base on k-GAN actually have some severe occlusions/overlaps.	I-Review	I-4	Review	721
<sep> <sep> [Summary]	O	O	Review	721
<sep> In this paper, the authors proposed an interesting method for image generation compositionally.	O	O	Review	721
Instead of modeling the generation process recurrently, the authors proposed to model the relationships simultaneously in the hidden vector space.	O	O	Review	721
This way, the model can generate multiple foreground objects and backgrounds more flexibly.	O	O	Review	721
However, as pointed above, the paper missed some experiment, ablation study and analysis to demonstrate the relational modeling in the image generation.	O	O	Review	721
The author need to either try more complicated images or add deeper analysis on the recent experimental results.	O	O	Review	721
Thank you for your consideration and feedback.	O	O	Reply	721
<sep> <sep> The primary motivation of this work is to argue for object compositionality in deep generative models (and in particularly GANs), which originates from two key observations.	O	O	Reply	721
First, real-world images are to a large degree compositional, and a generative model that is suitable equipped with a corresponding inductive bias should be better at capturing this distribution.	O	O	Reply	721
Second, in disentangling information content corresponding to different objects at a representational level they may be recovered a posteriori unlike in unstructured models.	O	O	Reply	721
<sep> <sep> In the following we will answer each of your comments.	O	O	Reply	721
<sep> <sep> (1) Our conclusion regarding FID arises from the way the Inception network (that provides the embedding) was trained.	B-Reply	B-1	Reply	721
In particular, by training on ImageNet for single-object classification it is unlikely that deep layers (eg.logits or final max-pool) provide high-level features that capture properties of multiple objects accurately.	I-Reply	I-1	Reply	721
In particular, it suggests that FID is limited in accurately evaluating generated images containing multiple objects, even though it is accurate in evaluating generative models on ImageNet (or related single-object tasks like CIFAR10, etc.)	I-Reply	I-1	Reply	721
as shown in [4]. Similarly, this does not preclude LR-GAN (or other compositional approaches) from using FID on ImageNet or CIFAR10.	I-Reply	I-1	Reply	721
<sep> <sep> On the contrary, we compute FID on multi-object images using an inception network that was pre-trained on single-object images (ImageNet).	B-Reply	B-1	Reply	721
We are interested in verifying that the generated images are faithful with respect to the training distribution in terms of the number of objects, their identities, etc.	I-Reply	I-1	Reply	721
To the best of our knowledge FID has not been used in this way previously.	I-Reply	I-1	Reply	721
LR-GAN [5] evaluates the Inception score only on MNIST-ONE and not on MNIST-TWO, although they conclude that it is unsuitable even in the single object case (see Appendix 6.3).	I-Reply	I-1	Reply	721
Based on our own observations in using FID on multi-object datasets (as summarised in Figure 9) we argue that FID is unable to judge generated images based on specific properties relating to multiple objects (eg.their total number, etc.).	I-Reply	I-1	Reply	721
The large differences that are observed in evaluating the subjective quality (human eval - Figure 6a) for models with similar FID provide additional evidence that this is the case.	I-Reply	I-1	Reply	721
<sep> <sep> (2) In this work we are interested generating scenes as compositions of objects, and in particular in verifying that this information can be disentangled at a representation level.	B-Reply	B-2	Reply	721
This requires evaluation on datasets for which a clear notion of ‚Äúobject‚Äù is available.	I-Reply	I-2	Reply	721
Compared to prior work that has focused primarily on the representation learning part (eg. [	I-Reply	I-2	Reply	721
1, 2, 3]), we focus on scaling these insights to more complex multi-object datasets.	I-Reply	I-2	Reply	721
<sep> <sep> We would like to emphasize that relevant prior work has only focused on Multi-MNIST [1, 2, 3], Shapes [2, 3], and Textured MNIST [3]. In this work we consider several more complex datasets, including two relational version of Multi-MNIST (triplet, rgb), a variation on CIFAR10 that has RGB MNIST digits in the foreground, and high-resolution CLEVR images that contain many rendered geometric objects and require lighting and shadows to be modeled.	B-Reply	B-2	Reply	721
<sep> <sep> Ideally we would be able to apply our approach to common segmentation datasets (eg.Pascal VOC, COCO) although in practice we find that these are still far out of reach for purely unsupervised approaches.	B-Reply	B-2	Reply	721
Such datasets have been designed with access to ground-truth labels in mind and the large imbalance between the visual complexity of objects (i.e. intra-class variation) and the number of samples renders them unsuitable for our purpose.	I-Reply	I-2	Reply	721
We consider CLEVR to be among the more complex multi-object datasets that are balanced in this way, and hence the feasibility of our approach on this dataset is an important step forward compared to prior work.	I-Reply	I-2	Reply	721

This paper explores compositional image generation.	O	O	Review	721
Specifically, from a set of latent noises, the relationship between the objects is modelled using an attention mechanism to generate a new set of latent representations encoding the relationship.	O	O	Review	721
A generator then creates objects separately from each of these (including alpha channels).	O	O	Review	721
A separate generator creates the background.	O	O	Review	721
The objects and background are finally combined in a final image using alpha composition.	O	O	Review	721
An independent setting is also explored, where the objects are directly sampled from a set of random latent noises.	O	O	Review	721
<sep> <sep> My main concern is that the ideas, while interesting, are not novel, the method not clearly motivated, and the paper fails to convince.	B-Review	B-1	Review	721
<sep> <sep> It is interesting to see that the model was able to somewhat disentangle the objects from the background.	B-Review	B-2	Review	721
However, overall, the experimental setting is not fully convincing.	I-Review	I-2	Review	721
The generators seem to generate more than one object, or backgrounds that do contain objects.	I-Review	I-2	Review	721
The datasets, in particular, seem overly simplistic, with background easily distinguishable from the objects.	I-Review	I-2	Review	721
A positive point is that all experimented are ran with 5 different seeds.	I-Review	I-2	Review	721
The expensive human evaluation used does not provide full understanding and do not seem to establish the superiority of the proposed method.	I-Review	I-2	Review	721
<sep> <sep> The very related work by Azadi et al on compositional GAN, while mentioned, is not sufficiently critiqued or adequately compared to within the context of this work.	B-Review	B-3	Review	721
<sep> <sep> The choice of an attention mechanism to model relationship seems arbitrary and perhaps overly complicated for simply creating a set of latent noises.	B-Review	B-4	Review	721
What happens if a simple MLP is used?	I-Review	I-4	Review	721
Is there any prior imposed on the scene created?	I-Review	I-4	Review	721
Or on the way the objects should interact?	I-Review	I-4	Review	721
<sep> On the implementation side, what MLP is used, how are its parameters validated?	B-Review	B-5	Review	721
<sep> <sep> What is the observed distribution of the final latent vectors?	B-Review	B-6	Review	721
How does this affect the generation process?	I-Review	I-6	Review	721
Does the generator use all the latent variables or only those with highest magnitude?	I-Review	I-6	Review	721
<sep> The attention mechanism has a gate, effectively adding in the original noise to the output ‚Äî is this a weighted sum?	B-Review	B-7	Review	721
If so, how are the coefficient determined, if not, have the authors tried?	I-Review	I-7	Review	721
<sep> <sep> The paper goes over the recommended length (still within the limit) but still fails to include some important details ‚Äîmainly about the implementation‚Äî while some of the content could be shortened or moved to the appendix.	B-Review	B-8	Review	721
Vague, unsubstantiated claims, such as that structure of deep generative models of images is determined by the inductive bias of the neural network are not really explained and do not bring much to the paper.	I-Review	I-8	Review	721
Thank you for your feedback and consideration.	O	O	Reply	721
<sep> <sep> In the following we first provide an overview of the main answers regarding your main concern that ‚Äú... the ideas, while interesting, are not novel, the method not clearly motivated, and the paper fails to convince‚Äù before proceeding to a detailed discussion:	O	O	Reply	721
<sep> * Compositionality is critical in reducing complex visual scenes to a set of primitives (objects) that can be re-combined freely to generate new scenes (combinatorial productivity).	B-Reply	B-1	Reply	721
There is substantial empirical evidence that neural networks can benefit from this in image processing tasks.	I-Reply	I-1	Reply	721
<sep> * The novelty of our approach is in combining insights from unsupervised multi-object image processing (representation learning) with GANs that have proven useful in generating complex images.	B-Reply	B-1	Reply	721
<sep> * The datasets that we consider are non-trivial and substantially more complex compared to relevant related work that only considers variations of Multi-MNIST.	B-Reply	B-1	Reply	721
Our results on CLEVR already significantly advance upon the state of the art in terms of unsupervised multi-object image-processing.	I-Reply	I-1	Reply	721
<sep> * The experimental evaluation is sound and the reported results are representative for the model performance: it consistently generates images as a composition of individual objects.	B-Reply	B-1	Reply	721
<sep> * Compared to a strong baseline of GANs we find that the generated images are of higher quality, and more faithful to the reference distribution, as confirmed by a large scale human study.	B-Reply	B-1	Reply	721
<sep> <sep> Detailed answers below:	O	O	Reply	721
<sep> The primary motivation of this work is to argue for object compositionality in deep generative models (and in particularly GANs), which originates from two key observations.	B-Reply	B-1	Reply	721
First, real-world images are to a large degree compositional, and a generative model that is suitable equipped with a corresponding inductive bias should be better at capturing this distribution.	I-Reply	I-1	Reply	721
Second, in disentangling information content corresponding to different objects at a representational level they may be recovered a posteriori unlike in unstructured models.	I-Reply	I-1	Reply	721
<sep> <sep> In our experiments we find that the proposed model is successful in doing both: it generates images of higher-quality that are more faithful to the reference distribution (as per human evaluation), and it consistently disentangles information content belonging to different objects (visual inspection).	B-Reply	B-2	Reply	721
<sep> <sep> We would like to emphasize this last part, and point out that the reported images in Figures 3 & 4 are representative of how the best performing models generate the scene.	B-Reply	B-2	Reply	721
In other words, on all datasets we consistently find that the network generates the images as a composition of individual objects.	I-Reply	I-2	Reply	721
Indeed on CLEVR we found cases in which a component generates more than one object, which is understood by the fact that the number of components is smaller than the number of objects in the scene (see also Figure 8 in Appendix A).	I-Reply	I-2	Reply	721
We also find infrequent cases (primarily on CLEVR, although sometimes on CIFAR10) in which the background generator generates an additional object.	I-Reply	I-2	Reply	721
This is understandable as there are no restrictions in our approach that prevent it from doing so.	I-Reply	I-2	Reply	721
However, given that in almost all other cases the network generate images as compositions of objects and background it seems reasonable to conclude that these are due to optimization issues (as are common in GANs).	I-Reply	I-2	Reply	721
After all, the compositional solution is clearly the superior choice, as is evident from our human evaluation compared to regular GAN.	I-Reply	I-2	Reply	721
<sep> <sep> The proposed framework combines insights from related work in multi-object image generation and relational reasoning.	B-Reply	B-3	Reply	721
There is substantial evidence that object compositionality is beneficial in a variety of image-related tasks, although purely unsupervised approaches (in particular those targeted at discovering object representations) have only been evaluated on toy datasets.	I-Reply	I-3	Reply	721
GANs have been shown to scale to complex images, and the proposed approach demonstrates that a combination of these ideas is fruitful.	I-Reply	I-3	Reply	721
More specifically, our contributions are (1) an implementation of recent insights from unsupervised multi-object image processing in the GAN framework, (2) strong evidence that a deep generative model may learn about objects purely through the process of generation (i.e. without a ‚Äúdecoder‚Äù), (3) strong evidence that object compositionality benefits the quality and properties of generated images, and (4) strong evidence that these ideas can be scaled to more complex datasets in using GANs.	I-Reply	I-3	Reply	721

The paper proposes a compositional generative model for GANs.	O	O	Review	721
Basically, assuming existence of K objects in the image, the paper creates a latent representation for each object as well as a latent representation for the background.	O	O	Review	721
To model the relation between objects, the paper utilizes the multi-head dot-product attention (MHDPA) due to Vaswani et a. 2017.	O	O	Review	721
Applying MHDPA to the K latent representations results in K new latent representations.	O	O	Review	721
The K new representations are then fed into a generator to synthesize an image containing one object.	O	O	Review	721
The K images together with the synthesized background image are then combined together to form the final image.	O	O	Review	721
The paper compares to the proposed approach to the standard GAN approach.	O	O	Review	721
The reported superior performance suggest the inductive bias of compositionality of scene leads to improved performance.	O	O	Review	721
<sep> <sep> The method presented in the paper is a sensible approach and is overall interesting.	O	O	Review	721
The experiment results clearly shows the advantage of the proposed method.	O	O	Review	721
However, the paper does have several weak points.	O	O	Review	721
Firs of all, it misses an investigation of alternative network design for achieving the same compositionality.	B-Review	B-1	Review	721
For example, what would be the performance difference if one replace the MHDPA with LSTM.	I-Review	I-1	Review	721
Another weak point is that it is unclear if the proposed method can be generalize to handle more complicated scene such as COCO images as the experiments are all conducted using very toy-like image datasets.	B-Review	B-2	Review	721
Thank you for your consideration and feedback.	O	O	Reply	721
<sep> <sep> The primary motivation of this work is to argue for object compositionality in deep generative models (and in particularly GANs), which originates from two key observations.	B-Reply	B-3	Reply	721
First, real-world images are to a large degree compositional, and a generative model that is suitable equipped with a corresponding inductive bias should be better at capturing this distribution.	I-Reply	I-3	Reply	721
Second, in disentangling information content corresponding to different objects at a representational level they may be recovered a posteriori unlike in unstructured models.	I-Reply	I-3	Reply	721
<sep> <sep> > ‚Äú... it is unclear if the proposed method can be generalize to handle more complicated scene such as COCO images as the experiments are all conducted using very toy-like image datasets.	O	O	Reply	721
‚Äù	O	O	Reply	721
<sep> Our works builds on prior work in purely unsupervised multi-object image generation and representation learning.	B-Reply	B-2	Reply	721
Whereas prior work has focused primarily on the representation learning part (eg. [	I-Reply	I-2	Reply	721
3, 4, 5]), here our focus is on scaling these ideas to more complex datasets.	I-Reply	I-2	Reply	721
In particular, among the multi-object datasets considered in relevant prior work are Multi-MNIST [3, 4, 7], Shapes [4, 5], and Textured MNIST [5]. In this work we consider several more complex datasets, including two relational version of Multi-MNIST (triplet, rgb), a variation on CIFAR10 that has RGB MNIST digits in the foreground, and high-resolution CLEVR images that contain many rendered geometric objects and require lighting and shadows to be modeled.	I-Reply	I-2	Reply	721
<sep> <sep> Ideally we would be able to apply our approach to common segmentation datasets (eg.Pascal VOC, COCO) although in practice we find that these are still far out of reach for purely unsupervised approaches.	I-Reply	I-2	Reply	721
Such datasets have been designed with access to ground-truth labels in mind and the large imbalance between the visual complexity of objects (i.e. intra-class variation) and the number of samples renders them unsuitable for our purpose.	I-Reply	I-2	Reply	721
We consider CLEVR to be among the more complex multi-object datasets that are balanced in this way, and hence the feasibility of our approach on this dataset is an important step forward compared to prior work.	I-Reply	I-2	Reply	721
<sep> <sep> > ‚Äú... it misses an investigation of alternative network design for achieving the same compositionality.	O	O	Reply	721
For example, what would be the performance difference if one replace the MHDPA with LSTM. ‚	O	O	Reply	721
Äú	O	O	Reply	721
<sep> Our proposed framework incorporates MHDPA to model relations between objects.	B-Reply	B-1	Reply	721
MHDPA is an instance of a graph network [1], which renders it suitable for this task.	I-Reply	I-1	Reply	721
It would be valid to compare MHDPA to other instances of graph networks, eg.the interaction function from [6] or the relational mechanism from [2]. In prior experiments we have explored several ablations and extensions of the current relational mechanism that approach these configurations.	I-Reply	I-1	Reply	721
We were unable to obtain significantly better FID scores for any of these variations, and so we settled with the mechanisms proposed in [8] to model relations between objects.	I-Reply	I-1	Reply	721
As our goal was to demonstrate the feasibility / benefits of incorporating such a mechanisms we did not consider it worth it to dedicate human evaluation to this.	I-Reply	I-1	Reply	721
However, we do agree that the paper could mention this and we will update it accordingly to make this more clear.	I-Reply	I-1	Reply	721
<sep> <sep> [1] Battaglia, Peter W., et al "Relational inductive biases, deep learning, and graph networks."	O	O	Reply	721
arXiv preprint arXiv:1806.01261 (2018).	O	O	Reply	721
<sep> [2] Chang, Michael B., et al "A compositional object-based approach to learning physical dynamics."	O	O	Reply	721
International Conference on Learning Representations.	O	O	Reply	721
2016.	O	O	Reply	721
<sep> [3] Eslami, SM Ali, et al "Attend, infer, repeat: Fast scene understanding with generative models."	O	O	Reply	721
Advances in Neural Information Processing Systems.	O	O	Reply	721
2016.	O	O	Reply	721
<sep> [4] Greff, Klaus, et al "Neural expectation maximization."	O	O	Reply	721
Advances in Neural Information Processing Systems.	O	O	Reply	721
2017.	O	O	Reply	721
<sep> [5] Greff, Klaus, et al "Tagger: Deep unsupervised perceptual grouping."	O	O	Reply	721
Advances in Neural Information Processing Systems.	O	O	Reply	721
2016.	O	O	Reply	721
<sep> [6] van Steenkiste, Sjoerd, et al "Relational neural expectation maximization: Unsupervised discovery of objects and their interactions."	O	O	Reply	721
International Conference on Learning Representations.	O	O	Reply	721
2018.	O	O	Reply	721
<sep> [7] Yang, Jianwei, et al "LR-GAN: Layered recursive generative adversarial networks for image generation."	O	O	Reply	721
International Conference on Learning Representations.	O	O	Reply	721
2017.	O	O	Reply	721
<sep> [8] Zambaldi, Vinicius, et al "Relational Deep Reinforcement Learning."	O	O	Reply	721
arXiv preprint arXiv:1806.01830 (2018).	O	O	Reply	721

In this paper the authors present a differentiable objective for slow feature analysis, to facilitate end-to-end training.	B-Review	B-1	Review	1533
I am not clear on the novelty of this formulation, as it appears to have been proposed in a similar form in previous works (e.g., A maximum-likelihood interpretation for slow feature analysis by Turner and Sahani - Eq., (	I-Review	I-1	Review	1533
2)) and can probably be considered straightforward.	I-Review	I-1	Review	1533
Nevertheless, the approximate whitening layer and the way it is used is a smart approach for this problem.	O	O	Review	1533
The experiments are interesting and shed light on the properties of the method.	O	O	Review	1533
In summary, the paper may lack technical novelty in some respect, but the experiments are convincing in terms of proof-of-concept, and the approach is smart.	B-Review	B-2	Review	1533
<sep> <sep> <sep> Dear Reviewer,	O	O	Reply	1533
<sep> Your intuition is right, the objective function itself is not novel and is indeed straightforward to derive.	B-Reply	B-1	Reply	1533
In fact, it is just an unordered version of the original SFA loss (which is in itself differentiable already).	I-Reply	I-1	Reply	1533
<sep> <sep> The whole novelty lies in the idea of using the described whitening layer, thus, incorporating the constraints in the model rather than the loss function.	I-Reply	I-1	Reply	1533
The paper you mentioned can be seen as doing the latter.	I-Reply	I-1	Reply	1533
Thus, we understand it to fall in line with "Bergstra, J. and Bengio, Y. - Slow, decorrelated features for pretraining complex celllike networks" where a penalty term for covariances is included in the loss function.	I-Reply	I-1	Reply	1533
Futhermore, the probabilistic model by Turner and Sahani is not optimized by gradient-descent, but trained by the Expectation Maximization algorithm.	I-Reply	I-1	Reply	1533
<sep> <sep> We tried to clarify that the derivation of the objective function is not an involved or novel part of our algorithm, e.g., in the description for equation (2).	I-Reply	I-1	Reply	1533
With the introductory sentence to Section 5 ("The key idea for gradient-based SFA is that a whitening layer can be applied to any differentiable architecture [..] to enforce outputs that approximately obey the SFA constraints while the architecture stays differentiable."),	I-Reply	I-1	Reply	1533
we hope that this is helps to clearly pinpoint what the original parts of our work are.	I-Reply	I-1	Reply	1533
<sep> <sep> Thank you for taking the time and effort to review our paper!	O	O	Reply	1533
<sep> Hopefully, you find the core idea more unambigiously presented in the current revision.	O	O	Reply	1533
<sep> <sep> Respectfully,	O	O	Reply	1533
the Authors	O	O	Reply	1533

Summary	O	O	Review	1533
The manuscript proposes to use power iterations in an approximate "whitening layer" to optimize the slowness objective of SFA in a very general setting.	O	O	Review	1533
A set of experiments illustrates that this way of doing nonlinear SFA is meaningful.	O	O	Review	1533
<sep> <sep> Quality	O	O	Review	1533
Although the idea is pretty straight forward and the paper shows qualitative results on a number of datasets, the relative merit of the approach is empirically not well characterized.	B-Review	B-1	Review	1533
<sep> <sep> Clarity	O	O	Review	1533
The manuscript is in general well written and the technical content is well accessible.	B-Review	B-2	Review	1533
However the description of the whitening layer implementation needs some more details.	I-Review	I-2	Review	1533
<sep> <sep> Originality	O	O	Review	1533
The idea of using a whitening layer together with the slowness objective has not been explored before.	B-Review	B-3	Review	1533
There is a second ICLR 2019 submission (Pfau et al) with a very similar idea, though.	I-Review	I-3	Review	1533
<sep> <sep> Empirical Evaluation	O	O	Review	1533
The approximate whitening should lead to a trade-off between whitening and slowness optimization.	B-Review	B-4	Review	1533
I miss an experiment illustrating that trade-off.	I-Review	I-4	Review	1533
Also the comparison to nonlinear SFA using expansion or kernelization of hierarchical SFA is empirically not properly characterized.	I-Review	I-4	Review	1533
In the end, if one takes the slowness objective seriously, one would use the method yielding slower results.	I-Review	I-4	Review	1533
<sep> <sep> Significance	O	O	Review	1533
The manuscript introduces a way of running nonlinear SFA with approximate constraints in a general deep learning setting with a differentiable implementation using a dedicated whitening layer based on power iterations.	B-Review	B-5	Review	1533
<sep> <sep> Reproducibility	O	O	Review	1533
The data is either synthetic or publicly available.	B-Review	B-6	Review	1533
The Keras implementation of the PowerWhitening layer as well as the entire neural network along with its optimization schedule is not shared.	I-Review	I-6	Review	1533
Hence, there should be some effort involved to reproduce the experiments.	I-Review	I-6	Review	1533
<sep> <sep> Pros and Cons	O	O	Review	1533
1+) The idea of an approximate whitening layer is conceptually simple and clear.	O	O	Review	1533
<sep> 2-) The description of the practical implementation of the power iteration is slightly imprecise.	B-Review	B-7	Review	1533
<sep> 3-) The algorithm scales badly in the number of output dimensions.	B-Review	B-8	Review	1533
This scaling is bad in a computational sense and also in a statistical sense.	I-Review	I-8	Review	1533
<sep> <sep> Details	O	O	Review	1533
a) Section 6.1: Why do you need to add the noise term?	B-Review	B-9	Review	1533
What is the statistical meaning of this added noise?	I-Review	I-9	Review	1533
<sep> b) Section 6.1: the solutions if comparable -> the solutions is comparable	B-Review	B-10	Review	1533
c) References: Shaham -> ICLR 2018 paper	B-Review	B-11	Review	1533
d) References: nystr√∂m -> Nystr√∂m	B-Review	B-12	Review	1533
e) The name for the algorithm "Power SFA" is a little bit bold.	B-Review	B-13	Review	1533
Dear Reviewer,	O	O	Reply	1533
<sep> we are very thankful for this detailed and actionable review, it gave us a lot to work with to, hopefully, improve our paper for the current revision.	O	O	Reply	1533
<sep> <sep> On Empirical Evaluation & Quality:	O	O	Reply	1533
We included an experiment on the synthetic dataset investigating the progression of average correlation and slowness for an increasing number of power iterations.	B-Reply	B-4	Reply	1533
Surprisingly, there seems to be no trade-off, but too low a number of power iterations will result in sub-optimal performance even if the average correlation is already low.	I-Reply	I-4	Reply	1533
We describe this qualitatively in the section on the experiments using synthetic data, and we included the progression plots for both metrics in the Appendix.	I-Reply	I-4	Reply	1533
<sep> <sep> Also, in Section 6.1, we conducted new experiments with non-linear models (a quadratic expansion network, common for non-linear SFA, and a multi-layer perceptron) on a non-linearly distorted version of the synthetic data.	B-Reply	B-4	Reply	1533
The experiments show that gradient-based training can improve performance when compared with greedy layer-wise training.	I-Reply	I-4	Reply	1533
<sep> Two things should be noted: (a) The experimental setup is not exhaustive (e.g., no systematic model selection has been conducted), but we believe it does illustrate the conceptual promise of the paradigm. (	I-Reply	I-4	Reply	1533
b) Kernelized SFA has not been included in these experiments, as there is no implementation readily available at the moment.	I-Reply	I-4	Reply	1533
<sep> <sep> The new architectures have been shared as a high-level overview in the Appendix and as actual implementation in the provided code.	I-Reply	I-4	Reply	1533
<sep> <sep> <sep> On Clarity & Reproducibility:	O	O	Reply	1533
To promote reproducibility, we uploaded code for the synthetic experiments (including the newly conducted ones) as well as for the NORB experiments.	B-Reply	B-6	Reply	1533
The "Discussion" section contains a link to the archive.	I-Reply	I-6	Reply	1533
The code includes a stand-alone implementation of the whitening layer in the Keras framework.	I-Reply	I-6	Reply	1533
We hope that this improves comprehensibility and encourages original experimentation with this method.	I-Reply	I-6	Reply	1533
<sep> <sep> <sep> On Significance:	O	O	Reply	1533
Nothing for us to reply to here, the description is spot-on.	B-Reply	B-5	Reply	1533
<sep> <sep> <sep> On Originality:	O	O	Reply	1533
We tried to make the differences between the mentioned work and ours more visible.	B-Reply	B-3	Reply	1533
While both papers are aiming to solve a similar problem, our method relies mainly on an simple architectural change (which is, however, applicable independently of the objective), while SpINs are theoretically derived directly from a more general problem formulation and their success stems from a smart optimization of a loss that enforces the constraints.	I-Reply	I-3	Reply	1533
We do see distinct merit in both approaches.	I-Reply	I-3	Reply	1533
<sep> <sep> <sep> On Details:	O	O	Reply	1533
a) The noise is a precautionary measure as closed-form SFA can have the problem of breaking due to linear dependencies in the data, and we do sample the data-generating coefficients randomly.	B-Reply	B-9	Reply	1533
While the current version of MDP (the framework we used for closed-form SFA) available on github includes methods to deal with this problem, the initial experiments have been conducted with the version published on PyPI which does not have this feature yet.	I-Reply	I-9	Reply	1533
We included a brief note on this in Section 6.1.	I-Reply	I-9	Reply	1533
<sep> b, c, d) Have been corrected.	B-Reply	B-12	Reply	1533
<sep> e) We agree that it is a little bold, but we decided to go with this name for two reasons: It hints at the core method underlying the algorithm and thus might be a useful mnemonic, and it caught on in our discussions, despite the actual decision to change it.	B-Reply	B-13	Reply	1533
As it is hard to come up with memorable and descriptive names, we ultimately decided to be a little bold.	I-Reply	I-13	Reply	1533
<sep> <sep> We greatly appreciate the time and effort you spent on reviewing our submission and hope you find your concerns addressed in our current revision.	O	O	Reply	1533
<sep> <sep> Respectfully,	O	O	Reply	1533
the Authors	O	O	Reply	1533

This paper gives an alternative to best-first search ("BFS"), plus heuristics, planning of molecules synthesis.	O	O	Review	110
It does so by training a policy network on ECFP4 (string encoding) representations of molecules, to predict which (sub)molecule to apply, with rewards +1 when the molecule to synthetize is complete, -1 if this branch of applications is complete and the synthesis failed, 0 otherwise.	O	O	Review	110
As far as I understood, it is trained in _retro_synthesis (decompose the molecule).	O	O	Review	110
This policy network is coupled to a search method (BFS of MCTS) both to reduce the branching factor, and to aggressively prune the validation of chemical rules (graph isomorphism).	O	O	Review	110
<sep> <sep> The details about the policy model are almost inexistant.	B-Review	B-1	Review	110
The run-time of MCTS seems more than twice longer than that of BFS, so, baring an explanation, it feels like those should be compared in wall clock time.	B-Review	B-2	Review	110
The "random" test set selection may be problematic to ensure that the whole model is working properly: you may want to test in generalization, on end-result (==start in retrosynthesis) molecules that are unknown to the policy network.	I-Review	I-2	Review	110
<sep> <sep> "essentially the complete published knowledge of chemistry":	B-Review	B-3	Review	110
1) Paywall :(	I-Review	I-3	Review	110
2) maybe you are talking about a specific subset of organic chemistry?	I-Review	I-3	Review	110
Even then, I doubt this includes all metabolic pathways and/or protein foldings.	I-Review	I-3	Review	110
<sep> <sep> The rest of the paper seems reasonable.	O	O	Review	110
<sep> This paper seems good enough for a workshop at ICLR, and it could spawn interesting discussions.	O	O	Review	110
Thanks for your review and your comments!	O	O	Reply	110
<sep> As your concerns are in line with the other reviewer, we hope that you do not mind that we will keep this reply short.	O	O	Reply	110
Please have a look at our other reply as well.	O	O	Reply	110
<sep> <sep> We have provided more details about the policy network in the text, and highlighted our previous publication, where the pure policy net is described in all details [Segler, Waller, Chem.	B-Reply	B-1	Reply	110
Eur.	I-Reply	I-1	Reply	110
J, (2017) DOI: 10.1002/chem.201605499 ].	I-Reply	I-1	Reply	110
In short, the molecules get encoded as ECFP4 fingerprints, which are then fed into a 5 layer Highway network, which in turn predicts the probability of the graph transformations.	I-Reply	I-1	Reply	110
<sep> <sep> We have also adapted the description of the training data in the manuscript.	B-Reply	B-3	Reply	110
Our training data are 5.5 million published organic (and many inorganic and organometallic) reactions carried out in synthetic chemistry labs, taken from the Reaxys database.	I-Reply	I-3	Reply	110
It does not contain metabolic pathways.	I-Reply	I-3	Reply	110
<sep> <sep> In the upcoming full paper we are investigating in detail where MCTS and BFS differ in performance.	B-Reply	B-2	Reply	110
Initial empirical evidence suggests that for more complex molecules (with a much larger tree), MCTS finds solutions more often.	I-Reply	I-2	Reply	110
Our random test set consists of molecules that have not been described in the literature before ‚Äì they were generated by sampling from a charRNN [1] trained on drug-like molecules.	I-Reply	I-2	Reply	110
Probably the best way for evaluation would be a time-split approach: Train only on data published before year X, then evaluate on data published after year X.	I-Reply	I-2	Reply	110
<sep> We are also looking forward to discussions at ICLR, as there are several papers in both the main and the workshop track that address some of our remaining issues!	O	O	Reply	110
<sep> <sep> [1] A. Graves, <a href="https://arxiv.org/abs/1308.0850" target="_blank" rel="nofollow">https://arxiv.org/abs/1308.0850</a>	O	O	Reply	110

Chemical synthesis planning is a long-standing and important problem.	O	O	Review	110
While not the first to propose machine learning to model an 'expert chemist' for chemical synthesis, the particular reinforcement learning approach with MCTS in this work is novel as far as I know.	O	O	Review	110
However, I have a couple questions and concerns.	O	O	Review	110
<sep> <sep> Primarily, not enough information is given about the training data or the policy network trained from it.	B-Review	B-1	Review	110
In general, good chemistry data is hard to obtain; information tends to be scattered, in different formats, and of varying quality.	I-Review	I-1	Review	110
So I'm skeptical about the claim that the data set contains "essentially the complete published knowledge of chemistry."	I-Review	I-1	Review	110
What are these reactions, how are they represented, and how do you determine the _best_ move for a particular molecule when training?	I-Review	I-1	Review	110
For the policy network, what is the network architecture?	I-Review	I-1	Review	110
These may have been published elsewhere, but more details should be provided here, especially for a machine learning audience.	I-Review	I-1	Review	110
<sep> <sep> I don't completely understand the performance improvement due to the MCTS.	B-Review	B-2	Review	110
It seems less useful in this application than in Go, because here whenever you reach a reward of Q(v)=1, the problem is solved and you stop.	I-Review	I-2	Review	110
In the experiments, MCTS shows an improvement over BFS+NN, which is definitely interesting, but this doesn't account for the fact that BFS is more than twice as fast (due to searching the tree in order?).	I-Review	I-2	Review	110
If the constraint was wall-clock time, would MCTS still outperform BFS?	I-Review	I-2	Review	110
I also wondered whether the MCTS policy described in Equation 1 performs better than simply sampling from the policy network output.	I-Review	I-2	Review	110
<sep> <sep> <sep> <sep> Thank you for your considerate review and questions!	O	O	Reply	110
<sep> <sep> We are happy to address your questions and concerns.	O	O	Reply	110
In short, we represent molecules as Extended Connectivity Fingerprints (ECFP4), which are fed into a Highway Network with 5 layers and ELU nonlinearities.	B-Reply	B-1	Reply	110
Due to the restricted space in the extended abstract, referred to our previous publication, which already describes the full details about the training data, molecular descriptors, the policy networks, and their architectures [Segler, Waller, Chem.	I-Reply	I-1	Reply	110
Eur.	I-Reply	I-1	Reply	110
J, (2017) DOI: 10.1002/chem.201605499] We have clarified this in the manuscript.	I-Reply	I-1	Reply	110
<sep> <sep> You are right about chemical reaction data, they are indeed hard to come by.	I-Reply	I-1	Reply	110
There is unfortunately no ‚Äúreaction MNIST‚Äù.	I-Reply	I-1	Reply	110
The reaction dataset we use stems from the Reaxys database, which is one of the most widely used databases by practicing organic chemists.	I-Reply	I-1	Reply	110
The statement that it contains ‚Äúthe complete published knowledge of chemistry‚Äù may seem bold if one considers the huge challenge of constructing common sense knowledge bases, e.g. for natural language understanding.	I-Reply	I-1	Reply	110
However, organic chemical reactions are a narrow domain and straightforward to represent computationally as graph transformations.	I-Reply	I-1	Reply	110
There are only a few million reactions published in the chemical literature.	I-Reply	I-1	Reply	110
Therefore, it is actually feasible to construct a knowledge base that covers almost every reaction ever published.	I-Reply	I-1	Reply	110
Nevertheless, we have removed the statement from the text to avoid confusion.	I-Reply	I-1	Reply	110
<sep> <sep> The best moves for a particular molecule are the reported reactions that have been used to make it.	I-Reply	I-1	Reply	110
This is completely analogous to AlphaGo, where, given a board position, the actually played moves are predicted to the best.	I-Reply	I-1	Reply	110
It is possible to have different winning moves/reactions for the same position/molecule both for Go and for us.	I-Reply	I-1	Reply	110
This is possibly one reason why neither AlphaGo nor our system reaches a very high accuracy.	I-Reply	I-1	Reply	110
<sep> <sep> <sep> The improvement of MCTS is more a philosophical one, as it allows estimating the ‚Äúvalue‚Äù of a molecule, which is its synthesizability (not all reasonable looking molecules can be made, which is a huge problem for computer aided drug design).	B-Reply	B-2	Reply	110
BFS by definition finds only one solution, and then stops.	I-Reply	I-2	Reply	110
MCTS on the other hand usually finds several solutions, and will backpropagate rewards from different branches to lower game tree nodes.	I-Reply	I-2	Reply	110
Even though MCTS eventually converges to one optimal branch, it is desirable to find not just one, but several alternative and robust routes, and MCTS more readily allows for that.	I-Reply	I-2	Reply	110
<sep> <sep> Is MCTS is thus less useful for retrosynthesis than in Go?	I-Reply	I-2	Reply	110
To some degree yes!	I-Reply	I-2	Reply	110
Empirically, we found that BFS is usually on par with MCTS on smaller, ‚Äúeasier‚Äù molecules, while MCTS usually finds better solutions for larger molecules (and thus larger search trees), where BFS sometimes struggles.	I-Reply	I-2	Reply	110
We are currently investigating this in detail for the full paper.	I-Reply	I-2	Reply	110
We would say what‚Äôs most useful about our findings is that the DNN policy (or DNN cost function for BFS) outperforms the hand-annotated heuristics regardless of the search method used.	I-Reply	I-2	Reply	110
<sep> <sep> BFS is faster because it does less calculation, due to the lack of the rollout phase.	I-Reply	I-2	Reply	110
This is also what (probably) makes MCTS stronger.	I-Reply	I-2	Reply	110
The two main bottlenecks in our system is the neural network and the application of the transformations, the tree search itself is much faster than these two steps.	I-Reply	I-2	Reply	110
Restricting wall-clock time and simply sampling from the policy network are indeed interesting experiments, which we will carry out for the full paper.	I-Reply	I-2	Reply	110

The papers empirically studies the leakage propagation in TD learning, which is the problem of propagation of error through the state space caused by the bootstrapping of TD.	O	O	Review	110
<sep> It suggests that the use of proper state space embedding might alleviate this problem.	O	O	Review	110
If two states are nearby in the input representation, but are far according to the dynamics of the MDP (that is, it takes many steps to reach from one state to another), the paper then suggests that the embedding should map them to two afar points.	O	O	Review	110
<sep> The paper considers three embeddings, one of them manually designed and two others learned by an unsupervised signal, and shows that they reduce the leakage propagation problem.	O	O	Review	110
<sep> <sep> The paper addresses an important problem, but I believe this work requires more study and deliberation (understanding that this is a workshop paper).	O	O	Review	110
Currently I cannot be very enthusiastic about this paper.	O	O	Review	110
For example, some of the shortcomings of this work are:	O	O	Review	110
<sep> - The paper is not clear about the choices of embedding.	B-Review	B-1	Review	110
What is the hand-crafted transformation, and what exactly is the rubber band loss?	I-Review	I-1	Review	110
It is desirable to be more formal here.	I-Review	I-1	Review	110
<sep> <sep> - Much of the intuition of this work is related to the porto-value functions and the eigenfunctions of Laplace-Beltrami operator, but the paper is only cursorily mention that (Mahadevan, 2005) did not use neural embedding to achieve so.	O	O	Review	110
Even so that is the case, the relation deserves much better comparison and acknowledgement.	O	O	Review	110
<sep> <sep> - It is stated in Section 1.1 that the detailed setup is given in Appendix A, but that appendix only has a figure.	B-Review	B-2	Review	110
What is the dynamics of the movement?	I-Review	I-2	Review	110
Is it stochastic or deterministic?	I-Review	I-2	Review	110
Thank you very much for this accurate description of the strengths and the shortcomings of this short paper.	O	O	Reply	110
<sep> We acknowledge that, unfortunately, in the process of reducing our draft to fit the 3 pages limit for the workshop, we ended up removing too much detail about the different embeddings (notably the rubber band loss and the hand-crafted transformation), as well as the detailed descriptions of the environments.	B-Reply	B-1	Reply	110
We will naturally address those with an extended version of the paper, which can then also contain deeper comparisons with related work (notably proto-value functions, which indeed was only superficially mentioned).	I-Reply	I-1	Reply	110
<sep> <sep> Note: the environment is deterministic.	B-Reply	B-2	Reply	110
It accepts every step from the agent, as long as it does not collide against a wall.	I-Reply	I-2	Reply	110
The policy we used is stochastic, though (it picks a random direction to move towards, at each point in time).	I-Reply	I-2	Reply	110

The paper considers the idea of projecting samples from an RL task into an intermediate representation before performing TD learning with a neural network.	O	O	Review	110
It is demonstrated that the quality of learned value functions depends in part upon this representation, as error propagates along states that are nearby in the chosen representation.	O	O	Review	110
<sep> <sep> It is well-known and -researched that representation and feature selection is an important step in RL.	B-Review	B-1	Review	110
A great deal of prior work is ignored, to the extent that a list would be unwieldy.	I-Review	I-1	Review	110
The paper provides some useful visuals for an introductory discussion on feature selection in RL, but otherwise no real insights or surprises.	I-Review	I-1	Review	110
Thanks for your review, despite the rejection.	O	O	Reply	110
Do you mind sharing just the 3 most relevant related works, in your opinion, that we failed to acknowledge?	B-Reply	B-1	Reply	110
We see this as a great opportunity to benefit from your expertise and constructive feedback, which is arguably the best possible outcome of the peer review system.	I-Reply	I-1	Reply	110
Greatly appreciated.	I-Reply	I-1	Reply	110

Pros: 1.	O	O	Review	110
Investigated an important technical problem in RL	O	O	Review	110
2.	O	O	Review	110
empirical study is limited, but convincing	O	O	Review	110
Cons: 1.	O	O	Review	110
Lacking formal definition and analysis of leakage propagation.	B-Review	B-1	Review	110
Under what the condition can leakage propagation happen?	I-Review	I-1	Review	110
This seems to be a general problem for TD-learning in state space with singularities.	I-Review	I-1	Review	110
<sep> 2.	O	O	Review	110
lacking connection to a broader community.	B-Review	B-2	Review	110
Although solving different problems, people have considered similar ideas of first perform unsupervised learning (dimension reduction/representation), and then perform planning/reinforce learning on embedding spaces, e.g.,	I-Review	I-2	Review	110
Chen et al Motion Planning with Diffusion Maps (IROS16)	I-Review	I-2	Review	110
Marlos et al A Laplacian Framework for Option Discovery in Reinforcement Learning (ICML17)	I-Review	I-2	Review	110
<sep> Thank you very much for your fair assessment of the strengths and limitations of our work.	O	O	Reply	110
In an extended version of this paper we will expand on the connections to the related literature, including the ones you mentioned.	O	O	Reply	110
<sep> <sep> We agree that it would be great to have a more formal definition of the leakage propagation.	B-Reply	B-1	Reply	110
At the moment we can quantitatively measure the MSVE of the value function estimation, but we can not exactly pinpoint what fraction of that error comes from the leakage propagation, and what fraction comes from other factors (limited capacity of network, issues in the optimization process, etc.).	I-Reply	I-1	Reply	110
The closest we got to that was to first train with MC and then continue training with TD.	I-Reply	I-1	Reply	110
<sep> It would also be great to understand under what exact conditions this leakage propagation happens, indeed.	B-Reply	B-2	Reply	110
We were able to design environments where it is more likely to happen (continuous state spaces having sharp discontinuities in the value function), but it's not yet a very precise characterization.	I-Reply	I-2	Reply	110
<sep> Perhaps we can make progress in those directions with future work.	O	O	Reply	110
Thanks for your contribution.	O	O	Reply	110

This paper proposes "Back-to-Back" regression for estimating the causal influence between X and Y in the linear model Y=(XE+N)F, where the E denotes a diagonal matrix of causal influences.	O	O	Review	110
Furthermore, this work theoretically shows the consistency of B2B and the experiments also verify the effectiveness of this approach.	O	O	Review	110
<sep> <sep> The writing is well and clear and there are some minors issues:	O	O	Review	110
- Further analysis and explanation for using \hat{E}=Diag(H)to estimate the causal influence might be needed.	B-Review	B-1	Review	110
<sep> - The model defined in Fig.1 seems the influence E should have a sparse diagonal vector.	B-Review	B-2	Review	110
It is possible to introduce an L1 regulation in E?	I-Review	I-2	Review	110
<sep> <sep> ##############	O	O	Review	110
After reading the author's feedback and the comments from other reviewers, I keep the current rating but tend to a borderline score and it is ok if it must be rejected because of the concerns of limited applicability and the experimental.	O	O	Review	110
<sep> <sep> # (1) clarify	O	O	Reply	110
<sep> We agree with #R2 that the original manuscript insufficiently detailed the relationship between diag(H) and the causal estimates.	B-Reply	B-1	Reply	110
<sep> <sep> We have now expanded the proof and added a section in the Appendix to clarify how E can be recovered from.	I-Reply	I-1	Reply	110
<sep> <sep> In addition, we describe in the appendix three methods to binarize diag(H) into causal and non causal features, when (1) signal to noise ratio is known (2) independent experiments are repeated or (3) we know that X contains both causal and non-causal features.	I-Reply	I-1	Reply	110
<sep> <sep> <sep> # (2) Can E use a sparse prior?	O	O	Reply	110
<sep> <sep> E should tend towards a sparse diagonal vector when a small proportion of factors causally influence Y.	B-Reply	B-2	Reply	110
<sep> In our implementation, B2B uses L2-regularization in both the forward regression (H) and the backward (G) regressions.	I-Reply	I-2	Reply	110
However, any regularization can be used.	I-Reply	I-2	Reply	110
<sep> <sep> Note that a distinct regularization can be implemented and optimized for each regression separately (e.g. L2 for G and L1 for H).	I-Reply	I-2	Reply	110
In this regard, we did pilot with L1-regularization on the H regression, to induce sparsity in E. However, we did not observe any clear improvement on our synthetic or MEG experiments, and this approach was significantly less efficient computationally.	I-Reply	I-2	Reply	110
Indeed, the efficient leave-one-out optimization of l2-regularization parameters detailed by Rifkin and Lippert 2007 only applies to l2 regularization.	I-Reply	I-2	Reply	110
<sep> <sep> Finally, sparsity can be a posteriori enforced onto via a thresholding method.	I-Reply	I-2	Reply	110
As mentioned above, we describe three thresholding methods in the appendix, together with their respective assumptions.	I-Reply	I-2	Reply	110

The authors introduce a method (B2B) for disentangling effects of correlated predictors in the context of high dimensional outcomes.	O	O	Review	110
Their model assumes the outcomes are constructed by a linear transformation of a set of true causes plus measurement noise.	O	O	Review	110
Specifically, they fit the model Y=(XE+N)F, where X are the predictors, E is a binary matrix indicating the true causes, N is a noise term, and F is a mixing term.	O	O	Review	110
They provide a closed form solution the model fit based on a pair of l2-regularized regressions.	O	O	Review	110
They simulate from the given model and provide comparisons against least-squares regression, canonical correlation analysis, and partial least squares.	O	O	Review	110
They also apply the method to brain imaging data containing 102 individuals reading 120 sentences plus scrambled sentences, with the goal of inferring which features of the words have an effect on imaging results.	O	O	Review	110
<sep> <sep> This paper appears to be technically sound, but it should be rejected based on 1) the relatively limited applicability of the model and 2) a lack of thorough experimentation indicating that this is an appropriate method under more general circumstances.	B-Review	B-6	Review	110
It is odd that the model assumes the outcomes are measured without error.	I-Review	I-6	Review	110
Instead, it is assumed that the causes are measured with error, and mixed via F. A more appropriate model may be: Y=(XE+N)F+M, where an additional noise term M allows for Y to be measured imprecisely.	I-Review	I-6	Review	110
Viewed in this light, the model starts to look a lot like canonical correlation analysis.	I-Review	I-6	Review	110
Consider a model Y=ZF+M, X=ZG+N, if dim(Z) = dim(X) and G is invertible, this can be re-written as Y=(X inv(G)-N)A+M, and we arrive at a similar model with specific restrictions about the structure of inv(G) (E will in general not be invertible, so they are not the same).	I-Review	I-6	Review	110
It is particularly odd, then, that the authors do no comparisons against any regularized form of CCA, which would seem to be the most natural method to use in this circumstance.	I-Review	I-1	Review	110
Moreover, in the simulations where they show B2B outperforms CCA, they use 1000 training samples with 10-100 possible causes.	B-Review	B-2	Review	110
In their experiments on real data, where it seems the CCA results are much closer to the results that B2B gives, they have 2700 samples and 4 possible causes.	I-Review	I-2	Review	110
This seems to imply the real data case might be better conditioned than the simulated case, so that regularization would have less of an impact.	I-Review	I-2	Review	110
<sep> <sep> In conclusion, the authors present a sound method for disentangling correlated possible causes when the outcome is high-dimensional.	B-Review	B-3	Review	110
However, the authors do not provide enough evidence that this method is generally useful and better than established methods to merit acceptance to ICLR.	I-Review	I-3	Review	110
A comparison to regularized CCA, application to more datasets and simulations under violations of the model would greatly improve the paper.	I-Review	I-3	Review	110
I also have two minor points.	I-Review	I-3	Review	110
1) the word ‚Äúcausal‚Äù can mean many things, and here it refers specifically to disentangling correlated predictors, rather than confounding in observations or direction of effect.	I-Review	I-3	Review	110
It would improve the paper to add some discussion of this point.	I-Review	I-3	Review	110
2) The comparisons in the experiments are done between E estimated from B2B and E=sum_j H_j^2 for other methods that do not directly estimate E. However, a more natural comparison might be against EF as this also includes estimates of the strength of influence of each observation, which is implicit in the sum above.	B-Review	B-4	Review	110
<sep> <sep> # (4) The authors do no comparisons against any regularized form of CCA	O	O	Reply	110
<sep> We thank R3 for this comment.	B-Reply	B-1	Reply	110
We now revised the manuscript (see Section 3, both synthetic and MEG experiments) to change CCA into an l2-regularized CCA, as implemented by the Pyrcca package provided by Bilenko and Gallant (2016).	I-Reply	I-1	Reply	110
L2-regularization CCA is now optimized similarly to B2B, i.e. over a nested-grid search optimization of the training set over 20 values logarithmically distributed between 1e-4 and 1e4.	I-Reply	I-1	Reply	110
Overall, our updated results do not change the conclusion of our paper.	I-Reply	I-1	Reply	110
However, we do observe one experimental case where regularized CCA outperforms B2B: the feature importance of the word function effect in MEG is higher with regularized CCA than with B2B. This unexpected superiority of CCA over B2B disappears when more than 4 features are tested.	I-Reply	I-1	Reply	110
<sep> <sep> # (5) The real data case might be better conditioned than the simulated case	O	O	Reply	110
<sep> We agree with R1 that the optimal use-case for B2B appears to be when a large number of covarying factors are investigated, as demonstrated in the synthetic experiments.	B-Reply	B-2	Reply	110
<sep> <sep> In this first method paper, we aimed to verify that B2B yields to plausible results.	I-Reply	I-2	Reply	110
We thus intentionally investigated well-described phenomena (the neural correlates of word length and word frequency).	I-Reply	I-2	Reply	110
B2B successfully matched our expectations.	I-Reply	I-2	Reply	110
First, word length and word frequency revealed early and late brain effects respectively.	I-Reply	I-2	Reply	110
Second, B2B did not reveal any spurious effect before stimulus onset.	I-Reply	I-2	Reply	110
Third B2B appeared reliably better than other baseline methods.	I-Reply	I-2	Reply	110
<sep> <sep> To address R1 comments, we now added an additional MEG analysis (see Figure 7 in the appendix) in which introduce additional features: the word-embedding vectors of each word provided by the Spacy package.	I-Reply	I-2	Reply	110
Our results show that B2B remains robust to the introduction of additional factors.	I-Reply	I-2	Reply	110
<sep> <sep> <sep> # (6) The word ‚Äúcausal‚Äù can mean many things, and here it refers specifically to disentangling correlated predictors, rather than confounding in observations or direction of effect.	O	O	Reply	110
It would improve the paper to add some discussion of this point.	O	O	Reply	110
<sep> <sep> We thank R3 for this remark.	B-Reply	B-3	Reply	110
We now clarify the definition in the manuscript:	I-Reply	I-3	Reply	110
<sep> ‚Äú	I-Reply	I-3	Reply	110
The present paper focuses on the restricted issue of disentangling the causal influence of linearly correlated predictors ) onto multivariate observations ).	I-Reply	I-3	Reply	110
The present approach thus differs from other causal discovery algorithms based on temporal-delays and/or nonlinear interaction in systems where the directionality of causation (from X to Y or vice versa) is unknown (e.g. \citep{peters2017elements, granger1969investigating, janzing2013quantifying, scholkopf2016modeling}.	I-Reply	I-3	Reply	110
‚Äú	I-Reply	I-3	Reply	110
<sep> <sep> # (7) The comparisons in the experiments are done between E estimated from B2B and E=sum_j H_j^2 for other methods that do not directly estimate E. However, a more natural comparison might be against EF as this also includes estimates of the strength of influence of each observation, which is implicit in the sum above.	O	O	Reply	110
<sep> <sep> We agree that EF is likely to be closer to Sum_j H_j^2.	B-Reply	B-4	Reply	110
However, the precise purpose of B2B, unlike other methods, is to retrieve E when F is unknown.	I-Reply	I-4	Reply	110
The introduction of Sum_j H_j^2 is solely designed to provide a fair chance to previous baseline.	I-Reply	I-4	Reply	110

<sep> The paper provides an iterative linear method to identify causal influences of putative cause matrix to signal matrix.	O	O	Review	110
The idea is a natural extension of previous forward and backward such as CCA and PLS.	O	O	Review	110
The paper has provided consistency guarantee and several synthetic and real data experiments as support.	O	O	Review	110
<sep> <sep> Technical questions:	O	O	Review	110
<sep> 1) The estimation of binary causal influence matrix E is set as \hat{E} = Diag(\hat{H}).	B-Review	B-1	Review	110
Why is Diag(\hat{H}) guaranteed to have binary elements?	I-Review	I-1	Review	110
<sep> <sep> 2) The Theorem 1 needs more explanation about why it proves consistency, which is currently isolated from other parts of the paper.	B-Review	B-2	Review	110
Why E\hat{H} = \hat{H} guarantees the consistency of \hat{E} = Diag(\hat{H})?	I-Review	I-2	Review	110
For example, \hat{H} can have more all-zero rows than E which still satisfies E\hat{H} = \hat{H}  but  \hat{E}  is not equals to E. In an extreme case,  \hat{H} = 0 will have  E\hat{H} = \hat{H} but is clearly not consistent.	I-Review	I-2	Review	110
<sep> <sep> 3) How does the Eq (4),(5) give an estimation \hat{E}?	B-Review	B-3	Review	110
<sep> <sep> 4) By Eq. (12,13) over?	B-Review	B-4	Review	110
10,11), H and G seem to be determined give X,Y. Then what are the maximization of Eq. (	I-Review	I-4	Review	110
<sep> <sep> <sep> General comments:	O	O	Review	110
<sep> 1) How does the problem in Eq.(1) differ from variable selection in linear regression where a plenty algorithms exist such as LASSO, spike-slab prior, SCAD, etc. ?	B-Review	B-5	Review	110
<sep> <sep> 2) The experiments are a bit weak with a simple synthetic experiment and a real dataset with just four features.	B-Review	B-6	Review	110
Can the experiment directly demonstrate the correctness of the theorem?	I-Review	I-6	Review	110
<sep> <sep> Typo:	B-Review	B-7	Review	110
<sep> Page 1, ‚Äúare are based on‚Äù	I-Review	I-7	Review	110
<sep> In general, I think B2B is an algorithm that has improvement over CCA and PLS.	O	O	Review	110
I am looking forward to the author response to address my above concerns.	O	O	Review	110
<sep> <sep> ##############	O	O	Review	110
I have read the author's feedback which addresses some of the confusion parts in the paper.	O	O	Review	110
I maintain the current rating mainly because of the experimental strength.	O	O	Review	110
# (1) Why is guaranteed to have binary elements?	O	O	Reply	110
<sep> <sep> In the linear case, is binary only in the absence of noise (more precisely, of noise on the active causal features).	B-Reply	B-1	Reply	110
<sep> <sep> Without loss of generality, we suppose that the non-zero features of are the first.	I-Reply	I-1	Reply	110
<sep> <sep> Since (Theorem), the last rows of are zero, and so are the last elements of.	I-Reply	I-1	Reply	110
<sep> <sep> We denote and as the first k features of and.	I-Reply	I-1	Reply	110
Therefore, the top left submatrix of is (Eq 8).	I-Reply	I-1	Reply	110
The diagonal elements of this submatrix will be in.	I-Reply	I-1	Reply	110
In the absence of noise on the k first features, this submatrix is identity.	I-Reply	I-1	Reply	110
<sep> <sep> Therefore, is binary.	I-Reply	I-1	Reply	110
<sep> <sep> In the presence of noise, the n-k last terms in will remain zero, but the average of the k first will be equal to	I-Reply	I-1	Reply	110
<sep> We now added clarifications at the end of Section 2.2 and in the appendix.	I-Reply	I-1	Reply	110
<sep> <sep> <sep> # (2) The Theorem 1 needs more explanation about why it proves consistency, which is currently isolated from other parts of the paper.	O	O	Reply	110
Why E\hat{H} = \hat{H} guarantees the consistency of \hat{E} = Diag(\hat{H})?	O	O	Reply	110
For example, \hat{H} can have more all-zero rows than E which still satisfies E\hat{H} = \hat{H}  but  \hat{E}  is not equals to E. In an extreme case,  \hat{H} = 0 will have  E\hat{H} = \hat{H} but is clearly not consistent.	O	O	Reply	110
<sep> <sep> The possibility that has more all-zero rows than E violates one of our assumptions, namely that  and are full rank on‚Äù (the subspace spanned by the columns of E).	B-Reply	B-2	Reply	110
<sep> <sep> Indeed, full rank of over implies that has full rank.	I-Reply	I-2	Reply	110
Similarly is full rank too.	I-Reply	I-2	Reply	110
Consequently, from Eq (9), none of the first k diagonal elements can be equal to zero.	I-Reply	I-2	Reply	110
<sep> <sep> In layman terms, our hypothesis implies that can only be recovered if all of its active elements lead to a change in some dimension(s) of.	I-Reply	I-2	Reply	110
Otherwise, these elements will be estimated to be non-causal, as expected.	I-Reply	I-2	Reply	110
<sep> <sep> # (3) How does the Eq (4),(5) give an estimation \hat{E}?	O	O	Reply	110
<sep> <sep> The estimation of E derives from Eq (2) and (3).	B-Reply	B-3	Reply	110
In contrast, Eq (4) and (5) implement the optimization technique described by Rifkin and Lippert 2007 in order to efficiently estimate optimal L2-regularization parameters through leave-one-sample-out cross-validation over the training set.	I-Reply	I-3	Reply	110
We clarify this passage in the updated manuscript, in Section 2.1.	I-Reply	I-3	Reply	110
<sep> <sep> # (4) By Eq. (12,13) over?	O	O	Reply	110
10,11), H and G seem to be determined give X,Y. Then what are the maximization of Eq. (	O	O	Reply	110
<sep> <sep> We apologize for our confused notation.	B-Reply	B-4	Reply	110
Equation (10) describes the calculation of a forward model.	I-Reply	I-4	Reply	110
<sep> Equation (11) describes the  calculation of a backward model.	I-Reply	I-4	Reply	110
<sep> Equation (12) describes CCA.	I-Reply	I-4	Reply	110
<sep> Equation (13) describes PLS	I-Reply	I-4	Reply	110
In other words, G and H represent different matrices in each equation.	I-Reply	I-4	Reply	110
We used similar notations to highlight the functional similarities of these matrices in the different models; but in order to avoid any confusion, we now add indices (e.g.,) to emphasize their differences (see equations in Section 3.2).	I-Reply	I-4	Reply	110

The premise of this paper is very interesting: the authors test the ability of deep networks to converge to the parity/FFT as a function of noise magnitude added to a ground truth initialization.	O	O	Review	127
They show that in both cases, the deep model only converges when initialized close enough.	O	O	Review	127
<sep> <sep> My concern is with the lack of detail in some of the experimental settings: while I can completely believe that deep models do indeed behave in this way, I'd like to have an enumeration of the range of things tried before being convinced that this is the case.	B-Review	B-1	Review	127
I've mentioned some things that would be nice to see in the comments.	I-Review	I-1	Review	127
<sep> <sep> Major Comments	O	O	Review	127
If the network architectures are as pictured in the figures, they look extremely small (in number of neurons), and it would be very interesting to have overparametrized networks as a comparison.	O	O	Review	127
<sep> <sep> It seems important to also try other initialization schemes and see if models converge from there, particularly with overparametrized networks.	B-Review	B-2	Review	127
My suspicion would be that for large enough networks, and small enough n, we would see the models correctly learn these functions.	I-Review	I-2	Review	127
<sep> <sep> More generally, it would be nice to see the range of architectures and methods tried described explicitly in the text (perhaps in the Appendix.)	O	O	Review	127
<sep> <sep> Minor Comments:	O	O	Review	127
Why use deep sigmoid networks for parity?	B-Review	B-3	Review	127
<sep> Test out on larger architectures?	B-Review	B-4	Review	127
<sep> Doesn't the DFT have very poor scaling (exponential variations in size?)	B-Review	B-5	Review	127
This would be a reason why this might be hard for a deep network to learn?	I-Review	I-5	Review	127
<sep> Also, why skip to learning the FFT before seeing if the DFT can be learned?	I-Review	I-5	Review	127
<sep> Would like actual details of network architectures -- how big are they aside from the input size? (	B-Review	B-6	Review	127
Width/depth?)	I-Review	I-6	Review	127
Were different batch sizes tried? (	B-Review	B-7	Review	127
1000 is a large-ish batch size.)	I-Review	I-7	Review	127
<sep> "Without encouragement towards a sparse solution, a deep linear network will learn dense solutions in general" -- even if many weights are nonzero, deep models typically have only a small set of weights that are very large in magnitude after training, so they are "almost" sparse?	O	O	Review	127
<sep> <sep> I think this is very important and interesting work, but would like more details to paint a clearer picture before acceptance.	O	O	Review	127
Thank you for your very thoughtful comments!	O	O	Reply	127
We have compiled responses below.	O	O	Reply	127
<sep> Many of the implementation details were present in earlier drafts of the paper, but were removed due to space constraints.	O	O	Reply	127
<sep> <sep> - The Fourier transform networks had log(n/2) layers of size n by n, where n = {32, 64, 128, 256}. The parity function networks had input sizes n = {16, 32, 64, 128}, with 2 log(n) layers and the number of hidden units halved every other layer, such that the final output layer had a single neuron.	B-Reply	B-1	Reply	127
<sep> <sep> - For the fast Fourier transform experiments, we tried initializing our networks with noisy weights around zero and the identity matrix, in addition to noisy versions of a hand-coded solution.	B-Reply	B-2	Reply	127
We found that noisy versions of the hand-coded solution had the best convergence properties, while still not converging to a sparse solution if the initialization noise scale was too large.	I-Reply	I-2	Reply	127
We thought this initialization to the hand-coded solution would represent a ‚Äúbest case‚Äù scenario, with other initializations likely to be less effective and this was empirically verified.	I-Reply	I-2	Reply	127
<sep> <sep> - We used deep sigmoid networks for the parity function experiments simply because they are often used as the activation of choice when attempting to learn XOR gates.	B-Reply	B-3	Reply	127
Since our hand-coded parity function baseline was made out of a tree of XOR gates, we thought sigmoid activations were the most natural choice.	I-Reply	I-3	Reply	127
Future work could certainly conduct experiments with other activation functions.	I-Reply	I-3	Reply	127
<sep> <sep> - For the fast Fourier transform experiments, we trained networks with hidden layers with up to 1.5x the number of units as the input and output layers.	B-Reply	B-4	Reply	127
We observed no additional benefit, but it is possible that even greater overparametrization could help.	I-Reply	I-4	Reply	127
<sep> <sep> - The DFT can be expressed as a single matrix multiplication, and can therefore be expressed by a linear neural network with no hidden layers.	B-Reply	B-5	Reply	127
We chose to examine the FFT because it can be expressed by a deep network, but not by a shallow network, and our aim is to examine the learning properties of deep neural networks.	I-Reply	I-5	Reply	127
Over the course of our experiments, we did indeed observe that a deep network with no sparsity constraint can learn to perform the DFT, but its weights will not generally have the efficient sparsity pattern of the FFT.	I-Reply	I-5	Reply	127
<sep> <sep> - Sparsity was calculated in the following way: for each trained network, we found the maximum value \epsilon, such that if all weights with magnitude less than \epsilon were set to zero, the network error decreased.	B-Reply	B-6	Reply	127
We defined the sparsity of the network as the L_0 norm of the network after rectification by this maximizing value of \epsilon.	I-Reply	I-6	Reply	127
As reported in the paper, we found that there was a clear basin of attraction around the hand-coded solution, within which the network converged to a sparsity pattern consistent with O(n log n) scaling, and outside of which the network did not converge to a sparse pattern.	I-Reply	I-6	Reply	127
<sep> <sep> - For the parity function experiments, we tried batch sizes of 250, 500 and 1000.	B-Reply	B-7	Reply	127
We saw no significant differences between different batch sizes.	I-Reply	I-7	Reply	127

The paper does an empirical study of how well neural network optimized by back propagation learns simple functions: parity function/ fast fourier transform.	O	O	Review	127
The paper concludes that the deep network can not learn those simple functions unless initialized near the optimal solution.	O	O	Review	127
<sep> The paper would benefit from explaining by what is meant by efficient representations (i.e number of neurons used vs number of examples etc).	O	O	Review	127
<sep> <sep> Question regarding learning the  Fourier transform:	O	O	Review	127
-  was the complex matrix learned by back propagation ?	B-Review	B-1	Review	127
or you used the discrete cosine transform?	I-Review	I-1	Review	127
<sep> -  what if your signals in the training were translated version one of another?	B-Review	B-2	Review	127
one would expect the network to learn the Fourier transform?	I-Review	I-2	Review	127
<sep> - In the Fourier case you use a deep linear network ,how many layers?	B-Review	B-3	Review	127
what if one uses only a linear layer?	I-Review	I-3	Review	127
<sep> - was the network fully connected ?	B-Review	B-4	Review	127
what if it was convolutional network?	I-Review	I-4	Review	127
would it learn the fourier transform?	I-Review	I-4	Review	127
<sep> <sep> Studying those simple functions is insightful, but it is hard to draw conclusions out of this simple set of experiments.	O	O	Review	127
For instance why deep learning works in computer vision is due to the use of inductive biases such as CNN, for learning the Fourier transform one would expect that data augmentation with translation might help the learning.	B-Review	B-5	Review	127
<sep> <sep> <sep> <sep> <sep> <sep> <sep> Thank you for your helpful comments and feedback!	O	O	Reply	127
We have compiled responses to your comments below.	O	O	Reply	127
<sep> <sep> - In order to express the complex-valued fast Fourier transform with only real numbers, we simply concatenated the real and imaginary parts of each input and output vector.	B-Reply	B-1	Reply	127
The hand-coded FFT weight matrices were correspondingly transformed.	I-Reply	I-1	Reply	127
Thus the network weights and input were entirely real valued, but represent complex values.	I-Reply	I-1	Reply	127
<sep> <sep> - The fast Fourier transform has a complexity of O(n log n), so any network with a single layer, while it may be able to implement the DFT in general, cannot implement the FFT.	B-Reply	B-3	Reply	127
<sep> <sep> - The FFT networks were fully connected.	B-Reply	B-4	Reply	127
<sep> <sep> - The reviewer notes that "why deep learning works in computer vision is due to the use of inductive biases such as CNN.‚Äù While we certainly agree that CNNs are extraordinarily useful for speeding up training, and are essentially necessary in practice, extensive experiments with MNIST seem to suggest that CNNs and fully connected nets don‚Äôt necessarily perform differently in the limit of large data and long training times (<a href="http://yann.lecun.com/exdb/mnist/," target="_blank" rel="nofollow">http://yann.lecun.com/exdb/mnist/,</a> see ‚Äú6-layer NN 784-2500-2000-1500-1000-500-10 (on GPU) [elastic distortions]‚Äù and ‚Äúlarge/deep conv.	B-Reply	B-5	Reply	127
net, 1-20-40-60-80-100-120-120-10 [elastic distortions]‚Äù).	O	O	Reply	127
Because our data is synthesized and we trained many networks for millions of epochs, our experiments occur in this large data, long training regime.	B-Reply	B-5	Reply	127
Thus, it is unclear to us whether inductive biases such as CNNs would have made a difference for our FFT experiments.	I-Reply	I-5	Reply	127
Additionally, we showed that enforcing the correct sparsity pattern for the parity function does not appear to increase the ability of the network to converge.	I-Reply	I-5	Reply	127

With simple examples, the authors clearly demonstrate the difference between what functions a deep neural network model can represent and what it can learn.	O	O	Review	127
This is important because the ability of deep neural networks to more efficiently represent complex functions is frequently cited as their primary advantage.	O	O	Review	127
The presentation, experiments, and conclusions are very good.	O	O	Review	127
We very much appreciate the positive feedback, thank you!	O	O	Reply	127

The authors show that a shallow neural net trained to mimic a deep net (regular or convolutional) can achieve the same performance as the deeper, more complex models on the TIMIT speech recognition task.	O	O	Review	1
They conclude that current learning algorithms are a better fit for deeper architectures and that shallow models can benefit from improved optimization techniques.	B-Review	B-1	Review	1
The experimental results also show that shallow models are able to represent the same function as DNNs/CNNs.	O	O	Review	1
To my knowledge, training an SNN to mimic a DNN/CNN through model compression has not been explored before and the authors seem to be getting good results at least on the simple TIMIT task.	O	O	Review	1
It remains to be seen if their technique scales up to large vocabulary tasks such as Switchboard and Broadcast News transcription.	O	O	Review	1
This being said, a few critiques come to mind:	O	O	Review	1
- The authors discuss factoring the weight matrix between input and hidden units and present it as being a novel idea.	B-Review	B-2	Review	1
They should be aware of the following papers:	I-Review	I-2	Review	1
T. N. Sainath, B. Kingsbury, V. Sindhwani, E. Arisoy and B. Ramabhadran, 'Low-Rank Matrix Factorization for Deep Neural Network Training with High-Dimensional Output Targets,' in Proc.	I-Review	I-2	Review	1
ICASSP, May 2013.	I-Review	I-2	Review	1
<sep> Jian Xue, Jinyu Li, Yifan Gong, 'Restructuring of Deep Neural Network Acoustic Models with Singular Value Decomposition', in Proc.	I-Review	I-2	Review	1
Interspeech 2013.	I-Review	I-2	Review	1
<sep> - It is unclear whether the SNN-MIMIC models from Table 1 use any factoring of the weight matrix.	B-Review	B-3	Review	1
If yes, what is k?	I-Review	I-3	Review	1
<sep> - It is unclear what targets were used to train the SNN-MIMIC models: DNN or CNN?	B-Review	B-4	Review	1
I assume CNN but it would be good to specify.	I-Review	I-4	Review	1
<sep> - On page 2 the feature extraction for speech appears to be incomplete.	B-Review	B-5	Review	1
Are the features logmel or MFCCs?	I-Review	I-5	Review	1
In either case, the log operation appears to be missing.	I-Review	I-5	Review	1
<sep> - On page 2 you claim that Table 1 shows results for 'ECNN' which is undefined.	B-Review	B-6	Review	1
The reviewer says: ‚ÄúThey conclude that current learning algorithms are a better fit for deeper architectures and that shallow models can benefit from improved optimization techniques.	O	O	Reply	1
‚Äù We are not really sure of this, but it is a possibility and we are trying to do the experiments necessary to answer this question.	B-Reply	B-1	Reply	1
<sep> <sep> Thanks for pointing us to related work on re-parameterizing the weight matrices.	B-Reply	B-2	Reply	1
We added these to the extended abstract.	I-Reply	I-2	Reply	1
What we propose is somewhat different from this prior work.	I-Reply	I-2	Reply	1
Specifically, we apply weight factorization during training (as opposed to after training) to speed convergence of the mimic model --- the weights of the linear layer and the weights in the non-linear hidden layer are trained at the same time with backprop.	I-Reply	I-2	Reply	1
<sep> <sep> The SNN-MIMIC models in Table 1 use 250 linear units in the first layer.	B-Reply	B-3	Reply	1
We updated the paper to include this information.	I-Reply	I-3	Reply	1
<sep> <sep> On page 2, the features are logmel: fourier-based filter banks with 40 coefficients distributed on a mel-scale.	B-Reply	B-5	Reply	1
We have modified the paper to clarify this.	I-Reply	I-5	Reply	1
<sep> <sep> The ECNN on page 2 is an ensemble of multiple CNNs.	B-Reply	B-6	Reply	1
Both SNN-MIMIC models (8k and 400k) are trained to mimic the ECNN.	I-Reply	I-6	Reply	1
We mimic an ensemble of CNNs because we don‚Äôt have any unlabeled data for TIMIT and thus must use the modest-sized train set for compression.	I-Reply	I-6	Reply	1
With only 1.1M points available for compression, we observe that the student MIMIC model is usually 2-3% less accurate than the teacher model.	I-Reply	I-6	Reply	1
We also observe, however, that whenever we make the teacher model more accurate, the student MIMIC model gains a similar amount of accuracy as well (suggesting that the fixed gap between the deep teacher and shallow MIMIC models is due to a lack of unlabeled data, not a limited representational power in the shallow models).	I-Reply	I-6	Reply	1
Because our goal is to train a shallow model of high accuracy, we needed to use a teacher model of maximum accuracy to help overcome this gap between the teacher and mimic not.	I-Reply	I-6	Reply	1
If we had a large unlabeled data set for TIMIT this would not be necessary.	I-Reply	I-6	Reply	1
The ensemble of CNNs is significantly more accurate than a single CNN, but we have not yet published that result.	I-Reply	I-6	Reply	1
We modified the paper to make all of this clearer.	I-Reply	I-6	Reply	1

An interesting workshop paper.	O	O	Review	1
For such a provocative title, more results are needed to support the conclusions.	B-Review	B-1	Review	1
Part of the resurgent success of neural networks for acoustic modeling is due to making the networks ‚Äúdeeper‚Äù with many hidden layers (see F. Seide, G. Li, and D. Yu, 'Conversational Speech Transcription Using Context-Dependent Deep Neural Networks', ICASSP 2011 which shows that shallow networks perform worse than deep for the same # of parameters).	B-Review	B-2	Review	1
This paper provides a different data point where a shallow network is trained using the author‚Äôs ‚ÄúMIMIC‚Äù technique performs as well as a deep network baseline on the TIMIT phone recognition task.	O	O	Review	1
The MIMIC technique involves using unsupervised soft labels from an ensemble of deep nets of unknown size and quality, including a linear layer of unknown size, and training on the un-normalized log prob rather than softmax output.	O	O	Review	1
The impact of each of these aspects on their own is not investigated; perhaps a deep neural network would gain from some or all of these MIMIC training steps as well.	B-Review	B-3	Review	1
Thank you for the comments.	O	O	Reply	1
We completely agree that more results are needed to support the conclusions, and this is why we submitted an extended abstract instead of full paper.	B-Reply	B-1	Reply	1
More experiments are underway, but we don't yet have final results to add to the abstract.	I-Reply	I-1	Reply	1
Preliminary results suggest that on TIMIT the MIMIC models are not as accurate as the teacher models mainly because we do not have enough unlabeled TIMIT data to capture the function of the teacher models, as opposed to because the MIMIC models have too little capacity or cannot learn a complex function in one layer.	I-Reply	I-1	Reply	1
Preliminary results also suggest that: 1) the key to making the shallow MIMIC model more accurate is to train it to be more similar to the deep teacher net, and 2) the MIMIC model is better able to learn to mimic the teacher model when trained on logit (the unnormalized log probabilities) than on the softmax outputs from the teacher net.	I-Reply	I-1	Reply	1
The only reason for including the linear layer between the input and non-linear hidden layer is to make training of the shallow model faster, not to increase accuracy.	I-Reply	I-1	Reply	1
Experiments suggest that for TIMIT there is little benefit from using more than 250 linear units.	I-Reply	I-1	Reply	1
<sep> <sep> We agree with papers such as Seide, Li, and Yu, that shallow nets perform worse than deep nets given the same # of parameters when trained with the current training algorithms.	B-Reply	B-2	Reply	1
It is possible that, as Yoshua Bengio suggests, deep models provide a better prior than shallow models for complex learning problems.	I-Reply	I-2	Reply	1
It is also possible that other training algorithms and regularization methods would allow  shallow models to work as well.	I-Reply	I-2	Reply	1
Or it may be a mix of the two.	I-Reply	I-2	Reply	1
We believe the question of whether models must be deep to achieve extra accuracy is as yet open, and our experiments on TIMIT provide one data point that suggests it *might* be possible to train shallow models that are as accurate as deeper models on these problems.	I-Reply	I-2	Reply	1
<sep> <sep> We have tried using some of the MIMIC techniques to improve the accuracy of deep models.	B-Reply	B-3	Reply	1
With the MIMIC techniques we have been able to train deep models with fewer parameters that are as accurate as deep models with more parameters (i.e., reduce the number of weights and number of layers needed in the deep models), but we have not been able to achieve significant increases in accuracy for the deep models.	I-Reply	I-3	Reply	1
If compression is done well, the mimic model will be as accurate as the teacher model, but usually not more accurate, because the MIMIC process tries to duplicate the function (I/O behavior) learned by the teacher model in the smaller student model.	I-Reply	I-3	Reply	1

This paper asks interesting questions and has interesting experimental results.	B-Review	B-1	Review	1
The generality of the results could be improved by considering more than one dataset, though.	I-Review	I-1	Review	1
<sep> <sep> You might want to first fix a typo in Rich's name...	B-Review	B-2	Review	1
<sep> I concur with David Krueger regarding the somewhat misleading statements in the abstract and introduction etc regarding the matching of depth with width (and a LOT more training examples), which does not apply in the case of a convolutional net.	B-Review	B-3	Review	1
This really needs to be fixed.	I-Review	I-3	Review	1
<sep> <sep> My take on the results is however quite different from the conclusions given in the paper.	B-Review	B-4	Review	1
The paper makes it sound as if we could find a better way to train shallow nets in order to get results as good as deep nets, as if it was just an optimization issue.	I-Review	I-4	Review	1
My interpretation is quite different.	I-Review	I-4	Review	1
The results seem more consistent with the interpretation that the depth (and convolutions) provide a PRIOR that helps GENERALIZING better.	I-Review	I-4	Review	1
This is consistent with the fact that a much wider network is necessary in the convolutional case, and that in both cases you need to complement the shallow net's training set with the fake/mimic examples (derived from observing the outputs of the deep net on unlabeled examples) in order to match the performance of a deep net.	I-Review	I-4	Review	1
I believe that my hypothesis could be disentangled from the one stated in the paper (which seems to say that it is a training or optimization issue) by looking at training error.	I-Review	I-4	Review	1
According to my hypothesis, the shallow net's training error (without the added fake / mimic examples) should not be significantly worse than that of the deep net (at comparable number of parameters).	I-Review	I-4	Review	1
According to the 'training' hypothesis that the authors seem to state, one would expect training error to be measurably lower for deep nets.	I-Review	I-4	Review	1
In fact, for other reasons I would expect the deep net's training error to be worse (this would be consistent with previous results, starting with my paper with Dumitru Erhan et al in JMLR in 2010).	I-Review	I-4	Review	1
<sep> <sep> It would be great to report those training errors.	B-Review	B-5	Review	1
Note that to be fair, you have to report training error with no early stopping, continuing training for a fixed and large number of epochs (the same in both cases) with the best learning rate you could find (separately for each type of network).	I-Review	I-5	Review	1
<sep> <sep> Finally, the fact that even shallow nets (especially wide ones) can be hard to train (see Yann Dauphin's ICLR 2013 workshop-track paper) also weakens the hope that we could get around the difficulty of training deep nets by better training shallow nets.	B-Review	B-6	Review	1
<sep> <sep> Several more papers need to be cited and discussed.	B-Review	B-7	Review	1
Besides my JMLR 2010 paper with Dumitru Erhan et al (Why Does Unsupervised Pre-training Help Deep Learning), another good datapoint regarding the questions raised here is the paper on Understanding Deep Architectures using a Recursive Convolutional Network, by Eigen, Rolfe & LeCun, submitted to this ICLR 2014 conference.	I-Review	I-7	Review	1
Whereas my JMLR paper is about understanding the advantages of depth as a regularizer, this more recent paper tries to tease apart various architectural factors (including depth) influencing performance, especially for convolutional nets.	I-Review	I-7	Review	1
Yoshua, thank you for your comments.	O	O	Reply	1
We believe you may have read an older draft and hope that most or all of the misleading statements were corrected in the Jan 3 draft.	O	O	Reply	1
Nonetheless, many of your comments still apply to the current paper.	O	O	Reply	1
<sep> <sep> We completely agree that generality would be improved with results on additional datasets.	B-Reply	B-1	Reply	1
We submitted a workshop abstract instead of full paper because we only had results for one data set, and are about to run experiments on two other datasets.	I-Reply	I-1	Reply	1
<sep> <sep> With TIMIT we did not use more training data to train the shallow models than was used to train the deep models.	B-Reply	B-6	Reply	1
We used exactly the same 1.1M training cases used to train the DNN and CNN models to train the SNN mimic model.	I-Reply	I-6	Reply	1
The only difference is that the mimic SNN does not see the original labels.	I-Reply	I-6	Reply	1
Instead, it sees the real-valued probabilities predicted by the DNN or CNN it is trying to mimic.	I-Reply	I-6	Reply	1
In general, model compression works best when a large unlabelled data set is available to be labeled by the ‚Äúsmart‚Äù model so that the smaller mimic model can be trained ‚Äúhard‚Äù with less chance of overfitting.	I-Reply	I-6	Reply	1
But for TIMIT unlabelled data was not available so we used the same data used to train the deep models for compression (mimic) training.	I-Reply	I-6	Reply	1
We believe that the fact that no extra data --- labeled or unlabelled --- was used to train the SNN models helps drive home the point that it may be possible to train shallow models to be as accurate as deep models.	I-Reply	I-6	Reply	1
<sep> <sep> We agree with your comment that ‚ÄúThe paper makes it sound as if we could find a better way to train shallow nets in order to get results as good as deep nets, as if it was just an optimization issue.	B-Reply	B-4	Reply	1
‚Äù, except that we view it more perhaps as an issue of regularization than of just optimization.	I-Reply	I-4	Reply	1
In particular, we agree that depth, when combined with current learning and regularization methods such as dropout, is providing a prior that aids generalization, but are not sure that a similar effect could not be achieved using a different learning algorithm and regularization scheme to train a shallow net on the original data.	I-Reply	I-4	Reply	1
In some sense we‚Äôre making a black-box argument: we already have a procedure that given a training set, yields a shallow net that has accuracy comparable to a deep fully-connected feedforward net trained on the same data.	I-Reply	I-4	Reply	1
If we hadn‚Äôt shown you what the learning algorithm was in our black box would you have been 100% sure that the wizard behind the curtain must have been deep learning?	I-Reply	I-4	Reply	1
The real question is whether the black box *must* go through the intermediate step of training a deep model to mimic, or whether there exist other learning and regularization procedures that could achieve the same result without going through the deep intermediary.	I-Reply	I-4	Reply	1
We do not (yet) know the answer to this question, but it is interesting that a shallow model can be trained that is as accurate as a deep model without access to any additional data.	I-Reply	I-4	Reply	1
We certainly agree that it is difficult to train large, shallow nets on the original targets with the learning procedures currently available.	I-Reply	I-4	Reply	1
<sep> <sep> We agree that looking at training errors can be informative, but they might not resolve the issue in this case.	B-Reply	B-5	Reply	1
If model compression has access to a very large unlabelled data set, if the mimic model has sufficient capacity to represent the deep model, the shallow model will learn to be a high-fidelity mimic of the deep model and will make the same predictions, and the error of the shallow mimic model and deep model on train and test data will be identical as the error of the mimic predictions compared to the deep model is driven to zero.	I-Reply	I-5	Reply	1
This is for the ideal case where we have access to a very large unlabelled data set, which unfortunately we did not have for TIMIT.	I-Reply	I-5	Reply	1
Exactly what training errors do you want to see: the error of the DNN on the original training data vs. the error of the SNN trained to mimic the DNN on the real-valued targets, but measured on the original labels of the training points, or vs. the error of an SNN trained on the original data and labels?	I-Reply	I-5	Reply	1
Early stopping was used when training the deep models, but was not used when training the mimic SNN models.	I-Reply	I-5	Reply	1
In fact we find it very difficult to make the SNN mimic model overfit when trained with L2 loss on continuous targets.	I-Reply	I-5	Reply	1
<sep> <sep> Thanks for the pointers to other papers we should have cited.	B-Reply	B-7	Reply	1
We‚Äôre happy to add them to the abstract.	I-Reply	I-7	Reply	1
And thanks again for the careful read of our abstract.	I-Reply	I-7	Reply	1
Sorry you had to struggle through the 1st draft.	I-Reply	I-7	Reply	1

Interesting paper.	O	O	Review	1
My comments:	O	O	Review	1
<sep> Abstract: 'Moreover, the shallow neural nets can learn these deep functions using a total number of parameters similar to the original deep model.' -	B-Review	B-1	Review	1
this does not appear to be true for the CNN model.	I-Review	I-1	Review	1
<sep> <sep> 4.	O	O	Review	1
last sentence first paragraph is missing a 'to' at the end of the line 'models TO prevent overfitting'	B-Review	B-2	Review	1
<sep> 6. '	B-Review	B-3	Review	1
It is challenging to...' sentence needs work	I-Review	I-3	Review	1
<sep> 7. '	B-Review	B-4	Review	1
insertion penalty' and 'language model weighting' could use definitions or references.	I-Review	I-4	Review	1
<sep> figure 1 -> table 1	O	O	Review	1
<sep> 7.1 The first claim (also made in the abstract) is not supported by the table for the SNN mimicking the CNN.	B-Review	B-5	Review	1
It appears that ~15x as many parameters were needed to achieve the same level of performance.	I-Review	I-5	Review	1
The last sentence of the first paragraph seems to acknowledge this...	I-Review	I-5	Review	1
<sep> The second paragraph should, I think, be clarified.	B-Review	B-6	Review	1
How are you increasing performance of the deep networks?	I-Review	I-6	Review	1
What experiments did you perform that lead to this conclusion?	I-Review	I-6	Review	1
<sep> <sep> 8.	O	O	Review	1
The last sentence does not seem supported to me.	B-Review	B-7	Review	1
Your results as presented only achieve the same level of performance as previous results, and in order to achieve this level of performance, it would be necessary to use their training methods first so that your SNNs have something to mimic, correct?	I-Review	I-7	Review	1
David, thank you for your comments.	O	O	Reply	1
We submitted a revised draft on Jan 3 that addressed some of your concerns.	O	O	Reply	1
We‚Äôre sorry you read the earlier, rougher draft.	O	O	Reply	1
<sep> You are correct that we are not able to train a shallow net to mimic the CNN model using a similar number of parameters as the CNN model, and the text has been edited to reflect this.	B-Reply	B-1	Reply	1
We believe that if we had a large (> 100M) unlabelled data set drawn from the same distribution as TIMIT that we would be able to train a shallow model with less than ~15X as many parameters to mimic the CNN with high fidelity, but are unable to test that hypothesis on TIMIT and are now starting experiments on another problem where we will have access to virtually unlimited unlabelled data.	B-Reply	B-5	Reply	1
But we agree that the number of parameters in the shallow model will not be as small as the number of parameters in the CNN because the weight sharing of the local receptive fields in the CNN allows it to accomplish more with a small number of weights than can be accomplished with one fully-connected hidden layer.	I-Reply	I-5	Reply	1
Note that the primary argument in the paper, that it is possible to train a shallow neural net (SNN) to be as accurate as a deeper, fully-connected feedforward net (DNN), does not depend on being able to train an SNN to mimic a CNN with the same number of parameters as the CNN.	B-Reply	B-7	Reply	1
We view the fact that a large SNN can mimic the CNN without the benefit of the convolutional architecture as an interesting, but secondary issue.	I-Reply	I-7	Reply	1
<sep> <sep> Thank you again for your comments.	O	O	Reply	1
We agree with everything you said.	O	O	Reply	1

This paper studies the importance of a neural networks weights and to which extend do they need to be updated.	O	O	Review	20708
Particularly, the authors show that freezing weights which have small gradient in the very beginning of the training only results in a very slight drop in the final accuracy.	O	O	Review	20708
<sep> <sep> This paper should be rejected because (1) the paper only provides some empirical results on freezing network network weights, I don't think there are much insights and useful information; (2) To my knowledge, the phenomenon that only a few parameters are important has been observed before by many papers.	B-Review	B-2	Review	20708
<sep> <sep> Given that, I vote for a rejection.	O	O	Review	20708
Thank you for your feedback.	B-Reply	B-1	Reply	20708
To best of our knowledge, the previous studies have observed the process of freezing complete layers in a neural network unlike our studies that investigates the importance of the individual gradient parameters even in different layers without the need to freeze the complete layer and here lies the uniqueness of our study.	I-Reply	I-1	Reply	20708

The paper presents the empirical observation that one can freeze (stop updating) a significant fraction of neural network parameters after only training for a short amount of time, without hurting final performance too much.	O	O	Review	20708
The technical contribution made by this paper is an algorithm for determining which weights to freeze, called partial backpropagation, and an empirical validation of the algorithm on various models for image recognition.	O	O	Review	20708
<sep> <sep> The observation that weights can be frozen is somewhat interesting, although similar findings have been reported before.	B-Review	B-2	Review	20708
<sep> It's not clear the proposed algorithm is useful.	B-Review	B-1	Review	20708
The authors mention that fully parameterized models are expensive to run, but they don't demonstrate any speed-ups using their approach.	I-Review	I-1	Review	20708
Such speed-up would also not be expected since the forward pass of the algorithm cannot get faster by freezing weights, and the impact on the backward pass is limited.	I-Review	I-1	Review	20708
I'd be willing to raise my rating if the authors can convince me of the usefulness of their algorithm.	I-Review	I-1	Review	20708
Thank you very much for your very useful feedback.	B-Reply	B-2	Reply	20708
This is mainly a conceptual paper to theoretically prove that it is possible to freeze certain insignificant weights in the neural network.	I-Reply	I-2	Reply	20708
By right if the number of the updates needed to be performed on the parameters is much lesser, the backward pass time is shorter, which will eventually speed up the whole process.	I-Reply	I-2	Reply	20708
However, freezing individual weights within a layer is not possible by any current deep learning framework (only freezing a complete layer will all its weights is possible), and developing the code from scratch to perform as efficiently as any framework would will take a considerable amount of time.	I-Reply	I-2	Reply	20708
Nevertheless, the purposes of this paper is to prove the concept theoretically with sufficient empirical evidences.	I-Reply	I-2	Reply	20708

<sep> In this paper, the authors performed an empirical study on the importance of neural network weights and to which extent they need to be updated.	O	O	Review	20708
Some observations are obtained such as from the third epoch on, a large proportion of weights do not need to be updated and the performance of the network is not significantly affected.	O	O	Review	20708
<sep> <sep> Overall speaking, the qualitative result in the paper has already been discovered in many previous work, although the quantitative results seem to be new.	O	O	Review	20708
However, there is large room to improve regarding the experimental design and the comprehensiveness of the experiments.	O	O	Review	20708
Just name a few as follows:	O	O	Review	20708
<sep> 1)<tab>For different models and different tasks, the quantitative results are different.	B-Review	B-1	Review	20708
There is no deep discussion on the intrinsic reason for this, and what is the most important factor that influences the redundancy of weight updates.	I-Review	I-1	Review	20708
The authors came to the conclusion that from the third epoch on, no need to update most of the weights. ‚	I-Review	I-1	Review	20708
Äú3‚Äù seems to be a magic number to me.	I-Review	I-1	Review	20708
Why is it?	I-Review	I-1	Review	20708
No solid experiments were done regarding this, and no convincing analysis was made.	I-Review	I-1	Review	20708
<sep> <sep> 2)<tab>The datasets used in the experiments are not diverse enough and are not of large scale.	B-Review	B-2	Review	20708
For example, the CIFA-10 and MNIST datasets are relatively of small scale.	I-Review	I-2	Review	20708
What if the datasets are much larger like ImageNet.	I-Review	I-2	Review	20708
In such more complicated case, will the weight updates still be unnecessary?	I-Review	I-2	Review	20708
Will the ratio and the epoch number change?	I-Review	I-2	Review	20708
What is the underlying factor determining these?	I-Review	I-2	Review	20708
For another example, there are many NLP datasets for language understanding and machine translation, which are of large scale.	I-Review	I-2	Review	20708
Why choosing an image captioning dataset (which I do not agree to be real-life experiments when compared with language understanding and machine translation)?	I-Review	I-2	Review	20708
Can the observations generalizable to more complicated tasks and datasets?	I-Review	I-2	Review	20708
<sep> <sep> 3)<tab>The models studied in the paper are also a little simple, especially for the text task.	B-Review	B-3	Review	20708
Why just using a single-layer LSTM?	I-Review	I-3	Review	20708
Why not popularly used Transformer?	I-Review	I-3	Review	20708
<sep> <sep> As a summary, for an empirical study to be convincing, the tasks, datasets, scales, model structures, detailed settings, and discussions are the critical aspects.	O	O	Review	20708
However, as explained above, this paper has not done a good job on these aspects.	O	O	Review	20708
Significantly more work needs to be done in order to make it an impactful work.	O	O	Review	20708
<sep> <sep> *I read the author rebuttal, but would like to keep my rating unchanged.	O	O	Review	20708
Thanks for your feedback.	O	O	Reply	20708
<sep> For point number 1, we will try to further discuss and analyze this in a convincing manner.	B-Reply	B-1	Reply	20708
<sep> <sep> For point 2, we have chosen Image Captioning as it combines both vision (CNN operating on large-sized images) and language (RNNs for language modeling), and we believe that it reflects image understanding and language modeling at the same time, which is the reason why we chose it.	B-Reply	B-2	Reply	20708
As for using transformers, they themselves are very sensitive to train, and in our study we only focus on delivering our concern, without focusing on using "the best model".	I-Reply	I-2	Reply	20708
<sep> <sep> For point 3, For your comment on the model simplicity, we believe that the used models though they are simple (such as one layer LSTM) they are sufficient enough to proof the concept as this is mainly a conceptual paper to theoretically prove that it is possible to freeze certain insignificant weights in a neural network.	B-Reply	B-3	Reply	20708

This work is expressed clearly and well written.	O	O	Review	20702
<sep> <sep> The authors propose a new method to learn graph matching.	O	O	Review	20702
It contributes in two aspects: 1) a new edge embedding strategy and 2) Hungarian attention incorporating with the loss function.	O	O	Review	20702
A set of experiments as well as ablation studies have been conducted to show the effectiveness of the method.	O	O	Review	20702
<sep> <sep> However, my concerns are:	O	O	Review	20702
1) Is the graph matching algorithms only applied in the field of image matchingÔºüHow about other fieldsÔºü	B-Review	B-1	Review	20702
2) And if not, is it more convincing to conduct more experiments across other related fields?	B-Review	B-2	Review	20702
<sep> 3) It will be better to give algorithm complexity and parameter analysis with the state-of-the-art algorithms since many additional operations are added.	B-Review	B-3	Review	20702
We thank the kind advice and the response is as follows.	O	O	Reply	20702
<sep> <sep> Graph matching is a well-established and fundamental problem in computer science and operation research.	B-Reply	B-1	Reply	20702
Besides vision, it also has wide applications in protein alignment, software quality check, graphics, resource allocation, social network analysis etc.	I-Reply	I-1	Reply	20702
with many application papers using off-the-shelf graph matching techniques.	I-Reply	I-1	Reply	20702
<sep> <sep> We mainly conduct experiments under the vision setting in line with the majority of literature in this area.	B-Reply	B-2	Reply	20702
This is because there are several public and well-maintained graph matching datasets and experiment protocol in vision community, which makes the evaluation more direct and convenient.	I-Reply	I-2	Reply	20702
<sep> <sep> To further show the benefit of our method, we conduct an extra experiment (PASCAL-PF with only geometric edge features) by incorporating the proposed Hungarian Attention mechanism to the method in [1]. We observed performance enhancement consistently.	I-Reply	I-2	Reply	20702
Please refer to 'response to review#1' for more details.	I-Reply	I-2	Reply	20702
<sep> <sep> In general, the extra parameters involved in our algorithm compared to PCA are on the calculation of edge embedding.	B-Reply	B-3	Reply	20702
As our method requires the dimensions of node and edge embeddings to be identical, we generally double the amount of parameters in PCA.	I-Reply	I-3	Reply	20702
<sep> <sep> [1] Zhen Zhang, and Wee Sun Lee. "	O	O	Reply	20702
Deep Graphical Feature Learning for the Feature Matching Problem.",	O	O	Reply	20702
ICCV 2019	O	O	Reply	20702

The authors proposed a new way to train graph siamese networks for the graph matching problem.	O	O	Review	20702
The overall framework of this paper is somehow similar to [1] and [2], except for the final Hungarian attention module, which is the key contribution of this paper.	O	O	Review	20702
In the current settings, the authors proved that using their Hungarian attention module, the performance can be improved.	O	O	Review	20702
However, it would be better if the Hungarian attention can be applied to DGCNN in [1] and CMPNN in [2]. It would be good if the author can do an extra experiment to apply the Hungarian attention module to these two modules.	B-Review	B-1	Review	20702
Also, the authors may want to add some discussion about these two papers in the related works section (both papers do have published their codes).	I-Review	I-1	Review	20702
<sep> <sep> In the current experiment settings, both visual and geometric feature is used.	B-Review	B-2	Review	20702
Is it possible for the module to only using geometric features as [1] and [2]?	I-Review	I-2	Review	20702
<sep> <sep> <sep> [1] Wang, Yue, and Justin M. Solomon. "	O	O	Review	20702
Deep Closest Point: Learning Representations for Point Cloud Registration.",	O	O	Review	20702
ICCV 2019,	O	O	Review	20702
[2] Zhen Zhang, and Wee Sun Lee. "	O	O	Review	20702
Deep Graphical Feature Learning for the Feature Matching Problem.",	O	O	Review	20702
ICCV 2019	O	O	Review	20702
<sep> We thank the reviewer for his constructive suggestion and comments.	O	O	Reply	20702
<sep> <sep> As suggested by the reviewer, we have tested Hungarian attention on the model in [2]. To this end, we perform Hungarian algorithm on the output of [2] and establish the attention link during training stage (on synthetic training data).	B-Reply	B-1	Reply	20702
The rest of the settings follow [2]. Results on Pascal-PF dataset can be summarized:	I-Reply	I-1	Reply	20702
<sep> Method                   [2]*             [2]<tab>        [2]+Hungarian attention*	I-Reply	I-1	Reply	20702
w/o rotate<tab><tab>88.3<tab><tab>     88.5<tab><tab>89.1	I-Reply	I-1	Reply	20702
w     rotate             69.6             69.9            70.2	I-Reply	I-1	Reply	20702
where '[2]' refers to the results reported in [2] and '[2]*' corresponds to our implementation using the public code online.	I-Reply	I-1	Reply	20702
We can conclude that the Hungarian Attention can consistently enhance the performance as claimed in our paper.	I-Reply	I-1	Reply	20702
We will add this part to the appendix.	I-Reply	I-1	Reply	20702
<sep> <sep> Besides, we are still training our method on geometric features.	B-Reply	B-2	Reply	20702
We will update our paper once ready.	I-Reply	I-2	Reply	20702
<sep> <sep> Thanks again to the reviewer for pointing out these two highly relevant papers.	B-Reply	B-1	Reply	20702
We will discuss the methods in [1,2] in the final version.	I-Reply	I-1	Reply	20702
<sep> <sep> [1] Wang, Yue, and Justin M. Solomon. "	O	O	Reply	20702
Deep Closest Point: Learning Representations for Point Cloud Registration.",	O	O	Reply	20702
ICCV 2019,	O	O	Reply	20702
[2] Zhen Zhang, and Wee Sun Lee. "	O	O	Reply	20702
Deep Graphical Feature Learning for the Feature Matching Problem.",	O	O	Reply	20702
ICCV 2019	O	O	Reply	20702

This paper studies the graph matching problem in the context of vision.	O	O	Review	20702
Although I am familiar with the graph matching problem, I have much less experience regarding its application in vision.	O	O	Review	20702
My understanding is that features are extracted from images and used to construct a graph.	O	O	Review	20702
This graph is then passed through a GNN but there are steps which are unclear.	B-Review	B-2	Review	20702
In particular on page 5, 'm and H are fed to a GRU as a sequential input' but I do not see where this fit into the architecture.	I-Review	I-2	Review	20702
Similarly, I am a bit confused by equations (8) and (9) as there is a H^(t+1)_v in both equations.	B-Review	B-4	Review	20702
Does equation (9) make the function u_t explicit?	I-Review	I-4	Review	20702
Then what is \Gamma_N and similarly what is \Gamma_E in equation (11)?	I-Review	I-4	Review	20702
<sep> As it is written, this paper seems more appropriate for a conference in vision.	O	O	Review	20702
Thanks for your specific questions that will help improve our paper.	O	O	Reply	20702
To clarify, Eq (8) corresponds to the GNN update rule in [Gilmer et al 2017] (in which the read-out function is a GRU) and Eq (9) is our update rule (CIE).	B-Reply	B-3	Reply	20702
So Eq (8) and (9) are for different methods.	I-Reply	I-3	Reply	20702
We do not employ any GRUs in our algorithm.	I-Reply	I-3	Reply	20702
Instead, we adopt a Graph Convolutional Layer with ReLU activation.	I-Reply	I-3	Reply	20702
<sep> <sep> Our main contribution is to propose a Hungarian attention mechanism, which dynamically generates links in computational graph and proved beneficial to graph matching.	B-Reply	B-5	Reply	20702
Though the experiments are confined in vision for the relatively standard experiment protocol in this area and rich public benchmark, while as discussed in our response to review#4, graph matching itself is a fundamental problem in computer science.	I-Reply	I-5	Reply	20702
<sep> <sep> And more importantly, the added new results in response to review#1 (imposing Hungarian attention to [1])  showed that our Hungarian attention is a general and effective means to improve graph matching (in [1] geometric edge features are utilized).	B-Reply	B-4	Reply	20702
In fact, the paper is written in an abstractive level in terms of the technical approach (the edge embedding and Hungarian attention are both general and have nothing to do with images), and the related work.	I-Reply	I-4	Reply	20702
Though the experiments are concerned with vision setting for the reasons we mention above (and also due to space limitation).	I-Reply	I-4	Reply	20702
We will add more broad discussion in the introduction and add the new results in the experiment part.	I-Reply	I-4	Reply	20702
<sep> <sep> [1] Zhen Zhang, and Wee Sun Lee. "	O	O	Reply	20702
Deep Graphical Feature Learning for the Feature Matching Problem.",	O	O	Reply	20702
ICCV 2019	O	O	Reply	20702

The paper proposes SVQN, an algorithm for POMDPs based on the soft Q-learning framework which uses recurrent neural networks to capture historical information for the latent state inference.	O	O	Review	20668
In order to obtain this formulation, the author first derive the variational bound for POMDPs and then present a practical algorithm.	O	O	Review	20668
<sep> <sep> The key idea of the paper is to replace DQN with Soft Q-learning that already demonstrated better performance on a variety of tasks.	B-Review	B-1	Review	20668
This seems to be an obvious extension of DRQNs (Hausknecht &amp; Stone, 2015) even though it did not appear in the literature.	B-Review	B-2	Review	20668
<sep> <sep> The authors evaluate the final algorithm on a set of ALE and DoomViz tasks.	O	O	Review	20668
The algorithm outperforms the previous methods, in particular, DRQNs.	O	O	Review	20668
The set of tasks and prior methods is adequate.	O	O	Review	20668
<sep> <sep> Overall, the contribution of the paper is not significant enough to be accepted to ICLR.	O	O	Review	20668
<sep> <sep> We thank the reviewer for the valuable comments.	O	O	Reply	20668
However, we humbly disagree on the primary concern that our paper is an "obvious extension" of DRQNs (Hausknecht &amp; Stone, 2015).	O	O	Reply	20668
<sep> <sep> Firstly, it is not just an "obvious extension" of DRQNs.	B-Reply	B-1	Reply	20668
As stated in the third paragraph of Section 1, both DRQNs and its improved version of Action-specific Deep Recurrent QNetwork (ADRQN) (Zhu et al 2018) fail to utilize the Markov property of the state in POMDPs, because they just represent the state as latent variables of neural networks.	I-Reply	I-1	Reply	20668
To solve this problem, our algorithm starts from the graphical model representation of POMDPs, which is very intuitive and generic, and then we derive the ELBO and finally lead to the design of the neural network.	I-Reply	I-1	Reply	20668
In the experiments, we show that our method outperforms both DRQN and ADRQN by a large margin on several challenging tasks.	I-Reply	I-1	Reply	20668
And our ablation study also shows that our method is more robust to the disturbance of the observation.	I-Reply	I-1	Reply	20668
Overall, as agreed by Reviewer #3, we provide a novel solution to POMDPs, which is better than DRQNs and ADRQN in terms of both theoretical formulation and empirical results.	I-Reply	I-1	Reply	20668
<sep> Secondly, it is not just "replace DQN with Soft Q-learning".	B-Reply	B-2	Reply	20668
The reason why we use soft Q-learning (i.e., Maximum Entropy Reinforcement Learning) has been explained in Section 3.2.	I-Reply	I-2	Reply	20668
As we want to solve the POMDPs under a unified graphical model, we derive the ELBO of POMDPs and design generative models to handle the inference of the hidden states.	I-Reply	I-2	Reply	20668
Moreover, we apply additional approximate functions to tackle the conditional prior problem (as stated in Section 4.2).	I-Reply	I-2	Reply	20668
Finally, to train the generative models and the planing algorithm jointly, we design a recurrent neural network to reduce the computation complexity.	I-Reply	I-2	Reply	20668
We also explore two different recurrent models in our context: GRU and LSTM, and both of them outperform the baseline methods on various tasks.	I-Reply	I-2	Reply	20668
Fig.4(a) also shows that our jointly training process is more effient than other baselines.	I-Reply	I-2	Reply	20668
Table 1 shows that our algorithm is more powerful than the naive soft q-learning algorithm (DSQN).	I-Reply	I-2	Reply	20668
To summarize, we have done much work to deal with the challenges in POMDPs and improve the performance of our algorithm.	I-Reply	I-2	Reply	20668
<sep> <sep> We hope our answers can address your concerns.	O	O	Reply	20668

This paper proposes a new sequential model-free Q-learning methodology for POMDPs that relies on variational autoencoders to represent the hidden state.	O	O	Review	20668
The approach is generic, well-motivated and has  clear applicability in the presence of partial observability.	O	O	Review	20668
The idea is to create a joint model for optimizing the hidden-state inference and planning jointly.	O	O	Review	20668
For that reason variational inference is used to optimize the ELBO objective in this particular setting.	O	O	Review	20668
All this is combined with a recurrent architecture that makes the whole process feasible and efficient.	O	O	Review	20668
The work is novel and it comes with the theoretical derivation of a variational lower bound for POMDPs in general.	O	O	Review	20668
This intuition is exploited to create a VAE based recurrent architecture.	O	O	Review	20668
One motivation comes from maximal entropy reinforcement learning (MERL), but which has the ad hoc objective of maximizing the policy entropy.	O	O	Review	20668
On the other hand SVQN optimizes both a variational approximation of the policy and that of the hidden state.	O	O	Review	20668
Here the rest terms of the ELBO objective can be approximated generatively and some of them are conditioned on the previous state which calls for a recurrent architecture.	O	O	Review	20668
The other parts are modeled by a VAE.	O	O	Review	20668
The paper also explores two different recurrent models in this context: GRU and LSTM are both evaluated.	O	O	Review	20668
Besides the nice theoretical derivation the paper presents compelling evidence by comparing this approach to competing approaches on four games of the flickering ATARI benchmark and outperforming the baselines significantly.	O	O	Review	20668
Also both the GRU and LSTM version outperforms the baseline methods on various tasks of the VIZDoom benchmark as well.	O	O	Review	20668
In general, I find that this well written paper presents a significant progress in modelling POMDPS in a model-free manner with nice theoretical justification and compelling empirical evidence.	O	O	Review	20668
We thank Reviwer #3 for the valuable comments and the appreciation of our novel contributions.	O	O	Reply	20668

This paper proposes a method to capture patterns of ‚Äúoff‚Äù neurons using a newly proposed metric.	O	O	Review	554
While the authors have considered only linear networks, the setup is still relevant because how often these networks can give meaningful results, and can possibly pave the way for future research into more general networks.	O	O	Review	554
<sep> <sep> Pros: The idea itself is interesting, the related works are discussed well, and MNIST experiments are very interesting.	O	O	Review	554
<sep> <sep> Cons/comments : The writing needs a lot of improvement if to be considered for a top venue like iclr.	B-Review	B-1	Review	554
Other than the MNIST experiments, which show and indicate the importance of relative contrast and boundary, I am not sure how other experiments are meaningful.	I-Review	I-1	Review	554
CIFAR and smallnorb experiments are merely presented, without discussions on what the interpretation shows or helps over the existing methods.	I-Review	I-1	Review	554
Infact, the other methods seem to capture a lot more information than the proposed method.	I-Review	I-1	Review	554
I would suggest adding more discussions and more experiments that show interpretation that this method/metric helps with to make this work stronger.	I-Review	I-1	Review	554
<sep> <sep> Have the authors considered  the metric to consider ‚Äúon‚Äù neurons instead of ‚Äúoff‚Äùneurons ?	B-Review	B-2	Review	554
Is it possible to have a general metric that combines the two in some way ?	I-Review	I-2	Review	554
Intuitively, its unclear to me why only the off patterns can help (except in specific cases as shown in MNIST experiments).	I-Review	I-2	Review	554
<sep> <sep> ‚Äúand thus is responsible for the activity vi‚Äù ‚Äì This is unclear to me.	B-Review	B-3	Review	554
I understand the projection part though, but I cant make sense of this statement.	I-Review	I-3	Review	554
<sep> <sep> ‚Äúinterpretation and interpretability ‚Äù in the introduction ‚Äì the writing is too informal.	B-Review	B-4	Review	554
Making use of italicized phrases like ‚Äúswitched linear projection‚Äù does not help with the understanding at all, especially because ‚Äúswitched‚Äù is defined after using the term atleast thrice.	I-Review	I-4	Review	554
<sep> <sep> Confirmation bias &lt;-&gt; ‚Äúinformation we want to get‚Äù.	B-Review	B-5	Review	554
<sep> <sep> The same issue right after eq 6. ‚	B-Review	B-6	Review	554
ÄúReference subtracted from ‚Ä¶.‚Äù where the first word is italicized to probably imply some intuitive explanation, but for someone not familiar with what reference is just tends to confuse the reader.	I-Review	I-6	Review	554
Please fix missing references.	I-Review	I-6	Review	554
<sep> <sep> Eq 7 seems written incorrectly, with the where ‚Äúv= ‚Ä¶‚Äù.	B-Review	B-7	Review	554
Please fix.	I-Review	I-7	Review	554
<sep> <sep> What is the variance of saliency checks ?	B-Review	B-8	Review	554
In other words, if the experiment of 100 random samples is repeated (say) 20 times, how different are the corresponding coefficients across these repeated runs ?	I-Review	I-8	Review	554
<sep> <sep> Figure 3 is waste of space (move to appendix?)	B-Review	B-9	Review	554
<sep> <sep> I might be splitting the hairs but Theorem 1 does not warrant a theorem.	B-Review	B-10	Review	554
The result/proof is too straightforward to be a theorem and is already known in some form in the folklore.	I-Review	I-10	Review	554
<sep> <sep> <sep> Thank you for reviewing our work.	O	O	Reply	554
<sep> <sep> The objective of Figure 5 is to provide a comparison of the penultimate-layer Insens, as well as layer-by-layer Insens from Figure 6, against other methods on more challenging datasets than MNIST.	B-Reply	B-1	Reply	554
We do make a small comment (in a segue to layer by layer visualisations and Figure 6) conceding that the penultimate-layer Insens does not necessarily provide significantly improved visualisations.	I-Reply	I-1	Reply	554
However, what makes up for that is the fact that Insens can show what each layer is doing in the neural network.	I-Reply	I-1	Reply	554
This seems like a significant feature that other methods lack.	I-Reply	I-1	Reply	554
Also, the statement that other methods "seem to capture a lot more information" needs to be stacked against the saliency and sanity checks provided in Figure 7.	I-Reply	I-1	Reply	554
Sure, Deep Taylor looks like it's showing us more, but it turns out it's just showing us back input, and not what the network is doing.	I-Reply	I-1	Reply	554
The problem with these visualisations is that we assume they "outline" the object of interest in the image - but that's making an assumption that these networks recognise by shape.	I-Reply	I-1	Reply	554
It's been shown that in fact they seem to "perceive" by texture rather than shape (Geirhos.etal, ICLR 2019).	I-Reply	I-1	Reply	554
<sep> Yes, we have considered including "on" neurons.	B-Reply	B-2	Reply	554
Our initial version of Insens (before it was called Insens) was averaging \hat{w}-\hat{c} from all the neurons.	I-Reply	I-2	Reply	554
We found that active neurons don't change the visualisations in a significant way.	I-Reply	I-2	Reply	554
We considered whether to propose a more general version of Insens, but decided to focus on the message of importance of the "off" neurons, which hasn't been considered before.	I-Reply	I-2	Reply	554
One possible objection to inclusion of active neurons is that their contributions are accounted in the switched projection, whereas the impact of the switched off neuron terminates at that neuron.	I-Reply	I-2	Reply	554
There is a potential for more generic future methods based on \hat{w}-\hat{c}, but we feel that pointing out the significance of the "off" neurons is a important contribution that would be of interest to many readers, who later on may go on to use this approach in different and perhaps even improved ways.	I-Reply	I-2	Reply	554
Having said all that, we concede that an explicit explanation to that effect should be made in the paper, since inclusion of active neurons is something that perceptive readers might wonder about.	I-Reply	I-2	Reply	554
<sep> <sep> The bar height in Figure 7 gives the mean of correlation over 100 samples and there is a bar (perceptible only in DeepTaylor and LRP) that shows the variance.	I-Reply	I-2	Reply	554
We can increase the sample size (is the reviewer suggesting we need to do it over 2000 samples?).	I-Reply	I-2	Reply	554
We are happy to add something to the caption explaining how variance is shown.	I-Reply	I-2	Reply	554
<sep> <sep> As pointed out by another reviewer, the explanation of the concept of neuron's centre is already pretty terse and fast.	I-Reply	I-2	Reply	554
While for some readers just the math is enough, we feel that a graphical representation of the concept of the centre is the most straight forward way to present the meaning of \hat{w}-\hat{c}, which is critical to understanding how Insens works.	I-Reply	I-2	Reply	554
<sep> <sep> In our opinion, a theorem is just a way of presenting a logical argument by making a statement followed by a proof.	B-Reply	B-10	Reply	554
Theorems are often used to prove trivial and intuitive results for the sake of completeness and unambiguity.	I-Reply	I-10	Reply	554
In our case, theorem is a clear way of presenting the building block of Insens.	I-Reply	I-10	Reply	554
Yes, the proof is elementary, but the theorem (even if obvious), is fundamental to the Insens method.	I-Reply	I-10	Reply	554
Indeed, once seen, our method for "collapsing" a deep network into a single linear projection might not seem that surprising.	I-Reply	I-10	Reply	554
The point is not that we merely show that it's possible, but what we do with it.	I-Reply	I-10	Reply	554
This seemingly straight forward observation leads us to decompose a computation in a neural network into active and inactive subnetworks.	I-Reply	I-10	Reply	554
We demonstrate how the inactive network, implicitly ignored by other interpretability methods, not only provides information for interpretability, but also can provide information about what happens inside the network.	I-Reply	I-10	Reply	554
Compared to DeepTaylor (which, as Figure 7 show is perhaps in the end not all that informative about what the model is doing), our method is mathematically simple and very intuitive - surely that's a good thing.	I-Reply	I-10	Reply	554
If the reviewer can provide a reference where switched linear projection has been presented, we'd be happy to reference it.	I-Reply	I-10	Reply	554
However, in the absence of prior publication using switched linear projections (or similar) for interpretability, we believe that, on the whole, we present something quite novel and not at all trivial.	I-Reply	I-10	Reply	554
<sep> <sep> We'll be happy to make other minor fixes suggested by the reviewer.	B-Reply	B-9	Reply	554

This manuscript introduces a novel method to explain activities of ReLU-based deep networks by constructing a linear subnetwork which only contains neurons activated by the input.	O	O	Review	554
The status of each neuron can be obtained given any input sample.	O	O	Review	554
Moreover, the author applies the notion of ‚Äúneuron‚Äôs center‚Äù, which is a neutral data point that is similar to actual input x, but with differences in particular objects to cause f(x) be positive.	O	O	Review	554
The activity of each neuron can be decomposed into the attribution of each input pixel, and this decomposition can also be used to measure the contribution of each pixel to the network stability.	O	O	Review	554
Overall, the proposed methodology is intuitive and distinctive to the state-of-the-art interpretability methods.	O	O	Review	554
<sep> <sep> However, the application constraint on the ReLU-based deep neural network prevents this method from being a model agnostic approach: the problem formulation would be much different if other non-linear activation functions are used.	B-Review	B-1	Review	554
Although the experiment part visualizes the superiority of switched linear projections over other prevalent approaches, the evaluations contain mostly subjective assessment and the arguments are monotonous.	I-Review	I-1	Review	554
I would suggest adding more experiments with quantitative analysis, or mathematically demonstrate why the proposed method is better than, say purely gradient-based method, in the linear case.	B-Review	B-2	Review	554
In addition, additional experiments on a broader set of input data (e.g., tabular, text) could avoid the evaluations look cherry-pick.	I-Review	I-2	Review	554
<sep> <sep> Minor issues:	O	O	Review	554
<sep> 1.	O	O	Review	554
In figure 2, I think it would be better to write down explicitly the connections between v, \hat{b} and \hat{w} for each neuron given any input.	B-Review	B-3	Review	554
Just seeing v and \hat{b} on top of each subfigure is a bit confusing.	I-Review	I-3	Review	554
<sep> 2.	B-Review	B-4	Review	554
I spent a long time to understand the "neuron‚Äôs center" concept, it might be better to add some background or mathematical formulation.	I-Review	I-4	Review	554
<sep> 3.	B-Review	B-5	Review	554
In figure 4, when the digits get misclassified, the Insens explanation should highlight the patterns of wrongly predicted digits, but the patterns of neurons' inactive state sensitivity still look like the correct digits.	I-Review	I-5	Review	554
<sep> 4.	O	O	Review	554
It would also be interesting to show how the Insens explanation would change when the input is under various kinds of adversarial attacks rather than adding simple Gaussian noise.	B-Review	B-6	Review	554
<sep> <sep> Thank you for taking time to review our paper.	O	O	Reply	554
<sep> <sep> Indeed, Insens in not model agnostic, but the driving idea of this work is that inactive neurons carry information about what is happening inside the network.	B-Reply	B-1	Reply	554
For non-ReLU networks there is no notion of inactive neurons as it would be hard to find, in a sigmoid network for instance, a neuron outputting exactly zero.	I-Reply	I-1	Reply	554
The non-linearity at exactly 0 is a unique feature of ReLU networks that allows separation of the architecture into active and inactive sub-networks - a feature that can be exploited for the analysis presented in the paper.	I-Reply	I-1	Reply	554
In fact, the switched linear projection itself is generalisable to networks with non-ReLU functions - we hint at this in the paper when we state that switched projection is equivalent to derivative of activity with respect to the input.	I-Reply	I-1	Reply	554
So, \hat{w}=dv/dx, and therefore \hat{b}=v-\hat{w}x, which can be computed for a neuron from a network of any activation function (as long as the function has a first derivative).	I-Reply	I-1	Reply	554
However, since we were specifically interested in the notion of separating the non-active subnetwork from the rest of the architecture, we decided, in the interest of readability, to limit the paper to ReLU networks only.	I-Reply	I-1	Reply	554
We believe that this is still a worthy and useful contribution on the account of prevalence of the ReLU networks in deep learning applications.	I-Reply	I-1	Reply	554
<sep> <sep> Following other reviewer's suggestion, we did include an objective and quantitative analysis of Insens based on salience and sanity checks of Abedayo et al's in the latest version of the paper.	B-Reply	B-4	Reply	554
As it turned out, the quality visualisations of the original definition of Insens , and the DeepTaylor method, were so good mostly because they echoed the input rather than what the model was doing.	I-Reply	I-4	Reply	554
The new definition of the layered Insens, considers the inactive states of neurons of one layer at a time.	I-Reply	I-4	Reply	554
The visualisations from the penultimate layer are still of decent quality, but now definitely not simply echoing the input.	I-Reply	I-4	Reply	554
At the same time, we can use the new layered definition to track the inactive state through different layers of the network.	I-Reply	I-4	Reply	554
<sep> <sep> We agree that more experiments on a broader set of input data is always a great idea, but the space is limited, and we felt that image-based visualisation are sufficient to present our novel method.	B-Reply	B-2	Reply	554
However, as the reviewer suggested, we did add visualisations for adversarial examples in the appendix.	I-Reply	I-2	Reply	554
<sep> <sep> In Figure 4, where the noisy digit gets misclassified, indeed the visualisation does not necessarily produce an image of the wrong digit.	B-Reply	B-5	Reply	554
But this assumes that the only way for a network to misclassify a digit is to mistake it for another one.	I-Reply	I-5	Reply	554
It's important to keep in mind that, given softmax output, the network divides the space of all images into digits.	I-Reply	I-5	Reply	554
As a result, there are many images that have nothing to do with numbers, yet the network will classify as one of the digits.	I-Reply	I-5	Reply	554
Thus, as in the case of the adversarial examples included in the appendix, the network does not necessarily "see" the wrong digit when making the wrong prediction.	I-Reply	I-5	Reply	554
Instead, it sees the noise that happens to produce a particular label.	I-Reply	I-5	Reply	554
We believe Insens visualisations highlight that noise, but it's hard for us to see patterns in it, since the network is not reacting to a shape-based pattern.	I-Reply	I-5	Reply	554

The work basically introduced a new way of looking at interpretability; instead of focusing on the source of activations in the network for a given input image, focus on the source of stability (non-active) neurons (in a ReLU network).	O	O	Review	554
The work starts by proving (although it is trivial) that in a ReLU (more generally any piece-wise linear) network, for a given input image, there is a locally linear relationship between a given neuron's activation and the image: v= w^T x + b. As the authors correctly mention, focusing on 'w' as the sensitivity analysis is basically the vanilla gradient method.	O	O	Review	554
The contribution, however, is focusing on the projection of bias and the introduced notion of 'centre'.	O	O	Review	554
With this provided notion, one can focus on the deactivated neurons in the network and how each input pixel is responsible for it.	O	O	Review	554
In other words, unlike previous work that focuses on the activation map, the authors correctly refer to the deactivated neurons as another source of the network's prediction.	O	O	Review	554
<sep> <sep> I'm have reasons for both accepting and rejecting this work.	O	O	Review	554
The work provides a new perspective and asks a very interesting question.	O	O	Review	554
The introduced method, although quite simple and trivial, is useful and the authors do a very good job of making valid and reasonable claims about their work's contribution and how it connects to the existing literature.	O	O	Review	554
The main drawback of the paper, however, is whether the contributions are enough for this venue.	B-Review	B-6	Review	554
The paper does not convince me that the introduced method would result in better interpretability of deep networks compared to what is already there.	I-Review	I-6	Review	554
Another minor (or for some people in the field major) issue is the experimental setup.	I-Review	I-6	Review	554
All of the experiments are focused on subjective examples and no objective measure of the introduced method is provided (and the field has many of those objective measures).	I-Review	I-6	Review	554
Providing a few examples of the method in comparison with other methods is not sufficient.	I-Review	I-6	Review	554
Anyhow, the experiment where they prove the usefulness of the method by adding background noise is interesting.	I-Review	I-6	Review	554
I would personally suggest the authors to expand this experiment to testing the method's sanity using the sanity measures provided in previous work: <a href="https://arxiv.org/abs/1810.03292" target="_blank" rel="nofollow">https://arxiv.org/abs/1810.03292</a> The claims made about the results on smallNORB can be controversial as the authors interpret their method's flipping of importance to be the reality of what's happening in the network and the other method's focus on the edges as false; this is not clear to be true.	I-Review	I-6	Review	554
My score would be subject to change if better experimental results are provided (and the other way round).	I-Review	I-6	Review	554
<sep> <sep> A few suggestions and questions:	O	O	Review	554
* One very important issue with the method is that it considers all of the inactive neurons.	B-Review	B-1	Review	554
We know that a substantial percentage of inactive neurons are just dead neurons the stability of which does not matter.	I-Review	I-1	Review	554
How would the method address the issue?	I-Review	I-1	Review	554
<sep> * There definitely needs to be an objective measure of the introduced method's performance compared to previous work.	B-Review	B-2	Review	554
<sep> * The work seems very related to DeepLIFT while there is no mentioning of it.	B-Review	B-3	Review	554
<sep> * I'm not a fan, but adding results on a SOTA ImageNET paper always helps with making the experiments section crisper.	B-Review	B-4	Review	554
<sep> * The authors claim that even small perturbations will change the activation pattern.	B-Review	B-5	Review	554
This is not a small claim and is definitely in need of more evidence.	I-Review	I-5	Review	554
Thank you for very insightful review.	O	O	Reply	554
The time taken to respond is a consequence of some soul searching and a decent amount of work we had to undergo in order to address the request for objective evaluation of the proposed method.	O	O	Reply	554
<sep> <sep> After quick test based on Abedayo et al's objective measures of visualisation, it became immediately apparent that the correlation between Insens visualisations from the trained, random weights and random label networks, though lower than DeepTaylor's, is still quite high.	B-Reply	B-1	Reply	554
However, after an investigation, we realised that if we compute Insens over the inactive neurons of a given layer (rather than over the whole network), then these correlations vary from layer to layer.	I-Reply	I-1	Reply	554
While this required a slight change of definition of Insens,  visualisations based on the penultimate layer of the network were still very good.	I-Reply	I-1	Reply	554
This new definition also created the potential for visualisation of the inactive state layer by layer.	I-Reply	I-1	Reply	554
We feel that these changes do not detract from the main argument of the paper, which promotes the use of inactive state for interpretability.	I-Reply	I-1	Reply	554
Hence, we‚Äôve decided to change the evaluation a bit and add the saliency tests.	I-Reply	I-1	Reply	554
The new version of the paper has been uploaded.	I-Reply	I-1	Reply	554
<sep> <sep> With respect to completely dead neurons, initially we thought these could be simply taken out of the network before the Insens computation.	I-Reply	I-1	Reply	554
But thinking about importance of the neurons that are off for most of the time (when tracking their activity over all training samples) as opposed to those that are inactive half of the time, we decided to supplement the Insens sum with a weighting factor.	I-Reply	I-1	Reply	554
The factor m_i/N multiplies the insensitivity vector by the ratio of the number of times the neuron in question is active (over the training data) , m_i, over the number of training examples, N.  For neurons that are always off m_i/N=0, for those that are almost always on, but inactive for a given input in Insens, m_i/N -&gt; 1.	I-Reply	I-1	Reply	554
<sep> <sep> We have included an analogy to DeepLIFT‚Äôs reference input when explaining the concept of neuron‚Äôs centre.	B-Reply	B-3	Reply	554
<sep> <sep> The main reason why we can‚Äôt at this time include the state of the art ImageNET visualisations is because our computation of Insens is (at this moment) not very efficient.	B-Reply	B-4	Reply	554
In VGG-16, there are, on average, 50% inactive neurons for a given input - that‚Äôs many millions of inactive neurons.	I-Reply	I-4	Reply	554
The easiest way to compute a switched vector is to take the derivative of neuron activity with respect to the network input, and then find \hat{b} by subtracting \hat{w}x from v.  Since our implementation is in Tensorflow, it would seem easy, but Tensorflow creates separate graph for each derivative of activity with respect to the input.	I-Reply	I-4	Reply	554
While it does have a single operation for computing sum of derivatives, this would give us a sum of \hat{w}, whereas for Insens we need the sum of \hat{w}-\hat{c} (and we can't calculated these sums separately since \hat{c}=v\hat{w}/(\hat{w}^t\hat{w}) is not independent of \hat{w}).	I-Reply	I-4	Reply	554
It should be possible to add an operation to Tensorflow that does what we need in one graph, but at this point we don‚Äôt have the Tensorflow know-how on how to do this in such a short time.	I-Reply	I-4	Reply	554
<sep> <sep> In relation to our claim that even small perturbations will change the activation pattern, this is based on some sporadic experimental evidence, which is not ready for publication and quite possibly would qualify as a different paper altogether.	B-Reply	B-5	Reply	554
We removed this statement from our conclusion and toned down the claims of Insens being better than active-based visualisation.	I-Reply	I-5	Reply	554
Nevertheless we feel that the idea of using inactive state for interpretability and Insens are still strong contributions that supplement existing methods for interpretability.	I-Reply	I-5	Reply	554

Notes:	O	O	Review	554
<sep> -Goal is to study the "active subnetwork" of Relu based networks for interpretability.	O	O	Review	554
<sep> -The question of interpretation seems rather thorny.	O	O	Review	554
<sep> -In Figure 4, the result for Insens seem alright, although it's weird that the data is just mnist digit / noise.	B-Review	B-1	Review	554
I feel like something with multiple objects would make it much clearer if there is an actual improvement?	I-Review	I-1	Review	554
For example on Figure 5 I'm not really sure if Insens is better.	I-Review	I-1	Review	554
The results often look worse to me than "DeepTaylor", especially on CIFAR10.	I-Review	I-1	Review	554
<sep> Review: This paper proposes to improve the interpretation of relu based networks by considering the "inactive network" which could potentially become activated by local perturbations instead of just considering the active part of the network (which is locally linear).	O	O	Review	554
I think this is a step in the right direction for the interpretation of relu based networks, although the results are somewhat borderline.	O	O	Review	554
<sep> Additionally the tasks could be much better, to show situations where an object is present but which is not related to the labels.	B-Review	B-2	Review	554
This would provide a much clearer test of the model's capabilities.	I-Review	I-2	Review	554
<sep> <sep> Thank you for your review and suggestions.	O	O	Reply	554
<sep> <sep> As the reviewer pointed out, in the original paper the Insens visualisations were similar to DeepTaylor one, on occasion perhaps not being even equally good.	B-Reply	B-1	Reply	554
Prompted by another review, we carried out saliency and sensitivity analysis which show that both the original Insens and DeepTaylor produced similar visualisations for the same input regardless of the model it passed through.	I-Reply	I-1	Reply	554
However, after redefining Insens to relate information of the inactive neuron sensitivity over individual layers of a network (in the latest edition of the paper), we created a method for layered interpretability, from the early stages where neurons "look at the entire input", to "decision making" patterns of the penultimate layer of the network.	I-Reply	I-1	Reply	554
<sep> <sep> The suggestion of evaluation over images with objects that need to be ignored is quite a nice idea.	B-Reply	B-3	Reply	554
When working on new experiments for the layered version of Insens, we did create a simple MNIST dataset with two different digits in the input image and one label.	I-Reply	I-3	Reply	554
In the first instance, the digit to be labeled was always on the left-hand side...in which case the task was trivial - the network easily learns to ignore the other side of the image, and the non-label digits are not highlighted in all visualisation methods (or are a bit fainter in case of DeepTaylor).	I-Reply	I-3	Reply	554
Then we tried a task where the each image contained randomly ordered even and odd number, with the even number labelled.	I-Reply	I-3	Reply	554
This network didn't train well over the 2CONV architecture (poor test accuracy).	I-Reply	I-3	Reply	554
The option of trying a bigger network is not appealing, since if the visualisation shows both digits as being important, it is not clear whether the visualisation is wrong.	I-Reply	I-3	Reply	554
After all, it's probably possible for the network to "memorise" all combinations of possible digits (at least in this test) and thus show both as important.	I-Reply	I-3	Reply	554
Hence, we decided not to pursue this experiment any further, especially since at best it could only make it to the appendix of the paper.	I-Reply	I-3	Reply	554

This paper describes an approach to domain adaptation that uses	O	O	Review	554
self-supervised losses to encourage source/target domain alignment for	O	O	Review	554
unsupervised domain adaptation.	O	O	Review	554
The authors propose to use four	O	O	Review	554
self-supervised tasks (variants of tasks used in the self-supervised	O	O	Review	554
representation learning for object recognition literature) that are	O	O	Review	554
used with a combined loss including unlabeled source and target	O	O	Review	554
training samples.	O	O	Review	554
The authors also propose an alignment heuristic for	O	O	Review	554
guiding early stopping.	O	O	Review	554
Experimental results on a standard battery of	O	O	Review	554
domain adaptation problems are given, plus some intriguing baseline	O	O	Review	554
results for semantic segmentation.	O	O	Review	554
<sep> <sep> The paper is written very well and the technical development and	O	O	Review	554
motivations for each decision are well discussed and argued.	O	O	Review	554
<sep> <sep> 1.	O	O	Review	554
The experimental evaluation is a bit limited as the object	B-Review	B-1	Review	554
recognition datasets are a bit limited.	I-Review	I-1	Review	554
Results on Office or	I-Review	I-1	Review	554
Office-Home would be nice.	I-Review	I-1	Review	554
<sep> <sep> 2.	O	O	Review	554
Using location classification for semantic segmentation seems	B-Review	B-2	Review	554
intuitively to be encouraging the network to learn coarse spatial	I-Review	I-2	Review	554
priors (which should be invariant across the two domains).	I-Review	I-2	Review	554
Have you	I-Review	I-2	Review	554
looked at how alignment is actually happening?	I-Review	I-2	Review	554
More qualitative	I-Review	I-2	Review	554
analysis in this direction would be useful to appreciate the	I-Review	I-2	Review	554
proposed approach.	I-Review	I-2	Review	554
<sep> <sep> 3.	O	O	Review	554
Related to the previous point, it would be interesting to see how	B-Review	B-3	Review	554
semgmentations in the unsupervised domain gradually change and	I-Review	I-3	Review	554
improve with increasing alignment.	I-Review	I-3	Review	554
<sep> <sep> In summary: the ideas are simple, intuitive, and well-explained -- I	O	O	Review	554
think the results reported would be easy to reproduce with minimal	O	O	Review	554
head scratching.	B-Review	B-4	Review	554
The experiments are interesting and not overstated.	I-Review	I-4	Review	554
<sep> <sep> Thank you for your thoughtful review.	O	O	Reply	554
Here we answer your questions:	O	O	Reply	554
1.	B-Reply	B-1	Reply	554
For rebuttal we ran our method (rotation only) on Office-31, using a ResNet-50 pre-trained on ImageNet, following standard procedures.	I-Reply	I-1	Reply	554
This dataset contains three domains: Amazon, Webcam and Dslr, a total of 4,652 images and 31 categories.	I-Reply	I-1	Reply	554
Because Office is small for deep learning and not used by many of the baselines we compare to in Table 2, these additional results should not be viewed as our main contribution, but here for completeness at the requests of reviewers.	I-Reply	I-1	Reply	554
The baseline results are taken from the Office-31 tables of these two papers:	I-Reply	I-1	Reply	554
Contrastive Adaptation Network for Unsupervised Domain Adaptation (Kang et al, 2019)	I-Reply	I-1	Reply	554
<a href="https://arxiv.org/pdf/1901.00976v2.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1901.00976v2.pdf</a>	I-Reply	I-1	Reply	554
Conditional Adversarial Domain Adaptation (Long et al, 2018)	I-Reply	I-1	Reply	554
<a href="https://arxiv.org/pdf/1705.10667.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1705.10667.pdf</a>	I-Reply	I-1	Reply	554
Please reference the two papers above for the baseline abbreviations.	I-Reply	I-1	Reply	554
<sep> ‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî-‚Äî‚Äî-	I-Reply	I-1	Reply	554
Source<tab><tab>A<tab>     D<tab>W<tab>     A<tab>        D<tab>    W<tab>Average	I-Reply	I-1	Reply	554
Target<tab><tab>W<tab>     W<tab>D<tab>     D<tab>A<tab>    A	I-Reply	I-1	Reply	554
‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî-‚Äî‚Äî-	I-Reply	I-1	Reply	554
Source only<tab>68.4<tab>     96.7<tab>99.3<tab>     68.9<tab>62.5<tab>    60.7<tab>76.1	I-Reply	I-1	Reply	554
JAN<tab><tab>        85.4<tab>     97.4<tab>99.8<tab>     84.7<tab>68.6<tab>    70.0<tab>84.3	I-Reply	I-1	Reply	554
MADA<tab><tab>90.0<tab>     97.4<tab>99.6<tab>     87.8<tab>70.3<tab>    66.4<tab>85.2	I-Reply	I-1	Reply	554
GTA<tab><tab>        89.5<tab>     97.9<tab>99.8<tab>     87.7<tab>72.8<tab>    71.4<tab>86.5	I-Reply	I-1	Reply	554
CDAN+E<tab>        94.1<tab>     98.6<tab>100.0    92.9<tab>71.0<tab>    69.3<tab>87.7	I-Reply	I-1	Reply	554
CAN<tab><tab>94.5<tab>     99.1<tab>99.8<tab>     95.0<tab>78.0<tab>    77.0<tab>90.6	I-Reply	I-1	Reply	554
‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî-‚Äî‚Äî-	I-Reply	I-1	Reply	554
Ours<tab><tab>91.0<tab>     98.2<tab>99.6<tab>     90.2<tab>71.5<tab>    71.4<tab>87.0	I-Reply	I-1	Reply	554
‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî-‚Äî‚Äî-	I-Reply	I-1	Reply	554
Our results are not state-of-the-art on Office-31, but very competitive.	I-Reply	I-1	Reply	554
In addition, we note that our method is simpler than the two better performing methods, CDAN+E (Kang et al, 2019) and CAN (Long et al, 2018), and is derived from a different perspective.	I-Reply	I-1	Reply	554
<sep> <sep> For question 2 and 3, we have added qualitative comparisons in Appendix G of our latest revision (page 16).	B-Reply	B-3	Reply	554

This paper introduces an unsupervised domain adaptation method that uses self-supervised tasks to bring the two different domains closer together.	O	O	Review	554
It runs experiments on some classic benchmarks.	O	O	Review	554
<sep> <sep> My score for this paper is weakly rejected because	O	O	Review	554
<sep> (1) the concept of self-supervision is not first proposed by this paper.	B-Review	B-1	Review	554
The proposed method is not novel.	I-Review	I-1	Review	554
It introduces three simple self-supervision tasks: flip, rotation and location, and the performance is not better than previous results such as DIRT-T;	I-Review	I-1	Review	554
<sep> (2) there are 7 benchmarks in Table2, but only 2 of 7 has result on R+L+F. In the paper, it mentioned because the result is not better, but the author should still provide them.	B-Review	B-2	Review	554
<sep> <sep> (3) it emphasizes the contribution of encouraging more study of self-supervision for unsupervised domain adaptation.	B-Review	B-3	Review	554
It doesn‚Äôt provide any way for how to design self-supervision task or whether more tasks is better.	I-Review	I-3	Review	554
I think it is an interesting paper, but not enough as a conference paper, maybe a workshop paper.	I-Review	I-3	Review	554
<sep> <sep> (4) there are some classic unsupervised domain adaption benchmarks like Office Dataset, and Bing-Caltech dataset, why not run the method on them?	B-Review	B-4	Review	554
<sep> <sep> (5) In ICCV 2019, there is a paper "S4L: Self-Supervised Semi-Supervised Learning".	B-Review	B-5	Review	554
The proposed method is almost same.	I-Review	I-5	Review	554
I think the difference is this paper changes the setting and considers the unsupervised data as target domain and supervised data as source domain.	I-Review	I-5	Review	554
Thank you for your time giving us feedback.	O	O	Reply	554
Here we answer your numbered concerns.	O	O	Reply	554
<sep> <sep> 1. ‚	B-Reply	B-1	Reply	554
ÄúThe concept of self-supervision is not first proposed by this paper.	I-Reply	I-1	Reply	554
‚Äù Since being proposed in the 1990s, self-supervised learning has become a wide and vibrant field of inquiry,  with hundreds, if not thousands of papers published in respected venues.	I-Reply	I-1	Reply	554
So, we are perplexed by the statement:  is this arguing that all these papers were published in error?	I-Reply	I-1	Reply	554
‚ÄúThe proposed method is not novel.	I-Reply	I-1	Reply	554
‚Äù  Such statements are unhelpful without references to prior work.	I-Reply	I-1	Reply	554
We have stated in the introduction what we perceive to be the novelties of our method.	I-Reply	I-1	Reply	554
Please provide references to previously published papers that render our novelties invalid.	I-Reply	I-1	Reply	554
<sep> ‚ÄúPerformance is not better than previous results such as DIRT-T.‚Äù  Our results are shown in Table 2, and many of them are better than DIRT-T. Our method is also simpler and derived from a different perspective.	I-Reply	I-1	Reply	554
<sep> <sep> 2.	O	O	Reply	554
Below are the requested results for R+L+F:	B-Reply	B-2	Reply	554
‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-	I-Reply	I-2	Reply	554
Source<tab><tab>MNIST<tab><tab>MNIST<tab><tab>SVHN<tab><tab>MNIST<tab><tab>MNIST	I-Reply	I-2	Reply	554
Target<tab><tab>MNIST-M<tab>SVHN<tab><tab>MNIST<tab><tab>USPS<tab><tab>USPS	I-Reply	I-2	Reply	554
‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-	I-Reply	I-2	Reply	554
Accuracy (%)<tab>98.7<tab><tab>        63.2<tab><tab>        85.7<tab><tab>        95.8<tab><tab>        87.0	I-Reply	I-2	Reply	554
‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-	I-Reply	I-2	Reply	554
There is not much difference between these numbers and the ones for R only.	I-Reply	I-2	Reply	554
<sep> <sep> 3. ‚	B-Reply	B-3	Reply	554
Äú[The authors] do not provide any way for how to design self-supervision task‚Äù.	I-Reply	I-3	Reply	554
Please see Section 3 titled ‚Äúdesigning self-supervised tasks for adaptation‚Äù.	I-Reply	I-3	Reply	554
<sep> <sep> 4.	O	O	Reply	554
Please see results on Office-31 in our reply to R3.	B-Reply	B-4	Reply	554
<sep> <sep> 5.	O	O	Reply	554
First, please note that ICCV 2019 papers are considered concurrent work, not prior work, to ICLR 2020 (ICCV‚Äô19 happened in November, whereas deadline for ICLR was in September).	B-Reply	B-5	Reply	554
Second, S4L, which is designed for semi-supervised learning, differs from ours both algorithmically and conceptually.	I-Reply	I-5	Reply	554
We have already discussed this in the related work section in the context of semi-supervised learning methods, but to make our point clearer, here are the results for our implementation of the algorithm described in their equation (1) and (2) on MNIST -&gt; MNIST-M, where improving upon the source only (no adaptation) baseline should have been very easy:	I-Reply	I-5	Reply	554
‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî	I-Reply	I-5	Reply	554
<tab><tab><tab>        | Accuracy (%)	I-Reply	I-5	Reply	554
‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî	I-Reply	I-5	Reply	554
Source only<tab><tab>|  44.9	I-Reply	I-5	Reply	554
S4L method<tab><tab>|  56.6	I-Reply	I-5	Reply	554
Our method<tab><tab>|  98.9	I-Reply	I-5	Reply	554
‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî‚Äî-‚Äî‚Äî‚Äî	I-Reply	I-5	Reply	554
The S4L result is barely better than source only, and qualitatively different from ours i.e. the difference should not come from merely implementation details.	I-Reply	I-5	Reply	554
The most important difference between their algorithm and ours is that they train the supervised task on labeled data, and self-supervised task on unlabeled data, while we train the self-supervised task(s) simultaneously on both domains (labeled and unlabeled).	I-Reply	I-5	Reply	554
Conceptually, training the self-supervised task on both domains is critical for alignment, which is the main objective for adaptation.	I-Reply	I-5	Reply	554
Because for semi-supervised learning, the labeled and unlabeled data come from the same domain, methods for semi-supervised learning e.g. S4L do not need to consider the alignment problem.	I-Reply	I-5	Reply	554
These comments are not intended to criticize S4L, as it is solving a different problem.	I-Reply	I-5	Reply	554
In fact, theoretical analysis for semi-supervised learning [Cohen, Cozman] [Ghifary et al] suggests that training the self-supervised task on both domains is not helpful for semi-supervised learning; it is interesting to see how this picture is different for domain adaptation.	I-Reply	I-5	Reply	554
<sep> <sep> ‚ÄúI think it is an interesting paper, but not enough as a conference paper, maybe a workshop paper.	I-Reply	I-5	Reply	554
‚Äù   We are happy you found the paper interesting.	I-Reply	I-5	Reply	554
We do ask you to please reconsider your recommendation in light of the arguments presented above.	I-Reply	I-5	Reply	554
Also, as similar works using self-supervision as a tool, e.g. S4L, were published at respectable conferences instead of workshops, it seems reasonable to argue that this work, too, deserves to be accepted to ICLR.	I-Reply	I-5	Reply	554
<sep> <sep> References:	O	O	Reply	554
Cohen, I., Cozman, F.G.: Risks of semi-supervised learning: how unlabeled data can degrade performance of generative classifiers.	O	O	Reply	554
In: Semi-Supervised Learning.	O	O	Reply	554
MIT Press (2006)	O	O	Reply	554
Muhammad Ghifary, W Bastiaan Kleijn, Mengjie Zhang, David Balduzzi, and Wen Li.	O	O	Reply	554
Deep reconstruction-classification networks for unsupervised domain adaptation.	O	O	Reply	554
In European Conference on Computer Vision, pp.597‚Äì613.	O	O	Reply	554
Springer, 2016.	O	O	Reply	554

This paper presents a novel unsupervised domain adaptation framework for neural networks.	O	O	Review	554
Similarly to existing approaches, it performs adaptation by aligning representations of the source and the target domains.	O	O	Review	554
The main difference is that this alignment is achieved not through explicitly minimizing some distribution discrepancy (this usually leads to challenging minimax optimization problems).	O	O	Review	554
Instead, the authors propose to use a battery of auxiliary self-supervised learning (SSL) tasks for both domains simultaneously.	O	O	Review	554
Each task is meant to align the source and the target representations along a direction of variation relevant to that task.	O	O	Review	554
Assuming that the battery is diverse enough, optimizing the representation for all the tasks leads to matching of the distributions.	O	O	Review	554
<sep> <sep> Pros:	O	O	Review	554
+ The paper is well-written and easy to read.	O	O	Review	554
<sep> + I like the simplicity of the idea and the fact that it achieves competitive performance without any adversarial learning (which may be very tricky to deal with).	O	O	Review	554
<sep> + The paper presents a reasonable procedure for hyper-parameter tuning and early stopping which seems to work well in practice.	O	O	Review	554
<sep> <sep> Cons:	O	O	Review	554
- The paper is purely practical with no theory backing the approach.	B-Review	B-1	Review	554
As a result, the discussion of guarantees and limitations is quite brief.	I-Review	I-1	Review	554
<sep> - It‚Äôs unclear how easy it is to come up with a reasonable set of SSL tasks for a particular pair of domains.	B-Review	B-2	Review	554
It seems that it may become a serious problem when the method is applied to something other than benchmarks.	I-Review	I-2	Review	554
Table 2 reveals that there is no consistent improvement over the existing approaches which suggests that the chosen battery of SSL tasks is not universal (as the authors themselves admit).	I-Review	I-2	Review	554
On a related note, it‚Äôs a bit disappointing that the authors mention SVHN results as a failure case but never provide a way to address the issue.	I-Review	I-2	Review	554
<sep> - It would be nice to some results for the Office dataset for completeness.	B-Review	B-3	Review	554
The authors could use a pre-trained network as a starting points just like it‚Äôs done in other papers.	I-Review	I-3	Review	554
According to the last paragraph of Section 6 this experiment should be feasible.	I-Review	I-3	Review	554
<sep> <sep> Notes/questions:	O	O	Review	554
* Table 2, last column: The performance of DIRT-T seems to be better than that of the proposed method and yet the latter is highlighted and not the former.	B-Review	B-4	Review	554
<sep> <sep> Overall, I think it‚Äôs a good paper presenting a thought-provoking idea.	O	O	Review	554
In my opinion, the weakest point of the work is the lack of any (neither principled nor practical) guidance as to how to choose the set of self-supervised tasks.	B-Review	B-2	Review	554
Despite this I feel that this submission should be accepted but at the same time I‚Äôm curious to see what the authors have to say regarding the concerns I raised in my review.	O	O	Review	554
Thank you and we are happy you found our paper thought-provoking.	O	O	Reply	554
Here we address the cons you wrote:	O	O	Reply	554
1.	B-Reply	B-1	Reply	554
It is true that we have no theory backing our approach.	I-Reply	I-1	Reply	554
On the other hand, it is rarely to see any deep learning paper with theory adequate enough to give ‚Äúguarantees‚Äù for datasets we actually care about.	I-Reply	I-1	Reply	554
<sep> 2.	B-Reply	B-2	Reply	554
This connects well with the comment at the end of the review, asking us for ‚Äúguidance as to how to choose the set of self-supervised tasks.	I-Reply	I-2	Reply	554
‚Äù We have in fact given some practical guidance in the paper, which we summarize below as two necessary conditions:	I-Reply	I-2	Reply	554
- The self-supervised task is well defined and nontrivial on both domains.	I-Reply	I-2	Reply	554
This rules out the case of rotation prediction on SVHN, since as we explain in the paper, ‚Äúthe rotation head learns to look at the periphery and cheat‚Äù.	I-Reply	I-2	Reply	554
<sep> - ‚ÄúThe labels created by self-supervision should not require capturing information on the very factors where the domains are meaninglessly different.	I-Reply	I-2	Reply	554
‚Äù as said and explained in section 3.	I-Reply	I-2	Reply	554
This is rules out tasks such as colorization and autoencoder, for which it is important to learn the low-level details of the image.	I-Reply	I-2	Reply	554
<sep> These two conditions are easy to reason about in practice.	I-Reply	I-2	Reply	554
If the ‚Äúbattery of self-supervised tasks‚Äù satisfy them, there should be notable improvement on top of the source only baseline as we observe empirically, but there won‚Äôt be a guarantee.	I-Reply	I-2	Reply	554
In addition, we would like this paper to add to the toolbox of available domain adaptation methods instead of becoming the only tool.	I-Reply	I-2	Reply	554
When a good self-supervised task satisfying the two conditions cannot be found (SVHN), previous methods have provided different tools to use.	I-Reply	I-2	Reply	554
When a good self-supervised task naturally exists, our method provides a simple and effective choice.	I-Reply	I-2	Reply	554
<sep> In the end, this is a valuable question from the reviewer and we plan to be more explicit about those conditions in the next revision.	I-Reply	I-2	Reply	554
<sep> 3.	O	O	Reply	554
Please see results on Office-31 in our reply to R3.	B-Reply	B-3	Reply	554
<sep> <sep> Your notes / questions: Thank you very much for pointing out our error with the highlighting.	B-Reply	B-4	Reply	554
This is an honest typo.	I-Reply	I-4	Reply	554
In the latest revision, we have improved our results to match that of DIRT-T; the modification we made for the improved results, as well as the original results, can be found in the last paragraph of Appendix B.	I-Reply	I-4	Reply	554

## Summary	O	O	Review	866
<sep> The authors identify a synergy between the rate distortion (RD) and reinforcement learning (RL) literature.	O	O	Review	866
RD work shows how to optimise resources when capacity is limited and the authors transfer this idea to RL and posit a novel algorithm based on the Actor critic algorithm.	O	O	Review	866
In experiments this is shown to learn more quickly and transfer between similar tasks more easiliy than the conventional AC algorithm.	O	O	Review	866
<sep> <sep> This is a genuinely inciteful piece of work and may be of very significant interest to the community.	O	O	Review	866
Particuarly to those in transfer learning, heirarchical learning and other areas of RL where an adaptable rate limited policy is an advantage.	O	O	Review	866
<sep> <sep> The experiments are limited to a single domain, and ideally this would be demonstrated across more than just those examples explored.	B-Review	B-1	Review	866
However, I think that the value of the theoretical advance, and the clarity/readability of the paper warrants acceptance.	O	O	Review	866
<sep> Thank you for your review.	O	O	Reply	866
We agree that much of the strength of the current paper lies in introducing a relatively novel, and principled theoretical framework to a broad audience.	B-Reply	B-1	Reply	866
We view this work as a jumping off point for readers who have some background in rate-distortion theory, or reinforcement learning.	I-Reply	I-1	Reply	866
However, few in the machine learning community have more than passing knowledge of both.	I-Reply	I-1	Reply	866
We feel the demonstration of the approach in a small-scale environment allows for an unhurried exposition of the theory and demonstration of its behavior.	I-Reply	I-1	Reply	866
Many of the details of the algorithm can be substituted, for example utilizing deep-NNs for approximating an optimal-but-capacity-limited channel, enabling the extension to large or continuous state-spaces.	I-Reply	I-1	Reply	866
Given the recommended page limits of the ICLR proceedings, we opted for a fuller and more accessible exposition of the theoretical approach, rather than an extensive demonstration of its empirical performance.	I-Reply	I-1	Reply	866

(score raised from 6 to 7 after the rebuttal)	O	O	Review	866
The paper explores the application of the rate-distortion framework to policy learning in the reinforcement learning setting.	O	O	Review	866
In particular, a policy that maps from states to actions is considered an information theoretic channel of limited capacity.	O	O	Review	866
This viewpoint provides an interesting angle which allows modeling/learning of (computationally) bounded-rational policies.	O	O	Review	866
While capacity-limitation might intuitively seem to be a disadvantage, intriguing arguments (based on solid theoretical foundations, rooted in first principles) can be made in favor of capacity-limited systems.	O	O	Review	866
Two of the main-arguments are that capacity-limited policies should be faster to learn and be more robust, i.e. generalize better.	O	O	Review	866
After thoroughly introducing these arguments on a less formal level and putting them into perspective with regard to reinforcement learning and related work in the literature, the paper demonstrates these properties in a toy grid-world example.	O	O	Review	866
When compared against a vanilla actor-critic (AC) algorithm, the capacity-limited version is shown to converge faster and reach better final policies.	O	O	Review	866
The paper then extends the basic version of the algorithm, which requires knowledge of the optimal value function, towards simultaneously learning the value function.	O	O	Review	866
While any theoretical guarantees are lost, the empirical results are still in line with the theoretical benefits, outperforming vanilla AC and producing better results in previously unencountered variations of the grid-world environment.	O	O	Review	866
<sep> <sep> The paper is very well written and the toy-examples illustrate the theoretical advantages in a very nice and intuitively understandable way.	O	O	Review	866
The topic of modeling capacity-limited RL agents and exploring how capacity-limitation is an advantage, rather than a ‚Äúbug‚Äù is very timely and important.	O	O	Review	866
In particular, rate-distortion theory might provide key-insights into building agents that generalize well, which is among the major open problems in reinforcement learning.	O	O	Review	866
The paper is thus very timely and highly relevant to a broad audience.	O	O	Review	866
<sep> <sep> The main weakness of the paper is that it is of quite limited novelty and that the brute-force approach towards using Blahut-Arimoto in RL is unlikely to scale to large, complex state-/action-spaces without major additional work.	B-Review	B-1	Review	866
Continuous state-/action-spaces are in principle covered by the theory, but they come with additional caveats and subtleties (I appreciate the authors using discrete notation with sums instead of integrals).	I-Review	I-1	Review	866
Additionally, when simultaneously learning the value function (in the online setting), any guarantees about Blahut-Arimoto convergence are lost.	B-Review	B-2	Review	866
However, solving either of these issues is hard and many attempts have been made in the communications community.	I-Review	I-2	Review	866
Despite these weaknesses I argue for accepting and presenting the paper at the conference for the following reasons:	O	O	Review	866
- modelling capacity-limited agents via ideas from rate-distortion theory (which is very closely related to free-energy optimization, such as ELBO maximization, Bayesian inference and the MDL principle) is an underrated topic in reinforcement learning.	B-Review	B-3	Review	866
On a conceptual level, the strong idea is that moving away from strict optimization and infinite-capacity systems is not a shortcoming but can actually help building agents that perform better and generalize better.	I-Review	I-3	Review	866
This is not a well established idea in the community.	I-Review	I-3	Review	866
The paper does a good job at introducing the general idea, illustrating it intuitively with toy examples and pointing out relevant literature.	I-Review	I-3	Review	866
<sep> - Simultaneously learning the value function is necessary in the RL setting, but breaks quite a bit of the theory.	B-Review	B-4	Review	866
However, very similar ideas seem to work quite well empirically in other settings, such as for instance ELBO maximization in VAEs, where the ‚Äúvalue function‚Äù is the log-likelihood (under the decoder), which is learned simultaneously while learning a ‚Äúpolicy‚Äù (the encoder) under capacity limitation (the KL term).	I-Review	I-4	Review	866
Similar arguments can be made for modern InfoBottleneck-style objectives in deep learning.	I-Review	I-4	Review	866
Based on this empirical observation, it is not unlikely that simultaneous learning of the value function works reasonably well without catastrophically collapsing in other settings and tasks.	I-Review	I-4	Review	866
<sep> - While achieving a solution that strictly lies on the rate-distortion curve might be crucial in communications, it might be of lesser significance for building RL agents that generalize well - slight sub-optimalities (solutions that lie off the RD curve) should still yield interesting agents.	B-Review	B-5	Review	866
Therefore, losing theoretical guarantees might be less severe for simply exploring how much the idea can be scaled up empirically.	I-Review	I-5	Review	866
<sep> <sep> Minor issues:	O	O	Review	866
1) While the paper, strictly speaking, introduces a novel algorithm and the Bellman loss function (which requires knowledge of the optimal value function), I think that the main contribution is a clear and well-focused introduction of rate-distortion theory in the context of RL, including very illustrative toy examples.	B-Review	B-6	Review	866
I do consider this an important contribution.	I-Review	I-6	Review	866
<sep> <sep> 2) Transfer to novel environments.	B-Review	B-7	Review	866
The final example (Fig.4) does show that the capacity limited agent performs better in novel environments.	I-Review	I-7	Review	866
However, I‚Äôm not entirely convinced that this demonstrates ‚Äúsuperior transfer to novel environments‚Äù (from the abstract).	I-Review	I-7	Review	866
While the latter might very well arise from capacity-limitations, I think that in the example in the paper there is not too much transfer going on, but the capacity-limited agent simply has a more stochastic policy which helps if unknown walls are in the way.	I-Review	I-7	Review	866
After all, the average accumulated reward of the capacity limited agent does also decrease significantly in the novel environment - it simply does a slightly better random walk than the AC (correct me if I‚Äôm wrong, of course).	I-Review	I-7	Review	866
On page 7, last paragraph this is phrased as: ‚Äúagents retain knowledge of exploratory actions‚Äù.	I-Review	I-7	Review	866
In my opinion this wording is a bit too strong to simply describe increased stochasticity.	I-Review	I-7	Review	866
<sep> <sep> 3) Since the paper does provide a good overview over the literature, I think it would help to mention that the current main approach towards generalizing (deep) RL is via hierarchical RL (options framework, etc) and provide a good reference.	B-Review	B-8	Review	866
<sep> <sep> 4) At the very end of the intro you might also want to mention that rate-distortion has been used before in the context of decision-making (not RL), for instance under the term rational inattention.	B-Review	B-9	Review	866
<sep> <sep> 5) Page 5, last paragraph: the paper mentions that one Blahut-Arimoto iteration is enough.	B-Review	B-10	Review	866
This is an empirical observation, justified by the toy experiments.	I-Review	I-10	Review	866
However, the wording sounds like this is a generally known fact.	I-Review	I-10	Review	866
Please rephrase to emphasize that this must not necessarily hold true in general and that convergence behavior might crucially depend on this.	I-Review	I-10	Review	866
<sep> <sep> 6) It would be good to give readers some guidance towards choosing beta if doing an exhaustive grid-search is infeasible.	B-Review	B-11	Review	866
I am aware that there is no good general rule or recipe, but perhaps something can be added to the discussion (even if it is just mentioning that there is no good heuristic, etc. -	I-Review	I-11	Review	866
however, there should be plenty of research in communications that deals with estimating the RD curve from as few points as possible).	I-Review	I-11	Review	866
<sep> <sep> 7) Please consider adding this reference - it has a very similar objective function (but for navigating towards multiple goals) and is very much in line with some of the theoretical arguments.	B-Review	B-12	Review	866
<sep> Informational Constraints-Driven Organization in Goal-Directed Behavior - Van Dijk, Polani, 2013.	O	O	Review	866
<sep> <sep> <sep> Thank you for your thoughtful and thorough review.	O	O	Reply	866
Your review identified a number of strengths and weaknesses, but concluded that the former outweigh the latter, and that the work is "very timely and highly relevant to a broad audience".	O	O	Reply	866
We strongly agree with this conclusion.	O	O	Reply	866
<sep> <sep> More specifically, in your review, you identified two main weaknesses of the current paper: "[A] it is of quite limited novelty and [B] that the brute-force approach towards using Blahut-Arimoto in RL is unlikely to scale to large, complex state-/action-spaces without major additional work".	O	O	Reply	866
<sep> <sep> Regarding [A], we respectfully disagree that the paper is of limited novelty.	B-Reply	B-1	Reply	866
Although there are a small handful of papers that have previously explored information-theoretic limits in RL (cited in our manuscript), this topic is, comparatively speaking, unexplored terrain.	I-Reply	I-1	Reply	866
Regarding the specifics of the novelty of our approach, we feel confident that our work is the first to propose an online, model-free, capacity-limited RL algorithm, and empirically demonstrate its performance against standard (non-capacity-limited) approaches.	I-Reply	I-1	Reply	866
<sep> <sep> Regarding [B], we agree that substantial additional work would be needed to extend the current algorithm to large state/action spaces.	B-Reply	B-2	Reply	866
The scope of the work involved prevents us from incorporating this into the manuscript within the author response period.	I-Reply	I-2	Reply	866
However, this should not imply that the approach cannot be scaled up.	I-Reply	I-2	Reply	866
<sep> <sep> Our demonstration of the algorithm utilized a tabular representation of policy and value functions.	B-Reply	B-4	Reply	866
Indeed, part of the value of this approach is to demonstrate that a tabular state representation does not preclude rational generalization.	I-Reply	I-4	Reply	866
But there is nothing intrinsic to RD, RL, or their combination, that requires a tabular representation.	I-Reply	I-4	Reply	866
Indeed, any standard function approximation scheme could be substituted into the current algorithm, from tile coding to deep NNs.	I-Reply	I-4	Reply	866
We envision a policy represented as a neural network, with an information rate constraint placed on the training of the network.	I-Reply	I-4	Reply	866
In other words, the network is trained to approximate an optimal capacity-limited channel (in the rate-distortion sense).	I-Reply	I-4	Reply	866
In standard practice, overfitting is prevented (if it is considered at all) via careful design of the network architecture.	I-Reply	I-4	Reply	866
In contrast, rate-distortion theory adds principled regularization that works regardless of the network architcture.	I-Reply	I-4	Reply	866
While implementing and fully testing this idea would require substantial additional work, we feel that such an effort would be a major separate contribution, and does not diminish the value of the current work.	I-Reply	I-4	Reply	866
<sep> <sep> Your review also identified a number of minor issues, here we briefly summarize how the manuscript has been revised in response to each of these points.	O	O	Reply	866
<sep> <sep> 1) Thank you for pointing this out.	B-Reply	B-6	Reply	866
We have made minor revisions to the manuscript to underscore this aspect of the paper's contribution.	I-Reply	I-6	Reply	866
<sep> 2) We agree that the demonstration of transfer to modified maze environments is a fairly limited type of generalization.	B-Reply	B-7	Reply	866
We have moderated some of the language used to describe this type of "generalization".	I-Reply	I-7	Reply	866
In effect it is a type of regularization on the agent's policy.	I-Reply	I-7	Reply	866
However, it is not quite the same as enforcing a more stochastic policy.	I-Reply	I-7	Reply	866
Capacity limits can actually *increase* the determinism of behavior (for example, a policy that takes the same deterministic action regardless of the state has an information rate of zero).	I-Reply	I-7	Reply	866
The actual balance of determinism and stochasticity learned by the agent represents the (approximate) optimal achievement of utility with an information constraint.	I-Reply	I-7	Reply	866
<sep> 3) Thank you for the suggestion, we have added a reference to point to related work in hierarchical RL.	B-Reply	B-8	Reply	866
<sep> 4) We have added a reference to the closely related "rational inattention" framework.	B-Reply	B-9	Reply	866
<sep> 5) Thank you, we clarify that using one Blahut iteration is not motivated by any strong theoretical basis.	B-Reply	B-10	Reply	866
<sep> 6) We added a brief discussion regarding the choice of the beta parameter to address this.	B-Reply	B-11	Reply	866
<sep> 7) Thank you for pointing out this citation, which we were previously unaware of.	B-Reply	B-12	Reply	866
We have incorporated it into the manuscript.	I-Reply	I-12	Reply	866

Disclosure: I reviewed this paper for a different conference but have read the new manuscript and noted the changes.	O	O	Review	866
<sep> <sep> Summary:	O	O	Review	866
The paper considers a very novel (but important) RL context where the agent has a constrained amount of information for representing a policy.	O	O	Review	866
The authors use techniques from rate-distortion theory to generate a clever Bellman loss function that can be used (1) in a context where V*(s) is already known, and more importantly (2) with an actor-critic architecture (CL-AC) where the value function is being learned online.	O	O	Review	866
CL-AC is shown to actually achieve higher converged and cumulative rewards than AC in many grid world domains and is shown to be advantageous in a transfer learning setting as well.	O	O	Review	866
<sep> <sep> Review:	O	O	Review	866
<sep> The ideas in the paper are very well described and laid out.	O	O	Review	866
The experiments are on grid worlds but for such a novel problem like this I think they are at the right level because they allow the reader to understand the results.	O	O	Review	866
The empirical results are compelling, but I have a strong technical concern about the convergence issue noted by the authors (which was also communicated to the authors in a previous conference‚Äôs review session).	O	O	Review	866
<sep> My main concern is, as the authors noted, the required state occupation probability p(s) for RDT is approximated in a way that could lead to bad behavior in the RL algorithm.	B-Review	B-1	Review	866
What we‚Äôre seeing here is the application of an RDT procedure that was designed for a static distribution being applied to a dynamic distribution of states (that can change based on the policy).	I-Review	I-1	Review	866
In RL, there is no guarantee that the previous occupation probabilities have anything to do with the current policy‚Äôs induced distribution.	I-Review	I-1	Review	866
In a hallway world with a decent reward down the left and a bigger reward to the right, an algorithm might start off by going down the left side several times, making the probabilities of states on the right 0.	I-Review	I-1	Review	866
If I am reading the algorithm right, the states on the right are going to be essentially dismissed as unlikely, and the ‚Äúgo right‚Äù action (which is optimal) will likely be compressed out, since the states it should be used in are considered unlikely.	I-Review	I-1	Review	866
More succinctly, early trajectories will bias p(s) and cause the algorithm to essentially want to optimize the policy for that distribution, likely causing it to stay in that distribution.	I-Review	I-1	Review	866
Even more dangerously, there may be cases where this could cause the algorithm to thrash between policies as p(s) oscillates between different parts of the state space.	I-Review	I-1	Review	866
<sep> In order to improve this paper and make it suitable for publication, the authors should at least empirically demonstrate how different state occupation probability approximations affect the algorithm.	B-Review	B-2	Review	866
A good example is the trace-decay probabilities mentioned (but not implemented) in the paper.	I-Review	I-2	Review	866
If the paper compared that approach to the current approach, and showed an environment where one or both approaches failed to act correctly, that would complete the scientific result.	I-Review	I-2	Review	866
Right now, only one approximation is demonstrated, and as detailed above, its behavior is suspect.	I-Review	I-2	Review	866
<sep> <sep> While most of the empirical results are well explained, the behavior in Figure 2B, where CL-AC is outperforming standard AC remain unclear.	B-Review	B-3	Review	866
I understand that in 2A (avg.	I-Review	I-3	Review	866
cumulative reward), CL-AC may be inducing a more efficient exploration policy and therefore the rewards during learning will be better.	I-Review	I-3	Review	866
But in 2B, we are just looking at the final policy.	I-Review	I-3	Review	866
Was standard AC not able to find the optimal policy after 100 episodes?	I-Review	I-3	Review	866
<sep> The results in the transfer learning context (Figure 3) are well done and produce a very interesting curve.	B-Review	B-4	Review	866
<sep> Reference 9 appears to only be available as an arXiv pre-print.	B-Review	B-5	Review	866
Papers that have not been properly vetted by peer review should not be cited in an ICLR paper unless they are extremely necessary, which this does not appear to be.	I-Review	I-5	Review	866
<sep> <sep> <sep> Typo: Page 6 ‚Äì sate -> state	B-Review	B-6	Review	866
<sep> <sep> <sep> Thank you for your thorough review.	O	O	Reply	866
We greatly appreciate your time and feedback on this work.	O	O	Reply	866
We agree that the dynamic nature of learning implies that the simple tally approach explored here does not accurately represent the state occupancy distribution of the existing policy.	B-Reply	B-1	Reply	866
We are currently exploring the implications of this fact, and applying an approach that uses a trace decay associated with each state.	I-Reply	I-1	Reply	866
We recognize your concern and the possibility that divergence may occur between the learned policy and state distribution.	I-Reply	I-1	Reply	866
To minimize this risk, we suggest that the approximated state distribution should change slowly relative to the policy, for example by using state eligibility traces with a slow decay rate or decaying the state distributions once per episode rather than once per every action selection.	I-Reply	I-1	Reply	866
A discussion of these issues has been added to the revised version of the paper.	I-Reply	I-1	Reply	866
<sep> <sep> Although these methods offer a great deal of efficiency and flexibility, we agree that at present we can offer no guarantees of convergence, particularly when extending the current algorithm to large state/action spaces.	B-Reply	B-1	Reply	866
Notably however, most guarantees for convergence in RL in general apply only to very limited circumstances, such as the tabular-based cases of TD algorithm methods (Sutton & Barto, 2018, p. 196).	I-Reply	I-1	Reply	866
As cautioned by Sutton & Barto (2018) convergence using stochastic approximation methods is not guaranteed unless restrictive conditions are met, such as infinite exploration or sufficiently small learning rates.	I-Reply	I-1	Reply	866
Most ‚Äúreal world‚Äù algorithms based on Deep-RL also lack convergence guarantees, especially when off-policy, nonlinear function approximation, and bootstrapping methods are combined in one RL algorithm, leading to the ‚Äúdeadly triad‚Äù issue (Sutton & Barto, 2018,  p. 249).	I-Reply	I-1	Reply	866
Of course, the theoretical possibility of divergence is less concerning in the face of empirical success.	I-Reply	I-1	Reply	866
As we are developing a relatively novel approach within RL, we believe the first step is to demonstrate the algorithm's behavior in small-scale setting.	I-Reply	I-1	Reply	866
Our future work seeks to extend this work to more complex learning domains.	I-Reply	I-1	Reply	866

This paper presents a generative sequence model based on the dilated CNN	O	O	Review	346
popularized in models such as WaveNet.	O	O	Review	346
Inference is done via a hierarchical	O	O	Review	346
variational approach based on the Variational Autoencoder (VAE).	O	O	Review	346
While VAE	O	O	Review	346
approach has previously been applied to sequence modeling (I believe the	O	O	Review	346
earliest being the VRNN of Chung et al (2015)), the innovation where is the	O	O	Review	346
integration of a causal, dilated CNN in place of the more typical recurrent	O	O	Review	346
neural network.	O	O	Review	346
<sep> <sep> The potential advantages of the use of the CNN in place of	O	O	Review	346
RNN is (1) faster training (through exploitation of parallel computing across	O	O	Review	346
time-steps), and (2) potentially (arguably) better model performance.	O	O	Review	346
This	O	O	Review	346
second point is argued from the empirical results shown in the	O	O	Review	346
literature.	O	O	Review	346
The disadvantage of the CNN approach presented here is that	B-Review	B-1	Review	346
these models still need to generate one sample at a time and since they are	I-Review	I-1	Review	346
typically much deeper than the RNNs, sample generation can be quite a bit	I-Review	I-1	Review	346
slower.	I-Review	I-1	Review	346
<sep> <sep> Novelty / Impact: This paper takes an existing model architecture (the	O	O	Review	346
causal, dilated CNN) and applies it in the context of a variational	O	O	Review	346
approach to sequence modeling.	B-Review	B-2	Review	346
It's not clear to me that there are any	I-Review	I-2	Review	346
significant challenges that the authors overcame in reaching the proposed	I-Review	I-2	Review	346
method.	I-Review	I-2	Review	346
That said, it certainly useful for the community to know how the	I-Review	I-2	Review	346
model performs.	I-Review	I-2	Review	346
<sep> <sep> Writing: Overall the writing is fairly good though I felt that the model	B-Review	B-3	Review	346
description could be made more clear by some streamlining -- with a single	I-Review	I-3	Review	346
pass through the generative model, inference model and learning.	I-Review	I-3	Review	346
<sep> <sep> Experiments: The experiments demonstrate some evidence of the superiority	O	O	Review	346
of this model structure over existing causal, RNN-based models.	O	O	Review	346
One point	O	O	Review	346
that can be drawn from the results is that a dense architecture that uses multiple levels of the	O	O	Review	346
latent variable hierarchy directly to compute the data likelihood is	O	O	Review	346
quite effective.	O	O	Review	346
This observation doesn't really bear on the central message	B-Review	B-4	Review	346
of the paper regarding the use of causal, dilated CNNs.	I-Review	I-4	Review	346
<sep> <sep> The evidence lower-bound of the STCN-dense model on MNIST is so good (low)	O	O	Review	346
that it is rather suspicious.	O	O	Review	346
There are many ways to get a deceptively good	B-Review	B-5	Review	346
result in this task, and I wonder if all due care what taken.	I-Review	I-5	Review	346
In	I-Review	I-5	Review	346
particular, was the binarization of the MNIST training samples fixed in	I-Review	I-5	Review	346
advance (as is standard) or were they re-binarized throughout training?	I-Review	I-5	Review	346
<sep> <sep> Detailed comments:	O	O	Review	346
- The authors state "In contrast to related architectures (e.g. (Gulrajani et	B-Review	B-6	Review	346
al, 2016; Sonderby et al 2016)), the latent variables at the upper layers	I-Review	I-6	Review	346
capture information at long-range time scales" I believe that this is	I-Review	I-6	Review	346
incorrect in that the model proposed in at least Gulrajani et al also	I-Review	I-6	Review	346
<sep> - It also seems that there is an error in Figure 1 (left).	B-Review	B-7	Review	346
I don't think	I-Review	I-7	Review	346
there should be an arrow between z^{2}_{t,q} and z^{1}_{t,p}. The presence	I-Review	I-7	Review	346
of this link implies that the prior at time t would depend -- through	I-Review	I-7	Review	346
higher layers -- on the observation at t. This would no longer be a prior	I-Review	I-7	Review	346
at that point.	I-Review	I-7	Review	346
By extension you would also have a chain of dependencies	I-Review	I-7	Review	346
from future observations to past observations.	I-Review	I-7	Review	346
It seems like this issue is	I-Review	I-7	Review	346
isolated to this figure as the equations and the model descriptions are	I-Review	I-7	Review	346
consistent with an interpretation of the model without this arrow (and	I-Review	I-7	Review	346
including an arrow between z^{2}_{t,p} and z^{1}_{t,p}.	I-Review	I-7	Review	346
<sep> - The term "kla" appears in table 1, but it seems that it is otherwise not	B-Review	B-8	Review	346
defined.	I-Review	I-8	Review	346
I think this is the same term and meaning that appears in Goyal et	I-Review	I-8	Review	346
al. (	I-Review	I-8	Review	346
2017), but it should obviously be defined here.	I-Review	I-8	Review	346
<sep> <sep> To better understand if the experimental improvements shown in our paper only stem from the hierarchical latent space or whether the synergy between the dilated CNNs and latent variable hierarchy is important, we ran additional experiments (as suggested by R1).	B-Reply	B-1	Reply	346
We replaced the deterministic TCN blocks with LSTM cells and kept the latent structure intact, dubbed RNNLadder.	I-Reply	I-1	Reply	346
We used TIMIT and IAM-OnDB for speech and handwriting datasets.	I-Reply	I-1	Reply	346
The log-likelihood performance measured by ELBO is provided below:	I-Reply	I-1	Reply	346
<sep> =======================================================	I-Reply	I-1	Reply	346
TIMIT          IAM-OnDB	I-Reply	I-1	Reply	346
=======================================================	I-Reply	I-1	Reply	346
25x256-LadderRNN (Normal)                         28207             1305	I-Reply	I-1	Reply	346
25x256-LadderRNN-dense (Normal)             27413             1278	I-Reply	I-1	Reply	346
=======================================================	I-Reply	I-1	Reply	346
25x256-LadderRNN (GMM)                             24839             1381	I-Reply	I-1	Reply	346
25x256-LadderRNN-dense (GMM)                 26240             1377	I-Reply	I-1	Reply	346
=======================================================	I-Reply	I-1	Reply	346
5x512-LadderRNN (Normal)                           49770             1299	I-Reply	I-1	Reply	346
5x512-LadderRNN-dense (Normal)               48612             1374	I-Reply	I-1	Reply	346
=======================================================	I-Reply	I-1	Reply	346
5x512-LadderRNN (GMM)                               47179             1359	I-Reply	I-1	Reply	346
5x512-LadderRNN-dense (GMM)                   50113             1581	I-Reply	I-1	Reply	346
=======================================================	I-Reply	I-1	Reply	346
25x256-STCN (Normal)                                    64913             1327	I-Reply	I-1	Reply	346
25x256-STCN-dense (Normal)                        70294             1729	I-Reply	I-1	Reply	346
=======================================================	I-Reply	I-1	Reply	346
25x256-STCN (GMM)                                        69195             1339	I-Reply	I-1	Reply	346
25x256-STCN-dense (GMM)                            71386             1796	I-Reply	I-1	Reply	346
=======================================================	I-Reply	I-1	Reply	346
<sep> Models in the table have similar number of trainable parameters.	B-Reply	B-5	Reply	346
The most direct translation of the the STCN architecture into an RNN counterpart has 25 stacked LSTM cells with 256 units each.	I-Reply	I-5	Reply	346
Similar to STCN, we use 5 stochastic layers.	I-Reply	I-5	Reply	346
Please note that stacking this many LSTM cells is unusual and resulted in instabilities during training.	I-Reply	I-5	Reply	346
The performance is similar to vanilla RNNs.	I-Reply	I-5	Reply	346
Hence, we didn‚Äôt observe a pattern of improvement with densely connected latent variables.	I-Reply	I-5	Reply	346
The second RNNLadder configuration uses 5 stacked LSTM cells with 512 units and a one-to-one mapping with the stochastic layers.	I-Reply	I-5	Reply	346
<sep> <sep> This experiments show that the modular structure of our latent variable design does allow for the usage of different building blocks.	I-Reply	I-5	Reply	346
Even when attached to LSTM cells, it boosts the log-likelihood performance (see 5x512-LadderRNN), in particular when used with dense connections.	I-Reply	I-5	Reply	346
However, the empirical results suggest that the densely connected latent hierarchy interacts particularly well with dilated CNNs.	I-Reply	I-5	Reply	346
We believe this is due to the hierarchical nature in both sides of the architecture.	I-Reply	I-5	Reply	346
On both datasets STCN models achieved the best performance and presented significant improvements with the dense connections.	I-Reply	I-5	Reply	346
This supports our contribution of a latent variable hierarchy, which models different aspects of information from the input time-series.	I-Reply	I-5	Reply	346

This paper introduces a new stochastic neural network architecture for sequence modeling.	O	O	Review	346
The model as depicted in figure 2 has a ladder-like sequence of deterministic convolutions bottom-up and stochastic Gaussian units top-down.	O	O	Review	346
<sep> <sep> I'm afraid I have a handful of questions about aspects of the architecture that I found confusing.	O	O	Review	346
I have a difficult time relating my understanding of the architecture described in figure 2 with the architecture shown in figure 1 and the description of the wavenet building blocks.	B-Review	B-2	Review	346
My understanding of wavenet matches what is shown in the left of figure 1: the convolution layers d_t^l depend on the convolutional layers lower-down in the model, thus with each unit d^l having dependence which reaches further and further back in time as l increases.	I-Review	I-2	Review	346
I don't understand how to reconcile this with the computation graph in figure 2, which proposes a model which is Markov!	I-Review	I-2	Review	346
In figure 2, each d_{t-1}^l depends only on on the other d_{t-1} units and the value of x_{t-1}, which then (in the left diagram of figure 2) generate the following x_t, via the z_t^l.	I-Review	I-2	Review	346
Where did the dilated convolutions go‚Ä¶?	I-Review	I-2	Review	346
I thought at first this was just a simplification for the figure, but then in equation (4), there is d_t^l = Conv^{(l)}(d_t^{l-1}).	I-Review	I-2	Review	346
Shouldn't this also depend on d_{t-1}^{l-1}‚Ä¶?	I-Review	I-2	Review	346
or, where does the temporal information otherwise enter at all?	I-Review	I-2	Review	346
The only indication I could find is in equation (13), which has a hidden unit defined as d_t^1 = Conv^{(1)}(x_{1:t}).	I-Review	I-2	Review	346
<sep> <sep> Adding to my confusion, perhaps, is the way that the "inference network" and "prior" are described as separate models, but sharing parameters.	B-Review	B-3	Review	346
It seems that, aside from the initial timesteps, there doesn't need to be any particular prior or inference network at all: there is simply a transition model from x_{t-1} to x_{t}, which would correspond to the Markov operator shown in the left and middle sections of figure 2.	I-Review	I-3	Review	346
Why would you ever need the right third of figure 2?	I-Review	I-3	Review	346
This is a model that estimates z_t given x_t.	I-Review	I-3	Review	346
But, aside from at time 0, we already have a value x_{t-1}, and a model which we can use to estimate z_t  given x_{t-1}‚Ä¶!	I-Review	I-3	Review	346
<sep> <sep> What are the top-to-bottom functions f^{(l)} and f^{(o)}?	B-Review	B-4	Review	346
Are these MLPs?	I-Review	I-4	Review	346
<sep> <sep> I also was confused in the experiments by the >= and <= on the reported numbers.	B-Review	B-5	Review	346
For example, in table 2, the text describes the values displayed as log-likelihoods, in which case the ELBO represents a lower bound.	I-Review	I-5	Review	346
However, in that case, why is the bolded value the *lowest* log-likelihood?	I-Review	I-5	Review	346
That would be the worst model, not the best ‚Äî does table 2 actually show negative log-likelihoods, then?	I-Review	I-5	Review	346
In which case, though, the numbers from the ELBO should be upper bounds, and the >= should be <=.	I-Review	I-5	Review	346
Looking at figure 4, it seems like visually the STCN and VRNN have very good reconstructions, but the STCN-dense has visual artifacts; this would correspond with the numbers in table 2 being log-likelihoods (not negative), in which case I am confused only by the choice of which model to bold.	I-Review	I-5	Review	346
<sep> <sep> <sep> <sep> UPDATE:	O	O	Review	346
<sep> Thanks for the clarifications and edits.	O	O	Review	346
FWIW I still find the depiction of the architecture in Figure 2 to be incredibly misleading, as well as the decision to omit dependencies from the distributions p and q at the top of page 5, as well as the use in table 3 of "ELBO" to refer to a *negative* log likelihood.	B-Review	B-1	Review	346
<sep> <sep> If it is advised by the reviewer, we would be glad to improve Figure 2.	B-Reply	B-2	Reply	346
We aimed to visualize dense connections and highlight the difference between STCN and STCN-dense models in Figure 2 as a graphical model.	I-Reply	I-2	Reply	346
Figure 5 (in appendix section) could be used as a replacement of Figure 2.	I-Reply	I-2	Reply	346
<sep> <sep> ‚Äú... decision to omit dependencies from the distributions p and q at the top of page 5...‚Äù this is because we don‚Äôt follow standard conditioning procedure.	B-Reply	B-1	Reply	346
In other words, the top-most layer is only conditioned on d_t^L while the lower layers (l+1) depend on d_t^l and z_t^l.	I-Reply	I-1	Reply	346
<sep> <sep> We will update Table 3 to the same convention used in other tables, i.e., NLL measured by ELBO.	I-Reply	I-1	Reply	346

The focus on novelty (mentioned in both the abstract, and conclusion as a direct claim) in the presentation hurts the paper overall.	O	O	Review	346
Without stronger comparison to other closely related work, and lack of citation to several closely related models, the claim of novelty isn't defined well enough to be useful.	B-Review	B-1	Review	346
Describing what parts of this model are novel compared to e.g. Stochastic WaveNet or the conditional dilated convolutional decoder of "Improved VAE for Text ..." (linked below, among many others) would help strengthen the novelty claim, if the claim of novelty is needed or useful at all.	I-Review	I-1	Review	346
Stochastic WaveNet in particular seems very closely related to this work, as does PixelVAE.	I-Review	I-1	Review	346
In addition, use of autoregressive models conditioned on (non-variational, in some sense) latents have been shown in both VQ-VAE and ADA among others, so a discussion would help clarify the novelty claim.	I-Review	I-1	Review	346
<sep> <sep> Empirical results are strong, though (related to the novelty issue) there should be greater comparison both quantitatively and qualitatively to further work.	B-Review	B-4	Review	346
In particular, many of the papers linked below show better empirical results on the same datasets.	I-Review	I-4	Review	346
Though the results are not always directly comparable, a discussion of *why* would be useful - similar to how Z-forcing was included.	I-Review	I-4	Review	346
<sep> <sep> In the qualitative analysis, it would be good to see a more zoomed out view of the text (as in VRNN), since one of the implicit claims of the improvement from dense STCN is improved global coherence by direct connection to the "global latents".	B-Review	B-2	Review	346
As it stands now the text samples are a bit too local to really tell.	I-Review	I-2	Review	346
In addition, the VRNN samples look quite a bit different than what the authors present in their work - what implementation was used for the VRNN samples (they don't appear to be clips from the original paper)?	I-Review	I-2	Review	346
<sep> <sep> On the MNIST setting, there are many missing numbers in the table from related references (some included below), and the >= 60.25 number seems so surprising as to be (possibly) incorrect - more in-depth analysis of this particular result is needed.	B-Review	B-3	Review	346
Overall the MNIST result needs more description and relation to other work, for both sequential and non-sequential models.	I-Review	I-3	Review	346
<sep> <sep> The writing is well-done overall, and the presented method and diagrams are clear.	O	O	Review	346
My primary concern is in relation to related work, clarification of the novelty claim, and more comparison to existing methods in the results tables.	O	O	Review	346
<sep> <sep> Variational Bi-LSTM <a href="https://arxiv.org/abs/1711.05717" target="_blank" rel="nofollow">https://arxiv.org/abs/1711.05717</a>	O	O	Review	346
<sep> Stochastic WaveNet <a href="https://arxiv.org/abs/1806.06116" target="_blank" rel="nofollow">https://arxiv.org/abs/1806.06116</a>	O	O	Review	346
<sep> PixelVAE <a href="https://arxiv.org/abs/1611.05013" target="_blank" rel="nofollow">https://arxiv.org/abs/1611.05013</a>	O	O	Review	346
<sep> Filtering Variational Objectives <a href="https://github.com/tensorflow/models/tree/master/research/fivo" target="_blank" rel="nofollow">https://github.com/tensorflow/models/tree/master/research/fivo</a>	O	O	Review	346
<sep> Improved Variational Autoencoders for Text Modeling using Dilated Convolutions <a href="https://arxiv.org/abs/1702.08139" target="_blank" rel="nofollow">https://arxiv.org/abs/1702.08139</a>	O	O	Review	346
<sep> Temporal Sigmoid Belief Networks for Sequential Modeling <a href="http://papers.nips.cc/paper/5655-deep-temporal-sigmoid-belief-networks-for-sequence-modeling" target="_blank" rel="nofollow">http://papers.nips.cc/paper/5655-deep-temporal-sigmoid-belief-networks-for-sequence-modeling</a>	O	O	Review	346
<sep> Neural Discrete Representation Learning (VQ-VAE) <a href="https://arxiv.org/abs/1711.00937" target="_blank" rel="nofollow">https://arxiv.org/abs/1711.00937</a>	O	O	Review	346
<sep> The challenge of realistic music generation: modelling raw audio at scale (ADA) <a href="https://arxiv.org/abs/1806.10474" target="_blank" rel="nofollow">https://arxiv.org/abs/1806.10474</a>	O	O	Review	346
<sep> Learning hierarchical features from Generative Models <a href="https://arxiv.org/abs/1702.08396" target="_blank" rel="nofollow">https://arxiv.org/abs/1702.08396</a>	O	O	Review	346
<sep> Avoiding Latent Variable Collapse with Generative Skip Models <a href="https://arxiv.org/abs/1807.04863" target="_blank" rel="nofollow">https://arxiv.org/abs/1807.04863</a>	O	O	Review	346
<sep> EDIT: Updated score after second revisions and author responses	O	O	Review	346
***Missing citations and novelty claim	O	O	Reply	346
We thank the reviewer for useful pointers to additional related papers.	B-Reply	B-1	Reply	346
In the revised version, we added a more complete related work section.	I-Reply	I-1	Reply	346
In particular, we discuss the most closely related Stochastic Wavenet paper in detail.	I-Reply	I-1	Reply	346
While SWaveNet and ours combine TCNs with stochastic variables there are important differences in how this is achieved.	I-Reply	I-1	Reply	346
Furthermore, we show that these design choices have implications in terms of modelling power and our architecture outperforms SWaveNet despite not having access to future information.	I-Reply	I-1	Reply	346
Furthermore, we provide log-likelihood results from Variational Bi-LSTM and Stochastic Wavenet are inserted into the result table.	I-Reply	I-1	Reply	346
In order to provide more evidence, we also include experiments on the Blizzard dataset.	I-Reply	I-1	Reply	346
<sep> <sep> We would like to emphasize that the main difference between our model and the models with autoregressive decoders (i.e., PixelVAE, Improved Variational Autoencoders for Text Modeling using Dilated Convolutions) is the sequential structure of our latent space.	B-Reply	B-1	Reply	346
For every timestep x_t we have a corresponding latent variable z_t, similar to stochastic RNNs, which helps modeling the uncertainty in sequence data.	I-Reply	I-1	Reply	346
We aim to combine TCNs with a powerful latent variable structure to better model sequence data rather than learning disentangled or interpretable representations.	I-Reply	I-1	Reply	346
The updated results show that our design successfully preserves the modeling capacity of TCNs and representation power of latent variables.	I-Reply	I-1	Reply	346
<sep> <sep> *** Handwriting sample figure.	O	O	Reply	346
<sep> In order to make a direct comparison, we include a new figure (similar to VRNN) comparing generated handwriting samples of VRNN, Stochastic Wavenet and STCN-dense.	B-Reply	B-2	Reply	346
The original figure referred to by the reviewer is now in the Appendix.	I-Reply	I-2	Reply	346
<sep> <sep> *** MNIST results	O	O	Reply	346
(Also see the answer to R1) We include a new figure comparing the performance of STCN, STCN-dense and VRNN on single test samples from seq-MNIST.	B-Reply	B-3	Reply	346
We find that STCN-dense makes very precise probability predictions for the pixel values as opposed to other models, this explains the drastic increase in likelihood performance.	I-Reply	I-3	Reply	346
<sep> We include a table providing KL loss per latent variable across the whole dataset.	I-Reply	I-3	Reply	346
We also provide a comparison between SKIP-VAE (Avoiding Latent Variable Collapse with Generative Skip Models) and our model.	I-Reply	I-3	Reply	346
It shows that STCN-dense effectively uses the latent space capacity (indicated by high KL values) and encodes the required information to reconstruct the input sequence.	I-Reply	I-3	Reply	346
We also provide generated MNIST samples in order to show that the discrepancy between the prior and approximate posterior does not degrade generative modeling capacity.	I-Reply	I-3	Reply	346
<sep> Finally, in our MNIST experiments, we followed Z-forcing paper‚Äôs instructions.	I-Reply	I-3	Reply	346
See reply to R1 for details of the experimental protocol.	I-Reply	I-3	Reply	346

The authors propose to improve abstractive summarization models by using pretrained embeddings, theme modeling and denoising.	O	O	Review	346
<sep> <sep> They propose a very interesting idea: to leverage the lead bias in news article to build supervized summarization task from 21.4 M of articles.	O	O	Review	346
Details are given how to produce this supervized data using simple heuristics.	O	O	Review	346
<sep> <sep> The  model is  train with a denoising loss, by introducing 2 types of noise (tokens from other article and sequence shuffle).	O	O	Review	346
Theme modeling is also introduced as a classification problem  (same as BERT) :  the system must learn to classify pairs of sentences from the same article and pairs from different articles.	O	O	Review	346
<sep> <sep> Experiments are conducted on 3 datasets.	O	O	Review	346
The proposed model outperforms the other unsupervized abstractive models and provides results closed to unsupervized extractive models, with a metrics which favors extractive models.	O	O	Review	346
Ablation study shows that pretraining yields most of the impact, whereas improvements due to theme modeling and denoising loss are marginal.	O	O	Review	346
<sep> <sep> In the Article example :	B-Review	B-1	Review	346
"in the wold"  ?	I-Review	I-1	Review	346
<sep> <sep> Conclusion :	O	O	Review	346
- dataset-agnostic : I don't see why since the approach take advantage of the lead bias.	B-Review	B-2	Review	346
<sep> - "outperforms previous systems by significant margins" : excessive.	B-Review	B-3	Review	346
<sep> <sep> Thanks for your comments.	O	O	Reply	346
Please find our responses below.	O	O	Reply	346
<sep> <sep> (1) We have corrected the typo.	B-Reply	B-1	Reply	346
<sep> (2) Sorry for the confusion.	B-Reply	B-2	Reply	346
We have removed the term ‚Äúdataset-agnostic‚Äù.	I-Reply	I-2	Reply	346
We were trying to point out that the pretraining technique generates one single model that achieves consistently good performance across all 3 test datasets.	I-Reply	I-2	Reply	346
<sep> (3) Thanks for pointing that out.	O	O	Reply	346
We have changed it to ‚ÄúTED outperforms previous unsupervised abstractive baselines‚Äù.	B-Reply	B-3	Reply	346
<sep> <sep> Should you have any questions, we are very happy to answer them.	O	O	Reply	346

Paper's Claims	O	O	Review	346
<sep> The paper introduces a new unsupervised abstractive summarization approach called TED, using a Transformer encoder and decoder.	O	O	Review	346
Their main contributions are as follows:	O	O	Review	346
1) Pretraining the encoder and decoder on news articles using the first beginning as the target summary.	O	O	Review	346
<sep> 2) Fine-tune on other datasets using so-called theme modeling, and separately a denoising loss.	O	O	Review	346
<sep> 3) TED's performance is claimed to significantly improve over GPT-2 while not being too far from the best unsupervised extractive summarization results.	O	O	Review	346
<sep> <sep> Decision	O	O	Review	346
<sep> Edit: After revisions and discussions, I recommend we accept this paper.	O	O	Review	346
<sep> <sep> I am leaning towards accepting this paper mostly because of the contribution #1 above.	O	O	Review	346
Unsupervised learning using large quantities of text that have the property of being typically written in a style that synthesizes information in the first 1-3 sentences is a powerful idea.	O	O	Review	346
That the performance is improved compared to other unsupervised abstractive summarization confirms the importance of this approach.	O	O	Review	346
<sep> <sep> However the importance of and justification for the fine-tuning steps are comparatively much more limited in my opinion.	O	O	Review	346
Also, some important details about the preprocessing for pre-training appear to be missing and they could be quite important.	O	O	Review	346
<sep> <sep> Detailed arguments for decision	O	O	Review	346
<sep> I view this effort as aiming to reproduce the BERT approach in the context of abstractive summarization, which is a good idea.	O	O	Review	346
The most clever contribution is in leveraging un-labeled text using the first few sentences as the target summary for pretraining.	O	O	Review	346
The results of just this part are already beating previous approaches, while not requiring any in-domain data, which is quite powerful.	O	O	Review	346
<sep> <sep> However, some relatively important details regarding the methodology are omitted or only glossed over and it would greatly contribute to making this work more reproducible if the details were included (see my detailed notes below, notably regarding section 2.2).	B-Review	B-1	Review	346
<sep> <sep> On the fine-tuning steps, I have several worries.	B-Review	B-2	Review	346
First, why not fine-tune using supervised learning, as would be the analog to the BERT approach?	I-Review	I-2	Review	346
Instead the authors go out of their way to do in-domain unsupervised learning, which provides a boost, yes, but still doesn't compare positively to extractive and/or supervised methods.	I-Review	I-2	Review	346
Second, why not perform the theme modeling and denoising also -- or rather only -- on the unlabelled pretraining data?	I-Review	I-2	Review	346
Why should it be done on the in-domain fine-tuning data instead (while not using the most valuable piece of in-domain information, namely the example summaries)?	I-Review	I-2	Review	346
After all, it's a fully unsupervised approach and it can actually be performed on any text at all, whether a summary for it exists or not.	I-Review	I-2	Review	346
<sep> <sep> Again regarding the unsupervised approach, and to push the BERT analogy further, I'm wondering why not initialize the pretraining model with a BERT-style trained model?	B-Review	B-3	Review	346
After all we could imagine building a system that adds more and more in-domain characteristics sequentially: first pretrain a BERT model, then fine-tune to summarization using what this paper calls pretraining, and then finally fine-tune again to a specific summarization domain.	I-Review	I-3	Review	346
<sep> <sep> So, to conclude, I find that this paper goes in the right direction and introduces important ideas for pretraining and fine tuning unsupervised abstractive summarization models, but that some decisions about how to use the various ideas (theme and denoising but no supervised learning, in-domain vs during pretraining) have not been explored enough.	O	O	Review	346
<sep> <sep> Extra notes	O	O	Review	346
<sep> page 2, second line: pretrainleverages (typo)	B-Review	B-4	Review	346
section 2.1: fix first sentence to make it an actual sentence.	I-Review	I-4	Review	346
<sep> section 2.2: "we obtain three years of online new articles ... via a search engine" please be more specific about your methodology.	B-Review	B-6	Review	346
<sep> section 2.2: You should double check more throughly that there is no data leakage in test.	B-Review	B-7	Review	346
There could be articles about the same exact events, years apart, for example.	I-Review	I-7	Review	346
I doubt that this would be a big effect, but there are easily ways to find highly similar articles between the pretraining data and test data to make sure.	I-Review	I-7	Review	346
<sep> section 2.2: "Next we conduct following data cleaning" fix (typo?).	B-Review	B-8	Review	346
Also that sentence probably belongs to the next paragraph.	I-Review	I-8	Review	346
<sep> section 2.2: Why did you pick the values that you did for the preprocessing heuristics (such as between 10-150 words, 150-1200 words, 3 sentences and not 2 or 1 or 4, the ratio 0.65, etc.)?	B-Review	B-9	Review	346
Were other values tried?	I-Review	I-9	Review	346
<sep> section 2.2: You mention you end up with 21.4M articles.	B-Review	B-10	Review	346
How many were there to start with?	I-Review	I-10	Review	346
What's the filtering ratio?	I-Review	I-10	Review	346
<sep> section 2.2: You mention that you pick the model with the best ROUGE-L score on the validation set.	B-Review	B-11	Review	346
How many models were there?	I-Review	I-11	Review	346
What was different between them?	I-Review	I-11	Review	346
<sep> section 2.2, OOV Problem: the information in this whole subsection would fit better in 2.1 where 'tokens' are left generic without specifying which type of token you're considering.	B-Review	B-12	Review	346
<sep> Figure 1: I find the upper part of this figure very confusing.	B-Review	B-13	Review	346
Why are there arrows going from the encoder/decoder to a summary, to theme loss, to article and back to encoder/decoder?	I-Review	I-13	Review	346
It's important that the summary is never seen by the theme loss otherwise it's not unsupervised anymore, and I also don't see why the arrow would go through article *after* theme loss.	I-Review	I-13	Review	346
I assume there must have been a mistake, please fix.	I-Review	I-13	Review	346
<sep> section 2.4: "the sequence is slightly shuffled by applying a permutation /sigma such that ..." The formula given here tells me that all token indices are shuffled with another token within a window k. That seems like a lot of moving around, and also depending on the implementation a token from the beginning could possibly end up at the very tail of the sentence by being picked iteratively again and again, thus falling outside the permutation distance k. Please provide more details on how this is done and a justification for why it was decided to do it this way.	B-Review	B-14	Review	346
<sep> Section 3.1: I'd like to know how long (preferably number of words, or at least number of wordpiece tokens) the summaries generated are.	B-Review	B-15	Review	346
What determines how long they are, is it a fixed size, or the model decides to stop on his own (or when hitting some limit), or something else?	I-Review	I-15	Review	346
<sep> section 4.2: Do you have any idea why your unsupervised approach yields more novel n-grams than a the supervised model you compare against?	B-Review	B-5	Review	346
This can be good as much as it can be bad, in that it could be going off-track.	I-Review	I-5	Review	346
Yes humans have high novelty, but high novelty in itself isn't necessarily good.	I-Review	I-5	Review	346
I don't find the argument that have more novel ngrams is intrinsically, necessarily good, compelling.	I-Review	I-5	Review	346
If I'm wrong, then it would be nice to have better explanation in the paper.	I-Review	I-5	Review	346
<sep> <sep> <sep> <sep> Regarding the extra notes (with the same order as in ‚ÄúExtra notes‚Äù):	O	O	Reply	346
<sep> (1) (2) Sorry about the typos.	B-Reply	B-4	Reply	346
We have fixed them.	I-Reply	I-4	Reply	346
<sep> (3) The search engine indexes major online news domain, for instance, New York Times and Bloomberg.	B-Reply	B-6	Reply	346
Then we collect the parsed articles within the 2016-2019 time range as the raw data.	I-Reply	I-6	Reply	346
<sep> (4)  We understand your concern about data leakage.	B-Reply	B-7	Reply	346
We went through the three test sets and did not find significantly overlapped articles as in the pretraining.	I-Reply	I-7	Reply	346
<sep> (5) Thanks for pointing it out.	B-Reply	B-8	Reply	346
We have revised it.	I-Reply	I-8	Reply	346
<sep> (6) Some explanations for the heuristic values selections:	B-Reply	B-9	Reply	346
<sep> 150 and 1,200 words: Articles with very long content are filtered them mainly to reduce memory consumption.	I-Reply	I-9	Reply	346
Short articles are filtered since the information might be too condensed and not suitable for summarization pretraining.	I-Reply	I-9	Reply	346
<sep> <sep> 10 and 150 words: Some leading sentences are extremely short, e.g. one or two words phrases.	I-Reply	I-9	Reply	346
Those are filtered since they have too little information to be reasonable summaries.	I-Reply	I-9	Reply	346
Longer leading sentences are removed to reduce the pretraining time.	I-Reply	I-9	Reply	346
<sep> <sep> 0.65: The overlap ratio is an indicator of the amount of information that the leading sentences maintain.	I-Reply	I-9	Reply	346
For instance,  in CNN/DM dataset, the median of the overlapping ratio of non-stopping words between golden summary and the article is 0.87, and the ratio between the first 3 sentences and the rest of the article is 0.77 (median).	I-Reply	I-9	Reply	346
Setting the number at 0.65 makes the final training set size fit with the available computation resources and ensures that the leading sentences contain enough information.	I-Reply	I-9	Reply	346
<sep> <sep> We mean to have demanding filtering criteria since we want high-quality pretraining data.	I-Reply	I-9	Reply	346
We didn‚Äôt try other settings since pretraining is a time-consuming process.	I-Reply	I-9	Reply	346
<sep> <sep> (7) We start with about 407 million articles.	B-Reply	B-10	Reply	346
The filtering ratio is about 95%.	I-Reply	I-10	Reply	346
We‚Äôve also added this information to the paper.	I-Reply	I-10	Reply	346
<sep> <sep> (8) We train one model for 10 epochs.	B-Reply	B-11	Reply	346
After each epoch, the model is evaluated on validation data.	I-Reply	I-11	Reply	346
We pick the check points with the highest ROUGE L.	I-Reply	I-11	Reply	346
<sep> (9) About OOV.	B-Reply	B-12	Reply	346
It is a good idea.	I-Reply	I-12	Reply	346
We have edited and moved the paragraph to section 2.1	I-Reply	I-12	Reply	346
<sep> (10)  About Figure 1.	B-Reply	B-13	Reply	346
Sorry about the confusion.	I-Reply	I-13	Reply	346
The ‚Äúsummary‚Äù refers to the generated summary from the transformer encoders/decoders, not the groundtruths summaries.	I-Reply	I-13	Reply	346
The process follows that the article is input to the transformer encoder/decoders and a summary is generated.	I-Reply	I-13	Reply	346
Then we compute the theme loss using the generated summary and the article.	I-Reply	I-13	Reply	346
We‚Äôve changed the text label ‚Äúsummary‚Äù in figure to ‚Äúgenerated summary‚Äù to avoid the confusion.	I-Reply	I-13	Reply	346
<sep> <sep> (11) About sequence shuffling.	B-Reply	B-14	Reply	346
Here is how we generate the permutations (the variable perm) of the indices using numpy.	I-Reply	I-14	Reply	346
Assume the length of the sequence is L, and the window size is k.	I-Reply	I-14	Reply	346
ids = np.arange(L)	I-Reply	I-14	Reply	346
noise =  np.random.uniform(0, k, size = L)	I-Reply	I-14	Reply	346
tmp = ids + noise	I-Reply	I-14	Reply	346
perm = tmp.argsort()	I-Reply	I-14	Reply	346
For tokens in the beginning, e.g. the first token, since there are at most k -1 elements smaller than tmp[0] in tmp, so the first token is at most shuffled to the kth position.	I-Reply	I-14	Reply	346
<sep> <sep> The motivation of shuffling is as follows.	I-Reply	I-14	Reply	346
The information is to extract and summarize is scattered across an article.	I-Reply	I-14	Reply	346
By applying this shuffling noise, we want our model to learn to recognize and reorganize the information.	I-Reply	I-14	Reply	346
<sep> <sep> (12) The generation has a hard limit, which is decided on the validation dataset.	B-Reply	B-15	Reply	346
For instance, the maximum generation length for CNN/DM dataset is 175.	I-Reply	I-15	Reply	346
Also, in beam search, if the generated token is &lt;EOS&gt;, i.e. the end of sentence, then the generation is terminated immediately for the current sequence.	I-Reply	I-15	Reply	346
<sep> <sep> (13) Since TED is an abstractive model, this experiment is to show that TED has the ability to summarize using words/phrases not in the original article, which is typical in human-edited summaries.	B-Reply	B-5	Reply	346
Explanations why TED has more novel grams could be TED has seen more data during the pretraining phase than PGNet (which is only trained using in-domain data).	I-Reply	I-5	Reply	346
Also PGNet uses RNN while TED leverages transformer.	I-Reply	I-5	Reply	346
The more powerful modeling ability of transformer can also help.	I-Reply	I-5	Reply	346
Also the major evaluation metrics is the ROUGE, on which TED shows competitive performances.	I-Reply	I-5	Reply	346

POS-DISCUSSION	O	O	Review	346
I thank the authors for their answer.	O	O	Review	346
I updated my score assuming ryxAY34YwB does not exist, and would encourage authors to discuss in more details the relationship with MeanSum if this gets accepted	O	O	Review	346
<sep> PRE-DISCUSSION	O	O	Review	346
<sep> This is an important contribution for the field of unsupervised summarization. "	O	O	Review	346
Unsupervised *" is trendy in NLP so this is a timely contribution.	O	O	Review	346
Furthermore, doing this for summarization is important because of the cost of getting gold summaries and the model used in translation is harder (impossible?)	O	O	Review	346
to adapt to this setting where there is information loss in one direction.	O	O	Review	346
<sep> <sep> However, I find major drawbacks in the current state of this paper.	O	O	Review	346
They are best related to the three contributions the author claim:	O	O	Review	346
- Contribution3: the use of BPE. "	B-Review	B-1	Review	346
BPE for X", with X being an NLP task can hardly count as a contribution today.	I-Review	I-1	Review	346
If we are counting who did it first, then this is taken at least by Liu &amp; Lapata 2019 through their use of BERT	I-Review	I-1	Review	346
- Contribution1: leveraging the lead bias for pre-training.	B-Review	B-2	Review	346
This is a great idea!	I-Review	I-2	Review	346
However, this seems to be covered by an accompanying paper (ICLR submission ryxAY34YwB) which is not referenced.	I-Review	I-2	Review	346
Because of common paragraphs and experimental setting I am assuming there is an overlap of the author sets in two papers.	I-Review	I-2	Review	346
PLEASE CORRECT IF THIS IS NOT THE CASE.	I-Review	I-2	Review	346
As you don't get to claim the same contribution twice, this contribution should go all to the benefit of the other paper.	I-Review	I-2	Review	346
<sep> - Contribution2: the use of combining reconstruction loss and theme loss for summarization is another great idea.	B-Review	B-3	Review	346
However, the paper that introduced this for summarization (as far as I know) is not cited nor compared too (MeanSum: <a href="https://arxiv.org/abs/1810.05739)."	I-Review	I-3	Review	346
target="_blank" rel="nofollow">https://arxiv.org/abs/1810.05739).</a> This seems like a major issue considering the similarity in the approach (including the use of the straight-through Gumbel softmax estimator).	I-Review	I-3	Review	346
<sep> <sep> Other comments:	O	O	Review	346
<sep> - Being a growing topic of study, I appreciated in particular the care taken to report a number of other approaches.	B-Review	B-4	Review	346
Could you please clarify which version of ROUGE was used in each case?	I-Review	I-4	Review	346
There are significant differences in the different implementations being used.	I-Review	I-4	Review	346
<sep> - Please also specify the version of ROUGE you used.	B-Review	B-5	Review	346
<sep> - Your numbers in Table 2 do not coincide with Table 3 of ryxAY34YwB (eg: LEAD-3 for CNN/DM).	B-Review	B-6	Review	346
Can you explain?	I-Review	I-6	Review	346
<sep> - Your ablation study (Sect 4.1) focuses on CNN/DM (NOTE: the caption of Table 4 says NYT, but the number correspond to CNN/DM.	B-Review	B-7	Review	346
I guess this is an error), where the topic &amp; reconstruction loss indeed helps.	I-Review	I-7	Review	346
However this is not the case for NYT, where LEAD-3 actually beats any of your approach.	I-Review	I-7	Review	346
This is not mention nor discussed.	I-Review	I-7	Review	346
<sep> - The example of Fig 4 reveals a major problem.	B-Review	B-8	Review	346
The summary states an incorrect fact: the gov accountability had indeed released a report earlier that week; but this was NOT a few hours before the reported incident.	I-Review	I-8	Review	346
What happened a few hours before was a report on Fox News.	I-Review	I-8	Review	346
<sep> <sep> <sep> In a summary: a good idea combining ideas of ryxAY34YwB and adapting MeanSum.	O	O	Review	346
However, this is in my opinion not enough material for a full paper.	O	O	Review	346
We appreciate your comments!	O	O	Reply	346
Please find our response below.	O	O	Reply	346
<sep> <sep> About the concern on our contributions.	O	O	Reply	346
<sep> (1) About SentencePiece.	B-Reply	B-1	Reply	346
We have removed the claim from the major contributions.	I-Reply	I-1	Reply	346
To the best of our knowledge, TED is one of the initial attempts to use SentencePiece in unsupervised text summarization.	I-Reply	I-1	Reply	346
<sep> <sep> (2) Thanks for pointing that out.	O	O	Reply	346
We have added the reference to that paper.	B-Reply	B-2	Reply	346
We believe the usage of denoising and theme modeling in summarization are still innovative as discussed more in the next response.	I-Reply	I-2	Reply	346
<sep> <sep> (3) Thanks for mentioning MeanSum and we have referenced it in the paper.	B-Reply	B-3	Reply	346
The reasons why we didn‚Äôt include MeanSum are:	I-Reply	I-3	Reply	346
<sep> First, MeanSum is for multi-document summarization, while the baseline models we are comparing are for single document.	I-Reply	I-3	Reply	346
<sep> <sep> Second, the denoising in TED is quite different from the reconstruction idea in MeanSum.	I-Reply	I-3	Reply	346
In TED‚Äôs denoising, the corrupted text are input to the transformer and the model is trained to filter the added noises.	I-Reply	I-3	Reply	346
Note the original (clean) text is not used as inputs or seen by TED in the forward pass.	I-Reply	I-3	Reply	346
However, the reconstruction process in MeanSum follows that it inputs multiple documents to RNN, generate the summaries (the encoded reviews), and then reconstruct each document from the summaries.	I-Reply	I-3	Reply	346
<sep> <sep> Third, the same reconstruction idea is also used in a baseline single document summarization model SEQ3 (NAACL 19) that we compared with in the paper, which is published at almost the same time as MeanSum (ICML 19).	I-Reply	I-3	Reply	346
Similar to MeanSum, SEQ3 tries to reconstruct the the single document from the generated summary.	I-Reply	I-3	Reply	346
As shown in table 2, TED outperforms SEQ3 by significant margins.	I-Reply	I-3	Reply	346
<sep> <sep> TED is innovative compared with both MeanSum and SEQ3.	I-Reply	I-3	Reply	346
First MeanSum and SEQ3 both use RNN, while TED builds on transformer.	I-Reply	I-3	Reply	346
Second, although both MeanSum and SEQ3 have a loss to make make the summary similar to the input article, it is implemented as the classical cosine similarity.	I-Reply	I-3	Reply	346
In contrast, TED innovatively encodes the similarity by the transformer encoder in a BERT-style.	I-Reply	I-3	Reply	346
<sep> <sep> About other comments:	O	O	Reply	346
(1) Most of the performances of baseline models are directly taken from the original paper.	B-Reply	B-4	Reply	346
After searching their paper, open-sourced code (if available) and by personal communications, we found that PacSum, TextRank (from the PacSum paper), SEQ3, Brief, GPT-2, SUMO, REFRESH, PGNet use ROUGE-1.5.5.	I-Reply	I-4	Reply	346
<sep> (2) The ROUGE version we use is ROUGE-1.5.5, same as mentioned above.	B-Reply	B-5	Reply	346
<sep> <sep> (3) We have corrected the numbers in Table 2 in the revised paper.	B-Reply	B-6	Reply	346
Please refer to the newest table for the performance.	I-Reply	I-6	Reply	346
<sep> <sep> (4) The ablation study in table 4 is on NYT dataset.	B-Reply	B-7	Reply	346
The full TED model, pretrain w/ theme modeling and pretrain w/ denoise all outperform the lead-3 baseline now.	I-Reply	I-7	Reply	346
<sep> <sep> (5) Fact/common sense checking would be an interesting future direction.	B-Reply	B-8	Reply	346
Our model manages to recognize that there are time-related information it still needs improvement on delivering factual information.	I-Reply	I-8	Reply	346
We‚Äôve added the analysis to section 4.2.	I-Reply	I-8	Reply	346

The paper describes a pipeline for image compression which allows to reliably detect specific manipulation patterns in compressed images.	O	O	Review	350
The results show that it is possible to learn image compression that performs similarly to a modern image compression algorithm while in the same time is optimized to reveal specific kinds of manipulations.	O	O	Review	350
The authors build upon (Korus &amp; Memon, 2019), but use a learnable codec instead of differentiable JPEG.	O	O	Review	350
<sep> <sep> The idea to regularize entropy of the latent representation of images is interesting.	O	O	Review	350
A method to train a well-performing image compression system which can also follow additional constraints (such as ability to reveal certain manipulations) is very valuable for practice.	B-Review	B-1	Review	350
Unfortunately, there are already available trainable compression methods and the authors do not compare to these methods.	I-Review	I-1	Review	350
However, in my opinion to detect manipulation in the image one should prove that visual content in some area of the image was significantly changed with respect to some original, while in the other parts of the image it was not changed.	I-Review	I-1	Review	350
Otherwise it becomes impossible to distinguish in-camera filtering and secondary postprocessing.	I-Review	I-1	Review	350
Basically, the authors present a method to detect whether a very particular configuration of some basic image processing filters (Gaussian blur, median filter, resampling)  was applied to the image.	I-Review	I-1	Review	350
Therefore the particular problem formulation looks very artificial.	I-Review	I-1	Review	350
<sep> <sep> With regards to the experiments in the paper, I was somewhat lost.	B-Review	B-2	Review	350
Compare the Fig.8.	I-Review	I-2	Review	350
5 and the Fig.	I-Review	I-2	Review	350
In the Fig.8, we see a big set of possible system configurations having different manipulation detection accuracy, image quality and compression performance.	I-Review	I-2	Review	350
In the Fig.5, we see a compression efficiency-image quality dependency.	I-Review	I-2	Review	350
However, it remains unclear how do the systems represented at these two graphs relate to each other, or, in the other words, what is he mapping between points of these graphs.	I-Review	I-2	Review	350
Next, poor performance of JPEG manipulation detection by the proposed  network does not prove that JPEG manipulation cannot be detected, it just shows that the proposed architecture does not perform well in this problem.	I-Review	I-2	Review	350
A comparative study which relates a new system to a current state of the art is required to claim that a proposed approach is better.	I-Review	I-2	Review	350
Finally, SSIM is not a standard way to compute image quality.	I-Review	I-2	Review	350
MS-SSIM and PSNR are also popular, and a user study is usually recommended to claim that some method generates images of better visual quality.	I-Review	I-2	Review	350
<sep> <sep> Summarizing, the authors do not provide a new best-performing image compression algorithm, and neither solve a problem of image manipulation detection, but show that it is possible to learn an image compression system with some additional constraints.	O	O	Review	350
I believe it is an interesting contribution, and I hope the authors can improve presentation of the experiments.	O	O	Review	350
Thank you for detailed comments.	O	O	Reply	350
<sep> <sep> Our setup involves a forensic analysis network which learns to distinguish basic image manipulations.	B-Reply	B-1	Reply	350
This corresponds to a well-established foundational test scenario, which can later be built upon to deliver practical manipulation detection algorithms.	I-Reply	I-1	Reply	350
Once the model learns to distinguish different image processing paths, it will respond differently to content coming from different sources.	I-Reply	I-1	Reply	350
For example, if an object is inserted or removed from a photo, that region is likely to solicit a different response than the rest of the image.	I-Reply	I-1	Reply	350
An anomaly detection scheme then then be used to precisely detect and pin-point the manipulation.	I-Reply	I-1	Reply	350
For a state-of-the-art system built upon this principle, we can refer readers to a recent work from CVPR [1].	I-Reply	I-1	Reply	350
<sep> Regarding, Fig.8, although there is some conceptual overlap, each figure is self-sufficient and should be viewed independently.	B-Reply	B-2	Reply	350
5 and Fig.	I-Reply	I-2	Reply	350
Fig.5 shows the standard rate-distortion trade-off for the baseline DCN model as well as standard hand-crafted codecs.	I-Reply	I-2	Reply	350
Fig.8 aims to show a more complex trade-off between rate, distortion, and forensic analysis accuracy.	I-Reply	I-2	Reply	350
The main goal is to show the impact of optimization for forensic analysis at different levels of its importance.	I-Reply	I-2	Reply	350
Fig.A6 which uses the same protocol and shows the same codecs using the same colors.	I-Reply	I-2	Reply	350
5 can be compared with Fig.	I-Reply	I-2	Reply	350
<sep> <sep> We agree that in principle we cannot prove that more reliable detection for JPEG image is not possible.	B-Reply	B-2	Reply	350
However, the forensic analysis network that we used was developed for and tested on JPEG images [2]. Due to their prevalence, forensic analysis of JPEG images is well investigated.	I-Reply	I-2	Reply	350
Hence, we can assume that the accuracy we observe is a good proxy for the upper bound on the achievable classification performance.	I-Reply	I-2	Reply	350
We did not perform any compression-specific tweaks and used exactly the same model in all cases.	I-Reply	I-2	Reply	350
<sep> <sep> Thank you for the suggestion.	B-Reply	B-2	Reply	350
We have included MS-SSIM results in the current manuscript (Figures A.5 and A.6).	I-Reply	I-2	Reply	350
We agree that performing a user study would be valuable.	I-Reply	I-2	Reply	350
We leave this evaluation for future work.	I-Reply	I-2	Reply	350
<sep> <sep> References (all of them were already referenced in the manuscript):	O	O	Reply	350
[1] Wu, Yue, Wael AbdAlmageed, and Premkumar Natarajan. "	O	O	Reply	350
ManTra-Net: Manipulation Tracing Network for Detection and Localization of Image Forgeries With Anomalous Features."	O	O	Reply	350
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp.9543-9552.	O	O	Reply	350
2019.	O	O	Reply	350
<sep> [2] Bayar, Belhassen, and Matthew C. Stamm. "	O	O	Reply	350
Constrained convolutional neural networks: A new approach towards general purpose image manipulation detection."	O	O	Reply	350
IEEE Transactions on Information Forensics and Security 13, no.	O	O	Reply	350
11 (2018): 2691-2706.	O	O	Reply	350

This paper presents a learned image compression method that is able to be robust under a variety of tasks.	O	O	Review	350
The results aren't state of the art in terms of rate-distortion performance, but this paper has a very good analysis of the results, and has produced a very fast codec.	O	O	Review	350
In that sense, this is a very interesting paper that may lead to other fast methods (the other fast method they compared the runtime against - WaveOne never published a complete description).	O	O	Review	350
<sep> <sep> This paper should be likely accepted, but the authors should town down the claims a bit.	B-Review	B-1	Review	350
The results presented do NOT show that this method is better than the best hand engineered approach, despite what they claim.	I-Review	I-1	Review	350
Even compared to BPG, which is NOT state of the art, the results are a mixed bag.	I-Review	I-1	Review	350
<sep> <sep> We would like to point out to the authors that the VVC codec has shown much stronger performance than BPG, and similarly the AV1 codec has surpassed the performance of BPG.	I-Review	I-1	Review	350
Moreover, even Pik has also surpassed the performance of BPG, so just showing stronger performance than BPG is not grounds to make the claim that this method is superior to hand engineered approaches.	I-Review	I-1	Review	350
<sep> <sep> Moreover, as I stated earlier, this method is not even better all the time, therefore weakening the claim.	O	O	Review	350
<sep> <sep> On the positives:	O	O	Review	350
- the paper fully describes the architecture, unlike WaveOne	O	O	Review	350
- the runtime numbers are impressive (as far as I know, there is no faster published method)	O	O	Review	350
- the authors consider applications other than compression performance (such as classification performance in forensic analysis)	O	O	Review	350
<sep> On the negatives, which I highly suggest that the authors fix if this paper is to be taken seriously by the community:	O	O	Review	350
- please be sure to explain that SSIM is computed in &lt;RGB | grayscale&gt;	B-Review	B-2	Review	350
- please be more explicit about which loss is used during training for distortion (i.e., "we use MSE for the training loss, but stop training when SSIM converges")	B-Review	B-3	Review	350
- please provide PSNR numbers for the method; and ideally MS-SSIM (in decibels) instead of PSNR	B-Review	B-4	Review	350
- please add other neural compression methods to the graphs	B-Review	B-5	Review	350
- please clarify that you create a file and decode a file for each image used to create the graphs (very important topic), as opposed to using the estimated file size	B-Review	B-6	Review	350
- tone down the claims w.r.t.beating classical codecs	B-Review	B-7	Review	350
Thank you for your detailed comments and for pointing out more recent hand-crafted codecs.	O	O	Reply	350
<sep> <sep> We apologize for the confusion.	B-Reply	B-1	Reply	350
We do not claim to get better results than state-of-the-art hand-crafted solutions.	I-Reply	I-1	Reply	350
In fact, in terms of the rate-distortion performance, our codec is slightly worse, although very close to BPG.	I-Reply	I-1	Reply	350
This is what we meant by saying ‚Äú... is competitive with best hand-engineered codecs‚Äù.	I-Reply	I-1	Reply	350
We have rephrased all related statements in the abstract and the introduction to avoid the confusion and better reflect the actual results.	I-Reply	I-1	Reply	350
<sep> <sep> Regarding the remaining remarks:	O	O	Reply	350
<sep> # please be sure to explain that SSIM is computed in &lt;RGB | grayscale&gt;	O	O	Reply	350
The SSIM was computed as the average over RGB channels.	B-Reply	B-2	Reply	350
We used the default implementation in the scikit-image package.	I-Reply	I-2	Reply	350
We have extended the manuscript to explain how image quality scores are calculated (Section 3.5 / Rate-distortion Trade-off).	I-Reply	I-2	Reply	350
<sep> <sep> # please be more explicit about which loss is used during training for distortion (i.e., "we use MSE for the training loss, but stop training when SSIM converges")	O	O	Reply	350
We repeated again in Section 3.4 that MSE was used as the training loss explicitly optimized using Adam.	B-Reply	B-3	Reply	350
<sep> <sep> # please provide PSNR numbers for the method; and ideally MS-SSIM (in decibels) instead of PSNR	O	O	Reply	350
We extended the results to include MS-SSIM in decibels.	B-Reply	B-4	Reply	350
The new results are included in the appendix (Figures A.5 and A.6).	I-Reply	I-4	Reply	350
<sep> <sep> # please add other neural compression methods to the graphs	O	O	Reply	350
We apologize but due to limited time for rebuttal, we were not able to include more neural compression methods in the comparison.	B-Reply	B-5	Reply	350
We hope to include more methods upon publication of the codec on github.	I-Reply	I-5	Reply	350
<sep> <sep> # please clarify that you create a file and decode a file for each image used to create the graphs (very important topic), as opposed to using the estimated file size	O	O	Reply	350
Yes, we fully encoded an image into a bit-stream and subsequently decoded and reconstructed the images.	B-Reply	B-6	Reply	350
The bit-stream structure is already explained in Section 3.3.	I-Reply	I-6	Reply	350
To address your doubt, we emphasized that this is the case in Section 3.5.	I-Reply	I-6	Reply	350
<sep> <sep> # tone down the claims w.r.t.beating classical codecs	O	O	Reply	350
We rephrased all statements to clarify the confusion and better reflect the actual results.	B-Reply	B-7	Reply	350

Summary of the paper	O	O	Review	350
- This work proposes a new deep-learning-based method to replace the lossy compression techniques of images.,	O	O	Review	350
jpg.	O	O	Review	350
- The work investigates the role of codec and shows that the proposed complex photo dissemination channels optimizes the codec related traits on images.	O	O	Review	350
- The method achieved much better performance in compressing images compared to practically used JPEG (QF-20)	O	O	Review	350
I think the paper is well written and the experiment seems to support the author's argument.	O	O	Review	350
Unfortunately, this field is not overlapped to my research field, and it is hard for me to judge this paper.	O	O	Review	350
Thank you for your comments.	O	O	Reply	350

This paper proposes APPROXLINE, which is a sound approximation to EXACTLINE and is able to compute tight deterministic bounds on probabilities efficiently when the input is restricted on a line.	O	O	Review	608
It is a nonconvex relaxation, therefore it is able to capture the nonconvexity of neural networks.	O	O	Review	608
APPROXLINE is applied to generative models to verify the consistency of image attributes through linear interpolations on the latent variables.	O	O	Review	608
<sep> <sep> To me, the most significant part is that the proposed approach has the potential to become a reliable metric for evaluating whether a generator disentangles latent representations, as long as a reliable attribute classifier can be trained.	B-Review	B-3	Review	608
I would suggest the authors to emphasize this part in their future versions.	I-Review	I-3	Review	608
<sep> <sep> However, the current version is quite difficult for me to understand, and I guess it is difficult for a broad range of audiences without background in program analysis.	B-Review	B-1	Review	608
Somehow I think the same message can be conveyed better without abusing terms from abstract interpretation.	I-Review	I-1	Review	608
I would also suggest the authors to reduce such abuse of notations.	I-Review	I-1	Review	608
At least, pseudocode could be provided.	I-Review	I-1	Review	608
<sep> <sep> As a result, I cannot give a confident judgement about whether the contribution of this paper is significant given the existence of EXACTLINE.	B-Review	B-2	Review	608
Still, I tend to accept this paper for its potential to become a good metric for generative models.	I-Review	I-2	Review	608
Thank you for your review.	O	O	Reply	608
We will gladly incorporate your suggestions to reduce our reliance on terms and knowledge from abstract interpretation, and have included pseudocode so that our techniques can be understood in isolation.	B-Reply	B-1	Reply	608
As probabilistic abstract interpretation has proved a powerful framework for probabilistic bound inference in the program analysis community, we felt that it would be an important contribution on its own to describe a usage for the machine learning community.	I-Reply	I-1	Reply	608
<sep> <sep> On the significance over ExactLine:  providing fast and sound overapproximations to exact methods is known to be non-trivial, and certainly publishable (see [1,2,3,4,5,6,7,8]).	B-Reply	B-2	Reply	608
While abstracting exact domains to less precise domains (sets of boxes) is a well known technique, the decision of whether, where, when, and what to approximate has no definitive answer.	I-Reply	I-2	Reply	608
In the case of restrictions to lines, we found that for larger networks, to be significantly more performant than simply sampling (as can be seen in Figure 2 and Section 4.2), over-approximation of ExactLine was absolutely necessary.	I-Reply	I-2	Reply	608
The design of our core novel contribution, a heuristic for the parts of ExactLine to approximate, turned out to be both a delicate and a critical problem.	I-Reply	I-2	Reply	608
We tested quite a few seemingly obvious heuristics, such as clustering ExactLine edges using k-means (both in the original dimensional space and projected to single dimensions in various ways) before determining the necessity of ensuring connectedness between the nodes in each approximation cluster (which turned out to be the best heuristic, and the one we present).	I-Reply	I-2	Reply	608
We will update the paper to mention these other options.	I-Reply	I-2	Reply	608
<sep> <sep> [1] Singh Gagandeep, Gehr Timon, P√ºschel Markus, Vechev Martin.	O	O	Reply	608
Boosting Robustness Certification of Neural Networks.	O	O	Reply	608
ICLR 2019	O	O	Reply	608
[2] Singh Gagandeep, Gehr Timon, Mirman Matthew, P√ºschel Markus, Vechev Martin.	O	O	Reply	608
<sep> Fast and Effective Robustness Certification.	O	O	Reply	608
NeurIPS 2018	O	O	Reply	608
[3] Singh Gagandeep, Ganvir Rupanshu, P√ºschel Markus, Vechev Martin.	O	O	Reply	608
Beyond the Single Neuron Convex Barrier for Neural Network Certification.	O	O	Reply	608
NeurIPS 2019	O	O	Reply	608
[4] Zhang, Huan, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel.	O	O	Reply	608
Efficient neural network robustness certification with general activation functions.	O	O	Reply	608
NeurIPS 2018.	O	O	Reply	608
<sep> [5] Wang, Shiqi, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman Jana.	O	O	Reply	608
Efficient formal safety analysis of neural networks.	O	O	Reply	608
In NeurIPS 2018.	O	O	Reply	608
<sep> [6] Salman, Hadi, Greg Yang, Huan Zhang, Cho-Jui Hsieh, and Pengchuan Zhang.	O	O	Reply	608
A convex relaxation barrier to tight robust verification of neural networks.	O	O	Reply	608
NeurIPS 2019.	O	O	Reply	608
<sep> [7] Wong, Eric and J. Z. Kolter.	O	O	Reply	608
Provable Defenses against Adversarial Examples via the Convex Outer Adversarial Polytope.	O	O	Reply	608
ICML 2018	O	O	Reply	608
[8] Mirman Matthew, Gehr Timon, and Vechev Martin.	O	O	Reply	608
Differentiable Abstract Interpretation for Provably Robust Neural Networks.	O	O	Reply	608
ICML 2018	O	O	Reply	608

summary:	O	O	Review	608
The paper proposes a method to efficiently verify that generative models are consistent with respect to some known (latent) attribute.	O	O	Review	608
The authors defines attribute consistency by 1) mapping pairs of input (x1, x2) with matching attribute to a latent space using an encoder n_E(x) and 2) measuring how correctly an auxiliary classifier will classify the known attribute using (decoded) linear interpolations between the two latent encodings.	O	O	Review	608
Importantly, the proposed method gives guaranteed bounds on this consistency score, as opposed to simply evaluating the classifier on a fixed set uniformly sampled points between x1 and x2.	O	O	Review	608
In experiments the authors use their method to test for attribute independence as well as consistency under left-right flipping of an image using two different autoencoder models (VAE and CycleAE) obtaining tighter bounds on the ‚Äòattribute consistency‚Äô score than competing methods.	O	O	Review	608
<sep> Decision &amp; supporting arguments:	O	O	Review	608
Conceptually I found the paper very appealing, and it tackles an important problem in generative modelling.	O	O	Review	608
However I have some concerns with respect to the paper in its current state:	O	O	Review	608
1) It is not clear to me why the attribute consistency score, a key component in the paper, is a good measure of consistency in generative models.	B-Review	B-1	Review	608
Notably, I miss motivation for why linear interpolations between encoded inputs should necessarily keep the attribute stable.	I-Review	I-1	Review	608
<sep> 2) Although I found the experiments interesting, I did not find the experimental section completely comprehensive.	B-Review	B-2	Review	608
There is no discussion or experiments probing the dependency on the quality of the auxiliary classifier or the encoder/decoder model used.	I-Review	I-2	Review	608
<sep> 3) I did not find the description of the proposed method to be reasonably self-contained.	B-Review	B-3	Review	608
Especially section 3 which describes the proposed method is challenging to follow.	I-Review	I-3	Review	608
The background material in section 2 reads very much like a set of definitions.	I-Review	I-3	Review	608
Since ICLR has a quite broad audience, I think the paper should be written in a more pedagogical way, with for instance clarifying examples.	I-Review	I-3	Review	608
An example of a sentence that is incredibly hard to parse is on page 4, describing domain lifting: ‚ÄúAny deterministic abstract domain can be directly interpreted as a probabilistic abstract domain, where the concretization of an element is given as the set of probability measures whose support is a subset of the set produced by the deterministic concretization.	I-Review	I-3	Review	608
‚Äù I think making this paper more pedagogical requires major rewriting.	I-Review	I-3	Review	608
<sep> <sep> Due to the above reasons I currently score the paper as a ‚Äòweak reject‚Äô.	O	O	Review	608
<sep> <sep> Further detailed questions/comments:	O	O	Review	608
Consistency Score	O	O	Review	608
Q1: What is the motivation behind the definition of the consistency attribute score.	B-Review	B-4	Review	608
Especially, why is an attribute considered consistent if it is stable to linear interpolations in the latent space?	I-Review	I-4	Review	608
<sep> <sep> Experiment Results:	O	O	Review	608
Q2.1: Did you perform any experiments on how the L1 score of the auxiliary classifier affects the consistency score?	B-Review	B-5	Review	608
I would also like to see some quantitative numbers on the auxiliary classifier.	I-Review	I-5	Review	608
<sep> Q2.2: Why is the L1 score used for training the classifier instead of bernoulli which seems more natural for binary attributes?	B-Review	B-6	Review	608
<sep> Q2.3: Similarly, I would like to see some numbers on the quality of the encoder/decodes.	B-Review	B-7	Review	608
Simply inspecting the interpolations in figure 3) the reconstructions seem quite blurry, likely due to the relatively small models used.	I-Review	I-7	Review	608
Is it prohibitively expensive to run the proposed method on bigger models (e.g. ResNet based encoder/decoders or Unet-style models)?	I-Review	I-7	Review	608
<sep> Q2.4: I believe it would be more informative to show the actual confidence intervals in figure 2b) instead of only the width of the confidence intervals?	B-Review	B-8	Review	608
<sep> <sep> Readability:	O	O	Review	608
Q3: I found it quite challenging to understand how the proposed is implemented in practice - My suggestion is that the authors add a pseudo-code / algorithm to section 3 clarifying exactly how the bounds reported in the experimental section are calculated.	B-Review	B-9	Review	608
<sep> <sep> <sep> Thank you for the thorough and clear review.	O	O	Reply	608
We will answer in two parts.	O	O	Reply	608
<sep> <sep> Q1.1: It is not clear to me why the attribute consistency score, a key component in the paper, is a good measure of consistency in generative models.	O	O	Reply	608
Notably, I miss motivation for why linear interpolations between encoded inputs should necessarily keep the attribute stable.	O	O	Reply	608
<sep> <sep> There have been a wealth of papers that propose autoencoder/generative model systems that claim that linear interpolations produce "interpretable" results [1-11]. It is in fact possible that not all defined attributes for a dataset should be preserved under "interpretable" interpolations.	B-Reply	B-1	Reply	608
For example, interpolating between a person with only a beard and the same person with only a mustache would likely fail to satisfy the disjunctive attribute "no beard or no mustache."	I-Reply	I-1	Reply	608
However, for many attributes we do expect intuitively consistency along interpolations between examples with those attributes, such as "has blond hair."	I-Reply	I-1	Reply	608
One can examine the named attributes provided with CelebA to decide whether they should remain consistent among interpolations (we believe they should).	I-Reply	I-1	Reply	608
<sep> <sep> Interestingly, this brings up the important point that deciding whether an attribute should correspond to a direction in the encoded representation for a dataset is likely a subjective question.	I-Reply	I-1	Reply	608
We do not claim to answer this.	I-Reply	I-1	Reply	608
Rather, our system attempts to verify this for a given dataset and given property.	I-Reply	I-1	Reply	608
<sep> <sep> Q1.2: Especially, why is an attribute considered consistent if it is stable to linear interpolations in the latent space?	O	O	Reply	608
<sep> <sep> We clarify that we do not measure the consistency of an attribute in vacuum, but with respect to a particular autoencoder.	B-Reply	B-4	Reply	608
An attribute which is consistent for one autoencoder might very well be inconsistent for another autoencoder, and this is not a judgement on the consistency of the attribute as much as it is a judgement on the consistency of the autoencoder.	I-Reply	I-4	Reply	608
<sep> <sep> [1] Vincent Dumoulin, Ishmael Belghazi, Ben Poole, Olivier Mastropietro, Alex Lamb, Martin Arjovsky, and Aaron Courville.	O	O	Reply	608
Adversarially learned inference.	O	O	Reply	608
arXiv preprint arXiv:1606.00704, 2016.	O	O	Reply	608
<sep> [2] Michael F Mathieu, Junbo Jake Zhao, Junbo Zhao, Aditya Ramesh, Pablo Sprechmann, and Yann LeCun.	O	O	Reply	608
Disentangling factors of variation in deep representation using adversarial training.	O	O	Reply	608
In Advances in Neural Information Processing Systems, pp.5040‚Äì5048, 2016.	O	O	Reply	608
<sep> [3] Samuel R Bowman, Luke Vilnis, Oriol Vinyals, Andrew M Dai, Rafal Jozefowicz, and Samy Bengio.	O	O	Reply	608
<sep> Generating sentences from a continuous space.	O	O	Reply	608
arXiv preprint arXiv:1511.06349, 2015.	O	O	Reply	608
<sep> [4] Alec Radford, Luke Metz, and Soumith Chintala.	O	O	Reply	608
Unsupervised representation learning with deep convolutional generative adversarial networks.	O	O	Reply	608
arXiv preprint arXiv:1511.06434, 2015.	O	O	Reply	608
<sep> [5] Lars Mescheder, Sebastian Nowozin, and Andreas Geiger.	O	O	Reply	608
Adversarial variational bayes: Unifying variational autoencoders and generative adversarial networks.	O	O	Reply	608
In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pp.2391‚Äì2400.	O	O	Reply	608
JMLR.	O	O	Reply	608
org, 2017.	O	O	Reply	608
<sep> [6] David Ha and Douglas Eck.	O	O	Reply	608
A neural representation of sketch drawings.	O	O	Reply	608
arXiv preprint arXiv:1704.03477, 2017.	O	O	Reply	608
<sep> [7] Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.	O	O	Reply	608
Density estimation using real nvp.	O	O	Reply	608
arXiv preprint arXiv:1605.08803, 2016.	O	O	Reply	608
<sep> [8] Anders Boesen Lindbo Larsen, S√∏ren Kaae S√∏nderby, Hugo Larochelle, and Ole Winther.	O	O	Reply	608
Autoencoding beyond pixels using a learned similarity metric.	O	O	Reply	608
arXiv preprint arXiv:1512.09300, 2015.	O	O	Reply	608
<sep> [9] Aaron Van den Oord, Nal Kalchbrenner, Lasse Espeholt, Oriol Vinyals, Alex Graves, et al Conditional image generation with pixelcnn decoders.	O	O	Reply	608
In Advances in neural information processing systems, pp.4790‚Äì4798, 2016.	O	O	Reply	608
<sep> [10] Yongyi Lu, Yu-Wing Tai, and Chi-Keung Tang.	O	O	Reply	608
Attribute-guided face generation using conditional cyclegan.	O	O	Reply	608
In Proceedings of the European Conference on Computer Vision (ECCV), pp.282‚Äì297, 2018.	O	O	Reply	608
<sep> [11] Zhenliang He, Wangmeng Zuo, Meina Kan, Shiguang Shan, and Xilin Chen.	O	O	Reply	608
Attgan: Facial attribute editing by only changing what you want.	O	O	Reply	608
IEEE Transactions on Image Processing, 2019.	O	O	Reply	608

Summary	O	O	Review	608
<sep> This work aims to provide warranties on the outputs of generative models by providing bounds on robustness&nbsp;(over adversarial attacks for instance, or other transformation in this case).	O	O	Review	608
The specific case of restricting the inputs to a line segment allows performing verification of robustness exactly (Exact-line approach, NeurIPS'19).	O	O	Review	608
The authors extend this work and apply it to verify robustness of some VAE and BEGAN like models.	O	O	Review	608
<sep> <sep> Positive aspects:	O	O	Review	608
- Rigorous work, I did not spot much typos.&nbsp;	O	O	Review	608
- First proofs given for generative models.	O	O	Review	608
<sep> <sep> Negative aspects:	O	O	Review	608
<sep> My main concern about this work is that the presentation is not didactic enough.	O	O	Review	608
<sep> - From the beginning, key concepts are not clearly defined, such as network certification, specification, and the "verification problem".	B-Review	B-2	Review	608
In the definition of robustness, a reference to a "safe set of outputs", as in Gehr et al would help the understanding.	I-Review	I-2	Review	608
<sep> - The introduction is too short and lacks context.	B-Review	B-3	Review	608
Figure 1 is not referred&nbsp;in the text and is not understandable with notations that are not yet introduced.&nbsp;	I-Review	I-3	Review	608
- Then follows without transition two pages of background that are mostly definitions but without&nbsp;a proper motivation, these are difficult to process.	B-Review	B-4	Review	608
<sep> - The work, an extension of the Exact-line approach, only gives a 5 lines description which is not insufficient to understand the approach.&nbsp;	B-Review	B-5	Review	608
<sep> Perhaps my assessment is too negative because I am unfamiliar with the certification literature, but since the work present applications in generative modeling, I think it should be understandable by readers from this background as well.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;	O	O	Review	608
Minor:	B-Review	B-1	Review	608
of of in caption of Fig 2	I-Review	I-1	Review	608
last line of page 5: J -&gt; j	I-Review	I-1	Review	608
I found the equivalence sign in the last equation of page 6 confusing, is it really supposed to be an equivalence here?&nbsp;	I-Review	I-1	Review	608
Page 6 : attribute detector... described below -&gt; in appendix	I-Review	I-1	Review	608
<sep> After seeing the authors changes in the manuscript the paper does look better, but similarly to Reviewer 2 I still judge it difficult to understand.	O	O	Review	608
We thank you for your review, and have fixed the typos that have been spotted.	B-Reply	B-1	Reply	608
While Figure 1 is referred to on the first page in the original version, we agree that this is insufficient and have added an overview which we hope explains it and our methods better.	B-Reply	B-5	Reply	608
As per your suggestion, we included these relevant definitions, and added pseudocode which will hopefully help explain our extensions to ExactLine.	I-Reply	I-5	Reply	608

This paper proposes two methods for instance-wise feature importance scoring, which is the task of ranking the importance of each feature in a particular example (in contrast to class-wise or overall feature importance).	O	O	Review	386
The approach uses Shapely values, which are a principled way of measuring the contribution of a feature, and have been previously used in feature importance ranking.	O	O	Review	386
<sep> <sep> The difficulty with Shapely values is they are extremely (exponentially) expensive to compute, and the contribution of this paper is to provide two efficient methods of computing approximate Shapely values when there is a known structure (a graph) relating the features to each other.	O	O	Review	386
<sep> <sep> The paper first introduces the L(ocal)-Shapely value, which arises by restricting the Shapely value to a neighbourhood of the feature of interest.	O	O	Review	386
The L-Shapely value is still expensive to compute for large neighbourhoods, but can be tractable for small neighbourhoods.	O	O	Review	386
<sep> <sep> The second approximation is the C(onnected)-Shapely value, which further restricts the L-Shapely computation to only consider connected subgraphs of local neighbourhoods.	O	O	Review	386
The justification for restricting to connected neighbourhoods is given through a connection to the Myerson value, which is somewhat obscure to me, since I am not familiar with the relevant literature.	O	O	Review	386
Nonetheless, it is clear that for the graphs of interest in this paper (chains and lattices) restricting to connected neighbourhoods is a substantial savings.	O	O	Review	386
<sep> <sep> I have understood the scores presented in Figures 2 and 3 as follows:	B-Review	B-1	Review	386
<sep> For each feature of each example, rank the features according to importance, using the plugin estimate for P(Y|X_S) where needed.	I-Review	I-1	Review	386
<sep> For each "percent of features masked" compute log(P(y_true | x_{S\top features})) - log(P(y_true | x)) using the plugin estimate, and average these values over the dataset.	I-Review	I-1	Review	386
<sep> <sep> Based on this understanding the results are quite good.	O	O	Review	386
The approximate Shapely values do a much better job than their competitors of identifying highly relevant features based on this measure.	O	O	Review	386
The qualitative results are also quite compelling, especially on images where C-Shapely tends to select contiguous regions which is intuitively correct behavior.	O	O	Review	386
<sep> <sep> Comparing the different methods in Figure 4, there is quite some variability in the features selected by using different estimators of Shapley values.	B-Review	B-2	Review	386
I wonder is there some way to attack the problem of distinguishing when a feature is ranked highly when its (exact) Shapley value is high versus when it is ranked highly as an artifact of the estimator?	I-Review	I-2	Review	386
<sep> <sep> We thank the reviewer for the detailed and encouraging comments!	O	O	Reply	386
Based on the suggestions from the reviewer, we have included an experiment in the updated version that measures the correlation between L-Shapley, C-Shapley and the Shapley value.	O	O	Reply	386
<sep> <sep> ‚ÄúUnderstanding of the evaluation metric‚Äù:	O	O	Reply	386
<sep> The evaluation metric we use is the following:	B-Reply	B-1	Reply	386
log(P(y_pred | x)) - log(P(y_pred | x_{top features MASKED})).	I-Reply	I-1	Reply	386
The reviewer's understanding is in general correct except that we use the predicted label instead of the true label in the data set, because we hope to find key features for why the model makes its own decision.	I-Reply	I-1	Reply	386
<sep> ‚ÄúI wonder is there some way to attack the problem of distinguishing when a feature is ranked highly when its (exact) Shapley value is high versus when it is ranked highly as an artifact of the estimator?‚Äù	O	O	Reply	386
<sep> We have added a new experiment in the updated version to address the problem of how the rank of features correlates with the rank produced by the true Shapley value.	B-Reply	B-2	Reply	386
We sample a subset of test data from Yahoo!	I-Reply	I-2	Reply	386
Answers with 9-12 words, so that the underlying Shapley scores can be accurately computed.	I-Reply	I-2	Reply	386
We employ two common metrics, Kendall's Tau and Spearman's Rho to measure the similarity (correlation) between two ranks.	I-Reply	I-2	Reply	386
We have observed a high rank correlation between our algorithms and the Shapley value.	I-Reply	I-2	Reply	386
See the figure in the link below, and also Appendix C for more details:	I-Reply	I-2	Reply	386
<a href="https://drive.google.com/open?id=1oWsWyA4IkDIbaOjwOOwMAYJzu6kUuQSa" target="_blank" rel="nofollow">https://drive.google.com/open?id=1oWsWyA4IkDIbaOjwOOwMAYJzu6kUuQSa</a>	I-Reply	I-2	Reply	386

This paper provides new methods for estimating Shapley values for feature importance that include notions of locality and connectedness.	O	O	Review	386
The methods proposed here could be very useful for model explainability purposes, specifically in the model-agnostic case.	O	O	Review	386
The results seem promising, and it seems like a reasonable and theoretically sound methodology.	O	O	Review	386
In addition to the theoretical properties of the proposed algorithms, they do show a few quantitative and qualitative improvements over other black-box methods.	O	O	Review	386
They might strengthen their paper with a more thorough quantitative evaluation.	O	O	Review	386
<sep> <sep> I think the KernelSHAP paper you compare against (Lundberg & Lee 2017) does more quantitative evaluation than what‚Äôs presented here, including human judgement comparisons.	O	O	Review	386
Is there a way to compare against KernelSHAP using the same evaluation methods from the original paper?	B-Review	B-1	Review	386
<sep> <sep> Also, you mention throughout the paper that the L-shapley and C-shapley methods can easily complement other sampling/regression-based methods.	B-Review	B-2	Review	386
It's a little ambiguous to me whether this was actually something you tried in your experiments or not.	I-Review	I-2	Review	386
Can you please clarify?	I-Review	I-2	Review	386
We thank the reviewer for the detailed suggestions and encouraging comments!	O	O	Reply	386
We have included an experiment with human evaluation in the updated version.	O	O	Reply	386
Below we respond to Reviewer 1‚Äôs questions in details.	O	O	Reply	386
<sep> <sep> ‚ÄúIs there a way to compare against KernelSHAP using the same (human) evaluation methods from the original paper?‚Äù	O	O	Reply	386
<sep> We agree with the reviewer that human evaluation is important in this area, and we have added a new experiment with human evaluation in the updated version.	B-Reply	B-1	Reply	386
<sep> <sep> In KernelSHAP paper, the authors designed experiments to argue for the use of Shapley value instead of LIME, which shows Shapley value is more consistent with human intuition on a data set with only a few number of features.	I-Reply	I-1	Reply	386
Both KernelSHAP and our algorithms are ways of approximating Shapley value when there is a large number of features, under which case the exact same experiment is difficult to replicate.	I-Reply	I-1	Reply	386
<sep> <sep> We have designed two experiments by ourselves involving human evaluation for our methods and KernelSHAP on IMDB in the updated version.	I-Reply	I-1	Reply	386
We assume that the key words contain an attitude toward a movie and can be used to infer the sentiment of a review.	I-Reply	I-1	Reply	386
In the first experiment, we ask humans to infer the sentiment of a review within a range of -2 to 2, given the key words selected by different model interpretation approaches.	I-Reply	I-1	Reply	386
Second, we also ask humans to infer the sentiment of a review with top words being masked, where words are masked until the predicted class gets a probability score of 0.1.	I-Reply	I-1	Reply	386
In both experiments, we evaluate the consistency with truth, the agreement between humans on a single review by standard deviation, and the confidence of their decision via the absolute value of the score.	I-Reply	I-1	Reply	386
We observe L-Shapley and C-Shapley take the lead respectively in two experiments.	I-Reply	I-1	Reply	386
See the table and an example interface in the links below, and also Section 5.3 for more details:	I-Reply	I-1	Reply	386
<a href="https://drive.google.com/open?id=1aHZPP0ZAdyODgTEFLRrQAKyS4uJ8h-XS" target="_blank" rel="nofollow">https://drive.google.com/open?id=1aHZPP0ZAdyODgTEFLRrQAKyS4uJ8h-XS</a>	I-Reply	I-1	Reply	386
<a href="https://drive.google.com/file/d/1_HOR28DGlKqEQVplGahv47o2xPe5lT5e/view?usp=sharing" target="_blank" rel="nofollow">https://drive.google.com/file/d/1_HOR28DGlKqEQVplGahv47o2xPe5lT5e/view?usp=sharing</a>	I-Reply	I-1	Reply	386
<sep> ‚ÄúIt's a little ambiguous to me whether you tried to complement other sampling/regression-based methods in your experiments or not.	O	O	Reply	386
Can you please clarify?‚Äù	O	O	Reply	386
<sep> In the experiments, we didn't combine our approach with sampling based methods as the number of model evaluations is already small enough in the setting (linear in the number of features).	B-Reply	B-2	Reply	386

The paper proposes two approximations to the Shapley value used for generating feature scores for interpretability.	O	O	Review	386
Both exploit a graph structure over the features by considering only subsets of neighborhoods of features (rather than all subsets).	O	O	Review	386
The authors give some approximation guarantees under certain Markovian assumptions on the graph.	O	O	Review	386
The paper concludes with experiments on text and images.	O	O	Review	386
<sep> <sep> The paper is generally well written, albeit somewhat lengthy and at times repetitive (I would also swap 2.1 and 2.2 for better early motivation).	O	O	Review	386
The problem is important, and exploiting graphical structure is only natural.	O	O	Review	386
The authors might benefit from relating to other fields where similar problems are solved (e.g., inference in graphical models).	O	O	Review	386
The approximation guarantees are nice, but the assumptions may be too strict.	O	O	Review	386
The experimental evaluation seems valid but could be easily strengthened (see comments).	O	O	Review	386
<sep> <sep> Comments:	O	O	Review	386
<sep> 1.	O	O	Review	386
The coefficients in Eq. (6) could be better explained.	B-Review	B-1	Review	386
<sep> <sep> 2.	O	O	Review	386
The theorems seem sound, but the Markovian assumption is rather strict, as it requires that a feature i has an S that "separates" over *all* x (in expectation).	B-Review	B-2	Review	386
This goes against the original motivation that different examples are likely to have different explanations.	I-Review	I-2	Review	386
When would this hold in practice?	I-Review	I-2	Review	386
<sep> <sep> 3.	O	O	Review	386
While considering chains for text is valid, the authors should consider exploring other graph structures (e.g., parsing trees).	B-Review	B-3	Review	386
<sep> <sep> 4.	O	O	Review	386
For Eqs. (	B-Review	B-4	Review	386
8) and (9), I could not find the definition of Y. Is this also a random variable representing examples?	I-Review	I-4	Review	386
<sep> <sep> 5.	O	O	Review	386
The authors postulate that sampling-based methods are susceptible to high variance.	B-Review	B-5	Review	386
Showing this empirically would have strengthened their claim.	I-Review	I-5	Review	386
<sep> <sep> 6.	O	O	Review	386
Can the authors empirically quantify Eqs. (	B-Review	B-6	Review	386
8) and (9)?	I-Review	I-6	Review	386
This might shed light as to how realistic the assumptions are.	I-Review	I-6	Review	386
<sep> <sep> 7.	O	O	Review	386
In the experiments, it would have been nice to see how performance and runtime vary with increased neighborhood sizes.	B-Review	B-7	Review	386
This would have quantified the importance of neighborhood size and robustness to hyper-parameters.	I-Review	I-7	Review	386
<sep> <sep> 8.	O	O	Review	386
For the image experiments, since C-Shapley considers connected subsets, it is perhaps not surprising that Fig.4 shows clusters for this method (and not others).	B-Review	B-8	Review	386
Why did the authors not use superpixels as features?	I-Review	I-8	Review	386
This would have also let them compare to LIME and L-Shapley.	I-Review	I-8	Review	386
<sep> <sep> <sep> 1. ‚	O	O	Reply	386
ÄúCoefficients in Eq. (6)‚Äù	O	O	Reply	386
<sep> The coefficients are derived from Myerson value, which can be interpreted as the Shapley value for the coalition game with a graph structure.	B-Reply	B-1	Reply	386
The details can be found in the proof of Theorem 2.	I-Reply	I-1	Reply	386
In particular, Equation (22) in the Appendix provides the concrete procedure of derivation.	I-Reply	I-1	Reply	386
<sep> <sep> 2. "	O	O	Reply	386
The Markovian assumption is rather strict."	O	O	Reply	386
<sep> <sep> We thank the reviewer for addressing this point.	B-Reply	B-2	Reply	386
We agree with the reviewer that Markovian assumption introduces bias in explanation, which aims for a better bias-variance trade-off when approximating Shapley values on structured data.	I-Reply	I-2	Reply	386
Theorem 1 and Theorem 2 quantify the introduced bias under the setting when the Markovian assumption is approximately true.	I-Reply	I-2	Reply	386
We also show on real data such an approximation achieves a better bias-variance trade-off empirically when the number of model evaluations is linear in the number of features.	I-Reply	I-2	Reply	386
<sep> <sep> 3. "	O	O	Reply	386
Use other graph structures like parse trees on language."	O	O	Reply	386
<sep> <sep> The reviewer made a very bright proposal.	B-Reply	B-3	Reply	386
As the current paper focuses on the study of the generic setting where data with graph structure, we only use the simplest possible model on language to demonstrate the validity of the proposed algorithms.	I-Reply	I-3	Reply	386
But the proposed idea can be a promising future direction.	I-Reply	I-3	Reply	386
The authors have been thinking along the same direction for a while.	I-Reply	I-3	Reply	386
One question one could ask is whether there exists a better solution concept in coalitional game theory under the setting of a parse tree.	I-Reply	I-3	Reply	386
Related literature includes [1] and [2] if the reviewer is interested to think about this further.	I-Reply	I-3	Reply	386
<sep> <sep> 4. "	O	O	Reply	386
Y in Eqs. (	O	O	Reply	386
8) and (9)."	O	O	Reply	386
<sep> <sep> We assume the model has the form P_m(Y|X).	B-Reply	B-4	Reply	386
Y is the response variable from the model.	I-Reply	I-4	Reply	386
<sep> <sep> 5. ‚	O	O	Reply	386
ÄúThe authors postulate that sampling-based methods are susceptible to high variance.	O	O	Reply	386
Show this empirically.	O	O	Reply	386
‚Äù	O	O	Reply	386
<sep> We have added an experiment in the updated version addressing the statistical dispersion of estimates of the Shapley value produced by sampling-based methods.	B-Reply	B-5	Reply	386
Two commonly used nonparametric metrics are introduced to measure the statistical dispersion between different runs of a common sampling-based method, as the number of model evaluations is varied.	I-Reply	I-5	Reply	386
Figure in the link below shows the variability of SampleShapley and KernelSHAP as a function of the number of model evaluations:	I-Reply	I-5	Reply	386
<a href="https://drive.google.com/file/d/1yUvJ_Jqn2Bg16U-poEtMcTGfWifIcQ3_/view?usp=sharing" target="_blank" rel="nofollow">https://drive.google.com/file/d/1yUvJ_Jqn2Bg16U-poEtMcTGfWifIcQ3_/view?usp=sharing</a>	I-Reply	I-5	Reply	386
See also Appendix E for details.	I-Reply	I-5	Reply	386
<sep> <sep> 6. "	O	O	Reply	386
Empirically quantify Eqs. (	O	O	Reply	386
8) and (9)."	O	O	Reply	386
<sep> <sep> While we agree with the reviewer that a good empirical quantification of quantities in Eqs. (	B-Reply	B-6	Reply	386
8) and (9) can verify the assumptions in practice, it is rather difficult to get a reliable estimate of the conditional mutual information (or similar quantities) in the high dimensional regime.	I-Reply	I-6	Reply	386
We have added one experiment in the updated version to validate the correlation between our algorithms and the Shapley value directly, which partially reflects the conclusion of our theorem.	I-Reply	I-6	Reply	386
See the figure in the link below and Appendix C for details: <a href="https://drive.google.com/file/d/1oWsWyA4IkDIbaOjwOOwMAYJzu6kUuQSa/view?usp=sharing" target="_blank" rel="nofollow">https://drive.google.com/file/d/1oWsWyA4IkDIbaOjwOOwMAYJzu6kUuQSa/view?usp=sharing</a>	I-Reply	I-6	Reply	386
<sep> The better performance on real data in terms of log-odds ratio decay when top features are masked may also be viewed as a partial empirical evidence on the fact that the introduced bias is not as big as the reduced variance.	I-Reply	I-6	Reply	386
<sep> <sep> 7. ‚	O	O	Reply	386
Äúit would have been nice to see how performance and runtime vary with increased neighborhood sizes‚Äù	O	O	Reply	386
<sep> We have included a section for sensitivity analysis of our algorithms in the updated version.	B-Reply	B-7	Reply	386
We study how correlation between the proposed algorithms and the Shapley value vary with the radius of neighborhood, the only hyper-parameter in our algorithms.	I-Reply	I-7	Reply	386
A plot of model evaluations against the radius of neighborhood is also included.	I-Reply	I-7	Reply	386
See the figures in the link below, and also Appendix D for details:	I-Reply	I-7	Reply	386
<a href="https://drive.google.com/open?id=1perbCh7oH95j3uDp6jNEM0vPvUvcUkZ8" target="_blank" rel="nofollow">https://drive.google.com/open?id=1perbCh7oH95j3uDp6jNEM0vPvUvcUkZ8</a>	I-Reply	I-7	Reply	386
<a href="https://drive.google.com/file/d/1f5yBIwxd85tyxQKB5gBlRtBX4pRe0noL/view?usp=sharing" target="_blank" rel="nofollow">https://drive.google.com/file/d/1f5yBIwxd85tyxQKB5gBlRtBX4pRe0noL/view?usp=sharing</a>	I-Reply	I-7	Reply	386
<sep> 8. "	O	O	Reply	386
Not use superpixels as features."	O	O	Reply	386
<sep> <sep> We agree with the reviewer that using superpixels may lead to better visualization results.	B-Reply	B-8	Reply	386
However, this leads to a performance decay in terms of the change in log-odds ratio when a fixed number of pixels are masked.	I-Reply	I-8	Reply	386
The same issue has been addressed in [3]. For fairness of comparison, we use the raw pixels as features for all methods.	I-Reply	I-8	Reply	386
<sep> <sep> [1] Winter, Eyal. "	O	O	Reply	386
A value for cooperative games with levels structure of cooperation."	O	O	Reply	386
International Journal of Game Theory 18.2 (1989): 227-240.	O	O	Reply	386
<sep> [2] Faigle, Ulrich, and Walter Kern. "	O	O	Reply	386
The Shapley value for cooperative games under precedence constraints."	O	O	Reply	386
International Journal of Game Theory 21.3 (1992): 249-266.	O	O	Reply	386
<sep> [3] Lundberg, Scott M., and Su-In Lee. "	O	O	Reply	386
A unified approach to interpreting model predictions."	O	O	Reply	386
Advances in Neural Information Processing Systems.	O	O	Reply	386
2017.	O	O	Reply	386

This paper proposes to learn entity representations by matching entities to the context it occurs in.	O	O	Review	386
It also shows that using these representations is very effective for a wide variety of down-stream entity-centric tasks such as entity typing, linking, and answering entity centric trivia questions.	O	O	Review	386
They train the model using a corpus of entity linked Wikipedia contexts (sentences unto length 128 tokens).	O	O	Review	386
The context is encoded with a BERT model and the CLS representation is used as the representation of context.	O	O	Review	386
After obtaining the representation, they train the entity embedding (present in the sentence) to be similar to the context embedding.	O	O	Review	386
They test their embeddings on few down-stream entity-centric tasks ‚Äî linking, typing and trivia question answering.	O	O	Review	386
<sep> <sep> Strengths:	O	O	Review	386
1.	O	O	Review	386
They try the entity representations on a wide variety of entity-centric tasks and get reasonable results.	O	O	Review	386
<sep> <sep> Weaknesses:	O	O	Review	386
1.	B-Review	B-1	Review	386
The biggest weakness of the paper is wrt novelty.	I-Review	I-1	Review	386
Masking out entities and training to context is not a new idea.	I-Review	I-1	Review	386
As pointed by the paper, Yamada et al 2017 have a very similar objective and it is not very clear from the paper what is the additional contribution that this paper makes.	I-Review	I-1	Review	386
Is using pretrained LMs the major difference?	I-Review	I-1	Review	386
If not, it would have been nice to see Yamada et al‚Äôs results with BERT.	I-Review	I-1	Review	386
Over all, this paper needs to make its own contribution clear compared to Yamada et al 2017.	I-Review	I-1	Review	386
<sep> 2.	O	O	Review	386
The paper needs to be written more clearly at several places.	B-Review	B-2	Review	386
Few examples are, even though in entity linking results (Table 1) the model achieves 83.0 with other papers achieving 90.9.	I-Review	I-2	Review	386
I didnt see a discussion on how to close the gap.	I-Review	I-2	Review	386
Even in the coNLL benchmark, the initial results of the paper is significantly behind.	I-Review	I-2	Review	386
Claims like ‚ÄúCoNLL -Aida is known to be restricted and idiotic-synctatic domain‚Äù should be backed by detailed analysis or atleast a citation.	I-Review	I-2	Review	386
Even after finetuning on the CoNLL benchmark, the result is 2.2 points behind state of the art and no discussions have been provided.	I-Review	I-2	Review	386
As a result, I think the entity linking section needs major re-writing and explanation of the results.	I-Review	I-2	Review	386
<sep> 3.	B-Review	B-3	Review	386
The paper makes an interesting observation that masking of entities is better for typing tasks and it affects linking performance, because spelling features are really important for linking.	I-Review	I-3	Review	386
It would be interesting to see a discussion on what could be done to remedy this.	I-Review	I-3	Review	386
Because if we have to retrain entity embeddings for different tasks, then it goes against the hypothesis of the paper which is to use entity representations for a wide variety of down-stream tasks.	I-Review	I-3	Review	386
<sep> 4.	O	O	Review	386
I found it confusing to read the setup in sec 5.4.	B-Review	B-4	Review	386
especially where it says we represent each category with three random exemplars.	I-Review	I-4	Review	386
Initially I thought 3 randomly sampled entities formed a category, which didnt make sense, but from figure 3, I think I understood that you first pick a category from Typenet and Wikipedia and then 3 entities are sampled from there.	I-Review	I-4	Review	386
Is that correct?	I-Review	I-4	Review	386
Regarding the results, can the poor results of Yamada et al can be understood by the fact that it was trained using smaller number of categories?	I-Review	I-4	Review	386
Also, why are the numbers wrt All entities left blank in Table 4.	I-Review	I-4	Review	386
Given that your model is similar, I am assuming its easy to retrain Yamada et al and test it on the all entities benchmark?	I-Review	I-4	Review	386
Thank you for your review and detailed questions.	O	O	Reply	386
<sep> <sep> As discussed in the response to all reviewers, we agree that RELIC's model architecture is not particularly novel.	B-Reply	B-1	Reply	386
We believe that this paper's contribution is in the extensive, and novel, experiments that go well beyond previous work in testing the extent to which embeddings learned from textual context can capture the knowledge required for a wide range of entity-centric tasks.	I-Reply	I-1	Reply	386
<sep> <sep> In response to your questions about our entity linking results we have updated our experiments to be more in line with other entity linking approaches.	B-Reply	B-2	Reply	386
First, we have adopted the same CoNLL alias table used by most other recent approaches.	I-Reply	I-2	Reply	386
Second, we reduced the TAC-KBP entity candidate set to only those entities in the TAC-KBP knowledge base (a reduction of 5m -&gt; 818k candidates).	I-Reply	I-2	Reply	386
Third we have updated provided the RELIC model with the start of each document, as well as the immediate context surrounding each entity mention.	I-Reply	I-2	Reply	386
<sep> <sep> Together, these modifications have brought RELIC's performance up to match the state of the art on CoNLL (94.9%), and second only to DeepType on TAC-KBP (RELIC: 89.8%, DeepType: 90.9%).	I-Reply	I-2	Reply	386
DeepType relies on the large Wikidata knowledge base for entity representations and we consider it significant that RELIC can match this system's performance with embeddings learned purely from context.	I-Reply	I-2	Reply	386
We discuss our modifications more in the response to all reviewers, as well as the updated paper.	I-Reply	I-2	Reply	386
<sep> <sep> As well as reporting the performance of the RELIC model that has been tuned toward the entity linking task (CoNLL + Aida tuning), we do still report the performance of the pure RELIC model that has never seen any in-domain data, and which does not have access to any alias table.	I-Reply	I-2	Reply	386
As you point out, these results do lag behind the state of the art but we hope that our new experiments show what is responsible for the gap between the pure model's performance, and the state of the art.	I-Reply	I-2	Reply	386
<sep> <sep> In response to your criticism of our vague characterisation of the CoNLL task, we have rewritten the entity linking section to focus on the specifics of how specialised entity linking approaches differ from the pure RELIC model.	B-Reply	B-2	Reply	386
Thank you for this suggestion, we believe that the section is now much more robust and meaningful.	I-Reply	I-2	Reply	386
<sep> <sep> We are glad that you found our investigation of the masking rates to be interesting and we would like to highlight that, simple as it is, masking mentions is a novelty of this paper not shared by previous work that focused on entity linking.	B-Reply	B-3	Reply	386
Thank you also for your observation that RELIC's broad utility is hindered by the different optimum mask rates for entity linking and typing tasks.	I-Reply	I-3	Reply	386
We have updated the paper with a discussion of optimum mask rates.	I-Reply	I-3	Reply	386
We consider the choosing of an optimum mask rate to be an ongoing research question, and we plan to experiment with variable mask rates that account for variation in entity frequency.	I-Reply	I-3	Reply	386
<sep> <sep> Finally, in response to your question about section 5.4, we have clarified the contents of Table 4.	B-Reply	B-4	Reply	386
There are two settings for both the TypeNet and Wikipedia category completion tasks.	I-Reply	I-4	Reply	386
The first contains all entities in each of those domains and the second (Yamada Subset) only contains the entities covered by the embedding table provided by Yamada et.al.	I-Reply	I-4	Reply	386
(<a href="https://github.com/studio-ousia/ntee)."	I-Reply	I-4	Reply	386
target="_blank" rel="nofollow">https://github.com/studio-ousia/ntee).</a> All of the comparisons between RELIC and Yamada use exactly the same entity and category vocabulary and the row for Yamada et.al.	I-Reply	I-4	Reply	386
is left blank in the "All Entities" column because their embedding table does not contain all of the entities in this set.	I-Reply	I-4	Reply	386
Since we perform a comparison to Yamada et.al.	I-Reply	I-4	Reply	386
by using their provided embeddings, on their entity vocabulary, and with no further task specific training for either approach, we believe that this is the cleanest comparison that we can make between the RELIC and Yamada entity embedding tables on an entity typing task.	I-Reply	I-4	Reply	386

<sep> This paper aims to learn entity representations by aggregating all the contexts that an entity appears in based on English Wikipedia.	O	O	Review	386
<sep> <sep> The idea is very simple, basically it represents each entity as a vector, and also represents each context as a vector, and maximizes the cosine similarity between the two vectors using a negative-sampling training objective.	B-Review	B-1	Review	386
The training process is similar as word2vec, and they leveraged all the hyperlinks in Wikipedia, and used BERT to encode the context (instead of learning a context vector for each word).	O	O	Review	386
<sep> <sep> As a result, the paper demonstrates that this set of entity embeddings are highly useful, and they were evaluated on 1) entity-level typing 2) entity linking 3) few-shot category reconstruction 4) answering trivia questions (TriviaQA).	O	O	Review	386
<sep> <sep> I think this is a nice empirical paper and the experiments are thorough.	O	O	Review	386
If they are going to release the entity embeddings, that would also benefit the community a lot and also encourage more research in this direction.	B-Review	B-1	Review	386
<sep> <sep> I am a bit concerned about the novelty of the approach.	B-Review	B-2	Review	386
It is a bit surprising that nobody has experimented with this before.	I-Review	I-2	Review	386
It seems that Yamada et al took a very similar approach but used simple bag-of-words approaches to encode the context (instead of BERT).	I-Review	I-2	Review	386
To me, this paper may be better for the NLP community but it should be fine to the ICLR community too.	I-Review	I-2	Review	386
<sep> <sep> I am also not completely sure how strong the evaluation results are indeed, esp.	B-Review	B-3	Review	386
related to the comparisons with Yamada et al, 2017, given the approaches are similar.	I-Review	I-3	Review	386
<sep> <sep> - It seems to be on par with or slightly worse than Yamada et al 2017 on entity linking.	I-Review	I-3	Review	386
<sep> <sep> - For the category completion task, RELIC is doing much better than Yamada et al 2017 on more complex Wikipedia categories but I am not sure if it is a completely fair comparison.	I-Review	I-3	Review	386
It‚Äôd be great if the authors can discuss all the key differences between the two approaches, from the model design to all the experimental details, that would help clear out all these confusions.	I-Review	I-3	Review	386
I have read the related work section but can't figure out all the details.	I-Review	I-3	Review	386
<sep> <sep> - The entity typing results are very strong.	I-Review	I-3	Review	386
I also like the TriviaQA experiments but the numbers are way behind the standard reading comprehension results.	I-Review	I-3	Review	386
<sep> <sep> <sep> Minor comment:	O	O	Review	386
- Why sec 5.3 (effect of masking) is listed together with other evaluation tasks?	B-Review	B-4	Review	386
Isn‚Äôt better to move it to analyses/ablation studies?	I-Review	I-4	Review	386
<sep> <sep> Thank you for your response and careful questions.	O	O	Reply	386
We agree that the RELIC model is simple and that the value of this paper is in the experiments which demonstrates the utility of these entity embeddings for a variety of tasks beyond entity linking.	B-Reply	B-1	Reply	386
We do plan to release the table of RELIC embeddings and we hope that these will be useful to the community in much the same way that word embeddings have been.	I-Reply	I-1	Reply	386
<sep> <sep> It is correct that RELIC's performance on TriviaQA is far behind that of the standard reading comprehension systems that have access to documents which are known to contain the answer.	B-Reply	B-3	Reply	386
However, RELIC is solving a much harder task and to provide a more meaningful benchmark, we have updated the paper with a comparison to Lee et.al.	I-Reply	I-3	Reply	386
2019's results on the open domain version of TriviaQA.	I-Reply	I-3	Reply	386
We discuss this comparison fully in the response to all reviewers and we are happy to say that RELIC's fast inner product search over 5m candidate answers captures 80% of the performance of Lee et.al.'s method, which relies on inference time reading of evidence text using an expensive BERT based model.	I-Reply	I-3	Reply	386
<sep> <sep> To perform the comparison with Yamada et.al.	I-Reply	I-3	Reply	386
we downloaded embeddings from their website (<a href="https://github.com/studio-ousia/ntee)," target="_blank" rel="nofollow">https://github.com/studio-ousia/ntee),</a> filtered the entities in the Wikipedia category completion task to only those covered by Yamada et.al.'s embedding table, and then ran the same evaluation script that was used to evaluate the RELIC embeddings.	I-Reply	I-3	Reply	386
As there is no task specific training for the Wikipedia category completion task, we believe that this is the cleanest comparison that we could make between the RELIC embedding table and the downloaded embeddings.	I-Reply	I-3	Reply	386
<sep> <sep> You make the valid point that the masking ablations are somewhat out of place in the primary results section.	B-Reply	B-4	Reply	386
However, we would like to point out that, despite the obvious simplicity of this experiment, we do believe that it is both novel and crucial to RELIC's success at entity typing and question answering.	I-Reply	I-4	Reply	386
All previous related work, such as that of Yamada et.al.,	I-Reply	I-4	Reply	386
has been geared toward entity linking and it subsequently does not experiment with mention masking (ignoring entity names is a ridiculous decision in the context of entity linking).	I-Reply	I-4	Reply	386
Conversely, for entity typing and question answering---where the name is by definition absent---entity masking is essential.	I-Reply	I-4	Reply	386
Simple as it is, we consider this experiment to be a key contribution of the paper.	I-Reply	I-4	Reply	386
<sep> <sep> Finally, we would like to alert you to the modifications that we have made to the entity linking experiments, to provide a cleaner comparison to previous work.	B-Reply	B-3	Reply	386
By simply reducing the search space to be more in line with other work, and also expanding the context available to the RELIC model, we now match the state of the art system which relies on a large hand engineered knowledge base.	I-Reply	I-3	Reply	386
Our modifications, and their significance are discussed fully in the response to all reviewers, as well as the updated paper.	I-Reply	I-3	Reply	386
<sep> <sep> ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî	O	O	Reply	386
<sep> Latent Retrieval for Weakly Supervised Open Domain Question Answering	O	O	Reply	386
Kenton Lee, Ming-Wei Chang, Kristina Toutanova (2019)	O	O	Reply	386
<a href="https://www.aclweb.org/anthology/P19-1612/" target="_blank" rel="nofollow">https://www.aclweb.org/anthology/P19-1612/</a>	O	O	Reply	386

The paper describes a new way of learning context dependent entity representations that are capable of encoding fine-grained entity types.	O	O	Review	386
This is realised by matching entities to all their contexts and thereby encoding all their properties.	O	O	Review	386
<sep> The contribution is RELIC, a table of entity representations that are learned given the above objective.	O	O	Review	386
This table, RELIC, can be used in various tasks like entity typing, entity linking and question answering.	O	O	Review	386
Given a corpus of entities and their respective contexts, the probability of an entity occurring under its context is maximised (additionally, the probability is minimised for negative samples).	O	O	Review	386
The data is taken from a Wikipedia dump.	O	O	Review	386
Without adding further information, the RELIC table can directly be used for entity linking.	O	O	Review	386
<sep> In the entity linking task, RELIC achieves a lower precision at two benchmarks (CoNLL-Aida, TAC-KBP 2010) than other approaches.	O	O	Review	386
This can be tackled by fine-tuning the RELIC table, which is done with the training set from the CoNLL-Aida task.	O	O	Review	386
With fine-tuning, comparable results are achieved.	O	O	Review	386
<sep> For entity typing, RELIC embeddings of entities are used as input for a 2-layer FF network, which then outputs which types belong to the entity.	O	O	Review	386
The FIGMENT and TypeNet datasets are used as benchmark here and it is shown that the RELIC based approach outperforms the other approaches.	O	O	Review	386
<sep> RELIC is also used for a category completion task, where a category is represented by a centroid of three randomly sampled entities belonging to it.	O	O	Review	386
The entities from RELIC are then ranked with the dot-product with the centroid.	O	O	Review	386
Two tasks are used to measure the performance here: the TypeNet completion task and a Wikipedia-based task.	O	O	Review	386
Compared to embeddings of a 2017 approach, the RELIC embeddings perform better.	O	O	Review	386
<sep> Finally, a QA task is performed using RELIC.	O	O	Review	386
Here, the questions are modelled as contexts and the entity which is closest in terms of cosine similarity is taken as answer.	O	O	Review	386
The performance is below the upper bound from 2018, but better than a classifier system from 2017.	O	O	Review	386
<sep> <sep> Overall, the paper is well structured and manages to show that RELIC is a versatile tool on which various tasks can be performed.	O	O	Review	386
The technical details are well covered and the evaluation is done in a detailed way.	O	O	Review	386
<sep> The contribution of the paper is mostly in the definition of context-entity pairs as input to a transformer model and in empirical evaluations.	O	O	Review	386
I specifically found the findings in 5.3 interesting.	O	O	Review	386
The technological contribution is rather limited.	B-Review	B-1	Review	386
<sep> <sep> Minor comments: At page 3, chapter 3.1 there is a word duplication [‚Ä¶]to correctly match match[‚Ä¶] that should be corrected.	B-Review	B-2	Review	386
Additionally, on page 5 it should be mentioned that the values in table 1 are precision values.	I-Review	I-2	Review	386
Thank you for your thorough reading of the paper and detailed review.	O	O	Reply	386
<sep> <sep> We agree that this paper's modelling contributions are simple, but we also feel that our empirical findings are the main contribution of this paper.	B-Reply	B-1	Reply	386
These go much further than all previous efforts in testing the limits of entity embeddings learned from textual context.	I-Reply	I-1	Reply	386
<sep> <sep> As a point of clarification, we would like to point out that for the TriviaQA question answering task, RELIC is solving a much harder problem than the 2018 upper bound.	I-Reply	I-1	Reply	386
RELIC has to retrieve the single correct answer from all 5m entities that have a Wikipedia page, whereas the 2018 upper bound is performing reading comprehension on a single document that is known to contain the answer (web setting).	I-Reply	I-1	Reply	386
<sep> <sep> We have updated the paper with a more recent and relevant comparison to "Latent Retrieval for Weakly Supervised Open Domain Question Answering" - Kenton Lee et.al.	I-Reply	I-1	Reply	386
2019 (<a href="https://www.aclweb.org/anthology/P19-1612/)."	I-Reply	I-1	Reply	386
target="_blank" rel="nofollow">https://www.aclweb.org/anthology/P19-1612/).</a> Lee et.al.'s approach does still apply a reading comprehension model, but passages that are retrieved from Wikipedia rather than the document provided in TriviaQA's reading comprehension task.	I-Reply	I-1	Reply	386
<sep> <sep> RELIC's answer retrieval approach achieves 80% of the performance of Lee et.al's approach.	I-Reply	I-1	Reply	386
We consider this significant, since Lee et.al.	I-Reply	I-1	Reply	386
rely on an expensive BERT based co-encoding of the question and evidence text at inference time, while RELIC performs a simple nearest neighbour search over 5m pre-indexed answer candidates, which is vastly faster.	I-Reply	I-1	Reply	386
<sep> <sep> We believe that our results: that RELIC can reconstruct complex Wikipedia categories; and that RELIC can directly retrieve answers to trivia questions with 80% of the accuracy of Lee et.al's retrieve-then-read model, are significant and worthy of publication at ICLR despite the simplicity of the RELIC model.	I-Reply	I-1	Reply	386
<sep> <sep> We would also like to alert you to our modification of our entity linking experiments in response to questions from other reviewers.	I-Reply	I-1	Reply	386
By simply reducing RELIC's search space to be more in line with other entity linking work, and adding extra document context to RELIC's text encoder, we have now matched the DeepType entity linking state of the art.	I-Reply	I-1	Reply	386
DeepType relies on the large hand created Wikidata knowledge base for entity representations.	I-Reply	I-1	Reply	386
The fact that RELIC can match DeepType's performance supports our central hypothesis that RELIC is managing to capture the type of knowledge that has previously been encoded by hand in structured knowledge bases.	I-Reply	I-1	Reply	386
We discuss these modifications fully in the response to all reviewers.	I-Reply	I-1	Reply	386

This is a well-written and quite clear work about how a previous work on image compression using deep neural networks can be extended to train representations which are also valid for semantic understanding.	O	O	Review	405
IN particular, the authors tackle the classic and well-known problems of image classification and segmentation.	O	O	Review	405
<sep> <sep> The work evolves around defining a loss function which initially considers only a trade-off between reconstruction error and total bit-rate.	O	O	Review	405
The representations trained with the loss function, at three different operational points, are used as inputs for variations of ResNet (image classification) and DeepLab (segmentation).	O	O	Review	405
The results obtained are similar to a ResNet trained directly over the RGB images, and actually with a slight increase of performance in segmentation.	O	O	Review	405
The most interesting part is a joint training for both compression and image classification.	O	O	Review	405
<sep> <sep> PROS	O	O	Review	405
P.1 Joint training for both compression and classification.	O	O	Review	405
First time to the authors knowledge.	O	O	Review	405
<sep> P.2 Performance on classification and segmentation tasks are very similar when compared to the non-compressed case with state-of-the-art ResNet architectures.	O	O	Review	405
<sep> P.3 Text is very clear.	O	O	Review	405
<sep> P.4 Experimentation is exhaustive and well-reported.	O	O	Review	405
<sep> <sep> CONS	O	O	Review	405
C1.	B-Review	B-1	Review	405
The authors fail into providing a better background regarding the metrics MS-SSIM and SSIM (and PSNR, as well) and their relation to the MSE used for training the network.	I-Review	I-1	Review	405
Also, I missed an explanation about whether high or low values for them are beneficial, as actually results compared to JPEG and JPEG-2000 differ depending on the experiment.	I-Review	I-1	Review	405
<sep> C2.	O	O	Review	405
The main problem is of the work is that, while the whole argument is that in an indexing system it would not be necessary to decompress the representation coded with a DNN, in terms of computation JPEG2000 (and probably JPEG) are much lighter that coding with DNN, even if considering both the compression and decompression.	B-Review	B-2	Review	405
The authors already point at another work where they explore the efficient compression with GPUs, but this point is the weakest one for the adoption of the proposed scheme.	I-Review	I-2	Review	405
<sep> C3.	B-Review	B-3	Review	405
The paper exceeds the recommendation of 8 pages and expands up to 13 pages, plus references.	I-Review	I-3	Review	405
An effort of compression would be advisable, moving some of the non-core results to the appendixes.	I-Review	I-3	Review	405
<sep> <sep> QUESTIONS	O	O	Review	405
Q1.	O	O	Review	405
Do you have any explanation for the big jumps on the plots of Figure 5 ?	B-Review	B-4	Review	405
<sep> Q2.	B-Review	B-5	Review	405
Did you try a joint training for the segmentation task as well ?	I-Review	I-5	Review	405
<sep> Q3.	O	O	Review	405
Why are the dots connected in Figure 10, but not in Figure 11.	B-Review	B-6	Review	405
<sep> Q4.	B-Review	B-7	Review	405
Actually results in Figure 10 do not seem good... or maybe I am not understanding them properly.	I-Review	I-7	Review	405
This is related to C1.	I-Review	I-7	Review	405
<sep> Q5.	B-Review	B-8	Review	405
There is a broken reference in Section 5.3.	I-Review	I-8	Review	405
Please fix.	I-Review	I-8	Review	405
Thank you for your review.	O	O	Reply	405
We considered your comments as follows.	O	O	Reply	405
<sep> C1 We have added definitions and clarification on the metrics to the paper.	B-Reply	B-1	Reply	405
For all of them high means good.	I-Reply	I-1	Reply	405
<sep> C2 We  gave an indexing system as an example application, but the main goal of the paper is to study the interplay between learned compression and inference in general.	B-Reply	B-2	Reply	405
As mentioned in the paper, classical compression can be much faster than learned one - and our computational gains are relative to a system using learned compression.	I-Reply	I-2	Reply	405
While falling back to classical codecs would be cheaper in terms of compute (since classical encoder+decoder is more efficient than the learned encoder), the story is not so simple, since this would come at the expense of transmitting more data for a given target image quality.	I-Reply	I-2	Reply	405
This can be crucial, since for mobile devices, data transmission (I/O) is responsible for most energy usage in common applications  (Pathak et al, 2012).	I-Reply	I-2	Reply	405
Since learned compression is still at its infancy, we expect the gap in terms of compression performance between learned methods and classical ones to grow.	I-Reply	I-2	Reply	405
Furthermore, with the increasing availability of dedicated neural network processing units on devices, deep image compression methods could become as fast as traditional ones.	I-Reply	I-2	Reply	405
<sep> C3 We have condensed the paper to remove redundant text and also moved some non-core results to the appendix.	B-Reply	B-3	Reply	405
<sep> <sep> Q1.	O	O	Reply	405
Yes, the standard learning rate schedule for training the ResNet classification architectures is a constant learning rate divided by factor 10 at fixed points in the training (every 8 epochs for our setting).	B-Reply	B-4	Reply	405
At the point when the learning rate is lowered the validation accuracy increases rapidly, and our validation curves show these jumps clearly.	I-Reply	I-4	Reply	405
<sep> The jumps/difference between operating points is due to more detail being present in images at higher bitrate (higher bpp) and therefore doing inference on them is easier.	I-Reply	I-4	Reply	405
<sep> Q2.	B-Reply	B-5	Reply	405
Yes we also did experiments for joint training with segmentation that are detailed in the revised version of the paper.	I-Reply	I-5	Reply	405
In short, we do not train jointly on the segmentation task but we take the jointly trained classification network (that improves classification) and use that as a starting point for segmentation, showing significant improvement for segmentation.	I-Reply	I-5	Reply	405
These results are shown in Figure 7.	I-Reply	I-5	Reply	405
<sep> Q3.	O	O	Reply	405
We have made the style of the plots consistent, connecting the dots for both.	B-Reply	B-6	Reply	405
<sep> Q4.	B-Reply	B-7	Reply	405
Figure 10 (also Figure 10 in the revised edition) shows how the compression metrics change when training jointly compared to training only the compression network.	I-Reply	I-7	Reply	405
It can be seen that training jointly improves the perceptual metrics MS-SSIM and SSIM slightly while PSNR gets slightly worse (higher is better for all metrics).	I-Reply	I-7	Reply	405
Figure 10‚Äôs main point is that the image compression metrics do not get worse in two out of three metrics as we do joint training.	I-Reply	I-7	Reply	405
At the same time, Figure 7 shows that the inference  performance (both segmentation and classification) significantly improves.	I-Reply	I-7	Reply	405
See Section 6.2 for a thorough discussion in the revised edition.	I-Reply	I-7	Reply	405
As this is not a core result it was moved to the appendix.	I-Reply	I-7	Reply	405
<sep> Q5.	O	O	Reply	405
We have fixed this in the revised edition of the paper.	B-Reply	B-8	Reply	405
<sep> <sep> (Pathak, A., Hu, Y. C., & Zhang, M. (2012, April).	O	O	Reply	405
Where is the energy spent inside my app?:	O	O	Reply	405
fine grained energy accounting on smartphones with eprof.	O	O	Reply	405
In Proceedings of the 7th ACM european conference on Computer Systems (pp.29-42).	O	O	Reply	405
ACM.)	O	O	Reply	405

Thanks for addressing most of the issues.	O	O	Review	405
I changed my given score from 3 to 6.	O	O	Review	405
<sep> <sep> Summary:	O	O	Review	405
This work explores the use of learned compressed image representation for solving 2 computer vision tasks without employing a decoding step.	O	O	Review	405
<sep> <sep> The paper claims to be more computationally and memory efficient compared to the use of original or the decompressed images.	O	O	Review	405
Results are presented on 2 datasets "Imagenet" and "PASCAL VOC 2012".	O	O	Review	405
They also jointly train the compression and classification together and empirically shows it can improve both classification and compression together.	O	O	Review	405
<sep> <sep> Pros:	O	O	Review	405
+ The idea of learning from a compressed representation is a very interesting and beneficial idea for large-scale image understanding tasks.	O	O	Review	405
<sep> <sep> Cons:	O	O	Review	405
- The paper is too long (13 pages + 2 pages of references).	B-Review	B-1	Review	405
The suggested standard number of pages is 8 pages + 1 page of references.	I-Review	I-1	Review	405
There are many parts that are unnecessary in the paper and can be summarized.	I-Review	I-1	Review	405
Summarizing and rewording them makes the paper more consistent and easier to read:	I-Review	I-1	Review	405
( 1.	B-Review	B-1	Review	405
A very long introduction about the benefits of inferring from the compressed images and examples.	I-Review	I-1	Review	405
<sep> 2.	B-Review	B-1	Review	405
A large part of the intro and Related work can get merged.	I-Review	I-1	Review	405
3.	O	O	Review	405
Experimental setup part is long but not well-explained and is not self-contained particularly for the evaluation metrics.	B-Review	B-1	Review	405
<sep> ‚ÄúPlease briefly explain what MS-SSIM, SSIM, and PSNR stand for‚Äù.	I-Review	I-1	Review	405
There is a reference to the Agustsson et al 2017 paper	I-Review	I-1	Review	405
‚Äúscalar quantization‚Äù, which is not well explained in the paper.	I-Review	I-1	Review	405
It is better to remove this part if it is not an important part or just briefly but clearly explain it.	I-Review	I-1	Review	405
<sep> 4.	B-Review	B-1	Review	405
Fig.4 is not necessary.	I-Review	I-1	Review	405
4.3 contains extra information and could be summarized in a more consistent way.	I-Review	I-1	Review	405
<sep> 5.	B-Review	B-1	Review	405
Hyperparameters that are applied can be summarized in a small table or just explain the difference between the	I-Review	I-1	Review	405
architectures that are used.)	I-Review	I-1	Review	405
<sep> <sep> - There are parts of the papers which are confusing or not well-written.	B-Review	B-5	Review	405
It is better to keep the sentences short and consistent:	I-Review	I-5	Review	405
E.g: subsection 3.2, page 5: ‚ÄúTo adapt the ResNet ‚Ä¶ where k is the number of ‚Ä¶ layers of the network‚Äù can be changed to 3 shorter sentences, which is easier to follow.	I-Review	I-5	Review	405
<sep> There are some typos: e.g: part 3.1, fever ---> fewer,	I-Review	I-5	Review	405
<sep> - As it is mentioned in the paper, solving a Vision problem directly from a compressed image, is not a novel method (e.g: DCT coefficients were used for both vision and audio data to solve a task without any decompression).	B-Review	B-2	Review	405
However, applying a deep representation for the compression and then directly solving a vision task (classification and segmentation) can be considered as a novel idea.	I-Review	I-2	Review	405
<sep> <sep> - In the last part of the paper, both compression and classification parts are jointly trained, and it is empirically presented that both results improved by jointly training them.	B-Review	B-3	Review	405
However, to me, it is not clear if the trained compression model on this specific dataset and for the task of classification can work well for other datasets or other tasks.	I-Review	I-3	Review	405
The experimental setup and the figures are not well explained and well written.	B-Review	B-4	Review	405
<sep> <sep> <sep> Thank you for your your review, we have considered your comments in the revised version of the paper.	O	O	Reply	405
Given the improved paper and positive perspective of the other reviews, we hope you reconsider your rating.	O	O	Reply	405
<sep> <sep> For specific points:	O	O	Reply	405
<sep> Regarding paper length: since this is a study paper, we felt it benefited from verbosity.	B-Reply	B-1	Reply	405
However, we have managed to shorten the paper to 9.5 pages, while keeping the original story intact.	I-Reply	I-1	Reply	405
We followed most of your suggestions: (1-2) We shortened the introduction and related work; (4) We made Section 4.3 (now Section 4.4) much more concise and moved Figure 4 to the appendix as it did not contain core results of our work. (	I-Reply	I-1	Reply	405
3) We added a better description of the compression metrics to the experiments section.	I-Reply	I-1	Reply	405
However, we also moved the compression results to the appendix, and added a more detailed explanation of the metrics there. (	I-Reply	I-1	Reply	405
5) We also fixed wording in the paper as you suggested and moved hyperparameter settings and details to the appendix, as we felt these details distract from the main message of the paper.	I-Reply	I-1	Reply	405
In addition to this, we refined presentation of joint training results using plots rather then presenting them in text.	I-Reply	I-1	Reply	405
<sep> <sep> As we mention in the paper, learning from DCT (of JPEG) has been done before.	B-Reply	B-2	Reply	405
However, our setting of using features from learned compression networks is significantly different.	I-Reply	I-2	Reply	405
The DCT of JPEG is simply a linear transform over 8x8 patches, whereas the compressed representation is a feature map from a deep convolutional neural network.	I-Reply	I-2	Reply	405
This opens directions such as joint learning of compression and inference (see Section 6) and warrants a full study of the problem.	I-Reply	I-2	Reply	405
<sep> <sep> To show that the improvement of joint training generalizes to another task, we added an experiment: We take the (jointly trained) classification network and finetune it for segmentation.	B-Reply	B-3	Reply	405
The results are shown in Figure 7, where the resulting network significantly outperforms the separately trained network - achieving a significant performance boost of 1.1-1.8% higher mIoU depending on the compression operating point.	I-Reply	I-3	Reply	405
See Figure 7 and discussion in Section 6.2 of the revised paper for more details.	I-Reply	I-3	Reply	405
<sep> We emphasize that this generalization is also occurring across datasets, from ILSVRC2012 (classification) to PASCAL VOC (segmentation).	I-Reply	I-3	Reply	405
<sep> <sep> Finally, we made an effort to better clarify and describe the experiments.	B-Reply	B-4	Reply	405

Neural-net based image compression is a field which is about to get hot, and this paper asks the obvious question: can we design a neural-net based image compression algorithm such that the features it produces are useful for classification & segmentation?	O	O	Review	405
<sep> <sep> The fact that it's an obvious question does not mean that it's a question that's worthless.	O	O	Review	405
In fact, I am glad someone asked this question and tried to answer it.	O	O	Review	405
<sep> <sep> Pros:	O	O	Review	405
- Clear presentation, easy to follow.	O	O	Review	405
<sep> - Very interesting, but obvious, question is explored.	O	O	Review	405
<sep> - The paper is very clear, and uses building blocks which have been analyzed before, which leaves the authors free to explore their interactions rather than each individual building block's property.	O	O	Review	405
<sep> - Results are shown on two tasks (classification / segmentation) rather than just one (the obvious one would have been to only discuss results on classification), and relatively intuitive results are shown (i.e., more bits = better performance).	O	O	Review	405
What is perhaps not obvious is how much impact does doubling the bandwidth have (i.e., initially it means more, then later on it plateaus, but much earlier than expected).	O	O	Review	405
<sep> - Joint training of compression + other tasks.	O	O	Review	405
As far as I know this is the first paper to talk about this particular scenario.	O	O	Review	405
<sep> - I like the fact that classical codecs were not completely discarded (there's a comparison with JPEG 2K).	O	O	Review	405
<sep> - The discussion section is of particular interest, discussing openly the pros/cons of the method (I wish more papers would be as straightforward as this one).	O	O	Review	405
<sep> <sep> Cons:	O	O	Review	405
- I would have liked to have a discussion on the effect of the encoder network.	B-Review	B-1	Review	405
Only one architecture/variant was used.	I-Review	I-1	Review	405
<sep> - For PSNR, SSIM and MS-SSIM I would like a bit more clarity whether these were done channel-wise, or on the grayscale channel.	B-Review	B-2	Review	405
<sep> - While runtime is given as pro, it would be nice for those not familiar with the methods to provide some runtime numbers (i.e., breakdown how much time does it take to encode and how much time does it take to classify or segment, but in seconds, not flops).	B-Review	B-3	Review	405
For example, Figure 6 could be augmented with actual runtime in seconds.	I-Review	I-3	Review	405
<sep> - I wish the authors did a ctrl+F for "??"	B-Review	B-4	Review	405
and fixed all the occurrences.	I-Review	I-4	Review	405
<sep> - One of the things that would be cool to add later on but I wished to have beeyn covered is whether it's possible to learn not only to compress, but also downscale.	B-Review	B-5	Review	405
In particular, the input to ResNet et al for classification is fixed sized, so the question is -- would it be possible to produced a compact representation to be used for classification given arbitrary image resolutions, and if yes, would it have any benefit?	I-Review	I-5	Review	405
<sep> <sep> General comments:	O	O	Review	405
- The classification bits are all open source, which is very good.	O	O	Review	405
However, there are very few neural net compression methods which are open sourced.	B-Review	B-6	Review	405
Would you be inclined to open source the code for your implementation?	I-Review	I-6	Review	405
It would be a great service to the community if yes (and I realize that it could already be open sourced -- feel free to not answer if it may lead to break anonymity, but please take this into consideration).	I-Review	I-6	Review	405
<sep> <sep> Thank you for your positive feedback.	O	O	Reply	405
As for your comments, we have addressed them as follows:	O	O	Reply	405
1) The reason for not exploring more encoders is twofold.	B-Reply	B-1	Reply	405
First, few of the state-of-the-art compression variants of neural networks are open-source which makes the implementation of different architectures very time consuming and difficult.	I-Reply	I-1	Reply	405
We picked this particular encoder since it has been used in at least 2 different works, Theis et al and Agustsson et al Second, the autoencoder compression methods also all have a similar structure and thus one could expect the performance to be similar for different encoders.	I-Reply	I-1	Reply	405
This is nevertheless an interesting direction of research worth pursuing.	I-Reply	I-1	Reply	405
<sep> 2) These were done channel-wise (RGB).	B-Reply	B-2	Reply	405
<sep> 3) We have not yet had time to do this as the code for segmentation, classification and compression networks have different levels of optimization (e.g., NCHW vs NHWC tensor layout), so doing a fair comparison is time consuming and involves careful engineering.	B-Reply	B-3	Reply	405
We however can do this before camera ready, if the paper is accepted.	I-Reply	I-3	Reply	405
We also note that the architectures used for compression and inference are very similar, convolutional networks with residual blocks, and therefore FLOPs should be a good proxy metric.	I-Reply	I-3	Reply	405
<sep> 4) This has been fixed in the revised edition of the paper	B-Reply	B-4	Reply	405
5) We agree that it would be interesting to learn the downscaling as well, after all it is just an anti-aliasing kernel (i.e. a convolution with a fixed kernel) followed by a subsampling operation and can be learned as well.	B-Reply	B-5	Reply	405
However, processing the images in full-resolution during training would quite significantly increase training times, which are already pushing our limits in terms of compute resources.	B-Reply	B-6	Reply	405
Another challenge is that hyperparameters of the ResNet architecture would likely need to be re-tuned.	I-Reply	I-6	Reply	405
We chose to adhere to the standard setting of the classification literature, so that we could use the hyperparameter settings and training schedules which have already been optimized extensively.	I-Reply	I-6	Reply	405

The paper is well organized with a clear idea of the proposed method and good related work descriptions.	O	O	Review	405
Overall, the descriptions are clear and easy to follow, but the experimental results need clarifying.	O	O	Review	405
<sep> <sep> - Regarding the multi-digit translation task, it is not straightforward to this reviewer how the proposed method could match the digits (semantic) with different colors (style) in different locations.	B-Review	B-1	Review	405
The description in the paper is not enough to explain the results in Fig.6.	I-Review	I-1	Review	405
To this reviewer, this task is more complex than the street view translation one.	I-Review	I-1	Review	405
In the same line, it is curious what the results would be if digits with different colors are overlapping at random location, rather than the grid-like arrangement.	I-Review	I-1	Review	405
<sep> <sep> - For the potential readers who are not knowledgeable in semantic segmentation, please give the full name of mIoU for reference.	B-Review	B-2	Review	405
<sep> <sep> - For further researches in this topic, it would be good to depict the limitations of the proposed method.	B-Review	B-3	Review	405
For examples, the translated images in the CelebA dataset are not photorealistic (Fig.12).	I-Review	I-3	Review	405
8)  and there are odd red lights in the middle of the results in GTA5<-BDD (Fig.	I-Review	I-3	Review	405
<sep> <sep> - typos: Fig.2-caption: m_{a}->m_{A}	B-Review	B-4	Review	405
We thank Reviewer 1 for the constructive review and detailed comments.	O	O	Reply	405
Below, we respond to each comment in detail.	O	O	Reply	405
Please see the blue fonts in the newly uploaded draft to check how the paper has changed, to be in accordance with the following responses.	O	O	Reply	405
<sep> <sep> <sep> 1.	O	O	Reply	405
Multi-digit translation.	O	O	Reply	405
<sep> We added more explanation for the multi-digit translation experiment to the paper.	B-Reply	B-1	Reply	405
<sep> <sep> (1) The MNIST-Multiple dataset is a controlled experiment, similar to MNIST-CD/CB [a], designed to verify our method's ability to disentangle content and style representations during I2I translation.	I-Reply	I-1	Reply	405
In particular, the content is represented by the different digits (0-9) and background classes, whereas style is represented by the shape and color variation added in digits as well as the (black or white) background colors.	I-Reply	I-1	Reply	405
Our goal is to encourage the network to understand the semantic information, i.e. the different digits and backgrounds, when translating an image from domain A to domain B. That is, a successfully translated image should have the content of domain A, i.e. the digit class, and the style of domain B, i.e. the digit and background colors respectively.	I-Reply	I-1	Reply	405
<sep> <sep> (2) We can achieve this by using the proposed EGSC-IT model.	B-Reply	B-1	Reply	405
First, the feature mask sub-network (F_A in Fig.2) extracts the content information, i.e. the digit class, and provides it to the decoder.	I-Reply	I-1	Reply	405
Second, the employed perceptual loss encourages the decoder to learn how to use this content information to do the translation while retaining semantic consistency.	I-Reply	I-1	Reply	405
Finally, the AdaIN sub-network (F_B in Fig.2) translates the style information of each semantic class, i.e. the digit and background colors respectively, by using AdaIN, which has proven very successful in arbitrary style transfer tasks (see later responses for a further comment on this).	I-Reply	I-1	Reply	405
We refer to the theoretical part of the paper where we provide a very detailed description of the translation procedure.	I-Reply	I-1	Reply	405
<sep> <sep> (3) We agree with Reviewer 1 that this experiment is quite challenging, but we observe that our model can still obtain good results without the need for ground-truth semantic labels or paired data.	B-Reply	B-1	Reply	405
For example, in Figure 6 top row the digits 1,2,3,4,6 can be successfully translated given the criteria described above.	I-Reply	I-1	Reply	405
In street view translation the scenes in an image are generally more complex - i.e. the within class variation in the BDD dataset is much larger than that of the synthetic MNIST-Multiple dataset.	I-Reply	I-1	Reply	405
We designed this experiment as a controlled, yet challenging, task to evaluate the different image-to-image translation methods.	I-Reply	I-1	Reply	405
Given the lack of ground-truth translated images to compare to in our setting - due to the unsupervised nature of our problem - we believe this simplified experiment offers a more direct and intuitive way to evaluate the expected translations compared to e.g. street-view translation.	I-Reply	I-1	Reply	405
<sep> <sep> (4) The setting of different colors that overlap at random locations, as proposed by Reviewer 1, seems very interesting in theory.	B-Reply	B-1	Reply	405
However, we believe that in practice it would be very difficult for any unsupervised translation method as there is too much ambiguity in the overlapped locations for a network to decide where to draw style cues from.	I-Reply	I-1	Reply	405
<sep> <sep> 2.	O	O	Reply	405
Full name of mIoU.	O	O	Reply	405
We added the full name 'mean Intersection over Union' (mIoU).	B-Reply	B-2	Reply	405
Thank you for the useful note.	I-Reply	I-2	Reply	405
<sep> <sep> 3.	O	O	Reply	405
Limitations.	O	O	Reply	405
<sep> Since our method does not use any semantic segmentation labels nor paired data, there are still some artifacts in the generated images for some hard cases.	B-Reply	B-3	Reply	405
This seems natural given the difficulty of the task.	I-Reply	I-3	Reply	405
For example: (a) in street view translation, day->night and night->day (e.g. Fig.7 top row).	I-Reply	I-3	Reply	405
7 bottom row) are more challenging than day->day (e.g. Fig.	I-Reply	I-3	Reply	405
As a result, it is sometimes hard for our model to understand the semantics in such cases.	I-Reply	I-3	Reply	405
Even state-of-the-art fully-supervised semantic segmentation networks suffer in low light or adverse weather conditions. (	I-Reply	I-3	Reply	405
b) in face gender translation, our model can successfully translate the gender attribute while keeping the semantics, e.g. skin, hair and background color, consistent with the exemplar image.	I-Reply	I-3	Reply	405
However, since we do not provide any semantic segmentation labels this results in some artifacts.	I-Reply	I-3	Reply	405
This discussion about limitations will be added in the paper.	I-Reply	I-3	Reply	405
In the future it would be interesting to extend our method to the semi-supervised setting in order to benefit from the presence of some fully-labeled data.	I-Reply	I-3	Reply	405
<sep> <sep> 4.	O	O	Reply	405
Typos.	O	O	Reply	405
<sep> We fixed them.	B-Reply	B-4	Reply	405
Thank you for finding them.	I-Reply	I-4	Reply	405
<sep> <sep> <sep> [a] A. Gonzalez-Garcia, J. van de Weijer, Y. Bengio.	O	O	Reply	405
Image-to-image translation for cross-domain disentanglement.	O	O	Reply	405
In NIPS, 2018.	O	O	Reply	405

The introduction is written to perfection.	O	O	Review	405
The paper discusses a core failing and need for I2I translation models.	O	O	Review	405
The one-to-one mapping assumption does not apply to most tasks.	O	O	Review	405
While the approach seems novel the analysis of the results are insufficient to convince me that the method is really working.	O	O	Review	405
This should be a workshop paper.	O	O	Review	405
<sep> <sep> For the motivation of the approach I am not convinced how the conditioned style is being used.	B-Review	B-1	Review	405
It would be nice to see some analysis of how the latent space changes given different input images.	I-Review	I-1	Review	405
Why would style information be propagated through the network?	I-Review	I-1	Review	405
Why wouldn't noise work just as well?	I-Review	I-1	Review	405
Although an abiliation study is performed there is no standard deviation reported so it is unclear if this number is fair.	I-Review	I-1	Review	405
<sep> <sep> In Figure 5 the t-sne doesn't look correct.	B-Review	B-2	Review	405
The points all seems to be projected on walls which could indicate some sort of overflow error.	I-Review	I-2	Review	405
The text only devotes 3 lines to discuss this figure.	I-Review	I-2	Review	405
It is not mentioned what part of the model the t-sne is computed from.	I-Review	I-2	Review	405
To me this experiment that studies the internal representation is critical to convincing a reader to use this method.	I-Review	I-2	Review	405
<sep> <sep> The segmentation results sound good.	B-Review	B-3	Review	405
Where is the improvement coming from?	I-Review	I-3	Review	405
The experimental section is cut short.	I-Review	I-3	Review	405
The experiment section is really squeezed in the last two pages while the other sections are overly descriptive and could be reduced.	I-Review	I-3	Review	405
<sep> <sep> The figures should be changed to be visible without color (put a texture on each block).	B-Review	B-4	Review	405
<sep> <sep> We thank Reviewer 2 for the constructive review and detailed comments.	O	O	Reply	405
We apologize if the experimental section text due to space constraints feels short and leads to misunderstandings.	O	O	Reply	405
We are going to clarify everything below.	O	O	Reply	405
Please see the blue fonts in the newly uploaded draft to check how our paper is changed, to be in accordance with the following responses.	O	O	Reply	405
<sep> <sep> <sep> 1.	O	O	Reply	405
Style information propagation.	B-Reply	B-1	Reply	405
<sep> As already mentioned, the style information in our method is propagated by using the Adaptive Instance Normalization (AdaIN) technique [b]. This is a well-known technique in the style transfer field which has proven to be very successful for arbitrary style transfers, and has been adopted by many follow-up works.	I-Reply	I-1	Reply	405
The idea behind AdaIN in our case is to align the mean and variance of the content feature channels coming from domain A (after applying the feature mask) with those of the style feature channels coming from domain B. According to [c], these feature statistics have been found to carry the style information in an image.	I-Reply	I-1	Reply	405
Noise can also be used to generate images with diverse style [d], as proposed by Reviewer 2.	I-Reply	I-1	Reply	405
However, our goal in this work is to allow users more explicit control over the translation process, which is something that noise-based approaches do not allow.	I-Reply	I-1	Reply	405
In particular, noise inputs do not easily translate to intuitive style guidance, in contrast to our exemplar-guided approach, where we propose to use a sub-network (F_B in Fig.2) to explicitly extract the feature statistics from the exemplar image itself and - through AdaIN - adapt accordingly the source image.	I-Reply	I-1	Reply	405
As a result, the user can match any desired style from the target domain just by picking the corresponding exemplar.	I-Reply	I-1	Reply	405
<sep> <sep> 2.	O	O	Reply	405
Latent space.	O	O	Reply	405
<sep> With respect to the previous question, Reviewer 2 asks for a visualization of how the latent space changes given different exemplar images.	B-Reply	B-1	Reply	405
Although generally a valid request, it does not apply to our case.	I-Reply	I-1	Reply	405
Let us explain why.	I-Reply	I-1	Reply	405
Due to the specifics of our architecture, the latent space is only associated with the content representation of an image, not the style of the exemplar.	I-Reply	I-1	Reply	405
The latter is only added after the encoder part, i.e. the latent space, and the feature mask sub-network through the AdaIN sub-network (see Fig.2).	I-Reply	I-1	Reply	405
As such, changing exemplars and visualizing the latent space would give the same point in the latent space if the source image (that provides the content) is the same.	I-Reply	I-1	Reply	405
Alternatively, changing source images and visualizing the latent space is not informative about the translation procedure as the style is only added after the feature mask and AdaIN sub-networks.	I-Reply	I-1	Reply	405
In summary, the latent space is only related to the source image since the style information is only combined in the decoder part through feature mask and AdaIN techniques.	I-Reply	I-1	Reply	405
Instead, to mimic what Reviewer 2 asked for, we added the male->female face translation results matrix in Fig.9.	I-Reply	I-1	Reply	405
We observe that the output image's content is consistent with the source image and its style is consistent with the target image.	I-Reply	I-1	Reply	405
Such observation can reflect how the latent space changes given different source images as well as exemplars.	I-Reply	I-1	Reply	405

I enjoyed reading this manuscript.	O	O	Review	405
The paper is based on a simple idea used by others as well (i.e., the image has two components, one  that encode content which is shared across domains and another one characterizing the domain specific style).	O	O	Review	405
The other important idea is the use of feature masks that steer the translation process without requiring semantic labels.	O	O	Review	405
This is similar to attention models used by others but I think it is novel when applying to this specific application domain.	B-Review	B-1	Review	405
I was a bit disappointed by the evaluation part.	I-Review	I-1	Review	405
The authors decided to perform ablation and to show the importance of each component using only the MNIST-Single dataset.	I-Review	I-1	Review	405
While this is good as a toy example I would have expected to see such analysis on a more complex example, e.g., street-view translation.	I-Review	I-1	Review	405
This is also surprising considering that it is not even present in the supplementary material.	I-Review	I-1	Review	405
Overall, this is a solid submission with interesting ideas and good implementation.	O	O	Review	405
We thank Reviewer 3 for the constructive review and detailed comments.	O	O	Reply	405
<sep> <sep> 1.	O	O	Reply	405
Ablation study	B-Reply	B-1	Reply	405
In our paper, we present the ablation study on the MNIST-Single dataset because it is a more controlled setting where we can generate ground truth for comparisons.	I-Reply	I-1	Reply	405
Furthermore, as mentioned in a previous answer, we believe that this simplified experiment offers a more direct and intuitive way to evaluate the expected translations compared to e.g. street-view translation.	I-Reply	I-1	Reply	405
However, as Reviewer 3 suggested, it is interesting to show the ablation study results on more complex examples too.	I-Reply	I-1	Reply	405
As such, we added these results in the supplementary material in Fig.15.	I-Reply	I-1	Reply	405
We observe that: 1) removing the feature mask leads to color mismatches or inaccuracies (e.g. Fig.15(a) 5th col).	I-Reply	I-1	Reply	405
15(a) 1st row 3rd col); 2) removing AdaIN reduces the model to unimodality (e.g. all images are translated to a sunny day with blue sky, see Fig.	I-Reply	I-1	Reply	405
15(a) 4th col) since the output image's style is not guided by the exemplar image; 3) removing perceptual loss leads to incorrect style (e.g.  Fig.	I-Reply	I-1	Reply	405
15(b) 5th col) and the color  spreads even given the feature mask since there is no perceptual feedback during training (e.g.  Fig.	I-Reply	I-1	Reply	405

This paper proposes a new way to create compact neural net, named Atomic Compression Networks (ACN).	O	O	Review	405
An immediate related work is LayerNet, where a deep neural net is created by replicating the same layer.	O	O	Review	405
Here, this paper extends replication down to the neuron level.	O	O	Review	405
<sep> <sep> I am leaning towards rejecting this paper because the experimental setup is not well justified and a few important details are missing before conclusions can be drawn.	O	O	Review	405
I would like to ask a few clarification questions.	O	O	Review	405
Depending on the authors‚Äô answers, I might be willing to adjust my rating.	O	O	Review	405
<sep> <sep> (1) Is there missing a delta in the first half of line 6 in Algorithm 1?	B-Review	B-1	Review	405
<sep> <sep> (2) Throughout the experiments, for the same hyperparameter (e.g. Table 4 in A.2) do you run Algorithm 1 more than once and select the best sample architecture?	B-Review	B-2	Review	405
If the answer is yes, summarizing all masks as one parameter will not be reasonable.	I-Review	I-2	Review	405
Given a yes answer, I would also like to ask if the same number of samples have been considered for FC (for the same hyperparameter).	I-Review	I-2	Review	405
<sep> <sep> (3) Is there any intuition behind why FC does a much worse job of fitting curves than ACN with much less parameters?	B-Review	B-3	Review	405
This refers to Fig.2, if we compare FC with 41 parameters to ACN with 18 parameters.	I-Review	I-3	Review	405
I am confused because MSE on sampled points often goes down when we increase the number of parameters for the application of curve fitting.	I-Review	I-3	Review	405
<sep> <sep> (4) Convolution can be thought of as a special case of ACN.	B-Review	B-4	Review	405
ConvNet is the default architecture for working on image datasets.	I-Review	I-4	Review	405
Since MNIST and CIFAR are considered, why not also compare to ConvNet?	I-Review	I-4	Review	405
<sep> <sep> (5) The claims that ‚ÄúACNs achieve compression rates of up to three orders of magnitudes compared to fine-tuned fully-connected neural networks with only a fractional deterioration of classification accuracy‚Äù is quite misleading.	B-Review	B-5	Review	405
Given fully-connected neural networks achieve up to 528 times with also a fractional deterioration (Sec.	I-Review	I-5	Review	405
4.3), by presumably having a shallower architecture.	I-Review	I-5	Review	405
Thank you for your time and the thorough evaluation of our paper.	O	O	Reply	405
<sep> <sep> In the following we want to clarify the points brought up in your review:	O	O	Reply	405
<sep> 1) There is no delta missing.	B-Reply	B-1	Reply	405
Line 6 in Algorithm 1 is meant as 2 consecutive lines since we return the two sets m and delta at the end of the alogirthm.	I-Reply	I-1	Reply	405
We will separate it to make it more clear.	I-Reply	I-1	Reply	405
<sep> However as you suggest it would also be possible to absorb the mask delta into m_i and only return m.	I-Reply	I-1	Reply	405
<sep> 2) No, we do not select the best sample architecture.	B-Reply	B-2	Reply	405
In the experiments we run Algorithm 1 only once per seed for 3 seeds and average the performance of all 3 resulting architectures.	I-Reply	I-2	Reply	405
We do not apply any selection regarding the sampled architectures.	I-Reply	I-2	Reply	405
All other models are also initialized, trained and evaluated over 3 different seeds and the results are averaged as well.	I-Reply	I-2	Reply	405
<sep> <sep> 3) To motivate the benefit of recursively repeating neurons, we would like to present an example from function composition.	B-Reply	B-3	Reply	405
Let us consider a simple function which has only two parameters.	I-Reply	I-3	Reply	405
By applying the composition we get a more complex function, but still having just two parameters.	I-Reply	I-3	Reply	405
We can keep composing and achieve a very complex function, yet with only two parameters.	I-Reply	I-3	Reply	405
Notice that the intuition of repeating neurons is equivalent to that of achieving a higher non-linear expressivity by composing functions, for instance composing a set of functions yields very deep representations, e.g.. Please consider that each can be a neuron, therefore our atomic networks are special cases of recursive function compositions from a set of base functions (a.k.a.	I-Reply	I-3	Reply	405
repeating neurons in our paper).	I-Reply	I-3	Reply	405
In our assessment, we are the first to consider adding non-linear expressivity by recursively applying the same set of neurons (a.k.a.	I-Reply	I-3	Reply	405
functions).	I-Reply	I-3	Reply	405
<sep> <sep> Therefore ACN achieves much deeper architectures with the same number of parameters compared to a standard FCN, what could further improve the fitting capability.	I-Reply	I-3	Reply	405
Finally we see the expected trend that the fit for both models increases respectively when increasing the number of parameters when going from left to right in both rows of figure 2.	I-Reply	I-3	Reply	405
<sep> <sep> 4) The main focus of this work is showing the advantage of ACN compared to MLP baselines on vector data.	B-Reply	B-4	Reply	405
The image datasets were added for experimental diversity as special case of high dimensional vector data (the images were flattened) with an explicit structure.	I-Reply	I-4	Reply	405
In the same way as MLPs, ACNs are not able to levarage the spatial information in image data compared to a specialized architecture like ConvNets.	I-Reply	I-4	Reply	405
Furthermore, although ConvNets share parameters of their filters over the image, they do not share parameters between layers.	I-Reply	I-4	Reply	405
Since the extension of the underlying idea of our ACNs to ConvNets is not feasible within the short time of the rebuttal periode, we plan to explore that direction in future work.	I-Reply	I-4	Reply	405
<sep> <sep> 5) In our experiments we follow the established trend of comparing the compression rate w.r.t.a large standard model.	B-Reply	B-5	Reply	405
However contrary to most work we also introduce a small, tuned FCN of comparable size to compressed networks, which is shown to be a very strong baseline [2].	I-Reply	I-5	Reply	405
In general our experiments confirm the findings of [1], that with a very large and comprehensive hyperparameter search including the general network architecture, one can find very shallow and small FC networks which perform on par or even better than most networks produced by compression techniques.	I-Reply	I-5	Reply	405
The inherent advantage of the compression techniques is however that in most cases they lead more reliably and with less computational effort to relatively small and well performing architectures.	I-Reply	I-5	Reply	405
<sep> The 528 times is a typo in the text, it should be 218 times as reported in table 2.	I-Reply	I-5	Reply	405
Furthermore the compression rates are achieved on different datasets e.g. the 1115 times of ACN compared to 133 of small FC on the internetAds dataset.	I-Reply	I-5	Reply	405
<sep> <sep> [1] Liu, Zhuang, Mingjie Sun, Tinghui Zhou, Gao Huang, and Trevor Darrell.	O	O	Reply	405
2018. ‚	O	O	Reply	405
ÄúRethinking the Value of Network Pruning.	O	O	Reply	405
‚Äù ArXiv:1810.05270 [Cs, Stat], October.	O	O	Reply	405
<a href="http://arxiv.org/abs/1810.05270."	O	O	Reply	405
target="_blank" rel="nofollow">http://arxiv.org/abs/1810.05270.</a>	O	O	Reply	405
<sep> [2] Chen, Wenlin, James Wilson, Stephen Tyree, Kilian Weinberger, and Yixin Chen. "	O	O	Reply	405
Compressing neural networks with the hashing trick."	O	O	Reply	405
In International Conference on Machine Learning, pp.2285-2294.	O	O	Reply	405
2015.	O	O	Reply	405

The paper describes a new method called Atomic Compression Network for constructing neural networks.	O	O	Review	405
The idea is straightforward.	O	O	Review	405
Basically, firstly create some neurons in random fashion, then reuse a subset of those neurons in each layer.	O	O	Review	405
The experiments shows ACN produces better accuracy than baseline models including a FC network, a Baysesina compression method, etc.	O	O	Review	405
for MINIST, etc.	O	O	Review	405
The paper also show ACN uses much less numbers of parameters and achieves similar accuracy when comparing with a large optima FC network on a set of datasets.	O	O	Review	405
<sep> <sep> Overall, I don‚Äôt support accepting this paper.	B-Review	B-1	Review	405
First, I don‚Äôt think the proposed idea is very innovative.	I-Review	I-1	Review	405
Please elaborate why this method seems to work well when comparing baseline models.	I-Review	I-1	Review	405
Is it just randomly constructed network also perform well?	I-Review	I-1	Review	405
Secondly, I‚Äôm not convinced we will use this method to build network in real world applications.	B-Review	B-2	Review	405
The model size is small, but in what cases this small model size matters?	I-Review	I-2	Review	405
Is this a reliable way to create useful models?	B-Review	B-3	Review	405
<sep> <sep> On page 7, in Figure 3, why logistic regression only has a single point in some of the plots?	B-Review	B-4	Review	405
<sep> <sep> <sep> Thank you for your time and the valuable feedback and insights regarding our paper.	O	O	Reply	405
<sep> <sep> We would like to clarify some points mentioned in your review:	O	O	Reply	405
<sep> &gt; ‚ÄûIs it just randomly constructed network also perform well?‚Äú	O	O	Reply	405
<sep> 1) No, naively randomly constructed networks do not perform well, as can be seen with the RER [1] baseline (section 4.2.2, figure 3 and table 5 in the appendix).	B-Reply	B-1	Reply	405
The proposed method works well compared to the other baselines because the special weight sharing architecture enables the model to use the available capacity given by the number of its parameters more efficiently.	I-Reply	I-1	Reply	405
As we show in the experimental section this applies to randomly constructed networks, where the shared weights are trained end-to-end what leads to an effective fine-tuned collective network.	I-Reply	I-1	Reply	405
However we want to emphasize that only the distribution and connections of the neurons are random, while the number of layers and number of neurons per layer is predefined.	I-Reply	I-1	Reply	405
Furthermore as we point out in the conclusion, the proposed method could be combined with smarter approaches to construct even more powerful networks, e.g. by using  NAS methods (cp. [	I-Reply	I-1	Reply	405
7]).	I-Reply	I-1	Reply	405
<sep> <sep> <sep> &gt; ‚ÄûThe model size is small, but in what cases this small model size matters?‚Äú	O	O	Reply	405
<sep> 2) The small model size achieved by the presented methods matters in different theoretical and real world scenarios.	B-Reply	B-2	Reply	405
An increasing number of recent publications are concerned with network compression approaches to improve scalability and minimize the required and utilized memory of originally huge models to run them on edge devices with restricted resources (IoT devices, smartphones, etc.) [	I-Reply	I-2	Reply	405
2,3,4,5,6].	I-Reply	I-2	Reply	405
<sep> <sep> &gt; ‚ÄûIs this a reliable way to create useful models?‚Äú	O	O	Reply	405
<sep> 3) The random construction of ACN is reliable and produces useful models, what is demonstrated by the reasonable variances shown in table 5 in the appendix.	B-Reply	B-3	Reply	405
In the performed experiments on 9 diverse real world datasets with a different number of instances, features and classes as well as on 3 image datasets, the results show that the performance and gains of the proposed method are significant.	I-Reply	I-3	Reply	405
<sep> <sep> <sep> &gt; ‚ÄûOn page 7, in Figure 3, why logistic regression only has a single point in some of the plots?‚Äú	O	O	Reply	405
<sep> 4) Since logistic regression has a constant number of parameters and in figure 3 we compare models for different numbers of parameters, there can only be one point for logistic regression in all plots.	B-Reply	B-4	Reply	405
<sep> <sep> <sep> <sep> [1] Cire≈üan, Dan C., Ueli Meier, Jonathan Masci, Luca M. Gambardella, and J√ºrgen Schmidhuber. "	O	O	Reply	405
High-performance neural networks for visual object classification."	O	O	Reply	405
arXiv preprint arXiv:1102.0183 (2011).	O	O	Reply	405
<sep> <sep> [2] Cheng, Yu, Duo Wang, Pan Zhou, and Tao Zhang.	O	O	Reply	405
2017. ‚	O	O	Reply	405
ÄúA Survey of Model Compression and Acceleration for Deep Neural Networks.	O	O	Reply	405
‚Äù ArXiv:1710.09282 [Cs], October.	O	O	Reply	405
<a href="http://arxiv.org/abs/1710.09282."	O	O	Reply	405
target="_blank" rel="nofollow">http://arxiv.org/abs/1710.09282.</a>	O	O	Reply	405
<sep> [3] Kim, Yong-Deok, Eunhyeok Park, Sungjoo Yoo, Taelim Choi, Lu Yang, and Dongjun Shin.	O	O	Reply	405
2015. ‚	O	O	Reply	405
ÄúCompression of Deep Convolutional Neural Networks for Fast and Low Power Mobile Applications.	O	O	Reply	405
‚Äù ArXiv:1511.06530 [Cs], November.	O	O	Reply	405
<a href="http://arxiv.org/abs/1511.06530."	O	O	Reply	405
target="_blank" rel="nofollow">http://arxiv.org/abs/1511.06530.</a>	O	O	Reply	405
<sep> [4] Han, S., X. Liu, H. Mao, J. Pu, A. Pedram, M. A. Horowitz, and W. J. Dally.	O	O	Reply	405
2016. ‚	O	O	Reply	405
ÄúEIE: Efficient Inference Engine on Compressed Deep Neural Network.	O	O	Reply	405
‚Äù In 2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA), 243‚Äì54.	O	O	Reply	405
<a href="https://doi.org/10.1109/ISCA.2016.30."	O	O	Reply	405
target="_blank" rel="nofollow">https://doi.org/10.1109/ISCA.2016.30.</a>	O	O	Reply	405
<sep> [5] Samie, Farzad, Vasileios Tsoutsouras, Lars Bauer, Sotirios Xydis, Dimitrios Soudris, and J√∂rg Henkel.	O	O	Reply	405
2016. ‚	O	O	Reply	405
ÄúComputation Offloading and Resource Allocation for Low-Power IoT Edge Devices.	O	O	Reply	405
‚Äù In 2016 IEEE 3rd World Forum on Internet of Things (WF-IoT), 7‚Äì12.	O	O	Reply	405
<a href="https://doi.org/10.1109/WF-IoT.2016.7845499."	O	O	Reply	405
target="_blank" rel="nofollow">https://doi.org/10.1109/WF-IoT.2016.7845499.</a>	O	O	Reply	405
<sep> [6] Mehta, Sachin, Mohammad Rastegari, Anat Caspi, Linda Shapiro, and Hannaneh Hajishirzi.	O	O	Reply	405
2018. ‚	O	O	Reply	405
ÄúESPNet: Efficient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation.	O	O	Reply	405
‚Äù In Computer Vision ‚Äì ECCV 2018, edited by Vittorio Ferrari, Martial Hebert, Cristian Sminchisescu, and Yair Weiss, 11214:561‚Äì80.	O	O	Reply	405
Cham: Springer International Publishing.	O	O	Reply	405
<a href="https://doi.org/10.1007/978-3-030-01249-6_34."	O	O	Reply	405
target="_blank" rel="nofollow">https://doi.org/10.1007/978-3-030-01249-6_34.</a>	O	O	Reply	405
<sep> [7] Elsken, Thomas, Jan Hendrik Metzen, and Frank Hutter.	O	O	Reply	405
2018. ‚	O	O	Reply	405
ÄúNeural Architecture Search: A Survey.	O	O	Reply	405
‚Äù ArXiv:1808.05377 [Cs, Stat], August.	O	O	Reply	405
<a href="http://arxiv.org/abs/1808.05377."	O	O	Reply	405
target="_blank" rel="nofollow">http://arxiv.org/abs/1808.05377.</a>	O	O	Reply	405

This paper explores the use of replicating neurons across and within layers to compress fully connected neural networks.	O	O	Review	405
The idea is simple, and is evaluated on a number of datasets and compared with fully connected, single layer, and several compression schemes.	O	O	Review	405
<sep> <sep> Strengths: a lot of nice experiments with clearly advantageous results are given.	O	O	Review	405
<sep> <sep> Weaknesses: One obvious baseline missing is sparse compression, which can be achieved using either l1 regularization, or hard thresholding + fine tuning, both of which are easy to implement and appear in several works, e.g.	B-Review	B-1	Review	405
<sep> Scalable Neural Network Compression and Pruning Using Hard Clustering and L1 Regularization (Yang, Ruozzi, Gogate)	I-Review	I-1	Review	405
Training skinny deep neural networks with iterative hard thresholding methods (Yin, Yuan, Feng, Yan)	I-Review	I-1	Review	405
<sep> ... many others just via googling ...	I-Review	I-1	Review	405
<sep> Also, I think this work should be compared with compression schemes that work via kronecker product, which seem very similar to this scheme (but where the kronecker matrix is binary to produce replication)	B-Review	B-2	Review	405
<sep> Compression of Fully-Connected Layer in Neural Network by Kronecker Product (Zhou, Wu)	I-Review	I-2	Review	405
(more via google)	I-Review	I-2	Review	405
<sep> One obvious advantage of replication over kronecker product is lower complexity, but nonetheless, the methods belong in a similar family.	I-Review	I-2	Review	405
<sep> <sep> Otherwise, I think the work makes sense, the idea is nice, and the results show promise!	O	O	Review	405
<sep> <sep> After rebuttal: I have read the rebuttal and the authors have basically addressed all my concerns.	B-Review	B-1	Review	405
It is a bit disappointing that simple L1 regularization can give competitive results, but the fact that the authors are willing to do the experiment and incorporate the results convinces me that there's nothing being hidden here, and the reader can make a fair and informed conclusion, so I have no more complaints.	I-Review	I-1	Review	405
Thank you very much for the feedback and the positive evaluation of our paper.	O	O	Reply	405
<sep> <sep> &gt; ‚ÄûOne obvious baseline missing is sparse compression...‚Äú	O	O	Reply	405
<sep> 1) Regarding the sparse compression baseline we want to point out, that the Bayesian Compression baseline [1] in our paper is implicitly sparsifying the network.	B-Reply	B-1	Reply	405
Furthermore the authors compare their method against the sparsifying variational dropout proposed by [2] and show that they achieve better results.	I-Reply	I-1	Reply	405
<sep> We performed some additional experiments employing simple L1 regularization and  L1 regularization combined with iterative hard thresholding (cp.	I-Reply	I-1	Reply	405
[3]) but without explicit cardinality constraint [4]. The results show that both methods in general perform a bit worse than the small FC baseline, beating our ACN in some of the cases where the small FC baseline is also stronger, especially for the two last parameter bins (with the highest number of parameters).	I-Reply	I-1	Reply	405
However it doesn‚Äòt change the overall impression and results.	I-Reply	I-1	Reply	405
We will add the additional results to the appendix to clarify the points made.	I-Reply	I-1	Reply	405
<sep> <sep> <tab><tab>SparseL1<tab>SparseL1+HT<tab>	I-Reply	I-1	Reply	405
<tab><tab>Accuracy<tab>Accuracy<tab>	I-Reply	I-1	Reply	405
har<tab><tab><tab><tab><tab>	I-Reply	I-1	Reply	405
&lt; 500<tab>&amp;<tab>0.000<tab>&amp;<tab>0.000<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="8">\</span>	I-Reply	I-1	Reply	405
&lt; 1000<tab>&amp;<tab>0.181<tab>&amp;<tab>0.193<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="9">\</span>	I-Reply	I-1	Reply	405
&lt; 2500<tab>&amp;<tab>0.181<tab>&amp;<tab>0.959<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="10">\</span>	I-Reply	I-1	Reply	405
&lt; 5000<tab>&amp;<tab>0.981<tab>&amp;<tab>0.967<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="11">\</span>	I-Reply	I-1	Reply	405
&gt;= 5000&amp;<tab>0.981<tab>&amp;<tab>0.975<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="12">\</span>	I-Reply	I-1	Reply	405
nomao<tab><tab><tab><tab><tab>	I-Reply	I-1	Reply	405
&lt; 250<tab>&amp;<tab>0.000<tab>&amp;<tab>0.000<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="13">\</span>	I-Reply	I-1	Reply	405
&lt; 500<tab>&amp;<tab>0.000<tab>&amp;<tab>0.000<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="14">\</span>	I-Reply	I-1	Reply	405
&lt; 1000<tab>&amp;<tab>0.718<tab>&amp;<tab>0.718<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="15">\</span>	I-Reply	I-1	Reply	405
&lt; 2500<tab>&amp;<tab>0.952<tab>&amp;<tab>0.949<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="16">\</span>	I-Reply	I-1	Reply	405
&gt;= 2500&amp;<tab>0.952<tab>&amp;<tab>0.951<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="17">\</span>	I-Reply	I-1	Reply	405
internetAds<tab><tab><tab><tab><tab>	I-Reply	I-1	Reply	405
&lt; 1000<tab>&amp;<tab>0.916<tab>&amp;<tab>0.913<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="18">\</span>	I-Reply	I-1	Reply	405
&lt; 2500<tab>&amp;<tab>0.916<tab>&amp;<tab>0.966<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="19">\</span>	I-Reply	I-1	Reply	405
&lt; 5000<tab>&amp;<tab>0.969<tab>&amp;<tab>0.966<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="20">\</span>	I-Reply	I-1	Reply	405
&lt; 10000&amp;<tab>0.977<tab>&amp;<tab>0.966<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="21">\</span>	I-Reply	I-1	Reply	405
&gt;= 10000&amp;<tab>0.977<tab>&amp;<tab>0.966<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="22">\</span>	I-Reply	I-1	Reply	405
isolet<tab><tab><tab><tab><tab>	I-Reply	I-1	Reply	405
&lt; 2500<tab>&amp;<tab>0.033<tab>&amp;<tab>0.488<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="23">\</span>	I-Reply	I-1	Reply	405
&lt; 5000<tab>&amp;<tab>0.033<tab>&amp;<tab>0.933<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="24">\</span>	I-Reply	I-1	Reply	405
&lt; 7500<tab>&amp;<tab>0.938<tab>&amp;<tab>0.933<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="25">\</span>	I-Reply	I-1	Reply	405
&lt; 10000&amp;<tab>0.938<tab>&amp;<tab>0.953<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="26">\</span>	I-Reply	I-1	Reply	405
&gt;= 10000&amp;<tab>0.938<tab>&amp;<tab>0.953<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="27">\</span>	I-Reply	I-1	Reply	405
spambase<tab><tab><tab><tab><tab>	I-Reply	I-1	Reply	405
&lt; 250<tab>&amp;<tab>0.000<tab>&amp;<tab>0.000<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="28">\</span>	I-Reply	I-1	Reply	405
&lt; 500<tab>&amp;<tab>0.000<tab>&amp;<tab>0.000<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="29">\</span>	I-Reply	I-1	Reply	405
&lt; 1000<tab>&amp;<tab>0.733<tab>&amp;<tab>0.739<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="30">\</span>	I-Reply	I-1	Reply	405
&gt;= 1000&amp;<tab>0.919<tab>&amp;<tab>0.922<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="31">\</span>	I-Reply	I-1	Reply	405
splice<tab><tab><tab><tab><tab>	I-Reply	I-1	Reply	405
&lt; 500<tab>&amp;<tab>0.000<tab>&amp;<tab>0.000<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="32">\</span>	I-Reply	I-1	Reply	405
&lt; 1000<tab>&amp;<tab>0.533<tab>&amp;<tab>0.533<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="33">\</span>	I-Reply	I-1	Reply	405
&lt; 2500<tab>&amp;<tab>0.889<tab>&amp;<tab>0.974<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="34">\</span>	I-Reply	I-1	Reply	405
&lt; 5000<tab>&amp;<tab>0.971<tab>&amp;<tab>0.974<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="35">\</span>	I-Reply	I-1	Reply	405
&gt;= 5000&amp;<tab>0.976<tab>&amp;<tab>0.977<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="36">\</span>	I-Reply	I-1	Reply	405
theorem<tab><tab><tab><tab><tab>	I-Reply	I-1	Reply	405
&lt; 250<tab>&amp;<tab>0.000<tab>&amp;<tab>0.000<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="37">\</span>	I-Reply	I-1	Reply	405
&lt; 500<tab>&amp;<tab>0.000<tab>&amp;<tab>0.000<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="38">\</span>	I-Reply	I-1	Reply	405
&lt; 1000<tab>&amp;<tab>0.422<tab>&amp;<tab>0.422<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="39">\</span>	I-Reply	I-1	Reply	405
&gt;= 1000&amp;<tab>0.488<tab>&amp;<tab>0.493<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="40">\</span>	I-Reply	I-1	Reply	405
bioresponse<tab><tab><tab><tab><tab>	I-Reply	I-1	Reply	405
&lt; 1000<tab>&amp;<tab>0.548<tab>&amp;<tab>0.548<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="41">\</span>	I-Reply	I-1	Reply	405
&lt; 2500<tab>&amp;<tab>0.548<tab>&amp;<tab>0.777<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="42">\</span>	I-Reply	I-1	Reply	405
&lt; 5000<tab>&amp;<tab>0.767<tab>&amp;<tab>0.791<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="43">\</span>	I-Reply	I-1	Reply	405
&lt; 10000&amp;<tab>0.788<tab>&amp;<tab>0.791<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="44">\</span>	I-Reply	I-1	Reply	405
&gt;= 10000&amp;<tab>0.788<tab>&amp;<tab>0.791<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="45">\</span>	I-Reply	I-1	Reply	405
optdigits<tab><tab><tab><tab><tab>	I-Reply	I-1	Reply	405
&lt; 250<tab>&amp;<tab>0.000<tab>&amp;<tab>0.000<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="46">\</span>	I-Reply	I-1	Reply	405
&lt; 500<tab>&amp;<tab>0.000<tab>&amp;<tab>0.000<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="47">\</span>	I-Reply	I-1	Reply	405
&lt; 750<tab>&amp;<tab>0.000<tab>&amp;<tab>0.104<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="48">\</span>	I-Reply	I-1	Reply	405
&lt; 1000<tab>&amp;<tab>0.104<tab>&amp;<tab>0.961<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="49">\</span>	I-Reply	I-1	Reply	405
&gt;= 1000&amp;<tab>0.979<tab>&amp;<tab>0.985<tab><span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="50">\</span>	I-Reply	I-1	Reply	405
<sep> &gt; ‚Äû...this work should be compared with compression schemes that work via kronecker product, ...‚Äú	O	O	Reply	405
<sep> 2) The proposed paper employing the Kronecker product is quite interesting.	B-Reply	B-2	Reply	405
We will add it to the related work.	I-Reply	I-2	Reply	405
Our 3rd baseline ‚ÄûTensorNet‚Äú [5] (see section 4.2.2) employs the Tensor-Train (TT) format [6]. The TT format is itself a special case of a Nested Kronecker Tensor Decomposition [7].	I-Reply	I-2	Reply	405
Furthermore [5] is well known in the network compression literature and comes with available code which simplifies the experiments.	I-Reply	I-2	Reply	405
Therefore we argue that the TensorNet baseline is a good representation of compression methods based on layer-wise matrix decomposition and low-rank approximations.	I-Reply	I-2	Reply	405
Furthermore our model does not only focus on layer-wise decompositions but takes the whole (deep) network structure into account.	I-Reply	I-2	Reply	405
<sep> <sep> <sep> <sep> [1] Louizos, Christos, Karen Ullrich, and Max Welling.	O	O	Reply	405
2017. ‚	O	O	Reply	405
ÄúBayesian Compression for Deep Learning.	O	O	Reply	405
‚Äù In Advances in Neural Information Processing Systems 30, edited by I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, 3288‚Äì3298.	O	O	Reply	405
Curran Associates, Inc. <a href="http://papers.nips.cc/paper/6921-bayesian-compression-for-deep-learning.pdf."	O	O	Reply	405
target="_blank" rel="nofollow">http://papers.nips.cc/paper/6921-bayesian-compression-for-deep-learning.pdf.</a>	O	O	Reply	405
<sep> [2] Molchanov, Dmitry, Arsenii Ashukha, and Dmitry Vetrov.	O	O	Reply	405
2017. ‚	O	O	Reply	405
ÄúVariational Dropout Sparsifies Deep Neural Networks.	O	O	Reply	405
‚Äù ArXiv:1701.05369 [Cs, Stat], June.	O	O	Reply	405
<a href="http://arxiv.org/abs/1701.05369."	O	O	Reply	405
target="_blank" rel="nofollow">http://arxiv.org/abs/1701.05369.</a>	O	O	Reply	405
<sep> [3] Han, Song, Jeff Pool, John Tran, and William Dally.	O	O	Reply	405
2015. ‚	O	O	Reply	405
ÄúLearning Both Weights and Connections for Efficient Neural Network.	O	O	Reply	405
‚Äù In Advances in Neural Information Processing Systems 28, edited by C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, 1135‚Äì1143.	O	O	Reply	405
Curran Associates, Inc. <a href="http://papers.nips.cc/paper/5784-learning-both-weights-and-connections-for-efficient-neural-network.pdf."	O	O	Reply	405
target="_blank" rel="nofollow">http://papers.nips.cc/paper/5784-learning-both-weights-and-connections-for-efficient-neural-network.pdf.</a>	O	O	Reply	405
<sep> [4] Jin, Xiaojie, Xiaotong Yuan, Jiashi Feng, and Shuicheng Yan.	O	O	Reply	405
2016. ‚	O	O	Reply	405
ÄúTraining Skinny Deep Neural Networks with Iterative Hard Thresholding Methods.	O	O	Reply	405
‚Äù ArXiv:1607.05423 [Cs], July.	O	O	Reply	405
<a href="http://arxiv.org/abs/1607.05423."	O	O	Reply	405
target="_blank" rel="nofollow">http://arxiv.org/abs/1607.05423.</a>	O	O	Reply	405
<sep> [5] Novikov, Alexander, Dmitry Podoprikhin, Anton Osokin, and Dmitry Vetrov.	O	O	Reply	405
2015. ‚	O	O	Reply	405
ÄúTensorizing Neural Networks.	O	O	Reply	405
‚Äù ArXiv:1509.06569 [Cs], September.	O	O	Reply	405
<a href="http://arxiv.org/abs/1509.06569."	O	O	Reply	405
target="_blank" rel="nofollow">http://arxiv.org/abs/1509.06569.</a>	O	O	Reply	405
<sep> [6] Oseledets, Ivan V. "Tensor-train decomposition."	O	O	Reply	405
SIAM Journal on Scientific Computing 33, no.	O	O	Reply	405
5 (2011): 2295-2317.	O	O	Reply	405
<sep> <sep> [7] Cichocki, Andrzej, Namgil Lee, Ivan V. Oseledets, A-H. Phan, Qibin Zhao, and D. Mandic. "	O	O	Reply	405
Low-rank tensor networks for dimensionality reduction and large-scale optimization problems: Perspectives and challenges part 1."	O	O	Reply	405
arXiv preprint arXiv:1609.00893 (2016).	O	O	Reply	405

This paper proposes a first step in the direction of 'real-world relevant RL approaches' in the sense of considering environments that don't halt their execution until an agent has finished its optimal action computation and execution but actually just go on being an environment.	O	O	Review	405
For this, the notion of a concurrent action is introduced.	O	O	Review	405
The paper focuses on value-based RL approaches.	O	O	Review	405
It introduces modifications to the classical MDP formulation such that concurrent actions can be handled.	O	O	Review	405
From a theoretical perspective the resulting Bellman operators (for both continuous and discrete time) remain contractions and thus maintain q-learning convergence guarantees.	O	O	Review	405
Qlearning models are adopted to support concurrent actions and the experiments  demonstrate that the suggested enhancements are working well.	O	O	Review	405
We thank the reviewer for their positive review and an accurate summary of the paper.	O	O	Reply	405

This paper considers the theoretically interesting and practically important problem of concurrent deep reinforcement learning (DRL), i.e., DRL in which the agent has to decide the next action while performing the previous one.	O	O	Review	405
This introduces several significant challenges, including delays/latency and interruption of an on-going action.	O	O	Review	405
To address this issue, this paper proposes to consider the continuous time formulation of the concurrent control problem, derive a continuous-time Bellman equation for the concurrent control scenarios, and then derive its discrete-time counterpart.	O	O	Review	405
Contraction properties are shown for both the continuous-time and discrete-time concurrent Bellman equations, and a value-based DRL algorithm based on the concurrent Bellman equations is proposed and tested on a few tasks.	O	O	Review	405
<sep> <sep> The high level idea of this paper is very interesting and attractive, and in particular, the introduction of continuous-time reinforcement learning is novel.	O	O	Review	405
In addition, the numerical experiments do show that a consistently improved performance of the proposed approach on both synthetic and more real-world robotic control tasks.	O	O	Review	405
However, there are several significant issues about technical clarity or even correctness in this paper, which I elaborate below:	O	O	Review	405
<sep> 1.	B-Review	B-1	Review	405
The settings in sections 3.1 and 3.2 are not clear.	I-Review	I-1	Review	405
In particular, for 3.1, the author may want to specify the policy clearly, including whether it is stationary or non-stationary.	I-Review	I-1	Review	405
And in addition, Q and V functions should either come with a \pi superscript, indicating which policy they use, or a \star superscript to indicate optimality.	I-Review	I-1	Review	405
Section 3.2 does not make sense to me in general.	I-Review	I-1	Review	405
It is not clear what the index i and the state value s_i(t) are.	I-Review	I-1	Review	405
And it is not clear why we need to differentiate between values of states/actions and the functions themselves.	I-Review	I-1	Review	405
The trajectory \tau is also not clearly defined.	I-Review	I-1	Review	405
The authors need to make these much more clear, and should clearly state the main setting/model that the paper is considering (which seems to be the concurrent discrete-time case, but also not very clear to me).	I-Review	I-1	Review	405
<sep> <sep> 2.	O	O	Review	405
The explanation of concurrent actions in continuous and discrete time is not clear.	B-Review	B-2	Review	405
In particular, Section 3.3 only speaks of the settings on a high level, and only brief explanations are given in Figure 1b and the beginning of Section 3.4.	I-Review	I-2	Review	405
Since the concurrent action setting is the central theme in this paper, I think a much more formal explanation should be given about how the system proceeds, instead of just a graphical example illustration.	I-Review	I-2	Review	405
In addition, the concurrent actions in discrete-time setting part is not even clearly mentioned (but is stated in the title of Section 3.3 and discussed subsequently).	I-Review	I-2	Review	405
The authors may also want to explain clearly what the episode is at the beginning of Section 3.4.	I-Review	I-2	Review	405
<sep> <sep> 3.	O	O	Review	405
The concurrent Bellman equation does not make much sense to me.	B-Review	B-3	Review	405
In particular, I think to define the optimal Q function, the bellman equation (7) and (9) should have a \max operator included.	I-Review	I-3	Review	405
Otherwise, it is only for policy evaluation.	I-Review	I-3	Review	405
Since the authors didn't clearly specify what the exact algorithm they are using (apart from a brief explanation by words in Section 3.5), I'm not sure whether I'm missing anything or not.	I-Review	I-3	Review	405
But the authors should definitely include a algorithm frame at least in the appendix, to clearly specify which of and how the concurrent Bellman equations are applied in their algorithm.	I-Review	I-3	Review	405
<sep> <sep> So in sum, although I think the paper is interesting and novel on the high level, I don't think it's ready for publishing.	O	O	Review	405
<sep> <sep> ############ post rebuttal comment ############	O	O	Review	405
After reading the authors' rebuttal and the modified version of the paper, I think most of my concerns have been correctly addressed.	O	O	Review	405
So I decide to improve my score to weak accept.	O	O	Review	405
Thank you for a thorough review.	O	O	Reply	405
Please see our responses to your comments below:	O	O	Reply	405
"1.	O	O	Reply	405
The settings in sections 3.1 and 3.2 are not clear."	O	O	Reply	405
<sep> We agree with the reviewer that the clarity of the setup and the method can be improved.	B-Reply	B-1	Reply	405
We addressed the reviewer‚Äôs comments in the updated version of the paper.	I-Reply	I-1	Reply	405
In particular, we: i) added the missing definitions (e.g. trajectory \tau), ii) clarified the exact problem setup considered, iii) added missing superscripts to the notation and iv) simplified the notation by removing the distinction between bolded and unbolded symbols.	I-Reply	I-1	Reply	405
<sep> <sep> "2.	O	O	Reply	405
The explanation of concurrent actions in continuous and discrete time is not clear."	O	O	Reply	405
<sep> Thank you for this excellent suggestion.	O	O	Reply	405
We added a section (i.e. Section 3.1) and illustrative figure (i.e. Figure 4) that hopefully clarify the main aspect of the paper.	B-Reply	B-2	Reply	405
We also added the definition of the episode as suggested by the reviewer.	I-Reply	I-2	Reply	405
<sep> <sep> "3.	O	O	Reply	405
The concurrent Bellman equation does not make much sense to me. "	O	O	Reply	405
<sep> Thank you for your suggestions.	O	O	Reply	405
We updated the manuscript to provide the details about the exact algorithm that was used in the experiments, which hopefully clarifies how the introduced method fits into a bigger robot-learning framework.	B-Reply	B-3	Reply	405
We also added an algorithm frame in the Appendix that should allow readers to fully understand the contribution of this paper.	I-Reply	I-3	Reply	405
We also applied the changes to the concurrent Bellman operator that include taking the maximum over actions.	I-Reply	I-3	Reply	405

The paper tackles the problem of making decisions for the next action while still engaged in doing the previous actions.	O	O	Review	405
Such a delay could either be part of the design (like a robot deciding the next action before its actors and motors have come to full rest after the current action) or an artefact of the delays inherent in the system (i.e. latency induced by calculations or latency of sensors).	O	O	Review	405
The paper shows how to model such delays within the Q-learning framework, show that their modelling preserves desirable contraction property of the Bellman update operator, and put their model into practice by an extensive set of experiments: learning policies for several simulated and a real-world setting.	O	O	Review	405
<sep> <sep> The authors claim that that addition of this "delay" does not hinder the performance much of the RL method is given sufficient "context" about the delay, i.e., given extra features as input in order to learn to compensate for it.	O	O	Review	405
The writing of the paper is lucid and sufficient background is provided to make the paper self-sufficient in its explanations.	O	O	Review	405
<sep> <sep> However, there are some reasons which do not allow me to fully support the paper's acceptance.	O	O	Review	405
<sep> <sep> The changes made to the basic Q-learning setup, albeit novel and with desirable properties, in my opinion, are (i) theoretically relatively straight forward, (ii) are not expressive enough to capture the problem in its full generality (explained later), and (iii) need more empirical justification with problems where their modification is indeed indispensable.	B-Review	B-1	Review	405
The authors touch on several different research areas cursorily (viz.	I-Review	I-1	Review	405
continuous reinforcement learning, Bellman contractions, feature engineering) while providing grounds for their idea, but in the end return to the familiar domain of discrete Q-learning with semi-hand-crafted (though theoretically motivated) features where the latency of actions can take a set of fixed values and the state is sampled at fixed intervals.	I-Review	I-1	Review	405
<sep> <sep> If the actions are continuous, then could method from Doya (2000) directly be used to solve these problems?	B-Review	B-2	Review	405
Can the value-based models which he describes be augmented and extensions developed which build on Lemma 3.1 instead of the well-trodden ground of Lemma 3.2?	I-Review	I-2	Review	405
Especially, if one of the objectives which the authors claim their policies are better is "policy duration", then the absence of purely continuous policies is particularly egregious.	I-Review	I-2	Review	405
Further, reducing the policy duration seems like an independent objective which perhaps can be used for reward shaping for the traditional policy methods, which will also lead to different baselines.	I-Review	I-2	Review	405
<sep> <sep> The authors explicitly say that their method focuses on "optimizing for a specific latency regime as opposed to being robust to all of them;" and that they explicitly avoid learning forward models by including additional features.	B-Review	B-3	Review	405
However, the advantages of placing such restrictions on the design space are unclear at best.	I-Review	I-3	Review	405
Would it be the case that the high-dimensional methods will fail in this setting?	I-Review	I-3	Review	405
Are there theoretical advantages to working on limiting the attention to known latency regimes?	I-Review	I-3	Review	405
I suspect that the authors have concrete reasons for making these design decisions, but these do not come across in the paper in the writing, or by means of additional baselines.	I-Review	I-3	Review	405
<sep> <sep> As an example of a different approach towards the problem, which the authors overlook in their related work section, is that of learning with spiking neurons and point processes.	B-Review	B-4	Review	405
These areas of research have also been interested in problems of the "thinking while moving" nature: that of reinforcement learning in the context of neurons where the neurons act by means of spikes in response to the environment and other "spikes" [1, 2]. More recently, with point processes, methods have been developed to attain truly asynchronous action and state updates [3, 4]. A differently motivated work which ends up dealing with similar problems is in the direction of adaptive skip intervals [5], where the network also chooses the "latency" in the discrete sense.	I-Review	I-4	Review	405
Adding such related work would help better contextualize this paper.	I-Review	I-4	Review	405
<sep> <sep> Some other ways the authors can improve the paper are (in no particular order):	B-Review	B-5	Review	405
<sep> - The description of the Vector-to-go is insufficient; some concrete examples will help.	I-Review	I-5	Review	405
<sep> - The results of the simulated experiments are given in the form of distributions and it is very difficult to discern the effect of individual features in Figure 1.	I-Review	I-5	Review	405
Additionally, due to missing error bars, or other measures of uncertainty, the claim that the performance of models with and without the delayed-actions is comparable to the blocking setting seems tenuous at best, just looking at the rewards.	I-Review	I-5	Review	405
<sep> - In particular, for the real experiments, we need more details about the experiment runs to determine why the performance of the policies in the real world is so vastly different.	I-Review	I-5	Review	405
Could the authors describe why the gap can be completely covered through simulations but not in the real world?	I-Review	I-5	Review	405
<sep> <sep> [1]: Vasilaki, Eleni, et al "Spike-based reinforcement learning in continuous state and action space: when policy gradient methods fail."	O	O	Review	405
PLoS computational biology 5.12 (2009): e1000586.	O	O	Review	405
<sep> [2]: Fr√©maux, Nicolas, Henning Sprekeler, and Wulfram Gerstner. "	O	O	Review	405
Reinforcement learning using a continuous time actor-critic framework with spiking neurons."	O	O	Review	405
PLoS computational biology 9.4 (2013): e1003024.	O	O	Review	405
<sep> [3]: Upadhyay, Utkarsh, Abir De, and Manuel Gomez Rodriguez. "	O	O	Review	405
Deep reinforcement learning of marked temporal point processes."	O	O	Review	405
Advances in Neural Information Processing Systems.	O	O	Review	405
2018.	O	O	Review	405
<sep> [4]: Li, Shuang, et al "Learning temporal point processes via reinforcement learning."	O	O	Review	405
Advances in Neural Information Processing Systems.	O	O	Review	405
2018.	O	O	Review	405
<sep> [5]: Neitz, Alexander, et al "Adaptive skip intervals: Temporal abstraction for recurrent dynamical models."	O	O	Review	405
Advances in Neural Information Processing Systems.	O	O	Review	405
2018.	O	O	Review	405
We thank the reviewer for their constructive feedback and exceptionally detailed review.	O	O	Reply	405
<sep> <sep> We agree with the reviewer that although our theoretical justification is based on continuous-time RL and discusses a general framework for handling delays in Q-learning (continuous or discrete), our actual experiments return to the ‚Äúwell-trodden‚Äù regime of discrete-time RL with an auxiliary VTG input to the critic network.	B-Reply	B-1	Reply	405
Regardless of whether the setting is continuous or discrete time RL, the problem of dealing with delays in RL persists.	I-Reply	I-1	Reply	405
To the best of our knowledge, most of the SOTA DRL implementations are based on discrete-time RL formulations.	I-Reply	I-1	Reply	405
We are not aware of any image-based DRL results that use a continuous-time RL formulation.	I-Reply	I-1	Reply	405
While that may be an interesting avenue, we believe this is outside of the scope of our work and believe our method to adapt discrete methods to handle delays is another way to approach the problem.	I-Reply	I-1	Reply	405
We clarified this in Section 2.	I-Reply	I-1	Reply	405
<sep> <sep> We agree with the reviewer that since ‚Äúpolicy duration‚Äù is a quantitative metric that we use to support our claim of faster learned trajectories, a reasonable baseline method should incorporate this optimization goal.	B-Reply	B-2	Reply	405
The baseline model we compare against penalizes slower policies that take more episode steps through reward discount gamma as well as an timestep penalty, a hyperparameter that returns a fixed negative reward every timestep.	I-Reply	I-2	Reply	405
This timestep penalty was tuned through a hyperparameter search, and is described in further detail in the Appendix.	I-Reply	I-2	Reply	405
Additionally, in Table 1 we add two baselines that do not utilize this reward penalty.	I-Reply	I-2	Reply	405
<sep> <sep> We also thank the reviewer for suggesting that we clarify the motivations behind restricting the design space.	B-Reply	B-3	Reply	405
We focus our study on model-free methods because image-based model-based methods, such as video prediction models, are challenging to learn and an active area of research that is tangential to our main focus of studying concurrent environments.	I-Reply	I-3	Reply	405
We limit our environments to known latency regimes because this is motivated by real-world robotics setups, where latencies can often be constrained within known upper bounds.	I-Reply	I-3	Reply	405
<sep> <sep> We appreciate the reviewer introducing additional related work and improvements that would help contextualize our contribution.	B-Reply	B-4	Reply	405
These are exciting research directions that we think show much promise for when they are applied to vision-based robotic control tasks.	I-Reply	I-4	Reply	405
We added a description of spiking neurons, point processes, and adaptive skip intervals in Section 2.	I-Reply	I-4	Reply	405
<sep> <sep> "1.	I-Reply	I-4	Reply	405
The description of the Vector-to-go is insufficient."	I-Reply	I-4	Reply	405
<sep> Thank you for this suggestion.	I-Reply	I-4	Reply	405
We have clarified the description of concurrent knowledge representations with a section in the appendix as well as with Figure 5.	I-Reply	I-4	Reply	405
<sep> <sep> "2.	I-Reply	I-4	Reply	405
The results of the simulated experiments are given in the form of distributions and it is very difficult to discern the effect of individual features in Figure 1.	I-Reply	I-4	Reply	405
Additionally, due to missing error bars, or other measures of uncertainty, the claim that the performance of models with and without the delayed-actions is comparable to the blocking setting seems tenuous at best."	I-Reply	I-4	Reply	405
<sep> We assume the reviewer is referring to Figure 2, not Figure 1, as our robotic grasping experiments do indeed report confidence intervals computed over multiple random seeds or real-world evaluations.	I-Reply	I-4	Reply	405
Figure 2 is a hyperparameter sensitivity plot obtained by performing a hyperparameter tuning experiment across many training runs of the CartPole and Pendulum control tasks.	I-Reply	I-4	Reply	405
The hyperparameter configurations are then sorted from best to worst, with the X axis plotting the sorted rank of the experiment.	I-Reply	I-4	Reply	405
One can interpret the entire plot as a distribution over returns over N experiments, where shorter-tailed distributions imply that the method more ‚Äúrobust‚Äù.	I-Reply	I-4	Reply	405
Larger area-under-curve means that obtaining good performance is less sensitive to choice of hyperparameters (which is crucial for getting RL algorithms to work on real robots, where sample complexity is prohibitive).	I-Reply	I-4	Reply	405
<sep> <sep> Because this computationally expensive hyperparameter optimization procedure does not yield multiple i.i.d.	I-Reply	I-4	Reply	405
experiments w.r.t a single hyperparameter configuration (for computational efficiency), we cannot estimate per-experiment uncertainty from this dataset as commonly done in RL.	I-Reply	I-4	Reply	405
<sep> <sep> "3.	I-Reply	I-4	Reply	405
Could the authors describe why the gap can be completely covered through simulations but not in the real world?"	I-Reply	I-4	Reply	405
<sep> Thank you for this suggestion.	I-Reply	I-4	Reply	405
To be completely frank, we are not sure exactly why the large-scale grasping success could be covered in the simulated but not in the real world.	I-Reply	I-4	Reply	405
However, real-world robotic tasks are difficult and sensitive to many parameters.	I-Reply	I-4	Reply	405
Given that, we still felt it important to report the full results.	I-Reply	I-4	Reply	405
We also added more experiment details in the Appendix.	I-Reply	I-4	Reply	405
<sep> <sep> Finally, we would like to thank the reviewer for summarizing the main concerns.	I-Reply	I-4	Reply	405
We felt these insightful comments could be useful to other reviewers, and added our response to the general comment.	I-Reply	I-4	Reply	405

1.	O	O	Review	20080
Summary	O	O	Review	20080
<sep> The authors report on an empirical study of emergent behavior of multiple RL agents learning to play hide-and-seek (a sparse reward task).	O	O	Review	20080
The main point of this paper is that RL agents learning at scale (large number of samples, batch-size 64000).	O	O	Review	20080
can learn to solve tasks with strategies that are human-interpretable (e.g., using ramps, boxes).	O	O	Review	20080
Scale also requires various simplifications (e.g., keeping the learning setup as close as possible to a single-agent problem as possible).	O	O	Review	20080
<sep> <sep> Agents are grouped in 2 teams (seekers, hiders).	O	O	Review	20080
Each agent receives a team reward, e.g., it can be punished for events that it did not participate in, e.g., if a team-mate is seen by an opponent.	O	O	Review	20080
If hiders are hidden, seekers also automatically see reward.	O	O	Review	20080
The first 40% of the episode there is no reward to let hiders hide.	O	O	Review	20080
<sep> <sep> There is one actor model, all agents share weights.	B-Review	B-5	Review	20080
Hence this is self-play: hiders and seekers use the same agent model.	I-Review	I-5	Review	20080
Also, all agents use a central value function that can see the entire state (decentralized execution, centralized learning).	B-Review	B-6	Review	20080
This makes the setting basically a single-agent problem, with the only decentralized aspect being each actor model only receiving its own observation.	I-Review	I-6	Review	20080
Note that a large body of multi-agent RL work in fact uses agents that do not share weights, etc.	I-Review	I-6	Review	20080
<sep> <sep> Other features described:	B-Review	B-7	Review	20080
- Auto-curricula: e.g. agents find new strategies (using ramps, boxes) that other agents have to counteract.	I-Review	I-7	Review	20080
<sep> - Human-relevant skills: They report that the agent model learns multiple ways to interact with (objects in) the environment that are semantically interesting (resembles something humans might do).	I-Review	I-7	Review	20080
<sep> - Authors compare with policies learning via intrinsic motivation.	I-Review	I-7	Review	20080
<sep> - Evaluation through transfer learning shows some benefit of transfer of hide-seek agents to auxiliary tasks.	I-Review	I-7	Review	20080
However, it is not so clear how this evaluation informs future work on transfer learning (e.g., how would you pick evaluation tasks for a given train-task?)	I-Review	I-7	Review	20080
<sep> <sep> 1.	O	O	Review	20080
Decision (accept or reject) with one or two key reasons for this choice.	O	O	Review	20080
<sep> <sep> Reject.	O	O	Review	20080
<sep> <sep> The main point of the paper is empirical RL at scale.	B-Review	B-1	Review	20080
Although the learned behaviors are human-interpretable, this does not seem surprising given the fact that in many (large-scale) RL applications (Atari games, Go, DotA 2, Starcraft), it has been observed that RL agents can learn to manipulate and use their environment (which includes other agents!)	I-Review	I-1	Review	20080
in unexpected ways / find creative ways to exploit the reward function (see e.g. demos in <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html)."	I-Review	I-1	Review	20080
target="_blank" rel="nofollow">https://www.alexirpan.com/2018/02/14/rl-hard.html).</a> There has also been work on object-level RL [Agnew, Domingos 2018], which involves agents interacting with objects in the environment.	B-Review	B-2	Review	20080
Compared to this, the observation that RL agents learn human-interpretable uses of objects does not seem surprising.	I-Review	I-2	Review	20080
<sep> <sep> The paper also does not give new insights in how to make large-scale RL ``'work'.	B-Review	B-3	Review	20080
For instance, there are no significant differences in algorithm / model structure from DotA / Starcraft agents that can inform future large-scale experiments.	I-Review	I-3	Review	20080
<sep> <sep> The paper also does not introduce new concrete evaluation metrics that can apply to other tasks / RL problems, skill detection / segmentation methods to learn the structure of auto-curricula.	B-Review	B-4	Review	20080
Furthermore, the setup is very close to a single-agent problem (see above), and is far simpler in the multi-agent assumptions from other decentralized multi-agent work (Foerster 2018, Jacques 2019, etc).	I-Review	I-4	Review	20080
Thank you for your review and constructive criticisms!	O	O	Reply	20080
We‚Äôll try to address each piece of criticism in turn.	O	O	Reply	20080
<sep> <sep> ‚Äî ‚ÄúThe main point of the paper is empirical RL at scale‚Äù	O	O	Reply	20080
<sep> The main point we hope to convey is that large-scale multi-agent reinforcement learning (MARL) can lead to self-supervised autocurricula in which agents learn successively more complex human-relevant skills such as construction and tool use.	B-Reply	B-1	Reply	20080
We absolutely agree that there have been many amazing previous results from MARL at scale, and we acknowledge many of the works you mention and more in our introduction and related work sections.	I-Reply	I-1	Reply	20080
We believe our work differs from these in that our environment is built from very simple components in a physically grounded simulator, making it extremely extensible.	I-Reply	I-1	Reply	20080
It is much more clear how one could add to or modify the hide-and-seek environment to include more human-relevant components than it is how one could modify games like Go, Dota, or Starcraft.	I-Reply	I-1	Reply	20080
<sep> <sep> ‚Äî ‚ÄúThere has also been work on object-level RL ‚Ä¶ the observation that RL agents learn human-interpretable uses of objects does not seem surprising.	O	O	Reply	20080
‚Äù	O	O	Reply	20080
<sep> We agree that there has been much work on object-level RL.	B-Reply	B-2	Reply	20080
We didn‚Äôt advertise this as a novel portion of our work, and we‚Äôve already included many citations that use object-level architectures and attention at the end of Section 4.	I-Reply	I-2	Reply	20080
We also acknowledge that there have been prior works where RL learns human-interpretable uses of objects, which is why we include a paragraph in Section 2 on prior work in tool-use; however, our work can be distinguished from these and the work you cite in that we provide no explicit signal for interacting with objects; the pressure to interact with the objects is solely a result of multi-agent competition.	I-Reply	I-2	Reply	20080
<sep> <sep> ‚Äî ‚ÄúThe paper also does not give new insights in how to make large-scale RL work‚Äù	O	O	Reply	20080
<sep> This paper was not on how to make large-scale RL work, but rather on showing the power of current large-scale RL algorithms in a new setting that is more physically grounded and human-relevant than previous settings like DotA, Starcraft, and Go.	B-Reply	B-3	Reply	20080
The main argument of the paper is that multi-agent autocurricula can lead to agents learning many human-relevant skills like tool-use and construction; the fact that we required no new significant algorithmic modifications actually strengthens this point in our opinion, as the results can‚Äôt be confused as a pathology of a new specific algorithm.	I-Reply	I-3	Reply	20080
That being said, we agree that it is a great direction for future research to incorporate methods that can learn faster or better in this environment.	I-Reply	I-3	Reply	20080
<sep> <sep> ‚Äî ‚ÄúThe paper also does not introduce new concrete evaluation metrics that can apply to other tasks / RL problems...‚Äù	O	O	Reply	20080
<sep> It‚Äôs very hard to create transfer tasks that are valid across domains.	B-Reply	B-4	Reply	20080
However, we hope that the tasks we proposed can be used as transfer metrics for any future research within our domain (both of which we will open source).	I-Reply	I-4	Reply	20080
<sep> <sep> ‚Äî ‚ÄúThere is one actor model, all agents share weights‚Äù	O	O	Reply	20080
<sep> Using shared weights, or at least some portion of training data coming from self-play, is very common (AlphaGo, DotA, Alphastar, Capture-the-Flag, NeuralMMO, etc.),	B-Reply	B-5	Reply	20080
and it doesn‚Äôt alter the multi-agent optimization objective.	I-Reply	I-5	Reply	20080
Each agent still takes a greedy gradient and has its own observations and memory state so that at execution they use no privileged information.	I-Reply	I-5	Reply	20080
Shared weights does not mean uni-brain (one brain many actions), which would indeed reduce this to a single agent problem.	I-Reply	I-5	Reply	20080
That being said, we‚Äôve run the hide-and-seek experiment with separate weights for each agent and as expected have seen no difference in learned strategy.	I-Reply	I-5	Reply	20080
<sep> <sep> ‚Äî ‚Äúall agents use a central value function that can see the entire state.	O	O	Reply	20080
This makes the setting basically a single-agent problem and is far simpler in the multi-agent assumptions from other decentralized multi-agent work‚Äù	O	O	Reply	20080
<sep> This is a commonly used method to reduce policy gradient variance in partially observed settings without letting agents cheat at execution time both for MARL (MADDPG, Counterfactual RL, AlphaStar) and also single agent RL (Dactyl, Asymmetric Actor Critic).	B-Reply	B-6	Reply	20080
We ablate this choice in the appendix and find that it is important at the given scale of compute but agents still learn without it.	I-Reply	I-6	Reply	20080
<sep> <sep> As for other MARL algorithms, we cite both of the works you mention in our paper already, and it is an excellent line of future research to incorporate methods like these into setups such as hide-and-seek to see if they bring benefit to learning.	I-Reply	I-6	Reply	20080
However, we don‚Äôt think algorithmic simplicity is a fault of our work but rather a strength.	I-Reply	I-6	Reply	20080
We show that with only standard simple algorithms, multi-agent autocurricula can lead to human-relevant skills like construction and tool-use in physically grounded environments, which we believe provides a good baseline for future algorithmic research.	I-Reply	I-6	Reply	20080

Authors in introduce a new competitive/cooperative physics-based environment in which different teams of agents compete in a visual concealment and search task with visibility-based team-based rewards (although There are no explicit incentives for agents to interact with objects in the environment).	O	O	Review	20080
They show that, complex behaviour emerge as the episode progresses and agents are able to learn 6 emergent skills/(counter-)strategies (including tool use), where agents intentionally change their environment to suit their needs.	O	O	Review	20080
Agents trained using self-play	O	O	Review	20080
<sep> In my opinion, this is an excellent paper which main contribution is to provide experimental evidence that relevant and complex skills and strategies can emerge from multi-agent RL competing scenarios.	O	O	Review	20080
<sep> <sep> Minor comments:	O	O	Review	20080
<sep> - Hide&amp;seek rules and safety issues: is it not supposed that hiders and the seekers could not get together (i.e., hiders cannot push seekers or as we can see in some videos)?	B-Review	B-1	Review	20080
Furthermore, it is surprising (one would say worrying) that hiders identified the barriers as an impediment to the seeker (not only as a way to hide).	I-Review	I-1	Review	20080
I wouldn‚Äôt say that this is a ‚Äú human-relevant strategies and skills ‚Äú as the authors claim.	I-Review	I-1	Review	20080
Hider agents even double walled seekers!	I-Review	I-1	Review	20080
<sep> - Have the authors thought about joining the Animal-AI Olympics (<a href="http://animalaiolympics.com/)" target="_blank" rel="nofollow">http://animalaiolympics.com/)</a> competition?	B-Review	B-2	Review	20080
It would be a great opportunity to to test the skills of your agents in a further general testing scenario.	I-Review	I-2	Review	20080
They provide an arena (test-bed) which contains 300 different intelligent tests for testing the cognitive abilities of RL agents (<a href="https://www.mdcrosby.com/blog/animalaiprizes1.html)" target="_blank" rel="nofollow">https://www.mdcrosby.com/blog/animalaiprizes1.html)</a> which have to interact with the environment.	I-Review	I-2	Review	20080
<sep> <sep> Thank you for the review and questions!	O	O	Reply	20080
<sep> <sep> ‚Äî ‚ÄúHide&amp;seek rules and safety issues: is it not supposed that hiders and the seekers could not get together (i.e., hiders cannot push seekers or as we can see in some videos)?	O	O	Reply	20080
Furthermore, it is surprising (one would say worrying) that hiders identified the barriers as an impediment to the seeker (not only as a way to hide).	O	O	Reply	20080
I wouldn‚Äôt say that this is a ‚Äú human-relevant strategies and skills ‚Äú as the authors claim.	O	O	Reply	20080
Hider agents even double walled seekers!‚Äù	O	O	Reply	20080
<sep> In the environment as is, the hiders can push the seekers during the preparation phase.	B-Reply	B-1	Reply	20080
It‚Äôs unclear that this is bad, but we agree that we could easily make it not the case, though it likely would not change the skill progression in the main hide-and-seek environment.	I-Reply	I-1	Reply	20080
However, as you note, this can definitely change the resulting skill progression in other game variants (Figure A.8).	I-Reply	I-1	Reply	20080
We also believe finding methods that can make agents converge on safe outcomes is an important direction for future research!	I-Reply	I-1	Reply	20080
<sep> <sep> ‚ÄúHave the authors thought about joining the Animal-AI Olympics (<a href="http://animalaiolympics.com/)" target="_blank" rel="nofollow">http://animalaiolympics.com/)</a> competition?‚Äù	O	O	Reply	20080
<sep> ‚Äî We thought this would be outside the scope of our current work, but we agree this challenge is very interesting.	B-Reply	B-2	Reply	20080
However, from the description it feels slightly different than the transfer tasks we propose.	I-Reply	I-2	Reply	20080
They say ‚ÄúThe goal will always be to retrieve the same food items by interacting with previously seen objects,‚Äù where in our transfer tests agents are given very different objectives from the original objective of hide-and-seek.	I-Reply	I-2	Reply	20080

# Review ICLR20, Emergent Tool Use...	O	O	Review	20080
<sep> This review is for the originally uploaded version of this article.	O	O	Review	20080
Comments from other reviewers and revisions have deliberately not been taken into account.	O	O	Review	20080
After publishing this review, this reviewer will participate in the forum discussion and help the authors improve the paper.	O	O	Review	20080
<sep> <sep> I apologize in advance for being reviewer 2.	O	O	Review	20080
<sep> <sep> ## Overall	O	O	Review	20080
<sep> **Summary**	O	O	Review	20080
<sep> The article introduces a new multi-agent physics environment called "hide-and-seek".	O	O	Review	20080
The authors trained agents in this environment and studied the emergence of and changes in strategies.	O	O	Review	20080
The authors also study the performance of these same agents in new "targeted intelligence tests" compared to training from scratch and compared to agents trained with curiosity.	O	O	Review	20080
<sep> <sep> **Overall Opinion**	O	O	Review	20080
<sep> I think the environment is very appealing and the paper is overall well-structured and demonstrates novel work.	O	O	Review	20080
Therefore I'd recommend this paper to be accepted.	O	O	Review	20080
That being said, there are glaring issues with some of the writing that need to be addressed before I think this work conforms to the standards of ICLR.	O	O	Review	20080
However, if these issues are addressed, I have no issue increasing my review score.	O	O	Review	20080
<sep> <sep> Main problems:	O	O	Review	20080
<sep> - The majority of the paper presents essentially a case study of what happened during a single seed of policy training.	B-Review	B-10	Review	20080
For RL literature that's very uncommon and I think it's consensus that DRL is very sensitive to random seeds.	I-Review	I-10	Review	20080
I know that you do have additional seeds in the appendix, but why didn't you mention those in the main body of the paper?	I-Review	I-10	Review	20080
You seem to have found some robustness against multiple seeds, so why not show it?	I-Review	I-10	Review	20080
And also the fact that Figure 1 &amp; 3 only apply to 1 seed is not mentioned.	I-Review	I-10	Review	20080
I think this is easy enough to fix - I suggest since you're already at 10 pages, to just bring in the additional seeds from the appendix and average over their performance in Fig.1&amp;3.	I-Review	I-10	Review	20080
<sep> - The contributions section is overselling the work: (1) states that autocurricula lead to changes in agent strategy - Maybe I'm mistaken here but that sounds like a tautology.	B-Review	B-11	Review	20080
In other words, "a self-generated sequence of challenges" ("Autocurricula", according to [Leibo et al 2019][1]) lead to changes in strategy.	I-Review	I-11	Review	20080
And (3) advertises "a proposed framework for evaluating agents in open-ended environments" and also "a suite of targeted intelligence tests for our domain".	I-Review	I-11	Review	20080
The former of those two is either not in the paper or you mean your section "6.2 Transfer and Fine-Tuning as Evaluation", which isn't novel (see e.g. [Alain &amp; Bengio, 2016][2])	I-Review	I-11	Review	20080
- Your acknowledgments should be anonymized until publication.	B-Review	B-12	Review	20080
Otherwise, reviewers might draw conclusions which group published this work, thus violating the double-blind review procedure.	I-Review	I-12	Review	20080
<sep> <sep> [1]: <a href="https://arxiv.org/pdf/1903.00742.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1903.00742.pdf</a>	O	O	Review	20080
[2]: <a href="https://arxiv.org/pdf/1610.01644.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1610.01644.pdf</a>	O	O	Review	20080
<sep> Like I mentioned above, I think these are all easy to address, which should allow acceptance of this work.	O	O	Review	20080
Here are some additional questions, comments, and nitpicks:	O	O	Review	20080
<sep> ## Specific comments and questions	O	O	Review	20080
<sep> ### Abstract	O	O	Review	20080
<sep> - "evidence that ... competition may scale better with increasing environment complexity" - that's only shown in the appendix	B-Review	B-13	Review	20080
<sep> ### Intro	O	O	Review	20080
<sep> - You mention TD-Gammon as a game, but I think it's an algorithm for the game Backgammon, similarly to how "Go" is the game and "AlphaGo" is an algorithm for playing.	B-Review	B-14	Review	20080
<sep> <sep> ### Rel.	O	O	Review	20080
Work	O	O	Review	20080
<sep> - all good	O	O	Review	20080
<sep> ### Hide And Seek	O	O	Review	20080
<sep> - Arena boundaries: What's the penalty and what's " too far outside the play area"?	B-Review	B-15	Review	20080
And in all depictions, it looks like the geometry of the arena is elevated around the edges and the agents don't have a jump action, so how would they ever go out of borders?	I-Review	I-15	Review	20080
After watching the videos: Apparently, the jagged-looking arena boundary in the videos is purely cosmetic and agents can still access that space.	I-Review	I-15	Review	20080
This is unclear from just the paper and the renderings in Figure 1.	I-Review	I-15	Review	20080
<sep> <sep> ### Policy Optimization	O	O	Review	20080
<sep> - Policy network and fusion are underspecified: How do you deal with the varying number of agents, boxes, obstacles?	B-Review	B-9	Review	20080
Do you just set the x/v of the missing pieces to zero or is the observation actually of a different shape in case there are more/fewer objects or agents?	I-Review	I-9	Review	20080
How's the embedding done that is depicted in Figure 2?	I-Review	I-9	Review	20080
Also, I didn't see the embedding being mentioned in the text - any reason for that?	I-Review	I-9	Review	20080
<sep> - Figure 2 - This diagram is visually appealing but confusing and needs to be improved.	B-Review	B-1	Review	20080
Why does the agent's embedding say "1"?	I-Review	I-1	Review	20080
Why do the other agents' embeddings have a "-1" at the end of the orange box and the others don't?	I-Review	I-1	Review	20080
Is the agent's embedding concatenated with the other embeddings?	I-Review	I-1	Review	20080
If so, why and how (concat, sum, multiply, conditional batch norm, etc.)?	I-Review	I-1	Review	20080
In the center and on the right you use a blue block to indicate the agent's embedding and then at the bottom right you seem to use it as a network component or something (between the "LSTM")?	B-Review	B-2	Review	20080
If you're trying to signal that this is the agent's perception at different stages in the network, I'd use a different color to separate it from the agent's lidar and pos/vel.	I-Review	I-2	Review	20080
You don't mention that "x,v" stands for "position, velocity".	B-Review	B-3	Review	20080
<sep> ### Auto-curriculum and Emergent Behavior	O	O	Review	20080
<sep> - Figure 3: "environment-specific" (add dash).	B-Review	B-4	Review	20080
Draw skill development boundaries like in Fig.1.	I-Review	I-4	Review	20080
<sep> - How exactly does the "surfing" work?	B-Review	B-5	Review	20080
The seekers step (not jump, right, since there is no jumping?)	I-Review	I-5	Review	20080
onto the boxes and then what?	I-Review	I-5	Review	20080
The momentum propels the box forward?	I-Review	I-5	Review	20080
Do other seekers push the box?	I-Review	I-5	Review	20080
Their movement on top of the box somehow moves the box (this seems to be the case judging by the videos but this is the least physically plausible)?	I-Review	I-5	Review	20080
This is a super interesting adaptation but I'd suspect the physics simulation to have a bug/glitch that's being exploited here.	I-Review	I-5	Review	20080
<sep> - You mention in footnote 3 that the developmental stage and changes in reward aren't necessarily correlated.	B-Review	B-6	Review	20080
The same seems to be true for the metrics in Fig.3, which raises the question how did you come up with those boundaries for the different developmental stages in Fig.1?	I-Review	I-6	Review	20080
Did someone look at rollouts from the trained policy every couple of million steps?	I-Review	I-6	Review	20080
And do all agents learn new skills at the same time or is there a delay?	B-Review	B-7	Review	20080
From my understanding, they are all using the same policy and critic networks but maybe dependent on the proximity of an agent to an object/obstacle, it's easier or harder to execute.	I-Review	I-7	Review	20080
<sep> <sep> ### Evaluation	O	O	Review	20080
<sep> - clear and well-written, slightly too much content in the appendix and not enough in the main paper.	B-Review	B-8	Review	20080
Weird appendix numbering - A.6 appears in the main paper pages after A.7	I-Review	I-8	Review	20080
<sep> ### Discussion and Future Work	O	O	Review	20080
<sep> - all good	O	O	Review	20080
<sep> ### Appendix	O	O	Review	20080
<sep> - I appreciate the TOC.	O	O	Review	20080
I did not look into Appendix B-D because it's another 10 pages on top of the 10 pages of the article.	O	O	Review	20080
<sep> <sep> All in all an interesting work.	O	O	Review	20080
Good luck with the rebuttal/discussion.	O	O	Review	20080
‚Äî ‚ÄúIs the agent's embedding concatenated with the other embeddings?	O	O	Reply	20080
If so, why and how (concat, sum, multiply, conditional batch norm, etc.)?‚Äù	O	O	Reply	20080
<sep> We concatenate all the entities together, such that the tensor has shape (number entities, entity dimension), run residual self attention, and then average pool getting a fixed sized vector of size (entity dimension).	B-Reply	B-1	Reply	20080
We‚Äôll add this clarification to the text.	I-Reply	I-1	Reply	20080
<sep> <sep> ‚Äî ‚ÄúIn the center and on the right you use a blue block to indicate the agent's embedding and then at the bottom right you seem to use it as a network component or something (between the "LSTM")?	O	O	Reply	20080
If you're trying to signal that this is the agent's perception at different stages in the network, I'd use a different color to separate it from the agent's lidar and pos/vel.	O	O	Reply	20080
‚Äù	O	O	Reply	20080
<sep> All the colored blocks represent activations in this diagram, but we agree re-using the blue coloring could be confusing.	B-Reply	B-2	Reply	20080
We‚Äôll change the color of the final two blue blocks for the camera ready version of the paper.	I-Reply	I-2	Reply	20080
<sep> <sep> ‚Äî ‚ÄúYou don't mention that "x,v" stands for "position, velocity".	O	O	Reply	20080
‚Äù	O	O	Reply	20080
<sep> Good catch!	B-Reply	B-3	Reply	20080
Thank you, we‚Äôll add a clarification to the text.	I-Reply	I-3	Reply	20080
<sep> <sep> ‚Äî ‚ÄúFigure 3: "environment-specific" (add dash).	O	O	Reply	20080
Draw skill development boundaries like in Fig.1.‚Äù	O	O	Reply	20080
<sep> Good suggestions.	B-Reply	B-4	Reply	20080
Thank you!	I-Reply	I-4	Reply	20080
<sep> <sep> ‚Äî ‚ÄúHow exactly does the "surfing" work?	O	O	Reply	20080
The seekers step (not jump, right, since there is no jumping?)‚Äù	O	O	Reply	20080
<sep> We do classify this as an exploit of the rules we designed in the last paragraph of Section 7, but we will add more clarification on how it works and that it is an exploit of our intended game rules in Section 5.	B-Reply	B-5	Reply	20080
You are right in that they more ‚Äústep‚Äù or ‚Äúlaunch‚Äù themselves from a ramp to the box.	I-Reply	I-5	Reply	20080
Once on top of the box, they can still ‚Äúgrab‚Äù the box, which keeps the relative orientation and position between agent and box fixed.	I-Reply	I-5	Reply	20080
The agents‚Äô movement action puts a force on the agent regardless of whether the agent is on the ground or not.	I-Reply	I-5	Reply	20080
So if the agent does this while grabbing the box, they will both move together since they have a fixed relative orientation and position.	I-Reply	I-5	Reply	20080
<sep> <sep> ‚Äî ‚ÄúYou mention in footnote 3 that the developmental stage and changes in reward aren't necessarily correlated.	O	O	Reply	20080
The same seems to be true for the metrics in Fig.3, which raises the question how did you come up with those boundaries for the different developmental stages in Fig.1?	O	O	Reply	20080
Did someone look at rollouts from the trained policy every couple of million steps?‚Äù	O	O	Reply	20080
<sep> We used a combination of looking at the reward, behavioral statistics (Figure 3), and watching trajectories.	B-Reply	B-6	Reply	20080
It is a very interesting line of future research to automatically detect large shifts in agent strategy!	I-Reply	I-6	Reply	20080
<sep> <sep> ‚ÄúAnd do all agents learn new skills at the same time or is there a delay?	O	O	Reply	20080
From my understanding, they are all using the same policy and critic networks but maybe dependent on the proximity of an agent to an object/obstacle, it's easier or harder to execute.	O	O	Reply	20080
‚Äù	O	O	Reply	20080
<sep> ‚Äî All agents have the same weights so they would learn the skill at the same time.	B-Reply	B-7	Reply	20080
However, we‚Äôve run some experiments where each agent has a different policy and we did not notice any significant differences to the shared weight case.	I-Reply	I-7	Reply	20080
Using shared weights is simpler to implement and cheaper to train, which is why we use them for all of our experiments.	I-Reply	I-7	Reply	20080
Anecdotally, agents‚Äô seems to learn the skills for easier cases in the environment first; for instance we notice they often learn to construct a 1 block barricade using existing walls before they learn to construct a 3 block fort in the center of the room.	I-Reply	I-7	Reply	20080

* Summary	O	O	Review	407
This paper addresses machine reading tasks involving tracking the states of entities over text.	O	O	Review	407
To this end, it proposes constructing a knowledge graph using recurrent updates over the sentences of the text, and using the graph representation to condition a reading comprehension module.	O	O	Review	407
The paper reports positive evaluations on three different tasks.	O	O	Review	407
<sep> <sep> * Review	O	O	Review	407
<sep> This is an interesting paper.	O	O	Review	407
The key technical component in the proposed approach is the idea that keeping track of entity states requires (soft) coreference between newly read entities and locations and the ones existing in the knowledge graph constructed so far.	O	O	Review	407
<sep> <sep> The proposed method seems plausible, but some details are impressionistic and it is not clear why and whether the modeling choices do what the paper says.	B-Review	B-1	Review	407
This is especially the case in a few places involving coreference:	I-Review	I-1	Review	407
1.	I-Review	I-1	Review	407
The paper says at the top of page 6 that the result of Eq 1 is a disambiguated intermediate node representation.	B-Review	B-1	Review	407
<sep> 2.	O	O	Review	407
The self attention in Eq 2 performs coreference disamguation which prevents different instances of the same location from being predicted for multiple entities.	B-Review	B-1	Review	407
<sep> <sep> While these may indeed be working as advertised, it would be good to see some evaluation that verifies that after learning, what is actually happening is coreference.	I-Review	I-1	Review	407
<sep> <sep> Why does the graph update require coreference pooling again?	B-Review	B-3	Review	407
Don't the updates in Eq 1 and 2 take care of this?	I-Review	I-3	Review	407
The ablation does not test this, right?	I-Review	I-3	Review	407
<sep> <sep> Another modeling choice that is not clear is regarding how the model processes the text -- reading prefixes of the paragraph, rather than one sentence at a time.	B-Review	B-4	Review	407
What happens if the model is changed to be read one sentence at a time?	I-Review	I-4	Review	407
<sep> <sep> That the model implicitly learns constraints from data is interesting!	O	O	Review	407
<sep> Bottomline: The paper presents interesting ideas and good results, but would be better if the modeling choices were better explored/motivated.	B-Review	B-1	Review	407
<sep> <sep> Thanks for the insightful comments.	O	O	Reply	407
We‚Äôve tried to improve our paper based on your feedback.	O	O	Reply	407
Most significantly, we‚Äôve performed additional ablation studies to confirm that our modeling choices improve performance, and we provide further empirical insight on what the coreference operations do.	B-Reply	B-3	Reply	407
We‚Äôve also updated the model description and the notation in Section 4 to clarify modeling mechanisms and choices.	I-Reply	I-3	Reply	407
Two important additions are a high-level summary of the model, which we give at the beginning of Section 4, and a table (Table 2) that lists what each symbol represents along with its dimensions.	I-Reply	I-3	Reply	407
Below we address your concerns point-by-point.	I-Reply	I-3	Reply	407
<sep> <sep> The proposed method seems plausible, but some details are impressionistic and it is not clear why and whether the modeling choices do what the paper says.	O	O	Reply	407
This is especially the case in a few places involving coreference:	O	O	Reply	407
1.	O	O	Reply	407
The paper says at the top of page 6 that the result of Eq 1 is a disambiguated intermediate node representation.	O	O	Reply	407
<sep> 2.	O	O	Reply	407
The self attention in Eq 2 performs coreference disamguation which prevents different instances of the same location from being predicted for multiple entities.	O	O	Reply	407
<sep> While these may indeed be working as advertised, it would be good to see some evaluation that verifies that after learning, what is actually happening is coreference.	O	O	Reply	407
<sep> ======	O	O	Reply	407
Based on your comments, we‚Äôve performed additional ablations to measure the impact of the co-reference mechanisms.	B-Reply	B-5	Reply	407
We find that removing any of them leads to a decrease in performance (Rows 2, 3, 4 of Table 5).	I-Reply	I-5	Reply	407
<sep> <sep> To provide more than just this quantitative insight, we‚Äôll expand here on how KG-MRC handles coreference to better motivate the modeling choices:	I-Reply	I-5	Reply	407
The construction of graph G_t from G_{t-1} uses co-reference disambiguation of nodes to prevent node duplication and to enforce temporal dependencies.	I-Reply	I-5	Reply	407
We perform coreference disambiguation between location nodes of G_t and G_{t-1} via Eq.2.	I-Reply	I-5	Reply	407
1 (call this inter-graph coreference) and between the location nodes in the same graph Gt (call this intra-graph coreference) via Eq.	I-Reply	I-5	Reply	407
The inter-graph coreference yields new, intermediate representations for the nodes in G_t.	I-Reply	I-5	Reply	407
These are further updated via the intra-graph coreference step.	I-Reply	I-5	Reply	407
<sep> <sep> Inter-graph Co-ref: One way to think about this is that we construct a new graph G_t at every time step.	B-Reply	B-6	Reply	407
Now the graph G_{t-1} might contain some location nodes which are predicted again at time step ‚Äòt‚Äô (e.g., in Figure 2, leaf node already existed in G_{t-1}).	I-Reply	I-6	Reply	407
Instead of replacing an old node with an entirely new node at ‚Äòt‚Äô, we take a recurrent approach and do a gated update that preserves some information stored in the node in previous time steps while adding new information unique to time step ‚Äòt‚Äô.	I-Reply	I-6	Reply	407
<sep> <sep> Intra-graph Co-ref: Inter-graph co-ref isn‚Äôt enough since the MRC module makes its span predictions independently.	I-Reply	I-6	Reply	407
This means that, at time step t, the model could predict the same span/location for multiple entities and add all these duplicates to the graph.	I-Reply	I-6	Reply	407
Moreover, a single location might have the same surface form but be from different parts of the paragraph (e.g. ‚Äúleaf‚Äù in the 1st and the 5th sentence of the para in figure 2).	I-Reply	I-6	Reply	407
The operations in Eq.2 resolve this by performing self-attention (i.e., the predicted locations of all entities are compared to each other).	I-Reply	I-6	Reply	407
<sep> =====	O	O	Reply	407

The paper proposes a recurrent knowledge graph (bipartite graph between entities and location nodes) construction & updating mechanism for entity state tracking datasets such as (two) ProPara tasks and Recipes.	O	O	Review	407
The model goes through the following three steps: 1) it reads a sentence at each time step t and identifies the location of each entity via machine reading comprehension model such as DrQA (entities are predefined).	O	O	Review	407
2) Co-reference module adjusts relationship scores (soft adjacency matrix) among nodes, including possibly new nodes introduced by the MRC model.	O	O	Review	407
3) to propagate the relational information across all the nodes, the model performs L layers of LSTM for each entity that attend on other nodes via attention (where the weights come from the adjacency matrix).	O	O	Review	407
The model repeats the three steps for each sentence.	O	O	Review	407
The model is trained by directly supervising for the correct span by the MRC model at each time step, which is possible because the data provides strong supervision for each sentence (not just the answer at the end).	O	O	Review	407
<sep> The model achieves the state of the art in the two tasks of ProPara and Recipes dataset.	O	O	Review	407
<sep> <sep> Strengths: The paper provides an elegant solution for tracking relationship between entities as time (sentence) progresses.	O	O	Review	407
I also agree with the authors that this line of work (dynamic KG construction and modification) is an important area of research.	O	O	Review	407
While the model shares a similar spirit to EntNet, I think the model has enough distinctions / contributions, especially given that it outperforms EntNet by a large margin.	O	O	Review	407
The model also obtains non-trivial improvement over previous SOTA models.	O	O	Review	407
<sep> <sep> Weaknesses: Paper could have been written better.	B-Review	B-7	Review	407
I had hard time understanding it.	I-Review	I-7	Review	407
The notations are overall confusing and not explained well.	I-Review	I-7	Review	407
Also there are a few unclear parts which I discuss in questions below.	I-Review	I-7	Review	407
<sep> <sep> Questions:	O	O	Review	407
1.	O	O	Review	407
Are e_{i,t} and lambda_{i,t} vectors?	B-Review	B-1	Review	407
Scalars?	I-Review	I-1	Review	407
Abstract node notations?	I-Review	I-1	Review	407
It is not clear in the model section.	I-Review	I-1	Review	407
Also, it took me a long time to figure out that ‚Äòi‚Äô is used to index each entity (it is mentioned later).	I-Review	I-1	Review	407
<sep> 2.	O	O	Review	407
The paper says v_i (initial representation of each entity) is obtained by looking at the contextualized representations (LSTM outputs) of entity mention in the context.	B-Review	B-2	Review	407
What happens if there are multiple mentions in the text?	I-Review	I-2	Review	407
Which one does it look at?	I-Review	I-2	Review	407
<sep> 3.	O	O	Review	407
For the LSTM in the graph update, why does it have only one input?	B-Review	B-3	Review	407
Shouldn‚Äôt it have two inputs, one for previous hidden state and the other for input?	I-Review	I-3	Review	407
<sep> 4.	O	O	Review	407
Regarding Recipe experiments, the paper says it reaches a better performance than the baseline using just 10k examples out of 60k.	B-Review	B-4	Review	407
This is great, but could you also report the number when the full dataset is used?	I-Review	I-4	Review	407
<sep> 5.	O	O	Review	407
What does it mean that in training time the model ‚Äúupdates‚Äù the location node representation with the encoding of correct span.	B-Review	B-5	Review	407
Do you mean you use the encoding instead?	I-Review	I-5	Review	407
<sep> 6.	O	O	Review	407
For ProPara task 2, what threshold did you choose to obtain the P/R/F1 score?	B-Review	B-6	Review	407
Is it the threshold that maximizes F1?	I-Review	I-6	Review	407
<sep> <sep> Thank you for the useful feedback.	O	O	Reply	407
We‚Äôve updated our paper to take it into account -- we‚Äôve updated the model description and the notation in Section 4 to clarify our method.	B-Reply	B-8	Reply	407
Two important additions are a high-level summary of the model, which we give at the beginning of Section 4, and a table (Table 2) that lists what each symbol represents along with its dimensions.	I-Reply	I-8	Reply	407
We also made several updates that address your specific questions.	O	O	Reply	407
<sep> <sep> 1.	O	O	Reply	407
Are e_{i,t} and lambda_{i,t} vectors?	O	O	Reply	407
Scalars?	O	O	Reply	407
Abstract node notations?	O	O	Reply	407
It is not clear in the model section.	O	O	Reply	407
Also, it took me a long time to figure out that ‚Äòi‚Äô is used to index each entity (it is mentioned later).	O	O	Reply	407
<sep> <sep> The entity and location embeddings  e_{i,t} and lambda_{i,t} are d-dimensional vectors, although we also overload the symbols to refer to abstract nodes in the model‚Äôs knowledge graphs.	B-Reply	B-1	Reply	407
In the updated manuscript we state both these facts explicitly and state much earlier that ‚Äòi‚Äô is the index for entities.	I-Reply	I-1	Reply	407
<sep> <sep> 2.	O	O	Reply	407
The paper says v_i (initial representation of each entity) is obtained by looking at the contextualized representations (LSTM outputs) of entity mention in the context.	O	O	Reply	407
What happens if there are multiple mentions in the text?	O	O	Reply	407
Which one does it look at?	O	O	Reply	407
<sep> <sep> When there are multiple mentions of entity i, the initial representation v_i is formed by summing the representations of each mention.	B-Reply	B-2	Reply	407
We have updated the paper to clarify this (Sec 4.1).	I-Reply	I-2	Reply	407
<sep> <sep> 3.	O	O	Reply	407
For the LSTM in the graph update, why does it have only one input?	O	O	Reply	407
Shouldn‚Äôt it have two inputs, one for previous hidden state and the other for input?	O	O	Reply	407
<sep> <sep> Good point!	B-Reply	B-3	Reply	407
We‚Äôve improved the notation used to describe the model in Section 4.	I-Reply	I-3	Reply	407
The update equation now shows clearly that the LSTM takes in the concatenation of two node inputs (entity and location embeddings) along with the previous hidden state.	I-Reply	I-3	Reply	407
<sep> <sep> 4.	O	O	Reply	407
Regarding Recipe experiments, the paper says it reaches a better performance than the baseline using just 10k examples out of 60k.	O	O	Reply	407
This is great, but could you also report the number when the full dataset is used?	O	O	Reply	407
<sep> <sep> We‚Äôve completed an experiment on the full Recipes dataset and updated the paper to describe the result (this experiment did not finish in time for the initial submission).	B-Reply	B-4	Reply	407
The model‚Äôs F1 score improves from 51.64 on the partial data to 54.27 on the full data, surpassing the previous state of the art by a more significant margin.	I-Reply	I-4	Reply	407
<sep> <sep> 5.	O	O	Reply	407
What does it mean that in training time the model ‚Äúupdates‚Äù the location node representation with the encoding of the correct span.	O	O	Reply	407
Do you mean you use the encoding instead?	O	O	Reply	407
<sep> <sep> We meant that we perform teacher-forcing to train the model.	B-Reply	B-5	Reply	407
During training, we extract the context encodings for the groundtruth span and use these in downstream operations  to obtain the node representations.	I-Reply	I-5	Reply	407
At test time, we use the MRC module‚Äôs predicted span rather than the groundtruth.	I-Reply	I-5	Reply	407
<sep> <sep> 6.	O	O	Reply	407
For ProPara task 2, what threshold did you choose to obtain the P/R/F1 score?	O	O	Reply	407
Is it the threshold that maximizes F1?	O	O	Reply	407
<sep> <sep> For ProPara task 2, our model was optimized for micro averaged F1 on the development set.	B-Reply	B-6	Reply	407
Tandon et al (2018) were kind enough to provide us with their evaluation script.	I-Reply	I-6	Reply	407

The paper addresses a challenging problem of predicting the states of entities over the description of a process.	O	O	Review	407
The paper is very well written, and easily understandable.	O	O	Review	407
The authors propose a graph structure for entity states, which is updated at each step using the outputs of a machine comprehension system.	O	O	Review	407
The approach is novel and well motivated.	O	O	Review	407
I will suggest a few improvements:	O	O	Review	407
<sep> 1.	O	O	Review	407
the NPN model seems a good alternative, will be good to have a discussion about why your model is better than NPN.	B-Review	B-1	Review	407
Also, NPN can probably be modified to output spans of a sentence.	I-Review	I-1	Review	407
I will be curious to know how it performs.	I-Review	I-1	Review	407
<sep> <sep> 2.	O	O	Review	407
A more detailed illustration of the system / network is needed.	B-Review	B-2	Review	407
Would have made it much easier to understand the paper.	I-Review	I-2	Review	407
<sep> <sep> 3.	O	O	Review	407
What are the results when using the whole training set of Recipes ?	B-Review	B-3	Review	407
<sep> <sep> <sep> <sep> We‚Äôre glad that you found the paper interesting and well-written.	O	O	Reply	407
To address your comments and questions:	O	O	Reply	407
<sep> 1.	O	O	Reply	407
the NPN model seems a good alternative, will be good to have a discussion about why your model is better than NPN.	O	O	Reply	407
Also, NPN can probably be modified to output spans of a sentence.	O	O	Reply	407
I will be curious to know how it performs.	O	O	Reply	407
<sep> <sep> The NPN model requires a pre-defined lexicon of action types (i.e., verbs), such as cut, bake, boil, etc.	B-Reply	B-1	Reply	407
For the recipes dataset, the action types and their causal effects were manually collected and defined.	I-Reply	I-1	Reply	407
Since the ProPara dataset does not have these annotations, we would have to manually identify action types to apply NPN to it.	I-Reply	I-1	Reply	407
<sep> Also, NPN treats the state change as a classification problem (of about 260 classes that are also manually defined).	I-Reply	I-1	Reply	407
In contrast, KG-MRC finds the state-describing span in the text directly, which we believe is a more generic approach.	I-Reply	I-1	Reply	407
<sep> <sep> 2.	O	O	Reply	407
A more detailed illustration of the system / network is needed.	O	O	Reply	407
Would have made it much easier to understand the paper.	O	O	Reply	407
<sep> <sep> We agree that more detail would help readers to understand the model better.	B-Reply	B-2	Reply	407
We‚Äôve made some hopefully significant updates to Section 4 (model description and notation) to improve clarity, and we hope you‚Äôll take the time to read the new manuscript.	I-Reply	I-2	Reply	407
Two important additions are a high-level summary of the model, which we give at the beginning of Section 4, and a table (Table 2) that lists what each symbol represents along with its dimensions.	I-Reply	I-2	Reply	407
<sep> <sep> 3.	O	O	Reply	407
What are the results when using the whole training set of Recipes ?	O	O	Reply	407
<sep> <sep> We‚Äôve completed an experiment on the full Recipes dataset and updated the paper to describe the result (this experiment did not finish in time for the initial submission).	B-Reply	B-3	Reply	407
The model‚Äôs F1 score improves from 51.64 on the partial data to 54.27 on the full data, surpassing the previous state of the art by a more significant margin.	I-Reply	I-3	Reply	407

After rebuttal:	O	O	Review	407
Authors have addressed all my doubts.	O	O	Review	407
I recommend accepting this paper.	O	O	Review	407
<sep> <sep> =============================	O	O	Review	407
Before rebuttal:	O	O	Review	407
Summary:	O	O	Review	407
<sep> This paper proposes a new way to do transfer learning.	O	O	Review	407
Specifically, authors first train a big source ConvNet and then for each task, they train a small ConvNet in which each layer subscribes to some k channels in the corresponding layer of the source ConvNet.	O	O	Review	407
Authors show that this model works better than methods that fine-tune the last few layers of the source network and performs close to costlier methods like progressive networks but with lesser parameters and higher throughput.	O	O	Review	407
Experiments on 5 tasks verify their claim.	O	O	Review	407
<sep> <sep> <sep> My comments:	O	O	Review	407
<sep> Overall, this is a very interesting paper.	O	O	Review	407
<sep> <sep> 1.	O	O	Review	407
This is an interesting model to do transfer or lifelong learning but only for ConvNet architectures with image data.	B-Review	B-1	Review	407
To avoid overstating the results, I request the authors to highlight this limitation in both the title and the abstract.	I-Review	I-1	Review	407
<sep> 2.	O	O	Review	407
Page 3, para starting with ‚ÄúIn detail‚Äù: Is the ResNet50 for delta model pre-trained or not?	B-Review	B-2	Review	407
I know it is not pre-trained based on future paragraphs.	I-Review	I-2	Review	407
But it is good to clarify it here.	I-Review	I-2	Review	407
<sep> 3.	B-Review	B-3	Review	407
Sharing the same source network across multiple tasks during inference time is useful only when all the tasks take the same input.	I-Review	I-3	Review	407
This is a very restricted application.	I-Review	I-3	Review	407
This needs to be elaborated and highlighted in the paper.	I-Review	I-3	Review	407
<sep> 4.	B-Review	B-4	Review	407
I would like to see the LF results included in the paper even though it has catastrophic forgetting issues.	I-Review	I-4	Review	407
<sep> 5.	O	O	Review	407
In Figure 4, the x-axis represents training throughput or inference throughput?	B-Review	B-5	Review	407
I guess it is training throughput.	I-Review	I-5	Review	407
Also, are the models trained for all the tasks in parallel (as described in serving all the tasks at once section) or separately?	I-Review	I-5	Review	407
Even though I can guess answers for these, it is better to make these explicit in the paper for the benefit of the readers.	I-Review	I-5	Review	407
<sep> 6.	B-Review	B-6	Review	407
It is never a good idea to show test curves for a task.	I-Review	I-6	Review	407
Please remove the test curves from Figure 4.	I-Review	I-6	Review	407
Instead, use a separate validation set and show validation curves.	I-Review	I-6	Review	407
<sep> 7.	O	O	Review	407
Are the authors willing to release the code to reproduce their results?	B-Review	B-7	Review	407
<sep> <sep> Minor comments:	B-Review	B-8	Review	407
<sep> 1.	I-Review	I-8	Review	407
Section 1, second para, 1st line: ‚Äúwee‚Äù should be ‚Äúwe‚Äù	I-Review	I-8	Review	407
2.	I-Review	I-8	Review	407
Table 1: Fix grammar in MP description.	I-Review	I-8	Review	407
<sep> <sep> C1.	O	O	Reply	407
Thanks for the comment.	O	O	Reply	407
We reflected your request in both the title and abstract of the revision.	B-Reply	B-1	Reply	407
<sep> <sep> C2.	O	O	Reply	407
Thanks for helping us clarify an important aspect of our scheme.	O	O	Reply	407
We clearly indicated that the delta model is to be trained in the paragraph you mentioned as well as the paragraph before it ("individual to-be-trained delta model) to avoid any confusion.	B-Reply	B-2	Reply	407
<sep> <sep> C3.	O	O	Reply	407
We appreciate your suggestion.	O	O	Reply	407
We have elaborated the reviewer's point in the paper by adding a new paragraph in Section 2.1.	B-Reply	B-3	Reply	407
<sep> <sep> C4.	O	O	Reply	407
Thanks for the comments.	O	O	Reply	407
We checked out our implementation to ensure the correctness and performed hyper-parameter tuning to get the best performance for LF.	B-Reply	B-4	Reply	407
We believe that our test case is extremely challenging for LF, because our five datasets do have very different distributions.	I-Reply	I-4	Reply	407
Note that the multi-task scenario in the original LF paper, in fact, uses multiple subsets of a single VOC dataset.	I-Reply	I-4	Reply	407
<sep> <sep> Our training is still running and we will append the table as soon as the training job is over (in a few hours).	I-Reply	I-4	Reply	407
We will include the results to the appendix of the revision at the same time.	I-Reply	I-4	Reply	407
<sep> ====&gt; We have completed the runs except for Food (which needs another 10+ hours).	I-Reply	I-4	Reply	407
We will add the entire outcome to the final version ASAP.	I-Reply	I-4	Reply	407
<sep> <sep> We explored a few sequences to get the best outcome for LF,  came up with the following,  which led to the accuracy changes for the datasets below.	I-Reply	I-4	Reply	407
<sep> <sep> sequence ImgNet    -&gt;Car     -&gt;Action   -&gt;CUB    -&gt;DTD	I-Reply	I-4	Reply	407
-----------------------------------------------------------	I-Reply	I-4	Reply	407
Car      |  81.87     28.40      22.78     22.44 .	I-Reply	I-4	Reply	407
#Car Top1 accuracy drops as new tasks are being added.	I-Reply	I-4	Reply	407
<sep> accuracy    Action  |    X          77.08      68.87     62.60	I-Reply	I-4	Reply	407
CUB      |   X            X            70.94     46.23	I-Reply	I-4	Reply	407
DTD      |   X            X              X          71.93	I-Reply	I-4	Reply	407
-------------------------------------------------------------	I-Reply	I-4	Reply	407
<sep> As you can see, once Action dataset is used, the accuracy against Car dataset drops significantly, as both are very heterogeneous.	I-Reply	I-4	Reply	407
Yet, adding CUB has somewhat limited impacts on Action.	I-Reply	I-4	Reply	407
Overall, the combination of datasets in our experiment seems to be a very challenging scenario for LF in terms of catastrophic forgetting.	I-Reply	I-4	Reply	407
We agree with the reviewer's suggestion to keep the LF result in the paper, as perhaps this can serve as a good example to study for fellow researchers.	I-Reply	I-4	Reply	407
<sep> <sep> Regarding the computational performance, LF overall showed the training throughput of 272.69 images/sec with 13.99 GB memory footprint.	I-Reply	I-4	Reply	407
The reason why LF is slower than FT is LF needs to perform extra forward paths to compute the loss for the old tasks.	I-Reply	I-4	Reply	407
<sep> <sep> C5.	O	O	Reply	407
Thank you for the question and comments.	O	O	Reply	407
The x-axis in Figure 4 represents training throughput.	B-Reply	B-5	Reply	407
We double-checked the caption of Figure 4 to ensure that it states training.	I-Reply	I-5	Reply	407
The models are trained separately in a sequential manner, and we explicitly stated it at the beginning of Section 3.1.	I-Reply	I-5	Reply	407
<sep> <sep> C6.	O	O	Reply	407
Thanks for pointing out this.	O	O	Reply	407
In fact, this was our typo, and the graph is indeed the validation curve.	B-Reply	B-6	Reply	407
We have fixed it in the revision.	I-Reply	I-6	Reply	407
<sep> <sep> C7.	O	O	Reply	407
We are in the process of obtaining the clearance for code-release.	B-Reply	B-7	Reply	407
In the meantime, the pseudo-code in Appendix A.1 should be sufficient enough for anyone to try out our channel pooling idea (i.e., it is already almost a python code snippet).	I-Reply	I-7	Reply	407
<sep> <sep> C8.	O	O	Reply	407
Minor comments: all corrected, thank you.	B-Reply	B-8	Reply	407

*** Increased to Accept from Weak Accept after author rebuttal and changes to the paper ***	O	O	Review	407
<sep> This paper proposes a method, SNOW, for improving the speed of training and inference for transfer and lifelong learning.	O	O	Review	407
SNOW starts with a pre-trained, frozen source model, and trains delta models for target tasks which, at each layer, concatenate a small number of task-specific features with the top-K most useful subset of features in the corresponding layer in the source model.	O	O	Review	407
As long as the target tasks are sufficiently related to the source task, it allows for small delta models and a small additional parameter overhead in the form of one weight per source model feature map.	O	O	Review	407
While there are (i) some issues with the presentation of results for training efficiency, (ii) some question marks over the sensitivity of the model to hyper-parameters, and (iii) several grammatical errors / typos in the manuscript, if these can be addressed I recommend the paper for acceptance because it seems to strike a superior balance of efficiency (regarding memory usage and inference speed) and accuracy when compared to a number of baselines, and to my knowledge it is a novel approach.	B-Review	B-3	Review	407
<sep> <sep> Detailed comments:	O	O	Review	407
* Section 2.2 - How is sigma (the exploratory noise added for feature selection during training) chosen and how sensitive is the approach to its value?	B-Review	B-4	Review	407
It seems like it was fine-tuned, given that a different sigma is chosen for the Action dataset (several orders of magnitude difference).	I-Review	I-4	Review	407
In practice, tuning sigma could significantly increase training time.	I-Review	I-4	Review	407
<sep> * It seems like the performance of only one run was plotted per hyperparameter setting - it would be informative to see a mean and standard deviation especially since the approach seems like it could be unstable for the wrong hyperparameter settings.	B-Review	B-5	Review	407
<sep> * Related to the previous point, how much do the top-K feature selections change throughout training?	B-Review	B-6	Review	407
One would have thought that this could cause instability during training for a high sigma.	I-Review	I-6	Review	407
If sigma is too low, you could end up with suboptimal feature selection.	I-Review	I-6	Review	407
<sep> * Figure 4 graphs are a bit misleading because the throughput on the x-axis is reported per GPU and the larger models all need 2 or more GPUs.	B-Review	B-7	Review	407
While this is mentioned in the main text, it is still optically deceptive and the results are GPU-dependent - presumably if the GPUs had a larger memory, the larger models would not seems as slow.	I-Review	I-7	Review	407
I think it would be clearer to plot images/sec on the x-axis or to rerun the experiments just using a single GPU.	I-Review	I-7	Review	407
<sep> * It is stated that  ‚Äú[d]etermining K [‚Ä¶] has a critical impact on both size and target accuracy in the target models‚Äù, where K is the number of feature maps in the source model that the delta model subscribes to in each layer.	B-Review	B-8	Review	407
How sensitive is the accuracy exactly?	I-Review	I-8	Review	407
Can this be quantified or discussed in more detail?	I-Review	I-8	Review	407
<sep> * Furthermore, how sensitive is the performance to the number of target-model-specific features at each layer?	B-Review	B-9	Review	407
<sep> * Different learning rate schedules were used for SNOW and baselines - initial lr for SNOW is 1.0, while for all other models it is 0.1.	B-Review	B-10	Review	407
Was it checked whether the baselines improve when they are run with an initial lr of 1.0?	I-Review	I-10	Review	407
Was this hyperparameter more heavily tuned for SNOW than for the baselines?	I-Review	I-10	Review	407
<sep> * Since the source model is fixed, the applicability of the approach to lifelong learning is heavily dependent on the usefulness of the source model to subsequent tasks.	B-Review	B-11	Review	407
If it is not, then one will have to incorporate large delta models.	I-Review	I-11	Review	407
Furthermore, there can be no transfer between the tasks trained in the delta models.	I-Review	I-11	Review	407
<sep> Grammatical errors / suggestions:	B-Review	B-3	Review	407
* Page 1, first line: ‚Äúhallmark‚Äù doesn‚Äôt make sense in this context - maybe ‚Äúkey objective‚Äù or ‚Äúgoal‚Äù?	I-Review	I-3	Review	407
<sep> * Page 1, 2nd paragraph, first line: ‚Äúwee‚Äù -&gt; ‚Äúwe‚Äù.	I-Review	I-3	Review	407
<sep> * Page 1, 2nd paragraph, line 6: ‚Äúbest top-K‚Äù -&gt; either ‚ÄúK best‚Äù or ‚Äútop K"	I-Review	I-3	Review	407
* Page 2, last paragraph, first line: ‚Äúthree folds‚Äù -&gt; ‚Äúthreefold"	I-Review	I-3	Review	407
* Section 2.1, line 2: ‚Äúpooing‚Äù-&gt;‚Äùpooling‚Äù.	I-Review	I-3	Review	407
Same typo on Page 4, last line.	I-Review	I-3	Review	407
<sep> * Page 6, line 1: ‚Äútraining from the scratch‚Äù -&gt; ‚Äútraining from scratch"	I-Review	I-3	Review	407
* Page 6, line 9: ‚Äúmore 6x than‚Äù -&gt; ‚Äú6x more than"	I-Review	I-3	Review	407
* Overall, the manuscript needs to be proofread a few times.	I-Review	I-3	Review	407
C1.	O	O	Reply	407
Thanks for the comment.	O	O	Reply	407
To demonstrate the effects of different sigma values, we did apply different values to the car dataset, and here is the result:	B-Reply	B-4	Reply	407
<sep> sigma<tab>1e-1        1e-3<tab>        1e-5<tab>1e-7	I-Reply	I-4	Reply	407
---------------------------------------------------------	I-Reply	I-4	Reply	407
top1<tab>81.27<tab>83.79<tab>83.45<tab>83.35	I-Reply	I-4	Reply	407
top5<tab>95.85<tab>96.94<tab>96.99<tab>96.88	I-Reply	I-4	Reply	407
<sep> As you can see too large or too small sigma values can lead to sub-optimal predictive power.	I-Reply	I-4	Reply	407
Therefore, it is important to develop a method to find good sigma values, as the reviewer pointed out.	I-Reply	I-4	Reply	407
We're currently researching in that direction: one idea we have is to examine the early weight distribution (i.e., after a few epochs) and then determine the sigma value to balance out exploration and stabilization.	I-Reply	I-4	Reply	407
We discussed this point in Section 3.2.	I-Reply	I-4	Reply	407
<sep> <sep> <sep> C2.	O	O	Reply	407
Thanks for the valuable suggestions.	O	O	Reply	407
We have measured SNOW-256 (with batch size 256) accuracy again over 5 times on each dataset.	B-Reply	B-5	Reply	407
We found that the avg top-1 accuracy is in fact slightly better than ones in the submission draft.	I-Reply	I-5	Reply	407
Here is the accuracy distribution and we have updated the draft with the avg/std numbers accordingly.	I-Reply	I-5	Reply	407
<sep> Food             DTD         Action      Cars        CUB	I-Reply	I-5	Reply	407
--------------------------------------------------------------------------	I-Reply	I-5	Reply	407
avg.	I-Reply	I-5	Reply	407
<tab>84.06<tab>    72.37<tab>    78.48       83.79<tab>    75.81	I-Reply	I-5	Reply	407
std<tab>        0.124          0.520       0.265       0.181       0.297	I-Reply	I-5	Reply	407
<sep> Note that SNOW-128 (with batch size 128) results are also based on the 5 runs.	I-Reply	I-5	Reply	407
<sep> <sep> <sep> C3.	O	O	Reply	407
The top-K feature selections change very frequently at the beginning of the training and get stabilized with more epochs.	B-Reply	B-6	Reply	407
Figure 5 in Section 3.2 shows which features are selected (in the solid vertical lines) during the training of CAR dataset under the same configuration/hyper-parameters in Section 3.1.	I-Reply	I-6	Reply	407
The top X-axis represents the channel indices, and the left Y-axis represents the training progress (in terms of iteration).	I-Reply	I-6	Reply	407
The horizontal dotted lines indicate the start of the next epoch.	I-Reply	I-6	Reply	407
You can see that some channels join and leave the top-K frequently (i.e., small dots) yet some stay in the top-K consistently, getting more stable as training continues.	I-Reply	I-6	Reply	407
<sep> <sep> Regarding the comment on sigma, please refer to the provided table in C1.	I-Reply	I-6	Reply	407
<sep> <sep> C4.	O	O	Reply	407
Thanks for the comments, and we agreed with the reviewer and updated the paper accordingly.	B-Reply	B-7	Reply	407
We wanted to normalize the comparison over the typical mini-batch size for the tested datasets, which made PyTorch split the training over multiple GPUs.	I-Reply	I-7	Reply	407
When two GPUs are used for training, the communication between GPUs can incur some overheads.	I-Reply	I-7	Reply	407
However, our platform has GPUDirect over NVLink2 between GPUs which has 160GB/s bandwidth, thus the impact should have been rather limited.	I-Reply	I-7	Reply	407
<sep> <sep> Per the reviewer's suggestion, we refreshed all the experiments under the single GPU constraint.	I-Reply	I-7	Reply	407
In detail, we reduced the batch sizes of MP, FT, PN until it fits into one GPU.	I-Reply	I-7	Reply	407
Additionally, we tested SNOW with a smaller batch size (128 from 256) to ensure that SNOW still offers advantages with that configuration.	I-Reply	I-7	Reply	407
As a result,  for the example of the Car dataset, the throughput gap between SNOW and PN decreases from 6x to 5.2x.	I-Reply	I-7	Reply	407
Figure 4 and Table 8 (in the Appendix) are all accordingly updated.	I-Reply	I-7	Reply	407
<sep> <sep> <sep> C5.	O	O	Reply	407
Thank you for the input.	B-Reply	B-8	Reply	407
As suggested, we experimented with the CAR dataset to study the effect of different Ks.	I-Reply	I-8	Reply	407
Our current finding shows that the accuracy is somewhat sensitive to the K values, and it seems there could be some sweet spot for K: we believe oversubscription may introduce unwanted noises to the delta model (in addition to the size/compute overhead).	I-Reply	I-8	Reply	407
We elaborated more in Section 2.2 and added results to Section 3.2.	I-Reply	I-8	Reply	407
<sep> <sep> K                  |    N/4         N/8         N/16	I-Reply	I-8	Reply	407
---------------------------------------------------	I-Reply	I-8	Reply	407
accuracy      |    83.10       83.79       83.39	I-Reply	I-8	Reply	407
<sep> <sep> C6.	O	O	Reply	407
We again used the CAR dataset to study the performance sensitivity to the number of target-model-specific features and showed the results below.	B-Reply	B-9	Reply	407
<sep> <sep> target-specific  |	I-Reply	I-9	Reply	407
feature count   |    M/4         M/8         M/16	I-Reply	I-9	Reply	407
---------------------------------------------------	I-Reply	I-9	Reply	407
accuracy          |    79.02       83.79       80.36	I-Reply	I-9	Reply	407
<sep> It shows that the performance is sensitive to the delta model size, and clearly exposes the existence of ideal size.	I-Reply	I-9	Reply	407
It is obvious that the same rule of thumb in neural network architecture design applies here too: having too few target-specific features hurt accuracy, but having too many (or too big delta net) does hurt as well because the number of target-specific samples may be relatively too small.	I-Reply	I-9	Reply	407
We added discussion and result in Section 3.2.	I-Reply	I-9	Reply	407

This paper attempts to tackle transfer learning and lifelong learning problem by subscribing to knowledge via channel pooling.	O	O	Review	407
The channel pooling is actually selecting the subsect of the feature map according to the way that prediction accuracy from the delta model can be maximized.	O	O	Review	407
Experiments show effectiveness of the proposed method.	O	O	Review	407
<sep> <sep> Pros:	O	O	Review	407
Overall, this paper is well written and easy to follow.	O	O	Review	407
The technique is sound and the problem studied in this paper is significant.	O	O	Review	407
<sep> <sep> Cons:	O	O	Review	407
1.	O	O	Review	407
<tab>I do not think that the model proposed in this paper is able to tackle lifelong learning problem.	B-Review	B-1	Review	407
The main reason is that lifelong learning basically requires only one model that will continue to learn from new tasks.	I-Review	I-1	Review	407
After learning several new tasks, people hope this model can still perform well on the previous tasks as well as the current ones.	I-Review	I-1	Review	407
However, in this paper, not only one model is learned.	I-Review	I-1	Review	407
Instead, new models appear when new tasks are given, which does not meet the definition or requirement of lifelong learning.	I-Review	I-1	Review	407
It only meets the requirement of transfer learning.	I-Review	I-1	Review	407
The experimental results also validate my opinion since only one new task is given while in lifelong learning, continuous new tasks will come and the original model should perform well on all of them as well as on the old tasks.	I-Review	I-1	Review	407
<sep> 2.	O	O	Review	407
<tab>In Figure 4, the legend in the first picture will confuse the readers.	B-Review	B-2	Review	407
I suggest the authors put it outside all the figures.	I-Review	I-2	Review	407
Besides, the proposed method in the last picture is not the best.	I-Review	I-2	Review	407
What do the authors want to convey by this picture?	I-Review	I-2	Review	407
<sep> <sep> <sep> C1.	B-Reply	B-1	Reply	407
We appreciate your comments on SNOW regarding the number of models.	I-Reply	I-1	Reply	407
One might assume that SNOW consists of multiple models as it has the source model and the ‚Äúdelta‚Äù models.	I-Reply	I-1	Reply	407
But, the term ‚Äúdelta model‚Äù is used for an easier explanation about the expanded parts in the SNOW architecture.	I-Reply	I-1	Reply	407
We argue that the entire architecture based on SNOW can be regarded as a single model (which just consists of various modules to deliver multi-task predictions) because a delta model alone is not semantically sufficient for an intended task when there already exists transferability from the source task to the target task.	I-Reply	I-1	Reply	407
In fact, the delta and source models must efficiently cooperate as a single-engine to perform target tasks effectively (which is the key difference from a collection of models such as ensemble learning), which is the main contribution in this work.	I-Reply	I-1	Reply	407
<sep> Expanding a single model as in SNOW is becoming a popular approach to address catastrophic forgetting in lifelong learning.	I-Reply	I-1	Reply	407
For example, ProgressiveNet (Rusu, 2016) in our experiment can be considered as a single model even though the entire layer pipelines are duplicated for each new task as an expansion.	I-Reply	I-1	Reply	407
Other various kinds of expansions have been published in major venues recently for lifelong learning, and we here provide a list of the latest representative publications with short summaries.	I-Reply	I-1	Reply	407
<sep> -Lifelong Learning with Dynamically Expandable Networks [ICLR18]	I-Reply	I-1	Reply	407
The authors considered lifelong learning simply as a special case of online or incremental learning, in the case of deep neural networks.	I-Reply	I-1	Reply	407
The proposed approach in this paper is to partially expand the model capacity with new tasks.	I-Reply	I-1	Reply	407
<sep> -Autonomous Deep Learning: Continual learning approach for dynamic environments [ICDM19]	I-Reply	I-1	Reply	407
A fully elastic deep neural network (DNN), namely Autonomous Deep Learning (ADL) is proposed where the new hidden layers can be dynamically added under the lifelong learning paradigm.	I-Reply	I-1	Reply	407
<sep> -Scalable Recollections for Continual Lifelong Learning [AAAI19]	I-Reply	I-1	Reply	407
A small auto-encoder per new task is attached for the experience replay purpose for multi-task lifelong learning (instead of episodic memories).	I-Reply	I-1	Reply	407
<sep> -Continual Palmprint Recognition Without Forgetting [ICIP19]	I-Reply	I-1	Reply	407
This paper proposes to use reinforcement learning to dynamically expand the neural network when facing newly registered palmprints.	I-Reply	I-1	Reply	407
<sep> -Lifelong Learning Starting from Zero [ICAGI19]	I-Reply	I-1	Reply	407
This work proposes to add new nodes/neurons for expansion (which adds new nodes to memorize new input combinations) and generalization (which adds new nodes that generalize from existing ones).	I-Reply	I-1	Reply	407
<sep> C2.	O	O	Reply	407
Thanks for suggestions.	B-Reply	B-2	Reply	407
We tried to place the legend outside the figures, but the space limitation makes it very hard.	I-Reply	I-2	Reply	407
As an alternative solution to prevent any confusion on the readers, we overlay the legend over a gray bounding box which increases the readability as well.	I-Reply	I-2	Reply	407
Hope this would work for you and future readers.	I-Reply	I-2	Reply	407
<sep> The purpose of the last picture in Fig.4 is to show that SNOW requires a similar number of epochs for convergence as well.	I-Reply	I-2	Reply	407
In the end, what matters most in practice is the wall-clock runtime which is num_epochs X total_samples/throughput.	I-Reply	I-2	Reply	407
In some cases, it is possible that a certain approach may have a better throughput but require more epochs for convergence, eventually netting a longer end2end training time.	I-Reply	I-2	Reply	407
Here, with the pictures in Fig.4, we showed that the total training time of SNOW will be superior to PN, FT, MP, because of the same epoch count for convergence (after 60 epochs) and higher throughput.	I-Reply	I-2	Reply	407
Note that we simply let all the algorithms run for 200 epochs to ensure that nothing is left for any algorithm.	I-Reply	I-2	Reply	407
We have made this point clear in the revision (the last paragraph in Section 3.1).	I-Reply	I-2	Reply	407

This paper studies the problem of identifying (discovering) synonymous entities.	O	O	Review	900
The paper proposes using the "contexts" of the entities as they occur in associated text corpora (e.g. Wiki) in the proposed neural-network based embedding approach for this task.	O	O	Review	900
The key novelties of the approach lie in the "matching" system used, where contexts of one entity are matched with that for the other entity to see how well they align with each other (which effectively determines the similarity of the two entities).	O	O	Review	900
Experiments are conducted on three different datasets to show the efficacy of the proposed approach.	O	O	Review	900
<sep> <sep> Overall I found the paper to be an interesting read with some nice ideas mixed in.	O	O	Review	900
However I also had some concerns which are highlighted later down below, which I believe if addressed would lead to a very strong work.	O	O	Review	900
<sep> <sep> Quality: Above average	O	O	Review	900
<sep> In general the method seems to work somewhat better than the baselines and the method does have a couple of interesting ideas.	O	O	Review	900
<sep> <sep> Clarity: Average	O	O	Review	900
<sep> I found a few key details to be missing and also felt the paper could have been better written.	B-Review	B-6	Review	900
<sep> <sep> Originality: Average	O	O	Review	900
<sep> The matching approach and use of the leaky units was interesting tidbits.	O	O	Review	900
Outside of that the work is largely about the application of such Siamese RNNs based networks to this specific problem. (	O	O	Review	900
The use of context of entities has already been looked at in previous works albeit in a slightly more limited manner)	O	O	Review	900
<sep> Significance: Slightly below average	O	O	Review	900
<sep> I am not entirely sold on the use of this approach for this problem given its complexity and unclear empirical gains vs more sophisticated baselines.	B-Review	B-7	Review	900
The matching aspect may have some use in other problems but nothing immediately jumps out as an obvious application.	I-Review	I-7	Review	900
<sep> <sep> ----	O	O	Review	900
<sep> Strengths / Things I liked about the paper:	O	O	Review	900
<sep> - In general the method is fairly intuitive and simple to follow which I liked.	O	O	Review	900
<sep> - The matching approach was an interesting touch.	O	O	Review	900
<sep> - Similarly for the "leaky" unit.	O	O	Review	900
<sep> - Experiments conducted on multiple datasets.	O	O	Review	900
<sep> - The results indicate improvements over the baselines considered on all the three datasets.	O	O	Review	900
<sep> <sep> Weaknesses / Things that concerned me:	O	O	Review	900
<sep> -  (W1) Slightly unfair baselines?	B-Review	B-1	Review	900
One of the first things that struck me in the experimental results was how competitive word2vec by itself was across all three datasets.	I-Review	I-1	Review	900
This made me wonder what would happen if we were to use a more powerful embedding approach say FastText, Elmo, Cove or the recently proposed BERT? (	I-Review	I-1	Review	900
The proposed method itself uses bidirectional LSTMs)	I-Review	I-1	Review	900
<sep> Furthermore all of them are equally capable of capturing the contexts as well.	I-Review	I-1	Review	900
An even more competitive (and fair) set of baselines could have taken the contexts as well and use their embeddings as well.	I-Review	I-1	Review	900
Currently the word2vec baseline is only using the embedding of the entity (text), whereas the proposed approach is also provided the different contexts at inference time.	I-Review	I-1	Review	900
The paper says using the semantic structure and the diverse contexts are weaknesses of approaches using the contexts, but I don't see any method that uses the context in an embedding manner -- say the Cove context vectors.	I-Review	I-1	Review	900
If the claim is that they won't add any additional value above what is already captured by the entity it would be good to empirically demonstrate this.	I-Review	I-1	Review	900
<sep> <sep> - (W2) Significance testing: On the topic of experimentation, I was concerned that significance testing / error estimates weren't provided for the main emprical results.	B-Review	B-2	Review	900
The performance gaps seem to be quite small and to me it is unclear how significant these gaps are.	I-Review	I-2	Review	900
Given how important significance testing is as an empirical practice this seems like a notable oversight which I would urge the authors to address.	I-Review	I-2	Review	900
<sep> <sep> - (W3) Missing key details: There were some key aspects of the work that I thought were not detailed.	B-Review	B-3	Review	900
Chief among these was the selection of the contexts for the entities.	I-Review	I-3	Review	900
How was this?	I-Review	I-3	Review	900
How were the 20 contexts identified?	I-Review	I-3	Review	900
Some of these entities are likely far more common than just 20 sentences and hence I wonder how these were selected?	I-Review	I-3	Review	900
<sep> <sep> Another key aspect I did not see addressed: How were the entities identified in the text (to be able to find the contexts for them)?	I-Review	I-3	Review	900
The paper claims that they would like to learn from minimal human annotations but I don't understand how these entity annotations in the text were obtained.	I-Review	I-3	Review	900
This again seems like a notable oversight.	I-Review	I-3	Review	900
<sep> <sep> - (W4) Concerns about the method: I had two major concerns about the method:	B-Review	B-4	Review	900
<sep> (a) Complexity of method :  I don't see an analysis of the computational cost of the proposed method (which scales quadratically with P the number of contexts);	I-Review	I-4	Review	900
<sep> (b) Effect of redundant "informative" contexts: Imagine you have a number of highly informative contexts for an entity but they are all very similar to each other.	B-Review	B-4	Review	900
Due to the way the matching scores are aggregated, these scores are made to sum to 1 and hence no individual score would be very high.	I-Review	I-4	Review	900
Given that this is the final coefficient for the associated context, this seems like a significant issue right?	I-Review	I-4	Review	900
<sep> <sep> Unless the contexts are selected to be maximally diverse, it seems like this can essentially end up hurting an entity which occurs in similar contexts repeatedly.	I-Review	I-4	Review	900
I would like to see have seen the rationale for this better explained.	I-Review	I-4	Review	900
<sep> <sep> (c) A smaller concern was understanding the reasoning behind the different loss functions in the siamese loss function with a different loss for the positive and the negative, one using a margin and one which doesn't.	B-Review	B-4	Review	900
One which scales to 1/4, the other scaling to (1-m)^2.	I-Review	I-4	Review	900
This seems pretty arbitrary and I'd like to understand this.	I-Review	I-4	Review	900
<sep> <sep> -(W5) Eval setting : My last concern was with the overall evaluation setup.	B-Review	B-5	Review	900
Knowledge bases like Freebase are optimized for precision rather than recall, which is why "discovery" of new relations is important.	I-Review	I-5	Review	900
However if you treat all missing relationships as negative examples then how exactly are you measuring the true ability of a method?	I-Review	I-5	Review	900
Thus overall I'm pretty skeptical about all the given numbers simply because we know the KBs are incomplete, but are penalizing methods that may potentially discover relations not in the KB.	I-Review	I-5	Review	900
We thank the reviewer for the thorough review and constructive feedback.	O	O	Reply	900
<sep> <sep> We first would like to thank the reviewer for the positive feedback on our work.	O	O	Reply	900
<sep> <sep> For the part that concerned the reviewer, we elaborate point by point as shown below:	O	O	Reply	900
<sep> (W1) For the experiment setting, the proposed model can work with various word embeddings.	B-Reply	B-1	Reply	900
The contribution of our work does not lie in the choice of word embeddings, but the proposed architecture that utilizes entity representations for bilateral matching among multiple pieces of contexts.	I-Reply	I-1	Reply	900
Our model is independent of the choice of word embeddings, and we adopt Word2vec as a base case.	I-Reply	I-1	Reply	900
We aim to experiment the modeling ability of different model architectures given the same word representation information for synonym discovery.	I-Reply	I-1	Reply	900
With sophisticated word embedding methods such as Elmo or BERT, which achieve decent performances on various NLP tasks, we do expect that both baselines and our model will get better performance.	I-Reply	I-1	Reply	900
<sep> <sep> (W2) We‚Äôve added the significance testing in the experiment and update Table 2 with discussions.	B-Reply	B-2	Reply	900
A single-tailed t-test is performed to see whether or not the proposed model can outperform other baselines with significant improvements.	I-Reply	I-2	Reply	900
<sep> <sep> (W3) For the missing key details, the contexts are randomly selected from all contexts in which each entity is mentioned.	B-Reply	B-3	Reply	900
Due to limitations on computing resources, we are only able to verify the performance of up to 20 pieces of randomly chosen contexts in which each entity is mentioned.	I-Reply	I-3	Reply	900
For Wiki+Freebase and PubMed+UMLS, the datasets come with entity mentions annotated.	I-Reply	I-3	Reply	900
While in MedBook+MKG, we apply existing NER model [1] with contextualized embeddings [2] to obtain the annotated entities from the text.	I-Reply	I-3	Reply	900
We clarified the claim about the annotation: the proposed model does not require additional structured annotations on the free-text corpus, such as entity ontologies, dependency parsing results during training and inference.	I-Reply	I-3	Reply	900
The inference stage for synonym discovery is also designed to be data-driven so that we do not need pre-specified candidate entity pairs prepared by domain experts to be verified by the model, which further alleviates annotation efforts.	I-Reply	I-3	Reply	900
We added these details in the revised version.	I-Reply	I-3	Reply	900

The paper presents a neural network model (SYNONYMNET) for automatically discovering synonymous entities from a large free-text corpus with minimal human annotation.	O	O	Review	900
The solution is fairly natural in the form of a siamese network, a class of neural network architectures that contain two or more identical subnetworks, which are an obvious approach for such a task, even though this task's SotA does not cover such architectures.	O	O	Review	900
even though the abstract consists the word novel, the chosen architecture is not a novel one but attached to this task, it can be considered as if.	O	O	Review	900
# Paper discussion:	O	O	Review	900
The introduction and the related work are well explained and the article is well structured.	O	O	Review	900
The authors mark very well the utility of automatically discovering synonyms.	O	O	Review	900
Section 2 presents the SynonymNet, mainly the bi-LSTM applied on the contexts and the bilateral matching with leaky unit and the context aggregation for each entity, along with training objectives and the inference phase.	O	O	Review	900
The novelty does not consist in the model since the model derives basically from a siamese network, but more in the approach, mainly the bilateral matching: one input is a context for an entity, the other input is a context for the synonym entity, and the output is the consensus information from multiple pieces of contexts via a bilateral matching schema with leaky unit (highest matched score with its counterpart as the relative informativeness score) and the context aggregation.	O	O	Review	900
The inference phase is a natural step afterward.	O	O	Review	900
Also, the usage of the leaky unit is clearly stated.	O	O	Review	900
Section 3 presents the experimental phase, which is correct.	O	O	Review	900
The choice of LSTMs is understandable but other experiments could have been done in order to make clearer why it has been chosen.	O	O	Review	900
Regarding also the word embeddings choice, other experiments could have been completed (word2vec and GloVe have been competing with many other embeddings recently).	O	O	Review	900
One noticed misspelling: GolVe (Pennington et al 2014)	O	O	Review	900
We thank the reviewer for the appreciation and the supportive comments.	O	O	Reply	900

Strengths:	O	O	Review	900
- clear explanation of the problem	O	O	Review	900
- clear explanation of the model and its application (pseudocode)	O	O	Review	900
- clear explanation of training and resulting hyperparameters	O	O	Review	900
<sep> Weaknesses:	O	O	Review	900
- weak experimental settings:	B-Review	B-1	Review	900
-- (a) comparison against 'easy to beat' baselines.	I-Review	I-1	Review	900
The comparison should also include as baselines the very relevant methods listed in the last paragraph of the related work section (Snow et a.l 2005, Sun and Grishman 2010, Liao et al 2017, Cambria et al 2018).	I-Review	I-1	Review	900
<sep> -- (b) unclear dataset selection: it is not clear which datasets are collected by the authors and which are pre-existing datasets that have been used in other work too.	B-Review	B-1	Review	900
It is not clear if the datasets that are indeed collected by the authors are publicly available.	I-Review	I-1	Review	900
Furthermore, no justification is given as to why well-known publicly available datasets for this task are not used (such as CoNLL-YAGO (Hoffart et al 2011), ACE 2004 (NIST, 2004; Ratinov et al 2011), ACE 2005 (NIST, 2005; Bentivogli et al 2010), and Wikipedia (Ratinov et al 2011)).	I-Review	I-1	Review	900
<sep> - the coverage of prior work ignores the relevant work of Gupta et al 2017 EMNLP.	B-Review	B-2	Review	900
This should also be included as a baseline.	I-Review	I-2	Review	900
<sep> - Section 2 criticises Mikolov et al's skip-gram model on the grounds that it introduces noisy entities because it ignores context structure.	B-Review	B-3	Review	900
Yet, the skip-gram model is used in the preprocessing step (Section 3.1).	I-Review	I-3	Review	900
This is contradictory and should be discussed.	I-Review	I-3	Review	900
<sep> - the definition of synonyms as entities that are interchangeable under certain contexts is well known and well understood and does not require a reference.	B-Review	B-4	Review	900
If a reference is given, it should not be a generic Wikipedia URL.	I-Review	I-4	Review	900
<sep> - the first and second bulletpoint of contributions should be merged into one.	B-Review	B-5	Review	900
They refer to the same thing.	I-Review	I-5	Review	900
<sep> - the paper is full of English mistakes.	B-Review	B-6	Review	900
A proficient English speaker should correct them.	I-Review	I-6	Review	900
<sep> <sep> We thank the reviewer for the comments and suggestions.	O	O	Reply	900
<sep> <sep> For the mentioned related works, Snow et a.l 2005, Sun and Grishman 2010, Liao et al 2017, Cambria et al 2018, they are not designed for synonym discovery task, so we do not compare with them in the experiments.	B-Reply	B-1	Reply	900
The mentioned related works introduce different ways to incorporate the context information when we are able to obtain external knowledge such as the entity ontologies, dependency parsing results.	I-Reply	I-1	Reply	900
Snow et al model the context by dependency path features extracted from parse trees.	I-Reply	I-1	Reply	900
Their model aims to extract the hypernym (is-a) entity pairs from the sentence.	I-Reply	I-1	Reply	900
Sun and Grishman use the dependency parsing results to devise an unsupervised model that clusters local contexts.	I-Reply	I-1	Reply	900
The contexts are used to discover patterns expressing relationships between entities.	I-Reply	I-1	Reply	900
Liao et al propose to annotate entity mentions from the sentence using limited contexts in short search queries.	I-Reply	I-1	Reply	900
Cambria et al learn concept primitives for sentiment analysis.	I-Reply	I-1	Reply	900
The model encodes the left context and right context separately while neglecting the target word for context modeling.	I-Reply	I-1	Reply	900
A neural tensor layer is used to model the interactions between left/right context.	I-Reply	I-1	Reply	900
<sep> <sep> The models mentioned above inspire us to devise the context encoder in SynonymNet that both 1) explicitly models the entity information using its contexts, and 2) does not use additional structured annotations for context modeling.	I-Reply	I-1	Reply	900
<sep> <sep> For the datasets, we verify the performance of the proposed model on both generic and domain-specific datasets in English and Chinese.	B-Reply	B-1	Reply	900
We updated the dataset descriptions in Section 3.1.	I-Reply	I-1	Reply	900
Wiki+Freebase contains generic entities and their contexts from Wikipedia.	I-Reply	I-1	Reply	900
The PubMed+UMLS and MedBook+MKG contain medical entities and their related context in medical literature.	I-Reply	I-1	Reply	900
Both Wiki+Freebase and PubMed+UMLS are pre-existing English datasets that are publicly available and adopted in previous synonym discovery works [1][2]. The MedBooK+MKG is a Chinese dataset collected by the authors, which is complementary to the existing English datasets, and will be made publicly available.	I-Reply	I-1	Reply	900
For other datasets, CoNLL-YAGO (Hoffart et al 2011) lacks a large enough training set for our model.	I-Reply	I-1	Reply	900
ACE 2004 (NIST, 2004; Ratinov et al 2011) and ACE 2005 (NIST, 2005; Bentivogli et al 2010) are less accessible due to copyright issues.	I-Reply	I-1	Reply	900
The Wiki+Freebase dataset we used shares the same source with Wikipedia (Ratinov et al 2011).	I-Reply	I-1	Reply	900
<sep> <sep> For Gupta et al this work mainly harnesses morphological regularities to deal with analogies like king ‚Äì queen = man ‚Äì woman.	B-Reply	B-2	Reply	900
This is different from the studied task, i.e., synonym discovery.	I-Reply	I-2	Reply	900
<sep> <sep> Thanks for the suggestions.	B-Reply	B-3	Reply	900
We updated Section 2 and Section 3.1.	I-Reply	I-3	Reply	900
Word embedding methods such as the skip-gram learn word representations effectively from a large-scale unannotated corpus.	I-Reply	I-3	Reply	900
The semantics in the pre-trained embeddings make them suitable to initialize word embeddings for our model.	I-Reply	I-3	Reply	900
The embeddings are updated as we train the model.	I-Reply	I-3	Reply	900
<sep> Also, the learned word embeddings are suitable to search for candidate entities.	I-Reply	I-3	Reply	900
Although the embeddings may involve noisy entities, they significantly narrow down the candidate searching space during inference phase: not all entities need to be verified with a target entity.	I-Reply	I-3	Reply	900
The noisy candidates introduced by the initial word embeddings are further pruned away by the matching layer in the SynonymNet model.	I-Reply	I-3	Reply	900
<sep> <sep> Thanks for your suggestions!	B-Reply	B-4	Reply	900
We removed the reference for entities according to your suggestions for simplicity.	I-Reply	I-4	Reply	900
To further clarify the technical novelty of the proposed algorithm, we have rephrased the contributions in Section 1.	I-Reply	I-4	Reply	900
<sep> <sep> Thanks again, and the paper has been proofread for grammar errors.	O	O	Reply	900
<sep> <sep> [1] Qu, Meng, Xiang Ren, and Jiawei Han. "	O	O	Reply	900
Automatic synonym discovery with knowledge bases."	O	O	Reply	900
Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.	O	O	Reply	900
ACM, 2017.	O	O	Reply	900
<sep> [2] <a href="https://github.com/mnqu/DPE" target="_blank" rel="nofollow">https://github.com/mnqu/DPE</a>	O	O	Reply	900

Summary: This paper proposes a technique for quantizing the weights and activations of a CNN.	O	O	Review	1142
The main contribution is in replacing the heuristic to find good quantization intervals of (Zhu et al, 2016) with a different heuristic based on a hierarchical clustering algorithm, and empirically validating its effectiveness.	O	O	Review	1142
<sep> <sep> Strenghts:	O	O	Review	1142
- The proposed nested-means heuristic is simple and makes sense intuitively.	O	O	Review	1142
<sep> - The experiments on two modern architectures seem solid and demonstrate good empirical performance.	O	O	Review	1142
<sep> <sep> Weaknesses:	O	O	Review	1142
- The main weakness is the limited novelty of this paper.	B-Review	B-1	Review	1142
The proposed setup is almost identical to the one in (Zhu et al, 2016), except for the replacement of the heuristic to find quantization intervals with another one.	I-Review	I-1	Review	1142
While the experiments demonstrate the empirical effectiveness of the method as a whole, what is missing is a direct, controlled comparison between the original heuristic and the proposed one.	I-Review	I-1	Review	1142
Now it is hard to tell whether the accuracy increases are obtained through the proposed adaptation or because of other factors such as a better implementation or longer training.	I-Review	I-1	Review	1142
<sep> - In section 4, it is not made clear whether the activations are quantized according to the same scheme as the weights (apart from the issue of selecting a good clipping interval, which is addressed).	B-Review	B-2	Review	1142
<sep> - The paper is a bit short on references, considering the many recent works on quantized neural networks.	B-Review	B-3	Review	1142
<sep> <sep> Minor comments and questions:	O	O	Review	1142
- The wording is sometimes imprecise, making some arguments hard to follow.	B-Review	B-4	Review	1142
Two examples:	I-Review	I-4	Review	1142
-- "Lowering the learning rate for re-training can diminish heavy changes in the weight distribution, at the cost of longer time to converge and the risk to get stuck at plateau regions, which is especially critical for trainable scaling factors"	B-Review	B-4	Review	1142
-- "This approach is beneficial because it defines cluster thresholds which are influenced by large weights that were shown to play a more important role than smaller weights (Han et al 2015b)"	B-Review	B-4	Review	1142
- The title says "for compression and inference acceleration", so it would be nice if the paper reports some compression and timing metrics in the experiments section.	B-Review	B-5	Review	1142
<sep> - The notation in section 3.1 overly complicated, could probably be simplified a bit for readability.	B-Review	B-6	Review	1142
<sep> - Section 3.3: "However, having an additional hyperparameter t_i for each scaling factor alpha_i renders the mandatory hyperparameter tuning infeasible." -	B-Review	B-7	Review	1142
> From section 4.2 in (Zhu et al, 2016), I believe the constant factor t is shared across all layers, making it only a single hyperparameter.	I-Review	I-7	Review	1142
<sep> - Last paragraph of section 4: "(Cai et al 2017) experimentally showed that the pre-activation distribution after batch normalization are all close to a Gaussian with zero mean and unit variance.	B-Review	B-8	Review	1142
Therefore, we propose to select a fixed clipping parameter gamma.". -	I-Review	I-8	Review	1142
> But what about the activations *before* the batchnorm layer where the assumption of zero mean and unit variance does not hold?	I-Review	I-8	Review	1142
Many thanks for the detailed feedback, which helped us to (hopefully) improve the revised version of the paper	O	O	Reply	1142
<sep> - Novelty: the difference you point out to (Zhu et al, 2016) is correct, we adopted the gradient-based scaling factors.	B-Reply	B-1	Reply	1142
We evaluated several ways of obtaining the scaling factors but the approach of (Zhu et al, 2016) is the best performing.	I-Reply	I-1	Reply	1142
Our contributions are as follows: (1) a novel clustering approach that achieves better performance and allows for configurable quantization levels without additional hyperparameters.	I-Reply	I-1	Reply	1142
As a result, we achieve 2.6% better Top1 accuracy (Inception on ImageNet) for the ternary (2-bit encoding) representation.	I-Reply	I-1	Reply	1142
The configurable quantization levels enables the quaternary (2-bit encoding) representation which achieves 3.8% better Top1 accuracy without increasing quantization footprint. (	I-Reply	I-1	Reply	1142
2) Activation quantization by arguing about appropriate clipping intervals. (	I-Reply	I-1	Reply	1142
3) An analysis of the inference workload using reduce-scale architecture that minimizes the number of multiplications and substantially reduces the amount of additions.	I-Reply	I-1	Reply	1142
<sep> <sep> - Comparison to (Zhu et al, 2016): as part of our result discussion we compare to (Zhu et al, 2016), with the same training parameters as for our quantization.	B-Reply	B-1	Reply	1142
The accuracy we obtain is actually higher than the one reported in (Zhu et al, 2016), most likely because we used adaptive learning rate.	I-Reply	I-1	Reply	1142
We hope that this methodology demonstrates the improvement of this quantization compared to prior work.	I-Reply	I-1	Reply	1142
<sep> <sep> - Activation quantization: we quantize activations differently to weights by a simple linear transformation, because non-uniform activations are extremely difficult to implement efficiently for inference.	B-Reply	B-2	Reply	1142
We addressed this issue in the revised submission.	I-Reply	I-2	Reply	1142
<sep> <sep> - References: please refer to the general comments, where we discuss our limited selection due to space constraints.	B-Reply	B-3	Reply	1142
<sep> <sep> - Notation: we changed the notation to a less cluttered notation.	B-Reply	B-6	Reply	1142
<sep> <sep> - Hyperparameter t: this is correct, t is shared across all layers.	B-Reply	B-7	Reply	1142
However, the number of hyper parameters increases if multiple quantization levels are used.	I-Reply	I-7	Reply	1142
<sep> <sep> - Batchnormalization: the output of the batchnorm layer is the input for the next convolution layer.	B-Reply	B-8	Reply	1142
Hence, we don‚Äôt have to quantize activations *before* the batchnorm layer in order to accelerate convolutions.	I-Reply	I-8	Reply	1142

This paper is about CNN model compression and inference acceleration using quantization.	O	O	Review	1142
The main idea is to use 'nest' clustering for weight quantization, more specifically, it partitions the weight values by recurring partitioning the weights by arithmetic means and negative of that of that weight clustering.	O	O	Review	1142
<sep> <sep> I have several questions for this paper:	O	O	Review	1142
<sep> 1) the main algorithm is mainly based on the hypothesis that the weights are with Gaussian distribution.	B-Review	B-1	Review	1142
What happens if the weights are not Gaussian, such as skewed distribution?	I-Review	I-1	Review	1142
Seems the outliners will bring lots of issues for this nest clustering  for partitioning the weight values.	I-Review	I-1	Review	1142
<sep> <sep> 2) Since the paper is on inference acceleration, there is no real inference time result.	B-Review	B-2	Review	1142
I think having some real inference time on these quantized models and showing how their inference time speedup is will be interesting.	I-Review	I-2	Review	1142
<sep> <sep> 3) Activation quantization in Section 4 is a standard way for quantization, but I am curious how to filter out the outliner, and how to set the clipping interval?	B-Review	B-3	Review	1142
<sep> <sep> 4) I am not sure what does the 'sparsity' mean in Table 2?	B-Review	B-4	Review	1142
Does this quantization scheme introduce many zeros?	I-Review	I-4	Review	1142
Or sparsity is corresponding to the compression ratio?	I-Review	I-4	Review	1142
If that is the case, then many quantization algorithms can actually achieve better compression ratios with 2 bits quantization.	I-Review	I-4	Review	1142
We appreciate your feedback on our initial submission.	O	O	Reply	1142
Regarding your questions:	O	O	Reply	1142
<sep> 1.	O	O	Reply	1142
Gaussian distribution: We observe that l2-regularized weights are close to a zero-mean Gaussian, but actually we only assume that weights are symmetrically distributed around zero (the assumption is only used in nested-means clustering for the initial split at zero).	B-Reply	B-1	Reply	1142
That is, our clustering is also compatible with non-Gaussian distributions and we rephrased our text to be clearer in this regard.	I-Reply	I-1	Reply	1142
Nevertheless, the empirical observation that weights are close to Gaussian is seconded by other work [1][2].	I-Reply	I-1	Reply	1142
<sep> 2.	O	O	Reply	1142
The focus of this work is on the concept of this quantization scheme, but we admit that more details on reduction of memory footprint and computational workload would be helpful, which is now included in the revised submission (see Table 6 and 7).	B-Reply	B-2	Reply	1142
A detailed study on inference performance on multiple architectures is beyond the scope of this work, as in our experience such experiments require various code optimizations.	I-Reply	I-2	Reply	1142
Otherwise, there would be little value in reporting such performance numbers.	I-Reply	I-2	Reply	1142
<sep> <sep> 3.	O	O	Reply	1142
This is correct, the activation quantization is a standard way for transforming floating-point values into an integer format.	B-Reply	B-3	Reply	1142
Section 4 is discussing an appropriate clipping interval (including how to select the interval) that can filter out the outliers.	I-Reply	I-3	Reply	1142
Our experimental results indicate that this selection is appropriate.	I-Reply	I-3	Reply	1142
<sep> <sep> 4.	O	O	Reply	1142
Sparsity refers to the percentage of zero-valued elements in the weights.	B-Reply	B-4	Reply	1142
For instance, 60% sparsity means that 60% of the weights are zero.	I-Reply	I-4	Reply	1142
<sep> <sep> [1] Chaim Baskin et al UNIQ: uniform noise injection for the quantization of neural networks	O	O	Reply	1142
[2] Charles Blundell et al Weight Uncertainty in Neural Networks	O	O	Reply	1142

This paper proposes to use n-ary representations for convolutional neural network model quantization.	O	O	Review	1142
A novel strategy of nested-means clustering is developed to update weights.	O	O	Review	1142
Batch normalization is also considered in the activation quantization.	O	O	Review	1142
Experiments on both weight quantization and activation quantization are conducted and show effectiveness.	O	O	Review	1142
<sep> <sep> Strengths:	O	O	Review	1142
1.	O	O	Review	1142
<tab>The idea of nested-means clustering is interesting, which somehow shows its effectiveness.	O	O	Review	1142
<sep> 2.	O	O	Review	1142
<tab>State-of-the-art experimental results.	O	O	Review	1142
<sep> 3.	O	O	Review	1142
<tab>The representation is excellent, and it is easy to follow.	O	O	Review	1142
<sep> <sep> Concerns:	O	O	Review	1142
1.	O	O	Review	1142
<tab>Though the experiment study seems solid, an ablation study is still missing.	B-Review	B-1	Review	1142
For example, how important is the nested-means clustering technique?	I-Review	I-1	Review	1142
What is the effect if replacing it with the original one or with other clustering methods?	I-Review	I-1	Review	1142
What will happen if expanding the interval in the quantization of activation?	I-Review	I-1	Review	1142
All these kinds of questions are hard to answer without an ablation study.	I-Review	I-1	Review	1142
<sep> 2.	O	O	Review	1142
<tab>It is not clear how the weight and activation quantization are addressed together.	B-Review	B-2	Review	1142
<sep> 3.	O	O	Review	1142
<tab>If counting the first and last layers, what is the size of the model (the number of parameters)?	B-Review	B-3	Review	1142
<sep> 4.	O	O	Review	1142
<tab>Similarly, what are the FLOPs in different settings of experiments?	B-Review	B-4	Review	1142
This seems missing.	I-Review	I-4	Review	1142
<sep> 5.	O	O	Review	1142
<tab>When discussing the related work about model compression, there are important references missing.	B-Review	B-5	Review	1142
I just list two references in the latest vision and learning literature:	I-Review	I-5	Review	1142
[Ref1] X. Lin et al Towards accurate binary convolutional neural network.	I-Review	I-5	Review	1142
NIPS 2017	I-Review	I-5	Review	1142
[Ref2] Z. Liu et al Bi-Real Net: Enhancing the Performance of 1-bit CNNs with Improved Representational Capability and Advanced Training Algorithm.	I-Review	I-5	Review	1142
ECCV 2018.	I-Review	I-5	Review	1142
<sep> <sep> Many thanks for the valuable feedback, we addressed all concerns in the revised version of the paper.	O	O	Reply	1142
In particular:	O	O	Reply	1142
<sep> - Ablation study: we agree, an ablation study is required to show the actual benefits of the nested-means clustering.	B-Reply	B-1	Reply	1142
We added the study in the revised submission.	I-Reply	I-1	Reply	1142
However, we were not able to finish the study on the activation clipping interval but we would include it in the next revision as well.	I-Reply	I-1	Reply	1142
<sep> <sep> - Weight and activation quantization: both, weight and activation quantization are required for inference acceleration.	B-Reply	B-2	Reply	1142
We added more information on how to efficiently calculate these representations for the inference.	I-Reply	I-2	Reply	1142
<sep> <sep> - Model size and FLOPs: we include an evaluation of both in Sec.6+7	B-Reply	B-3	Reply	1142
<sep> - Related work: selection was limited due to space constraints, but we now also included the provided references.	B-Reply	B-5	Reply	1142

In this manuscript, the authors propose a secondary objective for softmax minimization.	O	O	Review	353
This complementary objective is based on evaluating the information gathered from the incorrect classes.	O	O	Review	353
Considering these two objectives leads to a new training approach.	O	O	Review	353
The manuscript ends with a collection of tests on a variety of problems.	O	O	Review	353
<sep> <sep> This is an interesting point of view but the manuscript lacks discussion on several important questions:	O	O	Review	353
<sep> 1) How is this idea related to regularization?	B-Review	B-1	Review	353
If we increase the regularization parameter, we can attain sparse parameter vectors.	I-Review	I-1	Review	353
<sep> 2) Would this method also complement from overfitting?	B-Review	B-2	Review	353
<sep> 3) In the numerical experiments, the comparison is carried out against a "baseline" method.	B-Review	B-3	Review	353
Do the authors use regularization with these baseline methods?	I-Review	I-3	Review	353
I believe the comparison will be fair  if the regularization option is turned on for the baseline methods.	I-Review	I-3	Review	353
<sep> 4) Why combining the two objectives in a single optimization problem and then solving the resulting problem is not an option instead of the alternating method given in Algorithm 1?	B-Review	B-4	Review	353
<sep> 5) How does alternating between two objectives change the training time?	B-Review	B-5	Review	353
Do the authors use backpropagation?	I-Review	I-5	Review	353
We would like to thank the reviewer for all the insightful feedbacks.	O	O	Reply	353
Below we provide the explanations for each question or comment raised by the reviewer:	O	O	Reply	353
<sep> <sep> (Q1) How is this idea related to regularization?	O	O	Reply	353
If we increase the regularization parameter, we can attain sparse parameter vectors.	O	O	Reply	353
<sep> <sep> (A1) Conventionally, regularization techniques (e.g., Ridge or Lasso) are applied on the parameter space.	B-Reply	B-1	Reply	353
We want to point out that all the results reported in the manuscript, for both baselines and models trained by COT, have already used L2-norm regularization on the parameter space, exactly as specified in the original papers  (e.g., ResNet [1], WideResNet [2], and DenseNet [3]).	I-Reply	I-1	Reply	353
In other words, COT is applied on top of the existent of those regularization techniques.	I-Reply	I-1	Reply	353
<sep> <sep> If your questions haven‚Äôt been addressed satisfactorily, please kindly let us know and we will be happy to discuss further.	I-Reply	I-1	Reply	353
<sep> <sep> <sep> (Q2) Would this method also complement from overfitting?	O	O	Reply	353
<sep> <sep> (A2) Thank you for the comment.	B-Reply	B-2	Reply	353
We would like to further clarify what you meant by saying ‚Äúcomplement from overfitting.	I-Reply	I-2	Reply	353
‚Äù Our interpretation of the question is: whether COT could be used to fight against overfitting.	I-Reply	I-2	Reply	353
Overfitting means a model fails to generalize, and in our paper we have reported the generalized performance of models trained by COT on the test data, which confirms models trained by COT generalize better.	I-Reply	I-2	Reply	353
In addition, we also calculate the loss gap "(testing loss - training loss)" and report the results in the following table, where a smaller gap indicates that a model generalizes better.	I-Reply	I-2	Reply	353
Experimental results confirm that models trained by COT seem to generalize better due to the smaller gap between training and testing loss.	I-Reply	I-2	Reply	353
<sep> <sep> "(Testing loss - training loss)‚Äù from the state-of-the-art architectures on Cifar10	I-Reply	I-2	Reply	353
==================================================	I-Reply	I-2	Reply	353
<tab><tab><tab><tab>                Baseline<tab>        COT	I-Reply	I-2	Reply	353
ResNet-110 <tab><tab><tab>        0.36                 0.33	I-Reply	I-2	Reply	353
PreAct ResNet-18                 0.28                 0.26	I-Reply	I-2	Reply	353
ResNeXt-29 (2√ó64d)             0.20                 0.19	I-Reply	I-2	Reply	353
WideResNet-28-10<tab><tab>0.23                 0.21	I-Reply	I-2	Reply	353
DenseNet-BC-121           <tab>0.22                 0.22	I-Reply	I-2	Reply	353
=================================================	I-Reply	I-2	Reply	353
<sep> <sep> (Q3) In the numerical experiments, the comparison is carried out against a "baseline" method.	O	O	Reply	353
Do the authors use regularization with these baseline methods?	O	O	Reply	353
I believe the comparison will be fair if the regularization option is turned on for the baseline methods.	O	O	Reply	353
<sep> <sep> (A3) Yes, the regularization (e.g., L2 Norm) techniques are used in all of the baseline methods, as specified in their original papers (e.g., ResNet [1], WideResNet [2], and DenseNet [3]).	B-Reply	B-3	Reply	353
We agree with the reviewer that ‚Äúthe comparison will be fair if the regularization option is turned on for the baseline methods,‚Äù and that is exactly we did in our paper: all the hyper-parameters, regularization and other training techniques are configured in the same way as in the original papers.	I-Reply	I-3	Reply	353
For the details of experimental setup, please refer to the Section 3.2 in our manuscript.	I-Reply	I-3	Reply	353

This paper considers augmenting the cross-entropy objective with "complement" objective maximization, which aims at neutralizing the predicted probabilities of classes other than the ground truth one.	O	O	Review	353
The main idea is to help the ground truth label stands out more easily by smoothing out potential peaks in non-ground-truth labels.	O	O	Review	353
The wide application of the cross-entropy objective makes this approach applicable to many different machine/deep learning applications varying from computer vision to NLP.	O	O	Review	353
<sep> <sep> The paper is well-written, with a clear explanation for the motivation of introducing the complement entropy objective and several good visualization of its empirical effects (e.g., Figures 1 and 2).	O	O	Review	353
The numerical experiments also incorporate a wide spectrum of applications and network structures as well as dataset sizes, and the performance improvement is quite impressive and consistent.	O	O	Review	353
In particular, the adversarial attacks example looks very interesting.	O	O	Review	353
<sep> <sep> One small suggestion is that the authors can also make some comments on the connection between the two-step update algorithm (Algorithm 1) with multi-objective optimization.	B-Review	B-1	Review	353
In particular, I would suggest the authors also try some multi-objective optimization techniques apart from the simple but effective heuristics, and see if some Pareto-optimality can be guaranteed and better practical improvement can be achieved.	I-Review	I-1	Review	353
<sep> (Q1) One small suggestion is that the authors can also make some comments on the connection between the two-step update algorithm (Algorithm 1) with multi-objective optimization.	O	O	Reply	353
In particular, I would suggest the authors also try some multi-objective optimization techniques apart from the simple but effective heuristics, and see if some Pareto-optimality can be guaranteed and better practical improvement can be achieved.	O	O	Reply	353
<sep> <sep> (A1) We sincerely thank the reviewer for the helpful and constructive suggestion about associating COT with multi-objective optimization.	B-Reply	B-1	Reply	353
This is really a brilliant idea.	I-Reply	I-1	Reply	353
As a straight-line future work, we will survey multi-objective optimization techniques, and explore the direction of formulating COT into a multi-objective optimization problem.	I-Reply	I-1	Reply	353

<sep> ========	O	O	Review	353
Summary	O	O	Review	353
========	O	O	Review	353
<sep> The paper deals with the training of neural networks for classification or sequence generation tasks, using a cross-entropy loss.	O	O	Review	353
Minimizing the cross-entropy means maximizing the predicted probabilities of the ground-truth classes (averaged over the samples).	O	O	Review	353
The authors introduce a "complementary entropy" loss with the goal of minimizing the predicted probabilities of the complementary (incorrect) classes.	O	O	Review	353
To do that, they use the average of sample-wise entropy over the complement classes.	O	O	Review	353
By maximizing this entropy, the predicted complementary probabilities are encouraged to be equal and therefore, the authors claim that it neutralizes them as the number of classes grows large.	O	O	Review	353
The proposed training procedure, named COT, consists of alternating between the optimization of the two losses.	O	O	Review	353
<sep> <sep> The procedure is tested on image classification tasks with different datasets (CIFAR-10, CIFAR-100, Street View House Numbers, Tiny ImageNet and ImageNet), machine translation (training using IWSLT dataset, validation and test using TED tst2012/2013 datasets), and speech recognition (Gooogle Commands dataset).	O	O	Review	353
In the experiments, COT outperforms state-of-the-art models for each task/dataset.	O	O	Review	353
<sep> <sep> Adversarial attacks are also considered for the classification of images of CIFAR-10: using the Fast Gradient Sign and Basic Iterative Fast Gradient Sign methods on different models, adversarial examples specifically designed for each model, are generated.	O	O	Review	353
Then results of these models are compared to COT on these examples.	O	O	Review	353
The authors admit	B-Review	B-5	Review	353
that the results are biased since the adversarial attacks only target part of the COT objective, hence more accurate comparisons should be done in future work.	I-Review	I-5	Review	353
<sep> <sep> ===========================	O	O	Review	353
Main comments and questions	O	O	Review	353
===========================	O	O	Review	353
<sep> End of page 1: "the model behavior for classes other than the ground  truth stays unharnessed and not well-defined".	B-Review	B-1	Review	353
The probabilities  should still sum up to 1, so if the ground truth one is maximized,  the others are actually implicitly minimized.	I-Review	I-1	Review	353
No?	I-Review	I-1	Review	353
<sep> <sep> Page 3, sec 2.1: "optimizing on the complement entropy drives ≈∑_ij to 1/(K ‚àí 1)".	B-Review	B-2	Review	353
I believe that it drives each term ≈∑_ij /(1 ‚àí ≈∑_ig ) to be equal to 1/(K-1).	I-Review	I-2	Review	353
Therefore, it drives ≈∑_ij to (1 ‚àí ≈∑_ig)/(K-1) for j!=g.	I-Review	I-2	Review	353
<sep> <sep> This indeed flattens the ≈∑_ij for j!=g, but the effect on ≈∑_ig is not controlled.	I-Review	I-2	Review	353
In particular this latter can decrease.	I-Review	I-2	Review	353
Then in the next step of the algorithm, ≈∑_ig will be maximized, but with no explicit control over the complementary probabilities.	I-Review	I-2	Review	353
There are two objectives that are optimized over the same variable theta.	I-Review	I-2	Review	353
So the question is, are we sure that this procedure will converge?	I-Review	I-2	Review	353
What prevents situations where the probabilities will alternate between two values?	I-Review	I-2	Review	353
<sep> <sep> For example, with 4 classes, we look at the predicted probabilities of a given sample of class 1:	I-Review	I-2	Review	353
Suppose after step 1 of Algo 1, the predicted probabilities are:  0.5 0.3 0.1 0.1	I-Review	I-2	Review	353
After step 2:  0.1 0.3 0.3 0.3	I-Review	I-2	Review	353
Then step 1: 0.5 0.3 0.1 0.1	I-Review	I-2	Review	353
Then step 2: 0.1 0.3 0.3 0.3	I-Review	I-2	Review	353
And so on... Can this happen?	I-Review	I-2	Review	353
Or why not?	I-Review	I-2	Review	353
Did the algorithm have trouble converging in any of the experiments?	I-Review	I-2	Review	353
<sep> <sep> Sec 3.1:	O	O	Review	353
"additional efforts for tuning hyper-parameters might be required for optimizers to achieve the best performance": Which hyper-parameters are considered here?	B-Review	B-3	Review	353
If it is the learning rate, why not use a different one, tuned for each objective?	I-Review	I-3	Review	353
<sep> <sep> Sec 3.2:	O	O	Review	353
The additional optimization makes each training iteration more costly.	B-Review	B-4	Review	353
How much more?	I-Review	I-4	Review	353
How do the total running times of COT compare to the ones of the baselines?	I-Review	I-4	Review	353
I think this should be mentioned in the paper.	I-Review	I-4	Review	353
<sep> <sep> Sec 3.4:	O	O	Review	353
As the authors mention, the results are biased and so the comparison is not fair here.	B-Review	B-5	Review	353
Therefore I wonder about the  relevance of this section.	I-Review	I-5	Review	353
Isn't there an easy way to adapt the attacks to the two objectives to be able to illustrate the conjectured robustness of COT?	I-Review	I-5	Review	353
For example, naively having a two steps perturbation of the input: one based on the gradient of the primary objective and then perturb the result using the gradient of the complementary objective?	I-Review	I-5	Review	353
<sep> <sep> ===========================	O	O	Review	353
Secondary comments and typos	O	O	Review	353
===========================	O	O	Review	353
<sep> Page 3, sec 2.1: "...the proposed COT also optimizes the complement objective for neutralizing the predicted probabilities...", using maximizes instead of optimizes would be clearer.	B-Review	B-6	Review	353
<sep> <sep> In the definition of the complement entropy, equation (2), C takes as parameter only y^hat_Cbar but then in the formula, ≈∑_ig appears.	B-Review	B-7	Review	353
Shouldn't C take all \hat_y as an argument in this case?	I-Review	I-7	Review	353
<sep> <sep> Algorithm 1 page 4: I find it confusing that the (artificial) variable that appears in the argmin (resp.	B-Review	B-8	Review	353
argmax) is theta_{t-1}	I-Review	I-8	Review	353
(resp.	I-Review	I-8	Review	353
theta'_t) which is the previous parameter.	I-Review	I-8	Review	353
Is there a reason for this choice?	I-Review	I-8	Review	353
<sep> <sep> Sec 3:	B-Review	B-9	Review	353
"We perform extensive experiments to evaluate COT on the tasks" --> COT on tasks	I-Review	I-9	Review	353
<sep> "compare it with the baseline algorithms that achieve state-of-the-art in the respective domain." --	I-Review	I-9	Review	353
> domainS	I-Review	I-9	Review	353
<sep> "to evaluate the model‚Äôs robustness trained by COT when attacked" needs reformulation.	I-Review	I-9	Review	353
<sep> <sep> "we select a state- of-the-art model that has the open-source implementation" --> an open-source implementation	I-Review	I-9	Review	353
<sep> Sec 3.2:	B-Review	B-10	Review	353
Figure 4: why is the median reported and not the mean (as in Figure 3, Tables 2 and 3)?	I-Review	I-10	Review	353
<sep> <sep> Table 3 and 4: why is it the validation error that is reported and not the test error?	I-Review	I-10	Review	353
<sep> <sep> Sec 3.3:	B-Review	B-11	Review	353
"Neural machine translation (NMT) has populated the use of neural sequence models": populated has not the intended meaning.	I-Review	I-11	Review	353
<sep> <sep> "We apply the same pre-processing steps as shown in the model" --> in the paper?	I-Review	I-11	Review	353
<sep> <sep> Sec 3.4:	B-Review	B-12	Review	353
"We believe that the models trained using COT are generalized better" --> "..using COT generalize better"	I-Review	I-12	Review	353
<sep> "using both FGSM and I-FGSM method" --> methodS	I-Review	I-12	Review	353
<sep> "The baseline models are the same as Section 3.2." --	I-Review	I-12	Review	353
> as in Section 3.2.	I-Review	I-12	Review	353
<sep> <sep> "the number of iteration is set at 10." --	I-Review	I-12	Review	353
> to 10	I-Review	I-12	Review	353
<sep> "using complement objective may help defend adversarial attacks." --	I-Review	I-12	Review	353
> defend against	I-Review	I-12	Review	353
<sep> "Studying on COT and adversarial attacks.." --> could be better formulated	I-Review	I-12	Review	353
<sep> References: there are some inconsistencies (e.g.: initials versus first name)	I-Review	I-12	Review	353
<sep> <sep> Pros	O	O	Review	353
====	O	O	Review	353
- Paper is clear and well-written	O	O	Review	353
- It seems to me that it is a new original idea	O	O	Review	353
- Wide applicability	O	O	Review	353
- Extensive convincing experimental results	O	O	Review	353
<sep> Cons	O	O	Review	353
====	O	O	Review	353
- No theoretical guarantee that the procedure should converge	B-Review	B-2	Review	353
- The training time may be twice longer (to clarify)	B-Review	B-4	Review	353
- The adversarial section, as it is,  does not seem relevant for me	B-Review	B-12	Review	353
<sep> <sep> <sep> We sincerely thank the reviewer for the useful and detailed comments.	O	O	Reply	353
Below we provide explanations for each of your comments or questions.	O	O	Reply	353
<sep> <sep> (Q1) End of page 1: "the model behavior for classes other than the ground truth stays unharnessed and not well-defined".	O	O	Reply	353
The probabilities should still sum up to 1, so if the ground truth one is maximized,  the others are actually implicitly minimized.	O	O	Reply	353
No?	O	O	Reply	353
<sep> <sep> (A1) Your understanding is totally correct.	B-Reply	B-1	Reply	353
We have changed the original text to a more clear statement:	I-Reply	I-1	Reply	353
<sep> ‚ÄúTherefore, for classes other than the ground truth, the model behavior is not explicitly optimized --- their predicted probabilities are indirectly minimized when ≈∑_ig is maximized since the probabilities sum up to 1.‚Äù	I-Reply	I-1	Reply	353
<sep> We want to thank the reviewer again for crystalizing the manuscript.	I-Reply	I-1	Reply	353
<sep> <sep> <sep> (Q2) Page 3, sec 2.1: "optimizing on the complement entropy drives ≈∑_ij to 1/(K ‚àí 1)".	O	O	Reply	353
I believe that it drives each term ≈∑_ij /(1 ‚àí ≈∑_ig ) to be equal to 1/(K-1).	O	O	Reply	353
Therefore, it drives ≈∑_ij to (1 ‚àí ≈∑_ig)/(K-1) for j!=g.	O	O	Reply	353
<sep> <sep> This indeed flattens the ≈∑_ij for j!=g, but the effect on ≈∑_ig is not controlled.	O	O	Reply	353
In particular this latter can decrease.	O	O	Reply	353
Then in the next step of the algorithm, ≈∑_ig will be maximized, but with no explicit control over the complementary probabilities.	O	O	Reply	353
There are two objectives that are optimized over the same variable theta.	O	O	Reply	353
So the question is, are we sure that this procedure will converge?	O	O	Reply	353
What prevents situations where the probabilities will alternate between two values?	O	O	Reply	353
<sep> <sep> For example, with 4 classes, we look at the predicted probabilities of a given sample of class 1:	O	O	Reply	353
Suppose after step 1 of Algo 1, the predicted probabilities are:  0.5 0.3 0.1 0.1	O	O	Reply	353
After step 2:  0.1 0.3 0.3 0.3	O	O	Reply	353
Then step 1: 0.5 0.3 0.1 0.1	O	O	Reply	353
Then step 2: 0.1 0.3 0.3 0.3	O	O	Reply	353
And so on... Can this happen?	O	O	Reply	353
Or why not?	O	O	Reply	353
Did the algorithm have trouble converging in any of the experiments?	O	O	Reply	353
<sep> <sep> (A2) Thanks for the detailed comment.	B-Reply	B-2	Reply	353
As the reviewer pointed out, ‚Äúdrives ≈∑_ij to 1/(K ‚àí 1)‚Äù was indeed a typo and should be corrected to ‚Äúdrive ≈∑_ij /(1 ‚àí ≈∑_ig) to 1/(K-1)‚Äù.	I-Reply	I-2	Reply	353
We have modified the manuscript correspondingly.	I-Reply	I-2	Reply	353
Indeed, maximizing complement entropy in Eq(2) only drives ‚Äú≈∑_ij /(1 ‚àí ≈∑_ig) to 1/(K-1)‚Äù, and therefore in the example provided above, the predicted probabilities after step 2 can be ‚Äú0.1 0.3 0.3 0.3‚Äù or ‚Äú0.5, (1 - 0.5)/3, (1 - 0.5)/3, (1 - 0.5)/3‚Äù, or other values so long as the incorrect classes (≈∑_ij's) receive similar predicted probabilities.	I-Reply	I-2	Reply	353
According to our observations from the experiments, the probabilities tend to converge to ‚Äú0.5, (1 - 0.5)/3, (1 - 0.5)/3, (1 - 0.5)/3‚Äù.	I-Reply	I-2	Reply	353
Experiments show that the algorithm does not have trouble converging; the algorithm converges smoothly in all the experiments we have conducted.	I-Reply	I-2	Reply	353
Again, we thank the reviewer for the insightful comment; studying the theory of COT convergence is an intriguing topic and we leave it as a future work.	I-Reply	I-2	Reply	353
<sep> <sep> <sep> (Q3) Sec 3.1: "additional efforts for tuning hyper-parameters might be required for optimizers to achieve the best performance": Which hyper-parameters are considered here?	O	O	Reply	353
If it is the learning rate, why not use a different one, tuned for each objective?	O	O	Reply	353
<sep> <sep> (A3) Hyper-parameters in this statement indeed refer to the learning rate, and we have modified the statement in the manuscript to avoid confusion; the modified statement is provided below:	B-Reply	B-3	Reply	353
<sep> ‚Äútherefore, additional efforts for tuning learning rates might be required for optimizers to achieve the best performance.	I-Reply	I-3	Reply	353
‚Äù	I-Reply	I-3	Reply	353
<sep> Regarding the second question about tuning learning rates, we have conducted several experiments with different learning rates specifically tuned for each objective.	I-Reply	I-3	Reply	353
The experimental results show that using the same learning rate for both primary and complement objectives leads to the best performance when Eq(3) is used as the complement objective.	I-Reply	I-3	Reply	353
<sep> <sep> <sep> (Q4) Sec 3.2: The additional optimization makes each training iteration more costly.	O	O	Reply	353
How much more?	O	O	Reply	353
How do the total running times of COT compare to the ones of the baselines?	O	O	Reply	353
I think this should be mentioned in the paper.	O	O	Reply	353
<sep> <sep> (A4) Yes, one additional backpropagation is required in each iteration when applying COT.	B-Reply	B-4	Reply	353
On average, the total training time is about 1.6 times longer compared to the baselines.	I-Reply	I-4	Reply	353
Thanks for the suggestion, and we have included this in the latest manuscript (section 2.2).	I-Reply	I-4	Reply	353

This paper adds an interesting twist on top of recent unpaired image translation work.	O	O	Review	472
A domain-level translation function is jointly optimized with an instance-level matching objective.	O	O	Review	472
This yields the ability to extract corresponding image pairs out of two unpaired datasets, and also to potentially refine unpaired translation by subsequently training a paired translation function on the discovered matches.	O	O	Review	472
I think this is a promising direction, but the current paper has unconvincing results, and it‚Äôs not clear if the method is really solving an important problem yet.	O	O	Review	472
<sep> <sep> My main criticism is with the experiments and results.	B-Review	B-1	Review	472
The experiments focus almost entirely on the setting where there actually exist exact matches between the two image sets.	I-Review	I-1	Review	472
Even the partial matching experiments in Section 4.1.2 only quantify performance on the images that have exact matches.	I-Review	I-1	Review	472
This is a major limitation since the compelling use cases of the method are in scenarios where we do not have exact matches.	I-Review	I-1	Review	472
It feels rather contrived to focus so much on the datasets with exact matches since, 1) these datasets actually come as paired data and, in actual practice, supervised translation can be run directly, 2) it‚Äôs hard to imagine datasets that have exact but unknown matches (I welcome the authors to put forward some such scenarios), 3) when exact matches exist, simpler methods may be sufficient, such as matching edges.	B-Review	B-3	Review	472
There is no comparison to any such simple baselines.	I-Review	I-3	Review	472
<sep> <sep> I think finding analogies that are not exact matches is much more compelling.	B-Review	B-4	Review	472
Quantifying performance in this case may be hard, and the current paper only offers a few qualitative results.	I-Review	I-4	Review	472
I‚Äôd like to see far more results, and some attempt at a metric.	I-Review	I-4	Review	472
One option would be to run user studies where humans judge the quality of the matches.	I-Review	I-4	Review	472
The results shown in Figure 2 don‚Äôt convince me, not just because they are qualitative and few, but also because I‚Äôm not sure I even agree that the proposed method is producing better results: for example, the DiscoGAN results have some artifacts but capture the texture better in row 3.	I-Review	I-4	Review	472
<sep> <sep> I was also not convinced by the supervised second step in Section 4.3.	B-Review	B-5	Review	472
Given that the first step achieves 97% alignment accuracy, it‚Äôs no surprised that running an off-the-shelf supervised method on top of this will match the performance of running on 100% correct data.	I-Review	I-5	Review	472
In other words, this section does not really add much new information beyond what we could already infer given that the first stage alignment was so successful.	I-Review	I-5	Review	472
<sep> <sep> What I think would be really interesting is if the method can improve performance on datasets that actually do not have ground truth exact matches.	B-Review	B-4	Review	472
For example, the shoes and handbags dataset or even better, domain adaptation datasets like sim to real.	I-Review	I-4	Review	472
<sep> <sep> I‚Äôd like to see more discussion of why the second stage supervised problem is beneficial.	B-Review	B-5	Review	472
Would it not be sufficient to iterate alpha and T iterations enough times until alpha is one-hot and T is simply training against a supervised objective (Equation 7)?	I-Review	I-5	Review	472
<sep> <sep> Minor comments:	O	O	Review	472
1.	O	O	Review	472
In the intro, it would be useful to have a clear definition of ‚Äúanalogy‚Äù for the present context.	B-Review	B-6	Review	472
<sep> 2.	O	O	Review	472
Page 2: a link should be provided for the Putin example, as it is not actually in Zhu et al 2017.	B-Review	B-7	Review	472
<sep> 3.	B-Review	B-8	Review	472
Page 3: ‚ÄúWeakly Supervised Mapping‚Äù ‚Äî I wouldn‚Äôt call this weakly supervised.	I-Review	I-8	Review	472
Rather, I‚Äôd say it‚Äôs just another constraint / prior, similar to cycle-consistency, which was referred to under the ‚ÄúUnsupervised‚Äù section.	I-Review	I-8	Review	472
<sep> 4.	O	O	Review	472
Page 4 and throughout: It‚Äôs hard to follow which variables are being optimized over when.	B-Review	B-9	Review	472
For example, in Eqn.	I-Review	I-9	Review	472
7, it would be clearer to write out the min over optimization variables.	I-Review	I-9	Review	472
<sep> 5.	O	O	Review	472
Page 6: The Maps dataset was introduced in Isola et al 2017, not Zhu et al 2017.	B-Review	B-10	Review	472
<sep> 6.	B-Review	B-11	Review	472
Page 7: The following sentence is confusing and should be clarified: ‚ÄúThis shows that the distribution matching is able to map source images that are semantically similar in the target domain.	I-Review	I-11	Review	472
‚Äù	I-Review	I-11	Review	472
7.	O	O	Review	472
Page 7: ‚ÄúThis shows that a good initialization is important for this task.	B-Review	B-12	Review	472
‚Äù ‚Äî Isn‚Äôt this more than initialization?	I-Review	I-12	Review	472
Rather, removing the distributional and cycle constraints changes the overall objective being optimized.	I-Review	I-12	Review	472
<sep> 8.	O	O	Review	472
In Figure 2, are the outputs the matched training images, or are they outputs of the translation function?	B-Review	B-13	Review	472
<sep> 9.	O	O	Review	472
Throughout the paper, some citations are missing enclosing parentheses.	B-Review	B-14	Review	472
Thank you for the detailed and constructive review.	O	O	Reply	472
It highlighted motivation and experimental protocols that were further clarified in the revised version.	O	O	Reply	472
<sep> <sep> This paper is focused on exact analogy identification.	O	O	Reply	472
A core question in the reviews was the motivation for the scenario of exact matching, and we were challenged by the reviewer to find real world applications for it.	O	O	Reply	472
<sep> <sep> We believe that finding exact matches is an important problem and occurs in multiple real-world problems.	B-Reply	B-1	Reply	472
Exact or near-exact matching occurs in:	I-Reply	I-1	Reply	472
* 3D point cloud matching.	I-Reply	I-1	Reply	472
<sep> * Matching between different cameras panning the same scene in different trajectories (hard if they are in different modalities such as RGB and IR).	I-Reply	I-1	Reply	472
<sep> * Matching between the audio samples of two speakers uttering the same set of sentences.	I-Reply	I-1	Reply	472
<sep> * Two repeats of the same scripted activity (recipe, physics experiment, theatrical show)	I-Reply	I-1	Reply	472
* Two descriptions of the same news event in different styles (at the sentence level or at the story level).	I-Reply	I-1	Reply	472
<sep> * Matching parallel dictionary definitions and visual collections.	I-Reply	I-1	Reply	472
<sep> * Learning to play one racket sport after knowing to play another, building on the existing set of acquired movements and skills.	I-Reply	I-1	Reply	472
<sep> <sep> In all these cases, there are exact or near exact analogies that could play a major rule in forming unsupervised links between the domains.	I-Reply	I-1	Reply	472
<sep> We note that on a technical level, most numerical benchmarks in cross domain translation are already built using exact matches, and many of the unsupervised techniques could be already employing this information, even if implicitly.	I-Reply	I-1	Reply	472
We show that our method is more effective at it than other methods.	I-Reply	I-1	Reply	472
<sep> <sep> On a more theoretical level, cognitive theories of analogy-based reasoning mostly discuss exact analogies from memory (see, e.g., G. Fauconnier, and M. Turner, ‚ÄúThe way we think‚Äù, 2002 ).	I-Reply	I-1	Reply	472
For example, a new situation is dealt with by retrieving and adopting a motor action that was performed before.	I-Reply	I-1	Reply	472
Here, the chances of finding such analogies are high since the source domain is heavily populated due to life experiences.	I-Reply	I-1	Reply	472
<sep> <sep> Regarding experiments.	I-Reply	I-1	Reply	472
We believe that in some cases the requests are conflicting: we cannot provide numerical results in places for which there are no analogies and no metrics for success.	I-Reply	I-1	Reply	472
We provide a large body of experiments for exact matches and show that our method far surpasses everything else.	I-Reply	I-1	Reply	472
We have compared with multiple baselines covering all the reasonable successful approaches for matching between domains.	I-Reply	I-1	Reply	472
<sep> <sep> The experiments regarding cases without exact matches are, admittedly, less extensive, added for completeness, and not the focus of this paper.	B-Reply	B-4	Reply	472
<sep> <sep> The reviewer wondered if matching will likely work better with simpler methods.	B-Reply	B-3	Reply	472
Our baselines test precisely this possibility and show that the simpler methods do not perform well.	I-Reply	I-3	Reply	472
Specifically edge-based matches are well covered by the more general VGG feature baseline (which uses also low level maps - not just fc7).	I-Reply	I-3	Reply	472
AN-GAN has easily outperformed this method.	I-Reply	I-3	Reply	472
If it is possible to hand-craft a successful method for each task individually, these hand-crafted features are unlikely to generalize as well as the multi-scale VGG features or AN-GAN.	I-Reply	I-3	Reply	472
<sep> <sep> We put further clarification in the paper for the motivation for the second ‚Äúsupervised‚Äù step.	B-Reply	B-5	Reply	472
In unsupervised semantic matching, larger neural architecture have been theoretically and practically shown to be less successful (due to overfitting and finding it less easy to recover the correct transformation).	I-Reply	I-5	Reply	472
The distribution matching loss function (e.g. CycleGAN) is adversarial and is therefore less stable and might not optimize the quantity we care about (e.g. L1/L2 loss).	I-Reply	I-5	Reply	472
Once the datasets are aligned and analogies are identified, however, the cross domain translation becomes a standard supervised deep learning problem where large architectures do well and standard loss functions can be used.	I-Reply	I-5	Reply	472
This is the reason for the two steps.	I-Reply	I-5	Reply	472
It might be possible to include the increase in architecture into the alpha-iterations but it‚Äôs non-trivial and we didn‚Äôt find it necessary.	I-Reply	I-5	Reply	472

The paper presents a method for finding related images (analogies) from different domains based on matching-by-synthesis.	O	O	Review	472
The general idea is interesting and the results show improvements over previous approaches, such as CycleGAN (with different initializations, pre-learned or not).	O	O	Review	472
The algorithm is tested on three datasets.	O	O	Review	472
<sep> <sep> While the approach has some strong positive points, such as good experiments and theoretical insights (the idea to match by synthesis and the proposed loss which is novel, and combines the proposed concepts), the paper lacks clarity and sufficient details.	B-Review	B-1	Review	472
<sep> <sep> Instead of the longer intro and related work discussion, I would prefer to see a Figure with the architecture and more illustrative examples to show that the insights are reflected in the experiments.	B-Review	B-1	Review	472
Also, the matching part, which is discussed at the theoretical level, could be better explained and presented at a more visual level.	I-Review	I-1	Review	472
It is hard to understand sufficiently well what the formalism means without more insight.	I-Review	I-1	Review	472
<sep> <sep> Also, the experiments need more details.	B-Review	B-2	Review	472
For example, it is not clear what the numbers in Table 2 mean.	I-Review	I-2	Review	472
<sep> <sep> <sep> <sep> <sep> Thank you for your positive feedback on the theoretical and experimental merits of this paper.	O	O	Reply	472
<sep> <sep> Following your feedback on the clarity of presentation of the method.	B-Reply	B-1	Reply	472
we included a diagram (including example images) illustrating the algorithm.	I-Reply	I-1	Reply	472
To help keep the length under control, we shortened the introduction and related work section as you suggested.	I-Reply	I-1	Reply	472
<sep> <sep> We further clarified the text of the experiments.	B-Reply	B-2	Reply	472
Specifically the numbers in Tab 2 are the top-1 accuracy for both directions (A to B and B to A) when 0%, 10% and 25% of examples do not have matches in the other domain.	I-Reply	I-2	Reply	472
If some details remain unclear, we would be glad to clarify them.	I-Reply	I-2	Reply	472
<sep> <sep> We hope that your positive opinion of the content of the paper with the improvement in clarity of presentation will merit an acceptance.	O	O	Reply	472

This paper presents an image-to-image cross domain translation framework based on generative adversarial networks.	O	O	Review	472
The contribution is the addition of an explicit exemplar constraint into the formulation which allows best matches from the other domain to be retrieved.	O	O	Review	472
The results show that the proposed method is superior for the task of exact correspondence identification and that AN-GAN rivals the performance of pix2pix with strong supervision.	O	O	Review	472
<sep> <sep> <sep> Negatives:	O	O	Review	472
1.)	O	O	Review	472
The task of exact correspondence identification seems contrived.	B-Review	B-1	Review	472
It is not clear which real-world problems have this property of having both all inputs and all outputs in the dataset, with just the correspondence information between inputs and outputs missing.	I-Review	I-1	Review	472
<sep> 2.)	O	O	Review	472
The supervised vs unsupervised experiment on Facades->Labels (Table 3) is only one scenario where applying a supervised method on top of AN-GAN‚Äôs matches is better than an unsupervised method.	B-Review	B-2	Review	472
More transfer experiments of this kind would greatly benefit the paper and support the conclusion that ‚Äúour self-supervised method performs similarly to the fully supervised method.	I-Review	I-2	Review	472
‚Äù	I-Review	I-2	Review	472
<sep> Positives:	O	O	Review	472
1.)	O	O	Review	472
The paper does a good job motivating the need for an explicit image matching term inside a GAN framework	O	O	Review	472
2.)	O	O	Review	472
The paper shows promising results on applying a supervised method on top of AN-GAN‚Äôs matches.	O	O	Review	472
<sep> <sep> Minor comments:	O	O	Review	472
1.	O	O	Review	472
The paper sometimes uses L1 and sometimes L_1, it should be L_1 in all cases.	B-Review	B-3	Review	472
<sep> 2.	O	O	Review	472
DiscoGAN should have the Kim et al citation, right after the first time it is used.	B-Review	B-4	Review	472
I had to look up DiscoGAN to realize it is just Kim et al	I-Review	I-4	Review	472
We thank you for highlighting the novelty and successful motivation of the exemplar-based matching loss.	O	O	Reply	472
<sep> <sep> We think that the exact-analogy problem is very important.	B-Reply	B-1	Reply	472
Please refer to our comment to AnonReviewer2 for an extensive discussion.	I-Reply	I-1	Reply	472
<sep> <sep> Following your request, we have added AN-GAN supervised experiments for the edges2shoes and edges2handbags datasets.	B-Reply	B-2	Reply	472
The results as for the Facades case are very good.	I-Reply	I-2	Reply	472
<sep> <sep> Thank you for highlighting the inconsistency in L_1 notation and the confusing reference.	B-Reply	B-3	Reply	472
This has been fixed in the revised version.	I-Reply	I-3	Reply	472

Summary:	O	O	Review	472
This submission proposes a reinforcement learning framework based on human emotional reaction in the context of autonomous driving.	O	O	Review	472
This relies on defining a reward function as the convex combination of an extrinsic (goal oriented) reward, and an intrinsic reward.	O	O	Review	472
This later reward is learnt from experiments with humans performing the task in a virtual environment, for which emotional response is quantified as blood volume pulse wave (BVP).	O	O	Review	472
The authors show that including this intrinsic reward lead to a better performance of a deep Q networks, with respect to using the extrinsic reward only.	O	O	Review	472
<sep> Evaluation:	O	O	Review	472
Overall the proposed idea is interesting, and the use of human experiments to improve a reinforcement learning algorithm offers interesting perspectives.	O	O	Review	472
The weakness of the paper in my opinion is the statistical analysis of the results, the lack of in depth evaluation of the extrinsic reward prediction and the rather poor baseline comparison.	O	O	Review	472
<sep> Detailed comments:	O	O	Review	472
1.	O	O	Review	472
<tab>Statistical analysis	B-Review	B-1	Review	472
The significance of the results should be assessed with statistical methods in the following results:	I-Review	I-1	Review	472
Section 4.1: Please provide and assessment of the significance of the testing loss of the prediction.	I-Review	I-1	Review	472
For example, one could repetitively shuffle blocks of the target time series and quantify the RMSE obtained by the trained algorithm to build an H0 statistic of random prediction.	I-Review	I-1	Review	472
<sep> Section 4.2: the sentence ‚Äúimproves significantly when lambda is either non-zero or not equal to 1‚Äù does not seem valid to me and such claim should in any case be properly evaluated statistically (including correction for multiple comparison etc‚Ä¶).	I-Review	I-1	Review	472
<sep> Error bars: please provide a clear description in the figure caption of what the error bars represent.	I-Review	I-1	Review	472
Ideally in case of small samples, box plots would be more appropriate.	I-Review	I-1	Review	472
<sep> 2.	O	O	Review	472
<tab>Time lags in BVP	B-Review	B-2	Review	472
It would be interesting to know (from the literature) the typical latency of BVP responses to averse stimuli (and possible the latency of the various mechanisms, e.g. brain response, in the chain from stimuli to BVP).	I-Review	I-2	Review	472
Moreover, as latency is likely a critical factor in anticipating danger before it is too late, it would important to know how the prediction accuracy evolves when learning to predict at different time lags forward in time, and how such level of anticipation influence the performance of the Q-network.	I-Review	I-2	Review	472
<sep> 3.	O	O	Review	472
<tab>Poor baseline comparison	B-Review	B-3	Review	472
The comparison to reward shaping in section 4.4 is not very convincing.	I-Review	I-3	Review	472
One can imagine that what counts is not the absolute distance to a wall, but the distance to a wall in the driving direction, within a given solid angle.	I-Review	I-3	Review	472
As a consequence, a better heuristic baseline could be used.	I-Review	I-3	Review	472
<sep> Moreover, it is unclear whether the approaches should be compared with the same lambda: the authors need to provide evidence that the statistics (mean and possibly variance) of the chosen heuristic is match to the original intrinsic reward, otherwise it is obvious that the lambda should be adapted.	I-Review	I-3	Review	472
<sep> 4.	O	O	Review	472
<tab>Better analysis of figure 5-6(Minor)	B-Review	B-4	Review	472
I find figure 5-6 very interesting and I would suggest that the authors fully comment on these results.	I-Review	I-4	Review	472
E.g. : (1) why the middle plot of Fig.6 mostly flat, and why such differences between each curve from the beginning of the training. (	I-Review	I-4	Review	472
2) Why the goal oriented task leads to different optimal lambda, is this just a normalization issue?	I-Review	I-4	Review	472
<sep> <sep> Thank you for the detailed comments and constructive suggestions.	O	O	Reply	472
We are running additional experiments and will upload the updated manuscript when they are complete in the next few days.	B-Reply	B-1	Reply	472
We have calculated the baseline RMSE using a random target as suggested by the reviewer.	I-Reply	I-1	Reply	472
We have added these results and the significance of the difference between the baseline and reported results using an unpaired T-Test.	I-Reply	I-1	Reply	472
The RMSE of the model predictions is significantly lower for all participants than the RMSE with the random target.	I-Reply	I-1	Reply	472
The RMSE of the model predictions was 0.21 lower on average.	I-Reply	I-1	Reply	472
These results have been added to Table 1.	I-Reply	I-1	Reply	472
<sep> <sep> The error bars in the plots correspond to standard error.	I-Reply	I-1	Reply	472
Non-overlapping error bars correspond to 84% confidence according to z-test (Please see: <a href="https://tminka.github.io/papers/minka-errorbars.pdf)."	I-Reply	I-1	Reply	472
target="_blank" rel="nofollow">https://tminka.github.io/papers/minka-errorbars.pdf).</a> Scaling of these by c=1.64, leads to 95% significance when the bars don‚Äôt overlap.	I-Reply	I-1	Reply	472
We will add this information to the figure captions as well as the text in the paper.	I-Reply	I-1	Reply	472
This should clarify which of the comparisons are significant.	I-Reply	I-1	Reply	472
We will also modify the claim in the text to correspond to this.	I-Reply	I-1	Reply	472
<sep> <sep> We agree that there is a time delay between a stimulus and the physiological response to that stimulus.	B-Reply	B-2	Reply	472
Our system was trained to mimic the physiological response of a person, this delay is already modeled into the prediction .	I-Reply	I-2	Reply	472
While it might be interesting to introduce an artificial time delay (i.e., to reflect a response that is faster or slower that was actually experienced), we believe our experiments are the most representative of the delays experienced.	I-Reply	I-2	Reply	472
Please do clarify if we misunderstood your comment.	I-Reply	I-2	Reply	472
<sep> <sep> In this work we were trying to mimic a self-driving car in which the sensors are only facing a single direction and thus distance to the wall was an appropriate assumption.	B-Reply	B-3	Reply	472
We are not sure what the reviewer meant in the comment about the statistics of the ‚Äúchosen heuristic matching to the original intrinsic reward.	I-Reply	I-3	Reply	472
‚Äù We believe that a comparison with the same lambda values is the best initial test to run, without additional reasons to adjust the value of lambda on a case-by-case basis.	I-Reply	I-3	Reply	472
<sep> <sep> Fig.6 (Distance) shows that the average length of the episodes does not increase with the number of episodes.	B-Reply	B-4	Reply	472
This is because with increasing numbers of episodes the car travels further but also faster.	I-Reply	I-4	Reply	472
These two factors cancel one another out resulting in episodes with similar duration.	I-Reply	I-4	Reply	472
The goal-oriented task leads to a different optimal lambda due to the different nature of the reward compared to the velocity or distance task.	I-Reply	I-4	Reply	472
However, it should be noted that consistently a lambda that is non-zeros and not equal to 1 is optimal.	I-Reply	I-4	Reply	472
We are adding more discussion of these results.	I-Reply	I-4	Reply	472

Starting from the hypothesis that humans have evolved basic autonomic visceral responses that influence decision making in a meaningful way and that these are at work in driving a car, the authors propose to use such signals within the RL framework.	O	O	Review	472
This is accomplished by augmenting the RL reward function with a model learned directly from human nervous system responses.	O	O	Review	472
This leads to a	O	O	Review	472
convex combination of extrinsic rewards and visceral responses, with the goal to maximize extrinsic rewards and minimizing the physiological arousal response.	O	O	Review	472
The authors first show that they can train a CNN to predict systolic peaks from the pulse waveform based on the input images.	O	O	Review	472
The output of this network is then used with parametrically altered weightings in combination with the task related reward to evaluate performance on different driving tasks.	O	O	Review	472
The authors show that for different weightings performance on a number of driving tasks performance as measured by the collected extrinsic rewards is better.	O	O	Review	472
<sep> <sep> Overall, this is an interesting application of RL.	O	O	Review	472
It is OK to be inspired by biology, neuroscience, or psychology, but further reaching claims or interpretations of results in these fields need to be chosen carefully.	O	O	Review	472
The discussion of neuroscience and psychology are only partially convincing, e.g. there is extensive evidence that autonomic responses are highly dependent on cognition and not just decisions dependent on visceral, autonomic responses of the SNS.	B-Review	B-1	Review	472
Currently, the manuscript is rather loosely switching between inspirations, imprecise claims, and metaphorical implementations with relation to neuroscience.	I-Review	I-1	Review	472
The authors are encouraged to relate their work to some of the multi-criteria and structural credit assignment literature in RL, given the convex combination of rewards.	B-Review	B-2	Review	472
It may also be important to relate this work to imitation learning, given that the physiological measurements certainly also reflects states and actions by the human agents.	I-Review	I-2	Review	472
While one indication for the reasons of higher extrinsic rewards with the augmented system is mentioned by the authors, namely that the autonomic signal is continuous and while the extrinsic rewards are sparse is convincing, it is not at all clear, why the augmented system performs better as shown in figure 5.	B-Review	B-3	Review	472
<sep> <sep> Thank you for your thoughtful review and suggestions of related work.	O	O	Reply	472
We are running the additional experiments and will upload the updated manuscript when they are complete in the next few days.	O	O	Reply	472
In the meantime, here is a summary of the changes and responses to your questions.	O	O	Reply	472
We are tightening up the description of how our system is inspired by biological processes.	B-Reply	B-1	Reply	472
We want to emphasize that this work is leveraging the peripheral blood volume pulse as a signal that indicates changes in autonomic nervous system arousal, related to stress.	I-Reply	I-1	Reply	472
But the system is not mimicking the nervous system or attempting to replicate its processes.	I-Reply	I-1	Reply	472
We are revising the introduction to make this clear.	I-Reply	I-1	Reply	472
<sep> <sep> We appreciate the comment to relate this work to the imitation learning and credit assignment literature.	B-Reply	B-2	Reply	472
We are adding to the background sections to tie in this related work.	I-Reply	I-2	Reply	472
The imitation learning literature is relevant as the physiological reward could be considered similar to feedback from an expert.	I-Reply	I-2	Reply	472
The structural credit assignment problem, or generalization problem, is related in the way that it helps to address cases in which the parameter space is very large.	I-Reply	I-2	Reply	472
Our method helps reduce the sparsity of the reward signal and thus makes learning more practical in a large parameter space.	I-Reply	I-2	Reply	472
We are adding references to the following work on imitation learning and credit assignment:	I-Reply	I-2	Reply	472
<sep> Search-based Structured Prediction	I-Reply	I-2	Reply	472
Hal Daum√© III, John Langford, Daniel Marcu	I-Reply	I-2	Reply	472
<sep> A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning	I-Reply	I-2	Reply	472
St√©phane Ross, Geoffrey J. Gordon, J. Andrew Bagnell	I-Reply	I-2	Reply	472
<sep> Reinforcement and Imitation Learning via Interactive No-Regret Learning	I-Reply	I-2	Reply	472
Stephane Ross, J. Andrew Bagnell	I-Reply	I-2	Reply	472
<sep> Generative Adversarial Imitation Learning	I-Reply	I-2	Reply	472
Jonathan Ho, Stefano Ermon	I-Reply	I-2	Reply	472
<sep> Learning to Search Better Than Your Teacher	I-Reply	I-2	Reply	472
Kai-Wei Chang, Akshay Krishnamurthy, Alekh Agarwal, Hal Daum√© III, John Langford	I-Reply	I-2	Reply	472
<sep> Self-Improving Reactive Agents Based On Reinforcement Learning, Planning and Teaching	I-Reply	I-2	Reply	472
Long-Ji Lin	I-Reply	I-2	Reply	472
<sep> Regarding explaining why the augmented system performs better, we believe that the sparsity is the best explanation.	B-Reply	B-3	Reply	472
The qualitative examples also shed light on the types of situations in which the system is likely to get a high or low reward.	I-Reply	I-3	Reply	472
Having a less sparse reward that helps the vehicle avoid collisions is beneficial.	I-Reply	I-3	Reply	472

The method proposes to use physiological signals to improve performance of reinforcement learning algorithms.	O	O	Review	472
By measuring heart pulse amplitude the authors build an intrinsic reward function that is less sparse that the extrinsic one.	O	O	Review	472
It helps to be risk averse and allows getting better performances than the vanilla RL algorithm on a car-driving task.	O	O	Review	472
<sep> <sep> I found the paper well written and the idea is quite nice.	O	O	Review	472
I like the idea that risk aversion is processed as a data-driven problem and not as an optimisation problem or using heuristics.	O	O	Review	472
I think this general idea could be pushed further in other cases (like encourage fun, surprise, happiness etc. ).	O	O	Review	472
<sep> <sep> There are some issues with this paper yet.	O	O	Review	472
First, modifying the reward function also modifies the optimal policy.	B-Review	B-1	Review	472
In the specific case of car driving, it may not be bad to modify the policy so that it makes passenger less stressed but in general, it is not good.	I-Review	I-1	Review	472
This is why most of works based on intrinsic motivation also schedule the lambda parameter to decrease with time.	I-Review	I-1	Review	472
This is not something explored in this paper.	I-Review	I-1	Review	472
Also, this work is well suited to the car-driving scenario because stress is closely related to risk and accident.	B-Review	B-2	Review	472
But it may not work with other applications.	I-Review	I-2	Review	472
I would thus suggest that the title of the paper reflects the specific case of risk aversion.	I-Review	I-2	Review	472
Thank you for the review and the suggestion of additional experiments.	O	O	Reply	472
We are running experiments regarding the time-varying lambda and will upload the updated manuscript when they are complete in the next few days.	B-Reply	B-1	Reply	472
We agree that exploring a time varying lambda is of interest.	I-Reply	I-1	Reply	472
Our goal with this paper was to show that the blood pulse amplitude could be used effectively as an intrinsic reward function that is less sparse than the extrinsic reward from the environment.	I-Reply	I-1	Reply	472
We feel the experiments capture that and we are happy to include additional results from experiments in which the lambda parameter decreases temporally to illustrate how that influences performance.	I-Reply	I-1	Reply	472
The experiments take several days to complete after which we will upload the revised paper.	O	O	Reply	472
<sep> <sep> We are happy to change the title of the paper to reflect the specific case of risk aversion.	B-Reply	B-2	Reply	472
But we do believe that the principal applies beyond applications in driving to contexts in which stress may be an undesirable state.	I-Reply	I-2	Reply	472
We propose the following title: ‚ÄúVisceral Machines: Risk-Aversion in Reinforcement Learning with Intrinsic Physiological Rewards‚Äù.	I-Reply	I-2	Reply	472

<sep> [Summary]	O	O	Review	10101
This paper studies the relationship between gradient clipping in stochastic gradient descent and robustness to label noise.	O	O	Review	10101
Theoretical results show that gradient clipping in general is not robust to symmetric label noise.	O	O	Review	10101
The paper then proposes a variant of gradient clipping (cl-clipping) that induces label noise robustness.	O	O	Review	10101
Experiments support these claims on synthetic datasets and typical classification benchmarks.	O	O	Review	10101
<sep> <sep> [Decision]	O	O	Review	10101
The first contribution, that gradient clipping does not induce robustness to label noise, is an important negative result given the prominence of gradient clipping and datasets with noisy labels.	O	O	Review	10101
The second contribution, cl-clipping, amounts to minimizing a non-convex loss with saturating regions but, as far as I know, these properties are necessary for robustness to label noise.	B-Review	B-1	Review	10101
Theoretical results are limited to SGD with mini-batch size 1 but the insights carry over to larger mini-batches in the experiments.	I-Review	I-1	Review	10101
Overall, I recommend acceptance.	O	O	Review	10101
<sep> <sep> [Comments]	O	O	Review	10101
The parameter tau controls robustness, and a higher noise level requires a higher tau.	B-Review	B-1	Review	10101
There is little discussion on how this parameter is chosen in the experiments.	I-Review	I-1	Review	10101
On the synthetic dataset, the Huberized loss uses tau=1 and the partially Huberized loss uses tau=2.	I-Review	I-1	Review	10101
How are these values chosen?	I-Review	I-1	Review	10101
Did the authors observe a U-shaped curve when sweeping over tau?	I-Review	I-1	Review	10101
On the real-world datasets, tau is fixed for each method across different noise levels.	I-Review	I-1	Review	10101
Does this mean that a single value of tau worked best regardless of the noise level, or was it tuned for a particular noise level?	I-Review	I-1	Review	10101
<sep> <sep> Proposition 4 shows that symmetric noise breaks down the clipping method in Eq (7) which can be seen as a special case of gradient clipping.	B-Review	B-2	Review	10101
I might be missing something here, but it is not obvious to me that, when the norm of x is constant across the samples, Eq (7) is equal to gradient clipping.	I-Review	I-2	Review	10101
<sep> <sep> Thanks for the feedback!	O	O	Reply	10101
<sep> <sep> We have updated the draft to include a discussion on the choice of œÑ in Section 5.	B-Reply	B-1	Reply	10101
This is a tuning parameter that can be set by the user, similar to the q parameter from generalised cross-entropy, or noise estimates in loss-correction techniques.	I-Reply	I-1	Reply	10101
<sep> <sep> In our experiments, we chose œÑ so as to maximise accuracy on a set of (noisy) validation samples for the setting of noise rate œ± = 0.6.	I-Reply	I-1	Reply	10101
We did not tune œÑ for each noise rate, since this value of œÑ worked well for lower noise rates as well.	I-Reply	I-1	Reply	10101
Of course, there is no conceptual issue with tuning œÑ for each value of œ±, although there is a slight computational cost.	I-Reply	I-1	Reply	10101
<sep> <sep> For the range of œÑ, we found that values of œÑ = { 2, 10 } ‚Äî which correspond to clipping at probability values less than 0.5 and 0.1 respectively ‚Äî generally gave good performance for the datasets considered.	I-Reply	I-1	Reply	10101
In general, one can certainly expand this range, again with a slight computational cost.	I-Reply	I-1	Reply	10101
<sep> <sep> We indeed observe a U-shaped curve in general.	I-Reply	I-1	Reply	10101
Note also that as œÑ gets closer to 1, we essentially reduce to the original loss (e.g., log-loss).	I-Reply	I-1	Reply	10101
As œÑ gets larger, we essentially reduce to the linear loss.	I-Reply	I-1	Reply	10101
As shown in Table 2, intermediate values of œÑ yield better performance than either extreme under label noise.	I-Reply	I-1	Reply	10101
We have made a comment on this following the discussion of how œÑ is chosen.	I-Reply	I-1	Reply	10101
<sep> <sep> Proposition 4 indeed concerns loss-based gradient clipping, i.e., Equation 7.	B-Reply	B-2	Reply	10101
Per the discussion following Lemma 1, this is not exactly the same as gradient clipping in general.	I-Reply	I-2	Reply	10101
However, note that for linear models, the term ‚àámŒ∏(x, y) = ||x||2, so if this is constant then Equations 6 and 7 will coincide.	I-Reply	I-2	Reply	10101
We have added some clarifying text after Equation 7.	I-Reply	I-2	Reply	10101

Summary:	O	O	Review	10101
<sep> Gradient clipping has been studied as an optimization technique and also as a tool for privacy preserving, but in this paper, it studies the robustness properties of gradient clipping.	O	O	Review	10101
More specifically, the main question of the paper is: Can gradient clipping mitigate label noise?	O	O	Review	10101
The paper reveals that the answer is no, but further proposes a simple variant of gradient clipping is robust and has nice property of classification calibration.	O	O	Review	10101
Experiments show that the proposed variant works under label noise.	O	O	Review	10101
<sep> <sep> <sep> Strength of the paper:	O	O	Review	10101
<sep> The motivation and goal of the paper is stated in the title and is very clear, making it easier to follow the story of the paper.	O	O	Review	10101
There are sufficient background on the loss functions and gradient clipping in the beginning that helps guide the reader.	O	O	Review	10101
The proposed method is robust to label noise and has theoretical guarantees.	O	O	Review	10101
The relationship between similar work is summarized.	O	O	Review	10101
Experiments have both synthetic and benchmark datasets to demonstrate the behavior of the proposed method.	O	O	Review	10101
<sep> <sep> <sep> Weakness of the paper:	O	O	Review	10101
<sep> Currently, the experiments only include methods studied in the paper.	B-Review	B-1	Review	10101
It would be better to include baseline methods stated in the end of Section 5 or in Section 4.3.	I-Review	I-1	Review	10101
<sep> <sep> After response:	O	O	Review	10101
Thank you for the clarification!	O	O	Review	10101
I have read the other reviews and author comments.	O	O	Review	10101
Thanks for the feedback!	O	O	Reply	10101
<sep> <sep> We compare against the generalised cross-entropy (GCE) as this is (to our knowledge) a state-of-the-art loss-based technique for coping with label noise.	B-Reply	B-1	Reply	10101
Note that the methods discussed in Sec 4.3 employ the same base loss as GCE.	I-Reply	I-1	Reply	10101
<sep> <sep> The methods listed at the end of Sec 5 are based on distinct, complementary ideas.	I-Reply	I-1	Reply	10101
While certainly combining these with our clipped loss would be of interest, we wished to focus on our main message in the experiments (namely, the study of the viability of clipping to mitigate label noise).	I-Reply	I-1	Reply	10101

This paper studied a fundamental problem in robust machine learning, that is, can gradient clipping mitigate label noise?	O	O	Review	10101
The paper is well written, clearly motivated, highly novel and significant not only in a theoretical sense but also in a practical sense.	O	O	Review	10101
<sep> <sep> As argued in the abstract, gradient clipping is a widely-used technique which is generally motivated from the OPTIMIZATION point of view.	O	O	Review	10101
In this paper, the authors proposed an entirely new motivation of gradient clipping from the ROBUSTNESS point of view, since intuitively it should be able to mitigate label noise.	O	O	Review	10101
Surprisingly, the authors proved that for some simple binary classification with label noise, standard gradient clipping does not provide robustness; on the other hand, a simple variant of gradient clipping is robust, and is equivalent to suitably modifying the underlying loss function.	O	O	Review	10101
<sep> <sep> The major contributions were well summarized in the bottom of page 1, the related work was discussed in sec 4.3, and the caveats of this new methodology were also given in sec 4.4.	O	O	Review	10101
Note that the proposed composite loss-based gradient clipping is applicable even on top of existing noise-robust losses, for example, the generalized cross-entropy loss, and this serves as a convincing demonstration of the great significance of the paper.	O	O	Review	10101
Actually, the paper is full of insights, and I really enjoyed reviewing it.	O	O	Review	10101
<sep> <sep> I have a few questions on Tables 1 and 2.	B-Review	B-1	Review	10101
Table 1 said the standard gradient clipping is not robust according to Proposition 4.	I-Review	I-1	Review	10101
However, Proposition 4 is for the loss-based gradient clipping in (7) rather than the standard gradient clipping in (6).	I-Review	I-1	Review	10101
Perhaps I have missed something, but why the non-robustness of (7) can imply the non-robustness of (6)?	I-Review	I-1	Review	10101
<sep> <sep> In Table 2, Linear loss on MNIST, the test accuracy was 9.6 when rho=0.6.	B-Review	B-2	Review	10101
Is this a typo?	I-Review	I-2	Review	10101
The accuracy was still 78.8 when rho=0.4.	I-Review	I-2	Review	10101
Moreover, the authors explained why the theoretically grounded linear loss performed so badly, that is, the optimization was so difficult.	I-Review	I-2	Review	10101
How about CE+clipping loss on CIFAR-100?	I-Review	I-2	Review	10101
The standard gradient clipping was also harmful here, even when there was no label noise at all.	I-Review	I-2	Review	10101
Was this due to bad optimization or robustness (or both)?	I-Review	I-2	Review	10101
<sep> <sep> Since distributionally robust supervised learning is a future direction to go, I think the authors may be interested in a thought-provoking paper:	B-Review	B-3	Review	10101
W. Hu, G. Niu, I. Sato, and M. Sugiyama.	I-Review	I-3	Review	10101
Does distributionally robust supervised learning give robust classifiers?	I-Review	I-3	Review	10101
ICML 2018.	I-Review	I-3	Review	10101
Thanks for the feedback!	O	O	Reply	10101
<sep> <sep> Regarding Proposition 4: you are correct that it concerns loss-based gradient clipping, which is not the same as gradient clipping in general.	B-Reply	B-1	Reply	10101
Following the comments to AnonReviewer3, the two are related for linear models when the norms of the inputs are constant; see the discussion following Equation 7.	I-Reply	I-1	Reply	10101
<sep> <sep> The results of linear loss on MNIST under high noise are not a typo ‚Äî we observed that the linear loss can sometimes be unstable under high noise levels.	I-Reply	I-1	Reply	10101
In particular, the training can completely collapse.	I-Reply	I-1	Reply	10101
We hypothesise that one might be able to cope with this by adjusting learning rate schedule, for example, but in the interest of consistency we use the same architecture and settings regardless of noise level.	I-Reply	I-1	Reply	10101
<sep> <sep> Regarding the performance of CE + clipping on CIFAR-100, our intuition is the following: per Lemma 1, clipping is similar to linearising the base loss beyond a certain point. (	B-Reply	B-2	Reply	10101
It is not exactly so owing to the gradient of the margin.)	I-Reply	I-2	Reply	10101
Now, we observed that the linear loss does not perform well on CIFAR-100.	I-Reply	I-2	Reply	10101
One possible explanation for this is given in Sec 4.3, i.e., the gradients with respect to the probability estimates do not contain information about sample importances.	I-Reply	I-2	Reply	10101
We thus believe this poor performance translates to clipping with low enough thresholds.	I-Reply	I-2	Reply	10101
<sep> <sep> The citation on distributionally-robust learning is appreciated -- this is indeed relevant, and we have added it to the conclusion.	B-Reply	B-3	Reply	10101

The authors formulate the credit assignment method as minimizing the divergence between policy function and a learned prior distribution.	O	O	Review	627
Then they apply f-divergence optimization to avoid the model collapse in this framework.	O	O	Review	627
Empirical experiments are conducted on the program synthesis benchmark with sparse rewards.	O	O	Review	627
<sep> <sep> The main contribution of this paper is applying f-divergence optimization on the program synthesis task for credit assignment.	O	O	Review	627
<sep> <sep> + One of my concerns is that the experiment section is in a limited domain to argue it is a broad algorithm for credit assignment.	B-Review	B-1	Review	627
The paper will be stronger if the comparison is applied in a distant domain like goal-based robot learning etc.	I-Review	I-1	Review	627
With some experiments on a different domain, the paper will be more convincing.	I-Review	I-1	Review	627
<sep> <sep> + The improvement/margin in program synthesis task needed to be explained well, is the margin significant enough?	B-Review	B-2	Review	627
<sep> + The paper could discuss more on related papers on program synthesis in the related work section as the main experiment is in this work.	B-Review	B-3	Review	627
<sep> <sep> + The authors claim that the two-buffer estimation is better and lead to better gradient estimation, but it is not demonstrated empirically or theoretically.	B-Review	B-4	Review	627
It could be better if the ablation study is conducted in the experiment.	I-Review	I-4	Review	627
Or the author could provide a theoretical analysis of why equation (13) is better.	I-Review	I-4	Review	627
Moreover, the investigation of different choices of and is necessary.	I-Review	I-4	Review	627
<sep> + Another study needed is the investigation of different divergences; the work will be stronger if a KL divergence version is compared.	B-Review	B-5	Review	627
Otherwise, it is not clear how much the f-divergence will contribute to the performance.	I-Review	I-5	Review	627
<sep> <sep> Thank you for your time and detailed feedback.	O	O	Reply	627
<sep> We are glad to hear you found this work interesting and valuable, and understand your concerns.	O	O	Reply	627
We are confident that, following the points of clarification highlighted by you, we can resolve any ambiguities in the paper, and thank you for helping make the paper stronger as a result.	O	O	Reply	627
<sep> We answer most of the said pints below.	O	O	Reply	627
It would be very helpful to hear your thoughts on our responses so that we can make the appropriate modifications to the paper.	O	O	Reply	627
<sep> We hope that you will be willing to consider revising your assessment in light of the clarifications.	O	O	Reply	627
<sep> <sep> <sep> 1.	O	O	Reply	627
Evaluation of the proposed method on other domains	O	O	Reply	627
<sep> We would like to point out GACA can be useful in other challenging tasks such as combinational optimization and structured prediction where credit assignment from binary feedback remains a major challenge.	B-Reply	B-1	Reply	627
We want emphasize that one of the main purposes of this paper is to introduce the method of guided adaptive credit assignment.	I-Reply	I-1	Reply	627
As such, the purpose of this paper is not to beat every single benchmark but to show the benefit of this framework.	I-Reply	I-1	Reply	627
In particular, we demonstrate the effectiveness of GACA on two challenging program synthesis benchmarks, to our best knowledge, this work is the current state-of-the-art method that uses only binary supervision and outperforms previous methods by a large margin.	I-Reply	I-1	Reply	627
We leave the investigation of our method on other domains for future work.	I-Reply	I-1	Reply	627
<sep> <sep> <sep> 2.	O	O	Reply	627
Results explanation/significance	O	O	Reply	627
<sep> <sep> GACA outperforms recent state-of-the-art methods MeRL, BoRL, and MAPO by a large margin, on a variety of tasks‚Äîincluding the challenging WikiSQL and WikiTable,  as shown in Table 1, 2, 3.	B-Reply	B-2	Reply	627
To our best knowledge, GACA is by far the state-of-the-art method on these benchmarks using only binary feedback.	I-Reply	I-2	Reply	627
GACA is easy to implement and is a generalization of various credit assignment methods(MAPO MML, EML, RAML, and REINFORCE), we want to emphasize that GACA is general and can be further improved by combining it with techniques in other methods to further boost performance, such as meta-learning proposed in MeRL.	I-Reply	I-2	Reply	627
<sep> <sep> <sep> <sep> 3.	O	O	Reply	627
More related work on program synthesis	O	O	Reply	627
<sep> <sep> We have included several program synthesis papers in related work.	B-Reply	B-3	Reply	627
<sep> <sep> <sep> <sep> 4.	O	O	Reply	627
Why use two-buffer estimation in Eq.13	O	O	Reply	627
<sep> <sep> Because GACA enables reusing all the past trajectories while previous methods only use high-reward trajectories, two-buffer estimation naturally arises here as a result of using stratified sampling to obtain unbiased and low variance gradient.	B-Reply	B-4	Reply	627
w_b and w_c are calculated via stratified sampling, refer to Eq(13) for details.	I-Reply	I-4	Reply	627
<sep> <sep> <sep> 5.	O	O	Reply	627
What‚Äôs the performance of GACA if f-divergence is replaced with KL-divergence?	O	O	Reply	627
<sep> <sep> <sep> If KL-divergence is used, then GACA reduces to GACA w/o AG which means GACA without adaptive gradient estimation.	B-Reply	B-5	Reply	627
From experimental results(e.g.	I-Reply	I-5	Reply	627
Table 1), we can see that GACA w/o AG greatly outperforms baselines on both benchmarks.	I-Reply	I-5	Reply	627

This paper proposes guided adaptive credit assignment (GACA) for policy gradient methods with sparse reward.	O	O	Review	627
<sep> <sep> GACA attacks the credit assignment problem by	O	O	Review	627
1) using entropy regularized RL objective (KL divergence), iteratively update prior \bar{\pi} and \pi_\theta;	O	O	Review	627
2) generalizing KL to f-divergence to avoid mode seeking behaviour of KL;	O	O	Review	627
3) using 2 tricks to estimate the gradient of f-divergence to update \pi_\theta, a) modified MAPO (Liang et al 2018) estimator (using two buffers), b) replacing rho_f by the inverse of tail probability (Wang et al 2018).	O	O	Review	627
<sep> <sep> Experiments of program synthesis and instruction following are conducted, to show the proposed GACA outperform competitive baselines.	O	O	Review	627
<sep> <sep> Although the experimental results look promising, I have many concerns with respect to this paper as follows.	O	O	Review	627
<sep> <sep> 1.	O	O	Review	627
The organization is bad.	B-Review	B-1	Review	627
The main algorithm has been put into the appendix.	I-Review	I-1	Review	627
It should appear in the paper.	I-Review	I-1	Review	627
<sep> <sep> 2.	O	O	Review	627
There are too many typos and errors in the paper and derivations, which quite affected reading and understanding.	B-Review	B-2	Review	627
<sep> For example:	I-Review	I-2	Review	627
in Eq. (6), what is z \sim Z?	I-Review	I-2	Review	627
Should be z \in Z?	I-Review	I-2	Review	627
It also appears in many other places.	I-Review	I-2	Review	627
<sep> in Eq. (7), there should not be \sum_{z \in Z} here.	I-Review	I-2	Review	627
<sep> Proof for Prop.	I-Review	I-2	Review	627
1, I cannot really understand the notations here.	I-Review	I-2	Review	627
Please rewrite and explain this proof. (	I-Review	I-2	Review	627
I can see it follows Grau-Moya et al 2019, but the notations here are not clear.)	I-Review	I-2	Review	627
<sep> in Eq. (12), \pi_\theta / \bar{\pi} appeared, which one is correct?	I-Review	I-2	Review	627
11), \bar{\pi} / \pi_\theta is used, but in Eq. (	I-Review	I-2	Review	627
While in the proof for Lemma 2, it is \bar{\pi} / \pi_\theta.	I-Review	I-2	Review	627
And in Alg.	I-Review	I-2	Review	627
1 it is \pi_\theta / \bar{\pi}. Please make this consistent.	I-Review	I-2	Review	627
<sep> Typos, like "Combining Theorem 1 and Theorem 2 together, we summarize the main algorithm in Algorithm 1."	I-Review	I-2	Review	627
in the last paragraph of p6.	I-Review	I-2	Review	627
However, they appeared as Prop.	I-Review	I-2	Review	627
1 and Lemma 2.	I-Review	I-2	Review	627
Please improve the writing.	I-Review	I-2	Review	627
<sep> <sep> 3.	O	O	Review	627
The mutual information argument Eq. (9) seems irrelevant here. (	B-Review	B-6	Review	627
It follows Grau-Moya et al 2019, but the notations in the proof are bad and I cannot understand it).	I-Review	I-6	Review	627
Whether the solution is mutual information or not seems not helpful for getting better credit assignment.	I-Review	I-6	Review	627
I suggest remove/reduce related arguments around Eq. (9) and (10), and make space for the main algorithm.	I-Review	I-6	Review	627
<sep> <sep> 4.	B-Review	B-7	Review	627
The entropy regularized objective and the KL is kind of well known.	I-Review	I-7	Review	627
Maybe reduce the description here.	I-Review	I-7	Review	627
And the key point is Eq. (8), which lays the foundation of iteratively update \bar{\pi} and \pi_\theta.	I-Review	I-7	Review	627
However, Eq. (7).	I-Review	I-7	Review	627
8) is the optimal solution of KL Eq. (	I-Review	I-7	Review	627
Is it also the optimal solution of f-divergence used in the algorithm?	I-Review	I-7	Review	627
If it is, clearly show that.	I-Review	I-7	Review	627
If not, then update \bar{\pi} in Alg.	I-Review	I-7	Review	627
1 is problematic.	I-Review	I-7	Review	627
Please clarify this point.	I-Review	I-7	Review	627
<sep> <sep> 5.	O	O	Review	627
The 2 tricks used here for estimating the gradient of f-divergence with respect to \pi_\theta, i.e., modified MAPO estimator in Prop.	O	O	Review	627
2, and inverse tail probability in Wang et al 2018, seems quite important for the empirical performance.	O	O	Review	627
<sep> However, motivation is not clear enough.	B-Review	B-4	Review	627
First, why using two replay buffers "leads to a better approximation"?	I-Review	I-4	Review	627
Any theory/intuition or experiment to support this claim?	I-Review	I-4	Review	627
Second, why using inverse tail probability "achieve a trade-off between exploration and exploitation".	B-Review	B-5	Review	627
It seems not obvious to see that.	I-Review	I-5	Review	627
And also, explain why using this trick makes "\pi_\theta adaptively coverage and approximate prior distribution \bar{\pi}".	I-Review	I-5	Review	627
<sep> <sep> 6.	B-Review	B-3	Review	627
The claim that GACA recovers all the mentioned methods as special cases are questionable.	I-Review	I-3	Review	627
For example, as in E.1, "by simply choosing \rho_f as constant 1", comparing Eq. (12) with the gradient of REINFORCE, there is a difference that REINFORCE has a reward term, but GACA does not have.	I-Review	I-3	Review	627
Then why GACA reduces to REINFORCE?	I-Review	I-3	Review	627
Also in E.5, the RAML objective seems wrong.	I-Review	I-3	Review	627
There is no reward term here.	I-Review	I-3	Review	627
Please check them.	I-Review	I-3	Review	627
<sep> <sep> Overall, the proposed GACA method achieves promising results in program synthesis tasks.	O	O	Review	627
However, there are many concerns with respect to motivation and techniques that should be resolved.	O	O	Review	627
<sep> <sep> =====Update=====	O	O	Review	627
Thanks for the rebuttal.	O	O	Review	627
I keep my rating since some of my concerns are still not resolved.	O	O	Review	627
In particular, "Eq. (7).	B-Review	B-7	Review	627
8) is the optimal solution of KL Eq. (	I-Review	I-7	Review	627
Is it also the optimal solution of f-divergence used in the algorithm?"	I-Review	I-7	Review	627
Eq. (8) looks not the same as the paragraph above Lemma 2 "\bar{\pi} = \pi_\theta" to me.	I-Review	I-7	Review	627
If Eq. (11), the update in Alg.	I-Review	I-7	Review	627
8) is not the optimal solution of Eq. (	I-Review	I-7	Review	627
1 is somewhat problematic and other better choices exist.	I-Review	I-7	Review	627
Since Algorithm 1 explicitly uses f-divergence, I think at least this point should be clarified by the authors rather than my guess.	I-Review	I-7	Review	627
Thank you for your time and detailed feedback.	O	O	Reply	627
<sep> We are happy to hear you found this work valuable, and understand your concerns.	O	O	Reply	627
We are confident that, following the points of clarification highlighted by you, we can resolve any ambiguities in the paper, and thank you for helping make the paper stronger as a result.	O	O	Reply	627
We answer most of the said points below.	O	O	Reply	627
It would be very helpful to hear your thoughts on our responses so that we can make the appropriate modifications to the paper.	O	O	Reply	627
<sep> We hope that you will be willing to consider revising your assessment in light of the clarifications.	O	O	Reply	627
<sep> <sep> <sep> 1.	O	O	Reply	627
Typos in the paper, move algorithm to main paper, and other presentation suggestions	O	O	Reply	627
<sep> <sep> Thanks for pointing out typos in the submission, we have moved the main algorithm from Appendix to main paper, adjust the organization, and improved the presentation of the paper a lot.	B-Reply	B-2	Reply	627
The updated version of the paper is available now.	I-Reply	I-2	Reply	627
Again, thank you for reading the paper.	I-Reply	I-2	Reply	627
<sep> <sep> <sep> 2.	O	O	Reply	627
Why using two replay buffers "leads to a better approximation"	O	O	Reply	627
<sep> <sep> We acknowledge that this sentence is a little bit confusing.	B-Reply	B-4	Reply	627
What we mean is GACA enables using both high-reward and zero-reward trajectories, which leads to a higher sample efficiency.	I-Reply	I-4	Reply	627
While previous methods either only reply on on-policy trajectories(e.g.	I-Reply	I-4	Reply	627
REINFORCE, MML, etc), or use a buffer to save high-reward trajectories for replaying(e.g.	I-Reply	I-4	Reply	627
MAPO).	I-Reply	I-4	Reply	627
<sep> <sep> <sep> 4.	O	O	Reply	627
Motivations behind using inverse tail probability to approximate f-divergence	O	O	Reply	627
<sep> <sep> By using f-divergence, we reveal the connections between various previous credit assignment methods, for example, IML and RAML both minimize a reverse KL-divergence between policy and a target distribution, MAPO minimizes KL-divergence, etc.	B-Reply	B-5	Reply	627
Different divergence measures lead to a different approximation of policy to target distribution[1], for example, KL-divergence often leads to mode-collapse.	I-Reply	I-5	Reply	627
We want the policy distribution to approximate/cover the target distribution as good as possible, thus we utilize inverse tail probability technique which we found performs the best.	I-Reply	I-5	Reply	627
<sep> <sep> <sep> [1] Yingzhen Li, Richard E. Turner.	O	O	Reply	627
R√©nyi Divergence Variational Inference.	O	O	Reply	627
Advances in Neural Information Processing Systems(NeurIPS), 2016.	O	O	Reply	627
<sep> <sep> <sep> <sep> 5.	O	O	Reply	627
The claim that GACA recovers all the mentioned methods as special cases are questionable	O	O	Reply	627
<sep> <sep> Your concern about REINFORCE and RAML as special cases of GACA can be resolved if you recall that for simplicity and without loss of generality, we assumed that reward is 1 for successful task completion trajectories and 0 otherwise, this follows the notations convenience in [1, 2]. In the meanwhile, we do take your suggestions on improving the presentation of the paper that we have updated Appendix E with improved presentation of how does GACA recover existing credit assignment methods.	B-Reply	B-3	Reply	627
Thank you for reading our Appendix.	I-Reply	I-3	Reply	627
<sep> <sep> <sep> [1] Chen Liang, Mohammad Norouzi, Jonathan Berant, Quoc Le, and Ni Lao.	O	O	Reply	627
Memory augmented policy optimization for program synthesis with generalization.	O	O	Reply	627
Advances in Neural Information Processing Systems(NeurIPS), 2018.	O	O	Reply	627
<sep> [2] Kelvin Guu, Panupong Pasupat, Evan Liu, and Percy Liang.	O	O	Reply	627
From language to programs: Bridging reinforcement learning and maximum marginal likelihood.	O	O	Reply	627
In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp.1051‚Äì1062, Vancouver, Canada, July 2017.	O	O	Reply	627

Summary:	O	O	Review	627
This work proposed an off-policy framework for policy gradient approach called	O	O	Review	627
guided adaptive credit assignment (GACA) in a simplified setting of goal-oriented	O	O	Review	627
entropy regularized RL.	O	O	Review	627
<sep> GACA optimizes the policy via fitting a learnable prior distribution that using	O	O	Review	627
both high reward trajectory and zero reward trajectory to improve the sample efficiency.	O	O	Review	627
The experiments on sparse reward tasks such as WikiTableQuestions and WikiSQL	O	O	Review	627
demonstrate the effectiveness of the GACA, comparing with a set of advanced baselines.	O	O	Review	627
<sep> <sep> <sep> Detailed comments:	O	O	Review	627
<sep> Off-policy learning:	O	O	Review	627
The Environment dynamic is not considered.	O	O	Review	627
The trajectory	O	O	Review	627
reward is determined by the initial state, goal, and the sequence of actions taken thereafter.	O	O	Review	627
The off-policy learning can be applied since the distribution of	O	O	Review	627
initial state, and goal is not affected by the policy.	O	O	Review	627
This reduces to a	O	O	Review	627
weighted maximum likelihood problem.	O	O	Review	627
<sep> <sep> Resolving the sparse reward issue:	O	O	Review	627
In sparse reward tasks, many of trajectories have zero rewards, in order to utilize	O	O	Review	627
the zero reward trajectory (since in the weighted problem those samples have no	O	O	Review	627
contribution to the gradient).	O	O	Review	627
This work proposed to store the trajectories	B-Review	B-8	Review	627
into two replay buffers and samples from both of them separately.	I-Review	I-8	Review	627
<sep> Intuitively, it is not clear to me why minimizing mutual information between z and	I-Review	I-8	Review	627
reward would help the learning.	I-Review	I-8	Review	627
I am suspecting the reason is that mutual information brings non-zero gradient for zero reward trajectories (given zero-reward trajectories indeed helps the learning).	I-Review	I-8	Review	627
<sep> The authors also claimed that KL divergence performs worse than f-divergence due to the mode seeking issue.	B-Review	B-1	Review	627
Do the experiments in GACA w/o AG support this claim?	I-Review	I-1	Review	627
<sep> <sep> Ablation study:	O	O	Review	627
The authors claimed that using zero reward trajectory can help with sample efficiency.	O	O	Review	627
<sep> I wonder what the performance would be if we drop the zero reward trajectory buffer if we have a reasonable high frequency to reach the high trajectory reward sequence.	B-Review	B-2	Review	627
<sep> Is it necessary to incorporate the zero reward trajectory?	B-Review	B-3	Review	627
<sep> <sep> What is the exact formula of GACA w/o GP and GACA w/o AG?	B-Review	B-4	Review	627
<sep> <sep> The proposed method consists of three parts (GP, AG, and separate buffer. )	O	O	Review	627
<sep> Two variants (w/o GP, w/o AG) of GACA is conducted in the ablation study.	O	O	Review	627
<sep> How does the GACA perform if we drop the separate buffer?	B-Review	B-5	Review	627
What if we incorporate separate buffer for baselines.	I-Review	I-5	Review	627
Does GP/AG play an essential role in performance improvement,	I-Review	I-5	Review	627
comparing to a separate buffer?	I-Review	I-5	Review	627
<sep> <sep> <sep> Other questions:	O	O	Review	627
Since the sequence of actions is considered as a group, the performance	B-Review	B-6	Review	627
may highly depend on the size of action space and horizon.	I-Review	I-6	Review	627
<sep> What is the size of the horizon of the tested problems?	I-Review	I-6	Review	627
<sep> What is the value of WB and WC in each experiment?	I-Review	I-6	Review	627
<sep> <sep> <sep> Minor:	O	O	Review	627
There are many typos or grammar issues in this version.	B-Review	B-7	Review	627
e.g.,	I-Review	I-7	Review	627
L 3, Page 4, learn-able prior	I-Review	I-7	Review	627
Last paragraph, page 3, " as as a combination of expectations",	I-Review	I-7	Review	627
Page, 15 "is actually equals mutual"	I-Review	I-7	Review	627
Eq 23 -&gt; 24	I-Review	I-7	Review	627
Thank you for your time, detailed feedback, and a clear summary of our contribution.	O	O	Reply	627
<sep> We are happy to hear you found this work valuable.	O	O	Reply	627
<sep> We answer most of the said points below.	O	O	Reply	627
It would be very helpful to hear your thoughts on our responses so that we can make the appropriate modifications to the paper.	O	O	Reply	627
<sep> <sep> <sep> 1.	O	O	Reply	627
Is there an experiment demonstrate f-divergence performs better than KL-divergence?	O	O	Reply	627
<sep> GACA w/o AG is equivalent to replacing f-divergence with KL-divergence in GACA.	B-Reply	B-1	Reply	627
Table 1.	I-Reply	I-1	Reply	627
shows that GACA &gt; GACA w/o AG &gt; MAPO on both program synthesis benchmarks, this result demonstrates that f-divergence(adaptive gradient estimation) is better KL-divergence.	I-Reply	I-1	Reply	627
<sep> <sep> <sep> <sep> 2.	O	O	Reply	627
Does dropping out zero-reward trajectory buffer have an impact on the performance?	O	O	Reply	627
<sep> Intuitively, dropping out zero-reward trajectory buffer reduces the number of samples used to estimate gradient, thus it hurts the minimization of f-divergence and downgrades the performance.	B-Reply	B-2	Reply	627
Empirically, we found that dropping out zero-reward buffer downgrades the performance of GACA but still better than MAPO.	I-Reply	I-2	Reply	627
This result further validates the value of this work ‚Äî enable reusing off-policy samples by efficient credit assignment is important.	I-Reply	I-2	Reply	627
<sep> <sep> <sep> 3.	O	O	Reply	627
Does separate buffer help baselines?	O	O	Reply	627
<sep> Separate buffer doesn‚Äôt help baselines and is not necessary because mathematically baselines method can only utilize high-reward trajectories to compute gradient, as shown at the beginning of Section 4 and Appendix E.	B-Reply	B-5	Reply	627
We use separate buffer because GACA can use both high-reward and zero-reward trajectories, naturally, we can use stratified sampling to estimate unbiased and low variance gradient.	I-Reply	I-5	Reply	627
<sep> <sep> <sep> 4.	O	O	Reply	627
Typos	O	O	Reply	627
<sep> <sep> Thank you for pointing out typos, we have improved the presentation of the paper.	B-Reply	B-7	Reply	627
The updated version of the paper is available now.	I-Reply	I-7	Reply	627
Again, thank you for reading the paper.	I-Reply	I-7	Reply	627

> - A brief summary of the paper's contributions, in the context of prior work.	O	O	Review	76
<sep> <sep> The way we represent data -- the features we use -- has proven essential to a wide variety of tasks in machine learning.	O	O	Review	76
Often, the trivial features we naturally get from the data perform poorly.	O	O	Review	76
One approach is to hand-engineer features, having humans carefully construct features based on their understanding of the data and the task.	O	O	Review	76
Another approach, taken in deep learning, is to learn features as part of the optimization process of a multi-layer model.	O	O	Review	76
This paper proposes an alternative approach in which 'super-features' are generated by an iterative exploration process.	O	O	Review	76
<sep> <sep> As the reviewer understands it, this iterative process begins with random sigmoidial features.	O	O	Review	76
Features are evaluated on several subsets of the dataset and good features are selected.	O	O	Review	76
Principal component analysis is performed on the parameters of the good features in order to define a lower-dimensional space of good features.	O	O	Review	76
The next iteration proceeds on products of the principal components discovered in the previous step.	O	O	Review	76
In the limit, the discovered features form a space with nice algebraic properties.	O	O	Review	76
<sep> <sep> > - An assessment of novelty and quality.	O	O	Review	76
<sep> <sep> The reviewer is not an expert but to the best of their knowledge this approach is novel.	O	O	Review	76
<sep> <sep> The reviewer is concerned that this paper may be a bit rushed: it suffers from many grammatical errors, and some parts of the paper are hard to follow.	O	O	Review	76
The reviewer thinks that a bit of further revision would greatly benefit this paper.	O	O	Review	76
<sep> <sep> > - A list of pros and cons (reasons to accept/reject)	O	O	Review	76
<sep> Pros:	O	O	Review	76
* The paper introduces some interesting, novel ideas.	O	O	Review	76
In particular, attempting to do dimensionality reduction in parameter space seems like a really interesting strategy. (	O	O	Review	76
I'm concerned that PCA may not be a very good way to do this, but the idea is very interesting.)	B-Review	B-3	Review	76
<sep> <sep> Cons:	O	O	Review	76
* The paper does not do any experiments to test the efficacy of the proposed approach.	B-Review	B-1	Review	76
Given how radically different the proposed approach is from things that have been previously tried, it seems really difficult to have any significant confidence in it without experimental results. (	I-Review	I-1	Review	76
Not having experimental results for this would seem more appropriate if this were a workshop track submission.)	I-Review	I-1	Review	76
<sep> * The paper suffers from many grammatical issues.	B-Review	B-2	Review	76
These really need to be fixed in a final version of this paper.	I-Review	I-2	Review	76
<sep> * The paper is quite hard to follow at some points.	B-Review	B-3	Review	76
<sep> <sep> Testing this approach on a standard dataset would also provide an opportunity for the author to walk the reader through a concrete application of this approach, in addition to providing experimental validation of it.	O	O	Review	76
I would like to thank the reviewer for commenting the paper.	O	O	Reply	76
<sep> <sep> 1.	B-Reply	B-2	Reply	76
I will publish corrected version of the paper that will address grammatical and other issues asap.	I-Reply	I-2	Reply	76
<sep> 2.	B-Reply	B-1	Reply	76
I agree that experiments must be done, however, at this point it is not within scope of the paper and will be published somewhere else.	I-Reply	I-1	Reply	76
<sep> 3.	B-Reply	B-1	Reply	76
I agree that PCA is not the best way to reduce dimension of parameter space and some other method is worth to consider.	I-Reply	I-1	Reply	76
However, PCA may work for many cases when there is a well defined global maximum of likelihood in parameter space.	I-Reply	I-1	Reply	76

This paper presents an iterative way of defining increasingly complex feature spaces for prediction model selection.	O	O	Review	76
<sep> It is argued that in the limit, this sequence of features results in a feature algebra, meaning that products of features are linear combinations of features within the feature space.	O	O	Review	76
<sep> <sep> The mathematical ideas could be interested if explained in more clarity.	B-Review	B-1	Review	76
<sep> The nonlinear super features look like an interesting way of reasoning of feature compositions, however,	B-Review	B-2	Review	76
<sep> * I am not sure about the usefulness of the construction.	I-Review	I-2	Review	76
<sep> <sep> * Version 1 of the paper is quite unpolished.	B-Review	B-3	Review	76
<sep> <sep> MINOR:	I-Review	I-3	Review	76
<sep> In eq. (4) `maxarg' should be `argmax'.	I-Review	I-3	Review	76
<sep> In eq. (9) use `langle' and `	I-Review	I-3	Review	76
angle' instead of `<' and `>'.	I-Review	I-3	Review	76
<sep> Eq. (6) seems not to be used in Section 3.	I-Review	I-3	Review	76
I would like to thank the reviewer for commenting the paper.	O	O	Reply	76
My answers are given in same order as reviewers notes.	O	O	Reply	76
<sep> <sep> 1.	O	O	Reply	76
I believe the method for constructing features that form an algebra could be useful for finding computable efficient representations for a given data, especially for images and other data that have natural symmetries.	B-Reply	B-2	Reply	76
<sep> <sep> 2.	B-Reply	B-3	Reply	76
I will publish corrected version of the paper that will address grammatical and other issues asap.	I-Reply	I-3	Reply	76

The idea presented in this paper consists in iteratively building new features	O	O	Review	76
from products of so-called 'super features', obtained from a PCA in parameter	O	O	Review	76
space of multiple models trained on a subset of the data.	O	O	Review	76
The theoretical	O	O	Review	76
analysis is done with logistic regression, and no experiments are performed.	O	O	Review	76
<sep> <sep> In its current form, this paper is definitely not ready for publication.	B-Review	B-1	Review	76
The	I-Review	I-1	Review	76
fact that there is no experiment is already a pretty big downside, and the	I-Review	I-1	Review	76
theory does not seem complete enough to me to justify it.	I-Review	I-1	Review	76
In particular:	O	O	Review	76
- There is no proof or even intuition for the convergence of the procedure.	B-Review	B-2	Review	76
To	I-Review	I-2	Review	76
be fair, there is no claim that it will converge either, but what is the	I-Review	I-2	Review	76
point of Section 5 if this is not the case?	I-Review	I-2	Review	76
<sep> - The abstract mentions a guarantee of increasing likelihood which is not shown	B-Review	B-3	Review	76
in the paper.	I-Review	I-3	Review	76
<sep> - There is no analysis of the complexity of the algorithm (it seems costly,	B-Review	B-4	Review	76
especially since each iteration involves sampling multiple datasets).	I-Review	I-4	Review	76
<sep> - There is no discussion of extensions beyond logistic regression.	B-Review	B-5	Review	76
<sep> - There is no justification for using PCA in parameter space (which works best	B-Review	B-6	Review	76
with Gaussian-like unimodal distributions, but may fail in other situations:	I-Review	I-6	Review	76
how can we tell it makes sense for a specific application / model?)	I-Review	I-6	Review	76
<sep> <sep> That being said, this is an intriguing idea, and I am hoping the author will be able to investigate it more thoroughly so as to be able to present it in a more	O	O	Review	76
fleshed out paper in the future.	O	O	Review	76
<sep> <sep> There are several points that were unclear to me and may be worth mentioning in	O	O	Review	76
addition to the above high level comments:	O	O	Review	76
- The equation below eq.1 does not seem to be used anywhere.	B-Review	B-7	Review	76
<sep> - 'Values of regularization parameters must be found by maximizing Bayesian	B-Review	B-13	Review	76
integral in Equation 1.'	I-Review	I-13	Review	76
=> this integral is the likelihood -- optimizing	I-Review	I-13	Review	76
regularization parameters to maximize the likelihood seems wrong to me.	I-Review	I-13	Review	76
<sep> - '[eq.1] is estimated by maximum likelihood approximation': I do not see how	B-Review	B-8	Review	76
MLA is a good approximation here.	I-Review	I-8	Review	76
<sep> - eq.5 seems arbitrary to me, especially since the datasets are of different	B-Review	B-9	Review	76
sizes,  so each L_w_s involves a different number of terms.	I-Review	I-9	Review	76
<sep> - It is not mentioned exactly how the 'sample data' step works (for instance in	B-Review	B-10	Review	76
bootstrap one typically samples t_max points with replacement, but it does	I-Review	I-10	Review	76
not seem to be the case here).	I-Review	I-10	Review	76
<sep> - I do not understand how G_alpha,beta can be non-zero in eq.16, and still	B-Review	B-11	Review	76
lead to a linear combination.	I-Review	I-11	Review	76
<sep> - Not clear what are func and F in eq.19.	B-Review	B-12	Review	76
I would like to thank the reviewer for the comments.	O	O	Reply	76
My answers are given in the same order as reviewer‚Äôs items.	O	O	Reply	76
<sep> <sep> 1.	B-Reply	B-1	Reply	76
I agree that not presenting experiments in the paper is a big downside.	I-Reply	I-1	Reply	76
I will present experiments somewhere else.	I-Reply	I-1	Reply	76
<sep> 2.	O	O	Reply	76
I agree that convergence requires a special investigation.	B-Reply	B-2	Reply	76
However, for a limited training data set and with constraints on number of parameters (PCA) I believe it it is reasonable to expect that the iterative process described in paper will converge to polynomials of some finite degree.	I-Reply	I-2	Reply	76
<sep> This argument seems to be sufficient for the purpose of the paper.	I-Reply	I-2	Reply	76
The formal proof will be published somewhere else.	I-Reply	I-2	Reply	76
<sep> 3.	O	O	Reply	76
Because each iteration consists of solving a series of convex problems that contain all previous solutions, when parameters for products of features are zero, new solutions must have higher likelihoods or be the same as already found solutions (excluding some degenerate cases when multiple solutions have same likelihood).	B-Reply	B-3	Reply	76
<sep> 4.	O	O	Reply	76
Cost of the algorithms is contained because	B-Reply	B-4	Reply	76
a. for each iteration most of samples of solutions could be obtained from small subsets of training data - number of reads of training data is expected to have a highest cost;	I-Reply	I-4	Reply	76
b. number of iterations is limited because after N iterations features become 2^N degree polynomials, which is reasonable to be limited - please see the convergence argument above.	I-Reply	I-4	Reply	76
<sep> 5.	O	O	Reply	76
The ideas presented in the paper are not based on any specifics of logistic regression.	B-Reply	B-5	Reply	76
The only important property is that models are presented by probabilities that are predefined functions of scalar products of parameters and features.	I-Reply	I-5	Reply	76
<sep> The variety of model that has this property is much bigger set than a logistic regression case.	I-Reply	I-5	Reply	76
<sep> 6.	O	O	Reply	76
PCA is selected as a simple and reliable method of dimensionality reduction.	B-Reply	B-6	Reply	76
Other methods could be used as well.	I-Reply	I-6	Reply	76
<sep> 7.	O	O	Reply	76
Regularization parameters _could_ be found by maximizing Bayes integral in Eq.1, because it is not just a likelihood - it is a probability of data for a given model and regularization parameters,  that contains a _normalization_ _factor_ from prior probability of parameters (that is important!).	B-Reply	B-7	Reply	76
That normalization factor cannot be estimated by MLA-type method and must be computed exactly or with high enough accuracy for any possible values of regularization parameters.	I-Reply	I-7	Reply	76
<sep> Then, maximizing probability of data by regularization parameters will produce regularization solutions that are equivalent to regularization parameters found by maximizing likelihood of a validation set.	B-Reply	B-13	Reply	76
<sep> 8.	O	O	Reply	76
The iterative procedure in paper does not depend on finding best parameter-solutions.	B-Reply	B-8	Reply	76
It depends on obtaining samples in parameter space with high likelihood.	I-Reply	I-8	Reply	76
MLA is a reasonable method to get these samples.	I-Reply	I-8	Reply	76
There is no need for iterative process to have very good estimates for Bayesian integrals in Eq.1.	I-Reply	I-8	Reply	76
<sep> 9.	B-Reply	B-9	Reply	76
Eq.5 is an approximation.	I-Reply	I-9	Reply	76
It is selected due its simplicity for practical computations.	I-Reply	I-9	Reply	76
It may need a revision.	I-Reply	I-9	Reply	76
<sep> 10.	O	O	Reply	76
Sampling with replacement is a reasonable approach.	B-Reply	B-10	Reply	76
The whole idea of iterative approach in the paper is to find a set of features that minimally dependent on selection of training set and representative for any sampled set from available training data.	I-Reply	I-10	Reply	76
<sep> 11.	O	O	Reply	76
I will clarify the equation for the algebra in a revised version of the paper.	B-Reply	B-11	Reply	76
<sep> That will look like the following:	I-Reply	I-11	Reply	76
<sep> Iterative process will converge when set of super-features: F_a(x), a=1..NumFeatures, with bias super-feature F_0(x) will satisfy algebra equations:	I-Reply	I-11	Reply	76
<sep> F_a(x) F_b(x) = sum_d C_a,b,d F_d(x) + F_0(x)G_a,b , where C_a,b,d and G_a,b are constants in regard to x.	I-Reply	I-11	Reply	76
<sep> 12.	B-Reply	B-12	Reply	76
Eq.16 shows a property of feature algebra space: any function on feature space that could be represented by power series due to algebra is a linear function of features.	I-Reply	I-12	Reply	76

This paper proposes an initialization scheme for the recently introduced linear memory network (LMN) (Bacciu et al 2019) and the authors claim that this initialization scheme can help improving the model performance of long-term sequential learning problems.	O	O	Review	20276
<sep> <sep> My concerns lie with the novelty of the proposed model and the insufficiency of the experiments.	B-Review	B-1	Review	20276
First, the LMN seems to be a simpler version of LSTM and it has no significant advantages compared with other recurrent structures introduced in the past several years.	I-Review	I-1	Review	20276
<sep> Second, the autoencoder-based init scheme (Pasa&amp;Sperduti, 2014) is not new while the only technical contribution of this paper is a minor change of this scheme so that it works for the LMN.	B-Review	B-2	Review	20276
In my opinion, combining these two (LMN and init scheme) can hardly be considered as a solid novelty contribution.	I-Review	I-2	Review	20276
<sep> For the experiment part, the first two tasks are a bit toyish in 2019 and I have not seen any significant improvement gained from the proposed model.	B-Review	B-3	Review	20276
Even for the TIMIT dataset, the results are a bit far from state-of-the-art which makes the paper's claim less convincing.	B-Review	B-4	Review	20276
<sep> <sep> Overall I think the novelty contribution is marginal and I suggest the authors to test their models on larger-scale real problems.	B-Review	B-2	Review	20276
<sep> <sep> The writing is clear and easy to follow.	O	O	Review	20276
You can, of course, obtain the LMN from the LSTM equations by eliminating all the gates and making the CEC update through a generic linear function (in place of the sum).	B-Reply	B-1	Reply	20276
But these are not minor changes and radically change the inductive bias of the models.	I-Reply	I-1	Reply	20276
The LSTM uses the forget gate to reset the cell state activations, while the LMN uses a more efficient encoding and does not forget past activations.	I-Reply	I-1	Reply	20276
The result of this choice is that the LMN is better on tasks that require the memorization of long sequences (e.g. copy task, MNIST).	I-Reply	I-1	Reply	20276
On different tasks, like language modeling, other architectures (like the LSTM) are probably a better choice since the problem does not require explicit memorization.	I-Reply	I-1	Reply	20276
<sep> <sep> <sep> You are correct that the initialization scheme come from a previous contribution.	B-Reply	B-2	Reply	20276
However, what we show here is that such initialization is more coherent with the assumption and nature of the LMN, rather than for a RNN with non-linear memory.	I-Reply	I-2	Reply	20276
We also show how that the autoencoder initialization can help in some tasks (improving both the results of orthogonal and gated models) and hinder the performance in others.	I-Reply	I-2	Reply	20276
These results show that the proposed approach is complementary to LSTMs and other gated architectures, and that the two approaches can be used to solve different tasks of different nature (in terms of long and short-term memorization abilities).	I-Reply	I-2	Reply	20276
We are not aware of other researches investigating the differences between encoding/orthogonal-based approaches and gated models and the capabilities of the different memorization schemes (which, to the extent of our understanding, appears a relevant topic for ICLR).	I-Reply	I-2	Reply	20276
<sep> <sep> &gt;&gt;&gt; For the experiment part, the first two tasks are a bit toyish in 2019	O	O	Reply	20276
We agree that some of the benchmarks are simple tasks.	B-Reply	B-3	Reply	20276
However, the chosen datasets are used to compare against classic benchmarks in the literature of orthogonal RNNs.	I-Reply	I-3	Reply	20276
Most of the papers in the literature use pixel-MNIST.	I-Reply	I-3	Reply	20276
<sep> [1] copy task, pixel-MNIST, PTB	I-Reply	I-3	Reply	20276
[2] copy task, TIMIT, pixel-MNIST	I-Reply	I-3	Reply	20276
[3] pixel-MNIST, pixel-CIFAR10	I-Reply	I-3	Reply	20276
[4] copy, MNIST, TIMIT, PTB, MIDI	I-Reply	I-3	Reply	20276
<sep> If the reviewer is aware of different benchmarks allowing to compare with the related literature we will gladly consider it.	I-Reply	I-3	Reply	20276
<sep> <sep> <sep> &gt;&gt;&gt; Even for the TIMIT dataset, the results are a bit far from state-of-the-art which makes the paper's claim less convincing.	O	O	Reply	20276
<sep> Thank you for noticing this.	O	O	Reply	20276
The results may seem poor because we do not use bidirectional models.	B-Reply	B-4	Reply	20276
This is done to compare against [4]. We will update the paper to highlight this fundamental architectural difference with the literature.	I-Reply	I-4	Reply	20276
<sep> [1]  Eugene Vorontsov, Chiheb Trabelsi, Samuel Kadoury, and Chris Pal.	O	O	Reply	20276
On orthogonality and learning	O	O	Reply	20276
recurrent networks with long term dependencies.	O	O	Reply	20276
In ICML, pp.3570‚Äì3578, 1 2017.	O	O	Reply	20276
URL <a href="http://arxiv.org/abs/1702.00071."	O	O	Reply	20276
target="_blank" rel="nofollow">http://arxiv.org/abs/1702.00071.</a>	O	O	Reply	20276
[2] Scott Wisdom, Thomas Powers, John R. Hershey, Jonathan Le Roux, and Les Atlas.	O	O	Reply	20276
Full-Capacity	O	O	Reply	20276
Unitary Recurrent Neural Networks.	O	O	Reply	20276
In NIPS, pp.4880‚Äì4888, 10 2016.	O	O	Reply	20276
URL <a href="http://arxiv.org/abs/1611.00035."	O	O	Reply	20276
target="_blank" rel="nofollow">http://arxiv.org/abs/1611.00035.</a>	O	O	Reply	20276
[3] Bo Chang, Minmin Chen, Eldad Haber, and Ed H. Chi.	O	O	Reply	20276
AntisymmetricRNN: A Dynamical System	O	O	Reply	20276
View on Recurrent Neural Networks.	O	O	Reply	20276
2 2019.	O	O	Reply	20276
URL <a href="http://arxiv.org/abs/1902.09689" target="_blank" rel="nofollow">http://arxiv.org/abs/1902.09689</a>	O	O	Reply	20276
[4] Cijo Jose, Moustpaha Cisse, and Francois Fleuret.	O	O	Reply	20276
Kronecker Recurrent Units.	O	O	Reply	20276
In ICML, pp.<sep> 2385‚Äì2394, 5 2018.	O	O	Reply	20276
URL <a href="http://arxiv.org/abs/1705.10142."	O	O	Reply	20276
target="_blank" rel="nofollow">http://arxiv.org/abs/1705.10142.</a>	O	O	Reply	20276

Summary:	O	O	Review	20276
This paper proposes a new initialization method for recurrent neural networks.	O	O	Review	20276
They first obtain the weight from a linear optimal autoencoder.	O	O	Review	20276
And then they use the weight to initialize the Lieanr Memory Networks(LMN).	O	O	Review	20276
Basically, this paper is a combination of [1] and [2].	O	O	Review	20276
<sep> Strength:	O	O	Review	20276
The method of initializing LMN using a linear RNN is natural and simple. (	O	O	Review	20276
section 3.2)	O	O	Review	20276
The proposed initialization outperforms the baselines on the MNIST dataset.	O	O	Review	20276
<sep> <sep> Weakness:	O	O	Review	20276
What do you mean by the "optimal autoencoder"?	B-Review	B-1	Review	20276
<sep> The performance on TIMIT is worse than the baseline methods.	B-Review	B-2	Review	20276
<sep> The scale of the experiments is too small.	B-Review	B-2	Review	20276
Do you have any experiment results on any large dataset?	I-Review	I-2	Review	20276
e.g. Penn Treebank.	I-Review	I-2	Review	20276
<sep> <sep> Reference:	O	O	Review	20276
[1] Pre-training of Recurrent Neural Networks via Linear Autoencoders	O	O	Review	20276
[2] Linear Memory Networks	O	O	Review	20276
&gt;&gt;&gt; Weakness: What do you mean by the "optimal autoencoder"?	O	O	Reply	20276
<sep> We use a linear autoencoder because we can find the optimal solution (in the sense that it optimizes the mean squared error) with a closed-form solution.	B-Reply	B-1	Reply	20276
We approximate this solution by taking a fixed number of components.	I-Reply	I-1	Reply	20276
<sep> <sep> <sep> &gt;&gt;&gt; The performance on TIMIT is worse than the baseline methods.	O	O	Reply	20276
The scale of the experiments is too small.	O	O	Reply	20276
Do you have any experiment results on any large dataset?	O	O	Reply	20276
e.g. Penn Treebank.	O	O	Reply	20276
<sep> <sep> We did not perform experiments on PTB, but our expectation is that models based on autoencoding are not a good choice for language modeling tasks.	B-Reply	B-2	Reply	20276
This can be seen by looking at the performance of orthogonal models on language modeling tasks [1,2], which are always inferior to gated models.	I-Reply	I-2	Reply	20276
Our guess is that language modeling does not require the memorization of long sequences, and it is probably sufficient to remember a small amount of information.	I-Reply	I-2	Reply	20276
<sep> [1]  Eugene Vorontsov, Chiheb Trabelsi, Samuel Kadoury, and Chris Pal.	O	O	Reply	20276
On orthogonality and learning	O	O	Reply	20276
recurrent networks with long term dependencies.	O	O	Reply	20276
In ICML, pp.3570‚Äì3578, 1 2017.	O	O	Reply	20276
URL	O	O	Reply	20276
[2] Cijo Jose, Moustpaha Cisse, and Francois Fleuret.	O	O	Reply	20276
Kronecker Recurrent Units.	O	O	Reply	20276
In ICML, pp.<sep> 2385‚Äì2394, 5 2018.	O	O	Reply	20276
URL <a href="http://arxiv.org/abs/1705.10142."	O	O	Reply	20276
target="_blank" rel="nofollow">http://arxiv.org/abs/1705.10142.</a>	O	O	Reply	20276

Summary:	O	O	Review	20276
<sep> The paper proposes an autoencoder-based initialization for RNNs with linear memory.	O	O	Review	20276
The proposed initialization is aimed at helping to maintain longer-term memory and instability during training such as  exploding gradients (due to linearity).	O	O	Review	20276
<sep> <sep> Pros:	O	O	Review	20276
<sep> 1.	O	O	Review	20276
The paper is well written, the motivation and methods are clearly described.	O	O	Review	20276
<sep> <sep> Cons.	O	O	Review	20276
<sep> <sep> 1.	B-Review	B-1	Review	20276
The authors claimed the proposed method could help with exploding gradient  in training the linear memories.	I-Review	I-1	Review	20276
It would be helpful to include some experiments indicating that this was the case (for the baseline) and that this method does indeed help with this problem.	I-Review	I-1	Review	20276
<sep> <sep> 2.	O	O	Review	20276
The experiments on the copy task only showed results for length upto 500, which almost all baseline models are able to solve.	B-Review	B-2	Review	20276
I am not too sure how the proposed initialization helps in this case.	I-Review	I-2	Review	20276
<sep> <sep> 3.	O	O	Review	20276
TIMNIT is a relatively small speech recognition dataset.	B-Review	B-3	Review	20276
The task/ dataset does not require long-term memorization.	I-Review	I-3	Review	20276
It is nice to see that the initialization helps in this case.	I-Review	I-3	Review	20276
However, it is still a little how this experiment corresponds to the messsage that the authors are attempting to deliver at the end of the introduction.	I-Review	I-3	Review	20276
<sep> <sep> 4.	B-Review	B-1	Review	20276
In general, it seems that the experiments could be more carefully designed to reflect the contributions of the proposed method.	I-Review	I-1	Review	20276
Some suggestions for future edits are, more analysis on gradients, maybe more experiments on the stability of training such as gradients could help.	I-Review	I-1	Review	20276
<sep> <sep> Minor:	O	O	Review	20276
<sep> 1.	B-Review	B-5	Review	20276
There are some confusions, on P2 "we can construct a simple linear recurrent model which uses the autoencoder to encode the input sequences within a single vector", I think the authors meant encode the input sequences into a sequence of vectors?	I-Review	I-5	Review	20276
Equation 1 and 2 suggest that there is a vector m^t per timestep (as oppose to having 1 for the entire sequence).	I-Review	I-5	Review	20276
<sep> <sep> 2.	B-Review	B-4	Review	20276
Although the copy task was used in ((Arjovsky et al 2015), I believe the original task was proposed in the following paper and hence this citation should properly be the correct one to cite here,	I-Review	I-4	Review	20276
<sep> Hochreiter, Sepp and Schmidhuber, J√ºrgen.	I-Review	I-4	Review	20276
Long short-term memory.	I-Review	I-4	Review	20276
Neural computation, 9(8):	I-Review	I-4	Review	20276
1735‚Äì1780, 1997.	I-Review	I-4	Review	20276
<sep> <sep> <sep> &gt;&gt;&gt; 1.	O	O	Reply	20276
The authors claimed the proposed method could help with exploding gradient  in training the linear memories.	O	O	Reply	20276
It would be helpful to include some experiments indicating that this was the case (for the baseline) and that this method does indeed help with this problem.	O	O	Reply	20276
<sep> &gt;&gt;&gt; 4.	O	O	Reply	20276
In general, it seems that the experiments could be more carefully designed to reflect the contributions of the proposed method.	O	O	Reply	20276
Some suggestions for future edits are, more analysis on gradients, maybe more experiments on the stability of training such as gradients could help.	O	O	Reply	20276
<sep> <sep> We agree that this are interesting experiments.	B-Reply	B-1	Reply	20276
We believe that it is especially useful to study the effect on the gradient and training stability when combined with the truncated backpropagation (e.g. as done in the LSTM paper).	I-Reply	I-1	Reply	20276
Unfortunately, we still do not have the final results on these experiments.	I-Reply	I-1	Reply	20276
<sep> <sep> <sep> &gt;&gt;&gt; 2.	O	O	Reply	20276
The experiments on the copy task only showed results for length upto 500, which almost all baseline models are able to solve.	O	O	Reply	20276
I am not too sure how the proposed initialization helps in this case.	O	O	Reply	20276
<sep> We used the experiments on the copy tasks to show that the LMN architecture learns the copy task with a saturating nonlinearity (tanh).	B-Reply	B-2	Reply	20276
As far as we know, this is the only architecture that can do it, while most of the other models use variations of ReLUs.	I-Reply	I-2	Reply	20276
<sep> <sep> <sep> &gt;&gt;&gt; 1.	O	O	Reply	20276
There are some confusions, on P2 "we can construct a simple linear recurrent model which uses the autoencoder to encode the input sequences within a single vector", I think the authors meant encode the input sequences into a sequence of vectors?	O	O	Reply	20276
Equation 1 and 2 suggest that there is a vector m^t per timestep (as oppose to having 1 for the entire sequence).	O	O	Reply	20276
<sep> The state vector of the LAES m^t can be used to reconstruct the entire input sequence x^1, ‚Ä¶ x^t.	B-Reply	B-5	Reply	20276
Therefore, each vector m^t encodes the entire subsequence x^1, ‚Ä¶, x^t.	I-Reply	I-5	Reply	20276
We will update the paper to make this point clearer.	I-Reply	I-5	Reply	20276
<sep> <sep> <sep> &gt;&gt;&gt; 2.	O	O	Reply	20276
Although the copy task was used in ((Arjovsky et al 2015), I believe the original task was proposed in the following paper and hence this citation should properly be the correct one to cite here	O	O	Reply	20276
Thank you for noticing this, we will add the reference.	B-Reply	B-4	Reply	20276

The author proposed a simple but yet effective technique in order to regularized neural networks.	O	O	Review	272
The results obtained are quite good and the technique shows to be effective when it it applied even on state of the art topologies, that is welcome because some regularization techniques used to be applied in easy task or on a initial configuration which results are still far from the best known results.	O	O	Review	272
Thank you again!	O	O	Reply	272

The paper proposes a new regulariser for CNNs that penalises positive correlations between feature weights, but does not affect negative correlations.	O	O	Review	272
An alternative version which penalises all correlations regardless of sign is also considered.	O	O	Review	272
The paper refers to these as "local" and "global" respectively, which I find a bit confusing as these are very general terms that can mean a plethora of things.	B-Review	B-1	Review	272
<sep> <sep> The experimental validation is quite rigorous.	O	O	Review	272
Several experiments are conducted on benchmark datasets (MNIST, CIFAR-10, CIFAR-100, SVHN) and improvements are demonstrated in most cases.	O	O	Review	272
While these improvements may seem modest, the baselines are already very competitive as the authors pointed out.	O	O	Review	272
In some cases it does raise some questions about statistical significance though.	O	O	Review	272
More results with the global regulariser (i.e. not just on MNIST) would have been interesting, as the main novelty in the paper seems to be leaving the negative correlations alone, so it would be interesting to see exactly how much of a difference this makes.	B-Review	B-2	Review	272
<sep> <sep> One of my main concerns is ambiguity stemming from the fact that the paper sometimes discusses activations and sometimes filter weights, but refers to both as "features".	B-Review	B-3	Review	272
However, the authors have already said they will address this.	I-Review	I-3	Review	272
<sep> <sep> The paper somewhat ignores interactions with the choice of nonlinearity, which seems like it could be very important; especially because the goal is to obtain feature activations that are uncorrelated, and this is done only by applying a penalty to the weights (i.e. in a data-agnostic way and also ignoring any nonlinearity).	B-Review	B-4	Review	272
I believe the authors already mentioned in their responses to reviewer questions that this would be addressed, but I think this important and it definitely needs to be discussed.	I-Review	I-4	Review	272
<sep> <sep> In response to the authors' answer to my question about the role of biases: as they point out, it is perfectly possible to combine their proposed technique with the "multi-bias" approach, but this was not really my point.	B-Review	B-5	Review	272
Rather, the latter is an example that challenges the idea that features should not be positively correlated / redundant, which seems to be the assumption that this work is built upon.	I-Review	I-5	Review	272
My current intuition is that it's okay to have correlated features, as long as you're not wasting model capacity on them.	I-Review	I-5	Review	272
This is the case for "multi-bias", seeing as the weights are shared across sets of correlated features.	I-Review	I-5	Review	272
<sep> <sep> The dichotomy between regularisation methods that reduce capacity and those that don't which is described in the introduction seems a bit arbitrary to me, especially considering that weight decay is counted among the former and the proposed method is counted among the latter.	B-Review	B-6	Review	272
I think this very much depends on ones definition of model capacity (clearly weight decay does not actually reduce the number of parameters in a model).	I-Review	I-6	Review	272
<sep> <sep> Overall, the work is perhaps a bit incremental, but it seems to be well-executed.	B-Review	B-7	Review	272
The results are convincing, even if they aren't particularly ground-breaking.	I-Review	I-7	Review	272
> The paper refers to these as "local" and "global" respectively, which I find a bit confusing as these are very general terms that can mean a plethora of things.	O	O	Reply	272
<sep> We found the words ‚Äúlocal‚Äù and ‚Äúglobal‚Äù useful to avoid repeating long sentences like ‚Äúregularizing positive and negative correlations‚Äù, we also explain the origin of this notation on page five: in previous regularizations all feature weights influence each other (‚Äúglobal‚Äù), while OrthoReg only regularizes the nearest feature weights in angle (‚Äúlocal‚Äù).	B-Reply	B-1	Reply	272
<sep> <sep> <sep> > More results with the global regulariser (i.e. not just on MNIST) would have been interesting, as the main novelty in the paper seems to be leaving the negative correlations alone, so it would be interesting to see exactly how much of a difference this makes.	O	O	Reply	272
<sep> <sep> We have added the suggested comparison in Figure 6 for Wide Resnet on Cifar10 and Cifar100.	B-Reply	B-2	Reply	272
As it can be seen, OrthoReg has a lower error bound compared with regularizing the negative correlations (0.2% on Cifar10, and 0.7% on Cifar100).	I-Reply	I-2	Reply	272
<sep> <sep> <sep> > One of my main concerns is ambiguity stemming from the fact that the paper sometimes discusses activations and sometimes filter weights, but refers to both as "features".	O	O	Reply	272
However, the authors have already said they will address this.	O	O	Reply	272
<sep> <sep> We have fixed this issue accordingly replacing ‚Äúfeatures‚Äù with ‚Äúfeature weights‚Äù or ‚Äúfeature activations.	B-Reply	B-3	Reply	272
<sep> <sep> > The paper somewhat ignores interactions with the choice of nonlinearity, which seems like it could be very important; especially because the goal is to obtain feature activations that are uncorrelated, and this is done only by applying a penalty to the weights (i.e. in a data-agnostic way and also ignoring any nonlinearity).	O	O	Reply	272
I believe the authors already mentioned in their responses to reviewer questions that this would be addressed, but I think this important and it definitely needs to be discussed.	O	O	Reply	272
<sep> <sep> Although we successfully applied the proposed regularizer on ReLU networks, we agree with the reviewer that a thorough study on the effects of the non-linearities should be done.	B-Reply	B-4	Reply	272
We have modified the discussion part of the paper so as to reflect this important concern.	I-Reply	I-4	Reply	272
<sep> <sep> <sep> > In response to the authors' answer to my question about the role of biases: as they point out, it is perfectly possible to combine their proposed technique with the "multi-bias" approach, but this was not really my point.	O	O	Reply	272
Rather, the latter is an example that challenges the idea that features should not be positively correlated / redundant, which seems to be the assumption that this work is built upon.	O	O	Reply	272
My current intuition is that it's okay to have correlated features, as long as you're not wasting model capacity on them.	O	O	Reply	272
This is the case for "multi-bias", seeing as the weights are shared across sets of correlated features.	O	O	Reply	272
<sep> <sep> We now better understand the point, but note that there is no guarantee that networks with a high number of filter weights, and thus with a lot of redundant filters, will show a good behaviour in terms of generalization and overfitting.	B-Reply	B-5	Reply	272
We have added a comment on this fact in section 2.	I-Reply	I-5	Reply	272
<sep> <sep> > The dichotomy between regularisation methods that reduce capacity and those that don't which is described in the introduction seems a bit arbitrary to me, especially considering that weight decay is counted among the former and the proposed method is counted among the latter.	O	O	Reply	272
I think this very much depends on ones definition of model capacity (clearly weight decay does not actually reduce the number of parameters in a model).	O	O	Reply	272
<sep> <sep> As we explained in the paper, weight decay is shown to reduce the ‚Äúeffective number of parameters‚Äù of neural networks [1]. Taking this into account we think it is sensible to make the distinction between those regularizations which drop weights, activations‚Ä¶ (in essence, regularizations which reduce the capacity of the network), from those which do use all the capacity as effectively as possible.	B-Reply	B-6	Reply	272
<sep> <sep> However, we agree this distinction may not be as clear to a reader as we claimed in the paper, thus, we change the sentence ‚ÄúThere are two clearly defined regularization strategies in the literature‚Äù for ‚ÄúFrom the literature, two different regularization strategies can be defined‚Äù.	I-Reply	I-6	Reply	272
<sep> <sep> [1] Moody, J. E. (1991, December).	O	O	Reply	272
The effective number of parameters: An analysis of generalization and regularization in nonlinear learning systems.	O	O	Reply	272
In NIPS (Vol.847-854).	O	O	Reply	272
4, pp.	O	O	Reply	272
<sep> <sep> <sep> > Overall, the work is perhaps a bit incremental, but it seems to be well-executed.	O	O	Reply	272
The results are convincing, even if they aren't particularly ground-breaking.	O	O	Reply	272
<sep> <sep> Thanks.	B-Reply	B-7	Reply	272
We hope the new consistent results on the new version of wide residual networks strengthen our claims and the contribution.	I-Reply	I-7	Reply	272

Encouraging orthogonality in weight features has been reported useful for deep networks in many previous works.	O	O	Review	272
The authors present a explicit regularization cost to achieve de-correlation among weight features in a layer and encourage orthogonality.	O	O	Review	272
Further, they also show why and how negative correlations can and should be avoided for better de-correlation.	O	O	Review	272
<sep> <sep> Orthogonal weight features achieve better generalization in case of large number of trainable parameters and less training data, which usually results in over-fitting.	O	O	Review	272
As also mentioned by the authors biases help in de-correlation of feature responses even in the presence of correlated features (weights).	O	O	Review	272
Regularization techniques like OrthoReg can be more helpful in training deeper and leaner networks, where the representational capacity of each layer is low, and also generalize better.	O	O	Review	272
<sep> <sep> Although the improvement in performances is not significant the direction of research and the observations made are promising.	B-Review	B-1	Review	272
> Although the improvement in performances is not significant the direction of research and the observations made are promising.	O	O	Reply	272
<sep> <sep> On the new updated version, we show better performance improvements with the new wide ResNet results.	B-Reply	B-1	Reply	272
We hope these new results strengthen the significance of our work.	I-Reply	I-1	Reply	272

The authors proposed a template-based interpretable representation that works based on the earth mover's distance of each class to a number of "environments", which could be taken as union of a few random classes.	O	O	Review	272
To achieve this, they train several critics based on Fisher GAN.	O	O	Review	272
The method is evaluated based on classification and retrieval tasks.	O	O	Review	272
<sep> The representation, by construction, is aimed towards interpretation and is specially useful in multi-class classification tasks.	O	O	Review	272
<sep> Here are my concerns:	O	O	Review	272
- Since the environments are taken randomly in the experiments, it is not investigated how sensitive the method is with respect to the choices of environments.	B-Review	B-1	Review	272
Also, does it make any sense to design environments to include related (and not random) classes?	I-Review	I-1	Review	272
<sep> - It seems necessary to include some experiments to assess sensitivity of the interpretation with regard to the small perturbations that are not changing the class label.	B-Review	B-2	Review	272
Thank you for your constructive review.	O	O	Reply	272
Below we address your concerns.	O	O	Reply	272
<sep> <sep> ‚Äú- Since the environments are taken randomly in the experiments, it is not investigated how sensitive the method is with respect to the choices of environments. ‚	O	O	Reply	272
Äù	O	O	Reply	272
We partially addressed this concern in the results of table 1 (page 8) that shows the average F1 scores for the classification task over several runs, where each run has a different randomly selected choice of environments.	B-Reply	B-1	Reply	272
From this table it is clear that the standard deviation in F1 scores is low and in line with the standard deviations of the baselines.	I-Reply	I-1	Reply	272
This suggests that for sufficiently large and (the parameters that determine the amount of environments and the maximum amount of attributes per environment) the method is not sensitive with respect to the choices of environments.	I-Reply	I-1	Reply	272
We also added this sensitivity for different choices of and to the appendix of the revised version (see appendix A1, tables A1 and A2), where it becomes clear that even for small values, the sensitivity is low.	I-Reply	I-1	Reply	272
<sep> <sep> ‚ÄúAlso, does it make any sense to design environments to include related (and not random) classes?‚Äù	O	O	Reply	272
The rationale for not designing (handmade) environments is that they require knowledge about what would lead to distinguishing features.	B-Reply	B-1	Reply	272
Note that the randomly selected features will lead to many environments that are related to any class, thus ensuring a good choice over any set of features.	I-Reply	I-1	Reply	272
The idea is inspired by the Random Features approximation as developed in the work of [1] and [2], we have clarified this in the revision (‚ÄòRecent work‚Äô in section 2).	I-Reply	I-1	Reply	272
<sep> <sep> ‚Äú- It seems necessary to include some experiments to assess sensitivity of the interpretation with regard to the small perturbations that are not changing the class label.	O	O	Reply	272
‚Äù	O	O	Reply	272
Our interpretation of your question is as follows, please correct us if necessary: ‚ÄúWhat amount of perturbation is needed before the interpretation of the class label of the representation changes?‚Äù.	B-Reply	B-2	Reply	272
As part of the retrieval method we evaluated the size of the factor (the factor that determines how much the representation is modified for the retrieval experiment in section 4.3) and its influence on the change in class.	I-Reply	I-2	Reply	272
This gives an estimate of the sensitivity as it shows that small perturbations to representations don‚Äôt easily modify class membership.	I-Reply	I-2	Reply	272
We have added the results in section 4.3.	I-Reply	I-2	Reply	272
<sep> <sep> [1] <a href="https://arxiv.org/abs/1811.01713" target="_blank" rel="nofollow">https://arxiv.org/abs/1811.01713</a>	O	O	Reply	272
[2] <a href="http://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf" target="_blank" rel="nofollow">http://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf</a>	O	O	Reply	272

The paper defines a representation learning strategy based upon estimation	O	O	Review	272
of a matrix of Wasserstein distances.	O	O	Review	272
<sep> <sep> The idea is excellent.	O	O	Review	272
The ability to "solve" IPMs reliably is a recent	O	O	Review	272
development in deep learning whose ramifications are still being explored.	O	O	Review	272
<sep> Intuitively this line of research could plausibly result in general	O	O	Review	272
methods which are theoretically intelligible and broadly applicable.	O	O	Review	272
<sep> Indexing at least one side of the matrix of estimated WDs with events	O	O	Review	272
(rather than classes) has interpretability properties useful for	O	O	Review	272
information retrieval and also conveys benefits reminiscent of learning	O	O	Review	272
with privileged information.	O	O	Review	272
<sep> <sep> However, the exposition could be greatly improved by using the	B-Review	B-1	Review	272
standard language of probability theory.	I-Review	I-1	Review	272
The discussion in 3.1	I-Review	I-1	Review	272
was particularly painful to read.	I-Review	I-1	Review	272
What is the difference between	I-Review	I-1	Review	272
"existing in an environment" and "conditioning on a measurable event"?	I-Review	I-1	Review	272
<sep> Phrases like "belonging to any random subset of the dataset" suggest	I-Review	I-1	Review	272
a non-deterministic method of selecting an element of the power set of	I-Review	I-1	Review	272
the training data, but it is unclear what to do if more training data	I-Review	I-1	Review	272
arrives in this case.	I-Review	I-1	Review	272
<sep> Throughout the entire paper the word "random" is apparently used in the	B-Review	B-2	Review	272
colloquial sense of "arbitrary".	I-Review	I-2	Review	272
*Correct every instance of this.*	I-Review	I-2	Review	272
<sep> If you actually are referring to generating samples from a distribution,	I-Review	I-2	Review	272
be explicit about the generative process.	I-Review	I-2	Review	272
<sep> <sep> Section 3.5 was more confusing than enlightening.	B-Review	B-3	Review	272
In general I understand	I-Review	I-3	Review	272
that environments can be leveraged for intelligibility and admit manipulation	I-Review	I-3	Review	272
for information retrieval.	I-Review	I-3	Review	272
The exact strategy remains somewhat opaque.	I-Review	I-3	Review	272
If	I-Review	I-3	Review	272
you are under space constraints refer to an appendix with more explicit details.	I-Review	I-3	Review	272
<sep> <sep> In the experiments section phrases like "environments consist of random	B-Review	B-4	Review	272
combinations of classes" is also not helpful.	I-Review	I-4	Review	272
Do you mean something like	I-Review	I-4	Review	272
"uniformly selected from the set of all class pairs?"	I-Review	I-4	Review	272
Or something like	I-Review	I-4	Review	272
"uniformly selected from the power set of all classes?"	I-Review	I-4	Review	272
How volatile	I-Review	I-4	Review	272
are the experimental results with respect to the non-deterministic choice	I-Review	I-4	Review	272
of environments?	I-Review	I-4	Review	272
<sep> <sep> I want to accept this paper if the exposition is improved, which I think	O	O	Review	272
is possible during the response period.	O	O	Review	272
<sep> <sep> My other comments are not blocking issues, but would either improve the	O	O	Review	272
current paper or inform future directions of research.	O	O	Review	272
<sep> <sep> The technique bears some resemblance to Wasserstein Discriminant	B-Review	B-5	Review	272
Analysis.[1]  That paper seeks a projection that maximizes the ratio of	I-Review	I-5	Review	272
Wasserstein distance between classes vs. within classes.	I-Review	I-5	Review	272
Here,	I-Review	I-5	Review	272
although the common representation is a nonlinear mapping	I-Review	I-5	Review	272
analogous to a projection, we merely try to estimate all the	I-Review	I-5	Review	272
Wasserstein distances rather than maximize them, so it is not trained	I-Review	I-5	Review	272
to be discriminative per se.	I-Review	I-5	Review	272
That is ok since the representation is	I-Review	I-5	Review	272
designed to be used for a variety of tasks (modulo section 4.2), but it	I-Review	I-5	Review	272
does leave open the question "what if the matrix of estimated	I-Review	I-5	Review	272
Wasserstein distances isn't informative, e.g., due to poor choice of	I-Review	I-5	Review	272
environments?"	I-Review	I-5	Review	272
There is no attempt to assess the representation	I-Review	I-5	Review	272
except via utility in downstream tasks.	I-Review	I-5	Review	272
<sep> <sep> The common representation was justified computationally, but I suspect	B-Review	B-6	Review	272
is beneficial statistically.	I-Review	I-6	Review	272
It might facilitate safely including a	I-Review	I-6	Review	272
large number of environments and then spectrally compressing (i.e., SVD)	I-Review	I-6	Review	272
the resulting matrix without overfitting the data.	I-Review	I-6	Review	272
However clearly if	I-Review	I-6	Review	272
the capacity of this layer is too small, then all estimated WDs will	I-Review	I-6	Review	272
be close to zero.	I-Review	I-6	Review	272
If we posit a low Bayes error classifier for the	I-Review	I-6	Review	272
multi-class problem associated with the dataset, that might imply there	I-Review	I-6	Review	272
is some conditioning of the input under which the matrix of (actual) WDs	I-Review	I-6	Review	272
has rank equal to the number of classes, which would in turn provide a	I-Review	I-6	Review	272
useful diagnostic to guard against an insufficiently discriminative choice	I-Review	I-6	Review	272
of environments or insufficient capacity in the common representation.	I-Review	I-6	Review	272
If	I-Review	I-6	Review	272
the matrix is full rank with a flat spectrum, however, that might indicate	I-Review	I-6	Review	272
the choice of environments is too granular and overfitting has occurred,	I-Review	I-6	Review	272
it's not immediately obvious to me how to guard against this.	I-Review	I-6	Review	272
<sep> I am curious what the results in appendix A.1.	B-Review	B-7	Review	272
look like relative to the spectral	I-Review	I-7	Review	272
norm or the smallest eigenvalue of the estimated WD matrix (smallest	I-Review	I-7	Review	272
eigenvalue assuming number of environments &lt; number of classes,	I-Review	I-7	Review	272
otherwise the k-th eigenvalue where k = number of classes).	I-Review	I-7	Review	272
<sep> <sep> [1] <a href="https://arxiv.org/abs/1608.08063" target="_blank" rel="nofollow">https://arxiv.org/abs/1608.08063</a>	O	O	Review	272
<sep> We thank reviewer #3 for the elaborate and very constructive review.	O	O	Reply	272
We appreciate that you find it an excellent idea, yet acknowledge that the exposition had some issues.	O	O	Reply	272
We have tried to address your concerns and have thoroughly improved the formulation in the revised version (especially section 3).	O	O	Reply	272
<sep> <sep> ‚ÄúHowever, the exposition could be greatly improved by using the standard language of probability theory.	O	O	Reply	272
The discussion in 3.1 was particularly painful to read.	O	O	Reply	272
What is the difference between "existing in an environment" and "conditioning on a measurable event"?	O	O	Reply	272
Phrases like "belonging to any random subset of the dataset" suggest a non-deterministic method of selecting an element of the power set of the training data, but it is unclear what to do if more training data arrives in this case.	O	O	Reply	272
‚Äù	O	O	Reply	272
Indeed, these phrases lacked clarity and we have modified these sentences throughout the whole text in the revised version and especially in section 3.1.	B-Reply	B-1	Reply	272
<sep> <sep> ‚ÄúThroughout the entire paper the word "random" is apparently used in the colloquial sense of "arbitrary". *	O	O	Reply	272
Correct every instance of this.*	O	O	Reply	272
If you actually are referring to generating samples from a distribution, be explicit about the generative process.	O	O	Reply	272
‚Äù	O	O	Reply	272
We have corrected our use of the word ‚Äúrandom‚Äù in the paper.	B-Reply	B-2	Reply	272
Our intention is to convey the following: Environments are randomly generated in the following manner: the size is uniformly selected from the range given by [1] and the attributes that make up the environments are uniformly selected without replacement from the set of all attributes.	I-Reply	I-2	Reply	272
<sep> <sep> ‚ÄúSection 3.5 was more confusing than enlightening.	O	O	Reply	272
In general I understand that environments can be leveraged for intelligibility and admit manipulation for information retrieval.	O	O	Reply	272
The exact strategy remains somewhat opaque.	O	O	Reply	272
If you are under space constraints refer to an appendix with more explicit details.	O	O	Reply	272
‚Äù	O	O	Reply	272
We have rephrased and detailed section 3.5 to improve clarity.	B-Reply	B-3	Reply	272
<sep> <sep> ‚ÄúIn the experiments section phrases like "environments consist of random combinations of classes" is also not helpful.	O	O	Reply	272
Do you mean something like "uniformly selected from the set of all class pairs?"	O	O	Reply	272
Or something like "uniformly selected from the power set of all classes?"	O	O	Reply	272
<sep> We improved this formulation (as well as other phrases) as you have suggested.	B-Reply	B-4	Reply	272
These improvements can be found throughout the text and especially in the introduction and section 3.	I-Reply	I-4	Reply	272
<sep> <sep> ‚ÄúHow volatile are the experimental results with respect to the non-deterministic choice of environments?‚Äù	O	O	Reply	272
As can be seen from the standard deviations in table 1, the F1 scores in the classification task are not impacted much for different non-deterministic choices.	B-Reply	B-4	Reply	272
Intuitively, the sensitivity depends on the values of the hyperparameters and , the amount and maximum size of the environments respectively.	I-Reply	I-4	Reply	272
We thus added additional sensitivity analyses in appendix A1 (tables A1 and A2) of the revised version, illustrating that the sensitivity remains low for all values of or.	I-Reply	I-4	Reply	272
<sep> <sep> ‚ÄúThe technique bears some resemblance to Wasserstein Discriminant Analysis.[1] [...] That is ok since the representation is designed to be used for a variety of tasks (modulo section 4.2), but it does leave open the question "what if the matrix of estimated Wasserstein distances isn't informative, e.g., due to poor choice of environments?"	O	O	Reply	272
There is no attempt to assess the representation except via utility in downstream tasks.	O	O	Reply	272
‚Äù	O	O	Reply	272
Thank you for this reference, we have added it in section 2 (background ‚Äì recent work).	B-Reply	B-5	Reply	272
As mentioned above, we added figures that show a small variance for classification outcomes for different values of or, which suggests the representations are quite robust with respect to the choice of environments.	I-Reply	I-5	Reply	272
<sep> <sep> ‚ÄúThe common representation was justified computationally, but I suspect is beneficial statistically. [...]‚	O	O	Reply	272
Äù	O	O	Reply	272
These are interesting points.	B-Reply	B-6	Reply	272
From our composition experiments we found that, for the given values of and , the spectrum was very non-flat which suggests indeed that the representation could be further compressed to a large degree.	I-Reply	I-6	Reply	272
We believe that your suggestion of a diagnostic to guard against insufficient capacity is very interesting and could be part of further future work, for example by evaluating the evolution of the spectrum of the representations as training progresses.	I-Reply	I-6	Reply	272
<sep> <sep> ‚ÄúI am curious what the results in appendix A.1.	O	O	Reply	272
look like relative to the spectral norm or the smallest eigenvalue of the estimated WD matrix (smallest eigenvalue assuming number of environments &lt; number of classes, otherwise the k-th eigenvalue where k = number of classes).‚Äù	O	O	Reply	272
We have added tables A.3 and A.4 in the appendix that show average values of the spectral norm of 100 representations for different values of and.	B-Reply	B-7	Reply	272

Paper contributions	O	O	Review	272
=================	O	O	Review	272
- This paper proposes a method for constructing representations using a matrix of Wasserstein distances.	O	O	Review	272
These distances measure the discrepancy between each class and each environment, that is a random combination of some classes.	O	O	Review	272
<sep> - The paper evaluates this approach on a task of image retrieval.	O	O	Review	272
<sep> <sep> General notes	O	O	Review	272
============	O	O	Review	272
The general idea of measuring the distribution divergence for a set of classes is interesting and seems to be novel.	B-Review	B-1	Review	272
But I argue that this representation can be limiting:	I-Review	I-1	Review	272
- A set of divergences doesn't contain any pixel-level information, only divergences to some predefined classes	I-Review	I-1	Review	272
- As a consequence, this representation will not be able to discover information that is not covered by the labels	I-Review	I-1	Review	272
Because of these limitations, it seems that this particular representation may be less useful for some applications than others.	I-Review	I-1	Review	272
<sep> <sep> I don't follow why the paper proposes to use 'environments'  -- random combinations of classes.	B-Review	B-2	Review	272
It seems that a square matrix (n_c x n_c) with all classes should do the same job.	I-Review	I-2	Review	272
<sep> <sep> The experimentation is very weak and does very little to support the claims.	B-Review	B-3	Review	272
The paper considers only one substantial task to test the representation.	I-Review	I-3	Review	272
This task is image retrieval by image query.	I-Review	I-3	Review	272
The paper doesn't provide any comparison to existing methods or simple baselines.	I-Review	I-3	Review	272
<sep> <sep> The second contribution that the representations are interpretable and composable is not addressed.	B-Review	B-4	Review	272
I seems that it should be hard to interpret a large vector of distances to randomly chosen subsets of classes.	I-Review	I-4	Review	272
There is no experiment demonstrating interpretability of the proposed approach.	I-Review	I-4	Review	272
The compositionality is not addressed either.	I-Review	I-4	Review	272
The samples provided in the appendix are not convincing.	I-Review	I-4	Review	272
<sep> <sep> The paper is generally well written and it is easy to follow.	B-Review	B-5	Review	272
The literature review can be improved by providing prior work where "approaches use hidden state vector of LSTM" and "features extracted from CNNs" instead of generic references.	I-Review	I-5	Review	272
<sep> <sep> Some of the claims are vague and excessively broad:	B-Review	B-6	Review	272
- The proposed technique can be used with any task, but the paper is clearly limited to the retrieval task	I-Review	I-6	Review	272
- The environments are too vaguely described and can be misinterpreted in the introduction	I-Review	I-6	Review	272
<sep> Conclusion	O	O	Review	272
=========	O	O	Review	272
<sep> I recommend to reject on the basis that	O	O	Review	272
- the approach is more limited than the paper advocates	O	O	Review	272
- the experimentation is weak	O	O	Review	272
- some claims are not addressed	O	O	Review	272
<sep> Other notes	O	O	Review	272
==========	O	O	Review	272
I recommend using term divergence instead of distance when it is not symmetrical.	B-Review	B-7	Review	272
‚ÄúThe general idea of measuring the distribution divergence for a set of classes is interesting and seems to be novel.	O	O	Reply	272
‚Äù	O	O	Reply	272
Thank you for your review and the effort you put into it.	B-Reply	B-1	Reply	272
<sep> <sep> ‚Äú[...]	O	O	Reply	272
- A set of divergences doesn't contain any pixel-level information, only divergences to some predefined classes	O	O	Reply	272
- As a consequence, this representation will not be able to discover information that is not covered by the labels	O	O	Reply	272
Because of these limitations, it seems that this particular representation may be less useful for some applications than others.	O	O	Reply	272
‚Äù	O	O	Reply	272
We would argue that, to the contrary, using labeled information is useful and many applications require such representations.	B-Reply	B-1	Reply	272
Our approach offers an easy method to integrate continuous (images) and discrete (labels) information into one representation which, for instance, offers many possibilities given the current state of object recognizers in computer vision.	I-Reply	I-1	Reply	272
In particular, using labeled data to explore both global and local similarities over different classes can be useful in many specialized or critical applications where wrong classification results are highly undesirable (medical diagnosis, robotic automation,...)	I-Reply	I-1	Reply	272
<sep> ‚ÄúI don't follow why the paper proposes to use 'environments' -- random combinations of classes.	O	O	Reply	272
It seems that a square matrix (n_c x n_c) with all classes should do the same job.	O	O	Reply	272
‚Äù	O	O	Reply	272
Note that the experiments that are detailed in section 4.2 with plot in appendix A.1 experimentally confirm the validity of using random combinations.	B-Reply	B-2	Reply	272
Results for=1 are indicative of the outcome when using a square matrix, yet the results improve significantly for larger values.	I-Reply	I-2	Reply	272
We also explicitly tried using a square matrix which did not work as well.	I-Reply	I-2	Reply	272
We have clarified why we use environments in the revised submission (sections 2 and 4.2).	I-Reply	I-2	Reply	272
In short, we follow the findings of the work of [1] that apply the theory of Random Feature Approximations [2] which has shown to lead to beneficial shift-invariant properties.	I-Reply	I-2	Reply	272
<sep> <sep> ‚ÄúThe experimentation is very weak and does very little to support the claims.	O	O	Reply	272
The paper considers only one substantial task to test the representation.	O	O	Reply	272
This task is image retrieval by image query.	O	O	Reply	272
The paper doesn't provide any comparison to existing methods or simple baselines.	O	O	Reply	272
‚Äù	O	O	Reply	272
With all due respect, this is not correct on two accounts: first, we perform not only retrieval experiments (section 4.3), but also classification experiments on the obtained representation (4.2).	B-Reply	B-3	Reply	272
Additionally, for both experiments we provide a comparison to baselines.	I-Reply	I-3	Reply	272
For the classification task we provide baselines with three state-of-the-art classification models that employ binary cross-entropy (see table 1, section 4.2), for the retrieval based on modified representations we provide a baseline on the basis of CNN features (see table 2, section 4.3).	I-Reply	I-3	Reply	272
<sep> <sep> ‚ÄúThe second contribution that the representations are interpretable and composable is not addressed.	O	O	Reply	272
I seems that it should be hard to interpret a large vector of distances to randomly chosen subsets of classes.	O	O	Reply	272
There is no experiment demonstrating interpretability of the proposed approach.	O	O	Reply	272
The compositionality is not addressed either. [...]‚	O	O	Reply	272
Äù	O	O	Reply	272
We respectfully disagree on this account as well.	B-Reply	B-4	Reply	272
The retrieval experiment in section 4.3 is specifically designed to illustrate the interpretability and composability following the method described in section 3.5.	I-Reply	I-4	Reply	272
In that experiment we  compose new representations from existing representations by exploiting the structure of the representations that are interpretable over rows and columns.	I-Reply	I-4	Reply	272
We subsequently retrieve images that are similar to the modified representations, which we quantitatively have evaluated in table 2 and qualitatively in figure A2.	I-Reply	I-4	Reply	272
Additionally, the ‚ÄòSIM‚Äô retrieval method for this experiment relies on the interpretability of representations over different classes.	I-Reply	I-4	Reply	272
<sep> <sep> ‚ÄúThe paper is generally well written and it is easy to follow.	O	O	Reply	272
The literature review can be improved by [...]‚Äù	O	O	Reply	272
Thank you, we have improved this section in the revised version by adding several relevant works.	B-Reply	B-5	Reply	272
<sep> <sep> ‚Äú- The proposed technique can be used with any task, but the paper is clearly limited to the retrieval task	O	O	Reply	272
- The environments are too vaguely described and can be misinterpreted in the introduction‚Äù	O	O	Reply	272
Again we note that we implemented both a classification task and retrieval task.	B-Reply	B-6	Reply	272
We have rephrased and detailed certain parts of the paper.	I-Reply	I-6	Reply	272
<sep> <sep> ‚ÄúI recommend using term divergence instead of distance when it is not symmetrical.	O	O	Reply	272
‚Äù	O	O	Reply	272
Could you specifically refer to a relevant instance?	B-Reply	B-7	Reply	272
All distance estimates employed in the paper are intended as approximations or estimates of the Wasserstein distance which is a distance between distributions.	I-Reply	I-7	Reply	272
The IPM formulation is found to be symmetric and satisfies the triangular inequality when Lipschitz continuous [3].	I-Reply	I-7	Reply	272
<sep> [1] <a href="https://arxiv.org/abs/1811.01713" target="_blank" rel="nofollow">https://arxiv.org/abs/1811.01713</a>	O	O	Reply	272
[2] <a href="http://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf" target="_blank" rel="nofollow">http://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf</a>	O	O	Reply	272
[3] <a href="https://arxiv.org/abs/1701.07875" target="_blank" rel="nofollow">https://arxiv.org/abs/1701.07875</a>	O	O	Reply	272

The paper proposes to use a multi-step prediction model in model-based RL.	O	O	Review	656
The proposed model maps from current state and a sequence of actions to the state after taking those actions.	O	O	Review	656
The paper demonstrates on 2 tasks that in a model-predictive control loop combined with planning by cross-entropy method, this can yield better asymptotic performance than using single-step models.	O	O	Review	656
<sep> <sep> The insight of using multi-step prediction models is certainly appealing and makes a lot of sense in deterministic tasks.	O	O	Review	656
A systematic empirical comparison of multi-step deep models in RL is of interest, which this paper does provide to some extent.	O	O	Review	656
<sep> <sep> An obvious limitation of the proposed deterministic multi-step forward model is the restriction to deterministic systems.	B-Review	B-1	Review	656
One would expect that the performance deteriorates quickly as the system becomes more stochastic.	I-Review	I-1	Review	656
An extension to the stochastic case along the lines of Chua et al, 2018 is non-trivial as capturing the stochasticity is typically more challenging in long-term predictions.	I-Review	I-1	Review	656
Yet, the paper makes an additional assumption that is less clearly communicated: To be able to plan with a R-step model, one needs to be able to evaluate or approximate the sum of R rewards just from the first and last state in that R-long sequence.	B-Review	B-2	Review	656
This work uses simply the reward at the end r(s_{t+R}) as a proxy which works well in these MuJoCo tasks but can fail horribly in others.	I-Review	I-2	Review	656
One can imagine that a model not only outputs s_{t+R} but also the sum of R rewards given s_t and a_{t:t+R} which could work in more general settings but this is not explored in this paper.	I-Review	I-2	Review	656
The contribution in this paper limited as the proposed approach as well as the experimental comparison is restricted to a relatively specific class of problems and no attempts to generalize are made.	B-Review	B-3	Review	656
<sep> <sep> The experiments nicely compare against using single-step dynamics models and the results show that using the multi-step models for MPC performs better in the two considered tasks.	O	O	Review	656
However, as fas as I understand both the ACP and Chua et al baseline using the single-step prediction accuracy to train their models.	B-Review	B-4	Review	656
The paper is missing a comparison to single-step models that are trained using multi-step prediction losses ("backprop through time" as in Learning Nonlinear Dynamic Models by Langford et al 2009).	I-Review	I-4	Review	656
These models should be much more robust to error blow-up for multi-step prediction and do not require the specific reward structure assumed in this paper.	I-Review	I-4	Review	656
<sep> <sep> The proposed R-step model-based RL approach could be connected to the use of options (the planner and model operate on R-step options, but the MPC does update the policy after every time step).	B-Review	B-5	Review	656
It would be interesting to discuss this potential connection in the paper.	I-Review	I-5	Review	656
The paper does a good job of discussing existing recent work in the deep RL literature but it would also be good to also discuss earlier work on multi-step prediction (e.g. in time-series modeling).	I-Review	I-5	Review	656
<sep> <sep> All in all, I think the paper makes a small contribution demonstrating that multi-step models are useful for model-based RL in specific domains -- which is interesting but certainly not surprising.	O	O	Review	656
Unfortunately the paper stops somewhat early by not comparing to relevant baselines (single-step models trained with multi-step losses) and by not considering tasks where the benefit of multi-step planning would be less clear.	B-Review	B-4	Review	656
We thank the reviewer for a very detailed review.	O	O	Reply	656
<sep> <sep> "capturing the stochasticity is typically more challenging in long-term predictions": Yes, this is an interesting direction.	B-Reply	B-1	Reply	656
Such a model would need the ability to produce complex multimodal distributions of outcomes.	I-Reply	I-1	Reply	656
As our goal in this work was to understand why existing methods failed even on deterministic tasks, we leave it to future work to propose classes of multi-step models appropriate for stochastic environments.	I-Reply	I-1	Reply	656
<sep> <sep> "This work uses simply the reward at the end": In fact, our model is able to use reward at intermediate time steps.	B-Reply	B-2	Reply	656
To do this, we can use the variable-action-length version of our model, as used for visualization (mentioned in Section 2.2 paragraph 2 of the original version).	I-Reply	I-2	Reply	656
We also use this version in Fig 5.	I-Reply	I-2	Reply	656
to evaluate prediction error as a function of timesteps in the future.	I-Reply	I-2	Reply	656
We have added Section 2.2.1 to clarify this.	I-Reply	I-2	Reply	656
<sep> <sep> In our main experiments we use a transformed version of the reward function to select trajectories which have an outcome with the greatest x-axis position.	I-Reply	I-2	Reply	656
This is approximately equal to the sum of the rewards obtained along the trajectory under the original reward function, which provides a reward at each timestep proportional to the forward progress at that timestep.	I-Reply	I-2	Reply	656
We have updated Section 2.3.1 to better reflect this.	I-Reply	I-2	Reply	656
<sep> <sep> We apologize for not making these points more clear in the paper.	I-Reply	I-2	Reply	656
<sep> <sep> "single-step models that are trained using multi-step prediction losses": Yes, we agree that other models which directly minimize long-term prediction error will also produce better predictions that single-step models.	B-Reply	B-4	Reply	656
However, the main goal of this work is to point out the deficiencies of the single-step class of models typically used in the field.	I-Reply	I-4	Reply	656
As such, we simply chose one simple member of the class of multistep models to illustrate our point.	I-Reply	I-4	Reply	656
<sep> <sep> We have since run experiments to evaluate the potential of recurrent training of single-step models with multi-step loss functions.	I-Reply	I-4	Reply	656
While using a multi-step loss provides significant improvement over a single-step loss, the PCP remains somewhat more accurate.	I-Reply	I-4	Reply	656
We have updated Figure 5 and the related text with this result.	I-Reply	I-4	Reply	656
<sep> <sep> We furthermore have run these RNN models on the full bootstrapped planning task.	I-Reply	I-4	Reply	656
Planning with these models is hugely slower than with the PCP, as for each prediction of length H the RNN must be run forward H times, whereas the PCP need only be run H/R times; that is, the RNNs take 50 times as long on Swimmer.	I-Reply	I-4	Reply	656
We have included preliminary results with RNNs in Figure 7 and will update the paper with the completed experiments before camera ready.	I-Reply	I-4	Reply	656
We do not believe these results alter the message of the paper.	I-Reply	I-4	Reply	656
<sep> <sep> The Langford et al reference is very helpful and we will add a discussion of this paper to our related work.	I-Reply	I-4	Reply	656

The authors learn a model that predicts the state R steps in the future, given the current state and intervening actions, instead of the predicting the next time step state.	O	O	Review	656
The model is then used for standard model predictive control.	O	O	Review	656
The authors find numerically that their method, termed Plan-Conditional Predictor (PCP), performs better over long horizon times (~100 time steps), than other recent model-based and model-free algorithms.	O	O	Review	656
This because for long horizon time scales, the model predicting the state for the next time step accumulates error when used recursively.	O	O	Review	656
<sep> <sep> The key idea is to use a model that directly predicts multiple time steps into the future.	O	O	Review	656
While seemingly an obvious extension, it does not appear to have been used in current algorithms.	B-Review	B-1	Review	656
A main issue that I find with this approach is: since only the state after R steps is predicted, reward r(s_t,a_t) can only be used every R steps, not at every step.	I-Review	I-1	Review	656
The authors gloss over this issue because for both MuJoCo environments that they tested, they only need to consider reward at the end of the planning horizon.	I-Review	I-1	Review	656
Thus to make their algorithm generally applicable, the authors also need to show how or whether their method can deal with rewards that may appear at any time step.	I-Review	I-1	Review	656
<sep> <sep> Further, rather than speculate on the cause of the difference between their PCP and PETS (Chua et al 2018) on half-cheetah to be their different settings for CEM optimization (Fig 7b), the authors should just use the same settings to compare.	B-Review	B-2	Review	656
Possibly the authors ran out of time to do this for the current submission, but should certainly do it for the final version.	I-Review	I-2	Review	656
<sep> <sep> While the authors have already compared to other algorithms with similar aims, eg Chua et al 2018, they may also wish to compare to a recent preprint Clavera et al Sep 2018, which also aims to combine the sample efficiency of model-based methods while achieving the performance of model-free ones, by using an ensemble of models, over a 200 time step horizon.	B-Review	B-3	Review	656
However, given the recency of this algorithm, I don't consider this essential.	I-Review	I-3	Review	656
<sep> <sep> Overall, I feel that the authors idea of an R-step model is worth spreading in the community, if the above two main points are addressed.	O	O	Review	656
At the same time, I can only rate it at the border of the cutoff mark.	O	O	Review	656
‚Äúreward r(s_t, a_t) can only be used every R steps, not at every step‚Äù: In fact, our model is able to use reward at intermediate time steps.	B-Reply	B-1	Reply	656
To do this, we can use the variable-action-length version of our model, as used for visualization (mentioned in Section 2.2 paragraph 2).	I-Reply	I-1	Reply	656
We also use this version in Fig 5.	I-Reply	I-1	Reply	656
to evaluate prediction error as a function of timesteps in the future.	I-Reply	I-1	Reply	656
We apologize for not making this point more clear in the paper and we have revised the paper accordingly, adding a Section 2.2.1.	I-Reply	I-1	Reply	656
<sep> <sep> Comparison btw.	O	O	Reply	656
PCP & PETS: We directly compared PCP and PETS using the same CEM settings and found the PETS performance to be poor (1350 reward instead of 4600).	B-Reply	B-2	Reply	656
This is because our CEM implementations differ in details; most significantly, we warm start our planner with the plans from the previous timestep, similar to [1]. This means our CEM yields significantly better results with a smaller number of planning trajectories.	I-Reply	I-2	Reply	656
Given this difference in methods we feel the most fair comparison is to evaluate their method with the hyperparameters from their paper.	I-Reply	I-2	Reply	656
<sep> <sep> The Clavera et al paper was released less than 2 weeks before the ICLR deadline.	B-Reply	B-3	Reply	656
Furthermore, it is a hybrid method (their actual policy is feedforward) and is thus not subject to the analysis performed in our paper.	I-Reply	I-3	Reply	656
However, we will add a discussion of this work to our related work section.	I-Reply	I-3	Reply	656
<sep> <sep> [1]: Tassa, Y., Erez, T., & Smart, W. D. (2008).	O	O	Reply	656
Receding horizon differential dynamic programming.	O	O	Reply	656
In Advances in neural information processing systems (pp.1465-1472).	O	O	Reply	656

This paper proposes learning a transition model that takes an action sequence as an input (instead of a single action), and performing model-based planning by using the cross-entropy method.	O	O	Review	656
<sep> <sep> One obvious concern with this is that this produces a sequence of open-loop plans, rather than a closed-loop policies, with all the inherent limitations.	B-Review	B-1	Review	656
I could see this working well in practice in problems where anticipating how future decisions will react to state changes is not that important, however the authors should discuss the trade-offs more.	I-Review	I-1	Review	656
<sep> <sep> A larger concern for me revolves around learning the transition model.	B-Review	B-2	Review	656
Taking the action sequence as an input (which is one of the main novelties in the paper) is likely to require a lot of data, and maybe this is fine on relatively simple Mujoco tasks but I see it as a potential issue when trying to expand this to more realistic problems.	I-Review	I-2	Review	656
<sep> <sep> Finally, I suggest that the authors change the title to something more descriptive of the paper‚Äôs contents, as there is no analysis of asymptotic performance in the paper (as I would have thought from the title).	B-Review	B-3	Review	656
I also recommend that they look to see if there is any model-based work in the semi-MDP literature, which could be relevant here.	I-Review	I-3	Review	656
<sep> <sep> ‚Äúproduces a sequence of open-loop plans‚Äù: We feel the reviewer may misunderstand how a model-predictive (MPC) controller operates.	B-Reply	B-1	Reply	656
By replanning at each step, MPC converts an open-loop planner into a closed-loop controller.	I-Reply	I-1	Reply	656
Please refer to Section 2.3 and Algorithm 1 of our paper for a more precise description, or see <a href="https://ieeexplore.ieee.org/document/57020," target="_blank" rel="nofollow">https://ieeexplore.ieee.org/document/57020,</a> for example, for more background.	I-Reply	I-1	Reply	656
<sep> <sep> ‚Äúlikely to require a lot of data‚Äù: While we agree that our approach does require a significant amount of training data, the main objective of this work is to understand the limitations of existing neural dynamics models rather than to propose a practical new one.	B-Reply	B-2	Reply	656
<sep> <sep> ‚Äúchange the title‚Äù: Correspondingly, our paper examines performance in the limit of a very large number of training examples, hence the ‚Äúasymptotic‚Äù in our title.	B-Reply	B-3	Reply	656
<sep> <sep> Thank you.	O	O	Reply	656
Yes, we will certainly look for related work in the semi-MDP literature.	O	O	Reply	656

This paper study the model-based approach in deterministic low dimensional continuous control.	O	O	Review	656
As far as I am concerned and I understood, the main contribution of this paper is in substituting one-step-ahead prediction model with a multiple-step prediction model, resulting in a more accurate prediction model.	O	O	Review	656
I was not able to find points beyond this.	O	O	Review	656
I would be happy if the authors could clarify it.	O	O	Review	656
Please refer to our top-level comment.	O	O	Reply	656

###  Summary	O	O	Review	656
- The paper tries to understand what learning principles can lead to representations that allow zero-shot learning/generalization.	O	O	Review	656
<sep> - It explores the impact of two properties -- locality and compositionality -- on ZSL performance.	O	O	Review	656
<sep> - To encourage locality (and also compositionality since they can overlap), the paper uses an auxiliary loss at an earlier layer (when the receptive field of features is small) to predict local attributes.	O	O	Review	656
<sep> - For interpreting local features, the paper computes MI between the global feature map of one image and local features from a different image of the same class and visualizes it using a heatmap.	O	O	Review	656
- It uses normalized TRE to measure compositionality (Normalized to take into account that some methods are biased towards learning more compositional representations.)	O	O	Review	656
<sep> - It compares supervised, unsupervised, and self-supervised representation learning methods and studies the impact of locality and compositionality on ZSL performance for these methods.	O	O	Review	656
<sep> <sep> ### Decision and reasons	O	O	Review	656
I vote for a weak accept.	O	O	Review	656
However, I think it's a good paper and does a lot of things right.	O	O	Review	656
I'm willing to increase my score if the authors can convincingly answer my questions.	O	O	Review	656
<sep> Positives:	O	O	Review	656
1- The proposed zero-shot learning from scratch setting is a step in the right direction for focusing on uncovering general learning principles.	O	O	Review	656
<sep> <sep> 2- Locality and compositionality are sensible goals for good representations.	O	O	Review	656
The paper defines both and explores their importance with clear and novel experiment-designs and metrics.	O	O	Review	656
The experiments are also well conducted.	O	O	Review	656
<sep> <sep> Negatives:	O	O	Review	656
<sep> 1- The paper makes a lot of observations, but sometimes does not even try to explain some unexpected observations.	B-Review	B-1	Review	656
<sep> 2- CMDIM is presented as a self-supervised algorithm but seems to require class labels.	B-Review	B-3	Review	656
<sep> <sep> ### Supporting arguments for the reasons for the decision.	O	O	Review	656
<sep> <sep> Positives:	O	O	Review	656
<sep> 1- I agree with the paper that ZSL setting is more about uncovering learning principles and less about constructing practical systems that can do well in zero-shot settings.	O	O	Review	656
In a practical setting, it doesn't make much sense to zero-shot learning anyway.	O	O	Review	656
I also agree that current ZSL work is focusing too much on pushing the state-of-the-art using pre-trained imagenet features and missing the actual goal of the problem setting (I wouldn't say we shouldn't do that at all, however.	O	O	Review	656
Some learning principles may require a significant amount of data to learn good representations for zero-shot learning, and imagenet pretraining is a good proxy for that).	O	O	Review	656
This paper acts as a good reminder that ZSL research should be done keeping in mind the goal of ZSL.	O	O	Review	656
<sep> <sep> 2- The paper first defines locality and compositionality.	O	O	Review	656
It then uses interesting and meaningful metrics for empirically testing if these properties correlate with zero-shot performance.	O	O	Review	656
I found the experiment designs to be clever (such as computing parts F-1 score using boolean maps, visualizing MI between local and global features of images from the same class, etc).	O	O	Review	656
I think this paper will act as an important reference for motivating future work on learning more modular representations.	O	O	Review	656
<sep> <sep> Negatives:	O	O	Review	656
<sep> 1- The paper doesn't try to explain the possible reasons behind some observations.	B-Review	B-1	Review	656
For example, why does locality not correlate with ZSL performance of generative models?	I-Review	I-1	Review	656
Why does LC loss hurt performance for CMDIM?	B-Review	B-2	Review	656
<sep> 2- CMDIM draws positive samples from other images of the same class.	B-Review	B-3	Review	656
As a result, it's not a truly unsupervised learning method.	I-Review	I-3	Review	656
The direct comparison of CMDIM to DIM seems unfair.	I-Review	I-3	Review	656
<sep> <sep> ### Questions	O	O	Review	656
<sep> Q1-  Computation of the local classification and attribute auxiliary loss is a bit unclear.	B-Review	B-4	Review	656
How is it assured that a certain attribute is present in the local feature when computing the auxiliary attribute-loss?	I-Review	I-4	Review	656
<sep> <sep> Q2- Did the authors try a baseline in which AC is also trained on the global representation in the context of Figure 2?	B-Review	B-5	Review	656
The extra information about the parts may be the reason behind better ZSL performance, and a global AC could improve ZSL performance without improving Parts F1 score (Although a more likely outcome is that a global AC would increase both the parts F1 score and the ZSL accuracy.)	I-Review	I-5	Review	656
<sep> <sep> Q3- For VAEs, the local F-1 score does not correlate with ZSL performance.	B-Review	B-6	Review	656
This seems to contradict the idea locality leads to better ZSL performance.	I-Review	I-6	Review	656
Is there an explanation for this?	I-Review	I-6	Review	656
The paper just glances over this by calling this 'interesting.'	I-Review	I-6	Review	656
<sep> <sep> Q4- Can CMDIM be considered a self-supervised algorithm?	B-Review	B-7	Review	656
Doesn't it need class labels to draw positive samples from the same class?	I-Review	I-7	Review	656
<sep> <sep> <sep> ### Other minor remarks	O	O	Review	656
<sep> - "Formally, f(x) \elem R is compositional if it can be expressed as a combination of the elements of ..."	B-Review	B-8	Review	656
<sep> The definition would be more clear if the authors could mention some reasonable combination operators here (such as weighted average etc).	I-Review	I-8	Review	656
<sep> <sep> - "However, this choice in architecture does not guarantee locality, as CNN representations could only contain ‚Äúglobal‚Äù information, such as the class or color of the object, despite having a limited receptive field. "	B-Review	B-9	Review	656
<sep> <sep> I'm not sure what this means.	I-Review	I-9	Review	656
Why are CNN representations restricted to 'only' global information?	I-Review	I-9	Review	656
<sep> <sep> ### Update after author's response	O	O	Review	656
<sep> The author's response fixes some minor clarity issues.	O	O	Review	656
I think this work is a good contribution and should be accepted.	O	O	Review	656
I've updated my score accordingly.	O	O	Review	656
We thank the reviewer for their supportive comments and helpful suggestions.	O	O	Reply	656
In what follows we will attempt to address their concerns, grouped by category.	O	O	Reply	656
<sep> <sep> General observations	O	O	Reply	656
Why does locality not correlate with ZSL performance for generative models?	O	O	Reply	656
<sep> We will address this question in our answer to Q3 below.	B-Reply	B-1	Reply	656
<sep> <sep> Why does LC loss hurt CMDIM performance?	O	O	Reply	656
<sep> <tab>We hypothesize this is due to the fact that both CMDIM and the LC loss focus on discriminating classes at the local level, and that the LC objective is inherently less effective than the CMDIM formulation for this task (in terms of downstream ZSL performance).	B-Reply	B-2	Reply	656
As a result, forcing the model to account for both terms lowers downstream performance.	I-Reply	I-2	Reply	656
A more detailed explanation has been added to 5.1.	I-Reply	I-2	Reply	656
<sep> <sep> <sep> Questions.	O	O	Reply	656
<sep> Q1.	O	O	Reply	656
We do not have ground truth values for the local presence or absence of an attribute (this might be feasible on CUB by combining part information with attributes which sometimes map to specific parts such as tail color, but impossible on SUN and AWA2 by construction).	B-Reply	B-4	Reply	656
As a result, we consider the ground-truth value for each local feature (attribute or class) to be that of its class.	I-Reply	I-4	Reply	656
This means that some uninformative features are counted in the loss term (e.g. a local feature corresponding to pure background will not be able to predict the class or the attributes) but on average, the loss term encourages local features to capture class/attribute information when possible.	I-Reply	I-4	Reply	656
More complex setups in the field of attribute detection tend to use attention mechanisms to mitigate the effect of taking into account uninformative local features (such as a feature mapping to the background of the image) [1] but are outside the scope of this work.	I-Reply	I-4	Reply	656
<sep> <sep> Q2.	O	O	Reply	656
<sep> We initially ran experiments where we considered versions of AC and LC on the global representation.	B-Reply	B-5	Reply	656
For AC this is equivalent to multi-task learning combining the model and a ProtoNet.	I-Reply	I-5	Reply	656
For LC the same applies for a supervised classifier.	I-Reply	I-5	Reply	656
<sep> The addition of the global loss changed learning dynamics (e.g. VAEs tended to ignore the reconstruction term) and overall hyperparameter selection resulted in either:	I-Reply	I-5	Reply	656
Weaker (in terms of ZSL accuracy) models focusing on the AC and LC at the expense of their own loss term	I-Reply	I-5	Reply	656
Stronger models mainly ignoring AC and LC.	I-Reply	I-5	Reply	656
<sep> The part accuracy overall changed in a similar fashion: either staying close to the original model (ignoring AC/LC) or converging towards that of FC/PN.	I-Reply	I-5	Reply	656
As this did not provide useful insights into the original model, we dropped this line of investigation.	I-Reply	I-5	Reply	656
We believe local AC/LC behave differently as local versions of PN and FC do not dominate the performance of other models.	I-Reply	I-5	Reply	656
<sep> <sep> <sep> Q3.	O	O	Reply	656
<sep> This observation is actually more generally true for all models that include a reconstruction objective, such as VAEs but also AAEs, as outlined in figure 2.	B-Reply	B-6	Reply	656
We hypothesize that this is due to the fact that such models already have a good understanding of local information (essential for reconstructing) which is not really improved by the local objectives.	I-Reply	I-6	Reply	656
The main issue with those models is that they might be ‚Äútoo local‚Äù: focusing on capturing non-essential (from a class-discriminative point of view) local information, such as an image background, at the expense of more important aspects of an image.	I-Reply	I-6	Reply	656
<sep> In addition to this, these models score poorly in terms of the measures of compositionality we have introduced.	I-Reply	I-6	Reply	656
While we have considered locality and compositionality separately, they interact, and a model that is aware of local parts, but unable to combine them effectively will be weaker at ZSL.	I-Reply	I-6	Reply	656
<sep> <sep> Q4.	O	O	Reply	656
CMDIM is indeed a (weakly) supervised learning algorithm and does draw positive samples from the same class.	B-Reply	B-7	Reply	656
Overall the goal of introducing this model is to show the improvement one can achieve by changing the nature of positive/negative samples in DIM to learn class-discriminative rather than instance-discriminative features.	I-Reply	I-7	Reply	656
We have clarified the category name in 4.1 to highlight this (we put it in the same category as DIM/AMDIM due to conceptual similarities).	I-Reply	I-7	Reply	656
A detailed description of CMDIM has been added to section G of the appendix.	I-Reply	I-7	Reply	656
<sep> <sep> Other remarks.	O	O	Reply	656
<sep> ‚ÄúFormally ‚Ä¶‚Äù.	O	O	Reply	656
We have updated section 2.1 with examples of common combination operators, referencing more complex ones as found in e.g. [2]	B-Reply	B-8	Reply	656
‚ÄúHowever ‚Ä¶ field.	O	O	Reply	656
‚Äù.	O	O	Reply	656
We realize that this sentence was not clear and could lead to a misunderstanding.	B-Reply	B-9	Reply	656
We clarified section 2.2 accordingly.	I-Reply	I-9	Reply	656
<sep> <sep> <sep> Bibliography	O	O	Reply	656
[1] Liu, Xiao, et al "Localizing by describing: Attribute-guided attention localization for fine-grained recognition."	O	O	Reply	656
Thirty-First AAAI Conference on Artificial Intelligence.	O	O	Reply	656
2017.	O	O	Reply	656
<sep> <sep> [2] Higgins, Irina, et al "Scan: Learning hierarchical compositional visual concepts."	O	O	Reply	656
arXiv preprint arXiv:1707.03389 (2017).	O	O	Reply	656

UPDATE: My recommendation has been borderline because the discussion of the paper about the nature of locality and compositionality seems to be less in-depth than I would have expected, but if the authors will revise the submission to shift the focus of the paper to more focused on analysis and evaluation and weaken the claims that their model exhibits locality and compositionality, I would lean towards an accept as the empirical evaluation is extensive.	O	O	Review	656
<sep> <sep> ----	O	O	Review	656
Summary: This paper aims to investigate the role of locality and compositionality in zero-shot learning.	O	O	Review	656
The authors propose a novel evaluation setup that differs from the original zero-shot learning framework in that the model is not allowed to be pretrained on another dataset.	O	O	Review	656
The authors propose several methods for learning and visualizing local representations.	O	O	Review	656
<sep> <sep> The overall problem the paper tackles is quite ambitious which involve many parts: defining locality and compositionality, defining constraints for enforcing locality and compositionality, evaluating the existence of locality and compositionality, and evaluating model performance.	B-Review	B-3	Review	656
Because of the extensive nature of the research problem, the coverage of each piece of this research problem in this paper could have been more thorough: for example, I would be really excited for a more in-depth analysis on methods for enforcing locality, but the authors consider only one method, which is the auxiliary loss, and this method does not seem to be applicable for datasets that do not have attribute labels.	I-Review	I-3	Review	656
Given the formalism in section 2.1, I would furthermore be excited about a more in-depth analysis on methods for enforcing compositionality, but the authors only investigate compositionality from the perspective of a weighted average.	I-Review	I-3	Review	656
As a result, the claims about whether enforcing locality and compositionality helps with generalization seem weak, as the authors only do not seem to consider different ways of achieving locality and compositionality -- it is not clear whether their method for enforcing locality (with auxiliary losses) or compositionality (by explicitly performing a weighted average) is representative of enforcing locality and compositionality in general.	I-Review	I-3	Review	656
Furthermore, locality seems to be more of a statement about *ignoring* information (discussed below), which the authors do not explore.	I-Review	I-3	Review	656
As a result, my recommendation is borderline.	I-Review	I-3	Review	656
Perhaps the paper could benefit by reframing it with a more specific focus, with more emphasis on the evaluation, which the paper seems to do well.	I-Review	I-3	Review	656
I would recommend that the authors either (1) perform a more extensive analysis of methods for enforcing locality and compositionality or (2) shift the focus of the paper to more focused on analysis and evaluation and weaken the claims that their model exhibits locality and compositionality, as there is not enough evidence to tell whether their method for enforcing locality and compositionality is the best way of doing so.	I-Review	I-3	Review	656
<sep> <sep> <sep> Strengths:	O	O	Review	656
- The paper is well-motivated and tackles an important problem.	O	O	Review	656
<sep> - The empirical evaluation is extensive.	O	O	Review	656
<sep> - The framework of not relying on pretrained features is a novel contribution.	O	O	Review	656
<sep> <sep> Weaknesses:	O	O	Review	656
- There does not seem to be a comparison between a compositional model and a non-compositional model in section 5.3.	B-Review	B-1	Review	656
Would the authors be able to provide such an analysis?	I-Review	I-1	Review	656
Otherwise it is difficult to tell exactly how and to what extent compositionality helps.	I-Review	I-1	Review	656
<sep> - I would have assumed that enforcing locality should actually be a problem of *ignoring* information, rather than *predicting* labeled information.	B-Review	B-2	Review	656
However, the auxiliary loss introduction in section 4.1 only seems to enforce that local features (which by default are local from the CNN) are predictive of attributes/class, rather than enforcing that these features ignore information that is not local to the particular image patch they are modeling.	I-Review	I-2	Review	656
Would the authors be able to comment on this point, as well as provide an empirical analysis of how *unpredictive* the features of their model are on image patches elsewhere?	I-Review	I-2	Review	656
We thank the reviewer for the positive comments.	O	O	Reply	656
In what follows, we will attempt to address their remarks.	O	O	Reply	656
<sep> <sep> Your concerns are completely fair, and I think the issue is that we didn't make it clear enough that the paper is an evaluation paper (and we can correct that).	B-Reply	B-3	Reply	656
Rather, the methods we introduce are all meant to be different tools we felt would test / evaluate the effect of compositionality and locality.	I-Reply	I-3	Reply	656
It is true that the paper would have benefited from trying more local / compositional methods, but we think that as establishing a framework for discussing generalization in ZSL, our work has high value, and we hope that future works explore these factors in more depth under ZFS.	I-Reply	I-3	Reply	656
<sep> <sep> Comments on section 5.3.	O	O	Reply	656
The perspective we have taken in this work is to consider most CNN-based architectures to be compositional in one way or another (given that they arise from combining part representations e.g. feature maps).	B-Reply	B-1	Reply	656
In this context, it is complicated to introduce a non-compositional model, as it would require a different architecture, hence the use of the TRE proxy and reasoning in terms of degrees of compositionality.	I-Reply	I-1	Reply	656
Our second experiment in that section (fig.6) is an attempt to contrast a more compositional model (averaging part representations) with an ensemble (averaging predictions).	I-Reply	I-1	Reply	656
<sep> <sep> Comments on ‚Äúignoring‚Äù information.	O	O	Reply	656
We agree that a good criteria for a local representation would be that it ignores information from e.g. other patches.	B-Reply	B-2	Reply	656
This fits with our proposed definition of a local representation as one that contains information specific to a patch.	I-Reply	I-2	Reply	656
The reasoning behind the local losses was that as a local feature can only at best be predictive of the class information or attribute information that is present at the given location, the loss would encourage the model to account for this local information.	I-Reply	I-2	Reply	656
An example would be: a patch corresponding to the beak of a bird cannot predict the tail color, but having an AC loss will encourage it to take into account beak shape, and color.	I-Reply	I-2	Reply	656
One way to evaluate whether a local representation ignores local information is to estimate the mutual information between different local features corresponding to the same image.	I-Reply	I-2	Reply	656
We are working on evaluating this across models and datasets.	I-Reply	I-2	Reply	656

The paper proposes an evaluation framework for Zero-Shot Learning (ZSL) methods called zero-shot learning from scratch (ZFS) where the model is not allowed to be pretrained on other datasets such as ImageNet.	O	O	Review	656
The main motivation of this approach is that it is difficult to understand what is useful for generalization in ZSL since most state-of-the-art methods use features pretrained on large datasets such as ImageNet.	O	O	Review	656
<sep> Most state-of-the-art approaches exploit models pretrained on ImageNet.	O	O	Review	656
Instead, the paper proposes to randomly initialize model parameters to have a better understanding of what's happening in ZSL.	O	O	Review	656
<sep> ZFS adds one constraint: model parameters should not contain information about data outside that from the training split of the target dataset.	O	O	Review	656
<sep> Two main criteria are studied to study neural networks:	O	O	Review	656
- compositionality (ability to be expressed as a combination of simpler parts)	O	O	Review	656
- locality (ability to encode only information specific to locations of interest)	O	O	Review	656
To provide a better understanding of their claims, the authors use MTurk annotations to construct boolean map for each local part labelled in the CUB dataset.	O	O	Review	656
<sep> <sep> <sep> Although the paper is experimental, I vote for borderline accept for the following reasons:	O	O	Review	656
- The paper is well-written and the contributions are clear.	O	O	Review	656
<sep> - The evaluation metrics to evaluate how models generalize for both criteria are well motivated theoretically (e.g. Tree Reconstruction Error is used to evaluate compositionality), and different types of encoders (e.g. variations of DCGANS) are studied.	O	O	Review	656
<sep> - The analysis of models pretrained in different contexts (e.g. supervised classification, reconstruction etc...), with only global or local information, and their impact on generalization is clear (see conclusion for a summary of results).	O	O	Review	656
Some conclusions are very intuitive but useful to know (e.g. VAEs and reconstruction models are not well suited to learn representations that generalize in ZFS).	O	O	Review	656
<sep> <sep> <sep> The weaknesses I found in the paper are the following:	O	O	Review	656
- The paper claims that the models used are smaller than the ‚Äústandard‚Äù backbones common in state-of-the-art Imagenet-pretrained ZSL methods.	B-Review	B-1	Review	656
However, few-shot learning method (e.g. ProtoNet) do not retrain the whole model: Protonet freezes most layers and fine-tunes only the last layers to avoid overfitting.	I-Review	I-1	Review	656
<sep> - The paper introduces "Class-Matching Deep Informax (CMDIM)" which draws positive samples from other images from the same class to extract information that discriminative between categories instead of individual samples.	B-Review	B-2	Review	656
However, I did not understand its exact formulation and how it is exactly different from other DIM approaches.	I-Review	I-2	Review	656
<sep> <sep> Thank you for your thorough and helpful review.	O	O	Reply	656
<sep> <sep> Regarding the encoder backbone, we do freeze the pre-trained encoder when training Protonet, as you have indicated is common practice in ZSL studies.	B-Reply	B-1	Reply	656
We apologize that this was not clear, and we clarified this for future readers in the revision by adding information to section 4.5.	I-Reply	I-1	Reply	656
Our comment on the size of the encoders was only meant to hedge against any readers who might feel the results were too low compared to Imagenet-pretrained results from larger architectures (an example of such an improvement due to the size of the encoder is [1]).	I-Reply	I-1	Reply	656
<sep> <sep> We also clarified CMDIM in our revision, and this can be found in section G of the appendix.	B-Reply	B-2	Reply	656
To clarify here: CMDIM only differs from DIM / AMDIM in that positive samples are drawn from a mixture of patches from the same image and other images with the same label.	I-Reply	I-2	Reply	656
As such, CMDIM is not strictly self-supervised, as one reviewer notes, and this can be thought of as training the model to be good at retrieving patches from a query with the same label.	I-Reply	I-2	Reply	656
We added CMDIM following our observations in Section 5.2 to improve the ability of DIM to recognize similar parts between different images.	I-Reply	I-2	Reply	656
<sep> <sep> Bibliography	O	O	Reply	656
[1] Xian, Yongqin, Bernt Schiele, and Zeynep Akata. "	O	O	Reply	656
Zero-shot learning-the good, the bad and the ugly."	O	O	Reply	656
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.	O	O	Reply	656
2017.	O	O	Reply	656

The paper is proposing a multi-hop machine reading method tested on hotpotqa in the Full Wikipedia setting and squad-open datasets.	O	O	Review	656
<sep> For hotpotqa, It could also have been interesting to evaluate the method of the distractor ones.	B-Review	B-1	Review	656
<sep> First, the proposed method constructs a graph over the Wikipedia pages represented by their respective summary paragraphs.	I-Review	I-1	Review	656
<sep> In this representation, the hyperlinks among pages represent the edges.	I-Review	I-1	Review	656
<sep> Then, the authors trained a normalized RNN model to retrieve the candidate reasoning paths from the question.	I-Review	I-1	Review	656
<sep> The model is bootstrap using TF-IDF page retrieval techniques.	I-Review	I-1	Review	656
<sep> Then, a Beam-search decoding strategy is used to retrieve "reasoning path" which is then pass through a BertQA model using a simple question-reasoning-path concatenation technique.	I-Review	I-1	Review	656
<sep> One originality of the method is the negative sampling strategy that includes negative TF-IDF retrieval as starting points to robustify the sequential extraction process.	I-Review	I-1	Review	656
<sep> The detailed experiments and ablation tests give to illustrate the experimental relevance of the proposed method.	I-Review	I-1	Review	656
Thank you for reading our paper thoroughly and providing encouraging feedback.	O	O	Reply	656
<sep> <sep> # The results on HotpotQA distractor setting	O	O	Reply	656
Regarding the Hotpot distractor setting, we have evaluated our method on the settings, and the scores on the development set are reported in the first version of our manuscript (See Table 1, columns 6-9); due to the time constraints, we did not submit our model to the leaderboard.	B-Reply	B-1	Reply	656
The results show that our method achieves state-of-the-art scores on the distractor setting, outperforming the previous best-published model by more than 10 points.	I-Reply	I-1	Reply	656
Our work is the first to demonstrate the state-of-the-art performance on both the distractor and full wiki settings of HotpotQA.	I-Reply	I-1	Reply	656
We revised our manuscript to make the distractor evaluation clear (See Update 7 and Section 4.1 ‚ÄúHotpotQA‚Äù and  Section 4.2 in our updated manuscript).	I-Reply	I-1	Reply	656
We have a qualitative example in Appendix C.6 and Table 14, which shows how our sequential reasoning path process also helps in distractor setting.	I-Reply	I-1	Reply	656
<sep> <sep> We added new experimental results on Natural Questions Open (Table 4) and additional analysis on selected reasoning paths (Section 4.4) in our updated version.	I-Reply	I-1	Reply	656
We hope it will be helpful in evaluating the effectiveness of our method.	I-Reply	I-1	Reply	656

Summary	O	O	Review	656
========	O	O	Review	656
This paper introduces a graph-based recurrent retrieval model for retrieving evidence documents in a multi-hop reasoning question answering task.	O	O	Review	656
The main idea is that (1) the graph formed by Wikipedia links between passages can be used as constraint for constructing reasoning chains, and (2) the joint encoding of the question and current passage can be used to retrieve a subsequent passage in the reasoning chain.	O	O	Review	656
The paper describes a model for implementing the above retrieval system, and how they jointly train with a reading comprehension model.	O	O	Review	656
They demonstrate the effectiveness of the system on HotPotQA, showing improvements over previously published models, and SQuaD-Open, showing competitive results.	O	O	Review	656
<sep> <sep> Overall Comments	O	O	Review	656
===============	O	O	Review	656
The paper is an interesting, but incremental, improvement to the area of question answering.	O	O	Review	656
Overall, there are two main concerns about this work.	B-Review	B-2	Review	656
First, while the results are somewhat strong, the ideas presented are small variations on existing systems.	I-Review	I-2	Review	656
For example, Godbole et al 2019 and Ding et al 2019 both explore using graphical structural to constraint iterative, multi-hop, retrieval.	I-Review	I-2	Review	656
Also, Feldman et al 2019, describe an encoder based approach to encode question and paragraph context for iterative retrieval.	I-Review	I-2	Review	656
Asides from smaller modeling differences (choice of RNN, training regime, BERT reader, etc.)	I-Review	I-2	Review	656
to account for the difference in results, the main difference seems to be the joint training of the retrieval system with the reader.	I-Review	I-2	Review	656
Secondly, the paper lacks clarity on some formal definitions and definition of the graph, making it hard to understand the content precisely.	I-Review	I-2	Review	656
<sep> <sep> Detailed Comments	O	O	Review	656
================	O	O	Review	656
Below are some detailed comments about specific parts of the paper, in order of importance:	O	O	Review	656
<sep> 1.	B-Review	B-1	Review	656
One important limitation of this technique is the reliance on a linked documents for constructing the retrieval system.	I-Review	I-1	Review	656
It is not clear from the paper how much of the results are obtained from constraining the set of retrieved passages (after the initial retrieval) to Wikipedia links.	I-Review	I-1	Review	656
And whether, for example, substituting Wikipedia links with links derived from an off-the-shelf entity linking system would suffice.	I-Review	I-1	Review	656
<sep> <sep> 2.	B-Review	B-3	Review	656
Given that the retrieval model is restricted to link structure in Wikipedia that induces the proposed retrieval graph, I assume that there are ‚Äúreasoning paths‚Äù that do not exist in the graph, given Wikipedia‚Äôs policy of avoiding adding redundant links within a Wikipedia page.	I-Review	I-3	Review	656
It would have been informative to conduct an ‚ÄúOracle‚Äù experiment: that is, given the initial  set of retrieved nodes and the graph structure, are there *any* paths that provide the correct answer and reasoning chain?	I-Review	I-3	Review	656
That is to say, what is the upper-bound performance on the proposed system given the currently induced Wikipedia graph?	I-Review	I-3	Review	656
<sep> <sep> 3.	B-Review	B-4	Review	656
In Section 3, and even later on in the paper, it was not clear what ‚ÄúE‚Äù denotes.	I-Review	I-4	Review	656
It never seems to be defined, and is used interchangeably with ‚Äúgraph node‚Äù, ‚Äúwikipedia page‚Äù, ‚Äúwikipedia paragraph‚Äù and ‚Äúreasoning path‚Äù.	I-Review	I-4	Review	656
Are these the same thing?	I-Review	I-4	Review	656
It would be much clearer to define what E means, and perhaps separate the different concepts (node, passage, reasoning path) properly.	I-Review	I-4	Review	656
<sep> <sep> 4.	B-Review	B-5	Review	656
In Section 3, it seems that ‚Äòq‚Äô is not defined.	I-Review	I-5	Review	656
Is it the question?	I-Review	I-5	Review	656
<sep> <sep> 5.	B-Review	B-6	Review	656
In Section 3.1, it is not clear what the graph actually contains.	I-Review	I-6	Review	656
Does it contain all the paragraphs from Wikipedia?	I-Review	I-6	Review	656
Just the paragraphs with links?	I-Review	I-6	Review	656
The first paragraph of every Wikipedia page?	I-Review	I-6	Review	656
What granularity of the wikipedia page becomes an individual node in the graph?	I-Review	I-6	Review	656
<sep> <sep> 6.	O	O	Review	656
In Section 3.1.1.,	B-Review	B-7	Review	656
the representation of the starting retrieval (i.e., time-step = 0), h_0, is not defined.	I-Review	I-7	Review	656
Later in the section, the paper mentions the use of TF-IDF for the initial set of nodes, instead of the learned retrieval model.	I-Review	I-7	Review	656
This seems a bit unusual design decision without further explanation.	I-Review	I-7	Review	656
Particularly when taking the results in Table 4, showing TF-IDF based retrieval performs worse that the learned retrieval system from the proposed model.	I-Review	I-7	Review	656
<sep> <sep> 7.	B-Review	B-8	Review	656
In Section 3, C_{t} (the candidate set of paragraphs) is not defined.	I-Review	I-8	Review	656
This is an important set to define.	I-Review	I-8	Review	656
Is it the set of paragraphs derived from Wikipedia links, starting from the current node?	I-Review	I-8	Review	656
<sep> <sep> 8.	B-Review	B-9	Review	656
In Section 3.1.2, ‚ÄúLoss function‚Äù, the term g_{r} is not defined.	I-Review	I-9	Review	656
<sep> <sep> 9.	B-Review	B-10	Review	656
In Section 4.4 ‚ÄúAnalysis on reasoning path length‚Äù, it would have been useful to see the performance of the model with different path lengths.	I-Review	I-10	Review	656
This analysis is somewhat common on multi-hop reasoning tasks, and should be included.	I-Review	I-10	Review	656
<sep> <sep> 10.	B-Review	B-11	Review	656
Typo in Section 4.4: ‚Äú..., and out model is likely too terminate ‚Ä¶‚Äù  should be ‚Äú likely to terminate ‚Äú	I-Review	I-11	Review	656
<sep> We thank you for your helpful feedback.	O	O	Reply	656
We have substantially updated our manuscript to address all the concerns you kindly raised as much as we can.	O	O	Reply	656
<sep> <sep> First of all, we would like to address the two weaknesses you mention in your overall comments.	O	O	Reply	656
<sep> <sep> Originality.	O	O	Reply	656
<sep> <sep> # On the difference with other graph-based approaches	B-Reply	B-1	Reply	656
Our work has several significant originalities in its system design, training and inference time strategies from Ding et al (2019) and Godbole et al (2019), which leads to more than 20 point improvements over these previous approaches on HotpotQA full wiki.	I-Reply	I-1	Reply	656
<sep> <sep> 1)  System design: We formulate the retrieval as reasoning path search over the Wikipedia graph, instead of dynamically constructing an entity-graph for each question based on compiled document lists as in the previous work; the recurrent module dynamically updates and expands candidate paragraphs from the initial TF-IDF-based candidates at each time step.	I-Reply	I-1	Reply	656
In addition, our work also studies the interplay between our retrieval model and the reader model (See the response of ‚ÄúReasoning path retrieval and the interplay between our reader and retriever‚Äù below for details).	I-Reply	I-1	Reply	656
<sep> <sep> 2) Training strategy: To train our recurrent module to learn to retrieve the path, leveraging the graph structure, we train our model with negative sampling and multiple reference paths (See Section 3.1.2 and the summary by review#1).	B-Reply	B-1	Reply	656
<sep> <sep> 3) Inference strategy: We introduce beam-search based decoding to make the framework more scalable (See Section 3.1.1; also summarized by review#1 and #2), and the beam search with our reasoning path re-ranking is more effective than a greedy search.	B-Reply	B-1	Reply	656
As in Table 6, replacing beam search with greedy search deteriorates F1 by 3.7.	I-Reply	I-1	Reply	656
Also, our method does not need to encode all possible nodes like the previous studies, and instead each path only encodes its corresponding paragraphs.	I-Reply	I-1	Reply	656
<sep> <sep> The HotpotQA dataset used in the previous work is based on introductory paragraphs only.	I-Reply	I-1	Reply	656
By contrast, our method is applied not only to HotpotQA but also to the Natural Questions (See Update 1) and SQuAD Open datasets.	I-Reply	I-1	Reply	656
These two datasets are not restricted to the introductory paragraphs, and our method achieves state-of-the-art results.	I-Reply	I-1	Reply	656
This is made possible by our search-based decoding strategy.	I-Reply	I-1	Reply	656
One interesting observation on our Natural Questions experiments is that our model learns to retrieve multi-hop reasoning paths with our training strategy, even without multi-hop gold path annotations as in HotpotQA (See Appendix C.5 and Table 13).	I-Reply	I-1	Reply	656
This demonstrates the robustness and scalability of our approach.	I-Reply	I-1	Reply	656
<sep> <sep> # On the difference with other multi-step retrieval approaches	O	O	Reply	656
Previous multi-step approaches such as Das et al (2019), Qi et al (2019), Godbole et al (2019) and Feldman and El-Yaniv (2019) do not accommodate arbitrary steps of reasoning.	B-Reply	B-2	Reply	656
As review#1 and review#3 summarize, our RNN approach uses the EOE symbol to produce reasoning paths with different lengths.	I-Reply	I-2	Reply	656
This allows our model to be easily applicable to both multi-hop and single-hop questions without specifically changing the model architecture.	I-Reply	I-2	Reply	656
Table 8 demonstrates the effectiveness of this adaptive retrieval process.	I-Reply	I-2	Reply	656
In practice, it is not obvious if a question requires single-hop or multi-hop retrieval (e.g., some of the Natural Questions Open are clearly answerable based on single paragraph, while in some questions, multi-hop reasoning helps.),	I-Reply	I-2	Reply	656
and thus this flexibility is another significant advantage.	I-Reply	I-2	Reply	656
<sep> <sep> <sep> # Reasoning path retrieval and the interplay between our reader and retriever	O	O	Reply	656
Our framework benefits from the interplay between our retriever and reader.	B-Reply	B-3	Reply	656
Our retriever encodes the candidate paragraphs independently for scalability, and iteratively selects a paragraph at each time step conditioned by the prediction history.	I-Reply	I-3	Reply	656
Each of the resulting K reasoning paths (K=beam size) includes one or more paragraphs.	I-Reply	I-3	Reply	656
Our reader encodes the paragraphs in the paths jointly and predicts probabilities of each reasoning path E containing an answer span.	I-Reply	I-3	Reply	656
By encoding the paragraphs jointly, our reader model fully leverages the self-attention mechanism across the concatenated paragraphs in the retrieved reasoning paths; this is especially crucial for multi-hop reasoning as discussed in recent work (Wang et al 2019a).	I-Reply	I-3	Reply	656
The additional reasoning path re-ranking makes our overall framework robust, leading to large performance improvement (See Section 4.4 and Table 8,9).	I-Reply	I-3	Reply	656
This reasoning path re-ranking is one of the novel points in our work.	I-Reply	I-3	Reply	656
<sep> <sep> These significant differences together demonstrate state-of-the-art performance on the four experimental settings in the three datasets, HotpotQA (full wiki, distractor), SQuAD Open and Natural Questions Open (Update 1).	I-Reply	I-3	Reply	656
Notably, our method outperforms all the previous graph-based or multi-step retrieval methods by more than 20 points on HotpotQA full wiki and 15 points on SQuAD Open (See Table 1,2,3).	I-Reply	I-3	Reply	656
<sep> <sep> We added discussions in Section 2 (Related Work) to clarify these points.	I-Reply	I-3	Reply	656

This paper proposes a method to find a sequence of reasoning paragraphs in Wikipedia to answer queries requiring multi-hop reasoning.	O	O	Review	656
They make the key observation that answering multi-hop queries might require retrieving evidence that have very less lexical overlap with the question.	O	O	Review	656
Given a query, the proposed method starts from a set of initial paragraphs retrieved by a tf-idf retriever and uses the outgoing Wikipedia anchor link to hop to the next evidence.	O	O	Review	656
They propose a simple recurrent neural network that takes in the current paragraph (and the hidden state) and decide which paragraph to hop to in the next step.	O	O	Review	656
Because of the available supervision for the paragraphs (in HotpotQA), they can train a supervised path selector.	O	O	Review	656
They also add a special EoE token that denotes the end of the reasoning path, thereby having the ability to produce reasoning paths of different lengths.	O	O	Review	656
After training the retriever a beam of reasoning paths is sent to the reader module.	O	O	Review	656
The reader module re-ranks the reasoning paths again and then use a standard BERTQA model and the top re-ranked chain of paragraphs to find the evidence.	O	O	Review	656
<sep> <sep> Overall, the paper presents a well-designed system for handling multi-hop queries and the explicit recurrent state is a nice contribution and addition to the IR model proposed in Godbole et al 2019.	O	O	Review	656
The paper is clearly written for the most part.	O	O	Review	656
<sep> <sep> ===Update (11/12/2019)===	O	O	Review	656
The authors have addressed all my comments and have improved the results since.	O	O	Review	656
I am recommending acceptance.	O	O	Review	656
Nice work.	O	O	Review	656
<sep> <sep> Strengths:	O	O	Review	656
‚Äî The proposed method has demonstrated strong results on 2 datasets in challenging open-domain settings.	O	O	Review	656
The ablation results are helpful.	O	O	Review	656
<sep> ‚Äî The paper is clearly written and was straightforward to follow	O	O	Review	656
<sep> Weaknesses:	O	O	Review	656
<sep> 1.	B-Review	B-1	Review	656
The paper mentions that it studies the interplay between the retriever and reader.	I-Review	I-1	Review	656
It is unclear how it is doing so, since the retriever and the reader are not explicitly interacting with each other.	I-Review	I-1	Review	656
Cant the retriever and the reader be trained separately?	I-Review	I-1	Review	656
<sep> 2.	B-Review	B-2	Review	656
It is unclear / not motivated, why there is an extra step of re-ranking required in the reading stage?	I-Review	I-2	Review	656
In other words, what kinds of extra inductive bias is this additional step of re-ranking providing since the same kind of supervision was used while training the retriever model.	I-Review	I-2	Review	656
I do note that the ablation study is helpful and it is clear that it is effective, but it would be nice to see a discussion regarding why this second step of re-ranking helps.	I-Review	I-2	Review	656
<sep> 3.	B-Review	B-3	Review	656
Since the reader model (BERT reader) takes the top scoring chain of paragraphs concatenated together, that would imply that it is currently limited by the number of positional embeddings in the BERT model (512 tokens).	I-Review	I-3	Review	656
I think this limitation should be explicitly mentioned and possible remedies discussed.	I-Review	I-3	Review	656
<sep> 4.	B-Review	B-4	Review	656
The current approach is heavily dependent on Wikipedia graph and will not work if the hyperlink graph is not provided.	I-Review	I-4	Review	656
It would have been nice to have an entity linker component that could also create the graph structure.	I-Review	I-4	Review	656
I believe concurrent work such as Godbole et al 2019 has addressed this and the paper should mention this while contrasting with their work.	I-Review	I-4	Review	656
<sep> 5.	B-Review	B-5	Review	656
From figure 2, I got an impression that since the reader scored the span in "Top 2 reasoning path‚Äù higher, that was selected.	I-Review	I-5	Review	656
But after section 3.2, I was left confused because it looks like the reader model consumes the top scoring chain after the second stage of re-ranking.	I-Review	I-5	Review	656
This is not clear from the figure and should be fixed.	I-Review	I-5	Review	656
<sep> 6.	B-Review	B-6	Review	656
Discussion on scalability: Although the retriever is clearly very effective for such questions, the running time would be prohibitive (for open domain QA) as at test time, query dependent context representations is constructed for each of the paragraph in the reasoning chain.	I-Review	I-6	Review	656
I would like to see a discussion / some running time comparison where query independent paragraph representations are constructed and the network just encodes the query independently at test time.	I-Review	I-6	Review	656
<sep> <sep> Minor: Typo liked -&gt; linked (Sec 4.3, line 5)	B-Review	B-7	Review	656
[For the response to individual weaknesses, please read our response to Official Blind Review #3 (part 1 and part 2).]	O	O	Reply	656
<sep> <sep> To show the importance of the query-dependent encodings in terms of accuracy, we conducted an experiment again with a query-independent variant of our approach on the HotpotQA development set.	B-Reply	B-6	Reply	656
More specifically, our retriever model encodes paragraphs independently from their corresponding queries and sequentially retrieves paragraphs in the same manner as our proposed approach.	I-Reply	I-6	Reply	656
For a fair comparison, we use the same reader model (BERT wwm) with the path re-ranking.	I-Reply	I-6	Reply	656
We train the alternative model without using the data augmentation technique for quick experiments.	I-Reply	I-6	Reply	656
For evaluation, we provide results on both the distractor and full wiki settings.	I-Reply	I-6	Reply	656
<sep> <sep> The results are summarized in the table below:	I-Reply	I-6	Reply	656
<sep> <sep> encoding method   | full wiki QA F1  | full wiki QA EM  | distractor QA F1  | distractor QA EM	I-Reply	I-6	Reply	656
--------------------------   |----------------------|-----------------------|------------------------|-----------------------	I-Reply	I-6	Reply	656
query-dependent     |          64.1           |         52.6             |           81.2              |           68.0	I-Reply	I-6	Reply	656
query-independent |          47.3            |         37.8             |           80.0              |           66.4	I-Reply	I-6	Reply	656
<sep> For our query-dependent approach, the full wiki results correspond to ‚Äúretriever, no link-based negatives‚Äù in Table 6, and the distractor results correspond to ‚ÄúOurs (Reader: BERT wwm)‚Äù Table 1.	I-Reply	I-6	Reply	656
As seen in this table, the QA F1 and EM performance significantly deteriorate on the full wiki setting, which demonstrates the importance of the query-dependent encoding for complex and entity-centric open-domain question answering.	I-Reply	I-6	Reply	656
This is the reason why we employ our query-dependent approach, and we achieve competitive results on the three datasets.	I-Reply	I-6	Reply	656
<sep> <sep> We also found that the performance drop on the distractor setting is much smaller than that on the full wiki setting.	I-Reply	I-6	Reply	656
This is due to its closed nature.	I-Reply	I-6	Reply	656
In the distractor setting, we are given ten paragraphs and the two gold paragraphs are always included, which makes the retrieval task much easier than that in the full wiki setting.	I-Reply	I-6	Reply	656
We have only 10 paragraphs for each question, and thus the number of the possible reasoning paths is quite limited.	I-Reply	I-6	Reply	656
Therefore, our recurrent retriever model is likely to discover the gold reasoning paths by the beam search, and our reader model can select the gold paths by the robust re-ranking approach.	I-Reply	I-6	Reply	656
To verify this assumption, we checked the P EM score as a retrieval accuracy in the distractor setting.	I-Reply	I-6	Reply	656
If we only consider the top-1 path from the beam search, the P EM score of the query-independent model is 12% lower than that of our query-dependent model.	I-Reply	I-6	Reply	656
However, if we consider all the reasoning paths produced by the beam search, the coverage of the gold paths is almost the same.	I-Reply	I-6	Reply	656
As a result, our reader model can perform similarly with both the query-dependent/independent approaches.	I-Reply	I-6	Reply	656
This additionally shows the robustness of our re-ranking approach.	I-Reply	I-6	Reply	656
<sep> <sep> We are planning to add these experimental results in our next revision.	I-Reply	I-6	Reply	656

OVERVIEW:	O	O	Review	64
The authors propose to use depth information to better predict the visual relation between objects in an image.	O	O	Review	64
They do this by incorporating a pre-trained RGB-to-Depth model within existing frameworks.	O	O	Review	64
They claim the following contributions:	O	O	Review	64
1.	O	O	Review	64
First to utilize 3D information in visual relation detection.	O	O	Review	64
They synthesize depth images for existing benchmark datasets of VRD and VG using a pre-trained RGB-to-Depth model trained on NYUv2 to generate RGB-D data for visual relation detection.	O	O	Review	64
<sep> 2.	O	O	Review	64
Discuss and empirically investigate different strategies to extract features from depth maps for relation detection.	O	O	Review	64
<sep> 3.	O	O	Review	64
Study the quantitative and qualitative benefits of incorporating depth maps. "	O	O	Review	64
We show in our empirical evaluation using the VRD and VG datasets, that models using depth maps can outperform competing methods by a margin of up to 3% points".	O	O	Review	64
<sep> <sep> MAJOR COMMENTS:	O	O	Review	64
1.	B-Review	B-1	Review	64
I liked the idea of using depth information to inform visual relationships but I am not sure if the proposed approach is the way to go.	I-Review	I-1	Review	64
Given a depth image of the scene, we can generate a reconstruction of the scene in 3D, even if it is partial/imperfect.	I-Review	I-1	Review	64
Direct reasoning in 3D should now be possible instead of going via deep networks as proposed in the paper.	I-Review	I-1	Review	64
I believe a direct 3D approach would make a meaningful baseline at the very least and needs to be discussed.	I-Review	I-1	Review	64
<sep> 2.	B-Review	B-2	Review	64
The authors use a pre-trained RGB-to-Depth network trained on NYU-v2 to predict depth for the images of VRD and VG.	I-Review	I-2	Review	64
There is very little discussion about the quality of predicted depth maps.	I-Review	I-2	Review	64
Ideally, this needs to be quantified to convince the reader that the generated depth maps are "good" but at the very least the authors need to show qualitative examples (both good, typical and bad) to prove that the pre-trained network generates meaningful depth maps.	I-Review	I-2	Review	64
<sep> 3.	B-Review	B-3	Review	64
To use a siamese (shared weights) feature extractor between RGB and Depth images or not, is not a significant contribution by itself.	I-Review	I-3	Review	64
In principle, separate feature extractors lead to larger model complexity/learning capability and make sense given domain separation between RGB and Depth.	I-Review	I-3	Review	64
<sep> <sep> MINOR COMMENTS:	O	O	Review	64
1.	B-Review	B-4	Review	64
Figure 2 seems to indicate that a Faster-RCNN is used on both RGB and Depth steams which is backed up by text in Section 2 (first paragraph).	I-Review	I-4	Review	64
However, in Section 3.2, under RGB Feature Extraction and Depth Map Feature Extraction, the discussion is about VGG-16 and AlexNet-BN networks.	I-Review	I-4	Review	64
The VGG-16 network is pre-trained in ImageNet and finetuned to relevant data but it is not clear for what task?	B-Review	B-5	Review	64
If the task is object detection, it needs to be trained for it (not fine-tuned, unless it is being initialized from COCO pre-training).	I-Review	I-5	Review	64
The AlexNet-BN depth model is trained for relation detection using only depth.	B-Review	B-6	Review	64
But it is not clear if it is using proposals/boxes generated by RGB detection model or using ground-truth boxes.	I-Review	I-6	Review	64
Basically, the object-detection component of the pipeline is not clear at all.	I-Review	I-6	Review	64
<sep> <sep> NOTE:	O	O	Review	64
I would like to mention that I have published in monocular object pose estimation and work in the object recognition.	O	O	Review	64
I am not as familiar with the visual relation detection field but I understand all the components proposed by the authors in this work.	O	O	Review	64
I believe I understood the paper and reviewed it fairly (to the best of my ability).	O	O	Review	64
Q1.	O	O	Reply	64
I am not sure if the proposed approach is the way to go.	O	O	Reply	64
Given a depth image of the scene, we can generate a reconstruction of the scene in 3D...	O	O	Reply	64
<sep> A1.	O	O	Reply	64
Thank you for your valuable comments.	B-Reply	B-1	Reply	64
You are right that direct reasoning in 3D would be more beneficial.	I-Reply	I-1	Reply	64
However, to reconstruct a scene in 3D we would need to collect either 1) more than one RGB image or 2) more than one depth map, coming from different views of that scene.	I-Reply	I-1	Reply	64
This is a more involved process that has limitations both on data and computation.	I-Reply	I-1	Reply	64
What we have in our scenario is only one RGB image from the scene which we use to synthetically generate the depth map from.	I-Reply	I-1	Reply	64
Going through the RGB-to-Depth deep network in our architecture is the only way to acquire those depth maps in first place.	I-Reply	I-1	Reply	64
Other than the limitation in our current datasets, please note that in many real-world scenarios for humans (or for autonomous agents such as self-driving cars) this is a similar case: a car driving directly forward towards a pedestrian has no access to the rear-view of that person.	I-Reply	I-1	Reply	64
Depth maps, in this case, can already provide sufficient data on the distance to objects.	I-Reply	I-1	Reply	64
In summary, we are exploring a real-world scenario where a 3D reconstruction of the scene is not accessible.	I-Reply	I-1	Reply	64
<sep> <sep> 2.	O	O	Reply	64
There is very little discussion about the quality of predicted depth maps.	O	O	Reply	64
Ideally, this needs to be quantified...	O	O	Reply	64
<sep> A2.	O	O	Reply	64
Thank you for the nice suggestion.	B-Reply	B-2	Reply	64
Please find the attached qualitative examples in the updated version of our paper.	I-Reply	I-2	Reply	64
Please note that providing quantitative measures in our case is not possible as our dataset contains only RGB images and there are no ground truth depth maps available.	I-Reply	I-2	Reply	64
However, you can find the quantitative measures on the test data from the NYU dataset available in [1] that are supposed to be generalizable to unseen images.	I-Reply	I-2	Reply	64
<sep> <sep> [1] Laina, Iro, et al "Deeper depth prediction with fully convolutional residual networks."	O	O	Reply	64
2016 Fourth international conference on 3D vision (3DV).	O	O	Reply	64
IEEE, 2016.	O	O	Reply	64
<sep> <sep> 3.	O	O	Reply	64
To use a siamese (shared weights) feature extractor between RGB and Depth images or not, is not a significant contribution by itself...	O	O	Reply	64
<sep> A3.	B-Reply	B-3	Reply	64
Thank you for pointing this out.	I-Reply	I-3	Reply	64
We considered this a contribution as most state-of-the-art works assume otherwise without providing sufficient experiments on it.	I-Reply	I-3	Reply	64
However, we updated our contributions list to reflect your concern.	I-Reply	I-3	Reply	64
We removed this item as our contributions and only described it briefly in the feature extraction section.	I-Reply	I-3	Reply	64
<sep> <sep> Minor Comments:	O	O	Reply	64
<sep> 1.	O	O	Reply	64
Figure 2 seems to indicate that a Faster-RCNN is used on both RGB and Depth steams which is backed up by text in Section 2 (first paragraph)...	O	O	Reply	64
<sep> A1.	O	O	Reply	64
We did not aim to indicate that.	B-Reply	B-4	Reply	64
Please note that Faster-RCNN has the region proposal networks and the network we apply to depth stream in Figure 2 has only a feature extractor (ResNet18 in this case).	I-Reply	I-4	Reply	64
As shown in the RGB stream, RPN (from Faster R-CNN) is only applied to RGB images and the extracted regions are also used to provide bounding boxes for the depth maps (also explained in the mentioned paragraph).	I-Reply	I-4	Reply	64
<sep> <sep> <sep> 2.	O	O	Reply	64
The VGG-16 network is pre-trained in ImageNet and finetuned to relevant data but it is not clear for what task?	O	O	Reply	64
If the task is object detection, it needs to be trained for it (not fine-tuned, unless it is being initialized from COCO pre-training)...	O	O	Reply	64
<sep> A2.	B-Reply	B-5	Reply	64
This is pre-trained for object detection and fine-tuned for predicate prediction.	I-Reply	I-5	Reply	64
We appreciate your comment.	I-Reply	I-5	Reply	64
We made it clearer in the paper.	I-Reply	I-5	Reply	64
<sep> <sep> 3.	O	O	Reply	64
The AlexNet-BN depth model is trained for relation detection using only depth.	O	O	Reply	64
But it is not clear if it is using proposals/boxes generated by RGB detection model or using ground-truth boxes.	O	O	Reply	64
Basically, the object-detection component of the pipeline is not clear at all.	O	O	Reply	64
<sep> <sep> A3.We use the ground-truth bounding boxes.	B-Reply	B-6	Reply	64
During training, using noisy proposals from RGB detection would be sub-optimal (specially under predicate prediction setting).	I-Reply	I-6	Reply	64

This paper proposes to leverage the depth information for relation prediction, arguing that the depth information benefit the prediction of some predicates.	O	O	Review	64
To solve the lack of 3D data, an RGB-to-Depth model is trained on external available dataset and then applied to images from visual relation dataset.	O	O	Review	64
In the experiments, they investigate different strategies to extract features from depth maps and the explore effectiveness of depth information by comparing the model that only used depth map as input with those which use RGB information.	O	O	Review	64
The comparisons with other methods and ablation studies under both Zero-shot setting and normal setting demonstrate the effectiveness of depth information.	O	O	Review	64
<sep> <sep> +Strength:	O	O	Review	64
(1) The motivation is reasonable and what the authors make an attempt to explore is very meaningful.	O	O	Review	64
Visual relation especially the spatial relation is not likely to be predicted accurately without 3D information.	O	O	Review	64
In other words, it seems that visual relation prediction task will be extended to 3D images rather than staying within 2D images.	O	O	Review	64
Thus what the authors do is a good exploration for further extensions.	O	O	Review	64
<sep> (2) Comparisons with previous methods and the results show that the depth information is useful to some extent, but not so obvious.	O	O	Review	64
<sep> (3) The writing of this article is good and it‚Äôs very easy to understand.	O	O	Review	64
<sep> <sep> -Weakness:	O	O	Review	64
(1) The RGB-to-Depth Network is pretrained on other dataset.	B-Review	B-1	Review	64
Is there any gap when it is used for VG or VRD dataset?	I-Review	I-1	Review	64
<sep> (2) Although the depth map feature extraction seems to work well, it seems to be a little trivial.	B-Review	B-2	Review	64
Why a CNN, e.g. AlexNet, or VGG, can be used to extract depth features?	I-Review	I-2	Review	64
And why the AlexNet trained from scratch performs better than AlexNet pretrained on RGB images for object detection task and VGG net?	B-Review	B-2	Review	64
If the author can give more explanations, this part will be more insightful.	I-Review	I-2	Review	64
<sep> (3) From the plot which shows the top 10 percent absolute changes in prediction performance per predicate, the advantage of Depth is not obvious compared with RGB.	B-Review	B-3	Review	64
And Depth does not bring the advantage claimed in Abstract.	I-Review	I-3	Review	64
It‚Äôs a little hard to understand why depth information can rectify the prediction of (Tower, taller, trees).	I-Review	I-3	Review	64
To sum up, the qualitative results are not so satisfying.	I-Review	I-3	Review	64
<sep> (4) In Table 1, what really functions seems to be c_so, v_so, and l_so, while the improvement brought by depth is limited.	B-Review	B-4	Review	64
Q1.	O	O	Reply	64
The RGB-to-Depth Network is pre-trained on other dataset.	O	O	Reply	64
Is there any gap when it is used for VG or VRD dataset?	O	O	Reply	64
<sep> <sep> A1.	O	O	Reply	64
Thank you very much for your constructive feedback.	B-Reply	B-1	Reply	64
Please note that we are interested in the role that depth maps can play in relation detection and evaluating the generalizability power of an RGB-to-Depth model from one dataset to another, is not the focus of our research work.	I-Reply	I-1	Reply	64
Nevertheless, we updated our paper to provide samples of the generated depth maps from our datasets, as a qualitative measure.	I-Reply	I-1	Reply	64
Please note that providing quantitative measures in our case is not possible as our dataset contains only RGB images and there are no ground truth depth maps available.	I-Reply	I-1	Reply	64
However, you can find the quantitative measures on the test data from NYU dataset available in [1] that are supposed to be generalizable to unseen examples.	I-Reply	I-1	Reply	64
<sep> <sep> [1] Laina, Iro, et al "Deeper depth prediction with fully convolutional residual networks."	O	O	Reply	64
2016 Fourth international conference on 3D vision (3DV).	O	O	Reply	64
IEEE, 2016.	O	O	Reply	64
<sep> <sep> Q2.1.	O	O	Reply	64
Although the depth map feature extraction seems to work well, it seems to be a little trivial.	O	O	Reply	64
Why a CNN, e.g. AlexNet, or VGG, can be used to extract depth features?	O	O	Reply	64
<sep> <sep> A2.1.	B-Reply	B-2	Reply	64
Thanks for the interesting question.	I-Reply	I-2	Reply	64
Please note that we only use the architectural design of AlexNet (VGG or ResNet18) and train the weights of the network from scratch.	I-Reply	I-2	Reply	64
Any other CNN architecture would make a good feature extractor for depth maps as (similar to RGB images), in depth maps: 1) there is high covariance within the local neighborhood which diminishes with distance and 2) the statistics are mostly stationary across the depth maps.	I-Reply	I-2	Reply	64
CNNs are designed with the imposed inductive bias of locality and translation invariance which perfectly exploits such characteristics of the input domain[1].	I-Reply	I-2	Reply	64
<sep> [1] Battaglia, Peter W., et al "Relational inductive biases, deep learning, and graph networks."	O	O	Reply	64
arXiv preprint arXiv:1806.01261 (2018).	O	O	Reply	64
<sep> <sep> Q2.2.	O	O	Reply	64
And why the AlexNet trained from scratch performs better than AlexNet pre-trained on RGB images for object detection task and VGG net?	O	O	Reply	64
If the author can give more explanations, this part will be more insightful.	O	O	Reply	64
<sep> <sep> A2.2 This has been discussed briefly in Section 2.1.2.	B-Reply	B-2	Reply	64
While RGB and depth maps share some characteristics (mentioned above) that make them good candidates for CNN-based feature extraction, they are still different modalities representing different information and even having a different pixel range.	I-Reply	I-2	Reply	64
Therefore, sharing the same CNN weights between them would be sup-optimal.	I-Reply	I-2	Reply	64
We can elaborate more on this within the text.	I-Reply	I-2	Reply	64
<sep> <sep> Q3.	O	O	Reply	64
From the plot which shows the top 10 percent absolute changes in prediction performance per predicate, the advantage of Depth is not obvious compared with RGB.	O	O	Reply	64
And Depth does not bring the advantage claimed in Abstract.	O	O	Reply	64
It‚Äôs a little hard to understand why depth information can rectify the prediction of (Tower, taller, trees).	O	O	Reply	64
To sum up, the qualitative results are not so satisfying.	O	O	Reply	64
<sep> <sep> A3.	B-Reply	B-3	Reply	64
Thanks for pushing us towards more clarity.	I-Reply	I-3	Reply	64
You are right.	I-Reply	I-3	Reply	64
One of the points we wanted to make here was that improvements in under-represented predicates do not get reflected within the overall R@K. To address your concern regarding this, instead of only providing qualitative reports, we now report the result using a better quantitative metric (Macro R@K) which computes the R@K for each predicate separately and reports the mean overall.	I-Reply	I-3	Reply	64
Please find these results in the updated version.	I-Reply	I-3	Reply	64
We also further updated the mentioned plot and tried to make it more clear.	I-Reply	I-3	Reply	64
<sep> Regarding the predicate ‚Äútaller‚Äù, we removed this example as we had to remove VRD results for space constraints.	I-Reply	I-3	Reply	64
However, the explanation goes like this: a shorter person standing closer to the camera can look taller than a tall person standing further away (perspective).	I-Reply	I-3	Reply	64
Having access to a depth map helps us tackle this problem.	I-Reply	I-3	Reply	64
<sep> <sep> Q4.	O	O	Reply	64
In Table 1, what really functions seems to be c_so, v_so, and l_so, while the improvement brought by depth is limited.	O	O	Reply	64
<sep> <sep> A4.	B-Reply	B-4	Reply	64
This is a correct observation.	I-Reply	I-4	Reply	64
Please note that the improvement in visual relation detection community are generally in a smaller range, for example, Graph R-CNN improves the previous baseline by 1,5% points and neural motifs improve ‚Äòno context‚Äô baseline by 1,4% points.	I-Reply	I-4	Reply	64
However, to address your concern and shed more light on this, in the updated version of the paper we provided (a) the Macro R@K measure (as mentioned) and (b) a more extensive study on the effect of each feature.	I-Reply	I-4	Reply	64
Please note that the more relations are detected, the harder it gets to gain improvement with other features.	I-Reply	I-4	Reply	64
The same effect happens if we assume having only c, d, l and then add v (please refer to the new ablations).	I-Reply	I-4	Reply	64
In fact, depth maps can be more informative as visual features (l,c,d versus l,c,v).	I-Reply	I-4	Reply	64

<sep> <sep> ********* Post Rebuttal *********	O	O	Review	64
<sep> I appreciate the authors' effort in providing thorough responses and revised manuscript.	O	O	Review	64
<sep> <sep> I agree with the authors that "the finding not being surprising" is not a ground for rejection.	O	O	Review	64
I tried to word my final decision carefully but it seems it has still caused confusion for the authors.	O	O	Review	64
As I have mentioned in my original review, the rating was a result of the 4 points considered *together* .	O	O	Review	64
<sep> <sep> That is, if one exploits privileged information that needs extra sensory data and/or annotation (point 2), *and*, this privileged information is clearly related and thus should be normally useful for the final task (point 1), *and* achieve marginal improvements (point 3), it can be a ground for rejection.	O	O	Review	64
Especially, given that prior works with similar arguments exists (point 4).	O	O	Review	64
<sep> <sep> The rebuttal has alleviated the issue of marginal improvements (point 3) by introducing meanR@K (or as the revised paper refer to it, Macro R@K).	O	O	Review	64
Here, the improvements are more significant both compared to the state of the art and ablated baselines.	O	O	Review	64
<sep> <sep> The authors also argue that the related [Yang et al 2018] paper (point 4) should be considered a concurrent submission since the authors original submission was to AAAI18.	O	O	Review	64
<sep> <sep> The rebuttal also addresses other clarity or experimental issues which improves the quality of the revised work.	O	O	Review	64
<sep> <sep> Finally, I understand that the privileged information is only required during training time which is a good point.	O	O	Review	64
<sep> <sep> All in all, *assuming that [Yang et al 2018] is considered a concurrent work* according to ICLR, I think the revised paper becomes slightly above borderline and thus I change my rating to "weak accept".	B-Review	B-11	Review	64
If [Yang et al 2018] is not considered concurrent work, then, a conclusive comparison is required for the acceptance of the current work.	I-Review	I-11	Review	64
<sep> <sep> <sep> ********* Summary *********	O	O	Review	64
The paper poses the question of whether depth information is informative for visual relationship prediction using still images.	O	O	Review	64
It is intuitive that 3D arrangement of objects in an image can be a useful cue for predicting their relationship.	O	O	Review	64
As such it is important to see whether and to what extent depth information complements RGB information for visual relation detection.	O	O	Review	64
That is the focus of this paper.	O	O	Review	64
<sep> The paper proposes to use an off-the-shelf monocular depth estimation networks to augment the available RGB information towards better visual relation detection.	O	O	Review	64
For that, it proposes a specific network two-stream structure working on RGB image and (predicted) depth image.	O	O	Review	64
The proposed model demonstrates improved results upon state of the art for visual relation prediction.	O	O	Review	64
<sep> <sep> ********* Strengths and Weaknesses *********	O	O	Review	64
+ A comprehensive set of tests has been conducted.	O	O	Review	64
<sep> + Zero-shot prediction results are particularly interesting.	O	O	Review	64
<sep> + The experiment on ranking the predicate classes based on the change in prediction accuracy before and after using depth information (Figure 4) is interesting and intuitive.	O	O	Review	64
<sep> * The final results improve upon the state-of-the-art, especially on the zero-shot learning regime.	B-Review	B-4	Review	64
However, it seems that the improvement is mainly coming from the new architecture as opposed to the inclusion of the depth information.	I-Review	I-4	Review	64
That is, ours_{c,v,l} brings most of the improvement already the last step to ours_{c,v,l,d} is negligible for non-zero-shot case.	I-Review	I-4	Review	64
<sep> - Along the same line, it‚Äôs possible that this small difference between ours_{c,v,l} and ours_{c,v,l,d} for the standard predicate prediction, can be due to a hyper-parameter optimization that is (only or more thoroughly) done for ours_{c,v,l,d}. The hyper-parameter optimization scheme for different baselines is not described.	B-Review	B-5	Review	64
<sep> - Given the small difference of ablation levels, the comparison will be stronger if done multiple times and reporting mean and standard deviation of the results.	B-Review	B-6	Review	64
<sep> - For a fair comparison the visual feature vector v_{so} should be tried as the feature of the union bound box of both subject and object same way as it is done for depth feature vector d_{so}.	B-Review	B-7	Review	64
- The paper refers to ‚ÄúOurs-d‚Äô_{so}‚Äù as a baseline that *only* uses depth information with no image/label information.	B-Review	B-8	Review	64
However, it seems that the region proposals for this feature are coming from the image-based network that uses image information.	I-Review	I-8	Review	64
<sep> - Important related but uncited works:	O	O	Review	64
(1) [‚ÄúVisual Relationship Prediction via Label Clustering and Incorporation of Depth Information‚Äù ECCV workshops 2018] studies the same question as part of their work.	O	O	Review	64
<sep> <sep> ********* Final Decision *********	O	O	Review	64
I do not find the paper passing the acceptance bar mainly due to the following reasons together:	B-Review	B-9	Review	64
1) The finding is not surprising since most of the visual relations are either explicitly depth-related (e.g., behind) or are semantically constrained by depth (e.g. riding cannot happen at different depths when the image is taken orthogonal to the rider).	I-Review	I-9	Review	64
<sep> 2) an additional depth dataset is used which provides the model with privileged information.	I-Review	I-9	Review	64
Should it have been the case that depth information were inferred without an additional offline dataset, the results would have been more interesting.	I-Review	I-9	Review	64
<sep> 3) the improvements due to the additional depth network are not significant or conclusive.	I-Review	I-9	Review	64
<sep> 4) there is a prior uncited work with the same research question for effectiveness of depth information in visual relation detection which uses a similar approach.	I-Review	I-9	Review	64
<sep> <sep> ********* Minor points *********	O	O	Review	64
<sep> - the code is not available.	B-Review	B-10	Review	64
This is especially important since the paper is outperforming prior works which could be a contribution if reproducible.	I-Review	I-10	Review	64
<sep> - Section 2.2: is l_{so} concatenation of l_s and l_o?	I-Review	I-10	Review	64
<sep> - Section 2.2: y_{spo} is defined but never used.	I-Review	I-10	Review	64
<sep> - Equation 2: why do we have both e_p and f in the exponents?	I-Review	I-10	Review	64
Aren‚Äôt they the same?	I-Review	I-10	Review	64
<sep> - Equation 2:  P is never defined.	I-Review	I-10	Review	64
<sep> - Page 5: ‚Äúa fully connected hidden layer of 64, 200, 4096 and 20 neurons‚Äù: this amounts to 3 hidden layers.	I-Review	I-10	Review	64
<sep> - Why VGG network for visual feature and AlexNet for depth features?	I-Review	I-10	Review	64
<sep> - zero-shot learning results on visual genome is missing	I-Review	I-10	Review	64
- training procedure is a bit unclear: the text suggest that the fine tuning and/or learning of the three components might happen separately.	I-Review	I-10	Review	64
It is important to clearly state if they are done in an end-to-end fashion and simultaneously or separately; and why.	I-Review	I-10	Review	64
<sep> - It‚Äôs good to name the method in table 2 in the same fashion as table 1.	I-Review	I-10	Review	64
With the current naming (based on architecture) it is a bit confusing to understand the content without additional cross referencing.	I-Review	I-10	Review	64
For instance AlexNet-BN - Raw seems to correspond to Ours_{c,v,l,d}	I-Review	I-10	Review	64
- Figure 4: the frequency represented as different shades of red or blue is really hard to notice especially on a printed paper.	I-Review	I-10	Review	64
The red vs blue color coding is not necessary since the bars going up or down indicate the same quality.	I-Review	I-10	Review	64
So, it might be better to use red/blue for frequency instead (e.g. dark red high frequency to dark blue low frequency)	I-Review	I-10	Review	64
- Section 3.2: the AlexNet reference seems wrong, it should be "ImageNet Classification with Deep Convolutional Neural Networks" NIPS , 2012	I-Review	I-10	Review	64
- The structure of section 3.5 is currently flat while the content seems to be nested (two experiments and two sets of corresponding discussions).	I-Review	I-10	Review	64
It will read better if they are organized into subsections.	I-Review	I-10	Review	64
<sep> ********* Points of extensions (improvement) *********	O	O	Review	64
<sep> - I believe *unsupervised* discovery of depth information for visual relation detection can be an interesting direction since it is not limited to the availability of relevant depth dataset.	B-Review	B-1	Review	64
<sep> - It is not clearly motivated why one should use two separate networks for depth and RGB inputs in light of the additional complexity.	B-Review	B-2	Review	64
For instance, it is good to discuss what is the advantage of the proposed (computationally more expensive) method over the following two simpler baselines:	I-Review	I-2	Review	64
- Faster RCNN is used on RGBD input to produce a single feature vector	I-Review	I-2	Review	64
- above case with RGB input but have the Faster RCNN predict the depth map as an auxiliary loss.	B-Review	B-3	Review	64
<sep> <sep> <sep> <sep> ********* Points of extensions (improvement) *********	O	O	Reply	64
<sep> Q1.	O	O	Reply	64
I believe *unsupervised* discovery of depth information for visual relation detection can be an interesting direction since it is not limited to the availability of relevant depth dataset.	O	O	Reply	64
<sep> <sep> A1.	O	O	Reply	64
As mentioned in our first comment, unsupervised training of RGB-to-Depth network would mean generating depth maps from RGB images without having access to any external datasets containing corresponding depth maps (as the supervised signal).	B-Reply	B-1	Reply	64
The question is whether it is possible to convert one modality to another without having any parallel data (RGB and corresponding depth maps)?	I-Reply	I-1	Reply	64
We do not see an obvious way how to achieve that (it would be similar to the task of learning a function that generates animal sounds by looking at their images (going from image to sound modality) without having access to any parallel image and sound data).	I-Reply	I-1	Reply	64
<sep> <sep> Q2.	O	O	Reply	64
It is not clearly motivated why one should use two separate networks for depth and RGB inputs in light of the additional complexity.	O	O	Reply	64
For instance, it is good to discuss what is the advantage of the proposed (computationally more expensive) method over the following two simpler baselines:	O	O	Reply	64
- Faster RCNN is used on RGBD input to produce a single feature vector	O	O	Reply	64
<sep> A2.Our focus was not on improving object detection using depth maps which is already a well-explored area.	B-Reply	B-2	Reply	64
Bringing depth to the Faster R-CNN input would mostly affect object detection and we wanted to isolate this effect from visual relation detection.	I-Reply	I-2	Reply	64
Also, in this case, we either need to (1) apply shared weights for RGB and D signals which is not a good idea as discussed in Section 2.1.2 or (2) use separate weights for RGB and Depth maps.	I-Reply	I-2	Reply	64
This would be similar to our current architecture.	I-Reply	I-2	Reply	64
<sep> Q3.	O	O	Reply	64
Above case with RGB input but have the Faster RCNN predict the depth map as an auxiliary loss.	O	O	Reply	64
<sep> A3.	O	O	Reply	64
We cannot use depth maps in the loss function as we do not have access to any ground truth depth maps.	B-Reply	B-3	Reply	64

The paper is an extension of the matching networks by Vinyals et al in NIPS2016.	O	O	Review	414
Instead of using all the examples in the support set during test, the method represents each class by the mean of its learned embeddings.	O	O	Review	414
The training procedure and experimental setting are very similar to the original matching networks.	B-Review	B-1	Review	414
I am not completely sure about its advantages over the original matching networks.	I-Review	I-1	Review	414
It seems to me when dealing with 1-shot case, these two methods are identical since there is only one example seen in this class, so the mean of the embedding is the embedding itself.	B-Review	B-2	Review	414
When dealing with 5-shot case, original matching networks compute the weighted average of all examples, but it is at most 5x cost.	I-Review	I-2	Review	414
The experimental results reported for prototypical nets are only slightly better than matching networks.	B-Review	B-3	Review	414
I  think it is a simple, straightforward,  novel extension, but I am not fully convinced its advantages.	I-Review	I-3	Review	414
We thank Reviewer 2 for reviewing our paper.	O	O	Reply	414
This review‚Äôs main criticism is that our approach is too similar to the matching networks model proposed by Vinyals et al 2016.	O	O	Reply	414
We will update the related work section of our paper to clarify the relationship between prototypical networks and matching nets.	O	O	Reply	414
In the meantime, we would like to take this opportunity to elaborate upon some of the benefits of our approach relative to matching networks: better computational efficiency, a simpler form for the classifier, and a straightforward extension to the zero-shot setting.	O	O	Reply	414
<sep> <sep> First and foremost, prototypical networks are computationally more efficient than matching networks.	B-Reply	B-1	Reply	414
If there are K classes, each with N support examples, then computing distances for a query point will take O(K) time for prototypical networks vs. O(KN) for matching networks.	I-Reply	I-1	Reply	414
This is indeed a 5x speedup for the 5-shot scenario, which though not enormous is also not insignificant.	I-Reply	I-1	Reply	414
Even slightly larger scales such as N=10 or N=100 would lead to useful performance gains.	I-Reply	I-1	Reply	414
We see favorable applications of our approach to tasks such as document tagging where it is important to quickly label new documents without needing to compute distances to multiple support examples per tag.	I-Reply	I-1	Reply	414
<sep> <sep> Second is the simpler expression of our classifier (see Section 3.2 of our paper) compared to the non-parametric form of matching networks.	B-Reply	B-2	Reply	414
Not only does this require less storage (O(K) vs. O(KN)) but it also sets the stage for future work that explores the prediction of alternate classifiers beyond the linear ones we investigate here.	I-Reply	I-2	Reply	414
<sep> <sep> Finally, our approach affords a straightforward extension to the zero-shot setting that matching networks do not.	B-Reply	B-3	Reply	414
The matching networks approach is fundamentally about embedding support examples whereas prototypical networks focuses on learning an embedded representation for each class.	I-Reply	I-3	Reply	414
For the few-shot scenario we chose our representation to be the mean of embedded points, while for the zero-shot scenario we utilized the embedded metadata.	I-Reply	I-3	Reply	414
Such a generalization of the matching networks approach to zero-shot classification does not exist.	I-Reply	I-3	Reply	414

This paper proposes an improved version of matching networks, with better scalability properties with respect to the support set of a few-shot classifier.	O	O	Review	414
Instead of considering each support point individually, they learn an embedding function that aggregates over items of each class within the support set (eq.1).	O	O	Review	414
This is combined with episodic few-shot training with randomly-sampled partitions of the training set classes, so that the training and testing scenarios match closely.	O	O	Review	414
Although the idea is quite straightforward, and there are a great many prior works on zero-shot and few-shot learning, the proposed technique is novel to my knowledge, and achieves state-of-the-art results on several  benchmark datasets.	O	O	Review	414
One addition that I think would improve the paper is a clearer description of the training algorithm (perhaps pseudocode).	O	O	Review	414
In its current form the paper a bit vague about this.	O	O	Review	414
Thanks for taking the time to review our paper.	O	O	Reply	414
Including pseudocode is a valuable suggestion -- we will update the paper to include this.	O	O	Reply	414

*** Paper Summary ***	O	O	Review	414
<sep> This paper simplify matching network by considering only a single prototype per class which is obtained as the average of the embedding of the training class samples.	O	O	Review	414
Empirical comparisons with matching networks are reported.	O	O	Review	414
<sep> <sep> *** Review ***	O	O	Review	414
<sep> The paper reads well and clearly motivate the work.	O	O	Review	414
This work of learning metric learning propose to simplify an earlier work (matching network) which is a great objective.	O	O	Review	414
However, I am not sure it achieve better results than matching networks.	B-Review	B-1	Review	414
The space of learning embeddings to optimize nearest neighbor classification has been explored before, but the idea of averaging the propotypes is interesting (as a non-linear extension of Mensink et al 2013).	I-Review	I-1	Review	414
I would suggest to improve the discussion of related work and to consolidate the results section to help distinguish between the methods you outperform and the one you do not.	I-Review	I-1	Review	414
<sep> <sep> The related work section can be extended to include work on learning distance metric to optimize a nearest neighbor classification, see Weinberger et al, 2005 and subsequent work.	B-Review	B-2	Review	414
Extensions to perform the same task with neural networks can be found in Min et al, 09 that purse a goal very close to yours.	I-Review	I-2	Review	414
Regarding approaches pursuing similar goals with a different learning objective, you cite siamese network with pairwise supervision.	I-Review	I-2	Review	414
The learning to rank (for websearch) litterature with triplet supervision or global ranking losses is also highly relevant, ie.one example "the query" defines the class and the embedding space need to be such that positive/relevant document are closer to the query than the others.	I-Review	I-2	Review	414
I would suggest to start with Chris Burges 2010 tutorial.	I-Review	I-2	Review	414
One learning class	I-Review	I-2	Review	414
<sep> I am not sure the reported results correctly reflect the state of the art for all tasks.	B-Review	B-3	Review	414
The results are positive on Omniglot but I feel that you should also report the better results of matching networks on miniImageNet with fine tuning and full contextual embeddings.	I-Review	I-3	Review	414
It can be considered misleading not to report it.	I-Review	I-3	Review	414
On Cub 200, I thought that the state-of-the-art was 50.1%, when using features from GoogLeNet (Akata et al 2015), could you comment on this?	I-Review	I-3	Review	414
<sep> <sep> Overall, paper could greatly be improved, both in the discussion of related work and with a less partial reporting of prior empirical results.	O	O	Review	414
<sep> <sep> *** References ***	O	O	Review	414
<sep> Large Margin Nearest Neighbors.	O	O	Review	414
Weinberger et al, 2005	O	O	Review	414
From RankNet to LambdaRank to LambdaMART: An Overview, Chris J.C. Burges, June 23, 2010	O	O	Review	414
A Deep Non-linear Feature Mapping for Large-Margin kNN Classification, Min et al, 09	O	O	Review	414
Thank you very much for your review.	O	O	Reply	414
Regarding the CUB result, we ran experiments where we replaced the AlexNet features with GoogLeNet features and obtained a result of 54.6% accuracy (please see Table 3 of our paper revision dated Dec 6, 2016).	B-Reply	B-3	Reply	414
We believe this truly represents the state of the art at this point in time.	I-Reply	I-3	Reply	414
Regarding Omniglot and miniImagenet, we originally reported the non-FCE/fine-tuned matching networks results because we wanted to keep the comparison limited to the basic models themselves.	I-Reply	I-3	Reply	414
However, we agree that we should be thorough in our reporting and will include these results as well.	I-Reply	I-3	Reply	414
<sep> <sep> Regarding the relevant literature, both our model and LMNNs are based on Neighborhood Component Analysis and we believe that our model is more similar to NCA than to LMNN, as we do not use a margin-based loss and do not pre-select a set of target neighbors.	B-Reply	B-2	Reply	414
We believe that our model is closest in spirit to nonlinear NCA (from follow-up work by Salakhutdinov and Hinton, 2007).	I-Reply	I-2	Reply	414
We are certainly happy to include your provided references from the metric learning literature as they are indeed relevant.	I-Reply	I-2	Reply	414
We will also include a reference to the learning to rank literature as it relates to siamese networks, although we feel that this criticism applies to the current one-shot learning literature as opposed to just our paper.	I-Reply	I-2	Reply	414

The paper discusses the problem of optimizing neural networks with hard threshold and proposes a novel solution to it.	O	O	Review	414
The problem is of significance because in many applications one requires deep networks which uses reduced computation and limited energy.	O	O	Review	414
The authors frame the problem of optimizing such networks to fit the training data as a convex combinatorial problems.	O	O	Review	414
However since the complexity of such a problem is exponential, the authors propose a collection of heuristics/approximations to solve the problem.	O	O	Review	414
These include, a heuristic for setting the targets at each layer, using a soft hinge loss, mini-batch training and such.	O	O	Review	414
Using these modifications the authors propose an algorithm (Algorithm 2 in appendix) to train such models efficiently.	O	O	Review	414
They compare the performance of a bunch of models trained by their algorithm against the ones trained using straight-through-estimator (SSTE) on a couple of datasets, namely, CIFAR-10 and ImageNet.	O	O	Review	414
They show superiority of their algorithm over SSTE.	O	O	Review	414
<sep> <sep> I thought the paper is very well written and provides a really nice exposition of the problem of training deep networks with hard thresholds.	O	O	Review	414
The authors formulation of the problem as one of combinatorial optimization and proposing Algorithm 1 is also quite interesting.	O	O	Review	414
The results are moderately convincing in favor of the proposed approach.	O	O	Review	414
Though a disclaimer here is that I'm not 100% sure that SSTE is the state of the art for this problem.	B-Review	B-5	Review	414
Overall i like the originality of the paper and feel that it has a potential of reasonable impact within the research community.	O	O	Review	414
<sep> <sep> There are a few flaws/weaknesses in the paper though, making it somewhat lose.	O	O	Review	414
<sep> - The authors start of by posing the problem as a clean combinatorial optimization problem and propose Algorithm 1.	B-Review	B-1	Review	414
Realizing the limitations of the proposed algorithm, given the assumptions under which it was conceived in, the authors relax those assumptions in the couple of paragraphs before section 3.1 and pretty much throw away all the nice guarantees, such as checks for feasibility, discussed earlier.	I-Review	I-1	Review	414
<sep> - The result of this is another algorithm (I guess the main result of the paper), which is strangely presented in the appendix as opposed to the main text, which has no such guarantees.	B-Review	B-2	Review	414
- There is no theoretical proof that the heuristic for setting the target is a good one, other than a rough intuition	B-Review	B-3	Review	414
- The authors do not discuss at all the impact on generalization ability of the model trained using the proposed approach.	B-Review	B-4	Review	414
The entire discussion revolves around fitting the training set and somehow magically everything seem to generalize and not overfit.	I-Review	I-4	Review	414
<sep> <sep> Thank you for your review.	O	O	Reply	414
We respond to each of your questions and comments below.	O	O	Reply	414
<sep> <sep> Based on the quantization literature and other hard-threshold papers that we looked at and cited, SSTE is (by far) the most widely used method.	B-Reply	B-5	Reply	414
It‚Äôs true that there are many variations of the straight-through estimator (STE), but we compare to the main one (SSTE), and don‚Äôt know of any that outperform SSTE.	I-Reply	I-5	Reply	414
Note that neither STE nor SSTE has convergence guarantees (they‚Äôre biased estimators) but SSTE at least works well in practice.	I-Reply	I-5	Reply	414
<sep> <sep> While we agree that it would be nice to have better guarantees for FTPROP-MB, it is typical in AI and combinatorial search (as you likely know) to start from a theoretically-justified approach and then use that to define a more heuristic approach that sacrifices those guarantees in favor of efficiently achieving the desired property (i.e., feasibility), as we do here.	B-Reply	B-1	Reply	414
Since the problem we are solving is NP-complete and (most likely) hard to approximate, heuristics are unavoidable.	I-Reply	I-1	Reply	414
By using the (soft) hinge loss at each layer, FTPROP-MB is implicitly trying to maximize ‚Äúsoft feasibility‚Äù of the network because of the correspondence between the hinge loss and margin maximization.	I-Reply	I-1	Reply	414
<sep> <sep> Further, while feasibility is important for understanding the solution we propose, giving it up is necessary to avoid overfitting.	I-Reply	I-1	Reply	414
This is similar to the linear-separability property of the perceptron where the robust method for learning a perceptron is to use a hinge loss instead of the perceptron criterion.	I-Reply	I-1	Reply	414
We intend to further study the properties of FTPROP and (soft) feasibility in the future.	I-Reply	I-1	Reply	414
<sep> <sep> We did not put the FTPROP-MB pseudocode in the main paper because it‚Äôs such a simple algorithm and we were running short on space, but we can move it to the main body.	I-Reply	I-1	Reply	414
<sep> <sep> Space limitations also precluded further discussions of generalization ability.	B-Reply	B-2	Reply	414
We used standard approaches to avoid overfitting (L2 regularization, mini-batching, hinge vs. perceptron criterion, etc.),	I-Reply	I-2	Reply	414
which we mention in the paper (but can make more clear) and which account for the good generalization performance.	I-Reply	I-2	Reply	414

The paper studies learning in deep neural networks with hard activation functions, e.g. step functions like sign(x).	O	O	Review	414
Of course, backpropagation is difficult to adapt to such networks, so prior work has considered different approaches.	O	O	Review	414
Arguably the most popular is straight-through estimation (Hinton 2012, Bengio et al 2013), in which the activation functions are simply treated as identity functions during backpropagation.	O	O	Review	414
More recently, a new type of straight-through estimation, saturated STE (Hubara et al 2016) uses 1[|z|<1] as the derivative of sign(z).	O	O	Review	414
<sep> <sep> The paper generalizes saturated STE by recognizing that other discrete targets of each activation layer can be chosen.	O	O	Review	414
Deciding on these targets is formulated as a combinatorial optimization problem.	O	O	Review	414
Once the targets are chosen, updating the weights of each layer to minimize the loss on those targets is a convex optimization.	O	O	Review	414
The targets are heuristically updated through the layers, starting out the output using the proposed feasibility target propagation.	O	O	Review	414
At each layer, the targets can be chosen using a variety of search algorithms such as beam search.	O	O	Review	414
<sep> <sep> Experiments show that FTP often outperforms saturated STE on CIFAR and ImageNet with sign and quantized activation functions, reaching levels of performance closer to the full-precision activation networks.	O	O	Review	414
<sep> <sep> This paper's ideas are very interesting, exploring an alternative training method to backpropagation that supports hard-threshold activation functions.	O	O	Review	414
The experimental results are encouraging, though I have a few questions below that prevent me for now from rating the paper higher.	O	O	Review	414
<sep> <sep> Comments and questions:	O	O	Review	414
<sep> 1) How computationally expensive is FTP?	B-Review	B-1	Review	414
The experiments using ResNet indicate it is not prohibitively expensive, but I am eager for more details.	I-Review	I-1	Review	414
<sep> <sep> 2) Does (Hubara et al 2016) actually compare their proposed saturated STE with the orignal STE on any tasks?	B-Review	B-2	Review	414
I do not see a comparison.	I-Review	I-2	Review	414
If that is so, should this paper also compare with STE?	I-Review	I-2	Review	414
How do we know if generalizing saturated STE is more worthwhile than generalizing STE?	I-Review	I-2	Review	414
<sep> <sep> 3) It took me a while to understand the authors' subtle comparison with target propagation, where they say "Our framework can be viewed as an instance of target propagation that uses combinatorial optimization to set discrete targets, whereas previous approaches employed continuous optimization."	B-Review	B-3	Review	414
It seems that the difference is greater than explicitly stated, that prior target propagation used continuous optimization to set *continuous targets*. (One could imagine using continuous optimization to set discrete targets such as a convex relaxation of a constraint satisfaction problem.)	I-Review	I-3	Review	414
Focusing on discrete targets gains the benefits of quantized networks.	I-Review	I-3	Review	414
If I am understanding the novelty correctly, it would strengthen the paper to make this difference clear.	I-Review	I-3	Review	414
<sep> <sep> 4) On a related note, if feasible target propagation generalizes saturated straight through estimation, is there a connection between (continuous) target propagation and the original type of straight through estimation?	B-Review	B-4	Review	414
<sep> <sep> 5) In Table 1, the significance of the last two columns is unclear.	B-Review	B-5	Review	414
It seems that ReLU and Saturated ReLU are included to show the performance of networks with full-precision activation functions (which is good).	I-Review	I-5	Review	414
I am unclear though on why they are compared against each other (bolding one or the other) and if there is some correspondence between those two columns and the other pairs, i.e., is ReLU some kind of analog of SSTE and Saturated ReLU corresponds to FTP-SH somehow?	I-Review	I-5	Review	414
Thank you for your review.	O	O	Reply	414
We respond to each of your questions below.	O	O	Reply	414
<sep> <sep> 1) FTP-SH is no more expensive than backprop (in the same way that SSTE isn‚Äôt either, and SSTE is a special case of FTPROP-MB).	B-Reply	B-1	Reply	414
The only added cost is that the soft hinge loss requires computing an exponential, which is slower than a max (i.e., the cost of computing a sigmoid vs. a ReLU), but this is a minor difference in compute time.	I-Reply	I-1	Reply	414
<sep> <sep> 2) In the experiments, Hubara et al (2016) does not compare SSTE and STE directly, but in the text of the paper they report that ‚ÄúNot [saturating] the gradient when [the input] is too large significantly worsens performance.	B-Reply	B-2	Reply	414
‚Äù This is also what we found in preliminary experiments, where the unsaturated STE is significantly worse than STE.	I-Reply	I-2	Reply	414
Note, however, that STE is also a special case of our framework where the loss function is just loss(z, t) = -zt, so we generalize that as well (and pretty much any type of STE can be obtained by choosing different losses in our framework).	I-Reply	I-2	Reply	414
<sep> <sep> 3) Yes, this is a good point and correct.	B-Reply	B-3	Reply	414
We will update the paper to make this fact more clear.	I-Reply	I-3	Reply	414
Thank you.	I-Reply	I-3	Reply	414
<sep> <sep> 4) It‚Äôs possible, although if so it‚Äôs not an obvious connection, and we haven‚Äôt studied this issue in detail yet.	B-Reply	B-4	Reply	414
<sep> <sep> 5) Yes, good point.	B-Reply	B-5	Reply	414
This is somewhat confusing, and we will clarify it in the paper and remove the bolding, since the goal isn‚Äôt really to compare them against each other (although it is mildly interesting that saturating the ReLU improves performance in some cases).	I-Reply	I-5	Reply	414
There is no correspondence between those two columns and the other pairs; the formatting of the table is just unclear.	I-Reply	I-5	Reply	414

* Summary:	O	O	Review	414
The paper introduces a novel tensor decomposition that is reminiscent of canonical decomposition (CP) with low-rank factors, based on the observation that the core tensor in Tucker decomposition can be decomposed, resulting in a model interpolating between CP and Tucker.	O	O	Review	414
The authors argue that a straight application of AdaGrad on this decomposition is inadequate, and propose Ada^{imp} algorithm that enforces rotation invariance of the gradient update.	O	O	Review	414
The new decomposition is applied to ComplEx model (called PComplEx) that demonstrates better performance than the baseline.	O	O	Review	414
<sep> <sep> * Comments:	O	O	Review	414
Although the approach is well motivated, the paper has many ambiguities that need to better clarification.	O	O	Review	414
<sep> 1.	O	O	Review	414
Tucker decomposition results in lower dimension factors, "d" in the paper.	B-Review	B-1	Review	414
So the resulting core tensor is of size (d \times d \times d).	I-Review	I-1	Review	414
However, this core tensor is further decomposed with a rank-D CP as shown in Section 3, where D &gt;= d. Basically, first the original tensor is factored into lower rank d, and the core tensor is then expanded into rank D &gt;= d. The reader did not understand what is the justification for this approach?	I-Review	I-1	Review	414
Please provide further explanation on this part.	I-Review	I-1	Review	414
<sep> 2.	B-Review	B-2	Review	414
The confusion of P_2 and P_3 terms in the paper.	I-Review	I-2	Review	414
At the beginning of Section 3, P_2 is assumed to be identity through out the paper.	I-Review	I-2	Review	414
But P_2 is mentioned to have specific attributes in other parts of the paper, such as in the second paragraph from the bottom of page 4, the first paragraph and first equation on page 5.	I-Review	I-2	Review	414
And P_2 does not appear in AdaGrad algorithm.	I-Review	I-2	Review	414
<sep> 3.	O	O	Review	414
The experiment is lacking.	B-Review	B-3	Review	414
First, the paper does not explain the meaning of evaluation metrics.	I-Review	I-3	Review	414
Second, the authors do not provide an insight, why PComplEx is better than the ComplEx baseline on SVO dataset, but performs similarly on other datasets.	I-Review	I-3	Review	414
Which factors lead to such improvement?	I-Review	I-3	Review	414
<sep> 4.	B-Review	B-4	Review	414
The comparison to other state-of-the-arts is inadequate, each compared method only has one or few configurations in terms of number of parameters.	I-Review	I-4	Review	414
<sep> <sep> Overall the proposed decomposition method might have significant contribution to research progress in this field, but the paper fails to convince the reader of its significance.	O	O	Review	414
I feel the paper should be overhauled.	O	O	Review	414
1.	O	O	Reply	414
Tucker decomposition results in lower dimension factors, "d" in the paper.	O	O	Reply	414
So the resulting core tensor is of size (d \times d \times d).	O	O	Reply	414
However, this core tensor is further decomposed with a rank-D CP as shown in Section 3, where D &gt;= d. Basically, first the original tensor is factored into lower rank d, and the core tensor is then expanded into rank D &gt;= d. The reader did not understand what is the justification for this approach?	O	O	Reply	414
Please provide further explanation on this part.	O	O	Reply	414
<sep> <sep> ‚Üí We start from a tensor of size n x n x p. A Tucker decomposition of rank d leads to :	B-Reply	B-1	Reply	414
d x (n +n + p) parameters for the factors and d x d x d parameters for the core tensor.	I-Reply	I-1	Reply	414
<sep> In order to link this decomposition with the CP decomposition which is easier to optimize, we further decompose this core tensor with a CP decomposition of rank D. Thus, d x d x d parameters become d x (D + D + D) (which is smaller than d x d x d as long as D &lt; d^2/3).	I-Reply	I-1	Reply	414
<sep> We allow D &gt; d because a tensor of shape d x d x d can have a CP rank as high as d^2.	I-Reply	I-1	Reply	414
<sep> <sep> <sep> 2.	O	O	Reply	414
The confusion of P_2 and P_3 terms in the paper.	O	O	Reply	414
At the beginning of Section 3, P_2 is assumed to be identity through out the paper.	O	O	Reply	414
But P_2 is mentioned to have specific attributes in other parts of the paper, such as in the second paragraph from the bottom of page 4, the first paragraph and first equation on page 5.	O	O	Reply	414
And P_2 does not appear in AdaGrad algorithm.	O	O	Reply	414
<sep> ‚Üí There is indeed a confusion between P_2 and P_3 in the paper,  we thank the reviewer for pointing this out.	B-Reply	B-2	Reply	414
Since P_2 is assumed to be the identity, it should not appear in the paper outside of the definition of CPT (beginning of Section 3).	I-Reply	I-2	Reply	414
All further occurrences of P_2 are typos and have been fixed in the revision.	I-Reply	I-2	Reply	414
<sep> <sep> 3.	O	O	Reply	414
The experiment is lacking.	O	O	Reply	414
First, the paper does not explain the meaning of evaluation metrics.	O	O	Reply	414
Second, the authors do not provide an insight, why PComplEx is better than the ComplEx baseline on SVO dataset, but performs similarly on other datasets.	O	O	Reply	414
Which factors lead to such improvement?	O	O	Reply	414
<sep> ‚Üí Regarding evaluation metrics, we have added the definition of the mean reciprocal rank and hits@5% in Appendix 9.11.	B-Reply	B-3	Reply	414
We attribute the difference in performance on SVO to a difference in the underlying structure of the data that makes Tucker decomposition particularly suited.	I-Reply	I-3	Reply	414
Similarly to MurP being better on WN18RR than on FB237, it is possible that SVO is a dataset that is more amenable to a Tucker decomposition.	I-Reply	I-3	Reply	414
<sep> <sep> 4.The comparison to other state-of-the-arts is inadequate, each compared method only has one or few configurations in terms of number of parameters.	O	O	Reply	414
<sep> ‚Üí We performed new experiments.	B-Reply	B-4	Reply	414
Please, see the general comments.	I-Reply	I-4	Reply	414

The authors present a new way of decomposing 3-order tensors which uses interpolation	O	O	Review	414
between the Tucker and CP decompositions, called CPT.	O	O	Review	414
The main idea is to present the components of the CP model	O	O	Review	414
with an additional low-rank structure.	O	O	Review	414
<sep> The authors also provide a new optimization algorithm called ADA-imp, for learning this decomposition,	O	O	Review	414
which is a variant of Adagrad adapted to their settings.	O	O	Review	414
<sep> The paper is overall interesting, clearly written and well-motivated.	O	O	Review	414
<sep> The mathematical derivations are, as far as I could follow, correct and non-trivial. &	O	O	Review	414
nbsp;(I did not read all the details in the Appendix).	O	O	Review	414
<sep> The authors also show favorable experimental results on two knowledge-base datasets, with improved loss vs. #parameter used tradeoff.	O	O	Review	414
<sep> A few unclear issues and suggestions for improvements are below.	O	O	Review	414
<sep> <sep> The authors present the problem as completion of a binary 3-order tensor, i.e. predicting for triplets (subject, predicate, ?)	B-Review	B-1	Review	414
if '?'	I-Review	I-1	Review	414
refers to 0 or 1.	I-Review	I-1	Review	414
<sep> But they also write 'we formulate this problem as a multi-class classification problem, where the classes are the entities of the knowledge base' &nbsp;- so this is not a binary problem?	I-Review	I-1	Review	414
does this mean there is some structure that must be present in the tensor? (	I-Review	I-1	Review	414
e.g. there is exactly one '1' in each column of length N?	I-Review	I-1	Review	414
This should be clarified.	I-Review	I-1	Review	414
<sep> <sep> It would be good to make the description of Algorithms 1 and 2 more precise and detailed.	B-Review	B-2	Review	414
<sep> For example, the operation/algorithm AdaGrad(\eta;w_k; g_k;G_k) is not defined.	I-Review	I-2	Review	414
AdaGrad is described in the Appendix but it is hard to match it to get the precise operation used in Algorithm 1.	I-Review	I-2	Review	414
<sep> Algorithm 1 shows one step of PComplEx, and it would be good to add the entire PComplEx algorithm, with input,output&amp;parameters.	I-Review	I-2	Review	414
<sep> <sep> The authors present their method in the context of knowledge base completion, thus for tensors of order 3, but it is not clear if any of the components they proposed indeed specialized for this problem, or is it a contribution to general tensor decomposition.	B-Review	B-3	Review	414
Some remarks regarding the (in?)applicability of the method more generally would be helpful.	I-Review	I-3	Review	414
<sep> <sep> Figure 3 describing the experimental results should be explained better.	B-Review	B-4	Review	414
There are few methods shown only in some of the graphs and only for some parameter values - why?	I-Review	I-4	Review	414
<sep> The complexity measure 'parameters-per-entity' should be clearly defined (I didn't find it in the text).	I-Review	I-4	Review	414
Similarly, the performance measures 'mean reciprocal rank' and 'hits at 5%'	I-Review	I-4	Review	414
should be defined in terms of the tensor.	I-Review	I-4	Review	414
<sep> The authors should also add running times of the different experiments and methods.	I-Review	I-4	Review	414
<sep> <sep> <sep> Minor:	O	O	Review	414
--------	O	O	Review	414
In the main paper, the authors define an (N,L,N) tensor, but in the appendix Section 9.9 they list N and P. Does P refer to L here?	B-Review	B-5	Review	414
<sep> <sep> The authors mention a few times usage of 'deep-learning techniques' - but I believe that in at least some of the contexts, they refer to optimization methods which are typically used in deep learning, and &nbsp;are applied here to train other models presented in the text, and not to the usage of actual deep learning architectures - this is confusing and should be clarified.	B-Review	B-6	Review	414
<sep> <sep> Page 7, top: what are the matrices M^(1), M^(2), M^(3)?	B-Review	B-7	Review	414
they seem to be different for different decompositions &nbsp;	I-Review	I-7	Review	414
<sep> <sep> The authors present the problem as completion of a binary 3-order tensor, i.e. predicting for triplets (subject, predicate, ?)	O	O	Reply	414
if '?'	O	O	Reply	414
refers to 0 or 1.	O	O	Reply	414
But they also write 'we formulate this problem as a multi-class classification problem, where the classes are the entities of the knowledge base' - so this is not a binary problem?	O	O	Reply	414
does this mean there is some structure that must be present in the tensor? (	O	O	Reply	414
e.g. there is exactly one '1' in each column of length N?	O	O	Reply	414
This should be clarified.	O	O	Reply	414
<sep> ‚Üí Despite the ground truth tensor being binary, the evaluation of choice in this field is done by ranking.	B-Reply	B-1	Reply	414
Hence, the estimate we learn is a tensor of scores for each triple (subject, predicate, object).	I-Reply	I-1	Reply	414
This does not assume any particular structure on the columns (mode-3 fibers in our case).	I-Reply	I-1	Reply	414
We use the cross-entropy as a surrogate for the ranking loss : if there are several ones in a fiber of the ground truth tensor our model should learn a uniform distribution over these objects.	I-Reply	I-1	Reply	414
<sep> <sep> It would be good to make the description of Algorithms 1 and 2 more precise and detailed.	O	O	Reply	414
For example, the operation/algorithm AdaGrad(\eta;w_k; g_k;G_k) is not defined.	O	O	Reply	414
AdaGrad is described in the Appendix but it is hard to match it to get the precise operation used in Algorithm 1.	O	O	Reply	414
Algorithm 1 shows one step of PComplEx, and it would be good to add the entire PComplEx algorithm, with input, output &amp; parameters.	O	O	Reply	414
<sep> ‚Üí We added the full algorithm in the supplementary materials. (	B-Reply	B-2	Reply	414
Appendix 9.6).	I-Reply	I-2	Reply	414
<sep> <sep> The authors present their method in the context of knowledge base completion, thus for tensors of order 3, but it is not clear if any of the components they proposed indeed specialized for this problem, or is it a contribution to general tensor decomposition.	O	O	Reply	414
Some remarks regarding the (in?)applicability of the method more generally would be helpful.	O	O	Reply	414
<sep> ‚Üí No component of ADA^imp is specialized to tensors of order 3 and could be readily re-used for tensors of higher order.	B-Reply	B-3	Reply	414
We present it here for the order 3 due to the application we target, for which adaptive algorithms (Adagrad / Adam) seems to be critical.	I-Reply	I-3	Reply	414
<sep> <sep> Figure 3 describing the experimental results should be explained better.	O	O	Reply	414
There are few methods shown only in some of the graphs and only for some parameter values - why?	O	O	Reply	414
<sep> ‚Üí This issue is addressed in the general comment.	B-Reply	B-4	Reply	414
<sep> <sep> The complexity measure 'parameters-per-entity' should be clearly defined (I didn't find it in the text).	O	O	Reply	414
<sep> ‚Üí Parameters per entity are the total amount of parameters divided by the total number of entities.	B-Reply	B-4	Reply	414
Precise formulas for each method has been added in the supplementary (Appendix 9.11).	I-Reply	I-4	Reply	414
<sep> Similarly, the performance measures 'mean reciprocal rank' and 'hits at 5%' should be defined in terms of the tensor.	O	O	Reply	414
<sep> ‚Üí We added the precise definition of these metrics in the supplementary materials. (	B-Reply	B-4	Reply	414
Appendix 9.11)	I-Reply	I-4	Reply	414
<sep> The authors should also add running times of the different experiments and methods.	O	O	Reply	414
<sep> ‚Üí Running times as well as a convergence curve have been added in the supplementary materials (Appendix 9.12).	B-Reply	B-4	Reply	414
<sep> <sep> Minor: In the main paper, the authors define an (N,L,N) tensor, but in the appendix Section 9.9 they list N and P. Does P refer to L here?	O	O	Reply	414
<sep> ‚Üí yes sorry.	B-Reply	B-5	Reply	414
This is fixed in the revision	I-Reply	I-5	Reply	414
<sep> The authors mention a few times usage of 'deep-learning techniques' - but I believe that in at least some of the contexts, they refer to optimization methods which are typically used in deep learning, and are applied here to train other models presented in the text, and not to the usage of actual deep learning architectures - this is confusing and should be clarified.	O	O	Reply	414
<sep> ‚ÜíDeep learning techniques here refer specifically to dropout, batch-normalization and learning rate annealing.	B-Reply	B-6	Reply	414
This is clarified in the revision.	I-Reply	I-6	Reply	414
<sep> <sep> Page 7, top: what are the matrices M^(1), M^(2), M^(3)?	O	O	Reply	414
they seem to be different for different decompositions	O	O	Reply	414
‚Üí Indeed.	B-Reply	B-7	Reply	414
M^(1) is UP_1 for PCP, but U for CP or UPi_1 for PCP_full.	I-Reply	I-7	Reply	414
<sep> Since all these methods compute their final score in a CP fashion, we study the gradient with respect to the CP "factors" which are computed differently for different methods.	I-Reply	I-7	Reply	414

In this paper, a tensor decomposition method is studied for link prediction problems.	O	O	Review	414
The model is based on Tucker decomposition but the core tensor is decomposed as CP decomposition so that it can be seen as an interpolation between Tucker and CP.	O	O	Review	414
The performance is evaluated with several NLP data sets (e.g., subject-verb-object triplets).	O	O	Review	414
<sep> <sep> Although the entire idea is interesting, the current form of the paper is not sufficient for acceptance.	O	O	Review	414
The main reasons are (A) the proposed model is not completely novel and (B) the empirical results are not significant.	O	O	Review	414
<sep> <sep> (A) The idea of combining CP and Tucker is not new.	B-Review	B-1	Review	414
For example, Tomioka et al (2010; Section 3.4) considered the Tucker-CP patterns (CP decomposition of the Tucker core).	I-Review	I-1	Review	414
Although they used the Tucker-CP model to improve the interpretability rather than link prediction, the paper needs to make some attribution to the prior work.	I-Review	I-1	Review	414
<sep> <sep> (B) By looking Figure 3, the proposed method, PComplEx, is not significantly better than the existing methods such as ComplEx.	B-Review	B-2	Review	414
Except SVO data, PComplEx and ComplEx share almost the same performance curve.	I-Review	I-2	Review	414
Also, other existing methods such as TuckER and MurP are evaluated only in a few points while (P)ComplEx is evaluated in many points.	I-Review	I-2	Review	414
I feel this is unfair.	I-Review	I-2	Review	414
<sep> <sep> Tomioka, R., Hayashi, K., &amp; Kashima, H. (2010).	O	O	Review	414
Estimation of low-rank tensors via convex optimization.	O	O	Review	414
arXiv preprint arXiv:1010.0789.	O	O	Review	414
(A) The idea of combining CP and Tucker is not new.	B-Reply	B-1	Reply	414
For example, Tomioka et al (2010; Section 3.4) considered the Tucker-CP patterns (CP decomposition of the Tucker core).	I-Reply	I-1	Reply	414
Although they used the Tucker-CP model to improve the interpretability rather than link prediction, the paper needs to make some attribution to the prior work.	I-Reply	I-1	Reply	414
<sep> ‚Üí Indeed, the idea of combining CP and Tucker is far from new (we cite CANDELINC from 1980 and a method from Bro &amp; Andersson from 1998).	I-Reply	I-1	Reply	414
The interest of this paper is the method for optimization which differs from all of these prior work (and the work from Tomioka, Hayashi &amp; Kashima) due to the tasks and scales considered.	I-Reply	I-1	Reply	414
On these datasets, the loss is no longer Frobenius and the use of adaptive stochastic method is critical to obtain state of the art results.	I-Reply	I-1	Reply	414
We show that adaptive algorithms are crucial to learn these decompositions in this context and that the diagonal approximation made in practical implementations of these algorithms is too crude to learn the Tucker decomposition.	I-Reply	I-1	Reply	414
<sep> <sep> (B) By looking Figure 3, the proposed method, PComplEx, is not significantly better than the existing methods such as ComplEx.	B-Reply	B-2	Reply	414
Except SVO data, PComplEx and ComplEx share almost the same performance curve.	I-Reply	I-2	Reply	414
Also, other existing methods such as TuckER and MurP are evaluated only in a few points while (P)ComplEx is evaluated in many points.	I-Reply	I-2	Reply	414
I feel this is unfair.	I-Reply	I-2	Reply	414
<sep> ‚Üí Regarding the evaluation of other methods, please, see the general comment.	I-Reply	I-2	Reply	414
For the gain in performance: note that we provide curves whereas the standard in the field is tables for a fixed number of parameters.	I-Reply	I-2	Reply	414
The maximal gains we observe for a fixed number of parameters are substantial on other datasets: +0.14 MRR (absolute) on WN18 and +0.05 MRR on YAGO.	I-Reply	I-2	Reply	414
For SVO, our method provides better performances on all operating points compared to ComplEx, and by a fair margin.	I-Reply	I-2	Reply	414

This paper introduces few-shot learning for graph classification.	O	O	Review	20115
The authors propose a pre-training-&gt;fine-tuning approach to handle graph classes unseen at training time (and in only a few shots at test time).	O	O	Review	20115
<sep> <sep> At a high level, and to my understanding, their method a priori generates the ingredients for a graph of graphs, a "super-graph", in two steps: first, it discovers a prototype graph for each graph class in the dataset, then it clusters the prototype graphs into a set of super-classes by k-NN.	O	O	Review	20115
Both of these operations rely on the spectral distance between graphs, defined in this work using the spectrum of a graph's normalized Laplacian matrix and the pth Wasserstein distance between probability measures.	O	O	Review	20115
The intuition is that the super-graph built from these ingredients helps model latent relations between graph classes; these relations can be used at test time to improve classification of unseen graph classes.	O	O	Review	20115
<sep> <sep> During (pre-)training, the model builds super-graphs on each batch of data.	O	O	Review	20115
It uses super-graph information in two ways: an auxiliary classification head (an MLP called C^sup) is trained to map graph embeddings to their corresponding super-class labels, and the super-graph itself, whose nodes are embeddings for individual graphs in the batch, passes through a graph attention network (GAT) that outputs a base class for each graph -- this is the classification head C^GAT.	O	O	Review	20115
The graph embeddings themselves come from a feature extractor F_Œ∏ implemented as a graph isomorphism network (GIN).	O	O	Review	20115
<sep> <sep> During the fine-tuning stage the model adapts to and classifies graphs from classes unseen during training.	B-Review	B-1	Review	20115
Here the parameters of the feature extractor GIN and the C^sup MLP are frozen.	I-Review	I-1	Review	20115
C^sup outputs a set of super-class labels that are used to construct a super-graph, which in turn feeds into C^GAT, which in turn yields labels for the test graphs.	I-Review	I-1	Review	20115
C^GAT (but not the GIN or C^sup) fine-tunes on a small number q of labelled examples of each novel test class.	I-Review	I-1	Review	20115
The full model is evaluated on unlabelled examples from the novel test classes.	I-Review	I-1	Review	20115
This process assumes that the novel test graph classes belong to the same set of super classes as the training graph classes, a point that is, unfortunately, not discussed.	I-Review	I-1	Review	20115
<sep> <sep> There's a lot to digest in this paper, on both the technical and architectural sides.	B-Review	B-2	Review	20115
There are graphs of graphs (super-graphs) and different GNN variants operating on both, with the output of one graph network, the feature extracting GIN, feeding into another, the GAT classifier.	I-Review	I-2	Review	20115
Understanding all of these pieces and how they fit together is challenging for the reader: I got lost somewhat in the Classifier description in Section 4, while Section 3 defines many things and gives some math that might be extraneous.	I-Review	I-2	Review	20115
It is also not immediately obvious that fine-tuning takes place on the set G_N and testing on the set G_U. Overall, though, the paper became clear to me with time and I found the overall presentation to be good.	B-Review	B-3	Review	20115
Some additional figures that depict the super-graph construction and clustering would be useful.	B-Review	B-4	Review	20115
<sep> <sep> The construction and use of the super-graph structure to model relations between graph classes is interesting and novel to me, though it relies on well-established techniques (Wasserstein barycenters, Lloyd's algorithm for k-NN).	B-Review	B-5	Review	20115
The architecture itself, which combines GINs and GATs, is also novel to me; a downside is that it is highly complex.	I-Review	I-5	Review	20115
<sep> <sep> Experiments were undertaken on two datasets and seem fairly thorough, with variance established on a high number of seeds (high in the deep learning literature).	B-Review	B-6	Review	20115
They demonstrate that the proposed method makes significant improvements over baselines.	I-Review	I-6	Review	20115
The baselines are somewhat limited because, as the authors state, "there do not exist any standard state-of-the-art methods for few-shot graph classification".	I-Review	I-6	Review	20115
However, I do not think the authors should be penalized for trying something new.	I-Review	I-6	Review	20115
On the other hand, given the novelty of the task, it would be nice to see an investigation/discussion of how few-shot graph learning differs from few-shot image learning (where there has been much more work).	I-Review	I-6	Review	20115
<sep> <sep> I found the ablation and sensitivity studies illuminating, and I was pleased to see that the authors do support their claim that the super-graphs improve class separation over the feature extractor embeddings -- the GIN-k-NN baseline results provide evidence of this.	B-Review	B-7	Review	20115
<sep> <sep> One place where I lack confidence in the results: I am not very familiar with the datasets used (TRIANGLES and Letter-High) nor how standard they are in the graph-learning literature.	B-Review	B-8	Review	20115
The authors do not even describe in the paper what the graph classes in these datasets actually are or represent, which would be good to know.	I-Review	I-8	Review	20115
<sep> <sep> Overall, I think the paper is worth seeing and discussing at the conference, although it could be improved in various ways.	O	O	Review	20115
<sep> <sep> Minor errors:	B-Review	B-9	Review	20115
- there appears to be bracket imbalance in eq.6	I-Review	I-9	Review	20115
- "Lloyd's" is misspelled a few times	I-Review	I-9	Review	20115
<sep> Reviewer's note: I have significant experience in few-shot learning but not in graph neural networks.	O	O	Review	20115
We thank the reviewer for his comments and observations.	O	O	Reply	20115
We are in total agreement with the detailed overview of our method provided by you.	O	O	Reply	20115
Following are the answers to each question/comment you have raised.	O	O	Reply	20115
<sep> <sep> R2Q1: ‚ÄúThis process assumes that the novel test graph classes belong to the same set of super classes as the training graph classes, a point that is, unfortunately, not discussed.	O	O	Reply	20115
‚Äù	O	O	Reply	20115
R2A1: Thanks for pointing out the omission of this crucial discussion.	B-Reply	B-1	Reply	20115
Yes, we assume that the novel test classes belong to the same set of superclasses from the training graphs.	I-Reply	I-1	Reply	20115
The reason being that the novel class labeled samples are so much fewer than the base class labeled samples that the resulting supergraph ends up being extremely sparse and deviates a lot from the shape of the supergraph from the base classes; therefore it severely hinders‚Äôs ability to effectively aggregate information from the embeddings of the novel class labeled graphs.	I-Reply	I-1	Reply	20115
Instead, we pass the novel graph samples through our trained and infer its super-class label and this works very effectively for us, as is evidenced by our empirical results.	I-Reply	I-1	Reply	20115
We have accordingly updated our draft and this explanation can be found in the new Discussion subsection of Section 4.2 of our revised draft.	I-Reply	I-1	Reply	20115
<sep> <sep> R2Q2: I got lost somewhat in the Classifier description in Section 4, while Section 3 defines many things...	O	O	Reply	20115
R2A2: We have updated the description in Section 4 by adding in the new discussion section concerned above.	B-Reply	B-2	Reply	20115
<sep> <sep> R2Q3: It is also not immediately obvious that fine-tuning takes place on the set and testing on the set.	O	O	Reply	20115
<sep> R2A3: We have described this in the ‚Äúproblem definition‚Äù subsection in Section 3 (Preliminaries).	B-Reply	B-3	Reply	20115
Additionally, we added the sentence ‚ÄúFinally the evaluation is performed on the samples from the unseen test set.	I-Reply	I-3	Reply	20115
‚Äù at the end of our Classification subsection of 4.2.	I-Reply	I-3	Reply	20115
<sep> <sep> R2Q4: Some additional figures that depict the super-graph construction and clustering would be useful.	O	O	Reply	20115
<sep> R2A4: Thanks.	B-Reply	B-4	Reply	20115
We have added an illustration (Fig 2) that depicts the working of our Wasserstein super-class k-means clustering algorithm.	I-Reply	I-4	Reply	20115

This paper proposed a few-shot graph classification algorithm based on graph neural networks.	O	O	Review	20115
The learning is based on a large set of base class labeled graphs and a small set of novel class labeled graphs.	O	O	Review	20115
The goal is to learn a classification algorithm over the novel class based on the sample from the base class and novel class.	O	O	Review	20115
The learning process constitutes of the following steps.	O	O	Review	20115
First, the base class is classified into K super classes based on the spectral embedding of the graph (onto distributions over the corresponding graph spectrum) and the k-means algorithm with the Wasserstein metric.	O	O	Review	20115
Second, for each super class, the classification is done through a feature extractor and a classifier.	O	O	Review	20115
In the training of the feature extractor and classifier, the author introduces a super-graph with each node representing a super class.	O	O	Review	20115
Finally, in the fine-tuning stage, the feature extractor is fixed, and the classifier is trained based on the novel class.	O	O	Review	20115
<sep> <sep> This work seems to be the first attempt to adopt the few-shot learning in graph classification tasks.	O	O	Review	20115
The architecture is novel, and the classification of graph based on spectral embedding together with the Wasserstein metric is novel to me.	O	O	Review	20115
<sep> <sep> I vote for rejecting this submission for the following concerns.	O	O	Review	20115
<sep> <sep> 1.	O	O	Review	20115
The classification of base class into super classes seems questionable to me.	B-Review	B-1	Review	20115
In the meta-learning language, the author attempts to learn a good representation of graphs based on different graph classification tasks generated by a task distribution.	I-Review	I-1	Review	20115
In terms of graph classification, the task distribution is supported on the joint distributions (G, Y).	I-Review	I-1	Review	20115
Hence, to characterize different tasks, as far as I am concerned, the classification should take both the graph G and the label Y into consideration, instead of solely the graph.	B-Review	B-2	Review	20115
<sep> 2.	O	O	Review	20115
Though seemingly very important to the architecture, the purpose of constructing the super-graph g^{sup} in the training of C^{CAT} seems to be unclear to me.	B-Review	B-3	Review	20115
I would appreciate it if the author could provide more explanation on the introduction of the super-graph in training.	I-Review	I-3	Review	20115
<sep> <sep> We thank the reviewer for his comments and observations.	O	O	Reply	20115
Following are the answers to each question you have raised.	O	O	Reply	20115
<sep> R1Q1(a): ‚ÄúThe classification of base class into super classes seems questionable to me.	O	O	Reply	20115
In the meta-learning language, the author attempts to learn a good representation of graphs based on different graph classification tasks generated by a task distribution.	O	O	Reply	20115
In terms of graph classification, the task distribution is supported on the joint distributions (G, Y).‚Äù	O	O	Reply	20115
R1A1(a): Our model has two major components, (for super-class prediction) and (for graph label prediction).	B-Reply	B-1	Reply	20115
During the training phase of our classification,, which is a MLP layer, learns the super-class labels of the samples based on GIN‚Äôs extracted feature vectors (which represent base class labeled graphs).	I-Reply	I-1	Reply	20115
While, takes as input the ‚Äúgraph of graphs‚Äù (supergraph) which models the latent inter-class as well as intra-class information and is constructed in every training batch, along with base-class labels, to learn the associated class distribution.	I-Reply	I-1	Reply	20115
<sep> Then, during the fine-tuning phase on graphs with novel class labels, the feature extractor‚Äôs (GIN) parameters are fixed and is used to infer the super-class label of the novel class labeled graphs.	I-Reply	I-1	Reply	20115
Then, the parameters learned by get updated and further ‚Äúfine-tuned‚Äù for better performance on the novel samples.	I-Reply	I-1	Reply	20115
<sep> In addition to our brief overview, you could also find a very neatly detailed summarization of our method in reviewer 2‚Äôs comments (paragraphs 1-4).	I-Reply	I-1	Reply	20115
<sep> <sep> The meta-learning framework, where batches are sampled as ‚Äúepisodes‚Äù with N-way K-shot setting, does not perform as well in our few-shot setting on graphs for the following reasons:	I-Reply	I-1	Reply	20115
1) We have very limited total number of training classes (in order of 10s), when compared to the image domain (order of 100s and 1000s).	I-Reply	I-1	Reply	20115
This limitation hampers learning across tasks and generalization to new unseen tasks.	I-Reply	I-1	Reply	20115
2) In each of our batches, we randomly sample a fixed-size of training samples belonging to the set of N labels chosen.	I-Reply	I-1	Reply	20115
Therefore, when building our supergraph, we end up with k-NN graphs of ‚Äúvariable size‚Äù per super-class, compared to fixed size (K nodes) k-NN graphs that we would have got using episodic learning.	I-Reply	I-1	Reply	20115
We suspect this further allows our GAT to learn and generalize better to unseen graphs.	I-Reply	I-1	Reply	20115
<sep> Furthermore, in [1], the authors use a similar strategy in their ‚Äúbaseline++‚Äù method and produce good results.	I-Reply	I-1	Reply	20115
Their findings are also in sync with our empirical finding.	I-Reply	I-1	Reply	20115
[1] Chen et~al. ‚	O	O	Reply	20115
ÄúA closer look at Few-Shot Classification‚Äù, ICLR 2019	O	O	Reply	20115
<sep> R1Q1(b): Hence, to characterize different tasks, as far as I am concerned, the classification should take both the graph G and the label Y into consideration, instead of solely the graph.	O	O	Reply	20115
‚Äù	O	O	Reply	20115
R1A1(b): In every batch of graphs during both training and fine-tuning phase, each graph is associated with its corresponding graph label.	B-Reply	B-2	Reply	20115
In case of training, its a base-class and in the case of fine-tuning its a novel class.	I-Reply	I-2	Reply	20115
In the case of, the graph is accompanied by a regular class label and in case of, the graph is accompanied by a superclass label.	I-Reply	I-2	Reply	20115
<sep> <sep> R1Q2: ‚ÄúThough seemingly very important to the architecture, the purpose of constructing the super-graph in the training of seems to be unclear to me.	O	O	Reply	20115
‚Äù	O	O	Reply	20115
R1A2: What makes few-shot learning particularly difficult compared to common machine learning settings is the dearth of training examples, which results in a bad empirical risk approximation for the expected risk and therefore gives rise to an empirical risk minimizer that is sub-optimal.	B-Reply	B-3	Reply	20115
Reducing the required sample complexity can result in a better empirical risk minimizer.	I-Reply	I-3	Reply	20115
Therefore, given a very large space of hypotheses H, our goal is to further restrict and constrain H using some prior knowledge because a reduced H has reduced sample complexity and thus requires fewer training samples to be trained.	I-Reply	I-3	Reply	20115
We provide this ‚Äúprior knowledge‚Äù in the form of a ‚Äúgraph of graphs‚Äù, namely our super-graph, which captures both the latent inter-class and intra-class relationships between classes.	I-Reply	I-3	Reply	20115
Observe that in, we build a k-NN graph PER super-class, restricting any flow of information between super-classes, thus further restricting H. We force our model to jointly learn both the superclass and graph class labels.	I-Reply	I-3	Reply	20115
This way similar classes (grouped under a superclass) together contribute to learning a general prior representing the superclasses and each superclass also provides ‚Äúguidance‚Äù to better train with the few samples assigned to that superclass.	I-Reply	I-3	Reply	20115
<tab>	I-Reply	I-3	Reply	20115
The introduction of this prior knowledge in the form of a supergraph in during training also helps generalize better to the novel samples that are presented to our model in the fine-tuning stage.	I-Reply	I-3	Reply	20115
<sep> <sep> Additionally, we would also like to draw attention to the supergraph usage summary provided by reviewer 2 in paragraph 3 of their comments.	I-Reply	I-3	Reply	20115

This paper introduces few-shot graph classification problem and proposes super-class based graph neural network (GNN) to solve it.	O	O	Review	20115
Experiments on two datasets demonstrate that the proposed model outperforms a number of baseline methods.	O	O	Review	20115
Some ablation study and analysis are also provided.	O	O	Review	20115
Followings are my detail review.	O	O	Review	20115
<sep> <sep> It is interesting for the authors to introduce few-shot graph classification problem which is meaningful.	B-Review	B-1	Review	20115
If I understood correctly, the authors use graph spectral distance to find prototype graph of each class, then employ prototype graph clustering to obtain super-classes, which are further fed to GNN as the joint optimization of super-class and regular class prediction.	I-Review	I-1	Review	20115
To me, the novelty is incremental.	I-Review	I-1	Review	20115
<sep> <sep> The authors use two new datasets for experiments due to the requirement of numerous class labels.	B-Review	B-2	Review	20115
I concerned about performances of different GNN baseline methods in Letter data due to small graph size (with 4.6 nodes in average).	I-Review	I-2	Review	20115
The context neighbor information is important for multi-layer GNN.	I-Review	I-2	Review	20115
Thus I could not fully judge the effectiveness of proposed model in this data.	I-Review	I-2	Review	20115
<sep> <sep> In Table 3, I found performance of proposed model with one super-class is still better than different GNN.	B-Review	B-3	Review	20115
I did get the point from this result.	I-Review	I-3	Review	20115
Why there is no performance decrease as all have the same super-class label?	I-Review	I-3	Review	20115
What is the model performance when removing super-class augmentation?	I-Review	I-3	Review	20115
I would like to see more discussion or experiment about this.	I-Review	I-3	Review	20115
<sep> <sep> Update: I am satisfied with author's response and raised my score.	O	O	Review	20115
We thank the reviewer for his comments and observations.	O	O	Reply	20115
Following are the answers to each question/comment you have raised.	O	O	Reply	20115
<sep> <sep> R3Q1: ‚ÄúIt is interesting for the authors to introduce few-shot graph classification problem which is meaningful.	O	O	Reply	20115
If I understood correctly, the authors use graph spectral distance to find prototype graph of each class, then employ prototype graph clustering to obtain super-classes, which are further fed to GNN as the joint optimization of super-class and regular class prediction.	O	O	Reply	20115
To me, the novelty is incremental.	O	O	Reply	20115
‚Äù	O	O	Reply	20115
R3A1: Yes, your summary can serve as a high-level coarse overview of our work.	B-Reply	B-1	Reply	20115
Regarding the novelty being incremental, we respectfully disagree due to the following reasons.	I-Reply	I-1	Reply	20115
<sep> The task of few-shot learning on graphs to begin with is novel (as is also pointed out by you and all the other reviewers) and extremely challenging as there are no previous works in this few-shot setting on graphs.	I-Reply	I-1	Reply	20115
The introduction of using the-Wasserstein distance between the spectrum of graphs in order to build a supergraph and also cluster class-labels into superclasses is also novel.	I-Reply	I-1	Reply	20115
We are not aware of any graph NNs that have introduced a graph spectral Wasserstein distance between graphs for classification.	I-Reply	I-1	Reply	20115
<sep> <sep> We believe our superclass construction per batch embodies the ‚Äúfull context embedding‚Äù feature of matching networks [1], which essentially capture a wider context of the support set per batch and not just a single graph and prototype networks [2] by using precomputed Wasserstein prototypes to decide the superclasses that allow information flow between various classes too.	I-Reply	I-1	Reply	20115
Our architecture that jointly learns the superclass and regular class using two-phase (training and fine-tuning phase) training is also a novel construction.	I-Reply	I-1	Reply	20115
Finally, we have also shown our method works well in the semi-supervised and adaptive learning setting (Appendix A.5 and A.6).	I-Reply	I-1	Reply	20115
<sep> [1] Vinyals et~al. ‚	O	O	Reply	20115
ÄúMatching Networks for One Shot Learning‚Äú, NIPS 2016	O	O	Reply	20115
[2] Snell et~al. ‚	O	O	Reply	20115
ÄúPrototypical Networks for Few-shot Learning‚Äù, NIPS 2017	O	O	Reply	20115
<sep> R3Q2: Low average number of nodes per graph in the datasets used.	O	O	Reply	20115
<sep> R3A2: Thanks for pointing this out.	B-Reply	B-2	Reply	20115
We found two widely-used graph datasets in graph classification literature with larger average number of nodes, namely Enzymes and Reddit-12K.	I-Reply	I-2	Reply	20115
We conducted all our experiments (including sensitivity and ablation studies) on both these datasets and the results have been added to the revised paper.	I-Reply	I-2	Reply	20115
Enzymes has 33 nodes per graph and Reddit-12K has 391 nodes per graph on average.	I-Reply	I-2	Reply	20115
<sep> Please refer to the table 2 for new results.	I-Reply	I-2	Reply	20115
We find that our results show a marked improvement on the new datasets as well.	I-Reply	I-2	Reply	20115
<sep> +-------------------------+-----------------------------------------------------------+-----------------------------------------------------------+	I-Reply	I-2	Reply	20115
|    Method               |                            Reddit-12K                             |                              Enzymes                               |	I-Reply	I-2	Reply	20115
+-------------------------+-------------------+------------------+-------------------+------------------+-------------------+------------------+	I-Reply	I-2	Reply	20115
|                                 |       5SHOT     |      10SHOT    |      20SHOT    |       5SHOT     |      10SHOT    |      20SHOT    |	I-Reply	I-2	Reply	20115
| WL                          | 40.26 +- 5.17 | 42.57 +- 3.69 | 44.41 +- 3.43 | 55.78 +- 4.72 | 58.47 +- 3.84 | 60.10 +- 3.18 |	I-Reply	I-2	Reply	20115
| Graphlet                | 33.76 +- 6.94 | 37.59 +- 4.60 | 41.11 +- 3.71 | 53.17 +- 5.92 | 55.30 +- 3.78 | 56.90 +- 3.79 |	I-Reply	I-2	Reply	20115
| AWE                        | 30.24 +- 2.34 | 33.44 +- 2.04 | 36.13 +- 1.89 | 43.75 +- 1.85 | 45.58 +- 2.11 | 49.98 +- 1.54 |	I-Reply	I-2	Reply	20115
| Graph2Vec            | 27.85 +- 4.21 | 29.97 +- 3.17 | 32.75 +- 2.02 | 55.88 +- 4.86 | 58.22 +- 4.30 | 62.28 +- 4.14 |	I-Reply	I-2	Reply	20115
| Diffpool                 | 35.24 +- 5.69 | 37.43 +- 3.94 | 39.11 +- 3.52 | 45.64 +- 4.56 | 49.64 +- 4.23 | 54.27 +- 3.94 |	I-Reply	I-2	Reply	20115
| CapsGNN              | 36.58 +- 4.28 | 39.16 +- 3.73 | 41.27 +- 3.12 | 52.67 +- 5.51 | 55.31 +- 4.23 | 59.34 +- 4.02 |	I-Reply	I-2	Reply	20115
| GIN                        | 40.36 +- 4.69 | 43.70 +- 3.98 | 46.28 +- 3.49 | 55.73 +- 5.80 | 58.83 +- 5.32 | 61.12 +- 4.64 |	I-Reply	I-2	Reply	20115
| GIN-k-NN              | 41.31 +- 2.84 | 43.58 +- 2.80 | 45.12 +- 2.19 | 57.24 +- 7.06 | 59.34 +- 5.24 | 60.49 +- 3.48 |	I-Reply	I-2	Reply	20115
| OurMethod-GCN | 40.77 +- 4.32 | 44.28 +- 3.86 | 48.67 +- 4.22 | 54.34 +- 5.64 | 58.16 +- 4.39 | 60.86 +- 3.74 |	I-Reply	I-2	Reply	20115
| OurMethod-GIN  | 41.59 +- 4.12 | 45.67 +- 3.68 | 50.34 +- 2.71 | 55.42 +- 5.74 | 60.64 +- 3.84 | 62.81 +- 3.56 |	I-Reply	I-2	Reply	20115
+-------------------------+-------------------+------------------+-------------------+------------------+-------------------+------------------+	I-Reply	I-2	Reply	20115

Summary	O	O	Review	705
<sep> Learning embeddings of graphs in hyperbolic space have become popular and yielded promising results.	O	O	Review	705
A core reason for that is learning hierarchical representations of the graphs is easier in hyperbolic space due to the curvature and the geometrical properties of the hyperbolic space.	O	O	Review	705
Similar to [1, 2], this paper uses Lorentzian model of the hyperbolic space in order to learn embeddings of the graph.	O	O	Review	705
The main difference of the proposed approach in this paper is that  they come up with a closed-form solution such that each node representation close to the centroid of their descendants.	O	O	Review	705
A curious property of the equation for the centroids proposed to learn the embeddings of each node also encodes information related to the specificity in the Euclidean norm of the centroid.	O	O	Review	705
Also this paper introduces two additional hyperparameters.	O	O	Review	705
Beta hyperparameter is selected to control the curvature of the space.	O	O	Review	705
Depending on the task the optimal curvature can be tuned to be a different value.	O	O	Review	705
This also ties closely with the de-Sitter spaces.	O	O	Review	705
Authors provide results on different graph embedding benchmark tasks.	O	O	Review	705
The paper claims that, an advantage of the proposed approach is that the embedding of the model can be tuned with regular SGD without needing to use Riemannian optimization techniques.	O	O	Review	705
<sep> <sep> Questions	O	O	Review	705
<sep> Have you tried learning beta instead of selecting as a hyperparameter?	B-Review	B-1	Review	705
<sep> The paper claims that Riemannian optimization is not necessary for this model, but have you tried optimizing the model with the Riemannian optimization methods?	B-Review	B-2	Review	705
<sep> Equation 11, bears lots of similarity to the Einstein gyro-midpoint method proposed by Abraham Ungar which is also used by [2]. Have you investigated the relationship between the two formulations?	B-Review	B-3	Review	705
<sep> On Eurovoc dataset the results of the proposed method is worse than the d_P in H^d.	B-Review	B-4	Review	705
Do you have a justification of why that happens?	I-Review	I-4	Review	705
<sep> <sep> <sep> Pros	O	O	Review	705
The paper delivers some interesting theoretical findings about the embeddings learned in hyperbolic space, e.g. a closed for equation in the	O	O	Review	705
The paper is written well.	O	O	Review	705
The goal and motivations are clear.	O	O	Review	705
<sep> <sep> <sep> Cons	O	O	Review	705
Experiments are only limited to small scale-traditional graph datasets.	B-Review	B-5	Review	705
It would be more interesting to see how those embeddings would perform on large-scale datasets such as to learn knowledge-base embeddings or for recommendation systems.	I-Review	I-5	Review	705
<sep> <sep> Although the idea is interesting.	B-Review	B-6	Review	705
Learning graph embeddings have already been explored in [1]. The main contribution of this paper is thus mainly focuses on the close-form equation for the centroid and the curvature hyperparameter.	I-Review	I-6	Review	705
These changes provide significant improvements on the results but still the novelty of the approach is in that sense limited compared to [1].	I-Review	I-6	Review	705
<sep> <sep> Minor comment:	O	O	Review	705
<sep> It is really difficult to understand what is in Figure 2 and 3.	B-Review	B-7	Review	705
Can you reduce the number of data points and just emphasize a few nodes in the graph that shows a clear hierarchy.	I-Review	I-7	Review	705
<sep> <sep> [1] Nickel, Maximilian, and Douwe Kiela. "	O	O	Review	705
Learning Continuous Hierarchies in the Lorentz Model of Hyperbolic Geometry."	O	O	Review	705
arXiv preprint arXiv:1806.03417 (2018).	O	O	Review	705
<sep> [2] Gulcehre, Caglar, Misha Denil, Mateusz Malinowski, Ali Razavi, Razvan Pascanu, Karl Moritz Hermann, Peter Battaglia et al "Hyperbolic Attention Networks."	O	O	Review	705
arXiv preprint arXiv:1805.09786 (2018).	O	O	Review	705
-‚ÄúEq 11, bears lots of similarity to the Einstein gyro-midpoint‚Äù	O	O	Reply	705
As mentioned in our introduction, there exist various hyperbolic geometries with corresponding distances: the Poincar√© distance, the Lorentzian distance and the gyrodistance [A,B]. We	O	O	Reply	705

The paper proposes a new approach to compute hyperbolic embeddings based on the squared Lorentzian distance.	O	O	Review	705
This choice of distance function is motivated by the observation that the ranking of these distances is equivalent to the ranking of the true hyperbolic distance (e.g., on the hyperboloid).	O	O	Review	705
For this reason, the paper proposes to use this distance function in combination with ranking losses as proposed by Nickel & Kiela (2017), as it might be easier to optimize.	O	O	Review	705
Moreover, the paper proposes to use Weierstrass coordinates as a representation for points on the hyperboloid.	O	O	Review	705
<sep> <sep> Hyperbolic embeddings are a promising new research area that fits well into ICLR.	O	O	Review	705
Overall, the paper is written well and good to understand.	O	O	Review	705
It introduces interesting ideas that are promising to advance hyperbolic embeddings.	O	O	Review	705
However, in the current version of the paper, these ideas are not fully developed or their impact is unclear.	O	O	Review	705
<sep> <sep> For instance, using Weierstrass coordinates as a representations seems to make sense, as it allows to use standard optimization methods without leaving the manifold.	B-Review	B-1	Review	705
However, it is important to note that the optimization is still performed on a Riemannian manifold.	I-Review	I-1	Review	705
For that reason, following the Riemannian gradient along geodesics would still require the exponential map.	I-Review	I-1	Review	705
Moreover, optimization methods like Adam or SVRG are still not directly applicable.	I-Review	I-1	Review	705
Therefore, it seems that the practical benefit of this representation is limited.	I-Review	I-1	Review	705
<sep> <sep> Similarly, being able to compute the centroid efficiently in closed form is indeed an interesting aspect of the proposed approach.	B-Review	B-2	Review	705
Moreover, the paper explicitly connects the centroid to the least common ancestor of children in a	B-Review	B-3	Review	705
tree, what could be very useful to derive new embedding methods.	I-Review	I-3	Review	705
Unfortunately, this is advantage isn't really exploited in the paper.	I-Review	I-3	Review	705
The approach taken in the paper simply uses the loss function of Nickel & Kiela (2017) and this loss doesn't make use of centroids, as the paper notes itself.	I-Review	I-3	Review	705
The only use of the centroid seems then to justify the regularization method, i.e., that parents should have a smaller norm than their children.	I-Review	I-3	Review	705
However, this insight alone seems not particularly novel, as the same insight can be derived for standard hyperbolic method and has, for instance, been discussed in Nickel & Kiela (2017, 2018), Ganea et al (2018), De Sa (2018).	I-Review	I-3	Review	705
Using the centroid to derive new hyperbolic embeddings could be interesting, but, unfortunately, is currently not done in the paper.	I-Review	I-3	Review	705
<sep> <sep> Further comments	O	O	Review	705
- p.3: Projection back onto the Poincar√© ball/manifold is only necessary when	B-Review	B-4	Review	705
the exponential map isn't used.	I-Review	I-4	Review	705
The methods of Nickel & Kiela (2018), Ganea et al (2018) therefore don't have this problem.	I-Review	I-4	Review	705
<sep> - p.7: Since MR and MAP are ranking measures, and the ranking of distances between H^d and the L^2 distance should be identical, it is not clear to me why the experiments show significant differences for these methods when \beta=1	B-Review	B-5	Review	705
- p.7: Embeddings in the Poincar√© ball and the Hyperboloid are both compatible with the regularization method in eq.14 (using their respective norms).	B-Review	B-6	Review	705
It would be interesting to also see results for these methods with regularization.	I-Review	I-6	Review	705
- ‚ÄúUsing Weierstrass allows to use standard optimization methods without leaving the manifold.	O	O	Reply	705
However, the optimization is still performed on a Riemannian manifold.	O	O	Reply	705
‚Äù	O	O	Reply	705
<sep> We understand the concern that a Riemannian optimizer would probably be more approp	O	O	Reply	705

This paper proposed an unsupervised embedding method for hierarchical or graph datasets.	O	O	Review	705
The embedding space is a hyperbolic space as in several recent works such as (Nickel & Kiela, 2017).	O	O	Review	705
The author(s) showed that using the proposed embedding, the optimization has better numerical stability and better performance.	O	O	Review	705
I am convinced of the correctness and the experiment results, and I appreciate that the paper is well written with interesting interpretations such as the demonstration of the centroid.	O	O	Review	705
However, the novelty of this contribution is limited and may not meet the publication standard of ICLR.	O	O	Review	705
I suggest that the authors enhance the results and resubmit this work in a future venue.	O	O	Review	705
Theoretically, there are three theorems in section 3:	O	O	Review	705
Theorem 3.1 shows the coordinate transformation from the proposed parametrization to hyperboloid then to Poincare ball preserves the monotonicity of the Euclidean norm.	O	O	Review	705
This is straightforward by writing down the two transformations.	O	O	Review	705
Lemma 3.2 and theorem 3.3 state the centroid in closed expression based on the Lorentzian distance, taking advantage that the  Lorentzian distance is in a bi-linear form (no need to take the arcosh()  therefore the analysis are much more simplified) These results are quite striaghtforward from the expression of the energy function.	O	O	Review	705
Theorem 3.4  (centroid computation with constraints) shows that minimizing the energy function, when a is constrained to a discrete set, is equivalent to minimizing, where is given by Lemma 3.2.	O	O	Review	705
This is interesting as compared to the previous two theorems, but it is not clear whether/how this equivalence is used in the proposed embedding.	O	O	Review	705
Technically, there are three novel contributions,	O	O	Review	705
1.	O	O	Review	705
The proposed unconstrained reparametrization of the hyperboloid model does not require to project the embedding points onto the hyperbolic manifold in each update.	O	O	Review	705
2.	O	O	Review	705
The cost is based on the Lorentzian Distance, that is a monotonic transformation of the Riemannian distance (without taking the arccosh function).	O	O	Review	705
Therefore the similarity (a heat kernel applied on the modified distance function) is measured differently than the other works.	O	O	Review	705
Informally one can think it as t-SNE v.s.	O	O	Review	705
SNE which use different similarity measures in the target embedding.	O	O	Review	705
3.	O	O	Review	705
The authors discussed empirically the different choice of beta, which was typically chosen as beta=1 in previous works, showing that tunning the beta hyperparameter can give better embeddings.	O	O	Review	705
These contributions are useful but incremental.	O	O	Review	705
Notably, (1) needs more experimental evidence (e.g. a toy example) to show the numerical instability of the other methods, and to show the learning curves of the proposed re-parametrization against the Riemannian stochastic gradient descent, which are not given in the paper.	O	O	Review	705
By listing these theoretical and technical contributions, overall I find that most of these contributions are incremental and not significant enough for ICLR.	O	O	Review	705
- ‚ÄúTheorem 3.4 (centroid computation with constraints) shows that minimizing the energy function, when a is constrained to a discrete set, is equivalent to minimizing, where is given by Lemma 3.2.	O	O	Reply	705
This is interesting as compared to the previous two theo	O	O	Reply	705

Summary:	O	O	Review	705
The paper proposes a method for coordinating the exploration efforts of agents in a multi-agent reinforcement learning setting.	O	O	Review	705
The approach has two main components: (i) learning different exploration policies using different "joint" intrinsic rewards; and (ii) learning a higher-level policy that selects one of the exploration policies to be executed at the beginning of each episode.	O	O	Review	705
<sep> <sep> Each agent has its own novelty function which quantifies the novelty of observation seen by that agent.	O	O	Review	705
To coordinate exploration, these novelty functions are combined using aggregation functions to produce intrinsic reward for the agent.	O	O	Review	705
Each such aggregating function yields a different intrinsic reward.	O	O	Review	705
The authors propose several such aggregating functions as examples, however the method is applicable to other aggregating functions as well, as long as they can be computed off-policy.	O	O	Review	705
<sep> <sep> During training, the higher level policy selects one of the exploration policies which is then executed for the entire episode.	O	O	Review	705
The episode data is used in two ways: (i) to train the higher-level policy using policy gradients for maximizing extrinsic rewards along with an entropy term; and (ii) to train each exploration policy using soft actor-critic on its own intrinsic reward function (and extrinsic reward) in an off-policy manner.	O	O	Review	705
<sep> <sep> Experiments done on grid-world and VizDoom environment for three different tasks demonstrate that, on most tasks, the proposed approach performs at least as well as separately trained individual intrinsic rewards.	O	O	Review	705
Further ablation studies confirm that both the hierarchical setup and the "joint" intrinsic rewards are useful.	O	O	Review	705
<sep> <sep> <sep> Questions to the Authors:	O	O	Review	705
<sep> 1.	O	O	Review	705
The second sentence in section 5 is not clear - "Furthermore, the type of reward ... sufficiently complex".	B-Review	B-1	Review	705
The high-level policy selects an exploration strategy at the beginning of each episode and then sticks to it for the entire duration of the episode.	I-Review	I-1	Review	705
Changing the exploration strategy over the course of training might be useful in cases when agent needs to switch to a different exploration strategy after reaching a particular bottleneck state.	I-Review	I-1	Review	705
However, this would require the exploration strategy to be changed in the middle of an episode which is not supported.	I-Review	I-1	Review	705
Could you give an example where the exploration strategy must be changed over time even if one only selects the strategy at the beginning of each episode?	I-Review	I-1	Review	705
Also, why not select the exploration strategy after every fixed number of time steps within each episode (by making high-level policy a function of the current state)?	I-Review	I-1	Review	705
<sep> <sep> 2.	O	O	Review	705
Analyzing the role of high-level policy and its evolution over time on different tasks would be a very nice addition to the paper.	B-Review	B-2	Review	705
Qualitative experiments demonstrating that it provides a curriculum which helps the agents in surpassing the performance of individual intrinsic rewards would be helpful.	I-Review	I-2	Review	705
<sep> <sep> 3.	O	O	Review	705
Should \Pi in (10) also depend on i?	B-Review	B-3	Review	705
<sep> <sep> Though paper is reasonably well written I find the contributions are very marginal.	B-Review	B-4	Review	705
If authors can position the paper well with the existing literature and bring out the impact of the contributions it will be helpful.	I-Review	I-4	Review	705
<sep> <sep> Thank you for the detailed and insightful comments.	O	O	Reply	705
To address your first point, we can provide an illustrative example.	B-Reply	B-1	Reply	705
Let us say that we are attempting to solve task 1, where agents must spread out and collect all rewards on the map.	I-Reply	I-1	Reply	705
In this case it is possible that Leader-Follower rewards may be most successful at first since they all explore similar areas simultaneously, so if they happen to reach a region where a reward is located, there will be multiple agents there to have a chance at collecting it; however, this behavior is not optimal, as there are other rewards to collect around the map.	I-Reply	I-1	Reply	705
At this point in training, burrowing rewards may become more optimal since at least one of the agents will continue exploring the same region to collect the reward, but the other agents will explore other regions, potentially collecting more rewards.	I-Reply	I-1	Reply	705
We find that this type of situation occurs with reasonable frequency during training.	I-Reply	I-1	Reply	705
Re-selecting the exploration strategy within each episode may be useful for tasks with multi-stage goals, though we don‚Äôt consider these types of tasks in this work.	I-Reply	I-1	Reply	705
<sep> <sep> <tab>We have analyzed the role of the policy selector and have found some interesting behaviors.	B-Reply	B-2	Reply	705
We refer the reviewer to the revised Appendix (section A.6) for a discussion on this analysis.	I-Reply	I-2	Reply	705
Finally, the \Pi in equation 10 (i.e. the policy selector) does not depend on i, as all agents roll out their policies trained on the same intrinsic reward simultaneously.	I-Reply	I-2	Reply	705
In other words, there is no mixing of different policy types.	I-Reply	I-2	Reply	705
<sep> <sep> <tab>With respect to the position of our work within the literature, we believe we are the first work to address the problem of spatially coordinated exploration in deep multi-agent reinforcement learning.	B-Reply	B-4	Reply	705
Many multi-agent tasks require some notion of spatial coordination for optimal performance (e.g. search-and-rescue), and our method induces such coordination in exploration with decentralized agents, enabling success in these types of tasks with sparse rewards.	I-Reply	I-4	Reply	705
We show that naive applications of single-agent methods (Figure 3b independent and centralized intrinsic rewards) to multi-agent systems are relatively ineffective when compared to our approach.	I-Reply	I-4	Reply	705

Overall I like the approach in the paper.	O	O	Review	705
It proposes a nice 2 pronged method for exploiting exploration via intrinsic rewards for multi-agent systems.	O	O	Review	705
The parts that a bit lacking with the current version of the paper in this are the evaluation tasks are few and a bit simple and I think there needs to be more discussion on the "coverage" of the intrinsic reward types.	B-Review	B-17	Review	705
Are the ones proposed motivated by the tasks in the paper or are they sufficient for tasks in general?	B-Review	B-15	Review	705
Last using a more recent novelty metric could allow the method to work on more interesting/complex tasks.	B-Review	B-16	Review	705
<sep> <sep> More detailed feedback:	O	O	Review	705
- It would be good to include more learning curves in the main text for the paper.	B-Review	B-1	Review	705
<sep> - The fact that applying intrinsic motivation to multi-agent simulations seems like a natural idea would be to convert the problem to a "single" agent problem to compare against the "normal" application of intrinsic rewards.	B-Review	B-2	Review	705
This might be another baseline to consider for comparison.	I-Review	I-2	Review	705
<sep> - It says that all agents share the same replay buffer.	B-Review	B-3	Review	705
Does this also imply that every agent is performing the same task there are just many agents?	I-Review	I-3	Review	705
This does not make the problem very multi-agent with different goals.	I-Review	I-3	Review	705
Would it affect the algorithm significantly to work on an environment where the agents have various types of goals?	I-Review	I-3	Review	705
<sep> - As is noted in the text, this method appears to work well in the centralized training scheme that many have adopted recently.	B-Review	B-10	Review	705
However, It makes me wonder if there is a way to employ these exploration schemes in a non-centralized training form.	I-Review	I-10	Review	705
The ability to ask other agents in the world about there preferences and novelty of states appears to be a strong assumption, especially in a multi-agent robotics problem.	I-Review	I-10	Review	705
<sep> - While the authors note that the intrinsic rewards used in this work are not comprehensive it would be good to note how comprehensive they are.	B-Review	B-11	Review	705
Are there a few that were left out on purpose.	I-Review	I-11	Review	705
Do the authours believe this set is sufficient.	I-Review	I-11	Review	705
This statement makes it seem like the authors just tried a few options and found one that worked.	I-Review	I-11	Review	705
It would be good to expand on this discussion more.	I-Review	I-11	Review	705
<sep> - More detail for Figure 1 would be helpful to understand the overall network design.	B-Review	B-12	Review	705
While that figure it helpful maybe it would be good to include a version that goes into detail for the 2 agent environment.	I-Review	I-12	Review	705
Then a more compressed n agent version can also be shown.	I-Review	I-12	Review	705
<sep> - The paper describes a policy selector that is a type of high-level policy for HRL.	B-Review	B-13	Review	705
This design seems rather unique in that this part of the policy can optimizing for which intrinsic reward to toggle based on the extrinsic rewards observed.	I-Review	I-13	Review	705
I like it.	I-Review	I-13	Review	705
It is noted that entropy is important for this design.	I-Review	I-13	Review	705
Can this be analyzed in an empirical way?	I-Review	I-13	Review	705
Is this true for most environments/tasks?	I-Review	I-13	Review	705
<sep> - Task 2 seems a bit contrived.	B-Review	B-14	Review	705
Is there another instance of this type of task elsewhere in another paper?	I-Review	I-14	Review	705
It would be better to use more standard tasks if they are available.	I-Review	I-14	Review	705
<sep> - Before section 6.1 the paper is discussing rewards the are received.	B-Review	B-4	Review	705
It would be good to more explicit about where these rewards are coming from.	I-Review	I-4	Review	705
I think it is meant that these rewards are the extrinsic rewards but it does not say.	I-Review	I-4	Review	705
<sep> - As noted just before section 6.1 it seems for the collection of tasks 1-3 it is already obvious what types of intrinsic rewards should be used.	B-Review	B-5	Review	705
It would be good to include more tasks where this decision is less obvious.	I-Review	I-5	Review	705
<sep> - Why are there "black holes" in the environment?	B-Review	B-6	Review	705
Also if an agent steps into a black hole they are crushed never to be seen again.	I-Review	I-6	Review	705
What you describe sounds more like a wormhole where one end is non-stationary... Also, can the agents detect the presence of a black hole in some way?	I-Review	I-6	Review	705
<sep> - It appears the novel metric is count based.	B-Review	B-7	Review	705
While this can work in practice it seems a rather simple metric.	I-Review	I-7	Review	705
Is it possible to use something more like ICM or RND that was referenced in the paper?	I-Review	I-7	Review	705
Especially for the VizDoom environment?	I-Review	I-7	Review	705
<sep> - In table 2 where are some of the numbers bold?	B-Review	B-8	Review	705
It would be good to include this information in the caption for the table.	I-Review	I-8	Review	705
<sep> - I am not sure if the discussion on the behaviours the intrinsic reward functions result in are very surprising.	B-Review	B-9	Review	705
Maybe there is a more interesting behaviour that results from the combination of two intrinsic rewards?	I-Review	I-9	Review	705
<sep> <sep> Thank you for the detailed and insightful comments.	O	O	Reply	705
We would like first to articulate more clearly the motivation behind the tasks we have used.	B-Reply	B-15	Reply	705
When we consider the setting of multi-agent systems, we believe the notion of spatial coordination is of natural interest.	I-Reply	I-15	Reply	705
In other words, should agents in such environments coordinate their spatial positioning while exploring.	I-Reply	I-15	Reply	705
Our tasks are designed to test the extremes of the spectrum of spatial coordination (i.e. close together (task 2) vs. far apart (task 1)).	I-Reply	I-15	Reply	705
<sep> <sep> When designing intrinsic reward functions, we focus on inducing spatial coordination in a general manner that does not use domain-specific knowledge.	B-Reply	B-17	Reply	705
We argue that using these types of rewards for spatially coordinated exploration is generally useful for many problems in multi-agent systems.	I-Reply	I-17	Reply	705
The key contribution of our work is to provide examples which introduce a framework for expressing intrinsic reward functions that induce spatially coordinated exploration.	I-Reply	I-17	Reply	705
<sep> <sep> Regarding the use of more recent novelty metrics: we *thoroughly* tested Random Network Distillation [2] on the ViZDoom tasks and concluded that RND is unsuitable for the domain.	B-Reply	B-16	Reply	705
It is especially sensitive to the brightness of the input images, causing heavily visited rooms in the map with brighter walls leading to higher intrinsic rewards than unvisited dark colored rooms.	I-Reply	I-16	Reply	705
Image preprocessing techniques (contrast limited adaptive histogram equalization) improved performance somewhat, but the exploration was still highly biased towards specific regions.	I-Reply	I-16	Reply	705
We also implemented and tested the Intrinsic Curiosity Module [3] though we have not been able to replicate the results from the original paper and thus, cannot comment on its efficacy within our framework at this time.	I-Reply	I-16	Reply	705
<sep> <sep> Below we will answer specific questions that were not answered above:	O	O	Reply	705
<sep> -Comparing to single-agent intrinsic rewards	O	O	Reply	705
<sep> This is an interesting point, and we have run the appropriate experiments to test its efficacy.	B-Reply	B-2	Reply	705
We implement an intrinsic reward that considers the joint position of all agents (i.e. the inverse count of all agents being in their combined positions).	I-Reply	I-2	Reply	705
Our initial hypothesis is that our intrinsic reward functions provide additional inductive biases which encourage spatial coordination and should outperform this standard centralized intrinsic reward function.	I-Reply	I-2	Reply	705
Figures and a description of the implementation of centralized rewards are provided in the Appendix.	I-Reply	I-2	Reply	705
We find that across all tasks with 2 agents our approach learns more efficiently than this baseline, confirming our hypothesis.	I-Reply	I-2	Reply	705
<sep> <sep> -Agents sharing the same replay buffer	O	O	Reply	705
<sep> We apologize for the confusion.	B-Reply	B-3	Reply	705
Agents have multiple policy heads for each type of intrinsic reward, and these heads share experiences; however, agents do not share experiences with each other.	I-Reply	I-3	Reply	705
<sep> <sep> -Is it possible to decentralize training?	O	O	Reply	705
<sep> <sep> This is an interesting question.	B-Reply	B-10	Reply	705
One can imagine an adaptation of our method where agents leave ‚Äúmarkers‚Äù of how novel a region is to themselves such that other agents can detect these markers when they enter the region.	I-Reply	I-10	Reply	705
In this way, the assumption of communicating the novelty of observations across agents can be removed and our approach can be adapted to a decentralized training regime.	I-Reply	I-10	Reply	705
We leave this for future work.	I-Reply	I-10	Reply	705
<sep> <sep> -Can the importance of entropy in the policy selector be analyzed empirically?	O	O	Reply	705
<sep> <sep> We include experiments of our method run without the entropy bonus on the meta-policy across all tasks with 2 agents in the Appendix.	B-Reply	B-13	Reply	705
We find that its removal consistently hurts performance across all settings.	I-Reply	I-13	Reply	705
<sep> <sep> -Clarifying rewards described before section 6.1	O	O	Reply	705
<sep> Yes, we are referring to the extrinsic rewards.	B-Reply	B-4	Reply	705
The text has been modified to make this more clear.	I-Reply	I-4	Reply	705
<sep> <sep> -Clarifying ‚Äúblack holes‚Äù	O	O	Reply	705
<sep> These exist in order to make the exploration problem more challenging.	B-Reply	B-6	Reply	705
Agents are able to detect the probability of any black hole in their immediate vicinity opening at the next time step, and must learn to navigate around them (i.e. wait for the probability of opening to be low).	I-Reply	I-6	Reply	705
<sep> <sep> -Bolded numbers	O	O	Reply	705
<sep> The bolded numbers are those where the best mean score falls within one standard deviation of their score distribution.	B-Reply	B-8	Reply	705
We have added this description to the caption.	I-Reply	I-8	Reply	705
<sep> <sep> <sep> [1] Ta√Øga, Adrien Ali, et al "Benchmarking bonus-based exploration methods on the arcade learning environment."	O	O	Reply	705
arXiv preprint arXiv:1908.02388 (2019).	O	O	Reply	705
<sep> [2] Burda, Yuri, et al "Exploration by random network distillation."	O	O	Reply	705
arXiv preprint arXiv:1810.12894 (2018).	O	O	Reply	705
<sep> [3] Pathak, Deepak, et al "Curiosity-driven Exploration by Self-supervised Prediction."	O	O	Reply	705
International Conference on Machine Learning.	O	O	Reply	705
2017.	O	O	Reply	705

Contribution:	O	O	Review	705
<sep> The paper proposes to use a set of handcrafted intrinsic rewards that depend on the novelty of an observation as perceived by the rest of the other agents.	O	O	Review	705
For each pair of reward and agent, they learn a policy and a value through actor critic method, and then a meta-policy choses at the beginning of each episode which intrinsic rewards to use, meaning that the policy used by the agents corresponds to the one that maximizes the reward chosen.	O	O	Review	705
<sep> <sep> <sep> <sep> Review:	O	O	Review	705
<sep> <sep> The major limitation of the paper in my opinion is the fact that the "coordination" that occurs here is only happening at training time, not at execution time.	B-Review	B-1	Review	705
The agents eventually learn whatever trajectory they need to perform, and then proceed to do so without any interaction with the other agents.	I-Review	I-1	Review	705
In a sense, they don't even learn to explore collaboratively.	I-Review	I-1	Review	705
In other words, agents trained on task 1 in a given maze would not be able to solve task 2 on the same maze without essentially relearning everything from scratch.	I-Review	I-1	Review	705
<sep> The other corollary of the fact that each agent learns its own policy is that the number of agents is fixed at training time, preventing testing with a different number of agents, as sometimes done in the literature ([1] [2]).	I-Review	I-1	Review	705
<sep> <sep> Given this limitation the scope of the work basically reduces to the exploration of a fixed environment when the action space can be factored into different agents.	B-Review	B-2	Review	705
This "multi-agent" formulation is presumably meant to break down the computational complexity of having a joint observation/action space.	I-Review	I-2	Review	705
However, the experiments are conducted only with a very limited number of agents (only 2 in the non toy environment of vizdoom).	I-Review	I-2	Review	705
This small scale doesn't, in my opinion, demonstrate the advantage of the decomposition of the MDP over say SOTA single-agent exploration methods applied to the cartesian product of all the agents action spaces (in vizdoom the paper considers only 3 actions, so with two agents it would amount to 9 actions, which is still very tractable).	I-Review	I-2	Review	705
Once the trajectories of both agents are found, they can be distilled to each of them individually so that they only depend on the local observation.	I-Review	I-2	Review	705
<sep> <sep> <sep> Regarding the experiments on the Vizdoom environment, it appears that the traditional evaluation setup [3] doesn't involve providing the global position (x,y) to the agents as part of the observations (they must be inferred from the visual feed), contrary to the experimental setup presented in this paper.	B-Review	B-3	Review	705
<sep> In my opinion, this weakens the claim that the method "scales to more complex environments" since providing the position essentially makes the environment similar to a grid-world (arguably the visual feed isn't even needed to solve the task.	I-Review	I-3	Review	705
<sep> <sep> <sep> The use of a dynamic policy selection is somewhat interesting, but would benefit better investigation.	B-Review	B-4	Review	705
Firstly, it is not clear to me if all the selection of the policy to use during training affects all the trajectories of the batch, or if different episodes of the batch may have a different policy.	I-Review	I-4	Review	705
<sep> Secondly, it seems that the setting is typically the one of a (non-stationary) bandit, since there is no state and the "reward" is the return obtained by the policy.	B-Review	B-4	Review	705
Could you share the reason behind the choice of an actor-critic algorithm over classical bandit algorithms?	I-Review	I-4	Review	705
One obvious advantage of the latter are provable regret bounds.	I-Review	I-4	Review	705
<sep> In all, the selection policy seems to be useful during training, since it sometimes yields better solutions than any of the individual reward schemes.	B-Review	B-4	Review	705
It suggests that some form of curriculum over the rewards is occurring during training, but if this is really what is going on, then it's possible that the relevant literature about curriculum learning may offer more stable and principled solutions than an actor critic, for example population based training.	I-Review	I-4	Review	705
This could potentially solve the issues observed in task 2.	I-Review	I-4	Review	705
<sep> <sep> <sep> [1] Relational Deep Reinforcement Learning, Zambaldi et al, <a href="https://arxiv.org/abs/1806.01830" target="_blank" rel="nofollow">https://arxiv.org/abs/1806.01830</a>	O	O	Review	705
[2] A Structured Prediction Approach for Generalization in Cooperative Multi-Agent Reinforcement Learning, Carion et al, <a href="https://arxiv.org/abs/1910.08809" target="_blank" rel="nofollow">https://arxiv.org/abs/1910.08809</a>	O	O	Review	705
[3] Curiosity-driven Exploration by Self-supervised Prediction, Pathak et al, ICML 2017	O	O	Review	705
<sep> Thank you for the detailed and insightful comments.	O	O	Reply	705
Concerning the point of coordination only happening at training time, this is in fact by design.	B-Reply	B-1	Reply	705
We are operating within the recently popularized regime of centralized training with decentralized execution [1,2,3], while the works referenced by the reviewer are concerned with learning a centralized controller.	I-Reply	I-1	Reply	705
Within this regime, communication between agents is assumed to not be possible at testing time, so agents must learn to operate independently and coordination must be incorporated somehow during training.	I-Reply	I-1	Reply	705
Furthermore, we are not concerned with learning policies that transfer between tasks.	I-Reply	I-1	Reply	705
As is common in the intrinsic motivation literature, we simply want to explore the environment in order to enable learning in a single task with sparse rewards.	I-Reply	I-1	Reply	705
<sep> <sep> <tab>The multi-agent formulation is not designed to break down the computational complexity of the problem, but rather our method is designed to be useful in multi-agent scenarios by incorporating inductive biases regarding spatial coordination.	B-Reply	B-2	Reply	705
While the suggestion of learning with the joint action space and distilling to decentralized policies could potentially work for the 2 agent VizDoom case, such an approach would not work even in the 4 agent gridworld setting, where the joint action space contains 625 actions.	I-Reply	I-2	Reply	705
An approach that would not work in this ‚Äútoy‚Äù environment is not particularly useful to the multi-agent RL community.	I-Reply	I-2	Reply	705
Furthermore, we have run experiments where we maintain our centralized training with decentralized execution paradigm but use intrinsic rewards where the agents are treated as one agent (this was also asked for by R1).	I-Reply	I-2	Reply	705
Concretely, we use the inverse count of all agents being at their current positions, rather than considering agents independently.	I-Reply	I-2	Reply	705
We refer the reviewer to the curves labelled ‚ÄúCentralized‚Äù in Appendix section A.5.	I-Reply	I-2	Reply	705
We find that, while this approach is somewhat effective, it does not learn as quickly as our approach since it does not induce agents to coordinate their regions of exploration.	I-Reply	I-2	Reply	705
<sep> <sep> <tab>In VizDoom we do not provide the agents‚Äô locations as part of the observations.	B-Reply	B-3	Reply	705
As described in the appendix, we provide the egocentric image view, along with an indicator of whether each reward has been collected.	I-Reply	I-3	Reply	705
The global state, however, does include the agents‚Äô locations and orientations, but this information is only available to the critic and not available to the policies during execution.	I-Reply	I-3	Reply	705
<sep> <sep> <tab>To clarify the use of the policy selector: it only affects the selection of policies to use during rollouts.	B-Reply	B-4	Reply	705
During training, all policies are trained simultaneously using off-policy methods.	I-Reply	I-4	Reply	705
The point regarding non-stationary bandits is an interesting one.	I-Reply	I-4	Reply	705
In fact, it was our first instinct to use such methods for the policy selector; however, we found that the convergence guarantees rely on assumptions on the nature of how the reward distribution evolves.	I-Reply	I-4	Reply	705
Since we cannot characterize the evolution of rewards received by each policy type very well, we resorted to the policy gradient method described, which we find works well empirically.	I-Reply	I-4	Reply	705
We have provided additional analysis of the nature of the policy selector and how it enables our method to surpass the performance of individual intrinsic reward methods (Appendix section A.6).	I-Reply	I-4	Reply	705
We have not considered the idea of applying curriculum learning methods to our approach, though it is interesting and worth exploring.	I-Reply	I-4	Reply	705
<sep> <sep> [1] Foerster, Jakob N., et al "Counterfactual multi-agent policy gradients."	O	O	Reply	705
Thirty-Second AAAI Conference on Artificial Intelligence.	O	O	Reply	705
2018.	O	O	Reply	705
<sep> [2] Lowe, Ryan, et al "Multi-agent actor-critic for mixed cooperative-competitive environments."	O	O	Reply	705
Advances in Neural Information Processing Systems.	O	O	Reply	705
2017.	O	O	Reply	705
<sep> [3] Rashid, Tabish, et al "QMIX: monotonic value function factorisation for deep multi-agent reinforcement learning."	O	O	Reply	705
arXiv preprint arXiv:1803.11485 (2018).	O	O	Reply	705

This paper presents a computational model of motivation for Q learning and relates it to biological models of motivation.	O	O	Review	705
Motivation is presented to the agent as a component of its inputs, and is encoded in a vectorised reward function where each component of the reward is weighted.	O	O	Review	705
This approach is explored in three domains: a modified four-room domain where each room represents a different reward in the reward vector, a route planning problem, and a pavlovian conditioning example where neuronal activations are compared to mice undergoing a similar conditioning.	O	O	Review	705
<sep> <sep> Review Summary:	O	O	Review	705
I am uncertain of the neuroscientific contributions of this paper.	B-Review	B-1	Review	705
From a machine learning perspective, this paper has insufficient details to assess both the experimental contributions and proposed formulation of motivation.	I-Review	I-1	Review	705
It is unclear from the discussion of biological forms of motivation, and from the experimental elaboration of these ideas, that the proposed model of motivation is a novel contribution.	I-Review	I-1	Review	705
For these reasons, I suggest a reject.	I-Review	I-1	Review	705
<sep> <sep> The Four Rooms Experiment:	O	O	Review	705
<sep> In the four-rooms problem, the agent is provided with a one-hot encoding representing which cell it the agent is located in within the grid-world.	B-Review	B-2	Review	705
The reward given to the agent is a combination of the reward signal from the environment (a one-hot vector where the activation is dependent on the room occupied by the agent) and the motivation vector, which is a weighting of the rooms.	I-Review	I-2	Review	705
One agent is given access to the weighting vector mu in its state vector: the motivation is concatenated to the position, encoding the weighting of the rooms at any given time-step.	I-Review	I-2	Review	705
The non-motivated agent does not have access to mu in its state, although its reward is weighted as the motivated agent‚Äôs is.	I-Review	I-2	Review	705
The issue with this example is that the non-motivated agent does not have access to the information required to learn a value-function suitable to solve this problem.	I-Review	I-2	Review	705
By not giving the motivation vector to non-motivated agent, the problem has become a partially observable problem, and the comparison is now between a partially observable and fully observable setting, rather than a commentary on the difference between learning with and without motivation.	I-Review	I-2	Review	705
<sep> <sep> In places, the claims made go beyond the results presented.	B-Review	B-3	Review	705
How do we know that the non-motivated network is engaging in a "non-motivated delay binge"?	I-Review	I-3	Review	705
We certainly can see that the agent acquires an average reward of 1, but it is not evident from this detail alone that the agent is engaging in the behaviour that the paper claims.	I-Review	I-3	Review	705
<sep> <sep> Moreover, the network was trained 41 times for different values of the motivation parameter theta.	B-Review	B-4	Review	705
Counting out the points in figure 2, it would suggest that the sweep was over 41 values of theta, which leaves me wondering if the results represent a single independent trial, or whether the results are averaged over multiple trials.	I-Review	I-4	Review	705
Looking at the top-right hand corner I see a single yellow dot (non-motivated agent) presented in line with blue (motivated agent) suggesting that the point is possibly an outlier.	I-Review	I-4	Review	705
Given this outlier, I‚Äôm led believe that the graph represents a single independent trial.	I-Review	I-4	Review	705
A single trial is insufficient to draw conclusions about the behaviour of an agent.	I-Review	I-4	Review	705
<sep> <sep> The Path Routing Experiment:	O	O	Review	705
<sep> In the second experiment, where a population of agents is presented in fig 5, it is claimed that on 82% of the trials, the agent was able to find the shortest path.	B-Review	B-5	Review	705
Looking at the figure itself, at the final depicted iteration, all of the points are presented in a different colour and labelled ‚Äúshortest path‚Äù.	I-Review	I-5	Review	705
The graph suggests that 100% of the agents found the shortest path.	I-Review	I-5	Review	705
The claim is made that for the remaining 18% of the agents, the agents found close to the shortest path‚Äîa point not evident in the figures presented.	I-Review	I-5	Review	705
<sep> <sep> <sep> Pavlovian Conditioning Experiment:	O	O	Review	705
<sep> In the third experiment, shouldn‚Äôt Q(s) be V(s)?	B-Review	B-6	Review	705
In this setting, the agent is not learning the value of a state action pair, but rather the value of a state.	I-Review	I-6	Review	705
Moreover, the value is described as Q(t), where t is the time-step in the trial; however, elsewhere in the text it is mentioned that the state is not simply t, but contains also the motivation value mu.	I-Review	I-6	Review	705
<sep> The third experiment does not have enough detail to interpret the results.	B-Review	B-7	Review	705
It is unclear how many trials there were for both of the prediction settings.	I-Review	I-7	Review	705
It is unclear whether the problem described is a continuing problem or a terminating prediction problem‚Äîi.e.,	I-Review	I-7	Review	705
whether after the conditioned stimulus and unconditioned stimulus are presented to the agent, does the time-step (and thus the state) reset to 0, or does time continue incrementing?	I-Review	I-7	Review	705
If it is a terminating prediction problem, it is unclear whether the conditioned stimulus and unconditioned stimulus were delivered on the same time-steps for each independent trial.	I-Review	I-7	Review	705
If I am interpreting the state-construction correctly, the state is incrementing by one on each time-step; this problem is effectively a Markov Reward Process where the agent transitions from one state to the next until time stops with no ability to transition to previous states.	I-Review	I-7	Review	705
<sep> <sep> In both the terminating and continuing cases, the choice of inputs is unusual.	B-Review	B-8	Review	705
What was the motivation for using the time-step as part of the state construction?	I-Review	I-8	Review	705
<sep> <sep> How is the conditioned stimulus formulated in this setting?	B-Review	B-9	Review	705
It is mentioned that it is a function of time, but there are no additional details.	I-Review	I-9	Review	705
<sep> <sep> From reading the text, it is unclear whether fig 7b/c presents activations over multiple independent trials or a single trial.	B-Review	B-10	Review	705
<sep> <sep> General Thoughts on Framing:	O	O	Review	705
<sep> This paper introduces non-standard terms without defining them first.	B-Review	B-11	Review	705
For example, TD error is introduced as Reward Prediction Error, or RPE: a term that is not typically used in the Reinforcement Learning literature.	I-Review	I-11	Review	705
To my understanding, there is a hypothesis about RPE in the brain in the cognitive science community; however, the connection between this idea in the cognitive science literature and its relation to RL methods is not immediately clear.	I-Review	I-11	Review	705
<sep> <sep> Temporal Difference learning is incorrectly referred to as "Time Difference" learning (pg 2).	B-Review	B-12	Review	705
<sep> <sep> Notes on technical details:	B-Review	B-13	Review	705
<sep> - The discounting function gamma should be 0&lt;= gamma &lt;=1, rather than just &lt;=1.	I-Review	I-13	Review	705
<sep> <sep> - discounting not only prevents the sum of future rewards from diverging, but also plays an important role in determining the behaviour of an agent---i.e.,	I-Review	I-13	Review	705
the preference for short-term versus long-term rewards.	I-Review	I-13	Review	705
<sep> <sep> - pg 2 "the motivation is a slowly changing variable, that is not affected substantially by an average action" -- it is not clear from the context what an average action is.	I-Review	I-13	Review	705
<sep> <sep> - Why is the reward r(s|a), as opposed to r(s,a)?	I-Review	I-13	Review	705
<sep> <sep> Notes on paper structure:	B-Review	B-14	Review	705
<sep> - There are some odd choices in the structure of this paper.	I-Review	I-14	Review	705
For instance, the second section---before the mathematical framing of the paper has been presented---is the results section.	I-Review	I-14	Review	705
<sep> <sep> - In some sentences, citations are added where no claim is being made; it is not clear what the relevance of the citation is, or what the citation is supporting.	I-Review	I-14	Review	705
E.g., ‚ÄúWe chose to use a recurrent neural network (RNN) as a basis for our model‚Äù following with a citation for Sutton &amp; Barto, 1987.	I-Review	I-14	Review	705
<sep> <sep> - In some sentences, citations are not added where substantial claims are being made.	I-Review	I-14	Review	705
E.g, ‚ÄúThe recurrent network structure in this Pavlovian conditioning is compatible with the conventional models of working memory‚Äù.	I-Review	I-14	Review	705
This claim is made, but it is never made clear what the conventional computational models of working memory are, or how they fit into the computational approaches proposed.	I-Review	I-14	Review	705
<sep> <sep> - Unfortunately, a number of readers in the machine learning community might be unfamiliar with pavlovian conditioning and classical conditioning.	I-Review	I-14	Review	705
Taking the time to unpack these ideas and contextualise them for the audience might help readers understand the paper and its relevance.	I-Review	I-14	Review	705
<sep> <sep> - Figure 7B may benefit from displaying not just the predicted values V(s), but a plot of the prediction over time in comparison to the true expected return.	I-Review	I-14	Review	705
<sep> <sep> The authors would like to thank the Reviewer #3 for their time, and attention to the details.	O	O	Reply	705
We believe that the Reviewer #3‚Äôs comments helped make the manuscript more rigorous.	O	O	Reply	705
<sep> <sep> Please find the specific responses below.	O	O	Reply	705
<sep> <sep> ‚ÄúI am uncertain of the neuroscientific contributions of this paper.	O	O	Reply	705
From a machine learning perspective, this paper has insufficient details to assess both the experimental contributions and proposed formulation of motivation.	O	O	Reply	705
It is unclear from the discussion of biological forms of motivation, and from the experimental elaboration of these ideas, that the proposed model of motivation is a novel contribution.	O	O	Reply	705
For these reasons, I suggest a reject.	O	O	Reply	705
‚Äù	O	O	Reply	705
<sep> The authors had little choice but to shorten the descriptions to meet the eight-pages-max requirements imposed by the ICLR format.	B-Reply	B-1	Reply	705
On the bright side, it resulted in ‚Äúthe excellent clarity of this paper‚Äù, as pointed out by the Reviewer #2.	I-Reply	I-1	Reply	705
From the comments after the Reviewer #3 we conclude, that they also perfectly inferred (the most of) the details from the text.	I-Reply	I-1	Reply	705
We however agree with the Reviewer #3 that technical details should be explicitly present in the paper.	I-Reply	I-1	Reply	705
To this end, we extended our paper with the Methods appendix, featuring sufficient detail to reproduce our computational experiments.	I-Reply	I-1	Reply	705
We hope that this new section of the paper helps the Reviewer #3 clarify their technical questions, and therefore ‚Äúassess both the experimental contributions and proposed formulation of motivation‚Äù.	I-Reply	I-1	Reply	705
<sep> <sep> The neuroscientific contribution of the paper, briefly speaking, is the following.	I-Reply	I-1	Reply	705
In behavioral experiments, mice are often kept water-deprived, so that the reward upon task completion is lucrative.	I-Reply	I-1	Reply	705
This approach relies on the assumption that the perceived value of a reward depends not only on its physical value, but also on external factors.	I-Reply	I-1	Reply	705
Although the existence of such dependence ‚Äì named the motivational salience ‚Äì is known in psychology and has been modelled in neuroscience, it is still unclear how motivation affects the reward perception in the brain.	I-Reply	I-1	Reply	705
To this end, the results of numerous behavioral experiments critically rely on the process that is not yet well understood.	I-Reply	I-1	Reply	705
<sep> <sep> To bridge this gap, we propose a functional circuit in the brain that may modulate the reward perception using motivation.	I-Reply	I-1	Reply	705
Specifically, we found two large groups of cells in the ventral pallidum: cells tuned to positive and negative motivation respectively.	I-Reply	I-1	Reply	705
We built an RL model suggesting that these two groups of cells may be connected through a recurrent ‚Äúpush-pull‚Äù circuit (Fig.7F), retaining the information about the upcoming reward based on the cue and motivation.	I-Reply	I-1	Reply	705
Overall, our work yields important insights into the reward processing in the brain, and motivates future studies in the reward circuitry, thus contributing to rigorous interpretation of behavioral data.	I-Reply	I-1	Reply	705
<sep> <sep> The Four Rooms Experiment:	O	O	Reply	705
<sep> ‚ÄúThe issue with this example is that the non-motivated agent does not have access to the information required to learn a value-function suitable to solve this problem.	O	O	Reply	705
By not giving the motivation vector to non-motivated agent, the problem has become a partially observable problem, and the comparison is now between a partially observable and fully observable setting, rather than a commentary on the difference between learning with and without motivation.	O	O	Reply	705
‚Äù	O	O	Reply	705
<sep> The authors argue that in the Four Rooms experiment, the latent variable (motivation) has deterministic dynamics; therefore, an agent can learn to predict the exact reward on every iteration based on location, making the latent variable (motivation) unnecessary for the state formulation.	B-Reply	B-2	Reply	705
In this regard, the environment is fully observable.	I-Reply	I-2	Reply	705
Moreover, an agent is capable of learning such reward dynamics ‚Äì as shown by the non-motivated outlier agent in the Fig.2B. Yet, the rest of non-motivated agents were far less successful in maximizing the reward, as compared to the motivated agents under the same learning parameters.	I-Reply	I-2	Reply	705
<sep> <sep> Using the arguments above, the authors prefer to attribute the boost in learning to motivation.	I-Reply	I-2	Reply	705
However, we would like to acknowledge that, to the letter of POMDP definition (having a latent variable hidden from the agent), the Reviewer #3 is right in classifying the non-motivated setting as POMDP.	I-Reply	I-2	Reply	705
To this end, we also would not mind saying that motivation converts POMDP to MDP to facilitate learning the optimal policies.	I-Reply	I-2	Reply	705
<sep> <sep> ‚ÄúIn places, the claims made go beyond the results presented.	O	O	Reply	705
How do we know that the non-motivated network is engaging in a "non-motivated delay binge"?‚Äú	O	O	Reply	705
<sep> The authors thank the Reviewer #3 for this catch.	B-Reply	B-3	Reply	705
We should have stated explicitly that for each run, we displayed sequences of agent's locations to establish correspondence between policies and average reward rates.	I-Reply	I-3	Reply	705
We included this statement in the newly written Methods appendix.	I-Reply	I-3	Reply	705

The authors investigate mechanisms underlying action selection in artificial agents and mice.	O	O	Review	705
To achieve this goal, they use RL to train neural networks to choose actions that maximize their temporally discounted sum of future rewards.	O	O	Review	705
Importantly, these rewards depend on a motivation factor that is itself a function of time and action; this motivation factor is the key difference between the authors' approach and "vanilla" RL.	O	O	Review	705
In simple tasks, the RL agent learns effective strategies (i.e., migrating between rooms in Fig.5).	O	O	Review	705
1, and minimizing path lengths for the vehicle routing problem in Fig.	O	O	Review	705
<sep> <sep> The authors then apply their model to a task in which the agent is presented with sound cues.	O	O	Review	705
Depending on the trial block, the reward for the given cue is either zero, positive, or negative; the authors suggest that these varying reward values correspond to varying motivational states.	O	O	Review	705
In this setting, the model learns to have two populations of units; each selective to either positive or negative rewards.	O	O	Review	705
Recurrent excitation within populations and mutual inhibition between populations define the learned dynamics.	O	O	Review	705
<sep> <sep> Finally, the authors train mice on this same task, and record from neurons in area VP.	O	O	Review	705
Those neurons show a similar structure to the RNN: subpopulations of neurons respond to either positive or negative rewards.	O	O	Review	705
<sep> <sep> First, I'd like to thank the authors for the excellent clarity of this paper.	O	O	Review	705
It was very clear, and interesting to read.	O	O	Review	705
<sep> I have some suggestions for how to deepen the connection between the model and the experiment, and some concerns about the necessity of the motivation framework to the Pavlovian task:	O	O	Review	705
<sep> 1) The authors make the prediction that neurons in VP should show (functional) connectivity matching that learned by their model.	B-Review	B-1	Review	705
This could be tested in their data.	I-Review	I-1	Review	705
If that prediction is true, then one should see positive noise correlations for neuron pairs of the same preference (i.e., within the same pool, defined by spiking more for positive, or for negative rewards), and negative noise correlations for pairs of neurons with different preferences (i.e., one neuron in each pool).	I-Review	I-1	Review	705
<sep> <sep> 2) A recent preprint by Sederberg and Nemenman (doi: <a href="https://doi.org/10.1101/779223)" target="_blank" rel="nofollow">https://doi.org/10.1101/779223)</a> argued against over-interpreting the stimulus selectivity of neurons in recurrent circuits.	B-Review	B-2	Review	705
They showed that, even in randomly connected (untrained) networks: a) neurons show either positive or negative selectivity; and b) neuron pairs with selectivity for the same stimulus (or task) feature tend to excite each other, and neuron pairs with opposite selectivity tend to inhibit each other.	I-Review	I-2	Review	705
Given that finding, I wonder how compelling is the match between the mouse data and the RL agent (Figs.	I-Review	I-2	Review	705
6 and 7): could randomly-connected untrained networks show similar phenomena as in the mouse (Fig.6)?	I-Review	I-2	Review	705
<sep> <sep> I'm not asking if the untrained network can duplicate all the details of the trained one in Fig.7.	I-Review	I-2	Review	705
Just whether the mouse data could be recapitulated by a simpler (no training) model.	I-Review	I-2	Review	705
<sep> <sep> 3) For the Pavlovian conditioning in the RL agent, I'm not sure I'd describe this as changing motivation.	B-Review	B-3	Review	705
It seems instead that the (external) reward contingency really changes between states.	I-Review	I-3	Review	705
So the fact that the same network can make predictions in both cases seems more like metalearning than motivation-based action selection.	I-Review	I-3	Review	705
For this reason, it's hard for me to connect the two halves of the paper: the first half has nice ideas on motivation-based action selection, while the second one has no apparent action selection, and hence no mechanism for the agent's motivation to matter.	I-Review	I-3	Review	705
<sep> <sep> The authors would like to sincerely thank the Reviewer #2 for their time, interest in the paper, and thorough comments.	O	O	Reply	705
Below we attempted to address all of the reviewer specific concerns.	O	O	Reply	705
<sep> <sep> 1) "The authors make the prediction that neurons in VP should show (functional) connectivity matching that learned by their model.	O	O	Reply	705
This could be tested in their data.	O	O	Reply	705
If that prediction is true, then one should see positive noise correlations for neuron pairs of the same preference (i.e., within the same pool, defined by spiking more for positive, or for negative rewards), and negative noise correlations for pairs of neurons with different preferences (i.e., one neuron in each pool)."	O	O	Reply	705
<sep> <sep> The authors agree with the rationale for the proposed analysis.	B-Reply	B-1	Reply	705
Unfortunately, the full data containing the individual spikes is not yet available for analysis due to handling delays; instead, we operated on the average activations for each cell (Fig.6C, D, F).	I-Reply	I-1	Reply	705
To this end, in our original submission we did a simpler version of what the Reviewer #2 proposed ‚Äì though we did not expand its description due to the space limitations.	I-Reply	I-1	Reply	705
Namely, we averaged activity of each cell under each experimental condition, and then used correlations of the average activities to cluster cells in the data.	I-Reply	I-1	Reply	705
This way, activities of the cells within a same cluster had positive correlation, as anticipated by the Reviewer #2; the property of being positive/negative with respect to reward was established through visually evaluating cell activations in each cluster (Fig.6C, D, F).	I-Reply	I-1	Reply	705
<sep> To include an explicit description of correlation-based clustering procedure in the paper, we included the following statement in the newly written Methods appendix: ‚ÄúWe then clustered the recurrent neurons after training as follows.	I-Reply	I-1	Reply	705
First, for every neuron we computed 6 average activations, corresponding to the unique types of trials (positive/negative motivation with zero/small/large reward).	I-Reply	I-1	Reply	705
Then, we used the average activations to compute a correlation matrix for the neurons.	I-Reply	I-1	Reply	705
Finally, we processed the correlation matrix with the watershed algorithm (marker-based; h = 0.04), hence clustered the recurrent neurons‚Äù.	I-Reply	I-1	Reply	705
<sep> <sep> 2) "A recent preprint by Sederberg and Nemenman (doi: <a href="https://doi.org/10.1101/779223)" target="_blank" rel="nofollow">https://doi.org/10.1101/779223)</a> argued against over-interpreting the stimulus selectivity of neurons in recurrent circuits.	O	O	Reply	705
They showed that, even in randomly connected (untrained) networks: a) neurons show either positive or negative selectivity; and b) neuron pairs with selectivity for the same stimulus (or task) feature tend to excite each other, and neuron pairs with opposite selectivity tend to inhibit each other.	O	O	Reply	705
Given that finding, I wonder how compelling is the match between the mouse data and the RL agent (Figs.	O	O	Reply	705
6 and 7): could randomly-connected untrained networks show similar phenomena as in the mouse (Fig.6)?	O	O	Reply	705
I'm not asking if the untrained network can duplicate all the details of the trained one in Fig.7.	O	O	Reply	705
Just whether the mouse data could be recapitulated by a simpler (no training) model."	O	O	Reply	705
<sep> <sep> We appreciate the Reviewer #2 pointing out the paper by Sederberg and Nemenman, highlighting the issue of interpreting stimulus selectivity in recurrent circuits.	B-Reply	B-2	Reply	705
Although we could not account for this work in our original submission ‚Äì as it was published two days before the conference deadline ‚Äì the authors agree that it is now reasonable to perform additional analysis, as suggested by the Reviewer #2.	I-Reply	I-2	Reply	705
<sep> In agreement with the conclusions of the paper, when we substitute the trained weights in the model with the random weights, we observe positive- and negative-selectivity cells.	I-Reply	I-2	Reply	705
In particular, every cell has two tunings ‚Äì to motivation, and to cue (same as reward) ‚Äì reflecting two separate inputs to the neural network.	I-Reply	I-2	Reply	705
In random (no training) models, these inputs are propagated through independent random weights of both signs.	I-Reply	I-2	Reply	705
As a result ‚Äì and we observe it in simulation ‚Äì selectivity to motivation and selectivity to reward are independent, e.g. positive-motivation cell may be at the same time negatively tuned to the reward.	I-Reply	I-2	Reply	705
Therefore, in total, random connectivity in our task yields four clusters of cells: (positively/negatively tuned to motivation/reward).	I-Reply	I-2	Reply	705
On contrast, in the data, we only observe two clusters: positive-motivation cells are always positively tuned to reward, and negative-motivation cells are always negatively tuned to reward.	I-Reply	I-2	Reply	705
Thus, a non-trained model does not recapitulate the mouse data.	I-Reply	I-2	Reply	705

This paper builds a model of motivation-dependent learning.	O	O	Review	705
A motivation channel is provided as an additional input to and RL-based learning system (essentially concatenated to state information), similar to goal-conditioned approaches (as the authors mention).	O	O	Review	705
The motivational variables evolve according to their own rules, and are designed/interpreted as biological motivations such as water, food, sleep and work.	O	O	Review	705
While the narrative is interesting, I lean towards reject as I believe it failed to deliver on what it promised.	O	O	Review	705
<sep> <sep> In the first experiment, the satisfaction of these motivations are mapped onto a 4-room setting, where being in each room satisfies a motivation.	O	O	Review	705
The choice to map the four rooms to biological drives is cute, but possibly confusing/misleading since this navigation problem really has nothing to do with these biological drives.	O	O	Review	705
A claim is that by providing the motivation as input to the policy, it is more robustly (across seeds) able to learn the "migration" (i.e. cycling) behavior among the rooms.	O	O	Review	705
In a second example, a similar problem is solved involving navigation on a graph.	O	O	Review	705
<sep> <sep> The final, most substantial example, is a policy trained to solve a simple, abstract version of a behavioral task.	B-Review	B-2	Review	705
In this setting, a motivation channel was again used.	I-Review	I-2	Review	705
However, the motivation channel value is now fixed to one of two discrete values, essentially meaning it is simply a task-label variable, a paradigm that has already been applied in the context of simple models of neuroscience tasks, e.g. see Song et al 2017 "Reward-based training of recurrent neural networks for cognitive and value-based tasks".	I-Review	I-2	Review	705
<sep> There is a bit of a mixed framing overall as to whether it is being claimed that the "motivation" being passed as an input is a fundamental contribution to AI/RL (I think it is not), versus the computational modeling of biological motivation.	B-Review	B-4	Review	705
I think the people qualified to judge whether the computational model is a worthwhile model of motivation specifically are probably a narrower set of computational neuroscientists.	I-Review	I-4	Review	705
I do think there is value in the kind of computational modeling performed, involving establishing a relationship between training a neural network to solve a behavioral task and comparing this with real neural data.	I-Review	I-4	Review	705
This paradigm already becoming increasingly popular within computational neuroscience.	I-Review	I-4	Review	705
However, while I find the results slightly interesting, but not very significant, as someone interested in the biology of motivation, I question whether the nature of these contributions would be of broad interest at this venue.	I-Review	I-4	Review	705
<sep> More fundamentally, I don't believe there is a meaningful ML/AI/RL contribution, and I have some issues with the presentation of the first two examples.	B-Review	B-5	Review	705
While I do like the narrative inspiring these problems, I find the implementations of the problems too simplified to really be meaningfully related to their inspiration (in terms of motivated behaviors).	I-Review	I-5	Review	705
Rather than really model motivation as part of the policy architecture, the authors have proposed a solution to modeling motivation that makes motivation a feature of the environment.	I-Review	I-5	Review	705
Essentially, the reward provided by the environment depends on an extra latent variable and by hiding this (in the cases where the policy does not see motivation inputs), it is quite likely that it becomes too difficult for the value function to predict what is happening (the environment has become partially observed).	I-Review	I-5	Review	705
This seems less a setting where motivation channels solve a problem, and more just an example of an environment that has more complex rules for generating rewards being more challenging to learn about, especially if latent variables are not available to the value function.	I-Review	I-5	Review	705
Critically, it has not been shown that motivational systems are useful for artificial agents, rather the tasks themselves have been designed to attempt to be models of biological motivation.	I-Review	I-5	Review	705
<sep> Personally, I am interested in motivated behaviors and think that future AI developments should take note of this field, but again, the present work does not provide actionable insights into implementing an artificial motivation system.	B-Review	B-1	Review	705
At the same time, this work does not provide interesting enough neurobiological results for those to stand on their own either.	I-Review	I-1	Review	705
<sep> <sep> Minor clarification:	O	O	Review	705
<sep> "trained to perform in realistic tasks" -- the task is very simple.	B-Review	B-3	Review	705
I would consider this a fairly abstract model of the task.	I-Review	I-3	Review	705
<sep> We thank the reviewer for careful reading of our paper at least twice and providing the thorough, meaningful, and in depth review.	O	O	Reply	705
We would like to debate, however, the assessment of value of this work for both neuroscience and machine learning communities and its relevance to the venue.	O	O	Reply	705
We agree with the reviewer that ‚Äúfuture AI developments should take a note‚Äù of motivated behaviors.	B-Reply	B-1	Reply	705
Our overall goal is to facilitate this exchange.	I-Reply	I-1	Reply	705
It is also clear that neuroscience community should take notice of many developments in AI.	I-Reply	I-1	Reply	705
One of such developments in the hierarchical RL (HRL) that has not been mapped on neural circuits yet.	I-Reply	I-1	Reply	705
Our paper proposes that motivational salience, which we call ‚Äòmotivation‚Äô for brevity, may have evolved from modulating simple feeding behaviors to solving more complex hierarchical cognitive tasks.	I-Reply	I-1	Reply	705
As such, our paper aims at bridging the gap between HRL community in ML and neuro communities interested in understanding motivated behaviors.	I-Reply	I-1	Reply	705
Clearly, building a motivated HRL model is not a task for a single paper.	I-Reply	I-1	Reply	705
Our goal was therefore to introduce the concept of motivational salience to the ML community.	I-Reply	I-1	Reply	705
In addition, we believe, we have made substantial contributions to computational neuroscience and to understanding of computational algorithms run by circuits in ventral pallidum (VP) as detailed below	B-Reply	B-4	Reply	705
<sep> 1) Our paper presents the first example of neural network processing information about motivational salience.	B-Reply	B-4	Reply	705
Motivational salience has been described in RL framing before, but the networks processing motivation are missing.	I-Reply	I-4	Reply	705
The reviewer may not agree with how we frame the problem, but, perhaps, it is also important to formulate one solution in order to compel community to find alternatives.	I-Reply	I-4	Reply	705
Our solution is useful, however, because it helps solve complex computational tasks and allows to make sense of responses of neurons in basal ganglia.	I-Reply	I-4	Reply	705
<sep> <sep> 2) We explain the presence of two oppositely-tuned populations of neurons in VP as resulting from the need to solve temporal credit assignment problem via maintaining working memory about reward expectation between CS and US.	B-Reply	B-4	Reply	705
<sep> <sep> 3) Our general framework allows to derive clear experimentally testable predictions about network structure in VP.	B-Reply	B-2	Reply	705
We use a conventional machine learning algorithm (recurrent network training using backpropagation) to derive the structure of the network in VP from the first principles and show that it should contain inhibitory connections between two populations of neurons.	I-Reply	I-2	Reply	705
We agree with the reviewer that backpropagation has been used to train recurrent RL V-networks before, for example, in the neuroscience setting by Song et al (2017).	I-Reply	I-2	Reply	705
However, Song et al (2017) did not show that the network has a push-pull architecture.	I-Reply	I-2	Reply	705
Since this particular architecture is known to be important in neural systems, it is valuable to show that the same connectivity can be used in circuits implementing motivated behavior.	I-Reply	I-2	Reply	705
We argue that the presence of the push-pull circuit leads to the emergence of the two oppositely tuned populations of neurons.	I-Reply	I-2	Reply	705
<sep> <sep> <sep> Overall we suggest that our paper introduces motivational salience as a potential basis of HRL, uses the general machine learning framework based on motivational salience to explain existing experimental data (two populations of neurons), and generates clear experimentally testable predictions about the structure of network of real biological neurons in basal ganglia.	B-Reply	B-1	Reply	705
We thus humbly suggest that it makes a substantial contribution to the understanding of the circuit basis of computation involved in motivated behaviors.	I-Reply	I-1	Reply	705

Paper proposes Gated Muiltimodal Unit, a building block for connectionist models capable of handling multiple modalities.	O	O	Review	360
<sep> <sep> (Figure 2) The bimodal case returns weighted activation by gains of gating units, do you do anything special to keep multi-modal case weighted as well?	B-Review	B-1	Review	360
I.e. how the equation for h in section 3.1 would look like for multi-modal case.	I-Review	I-1	Review	360
Also what‚Äôs the rationale for using tanh nonlinearity (over, say RELU), is it somehow experimentally optimised choice?	I-Review	I-1	Review	360
<sep> <sep> I would find interesting a discussion on a possibility of handling missing data in case one or more modalities are unavailable at test time.	B-Review	B-5	Review	360
Is this possible in the current model to back-off to fewer modalities?	I-Review	I-5	Review	360
Synthetic example may suggest that‚Äôs in fact possible.	I-Review	I-5	Review	360
Those numbers, perhaps, could be added to table 2.	I-Review	I-5	Review	360
<sep> <sep> In the synthetic experiment, you should compare MGU with the fully-connected MLP model really, with similar complexity - that is - at least two hidden units (as GMU has two such for each modality) followed by logistic regression.	B-Review	B-2	Review	360
At least in terms of capability of drawing decision boundary, those should be comparable.	I-Review	I-2	Review	360
<sep> <sep> I think, broader discussion shall be written on the related work associated with mixture of experts models (which is fact are very similar conceptually) as well as multiplicative RNN models [1]. Also, gating unit in LSTM can, in principle, play very similar role when multiple modalities are spliced in the input.	B-Review	B-3	Review	360
<sep> <sep> Overall, the paper is interesting, so is the associated (and to be released) dataset.	O	O	Review	360
<sep> <sep> Minor comments/typos:	B-Review	B-4	Review	360
<sep> Sec.3.3:  layers and a MLP (see Section 3.4) -> layers and an MLP	I-Review	I-4	Review	360
<sep> Apologies for unacceptably late review.	O	O	Review	360
<sep> <sep> [1] Multiplicative LSTM for sequence modelling B Krause, L Lu, I Murray, S Renals	O	O	Review	360
<sep> Thanks for your review.	O	O	Reply	360
These are our comments:	O	O	Reply	360
<sep> 1.	O	O	Reply	360
We proposed untied weights for the multi-modal case, i.e.  there is a different linear transformation for each gate (rendered latex: <a href="http://i.imgur.com/zzyq27I.gif):" target="_blank" rel="nofollow">http://i.imgur.com/zzyq27I.gif):</a>	B-Reply	B-1	Reply	360
h_i = tanh(W_i x_i )<span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="0">\</span>	I-Reply	I-1	Reply	360
z_i = \sigma ( W_{z_i} [x_1,x_2, ... , x_k] )<span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="1">\</span>	I-Reply	I-1	Reply	360
h = \sum_i z_i h_i	I-Reply	I-1	Reply	360
<sep> Since we have not addressed the multi-modal scenario, this formulation is opened to experimental evaluation.	I-Reply	I-1	Reply	360
<sep> <sep> 2.	O	O	Reply	360
Following the gated units in recurrent networks (e.g GRUs, LSTMs), we fixed this tanh activation function.	B-Reply	B-5	Reply	360
However, this is also a choice to be made when building the neural network architecture.	I-Reply	I-5	Reply	360
<sep> <sep> 3.	O	O	Reply	360
An MLP with two hidden units is also able to solve the task.	B-Reply	B-2	Reply	360
However, it is not clear how the model is dealing with the added noise, you can see the plot for the same synthetic dataset used in Figure 7 using the MLP with 2 hidden units in <a href="http://i.imgur.com/Bjsdlbl.png" target="_blank" rel="nofollow">http://i.imgur.com/Bjsdlbl.png</a>	I-Reply	I-2	Reply	360
<sep> 4.	O	O	Reply	360
We agree.	B-Reply	B-3	Reply	360
We‚Äôll extend the discussion and experimentation for the comparison with other gated models.	I-Reply	I-3	Reply	360

The paper introduces Gated Multimodal Units GMUs, which use multiplicative weights to select the degree to which a hidden unit will consider different modalities in determining its activation.	O	O	Review	360
The paper also introduces a new dataset, "Multimodal IMDb," consisting of over 25k movie summaries, with their posters, and labeled genres.	O	O	Review	360
<sep> <sep> GMUs are related to "mixture of experts" in that different examples will be classified by different parts of the model, (but rather than routing/gating entire examples, individual hidden units are gated separately).	O	O	Review	360
They are related to attention models in that different parts of the input are weighted differently; there the emphasis is on gating modalities of input.	O	O	Review	360
<sep> <sep> The dataset is a very nice contribution, and there are many experiments varying text representation and single-modality vs two-modality.	O	O	Review	360
What the paper is lacking is a careful discussion, experimentation and analysis in comparison to other multiplicative gate models---which is the core intellectual contribution of the paper.	B-Review	B-1	Review	360
For example, I could imagine that a mixture of experts or attention models or other gated models might perform very well, and at the very least provide interesting scientific comparative analysis.	I-Review	I-1	Review	360
I encourage the authors to continue the work, and submit a revised paper when ready.	I-Review	I-1	Review	360
<sep> <sep> As is, I consider the paper to be a good workshop paper, but not ready for a major conference.	O	O	Review	360
Thanks for your review.	O	O	Reply	360
We will focus on including other gated models for comparison and including a more elaborated comparison between GMU and other multiplicative architectures.	B-Reply	B-1	Reply	360
We also thank you for suggesting our work to the workshop, we would be glad to share it on this event.	I-Reply	I-1	Reply	360

This paper proposed The Gated Multimodal Unit (GMU) model for information fusion.	O	O	Review	360
The GMU learns to decide how modalities influence the activation of the unit using multiplicative gates.	O	O	Review	360
The paper collected a large genre dataset from IMDB and showed that GMU gets good performance.	O	O	Review	360
<sep> <sep> The proposed approach seems quite interesting, and the audience may expect it can be used in general scenarios beyond movie genre prediction.	B-Review	B-1	Review	360
So it is quite straightforward that the paper should test the algorithm in other applications, which was not done yet.	I-Review	I-1	Review	360
That is the biggest shortcoming of this paper in my opinions.	I-Review	I-1	Review	360
<sep> Another concern lies in how to evaluate the performance of information fusion.	B-Review	B-2	Review	360
The abstract claims "The model improves the macro f-score performance of single-modality models by 30% and 4% with respect to visual and textual information respectively", however, such an improvement is off the key.	I-Review	I-2	Review	360
If two modals are complementary to each other, the fusion results will always be higher.	I-Review	I-2	Review	360
The key fact is how much better than baselines the proposed GMU is.	I-Review	I-2	Review	360
There is a long list of techniques for fusions, so it is difficult to conduct an impressive comparison on only one real dataset.	B-Review	B-3	Review	360
I think GMU did a nice work on movie dataset, but I would also expect other techniques, including fine-tuning, dropout, distillation may help too.	I-Review	I-3	Review	360
It would be nice if the author could compare these techniques.	I-Review	I-3	Review	360
<sep> <sep> I also hope this paper could talk in more details the connection with mixture-of-expert (MoE) model.	B-Review	B-4	Review	360
Both models are based on the nonlinear gated functions, while both method may suffer from local minimum for optimization on small datasets.	I-Review	I-4	Review	360
I would like more in-depth discussion in their similarity and difference.	I-Review	I-4	Review	360
<sep> <sep> To gain more attention for GMU, I would encourage the author to open-source their code and try more datasets.	B-Review	B-5	Review	360
Thanks for your review.	O	O	Reply	360
Our comments are embedded below.	O	O	Reply	360
<sep> <sep> ".. the paper should test the algorithm in other applications...".	O	O	Reply	360
<sep> <sep> We agree the model should be tested in more applications.	B-Reply	B-1	Reply	360
However, as stated in another submission related to multimodal learning (<a href="https://openreview.net/forum?id=rJJ3YU5ge)" target="_blank" rel="nofollow">https://openreview.net/forum?id=rJJ3YU5ge)</a> and to the best of our knowledge, there are not standard multimodal datasets, most of the open multimodal datasets task involves the mapping from one modality to another (e.g. image captioning) rather than finding a way to combining them to improve the performance in the particular task.	I-Reply	I-1	Reply	360
Indeed, this was the main motivation to build a publicly available dataset.	I-Reply	I-1	Reply	360
We‚Äôll evaluate another preliminary dataset we have been collecting composed of books with their covers, however we would appreciate any suggestion for other standard dataset to be included as well.	I-Reply	I-1	Reply	360
<sep> <sep> "Another concern lies in how to evaluate the performance of information fusion.	O	O	Reply	360
The abstract claims "The model improves the macro f-score performance of single-modality models by 30% and 4% with respect to visual and textual information respectively", however, such an improvement is off the key.	O	O	Reply	360
If two modals are complementary to each other, the fusion results will always be higher.	O	O	Reply	360
The key fact is how much better than baselines the proposed GMU is."	O	O	Reply	360
<sep> <sep> We agree that the main comparison it is not with single but with multimodal approaches, and thus the abstract should emphasize it.	B-Reply	B-2	Reply	360
Unfortunately, the phrase you quote was part of one of the first versions of our paper and we missed to update it with our last findings (we‚Äôll update it in the next revision).	I-Reply	I-2	Reply	360
We compared the model with two early fusion models  (concatenate and linear sum) which have proven to be a good way to combine multimodal features.	I-Reply	I-2	Reply	360
We also compared with a simpler late fusion strategy (avg_probs).	I-Reply	I-2	Reply	360
GMU obtained better results in all metric reported for this multilabel task.	I-Reply	I-2	Reply	360
<sep> <sep> "...I would also expect other techniques, including fine-tuning, dropout, distillation may help too.	O	O	Reply	360
It would be nice if the author could compare these techniques."	O	O	Reply	360
<sep> <sep> We initially avoided fine-tuning VGG and the word vectors because it could easily overfit our dataset (~16K training samples Vs.	B-Reply	B-3	Reply	360
138M(VGG), 12M (word vectors) of parameters).	I-Reply	I-3	Reply	360
We included dropout as regularization strategy, but it is not clear for us how can be used as fusion strategy.	I-Reply	I-3	Reply	360
We'll try fine-tuning both representations and look at distillation as a late fusion strategy.	I-Reply	I-3	Reply	360
<sep> "I also hope this paper could talk in more details the connection with mixture-of-expert (MoE) model.	O	O	Reply	360
Both models are based on the nonlinear gated functions, while both method may suffer from local minimum for optimization on small datasets.	O	O	Reply	360
I would like more in-depth discussion in their similarity and difference."	O	O	Reply	360
<sep> <sep> We‚Äôll add a more detailed discussion of MoE Vs GMU.	B-Reply	B-4	Reply	360
We‚Äôll also train the MoE with the best model of each modality, and discuss the results.	I-Reply	I-4	Reply	360
<sep> <sep> "To gain more attention for GMU, I would encourage the author to open-source their code and try more datasets."	O	O	Reply	360
<sep> <sep> So far, we‚Äôve focused on releasing the dataset, but we also plan to release the code as soon as possible.	B-Reply	B-5	Reply	360
We want to refactor it so that it could be easy to use and to reproduce these results.	I-Reply	I-5	Reply	360

Summary:	O	O	Review	719
Standard CNN models for MNIST, CIFAR10 and ImageNet are vulnerable with regard	O	O	Review	719
to (adversarial) rotation and translation of images.	O	O	Review	719
<sep> The paper experimentally examines different ways of formulating attacks	O	O	Review	719
(gradient descent, grid search and sampling) and defenses	O	O	Review	719
(random augmentation, worst-case out of sample robust training,	O	O	Review	719
aggregated classification) for this class of image transformation.	O	O	Review	719
<sep> <sep> The main results are:	O	O	Review	719
- Gradient descent is not effective at generating worst-case rotations /	O	O	Review	719
translations due to nonconcavity of the adversarial objective	O	O	Review	719
- Grid search is very effective due to low parameter space	O	O	Review	719
- Sampling and pick the worst is also effective and cheap, for similar reasons	O	O	Review	719
- L infinity ball pixel perturbation robustness is orthogonal to the examined	O	O	Review	719
transformations and does not provide good defense mechanism	O	O	Review	719
- Just augmenting data with random translation / rotations is not a strong	O	O	Review	719
defense	O	O	Review	719
- Using a worst-case out of sample of 10 for training with an approximation of	O	O	Review	719
a robust optimization objective combined with an aggregated result for	O	O	Review	719
classification is a stronger defense	O	O	Review	719
<sep> Recommendation:	O	O	Review	719
The paper presents a comprehensive study of a relevant class of adversarial	O	O	Review	719
image perturbations for state-of-the-art neural network models.	O	O	Review	719
<sep> The results are a useful pointer towards future research directions and for	O	O	Review	719
building more robust systems in practice.	O	O	Review	719
<sep> I recommend to accept the paper.	O	O	Review	719
<sep> <sep> Strong points:	O	O	Review	719
- The paper is well written, has clear structure and is technically easy to	O	O	Review	719
understand.	O	O	Review	719
<sep> - The question of padding and cropping comes up naturally and is then answered.	O	O	Review	719
<sep> <sep> Open questions (things that could potentially be of interest when added):	O	O	Review	719
- Loss landscapes look like most of the nonconcavity is along the translation	B-Review	B-1	Review	719
parameter.	I-Review	I-1	Review	719
Any idea why?	I-Review	I-1	Review	719
<sep> - What mechanisms within CNN models do or do not learn (generalize) rotation	B-Review	B-2	Review	719
and translation from provided data (including augmentation)?	I-Review	I-2	Review	719
<sep> <sep> Specific:	B-Review	B-3	Review	719
- Page 2: perturbrbations (Typo)	I-Review	I-3	Review	719
- Page 3: witho (Typo)	I-Review	I-3	Review	719
- Page 3: Constrained optimization problems typically written as	I-Review	I-3	Review	719
max_{...} \mathcal L(x', y) s.t.	I-Review	I-3	Review	719
x' = T(...)	I-Review	I-3	Review	719
(s.t.	I-Review	I-3	Review	719
for subject to instead of for) but that's matter of taste I guess	I-Review	I-3	Review	719
- Page 4: first order -> first-order (consistency)	I-Review	I-3	Review	719
- Page 4: tyipcally (Typo)	I-Review	I-3	Review	719
- Page 4: occurs most common(ly)	I-Review	I-3	Review	719
<sep> I am not sufficiently knowledgable about the previous literature to ensure that	O	O	Review	719
the claimed novelty of the paper is truly as novel.	O	O	Review	719
<sep> <sep> We thank the reviewer for their kind words.	O	O	Reply	719
<sep> <sep> -- Regarding the loss landscape: it appears that the loss landscape exhibits significant non-concavity in both directions (see page 19 for additional plots).	B-Reply	B-1	Reply	719
We do agree however that the translation direction is mostly responsible for the loss value (changes along the rotation direction appear jagged and without consistent patterns).	I-Reply	I-1	Reply	719
We do not have concrete ideas about why this this happening but we agree that it is an interesting research direction.	I-Reply	I-1	Reply	719
<sep> <sep> -- Since for vanilla convolutional layers input translation can only lead to output translation, the main mechanisms responsible for translation non-robustness are max-pooling units and strided convolutions.	B-Reply	B-2	Reply	719
We do not have a similar understanding for the case of rotations.	I-Reply	I-2	Reply	719
This is an important direction for future work, but we believe that it goes beyond the scope of the current paper.	I-Reply	I-2	Reply	719
<sep> <sep> We will update our manuscript to incorporate the typos and fixes pointed out.	B-Reply	B-3	Reply	719

The paper states that basic transformation (translation and rotation) can easily fool a neural network in image classification tasks.	O	O	Review	719
Thus, image classification models are actually more vulnerable than people thought.	O	O	Review	719
The message conveyed by the paper is clear and easy to get.	O	O	Review	719
The experiments are natural and interesting.	O	O	Review	719
Some interesting points:	O	O	Review	719
--The model trained with data augmentation that covers the attack space does not alleviate the problem sufficiently.	O	O	Review	719
<sep> --Gradient descent does not provide strong attack, but grid search does.	O	O	Review	719
This may be due to the high non-concavity, compared to the small perturbation case.	O	O	Review	719
<sep> <sep> One possible question is the novelty, as this idea is so simple that probably many people have observed similar phenomenon--but have not experimented that extensively.	B-Review	B-1	Review	719
<sep> Also, there are some related works that also show the vulnerability under spatial transformations.	B-Review	B-1	Review	719
But some are concurrent works to 1st version of the paper (though published), so I tend to not to judge it by those works.	I-Review	I-1	Review	719
<sep> Other comments:	O	O	Review	719
1.	B-Review	B-3	Review	719
page 3 in the paragraph starting with ‚ÄòWe implement ‚Ä¶‚Äô, the author chooses a differentiable bilinear interpolation routine.	I-Review	I-3	Review	719
However, the interpolation method is not shown or explained.	I-Review	I-3	Review	719
<sep> 2.	B-Review	B-4	Review	719
In term of transformation, scaling and reflecting are also transformations.	I-Review	I-4	Review	719
It should be straightforward to check the robustness with respect to them.	I-Review	I-4	Review	719
Comments?	I-Review	I-4	Review	719
<sep> 3.	O	O	Review	719
Header in tables is vague.	B-Review	B-5	Review	719
Like ‚ÄòNatural‚Äô or ‚ÄòOriginal‚Äô, etc.	I-Review	I-5	Review	719
More description of the Header under tables is helpful.	I-Review	I-5	Review	719
<sep> 4.	B-Review	B-6	Review	719
For CIFAR10 and especially for ImageNet dataset, Aug30 and Aug40 models showed lower accuracy&nbsp;than No Crop model&nbsp;on Nat test set.	I-Review	I-6	Review	719
This is little strange because data augmentation (such as random rotation) is commonly used strategy to improve test accuracy.	I-Review	I-6	Review	719
I think this might mean that the model is not trained enough and underfitted, maybe because excessive data augmentation lowered the training speed.	I-Review	I-6	Review	719
<sep> <sep> We thank the reviewer for their kind words.	O	O	Reply	719
<sep> <sep> Regarding the novelty of our paper: We agree that we are not the first to experimentally study the robustness of classifiers to rotations and translation (as we mention in our paper including relevant citations).	B-Reply	B-1	Reply	719
We would like to emphasize however that simply pointing out this flaw is not enough to establish it as a relevant problem with current classifiers.	I-Reply	I-1	Reply	719
After all, we also need to understand if this issue is only a small glitch that we can fix with a few simple modifications, or if it requires more thought and further research.	I-Reply	I-1	Reply	719
This is why we go into significantly more depth than prior work with respect to possible fixes and show that standard approaches (data augmentation, robust optimization, ensembles / majority voting) do help to some extent, but are still far from fully solving the problem. (	I-Reply	I-1	Reply	719
Please also refer to our response to Reviewer 3 on the same topic.)	I-Reply	I-1	Reply	719
<sep> <sep> We will address the other points raised below.	O	O	Reply	719
<sep> <sep> 1.	O	O	Reply	719
We used the approach from "Spatial Transformer Networks" (Jaderberg et al 2015) and their open source implementation.	B-Reply	B-3	Reply	719
We will clarify this point in our updated manuscript and add a link to the implementation.	I-Reply	I-3	Reply	719
<sep> <sep> 2.	O	O	Reply	719
We agree that scaling and reflecting are natural transformations to consider.	B-Reply	B-4	Reply	719
We decided to restrict ourselves to two transformations and perform a comprehensive study in this case, rather than perform fewer experiments with more transformations.	I-Reply	I-4	Reply	719
We chose translations since ConvNets are often claimed to be inherently robust to these transformations, and rotations since we believe they are the simplest to describe.	I-Reply	I-4	Reply	719
Moreover, rotations don't discard any image information (other than edge effects) while (say) downscaling does.	I-Reply	I-4	Reply	719
<sep> <sep> 3.	O	O	Reply	719
We will update the manuscript to clarify the table headers.	B-Reply	B-5	Reply	719
<sep> <sep> 4.	O	O	Reply	719
To the best of our knowledge, none of the publicly available implementations for training state-of-the-art ImageNet or CIFAR10 models use random rotations as data augmentation.	B-Reply	B-6	Reply	719
This is likely due to the fact that random rotations typically do not yield  any benefits in (non-robust) test error (as our experimental results show).	I-Reply	I-6	Reply	719
<sep> <sep> We would also like to emphasize that all of our models were trained until convergence (the loss plateaued) and hence the reduced test performance is not an artifact of training for insufficient steps (we will add a note about this to our manuscript).	I-Reply	I-6	Reply	719
At a high level, a decrease in test performance due to data augmentation is not surprising.	I-Reply	I-6	Reply	719
If the transformations used are not present in the test set, then a model that has learned to be invariant to these transformations will typically perform worse on the test set. (	I-Reply	I-6	Reply	719
This is also the case when learning models that are adversarially robust to L_p perturbations; there is a decrease in test accuracy.)	I-Reply	I-6	Reply	719
As an extreme, consider an MNIST model that learns to be invariant to rotations up to 180 degrees.	I-Reply	I-6	Reply	719
Clearly, this invariance is only hurting the model's performance since it cannot easily distinguish '6' from '9'.	I-Reply	I-6	Reply	719

Summary	O	O	Review	719
The authors study robustness of neural networks for image recognition tasks with respect to geometric transformations in input space.	O	O	Review	719
The question is posed in an adversarial setting, where the authors exploit that Conv/ResNets are not fully translation and rotation invariant.	O	O	Review	719
The authors propose three untargeted attacks to increase the classification error of the network: a first-order method, an attack involving random transformations and a grid search of allowed transformations.	O	O	Review	719
For the random and grid search the worst prediction is considered the outcome of the attack.	O	O	Review	719
The authors observe that first-order attacks are not very successful in fooling the network compared to the grid search.	O	O	Review	719
Data augmentation as a counter measure is found to be not sufficient and adversarial (robust) training with respect to the random search attack is proposed in addition.	O	O	Review	719
<sep> <sep> Evaluation	O	O	Review	719
The paper is well written and particularly the empirical part is interesting.	O	O	Review	719
However, novelty is limited, the best approach boils down to a grid search that tests multiple hypotheses instead of a single one.	O	O	Review	719
There are some conceptual problems and important aspects like confidences of the classification are not addressed.	O	O	Review	719
<sep> <sep> Novelty:	O	O	Review	719
Many claims and observations appear trivial and well-known.	B-Review	B-1	Review	719
E.g.,	I-Review	I-1	Review	719
- the research question has already been addressed by related work, leaving the proposed attacks trivial given that the attack space (allowed transformations) is specified ad hoc and without a proper measure.	I-Review	I-1	Review	719
<sep> - that data augmentation and training with the adversarial loss function (i.e. with the attack scheme in mind) is helpful is straight forward and not surprising	B-Review	B-1	Review	719
<sep> Detailed comments:	O	O	Review	719
The authors study whether neural networks are robust to transformations in input space and resort to a benign adversarial setting.	B-Review	B-2	Review	719
I'm wondering whether this allows for an answer regarding general robustness?	I-Review	I-2	Review	719
That is, the experiments are conducted wrt the worst case, while the training does not account for an attack setting.	I-Review	I-2	Review	719
E.g, it is unclear why the classifier would not involve a pre-processing step to counter transformations in input space, see Rowley et al (1998).	I-Review	I-2	Review	719
<sep> <sep> Translation and rotation invariance of neural networks has been addressed by many authors, e.g., see Jaderberg et al (2015) and Marcos et al (2017).	B-Review	B-3	Review	719
<sep> <sep> Adversarial examples are defined to be similar and misclassified with high confidence.	B-Review	B-4	Review	719
<sep> The similarity of the transformation is not addressed properly.	I-Review	I-4	Review	719
E.g., if the goal of the adversary is to force errors, why not allow for rotations of 180 degrees?	I-Review	I-4	Review	719
Pixel-based attacks (Goodfellow et al 2014) are more rigorous in this regard while the cited transformation-based attacks (Kanbak et al 2017; Xiao et al 2018) are virtually indistinguishable from the real test cases.	I-Review	I-4	Review	719
<sep> <sep> The effectiveness of the grid search attack seems to be connected to performing individual tests for each test case where only the worst outcome would count.	B-Review	B-5	Review	719
The sheer number should render a misclassification more likely compared to the competitors.	I-Review	I-5	Review	719
This is supported by empirical findings showing that only a small subset of transformations per test case accounts for the misclassification on CIFAR10 and ImageNet (Fig.10 in the Appendix).	I-Review	I-5	Review	719
<sep> <sep> Regarding the padding experiments, I wonder whether the network architecture is appropriate for the new input.	B-Review	B-6	Review	719
Here, more experimentation is necessary.	I-Review	I-6	Review	719
The conclusion with respect to the first-order method remains a conjecture.	I-Review	I-6	Review	719
<sep> <sep> References:	O	O	Review	719
- Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy.	O	O	Review	719
Explaining and harnessing adversarial examples.	O	O	Review	719
arXiv preprint arXiv:1412.6572, 2014.	O	O	Review	719
<sep> - Max Jaderberg, Karen Simonyan, and Andrew Zisserman.	O	O	Review	719
Spatial transformer networks.	O	O	Review	719
In Advances in neural information processing systems, pp.2017‚Äì2025, 2015.	O	O	Review	719
<sep> - Can Kanbak, Seyed-Mohsen Moosavi-Dezfooli, and Pascal Frossard.	O	O	Review	719
Geometric robustness of deep networks: analysis and improvement.	O	O	Review	719
arXiv preprint arXiv:1711.09115, 2017.	O	O	Review	719
<sep> - Diego Marcos, Michele Volpi, Nikos Komodakis, and Devis Tuia.	O	O	Review	719
Rotation equivariant vector field networks.	O	O	Review	719
In The IEEE International Conference on Computer Vision (ICCV), Oct 2017.	O	O	Review	719
<sep> - Henry Rowley, Shumeet Baluja, and Takeo Kanade.	O	O	Review	719
Rotation invariant neural network-based face detection.	O	O	Review	719
In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pp.38.	O	O	Review	719
sn, 1998.	O	O	Review	719
<sep> - Chaowei Xiao, Jun-Yan Zhu, Bo Li, Warren He, Mingyan Liu, and Dawn Song.	O	O	Review	719
Spatially transformed adversarial examples.	O	O	Review	719
arXiv preprint arXiv:1801.02612, 2018.	O	O	Review	719
We thank the reviewer for their comments.	O	O	Reply	719
We will address concerns raised below:	O	O	Reply	719
<sep> - On the novelty of our approach.	B-Reply	B-1	Reply	719
We are aware that the robustness of NNs to spatial transformations has already been addressed as a research question.	I-Reply	I-1	Reply	719
We cite some of the relevant work (collecting all the citations in a vast field such as deep learning is unfortunately hardly possible) and we plan to add the references pointed out by the reviewer.	I-Reply	I-1	Reply	719
However, we believe that our paper contains a number of novel contributions that are not present in prior work (as we outline in our "summary of contributions" section):	I-Reply	I-1	Reply	719
a) We evaluate concrete and natural baselines for improving spatial robustness.	I-Reply	I-1	Reply	719
While our worst-of-10 training approach is inspired by robust optimization, it has not been applied in this form before (to the best of our knowledge).	I-Reply	I-1	Reply	719
<sep> b) We evaluate the robustness of L_inf trained models, as well as combinations of L_inf and spatial attacks.	I-Reply	I-1	Reply	719
<sep> c) We provide insights on the performance of first-order methods for this task.	I-Reply	I-1	Reply	719
<sep> d) Finally, we point out that a few black-box queries suffice to find misclassifications.	I-Reply	I-1	Reply	719
<sep> (Please also refer to our response to Reviewer 2 on the same topic.)	O	O	Reply	719
<sep> <sep> - The reviewer mentions multiple times how our results are trivial and not surprising.	B-Reply	B-1	Reply	719
We believe that when a problem is as fundamental as the one we study, rigorous evaluation of simple baselines is an important contribution.	I-Reply	I-1	Reply	719
We were not able to find such a thorough study in prior work.	I-Reply	I-1	Reply	719
<sep> <sep> - We are aware of the existence of rotation-invariant architectures as well as preprocessing approaches to transformation robustness.	B-Reply	B-3	Reply	719
Our goal is to understand the spatial robustness of the most popular architectures used for these tasks and challenge the conventional wisdom that these architectures will automatically generalize to naturally occuring transformations.	I-Reply	I-3	Reply	719
Regarding the results of Rowley et al (1998), we would like to emphasize that rotation-invariant face detection is significantly easier, since faces have a canonical orientations (whereas most CIFAR10 and ImageNet categories do not).	I-Reply	I-3	Reply	719
The goal of Marcos et al (2017) is to learn models that are *fully* rotation invariant (i.e. 180 degree rotations are acceptable).	I-Reply	I-3	Reply	719
This is a fundamentally different task from learning models robust to *small* rotations since the later can still exploit the orientation of the image to some extent.	I-Reply	I-3	Reply	719
We will add a discussion of these papers in our manuscript.	I-Reply	I-3	Reply	719
<sep> <sep> - The definition of adversarial examples we are concerned with is "images with semantically similar content that are classified differently".	B-Reply	B-4	Reply	719
Arguably, a 30 degree rotation does not change the content of the image to a human (see provided images in the Appendix), so we consider these to be valid adversarial examples.	I-Reply	I-4	Reply	719
In contrast, a 180 degree rotation would certainly appear wrong or unnatural to a human, such as a '6' turned into a '9' or an upside-down boat.	I-Reply	I-4	Reply	719
We don't view the "high confidence" component of "standard" adversarial examples as very important.	I-Reply	I-4	Reply	719
After all, classifiers are evaluated based on their top1 (and sometimes top5) accuracy.	I-Reply	I-4	Reply	719
Thus the relevant quantity in our setting is the robust accuracy.	I-Reply	I-4	Reply	719
Similarly, we do not view indistinguishability as important, as long as the original and perturbed images have the same content to a human and do not appear clearly transformed.	I-Reply	I-4	Reply	719
<sep> <sep> - On related work: We want to emphasize that the attack of Xiao et al (2018) is a complex attack, operating in a much larger perturbation space (the space of smooth deformations) and utilizing *full gradient access* to the target model.	B-Reply	B-4	Reply	719
It is natural to expect such an attack to succeed with high confidence with minimal distortion.	I-Reply	I-4	Reply	719
At the same time, however, these cannot be seen as "naturally occuring transformations" outside of a security context, in contrast to rotations and translations.	I-Reply	I-4	Reply	719
<sep> <sep> We do not follow the reviewers‚Äô comments about the transformations of Kanbak et al (2018).	I-Reply	I-4	Reply	719
The set of transformations from their paper is very similar to ours, differing in only in parametrization.	I-Reply	I-4	Reply	719
We also want to emphasize that their paper focuses exclusively on first order methods.	I-Reply	I-4	Reply	719
Thus the reliability of their evaluation (compared to the ground-truth gridding that we perform) is questionable given our results about the effectiveness of first-order methods.	I-Reply	I-4	Reply	719
We already include a discussion about this paper in our manuscript.	I-Reply	I-4	Reply	719
<sep> <sep> - We do not understand the reviewer's concern about the amount of grid points used and would be grateful if the reviewer could further elaborate this point.	B-Reply	B-5	Reply	719
If the loss landscape was as well-behaved as in the case of L_inf perturbations, an attack based on projected gradient descent would clearly match a grid search.	I-Reply	I-5	Reply	719
After all, PGD is allowed full access to the gradient of the model (3 real numbers) whereas our grid attack only has access to the output label of the model (a single bit, "classified correctly" or "misclassified").	I-Reply	I-5	Reply	719

The paper tackles the collaborative multi-agent RL problem as the problem of finding almost-decentralized value functions, where the loss tries to minimize communications between the agents.	O	O	Review	719
The core idea is around maximizing the mutual information between each massage and the existing knowledge of its receiver.	O	O	Review	719
This way, redundant messages are naturally removed.	O	O	Review	719
The authors then assert an entropy regularization to (almost) prevent the agents from *cheating*. The paper is in general well-written and motivated.	O	O	Review	719
There are however certain issues that should be addressed. [	O	O	Review	719
The second one is my main issue.]	O	O	Review	719
<sep> 1.	O	O	Review	719
The term *message* has been used repeatedly but not defined.	B-Review	B-1	Review	719
You should define precisely what you mean by a message in the background section.	I-Review	I-1	Review	719
In particular, it is not clear from the text what a message looks like mathematically.	I-Review	I-1	Review	719
You may also consider giving intuitive examples of how different ways of designing a message alters the behaviour in a given context before start talking about how to optimise them.	I-Review	I-1	Review	719
<sep> <sep> 2.	B-Review	B-2	Review	719
Section 3.1 needs a revisit.	I-Review	I-2	Review	719
I assume by "optimal action policy of agent j" you mean "optimal policy of agent j".	I-Review	I-2	Review	719
Formally, an optimal policy is greedy to the optimal value function and is deterministic unless there exist multiple actions with same optimal value at a given state.	I-Review	I-2	Review	719
Therefore, the mutual information is not mathematically well-defined since most of the time the optimal policy is deterministic and does not induce a probability distribution.	I-Review	I-2	Review	719
<sep> <sep> 2.1 What is the optimal value function of an agent?	B-Review	B-2	Review	719
The agents are not optimizing their own value function, so even if your complex model converges, it does not imply optimality of agent-level value functions (and they shouldn‚Äôt be locally optimal).	I-Review	I-2	Review	719
If by that you mean the agent-level value functions *after* convergence of, then you need to clarify it to avoid the confusion.	I-Review	I-2	Review	719
Even so, it is still not clear how you conceive the agent-level policies from these value functions.	I-Review	I-2	Review	719
<sep> <sep> 2.2.	O	O	Review	719
Minor: As for the notation, I found quite strange for a policy; you may want to consider something like.	B-Review	B-2	Review	719
<sep> <sep> 3.	B-Review	B-3	Review	719
If is learnt, then message encoding is not stationary at least in the training time.	I-Review	I-3	Review	719
It may make the training potentially become unstable.	I-Review	I-3	Review	719
Specifically, there is no condition to assure stability of your model.	I-Review	I-3	Review	719
Suggestion: your entropy regularization might be sufficient to induce stability.	I-Review	I-3	Review	719
More discussion on this (or a simple experiment to show if an instability exists and will be alleviated with regularization) would be quite helpful.	I-Review	I-3	Review	719
<sep> 4.	B-Review	B-4	Review	719
If I understand it correctly [and it wasn't clear from the text], the encoder is conditioned on local history, which induces that all the agents must share same history shape (tensor-wise), which in turn means that all the local agents has to have same local state shape (computationally, they should for example have same output/internal-state shape in their neural networks).	I-Review	I-4	Review	719
This sounds like a limitation, and it may only be OK in domains where agents are homogenous.	I-Review	I-4	Review	719
<sep> <sep> Thanks for your detailed and constructive comments.	O	O	Reply	719
Here we provide explanations to clarify your questions.	O	O	Reply	719
<sep> Q1: Precise definition of the message.	O	O	Reply	719
<sep> A1: A message from agent to agent encodes necessary information of the local observation-action history of agent, which is helpful for the decision making of agent.	B-Reply	B-1	Reply	719
Precisely, a message is defined as a sample drawn from a multivariate Gaussian distribution, whose covariance is a unit matrix and whose mean is given by an encoder, where is the local observation-action history of agent and are parameters of the encoder.	I-Reply	I-1	Reply	719
As the reviewer suggested, we have refined and moved this definition to the beginning of Sec.3 in the updated version of our paper.	I-Reply	I-1	Reply	719
<sep> Q2: Confusion about "optimal action policy of agent" in Sec 3.1.	O	O	Reply	719
<sep> A2: Sorry, this is a typo.	B-Reply	B-2	Reply	719
It should be ‚Äúaction selection of agent‚Äù.	I-Reply	I-2	Reply	719
As shown in Fig.1, the mutual information is defined between messages and action selection.	I-Reply	I-2	Reply	719
The variable used in the definition of mutual information is a random variable, whose probability distribution describes how the actions are selected by agent.	I-Reply	I-2	Reply	719
As action selection may depend on other agents, action selection can be stochastic and thus the mutual information is still well-defined.	I-Reply	I-2	Reply	719
We have added more descriptions in the updated version of our paper.	I-Reply	I-2	Reply	719
<sep> Q3: Stability issue of our model.	O	O	Reply	719
<sep> A3: Like QMIX, during the training, our model is just one neural network (the message encoder can be regarded as some hidden layers), which is trained in an end-to-end fashion.	B-Reply	B-3	Reply	719
Therefore, the message encoder will not introduce extra instability, and our model is faced with similar stability issue with QMIX.	I-Reply	I-3	Reply	719
As in QMIX (and many other works in deep reinforcement learning), we use target networks, for both value functions and the message encoder, to stabilize training.	I-Reply	I-3	Reply	719
<sep> Q4: The same history shape of agents limits the domains that our method can be applied.	O	O	Reply	719
<sep> A4: Like most algorithms in MARL, we share network structure and parameters among agents.	B-Reply	B-4	Reply	719
Such sharing is feasible because in common MARL benchmarking environments, such as SC2 unit micromanagement [Samvelyan et al AAMAS 2019] and MPE [Lowe et al NeurIPS 2017], heterogeneous agents have observation and action spaces with the same shape.	I-Reply	I-4	Reply	719
In our SC2 experiments, results on three tasks (1o2r_vs_4r, 1o10b_vs_1r, and MMM) verify that our approach works well with heterogeneous agents.	I-Reply	I-4	Reply	719
<sep> We hope that our clarification can address your questions.	O	O	Reply	719
Please let us know if you have any other questions.	O	O	Reply	719
<sep> [Samvelyan et al AAMAS 2019] Samvelyan, M., Rashid, T., Schroeder de Witt, C., Farquhar, G., Nardelli, N., Rudner, T.G., Hung, C.M., Torr, P.H., Foerster, J. and Whiteson, S., 2019, May. The starcraft multi-agent challenge.	O	O	Reply	719
In Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems (pp.2186-2188).	O	O	Reply	719
International Foundation for Autonomous Agents and Multiagent Systems.	O	O	Reply	719
<sep> [Lowe et al NeurIPS 2017] Lowe, R., Wu, Y., Tamar, A., Harb, J., Abbeel, O.P. and Mordatch, I., 2017.	O	O	Reply	719
Multi-agent actor-critic for mixed cooperative-competitive environments.	O	O	Reply	719
In Advances in Neural Information Processing Systems (pp.6379-6390).	O	O	Reply	719

Authors propose a new method for multi-agent reinforcement learning by using nearly decomposable value functions.	O	O	Review	719
The main idea is to have local (agent specific) value function and one global value function (for all agents).	O	O	Review	719
They also try minimizing the required communication need for multi-agent setup.	O	O	Review	719
To this end they deploy variational inference tools and support their method with an experimental study.	O	O	Review	719
<sep> <sep> I found the paper interesting and empirical evaluation is good.	B-Review	B-1	Review	719
However, my knowledge in the field is quite limited.	I-Review	I-1	Review	719
<sep> <sep> Thanks for your comments and interest in our paper.	O	O	Reply	719
<sep> Recently, the learning paradigm of value function factorization stands out as an effective approach for multi-agent deep reinforcement learning. [	B-Reply	B-1	Reply	719
Samvelyan et al AAMAS 2019] shows that its performance is much better than multi-agent policy gradients and independent value-based algorithm on StarCraft II micromanagement tasks.	I-Reply	I-1	Reply	719
<sep> However, current value function factorization methods *fully* decompose the Q-functions among agents, and, as a result, each agent acts solely on its own local observations during execution.	I-Reply	I-1	Reply	719
This full decomposition is not effective in many cases, because it is quite common that an agent‚Äôs optimal decision makings sometimes depend on information from other agents.	I-Reply	I-1	Reply	719
<sep> To address these limitations, in this paper, we develop a novel function factorization method that learns nearly decomposable value functions.	I-Reply	I-1	Reply	719
Our model learns not only Q-functions for agents but also communication protocols for their improved coordination.	I-Reply	I-1	Reply	719
Different from other communication approaches, we explicitly formalize novel optimization objectives for minimizing communication so that only useful and necessary information (those can reduce uncertainty in value functions of other agents) can be exchanged between agents.	I-Reply	I-1	Reply	719
These novelties explain why our method can significantly improve the performance of QMIX on StarCraft II micromanagement tasks even when 80% of the messages are cut off while other communication methods, e.g., TarMAC [Das et al ICML 2019], can not.	I-Reply	I-1	Reply	719
<sep> [Samvelyan et al AAMAS 2019] Samvelyan, M., Rashid, T., Schroeder de Witt, C., Farquhar, G., Nardelli, N., Rudner, T.G., Hung, C.M., Torr, P.H., Foerster, J. and Whiteson, S., 2019, May. The starcraft multi-agent challenge.	O	O	Reply	719
In Proceedings of the 18th International Conference on Autonomous Agents and Multi-Agent Systems (pp.2186-2188).	O	O	Reply	719
International Foundation for Autonomous Agents and Multi-agent Systems.	O	O	Reply	719
<sep> [Das et al ICML 2019] Das, A., Gervet, T., Romoff, J., Batra, D., Parikh, D., Rabbat, M. and Pineau, J., 2019, May. TarMAC: Targeted Multi-Agent Communication.	O	O	Reply	719
In International Conference on Machine Learning (pp.1538-1546).	O	O	Reply	719

The authors propose a framework for combining value function factorization and communication learning in a multi-agent setting by introducing two regularizers, one for maximizing mutual information between decentralized Q functions and communication messages and the other for minimizing the entropy of messages between agents.	O	O	Review	719
The authors also discuss a method for dropping non-informative messages.	O	O	Review	719
They illustrate their approach on sensor and hallway tasks and evaluate their method on the decentralized StarCraft II benchmark.	O	O	Review	719
The paper addresses an interesting problem, and the authors show that their approach gives good performance compared to alternative approaches even when a large percentage of communication is cut off between the agents.	O	O	Review	719
<sep> <sep> Questions/Comments:	O	O	Review	719
- Implementation details (e.g., hyper-parameters, model size) are missing from the paper.	B-Review	B-1	Review	719
<sep> - The results are average over only 3 seeds, is this enough to compare different algorithms?	B-Review	B-2	Review	719
<sep> - How should beta should be determined?	B-Review	B-3	Review	719
<sep> - The authors present results when 80% of messages are cut off.	B-Review	B-4	Review	719
What is the performance of the model when all communication is cut off for comparison?	I-Review	I-4	Review	719
<sep> - How does the approach work in competitive environments?	B-Review	B-5	Review	719
<sep> - The experimental results section is not well organized.	B-Review	B-6	Review	719
The authors mention five question on page 6, but it is not very clear with examples/set of experiments address which question.	I-Review	I-6	Review	719
<sep> - There are many spelling/grammar errors in the paper.	B-Review	B-7	Review	719
Thanks for your comments.	O	O	Reply	719
Here we provide explanations to clarify your questions.	O	O	Reply	719
In addition, please feel free to refer to our response to reviewer #1, which summarizes novelties of our paper.	O	O	Reply	719
<sep> Q: Implementation details (e.g., hyper-parameters, model size) are missing from the paper.	O	O	Reply	719
<sep> A: These details were described in Appendix B of our original submission because of the space limitation.	B-Reply	B-1	Reply	719
<sep> Q: The results are average over only 3 seeds, is this enough to compare different algorithms?	O	O	Reply	719
<sep> A: We have run all the SC2 experiments with more random seeds and found that the variances of learning curves are similar and the performance comparison results do not change.	B-Reply	B-2	Reply	719
We have shown learning curves averaged over 5 different random seeds in Fig.7, 8, and 10 in the updated version of our paper.	I-Reply	I-2	Reply	719
Q: How beta should be determined?	O	O	Reply	719
<sep> A: is used to trade off communication costs and communication effects.	B-Reply	B-3	Reply	719
We have studied how affects the message embedding on the task sensor, as shown in Fig.3 on page 6.	I-Reply	I-3	Reply	719
We also find that the performance of our method is robust across all the tested environments when.	I-Reply	I-3	Reply	719
Therefore, we recommend that a in this region being tried first on new tasks and some fine-tuning may improve the performance further.	I-Reply	I-3	Reply	719
<sep> Q: The authors present results when 80% of the messages are cut off.	O	O	Reply	719
What is the performance of the model when all communication is cut off for comparison?	O	O	Reply	719
<sep> A: We have shown the performance comparison when all communication is cut off, which is illustrated by Fig.10 on page 16 of our original submission.	B-Reply	B-4	Reply	719
<sep> Q: How does the approach work in competitive environments?	O	O	Reply	719
<sep> A: Our approach is designed for a team of agents to learn to effectively collaborate and coordinate.	B-Reply	B-5	Reply	719
These cooperative scenarios are common in the field of MARL [Foerster et al AAAI 2018, Rashid et al ICML 2018]. Of course, such a team of agents can compete against another opponent team in competitive settings.	I-Reply	I-5	Reply	719
<sep> In mixed cooperative-competitive tasks, our method is readily combined with IC3Net [Singh et al ICLR 2019], learning gates to cut off messages sent to the opponents.	I-Reply	I-5	Reply	719
It will be the same as how TarMAC [Das et al ICML 2019] is adapted to mixed environments.	I-Reply	I-5	Reply	719
However, this setting is not the focus of this paper, and we will explore it in the future.	I-Reply	I-5	Reply	719
<sep> Q: The experimental results section is not well organized.	O	O	Reply	719
The authors mention five questions on page 6, but it is not very clear which examples/set of experiments address which question.	O	O	Reply	719
<sep> A: Performance comparison and visualization results of didactic experiments can clarify all the questions.	B-Reply	B-6	Reply	719
Our SC2 experiments further prove that the miscoordination problem of full decomposition methods is quite common and that our method can outperform QMIX and a state-of-the-art attentional communication algorithm.	I-Reply	I-6	Reply	719
<sep> We hope that our clarifications can address your questions.	O	O	Reply	719
Please let us know if you have any other questions.	O	O	Reply	719
<sep> [Foerster et al AAAI 2018] Foerster, J.N., Farquhar, G., Afouras, T., Nardelli, N. and Whiteson, S., 2018, April.	O	O	Reply	719
Counterfactual multi-agent policy gradients.	O	O	Reply	719
In Thirty-Second AAAI Conference on Artificial Intelligence.	O	O	Reply	719
<sep> <sep> [Rashid et al ICML 2019] Rashid, T., Samvelyan, M., Witt, C.S., Farquhar, G., Foerster, J. and Whiteson, S., 2018, July.	O	O	Reply	719
QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning.	O	O	Reply	719
In International Conference on Machine Learning (pp.4292-4301).	O	O	Reply	719
<sep> [Singh et al ICLR 2019] Singh, A., Jain, T. and Sukhbaatar, S., 2019.	O	O	Reply	719
Learning when to communicate at scale in multiagent cooperative and competitive tasks.	O	O	Reply	719
In International Conference on Learning Representations.	O	O	Reply	719
<sep> [Das et al ICML 2019] Das, A., Gervet, T., Romoff, J., Batra, D., Parikh, D., Rabbat, M. and Pineau, J., 2019, May. TarMAC: Targeted Multi-Agent Communication.	O	O	Reply	719
In International Conference on Machine Learning (pp.1538-1546).	O	O	Reply	719

The main contribution of this paper is to propose an improvement to the bits back (BB) coding scheme by using asymmetric numeral systems (ANS) rather than arithmetic coding for the implementation.	O	O	Review	578
ANS is a natural fit with BB since it traverses the coded sequence stack-style rather than FIFO.	O	O	Review	578
A second contribution is show how generative models with continuous latent variables can be used (via discretization) within this scheme.	O	O	Review	578
The paper is generally well-written, and the explanation in Sec 2.4 was especially clear.	O	O	Review	578
However I have some questions about the evaluation and practical application of this scheme.	O	O	Review	578
<sep> <sep> The comparison in Figure 1 is very compelling, but it would be helpful to have some additional information.	B-Review	B-1	Review	578
In particular, does the size reported for BB-ANS include any overhead related to meta information (e.g., number of images stored, their dimensions, format, etc.)?	I-Review	I-1	Review	578
PNG is a general purpose image file format, so it certainly contains such overhead.	I-Review	I-1	Review	578
This makes it unclear how fair of a comparison we have here.	I-Review	I-1	Review	578
Similarly, bz2 is a general purpose file compression scheme.	I-Review	I-1	Review	578
What file format were the images written as before being compressed?	B-Review	B-2	Review	578
Either of those cases (PNG, bz2) could be opened on any other computer without the need for additional information (just a program that knows how to read/decompress those file formats).	I-Review	I-2	Review	578
On the other hand, the BB-ANS bitstream is not interpretable without the models used when compressing, and as discussed in Sec 4.3, there is certainly additional overhead involved in communicating the model which is not indicated here.	I-Review	I-2	Review	578
<sep> <sep> In any case, the compression rate achieved is impressive, but at the same time, not so surprising given that the model was trained on MNIST.	B-Review	B-3	Review	578
Have you checked how well a model trained on a more general image dataset (e.g., ImageNet) compresses other images (e.g., MNIST)?	I-Review	I-3	Review	578
<sep> <sep> Sec 3.2 mentions finding that around 400 clean bits are required.	B-Review	B-4	Review	578
How does the performance vary as fewer (or more) clean bits are used?	I-Review	I-4	Review	578
More generally, do you have suggestions for how to determine an appropriate number of clean bits for other scenarios? (	I-Review	I-4	Review	578
E.g., does it depend on the number of images to be compressed?	I-Review	I-4	Review	578
their size?	I-Review	I-4	Review	578
some notion of the entropy of the set of images to be compressed?	I-Review	I-4	Review	578
other factors?)	I-Review	I-4	Review	578
<sep> <sep> Also, how does the performance vary with the number of symbols (images) to be compressed?	B-Review	B-5	Review	578
I'd believe that the compression rate approaches the ELBO as the number of compressed images becomes large, but how quickly does this convergence occur?	I-Review	I-5	Review	578
How well does the method do if the VAE is trained using a smaller sample size?	I-Review	I-5	Review	578
<sep> <sep> Overall this is an interesting idea, and I believe it could be an excellent lossless compression scheme in scenarios where it's applicable.	O	O	Review	578
At the same time, there are many aspects where the paper could be strengthened by providing a more thorough investigation/evaluation.	O	O	Review	578
<sep> <sep> <sep> Minor:	O	O	Review	578
- In Sec 2.1, using p for both a general pdf and the model to be learned (i.e., of both s_n and b_i) is potentially confusing.	B-Review	B-6	Review	578
<sep> - Sec 2.5.1 talks about using uniform quantization (buckets of equal width \delta y), but then Appendix B talks about using (nonuniform) maximum entropy discretization.	I-Review	I-6	Review	578
Which was used in the experiments?	I-Review	I-6	Review	578
In an implementation, the quantization strategy needs to be known by both sender and receiver too, so this is additional meta-information overhead, right?	I-Review	I-6	Review	578
<sep> - The discussion in Sec 4.1 seems very speculative and not particularly convincing.	I-Review	I-6	Review	578
Thank you for taking the time to read and review our paper.	O	O	Reply	578
We address the points raised below.	O	O	Reply	578
For ease of reading we've interleaved our responses with the points from the review.	O	O	Reply	578
<sep> > The comparison in Figure 1 is very compelling, but it would be helpful to have some additional information.	O	O	Reply	578
In particular, does the size reported for BB-ANS include any overhead related to meta information (e.g., number of images stored, their dimensions, format, etc.)?	O	O	Reply	578
PNG is a general purpose image file format, so it certainly contains such overhead.	O	O	Reply	578
This makes it unclear how fair of a comparison we have here.	O	O	Reply	578
Similarly, bz2 is a general purpose file compression scheme.	O	O	Reply	578
What file format were the images written as before being compressed?	O	O	Reply	578
<sep> <sep> As the review points out, Figure 1 compares our algorithm, which is specialised to MNIST digits, to two general purpose algorithms.	B-Reply	B-1	Reply	578
The figure, which appears in the introduction, was intended to give the reader an intuitive sense of what the paper is about, rather than provide a rigorous comparison.	I-Reply	I-1	Reply	578
<sep> <sep> For readers seeking more detail, rather than provide more technical details in the paper, which we feel would distract from the flow of the introduction, we've added code to reproduce the figure to the Github repo (<a href="https://github.com/bits-back/bits-back/blob/master/make_fig_1.py" target="_blank" rel="nofollow">https://github.com/bits-back/bits-back/blob/master/make_fig_1.py</a> ) and updated the paper, mentioning the code to reproduce the figure in a footnote on page 2.	I-Reply	I-1	Reply	578
<sep> <sep> To answer the specific points in the review, the BB-ANS bit stream does not include any overhead related to meta information.	I-Reply	I-1	Reply	578
It was generated using the BB-ANS algorithm detailed in Sec 2.4, which has no provision for meta data.	I-Reply	I-1	Reply	578
The PNG stream does, as pointed out, contain some meta-data, including (at least) the dimensions of and number of color channels in the images.	I-Reply	I-1	Reply	578
The bz2 stream contains no metadata and was run directly on the raw bits in the (concatenated) images, with no shape or channel information.	I-Reply	I-1	Reply	578
We thought this was the fairest way to compare bz2 to BB-ANS.	I-Reply	I-1	Reply	578
<sep> <sep> <sep> <sep> > Either of those cases (PNG, bz2) could be opened on any other computer without the need for additional information (just a program that knows how to read/decompress those file formats).	O	O	Reply	578
On the other hand, the BB-ANS bitstream is not interpretable without the models used when compressing, and as discussed in Sec 4.3, there is certainly additional overhead involved in communicating the model which is not indicated here.	O	O	Reply	578
<sep> <sep> A program that knows how to read/decompress PNG/bz2 formats is analogous to a program that implements BB-ANS and has access to a model.	B-Reply	B-2	Reply	578
That is to say, a compressed bz2 bitstream is equally as incomprehensible as a BB-ANS bitstream without access to software which knows how the data was compressed.	I-Reply	I-2	Reply	578
The fact that a person could open bz2 compressed files on any computer now is simply due to the popularity of that compression scheme.	I-Reply	I-2	Reply	578
<sep> <sep> However, it's possible that a program that implements BB-ANS for encoding and contained the model weights could be larger than the analogous program required to encode/decode a format like bz2.	I-Reply	I-2	Reply	578
We don't rigorously compare these file sizes, because we feel it's outside of the scope of our paper.	I-Reply	I-2	Reply	578
However we do discuss this issue and potential mitigations in section 4.3.	I-Reply	I-2	Reply	578
<sep> <sep> <sep> > In any case, the compression rate achieved is impressive, but at the same time, not so surprising given that the model was trained on MNIST.	O	O	Reply	578
Have you checked how well a model trained on a more general image dataset (e.g., ImageNet) compresses other images (e.g., MNIST)?	O	O	Reply	578
<sep> <sep> This is a very interesting point, and certainly a relevant one if we are to consider using BB-ANS as we would use generic algorithms like PNG.	B-Reply	B-3	Reply	578
However, we believe that it is essentially a modelling question, and the main focus of this paper is not on modelling questions, but on how to do compression given a model.	I-Reply	I-3	Reply	578
<sep> <sep> To find out how well BB-ANS would compress MNIST data using a model trained on ImageNet, we would not need to run BB-ANS compression with the model.	I-Reply	I-3	Reply	578
Instead we could just examine the loss values (i.e. ELBO) obtained on MNIST data with a latent variable model trained on ImageNet.	I-Reply	I-3	Reply	578
That is because we have shown that BB-ANS can losslessly compress data at a rate close to the ELBO value.	I-Reply	I-3	Reply	578
Therefore this problem is not one related to BB-ANS directly, but instead a modelling question - can we train a model that would have low negative ELBO (loss) values for a wide range of images?	I-Reply	I-3	Reply	578

The paper is very well written and the clarity is overall high.	O	O	Review	578
However, I was left with some questions about the significance of this work after reading this paper.	O	O	Review	578
<sep> <sep> The authors approach the problem in the Bayesian inference framework.	B-Review	B-1	Review	578
Essentially, the message is modeled as a linear neural network with a single latent layer.	I-Review	I-1	Review	578
The authors only specify the distributions for the posterior and prior in the experimental section, where they set them both to Gaussians.	B-Review	B-2	Review	578
This naturally raise the question how is this model different from the probabilistic PCA model?	B-Review	B-3	Review	578
Moreover, I am confused why would it be necessary to introduce an approximation q(y|s) of the posterior p(y|s), when there is a well known closed form expression for Gaussians?	B-Review	B-4	Review	578
Furthermore, this Gaussian model is well known to have non-unique maximum likelihood solution (due to the invariance to an arbitrary orthogonal transformation).	B-Review	B-5	Review	578
How does that influence the addressed compression problem?	I-Review	I-5	Review	578
Going back to equations (1)-(2), if the authors chose different distributions and the need for the ELBO was justified, wouldn‚Äôt that lead to an approximate representation?	B-Review	B-6	Review	578
That is, wouldn‚Äôt that necessary imply some loss in compression?	I-Review	I-6	Review	578
And if yes, wouldn't then the proposed approach be not a lossless but a lossy compression algorithm?	I-Review	I-6	Review	578
And then why would this particular approach be better than other numerous lossy compression algorithms which the authors cite?	B-Review	B-7	Review	578
Thanks very much for taking the time to read and review our paper.	O	O	Reply	578
<sep> <sep> Summary of our response	O	O	Reply	578
------------------------------------------	O	O	Reply	578
The first part of the review focuses mainly on modelling questions.	O	O	Reply	578
We directly address the points made below.	O	O	Reply	578
However we'd like to emphasize that our paper, and the contributions we make, are not intended to be about modelling, and for more detail on the type of modelling we did, readers should refer to other papers that we cite, such as [1] and [2].	O	O	Reply	578
<sep> The second part of the review presents an argument which concludes that our method results in lossy compression.	O	O	Reply	578
This argument is incorrect.	O	O	Reply	578
Our algorithm is theoretically guaranteed to be lossless, because it comprises a sequence of ANS steps, each of which is lossless.	O	O	Reply	578
We think the code that we have written, which tests the correctness of decoded data explicitly, provides a strong practical demonstration of this (<a href="https://github.com/bits-back/bits-back/blob/master/torch_vae/torch_bin_mnist_compress.py#L89" target="_blank" rel="nofollow">https://github.com/bits-back/bits-back/blob/master/torch_vae/torch_bin_mnist_compress.py#L89</a> and <a href="https://github.com/bits-back/bits-back/blob/master/torch_vae/torch_mnist_compress.py#L83)."	O	O	Reply	578
target="_blank" rel="nofollow">https://github.com/bits-back/bits-back/blob/master/torch_vae/torch_mnist_compress.py#L83).</a>	O	O	Reply	578
<sep> The argument made is highly concerning for us because it suggests that the reviewer has not understood our method, and its significance, at all.	O	O	Reply	578
<sep> <sep> Detailed response	O	O	Reply	578
-----------------------------	O	O	Reply	578
> Essentially, the message is modeled as a linear neural network with a single latent layer.	O	O	Reply	578
<sep> <sep> The message is not modelled.	B-Reply	B-1	Reply	578
The data (in our experiments, the MNIST dataset), is modelled using a variational auto-encoder (VAE) model.	I-Reply	I-1	Reply	578
In our experiments we use a generative model with a ReLU non-linearity, as detailed in our paper, Section 3.2, paragraphs 3 and 4.	I-Reply	I-1	Reply	578
See [1] or [2] for an introduction to these models.	I-Reply	I-1	Reply	578
<sep> <sep> > The authors only specify the distributions for the posterior and prior in the experimental section, where they set them both to Gaussians.	O	O	Reply	578
<sep> <sep> We also specify a likelihood for each of the two different VAE models that we used in our experiments.	B-Reply	B-2	Reply	578
We do this in Section 3.2, paragraphs 3 and 4.	I-Reply	I-2	Reply	578
The (approximate) posterior we use is Gaussian but only when conditioned on the observation.	I-Reply	I-2	Reply	578
The mapping from the observation to the conditional mean and covariance matrix is non-linear.	I-Reply	I-2	Reply	578
<sep> <sep> > This naturally raise the question how is this model different from the probabilistic PCA model?	O	O	Reply	578
<sep> <sep> The key difference is the non-linearity in the conditional distribution (likelihood) p(s | y).	B-Reply	B-3	Reply	578
We also use discrete distributions for p(s | y), not Gaussian as in PPCA.	I-Reply	I-3	Reply	578
This is detailed in Section 3.2 of our paper, paragraphs 3 and 4.	I-Reply	I-3	Reply	578
<sep> <sep> > Moreover, I am confused why would it be necessary to introduce an approximation q(y|s) of the posterior p(y|s), when there is a well known closed form expression for Gaussians?	O	O	Reply	578
<sep> <sep> The likelihoods we use contain ReLU non-linearities and there is not conjugacy between the prior and the likelihood, and no known closed form expression for the posterior in this case.	B-Reply	B-4	Reply	578
Also the observations are not Gaussian.	I-Reply	I-4	Reply	578
<sep> <sep> > Furthermore, this Gaussian model is well known to have non-unique maximum likelihood solution (due to the invariance to an arbitrary orthogonal transformation).	O	O	Reply	578
How does that influence the addressed compression problem?	O	O	Reply	578
<sep> <sep> Although the review is wrong about the type of model we use, it is true that the model we use also has symmetries which imply that no maximum likelihood solution is unique.	B-Reply	B-5	Reply	578
As far as we are aware this does not influence the addressed compression problem.	I-Reply	I-5	Reply	578
<sep> <sep> > Going back to equations (1)-(2), if the authors chose different distributions and the need for the ELBO was justified, wouldn‚Äôt that lead to an approximate representation?	O	O	Reply	578
That is, wouldn‚Äôt that necessary imply some loss in compression?	O	O	Reply	578
And if yes, wouldn't then the proposed approach be not a lossless but a lossy compression algorithm?	O	O	Reply	578
<sep> <sep> Any practical model for real world data is approximate.	B-Reply	B-6	Reply	578
This implies that any lossless compression algorithm using that model will not attain an optimal compression rate.	I-Reply	I-6	Reply	578
However a sub-optimal compression rate is *not* the same as lossy compression.	I-Reply	I-6	Reply	578
The 'compression rate' pertains to the length of the message which is output by the algorithm, not the amount of data loss.	I-Reply	I-6	Reply	578
See [3] Chapters 4-6 for an introduction to these topics.	I-Reply	I-6	Reply	578
<sep> <sep> References	O	O	Reply	578
-----------------	O	O	Reply	578
[1] Kingma, D. P. and Welling, M. (2013).	O	O	Reply	578
Auto-Encoding Variational Bayes.	O	O	Reply	578
In Proceedings of the International Conference on Learning Representations (ICLR).	O	O	Reply	578
<sep> [2] Rezende, D. J., Mohamed, S., and Wierstra, D. (2014).	O	O	Reply	578
Stochastic backpropagation and approximate inference in deep generative models.	O	O	Reply	578
In International Conference on Machine Learning (ICML).	O	O	Reply	578
<sep> [3] Mackay, D. (2003).	O	O	Reply	578
Information Theory, Inference and Learning Algorithms.	O	O	Reply	578
Cambridge University Press.	O	O	Reply	578

This paper is built on a simple but profound observation: Frey's bits-back coding algorithm can be implemented much more elegantly when replacing arithmetic coding (AC) with asymmetric numerical systems (ANS), a much more recent development not known at the time, simply due to the fact that it encodes symbols in a stack-like fashion rather than queue-like.	O	O	Review	578
<sep> <sep> This simple observation makes for an elegantly written paper, with promising results on MNIST.	O	O	Review	578
I truly enjoyed reading it, and I'm convinced that it will spark some very interesting further work in the field of compression with latent-variable models.	O	O	Review	578
<sep> <sep> Having said that, I would like to point out some possible limitations of the proposed approach, which I hope the authors will be able to address/clarify:	O	O	Review	578
<sep> 1.	B-Review	B-1	Review	578
At the beginning of section 2.1, the authors define the symbols as chained conditionals prod_n p(s_n | s_1 ... s_n-1), which is generally permissible in AC as well as ANS, as long as the decoding order is taken into account.	I-Review	I-1	Review	578
That is, in AC, the symbols need to be encoded starting with the first symbol in the chain (s_1), while in ANS, the symbols must be encoded starting with the last symbol in the chain, because the decoding order is inverted.	I-Review	I-1	Review	578
<sep> <sep> In their description of BB-ANS, the authors omit the discussion of conditional chains.	I-Review	I-1	Review	578
It is unclear to me if a conditioning of the symbols is feasible in BB-ANS due to the necessity to maintain a strict decoding order.	I-Review	I-1	Review	578
It would be very helpful if the authors could clarify this, and update the paper accordingly, because this could present a serious limitation.	I-Review	I-1	Review	578
For instance, the authors simply extrapolate the performance of their method to PixelVAE; however, this model is autoregressive, so a conditioning of symbols seems necessary.	I-Review	I-1	Review	578
Similarly, in appendix A, the authors mention the work of Minnen et al (2018), where the same situation would apply, albeit one probabilistic level higher (on encoding/decoding the latents with an autoregressive prior).	I-Review	I-1	Review	578
<sep> <sep> 2.	B-Review	B-2	Review	578
Furthermore, in both cases (PixelVAE and Minnen et al), the symbols (s) and latents (y) are defined as jointly conditioned on each other (i.e., computing the posterior on one element of y requires knowledge of all elements of s, and computing the likelihood on one element of s requires knowledge of all elements of y).	I-Review	I-2	Review	578
This seems to imply that all operations pertaining to one data vector (i.e. to one image) would have to be done in a monolithic fashion, i.e.: first sample all elements of y from the stack, then encode all elements of s, and then encode all elements of y. Hence, if the goal is to compress only one image, the algorithm would never get to the point of reusing the "bits back", and the overhead of BB-ANS would be prohibitive.	I-Review	I-2	Review	578
It seems that in the MNIST experiments, the authors avoid this problem by always encoding a large number of images at a time, such that the overhead is amortized.	I-Review	I-2	Review	578
<sep> <sep> 3.	O	O	Review	578
Similarly, although the compression of continuous-valued variables up to arbitrary precision is an exciting development and I do not wish to undermine the importance of this finding, it should be noted that the finer the quantization gets, the larger the potential overhead of the coding scheme will grow.	B-Review	B-3	Review	578
In practice, this would make it necessary to encode more and more images together, in order to still benefit from the method.	I-Review	I-3	Review	578
This would be a good point to make in the discussion.	I-Review	I-3	Review	578
<sep> <sep> 4.	O	O	Review	578
The authors state in the appendix that learned compression methods like Ball√© et al (2018) and Minnen et al (2018) could be improved by using BB-ANS.	B-Review	B-4	Review	578
The potential gain of BB-ANS for these models seems rather small, though, as the entropy of y must be larger or equal to the entropy of y conditioned on s: H[y] >= H[y|s], the latter of which should represent the potential coding gain.	I-Review	I-4	Review	578
Ball√© et al (2018), however, found that the bits used to encode the hierarchical prior (i.e. H[y]) is only a small fraction of the total bitrate, thus upper bounding the potential gains for this type of model.	I-Review	I-4	Review	578
<sep> <sep> Overall, I think this is a well-written, important and elegant paper, and I would like to see it accepted at this conference.	O	O	Review	578
If the authors can satisfactorily address some of the above potential limitations, it might turn out to be even better.	O	O	Review	578
<sep> <sep> > 2.	O	O	Reply	578
Furthermore, in both cases (PixelVAE and Minnen et al), the symbols (s) and latents (y) are defined as jointly conditioned on each other (i.e., computing the posterior on one element of y requires knowledge of all elements of s, and computing the likelihood on one element of s requires knowledge of all elements of y).	O	O	Reply	578
This seems to imply that all operations pertaining to one data vector (i.e. to one image) would have to be done in a monolithic fashion, i.e.: first sample all elements of y from the stack, then encode all elements of s, and then encode all elements of y. Hence, if the goal is to compress only one image, the algorithm would never get to the point of reusing the "bits back", and the overhead of BB-ANS would be prohibitive.	O	O	Reply	578
It seems that in the MNIST experiments, the authors avoid this problem by always encoding a large number of images at a time, such that the overhead is amortized.	O	O	Reply	578
<sep> <sep> 2. (	O	O	Reply	578
RESPONSE) The point you make here is correct.	B-Reply	B-2	Reply	578
When there is no 'other information' to communicate, and only a single sample, or a very small number of i.i.d.	I-Reply	I-2	Reply	578
samples are to be compressed, our method is sub-optimal, and we should certainly have highlighted this limitation in our paper.	I-Reply	I-2	Reply	578
We have extended the first paragraph of Section 2.5 of our paper, emphasizing this point .	I-Reply	I-2	Reply	578
We have also renamed Section 2.5 to "Issues affecting the efficiency of BB-ANS".	I-Reply	I-2	Reply	578
<sep> <sep> Nevertheless, we believe there are common use cases where a large enough number of (roughly) i.i.d.	I-Reply	I-2	Reply	578
samples need to be coded, one example being a person's photo library, stored on their computer or smartphone.	I-Reply	I-2	Reply	578
It is also possible that file meta-data could be used as a source of extra information.	I-Reply	I-2	Reply	578
We have yet to investigate whether there is sufficient information in typical real world meta-data to resolve this issue.	I-Reply	I-2	Reply	578
<sep> <sep> <sep> <sep> > 3.	O	O	Reply	578
Similarly, although the compression of continuous-valued variables up to arbitrary precision is an exciting development and I do not wish to undermine the importance of this finding, it should be noted that the finer the quantization gets, the larger the potential overhead of the coding scheme will grow.	O	O	Reply	578
In practice, this would make it necessary to encode more and more images together, in order to still benefit from the method.	O	O	Reply	578
This would be a good point to make in the discussion.	O	O	Reply	578
<sep> <sep> 3. (	O	O	Reply	578
RESPONSE) This is a good point, which is definitely worth mentioning.	B-Reply	B-3	Reply	578
We have added an extra paragraph discussing this point, near the end of Section 2.5.1.	I-Reply	I-3	Reply	578
We also mention that we found that increasing the precision past around 16 bits yielded no measurable gains in compression rate.	I-Reply	I-3	Reply	578
We think this is because the models we used (like most machine learning implementations) operated at 32 bit floating point precision.	I-Reply	I-3	Reply	578
<sep> <sep> <sep> <sep> > 4.	O	O	Reply	578
The authors state in the appendix that learned compression methods like Ball√© et al (2018) and Minnen et al (2018) could be improved by using BB-ANS.	O	O	Reply	578
The potential gain of BB-ANS for these models seems rather small, though, as the entropy of y must be larger or equal to the entropy of y conditioned on s: H[y] >= H[y|s], the latter of which should represent the potential coding gain.	O	O	Reply	578
Ball√© et al (2018), however, found that the bits used to encode the hierarchical prior (i.e. H[y]) is only a small fraction of the total bitrate, thus upper bounding the potential gains for this type of model.	O	O	Reply	578
<sep> <sep> 4. (	O	O	Reply	578
RESPONSE) Thanks a lot for pointing that out.	B-Reply	B-4	Reply	578
The paragraph in question here is not central to our paper.	I-Reply	I-4	Reply	578
However we feel that in spite of the limited gains in compression rate from BB-ANS in the case of the two papers mentioned, it's still worth us including this paragraph, particularly because it's quite possible that in future work similar to the two papers mentioned the gain from getting the bits back could be more significant.	I-Reply	I-4	Reply	578
We've reworded the paragraph, incorporating the bound which you mention.	I-Reply	I-4	Reply	578
<sep> <sep> References	O	O	Reply	578
---------------	O	O	Reply	578
[1] Johnson, M., Duvenaud, D., Wiltschko, A., Datta, S. and Adams, R. (2016).	O	O	Reply	578
Composing graphical models with neural networks for structured representations and fast inference.	O	O	Reply	578
In Advances in Neural Information Processing Systems (NIPS).	O	O	Reply	578

The hypothesis in this paper is that the primary purpose of the cells of the V1 cortex is to perceive motions and predict changes in the local image contents.	O	O	Review	578
The authors show that by learning from image pairs from a continuous sequence, both V1-like features and motion operators can be learned.	O	O	Review	578
I found the hypothesis and formulation reasonable, the numerical results are supportive, it's actually interesting to see that the proposed model's motion prediction outperforms the other dedicated models.	O	O	Review	578
Further, the authors used inference to infer the motion during learning, I think this is quite a novel topic to work on.	O	O	Review	578
Overall, this makes a good submission.	O	O	Review	578
<sep> <sep> Here are some issues could be addressed further:	O	O	Review	578
<sep> 1.	B-Review	B-1	Review	578
Section 3.3 introduces subvectors.	I-Review	I-1	Review	578
This implicitly introduces an independence assumption when combined with a motion operator.	I-Review	I-1	Review	578
Then in section 5, the authors studied the dimensionality of subvectors.	I-Review	I-1	Review	578
If the subspaces are assumed to be 2, then this independence regularization is quite strong.	I-Review	I-1	Review	578
This may not support the authors' claim that the prediction of motion is enough to achieve V1-like features and I tend to conclude the V1-like receptive fields come from the implicit independence constraint.	I-Review	I-1	Review	578
I'd suggest an additional ablation experiment to verify the impact of the subspace assumption.	I-Review	I-1	Review	578
<sep> <sep> 2.	O	O	Review	578
To model the motion,  we can directly use lie operators, the authors may want to discuss the connection between the suggested method and the Lie group approach.	B-Review	B-2	Review	578
<sep> <sep> 3.	B-Review	B-3	Review	578
I found some minor issues, e.g.:	I-Review	I-3	Review	578
3.1 In Section 3.2 it's normalized tight frame (Parseval frame).	I-Review	I-3	Review	578
<sep> 3.2 In Equation 2 I understand it's a deconvolution, however, the notation is still not ideal.	I-Review	I-3	Review	578
<sep> 3.3 In the section paragraph of Section 3.2,  'the representation has the isometry property' and 'the vector representation also preserves the angle' should be switched?	I-Review	I-3	Review	578
<sep> 3.4 small typos like 'mortar cortex' -&gt; 'motor cortex'.	I-Review	I-3	Review	578
We are very grateful for your positive review and insightful comments.	O	O	Reply	578
<sep> <sep> Q1: ‚ÄúI tend to conclude the V1-like receptive fields come from the implicit independence constraint.	O	O	Reply	578
‚Äù	O	O	Reply	578
A1: This is a deep insight that we agree.	B-Reply	B-1	Reply	578
We have added a comment that this constraint is necessary for the emergence of V1-like receptive fields in Subsection 3.3.	I-Reply	I-1	Reply	578
<sep> <sep> In Appendix G (Appendix D of the original version), we include an ablation study of subspace assumption.	I-Reply	I-1	Reply	578
V1-like patterns also emerge when the dimensionality of subspace is higher (e.g., 4 or 6).	I-Reply	I-1	Reply	578
<sep> <sep> Following your suggestion, we have added a result in Appendix E of the revised version, where we totally remove the assumption of sub-vectors.	I-Reply	I-1	Reply	578
In this case, more blob-like patterns are learned.	I-Reply	I-1	Reply	578
<sep> <sep> The sub-vectors may correspond to columns or modules of neurons, or capsules, i.e., neurons that form sub-groups.	I-Reply	I-1	Reply	578
<sep> <sep> Q2: ‚Äúconnection between the suggested method and the Lie group approach.	O	O	Reply	578
‚Äù	O	O	Reply	578
<sep> A2: Thanks for the insightful suggestion.	O	O	Reply	578
We have added a comment on this connection in Section 2.	O	O	Reply	578
<sep> <sep> In our work, the displacements dx form a 2D Euclidean group.	B-Reply	B-2	Reply	578
Our modeling of local motion dx is similar to the treatment of Lie group via Lie algebra by analyzing infinitesimal changes.	I-Reply	I-2	Reply	578
<sep> <sep> The objects in the image may undergo more complex motions which form more complex Lie groups (e.g., rotations and translations).	I-Reply	I-2	Reply	578
We can again represent the objects (e.g., their poses) by vectors, and represent the motions of the objects by matrices.	I-Reply	I-2	Reply	578
<sep> <sep> <sep> We have followed your suggestions to correct those minor errors in the revision.	B-Reply	B-3	Reply	578
Thank you for careful reading.	I-Reply	I-3	Reply	578

The authors propose a model for learning local pixel motions between pairs of frames using local image representations and relative pixel displacements between agents and objects.	O	O	Review	578
The model learned is compared to the ability of the primary visual cortex where adjacent simple cells share quadrature relationships and capture local motion.	O	O	Review	578
<sep> <sep> "The representation theory underlies much of modern mathematics and holds the key to the quantum	B-Review	B-1	Review	578
theory (Zee, 2016)."	I-Review	I-1	Review	578
<sep> Can the relevance of this claim be elaborated on?	I-Review	I-1	Review	578
<sep> <sep> "Figure 1 illustrates the scheme of representation."	B-Review	B-2	Review	578
<sep> Please provide more detail here on what is happening in the figure.	I-Review	I-2	Review	578
The caption and reference here are not informative to what the figure is representing.	I-Review	I-2	Review	578
<sep> <sep> "We obtain the training data by collecting static images for (It) and simulate the	B-Review	B-4	Review	578
displacement field ...  We refer to this method as self-supervised learning"	I-Review	I-4	Review	578
This is not self-supervised learning.	I-Review	I-4	Review	578
In self-supervised learning the training label/signal is generated by the system.	I-Review	I-4	Review	578
In this case artificial data is being generated as the displacement between images is sampled.	I-Review	I-4	Review	578
<sep> <sep> Since the motion between images is artificially generated what guarantees are there that the model is learning to capture realistic motion behavior?	B-Review	B-5	Review	578
Why not use adjacent video frames?	I-Review	I-5	Review	578
<sep> <sep> "Note that those methods train deep and complicated neural networks with large scale datasets to	B-Review	B-6	Review	578
predict optical flows in supervised manners, while our model can be treated as a simple one-layer	I-Review	I-6	Review	578
network, accompanied by weight matrices representing motions."	I-Review	I-6	Review	578
<sep> Is there a comparison on execution times of the different approaches?	I-Review	I-6	Review	578
<sep> <sep> "by obtaining the pre-trained models and testing on V1Deform testing data"	B-Review	B-7	Review	578
Is this a fair comparison if the proposed approach was trained on V1Deform training data and the comparison methods were not.	I-Review	I-7	Review	578
A more appropriate comparison would be to apply all the methods to infer the displacement fields between video frames which is also a more natural application.	I-Review	I-7	Review	578
This can be controlled to contain small motions if needed.	I-Review	I-7	Review	578
Why nt use the MUG dataset here?	I-Review	I-7	Review	578
<sep> <sep> "Displacements at image border are leaved out" -&gt; left out	B-Review	B-8	Review	578
<sep> Sections 5.4, 5.5 and 5.6 show only qualitative results with no comparison methods.	B-Review	B-9	Review	578
Can the authors provide reasons that other methods could not be used for evaluation?	I-Review	I-9	Review	578
<sep> <sep> I am not sure I understand the motivation for the approach.	B-Review	B-3	Review	578
Why do we need this over other methods that can better capture larger motions.	I-Review	I-3	Review	578
This needs to be more clear from the introduction.	I-Review	I-3	Review	578
Why do we care if the approach captures aspects of V1 for the tasks presented?	I-Review	I-3	Review	578
<sep> <sep> The work is sensible and the approach is clear but I found the evaluation and motivation lacking in key areas that I mention above.	B-Review	B-10	Review	578
The authors should revise and make it clear to the reader why we should care about this problem.	I-Review	I-10	Review	578
Aligning with V1 is interesting but it does not come into play in the applications of the approach or the analysis so I am not sure why I should care.	I-Review	I-10	Review	578
The evaluation also needs to be much more convincing before I could recommend acceptance.	I-Review	I-10	Review	578
Thank you for your valuable comments and suggestions.	O	O	Reply	578
<sep> <sep> Q1: ‚Äú‚ÄòThe representation theory underlies much of modern mathematics and holds the key to the quantum theory (Zee, 2016).‚Äô Can the relevance of this claim be elaborated on?‚Äù	O	O	Reply	578
<sep> A1: Yes.	B-Reply	B-1	Reply	578
In representation theory in mathematics, for a group G, each element g is represented by a matrix M(g) acting on the vector v in a vector space.	I-Reply	I-1	Reply	578
For two elements g1 and g2 in G, g1*g2 is represented by M(g1) M(g2).	I-Reply	I-1	Reply	578
In our work, the displacements dx form a 2D Euclidean group.	I-Reply	I-1	Reply	578
Each dx is represented by a matrix M(dx) acting on the vector v(x) that represents the local image content.	I-Reply	I-1	Reply	578
<sep> <sep> In quantum physics, a particle at position x is represented by a vector v(x) in a Hilbert space.	I-Reply	I-1	Reply	578
If the particle undergoes a displacement dx, the vector is transformed by a displacement matrix (or operator) M(dx), so that v(x+dx) = M(dx) v(x).	I-Reply	I-1	Reply	578
In our work, v(x) represents the local image content, and M(dx) represents pixel displacement.	I-Reply	I-1	Reply	578
<sep> More generally, a particle of a certain momentum with a certain spin (as well as other properties) is represented by a vector in a Hilbert space.	I-Reply	I-1	Reply	578
When the particle undergoes a Lorentz transformation (a more general notion of displacement in space-time), the vector is multiplied by a matrix (or operator) representing the Lorentz transformation.	I-Reply	I-1	Reply	578
Different types of particles correspond to different schemes of representing the Lorentz transformations.	I-Reply	I-1	Reply	578
<sep> We adopt such mathematical language in our work.	I-Reply	I-1	Reply	578
More generally, we may use vectors to represent various objects in the image, and use matrices to represent the motions of these objects.	I-Reply	I-1	Reply	578
<sep> Such a mathematical language was adopted by earlier papers before.	I-Reply	I-1	Reply	578
<sep> In [1], the authors study the change of images when the camera undergoes motion.	I-Reply	I-1	Reply	578
Each image frame is represented by a vector.	I-Reply	I-1	Reply	578
The camera motion is represented by a matrix.	I-Reply	I-1	Reply	578
This idea was also alluded to in [2].	I-Reply	I-1	Reply	578
In [3], the authors study the grid cells as forming a high-dimensional vector representation of the 2D position of the agent.	I-Reply	I-1	Reply	578
The self-motion of the agent is represented by a matrix.	I-Reply	I-1	Reply	578
<sep> Unlike vector representation that is common in deep learning models, the matrix representation is relatively rare.	I-Reply	I-1	Reply	578
Our work is an example along this theme.	I-Reply	I-1	Reply	578
<sep> <sep> [1] Jayaraman, Dinesh, and Kristen Grauman. "	O	O	Reply	578
Learning image representations tied to ego-motion."	O	O	Reply	578
Proceedings of the IEEE International Conference on Computer Vision.	O	O	Reply	578
2015.	O	O	Reply	578
<sep> <sep> [2] Paccanaro, Alberto, and Geoffrey E. Hinton. "	O	O	Reply	578
Learning distributed representations of concepts using linear relational embedding."	O	O	Reply	578
IEEE Transactions on Knowledge and Data Engineering 13.2 (2001): 232-244.	O	O	Reply	578
<sep> <sep> [3] Gao, Ruiqi, et al "Learning grid cells as vector representation of self-position coupled with matrix representation of self- motion."	O	O	Reply	578
Seventh International Conference on Learning Representations (2019).	O	O	Reply	578
<sep> <sep> Q2: About the motivation. ‚	O	O	Reply	578
ÄúWhy do we care if the approach captures aspects of V1 for the tasks presented?‚Äù ‚ÄúWhy do we need this over other methods that can better capture larger motions.	O	O	Reply	578
‚Äù	O	O	Reply	578
<sep> A2:  This is an important question.	O	O	Reply	578
<sep> <sep> For tasks like optical flow estimation, current state of the art methods such as FlowNet2 use very complex deep neural networks, which are black box models.	B-Reply	B-3	Reply	578
Our model is much simpler and is based on explicit vector and matrix representations.	I-Reply	I-3	Reply	578
It is worthwhile to explore such models.	I-Reply	I-3	Reply	578
Our new experiments also show that our method can achieve performances that are comparable to existing methods.	I-Reply	I-3	Reply	578
<sep> <sep> Following your suggestion, we have strengthened the motivation of our work in the introduction.	I-Reply	I-3	Reply	578
<sep> <sep> Your comment on evaluation is well taken.	I-Reply	I-3	Reply	578
We have added evaluations on two more datasets in revision.	I-Reply	I-3	Reply	578
One dataset is created in a similar manner as the public dataset of FlyingChairs.	I-Reply	I-3	Reply	578
The other is the public MPI-Sintel dataset.	I-Reply	I-3	Reply	578
See Subsections 5.1, 5.3 and Appendices E, F for details.	I-Reply	I-3	Reply	578
<sep> <sep> About larger motions, the motions in the FlyingChairs dataset tend to be very big and abrupt, which does not really reflect typical motion behaviors observed in daily life.	I-Reply	I-3	Reply	578
On the other hand, our model can be modified to a multi-resolution scheme to deal with larger motions.	I-Reply	I-3	Reply	578
Currently we are exploring this direction.	I-Reply	I-3	Reply	578
<sep> <sep> Q3: ‚Äú‚ÄòFigure 1 illustrates the scheme of representation.	O	O	Reply	578
‚Äô Please provide more detail here on what is happening in the figure.	O	O	Reply	578
The caption and reference here are not informative to what the figure is representing.	O	O	Reply	578
‚Äù	O	O	Reply	578
<sep> A3: Thanks for the suggestion.	O	O	Reply	578
In the introduction of the revised version, we have included detailed explanation of Figure 1.	B-Reply	B-2	Reply	578
<sep> <sep> Q4: ‚Äú‚ÄòWe obtain the training data by collecting static images for (It) and simulate the displacement field‚Äô.	O	O	Reply	578
This is not self-supervised learning.	O	O	Reply	578
‚Äù	O	O	Reply	578
<sep> A4: Following your suggestion, we have removed the wording ‚Äúself-supervised learning‚Äù, and changed the wording to ‚Äúlearning from image pairs with synthetic motions‚Äù.	B-Reply	B-4	Reply	578
<sep> <sep> To be continued in the next message.	O	O	Reply	578

Summary:	O	O	Review	578
This paper proposes a representation model for describing local pixel displacement.	O	O	Review	578
The proposed model uses matrix multiplication for optical flow estimation, where an image is transformed into a vector and the local motion is modeled by a matrix.	O	O	Review	578
<sep> The recommendation of this work is based on the following reasons.	O	O	Review	578
First, the motivation of the proposed method is not convincing.	O	O	Review	578
While the proposed ideas are interesting, it is not clear why this approach sheds light on our understanding of motion perception.	B-Review	B-1	Review	578
Is there any psychological evidence to support the proposed model?	I-Review	I-1	Review	578
Or the authors simply take some ideas form V1 model and add a module to ‚Äúexplain‚Äù motion?	I-Review	I-1	Review	578
Second, the experimental results are not sufficient to demonstrate the effectiveness of the proposed model.	I-Review	I-1	Review	578
<sep> Major issues:	O	O	Review	578
First, while it is interesting to use matrix multiplication to model motion, it is not clear why the motion between patches I_t[x] and I_{t+1}[x] can be approximated with linear transformation (Section 3.4).	B-Review	B-2	Review	578
Furthermore, it is not clear why the transformation M only depends on the displacement of the center pixel whereas different pixels in a patch I_t[x] could have different displacements.	B-Review	B-3	Review	578
<sep> Second, the proposed model for optical flow estimation is only evaluated on the proposed V1Deform dataset.	B-Review	B-4	Review	578
If the authors position this paper ‚Äúmay shed light on our motion perception in primary visual cortex‚Äù, the authors certainly need to carry out sufficient psychophysical experiments.	I-Review	I-4	Review	578
<sep> Minor issues:	O	O	Review	578
First, Eq.2 does not seem correct to me.	B-Review	B-5	Review	578
The left and right sides of Eq.2 have different dimensions.	I-Review	I-5	Review	578
<sep> Second, the authors may consider using {} instead of () to define a set of pixels or vectors in Section 3.1.	I-Review	I-5	Review	578
<sep> Third, while the reconstruction loss (Eq.7) is used in this paper, I wonder what the results would be like if the authors simply enforce W‚ÄôW=I instead.	I-Review	I-5	Review	578
<sep> <sep> Thanks for your valuable comments and suggestions.	O	O	Reply	578
<sep> <sep> Q1: ‚Äúit is not clear why this approach sheds light on our understanding of motion perception.	O	O	Reply	578
Is there any psychological evidence to support the proposed model?‚Äù	O	O	Reply	578
<sep> A1: In this paper, we seek to explain two important features of the simple cells in V1.	B-Reply	B-1	Reply	578
One is that they can be approximated by Gabor filters.	I-Reply	I-1	Reply	578
The other is that adjacent cells have quadrature phase relation.	I-Reply	I-1	Reply	578
Our motion model gives simple explanations to the above two features.	I-Reply	I-1	Reply	578
<sep> <sep> About motion perception, we did consult experts on the neuroscience and psychophysics of motion perception in V1.	I-Reply	I-1	Reply	578
Existing neuroscience models are usually based on the spatial-temporal filters, such as the motion energy model of [1]. In Subsection 4.4, we connect our work to this model to explain the emergence of spatial-temporal filters.	I-Reply	I-1	Reply	578
Moreover, we present a recurrent implementation of the spatial-temporal filtering.	I-Reply	I-1	Reply	578
This recurrent implementation is more efficient and more biologically plausible than plain implementation of spatial-temporal filters which requires memorizing the past frames.	I-Reply	I-1	Reply	578
<sep> <sep> [1] Edward H Adelson and James R Bergen.	O	O	Reply	578
Spatiotemporal energy models for the perception of motion.	O	O	Reply	578
Josa a, 2(2):284‚Äì299, 1985.	O	O	Reply	578
<sep> <sep> In our paper, we also follow the protocol of the neuroscience papers [2,3] to evaluate the learned filters.	O	O	Reply	578
<sep> <sep> [2] Dario L Ringach.	O	O	Reply	578
Spatial structure and symmetry of simple-cell receptive fields in macaque primary visual cortex.	O	O	Reply	578
Journal of neurophysiology, 88(1):455‚Äì463, 2002.	O	O	Reply	578
<sep> <sep> [3] Martin Rehn and Friedrich T Sommer.	O	O	Reply	578
A network that uses few active neurons to code visual input predicts the diverse shapes of cortical receptive fields.	O	O	Reply	578
Journal of computational neuroscience, 22(2):135‚Äì146, 2007.	O	O	Reply	578
<sep> <sep> Q2: ‚Äúwhy the motion between patches I_t[x] and I_{t+1}[x] can be approximated with linear transformation‚Äù	O	O	Reply	578
<sep> A2: Thanks for the insightful question.	B-Reply	B-2	Reply	578
One motivation of our model is based on Fourier analysis: An image patch I can be expressed as I(x) = sum_k c_k e^{i&lt;\omega_k, x&gt;} in a Fourier decomposition.	I-Reply	I-2	Reply	578
If we shift it by dx, the shifted image patch J(x) = I(x - dx) = sum_k c_k e^{-i&lt;\omega_k, dx&gt;} e^{i&lt;\omega_k, x&gt;}. The change from the complex number c_k to c_k e^{-i&lt;\omega_k, dx&gt;} corresponds to rotating a 2D vector by a 2 x 2 matrix.	I-Reply	I-2	Reply	578
This is a simple example that the shift can be represented by a linear transformation in the frequency domain, as a change in phase.	I-Reply	I-2	Reply	578
<sep> <sep> We want to emphasize that our model does not assume Fourier basis or its localized version such as Gabor filters.	I-Reply	I-2	Reply	578
Our model figures it out with generic vector and matrix representations.	I-Reply	I-2	Reply	578
<sep> <sep> We have added the above motivation to the introduction.	I-Reply	I-2	Reply	578
<sep> <sep> Q3: ‚Äúwhy the transformation M only depends on the displacement of the center pixel whereas different pixels in a patch I_t[x] could have different displacements‚Äù	O	O	Reply	578
<sep> A3: Thanks for the good question.	B-Reply	B-3	Reply	578
We assume that the motion is smooth, so that within a relative small local patch, the motion is constant.	I-Reply	I-3	Reply	578
Of course, the patch size or the filter size should be related to image resolution.	I-Reply	I-3	Reply	578
For images with higher resolution, we may want to use smaller filter size to make this assumption hold.	I-Reply	I-3	Reply	578
We have added a comment on this point in the introduction when discussing the Fourier analysis motivation.	I-Reply	I-3	Reply	578
<sep> <sep> To be continued in the next message.	O	O	Reply	578

Summary: This paper introduces a simple idea to optimize the weights of a weighted empirical training distributions.	O	O	Review	20133
The goal is to optimize the population risk, and the idea is to optimize a distribution over the training examples to maximize the cosine similarity between training set gradients and validation set gradients.	O	O	Review	20133
The distribution over the training set is parameterized by a neural network taking as arguments the	O	O	Review	20133
<sep> Strengths:	O	O	Review	20133
- The method is quite simple.	O	O	Review	20133
<sep> - The results appear to be strong, although I am less familiar with the NMT baselines.	O	O	Review	20133
The imagenet results seem quite strong to me.	O	O	Review	20133
<sep> <sep> Weaknesses:	O	O	Review	20133
- I couldn't find a particularly clear description of the scoring networks architecture.	B-Review	B-1	Review	20133
Given that it observes the whole dataset, this seems like a critical choice that could have a big impact on the complexity of this approach.	I-Review	I-1	Review	20133
At the very least, this should be clearly reported, and I recommend a more thorough investigation of this choice.	I-Review	I-1	Review	20133
<sep> - The authors report that their method takes 1.5x to 2x longer to run than the uniform baseline.	B-Review	B-2	Review	20133
Yet, they ran all methods for the same number of steps / epochs.	I-Review	I-2	Review	20133
It seems to me that a fairer comparison might be letting all methods enjoy the same total budget measure roughly by wall time.	I-Review	I-2	Review	20133
<sep> <sep> Questions:	O	O	Review	20133
- I didn't follow why the computation of the per example gradient grad l(x_i, y_i, theta_t-1) is so onerous.	B-Review	B-3	Review	20133
Isn't that computed on line 5 already?	I-Review	I-3	Review	20133
We thank the reviewer for providing many good suggestions and questions.	O	O	Reply	20133
We have addressed your concerns here and updated the paper with some clarifications.	O	O	Reply	20133
We would appreciate if you could check our response and revisions (and if these have indeed clarified the concerns, revise the overall assessment).	O	O	Reply	20133
We would also be happy to continue the discussion and make any additional modifications as deemed necessary.	O	O	Reply	20133
<sep> <sep> reviewer #3 question1: scoring network architecture	O	O	Reply	20133
<sep> response:	O	O	Reply	20133
We are sorry for the lack of clarity with respect to this!	B-Reply	B-1	Reply	20133
This was simply an oversight.	I-Reply	I-1	Reply	20133
<sep> <sep> For image classification, we use an identical network architecture with the main model, but with independent weights and a regressor to predict the score instead of a classifier to predict image classes.	I-Reply	I-1	Reply	20133
For the multilingual NMT experiments, since we only want to model a simple distribution over n training languages, we use a fully connected 2-layer perceptron network.	I-Reply	I-1	Reply	20133
For each target sentence and its corresponding source sentences, the input feature is a n-dimensional vector of 0 and 1, where 1 indicates a source language exists for the given target sentence.	I-Reply	I-1	Reply	20133
We have updated the image classification and NMT instantiation section, as well as the appendix, with clarifications of the network structure, and will release our code once the paper is accepted.	I-Reply	I-1	Reply	20133
<sep> <sep> <sep> reviewer #3 question2: The authors report that their method takes 1.5x to 2x longer to run than the uniform baseline.	O	O	Reply	20133
Yet, they ran all methods for the same number of steps / epochs.	O	O	Reply	20133
It seems to me that a fairer comparison might be letting all methods enjoy the same total budget measure roughly by wall time.	O	O	Reply	20133
<sep> <sep> response:	O	O	Reply	20133
The main objective of DDS is to improve model performance, while remaining much simpler and more efficient than other methods that optimize a data selector using reinforcement learning that require multiple independent training runs.	B-Reply	B-2	Reply	20133
For example, in the IMDB movie review experiment in  [1], the data filtering agent is also trained for 200 episode, where each episode uses around 40% of the whole dataset, requiring a total of 80x more training time than a single training run.	I-Reply	I-2	Reply	20133
Therefore, the 1.5-2x increase in time afforded by DDS is much more manageable.	I-Reply	I-2	Reply	20133
<sep> <sep> For image classification, training the standard baseline for longer does not help, since the main model will start to overfit, which indicates that spending more time on the baseline would not have a positive effect.	I-Reply	I-2	Reply	20133
<sep> <sep> reviewer #3 question3:  I didn't follow why the computation of the per example gradient grad l(x_i, y_i, theta_t-1) is so onerous.	O	O	Reply	20133
Isn't that computed on line 5 already?	O	O	Reply	20133
<sep> <sep> response:	O	O	Reply	20133
In practice, a single gradient is computed with respect to a mini-batch of training data of size n to improve computational efficiency.	B-Reply	B-3	Reply	20133
However, using the per-example gradient requires one to compute the gradient for each example in a batch, which essentially slows down training by a factor of n. Therefore, we propose the simplification in Eqn.	I-Reply	I-3	Reply	20133
7 to compute the per example gradient.	I-Reply	I-3	Reply	20133
<sep> <sep> <sep> [1] Learning what data to learn <a href="https://arxiv.org/pdf/1702.08635.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1702.08635.pdf</a>	O	O	Reply	20133

This paper presents a reinforcement learning approach towards using data that present best correlation with a validation set‚Äôs gradient signal.	O	O	Review	20133
The broader point of this paper is that there is inevitably some distribution shift going from train to test set - and the validation set can be a small curated set whose distribution is closer to the testing distribution than what the training dataset's distribution is.	O	O	Review	20133
The problem setup bears relationship to several areas including domain adaptation/covariate shift problems, curriculum learning based approaches amongst others.	O	O	Review	20133
One assumption that I see which needs to be understood more is equation (6) - wherein, somehow, there is a Markov assumption used to zero out the contribution of the scoring network on parameters unto previous time step.	O	O	Review	20133
Trying to understand the implications of this assumption (how the performance varies with/without this assumption) would be instructive for understanding potential shortcomings of this framework.	O	O	Review	20133
I think the paper is well written, handles an important question.	O	O	Review	20133
That said, I am not too aware of recent work in this area to make a decisive judgement on this paper‚Äôs novelty/contributions.	O	O	Review	20133
We thank the reviewer for providing the feedback and suggestions.	O	O	Reply	20133
Please see our response to Reviewer #1, question 4).	O	O	Reply	20133
We have also updated the paper to add some clarifications.	O	O	Reply	20133
We would really appreciate if you could check whether our response has cleared your concern, and that you could consider improving the overall assessment.	O	O	Reply	20133
We would love to continue the discussion and make improvements to our paper.	O	O	Reply	20133

The paper proposes an iterative method that jointly trains the model and a scorer network that places a non-uniform distribution over data sets.	O	O	Review	20133
The paper proposes a gradient method to learn the scorer network based on reinforcement learning, which is novel as to what the reviewer knows.	O	O	Review	20133
<sep> <sep> There are several concerns/questions:	O	O	Review	20133
<sep> 1) The paper doesn‚Äôt define the D_{dev} clearly.	B-Review	B-1	Review	20133
How is D_{dev} chosen?	I-Review	I-1	Review	20133
Is it a subset of D_{train}?	I-Review	I-1	Review	20133
<sep> <sep> 2) In section 2.1, why ‚Äúsmaller development set D_{dev} is much closer to the P_{test}(X,Y)‚Äù?	B-Review	B-2	Review	20133
P_{test}(X,Y) is supposed to be not observed during training?	I-Review	I-2	Review	20133
<sep> <sep> 3) In Eq (5), if D_{dev} is s subset of D_{train}, if \theta* is the minimal of J, it means the gradient	B-Review	B-3	Review	20133
at  \theta* is 0.	I-Review	I-3	Review	20133
To calculate the gradient of J with respect to \psi, by chain rule, it need to calculate gradient to \theta* first then \theta* to \psi.	I-Review	I-3	Review	20133
If gradient of \theta* is 0, the product is also 0?	I-Review	I-3	Review	20133
So the \psi will not be updated if D_{dev}  is sufficiently similar to D_{train} ?	I-Review	I-3	Review	20133
<sep> <sep> 4) In Section 2.3, it omits the second order Hessian term.	B-Review	B-4	Review	20133
How does that influence the performance?	I-Review	I-4	Review	20133
<sep> <sep> 5) it mentions ‚Äúwithout significant computing overhead‚Äú in abstract, which is not demonstrated elsewhere.	B-Review	B-5	Review	20133
<sep> <sep> 6) In the experiments, table 1, it seems the major improvement comes from retrain and TCS rather than DDS?	B-Review	B-6	Review	20133
In figure 3, it is better to show the weights of an image without DDS and comparing that with DDS.	I-Review	I-6	Review	20133
<sep> <sep> 7) The paper contains many typos such as Eqn.11 is not defined in the main paper, the ‚ÄúEqn ??‚	B-Review	B-7	Review	20133
Äù Appears in the appendix, ‚Äútha minimizes‚Äù etc.	I-Review	I-7	Review	20133
<sep> <sep> In general, the idea of the paper is natural and the results seem promising.	O	O	Review	20133
I am looking forward to the reply to my questions/concerns.	O	O	Review	20133
<sep> <sep> #############	O	O	Review	20133
<sep> I have read the author's feedback.	O	O	Review	20133
I think the clarity of both methodology and experiment does not reach the acceptance level and would maintain my current rating.	O	O	Review	20133
<sep> <sep> Thank you very much for providing many pieces of good feedback and clarification questions.	O	O	Reply	20133
We believe that in both the response and the revised draft we have clarified or rectified all of the reservations that were stated in the original review.	O	O	Reply	20133
We would appreciate if you could check our response and revisions (and if these have indeed clarified the concerns, revise the overall assessment).	O	O	Reply	20133
We would also be happy to continue the discussion and make any additional modifications as deemed necessary.	O	O	Reply	20133
<sep> <sep> Reviewer #1 question 1): The paper doesn‚Äôt define the D_{dev} clearly.	O	O	Reply	20133
How is D_{dev} chosen?	O	O	Reply	20133
Is it a subset of D_{train}?	O	O	Reply	20133
<sep> <sep> Response:	O	O	Reply	20133
For our machine translation tasks, is simply the dev set that comes with the dataset.	B-Reply	B-1	Reply	20133
<sep> <sep> For our image classification tasks, for we hold out about 10% of the *training* data.	I-Reply	I-1	Reply	20133
For example, in CIFAR-10 (4,000), is the last 400 images, while in ImageNet-10%, since we use the first 102 TFRecord shards, consists of the last 10 shards.	I-Reply	I-1	Reply	20133
Here, ‚Äúlast‚Äù follows the order in which the data is posted on their website for CIFAR-10, and the order in which the TFRecord shards are processed for ImageNet.	I-Reply	I-1	Reply	20133
All data in are excluded from.	I-Reply	I-1	Reply	20133
Thus, for example, with CIFAR-10 (4,000),, ensuring that in total, we are only using the amount of data that we claim to use.	I-Reply	I-1	Reply	20133
<sep> <sep> Thus, in all cases, there is no overlap between and, or and (as is standard in machine learning experiments).	I-Reply	I-1	Reply	20133
We have added a clarification in the method section of the paper, and we also updated the details in the appendix.	I-Reply	I-1	Reply	20133
<sep> <sep> Reviewer #1 question 2): In section 2.1, why ‚Äúsmaller development set D_{dev} is much closer to the P_{test}(X,Y)‚Äù?	O	O	Reply	20133
P_{test}(X,Y) is supposed to be not observed during training?	O	O	Reply	20133
<sep> <sep> Response:	O	O	Reply	20133
It is correct that P_{test}(X, Y) is not observed, but practically in model training it is commonly more possible to collect a dev set that reflects the test scenario.	B-Reply	B-2	Reply	20133
To take the example of the multilingual NMT, in this case we would like to use training data from *many different languages* to improve the performance of *a particular low-resource language*. Here, D_{train} is the aggregation of data from all languages, while D_{dev} could be a separate small set of data from the low-resource language we are interested in.	I-Reply	I-2	Reply	20133
This small dev set is possible to gather, even if we can‚Äôt gather a large training set in the language.	I-Reply	I-2	Reply	20133
P_{test}(X, Y) in this case is the distribution of the low-resource language, which is much better captured by the small D_{dev} from this low-resource language.	I-Reply	I-2	Reply	20133
<sep> <sep> Similar settings can easily be thought of in other scenarios as well: in a domain adaptation setting we can obtain a small dev set in the target domain, or in a setting of training on noisy data we can often obtain a small clean dev set.	I-Reply	I-2	Reply	20133
We have updated the method section of the paper to clarify this issue.	I-Reply	I-2	Reply	20133
<sep> <sep> Finally, even if the training set and dev set come from *exactly* the same data distribution, likelihood on the dev set is still going to be a better estimator of test performance, as the model is not able to train on the dev set directly (which is why we use dev sets in standard machine learning setups in the first place).	I-Reply	I-2	Reply	20133
<sep> <sep> Reviewer #1 question 3): In Eq (5), if D_{dev} is s subset of D_{train}, if \theta* is the minimal of J, it means the gradient at  \theta* is 0.	O	O	Reply	20133
To calculate the gradient of J with respect to \psi, by chain rule, it need to calculate gradient to \theta* first then \theta* to \psi.	O	O	Reply	20133
If gradient of \theta* is 0, the product is also 0?	O	O	Reply	20133
So the \psi will not be updated if D_{dev}  is sufficiently similar to D_{train} ?	O	O	Reply	20133
<sep> <sep> Response:	O	O	Reply	20133
As we mentioned in point (1), does not overlap with, so these gradients will be inherently different.	B-Reply	B-3	Reply	20133

The paper investigates adversarial attacks on learned (fixed) policies.	O	O	Review	20625
In particular, they devise optimal attacks in the sense that e.g. the agent‚Äôs objective should be minimised by the attacker.	O	O	Review	20625
It is assumed that the attacker can manipulate the observed state of the agent at each time step during testing in a restricted way such that perturbations are small in the state or feature space.	O	O	Review	20625
The paper derives attacker value functions when the attacker‚Äôs goal ist to minimise the original agent‚Äôs average cumulative reward and shows how to maximise them using gradient methods.	O	O	Review	20625
In order to show when attacks are more likely to be successful, a theorem is presented and proved that shows that the resilience of a policy against attacks depends on its smoothness.	O	O	Review	20625
Experiments show that a) attacks that are trained for optimality w.r.t.to minimising the average reward of the agent outperform a baseline method that only optimises a related criterion.	O	O	Review	20625
b) Agent policies that are trained with DRQN, yielding a recurrent controller, outperform non recursive ones.	O	O	Review	20625
<sep> <sep> Overall, I think this paper can be a good contribution to the subfield of adversarial attacks on MDP policies.	O	O	Review	20625
In my view, the derivations and overall structure and results of the paper are sound.	B-Review	B-1	Review	20625
However, I would have liked to get a better understanding and motivation for the investigated problem setting, such as projected applications and state or features spaces that could be manipulated in the proposed way.	I-Review	I-1	Review	20625
<sep> <sep> Pros:	O	O	Review	20625
Paper is well written and generally easy to follow.	O	O	Review	20625
<sep> The derivations look sound and are well motivated.	O	O	Review	20625
Proposition 5.1.	O	O	Review	20625
can help in understanding how to train resilient agent policies.	O	O	Review	20625
<sep> Experiments confirm that optimising for optimal attacks does indeed find empirically better attack strategies.	O	O	Review	20625
<sep> <sep> <sep> Cons:	O	O	Review	20625
No real application was presented.	B-Review	B-2	Review	20625
While applications are imaginable, a real application would have been beneficial.	I-Review	I-2	Review	20625
In particular, getting an idea of how real pertubations may look like in a realistic domain.	I-Review	I-2	Review	20625
The same holds for the assumption that the state (or features) can be manipulated at each time step, but only slightly.	I-Review	I-2	Review	20625
<sep> The implications of Proposition 5.1.	B-Review	B-3	Review	20625
were never tested, as far as I understand.	I-Review	I-3	Review	20625
You only test DRQN vs DQN, which validates your POMDP assertions, but other comparisons are missing.	I-Review	I-3	Review	20625
<sep> The tested Open AI Gym environments are very basic, with the exception of Pong.	B-Review	B-4	Review	20625
This reiterates my application argument.	I-Review	I-4	Review	20625
<sep> <sep> Notation/Writing:	O	O	Review	20625
On page 5, last paragraph you should use a different letter for J in order to reduce notational confusion.	B-Review	B-5	Review	20625
Section 6 is not on the same standard as the other sections in terms of writing, e.g. 'We have obtained from 3 policies‚Äò , some stray ‚Äôthe‚Äô, some plural vs. singular issues.	B-Review	B-6	Review	20625
<sep> <sep> We would like to thank the reviewer for their valuable feedback and careful reading.	O	O	Reply	20625
We appreciated the thorough summary that was provided.	O	O	Reply	20625
<sep> <sep> 1.	O	O	Reply	20625
REV2: However, I would have liked to get a better understanding and motivation for the investigated problem setting, such as projected applications and state or features spaces that could be manipulated in the proposed way.	O	O	Reply	20625
<sep> <sep> One of the motivations is that modern control systems are increasingly relying on advanced infrastructure to get real-time measurements.	B-Reply	B-1	Reply	20625
This increase in complexity increases their exposure to malicious threats.	I-Reply	I-1	Reply	20625
Each measurement signal may be compromised or altered by an adversary.	I-Reply	I-1	Reply	20625
Therefore, resiliency to these attacks is an important property for control systems.	I-Reply	I-1	Reply	20625
Attacks for linear systems are well studied, but little has been done in the field of controlled Markov chains, and that of RL more generally.	I-Reply	I-1	Reply	20625
<sep> <sep> 2.	O	O	Reply	20625
REV#2: No real application was presented.	O	O	Reply	20625
While applications are imaginable, a real application would have been beneficial. [‚	O	O	Reply	20625
Ä¶].	O	O	Reply	20625
<sep> We agree that a real application would have been beneficial, which is part of the future work.	B-Reply	B-2	Reply	20625
A real application involves the use of reinforcement learning for heat-control in complex systems (like buildings).	I-Reply	I-2	Reply	20625
We would like to verify robustness to adversarial attacks through the methods proposed in this paper.	I-Reply	I-2	Reply	20625
The idea is that an attacker can inject malicious data to your measurement network, or alter the behaviour of one/multiple sensor/s.	I-Reply	I-2	Reply	20625
<sep> <sep> 3.	O	O	Reply	20625
REV#2: The implications of Proposition 5.1.	O	O	Reply	20625
were never tested [‚Ä¶]	O	O	Reply	20625
<sep> To test Proposition 5.1, we compare the results obtained when attacking a policy trained using DQN and DDPG.	B-Reply	B-3	Reply	20625
DDPG is known to output smooth policies for continuous systems.	I-Reply	I-3	Reply	20625
And indeed, as shown in Figures 1 and 9, policies trained with DDPG are more robust than other policies.	I-Reply	I-3	Reply	20625
<sep> <sep> In a revised version of the paper, we plan to further illustrate the result of Proposition 5.1 by computing the smoothness of the various policies that we attack.	I-Reply	I-3	Reply	20625
This smoothness can be quantified by the best constant (defined in Proposition 5.1).	I-Reply	I-3	Reply	20625
<sep> <sep> 4.	O	O	Reply	20625
REV#2: The tested Open AI Gym environments are very basic, with the exception of Pong[‚Ä¶]	O	O	Reply	20625
<sep> We chose environments that may be close to real control systems, such as LunarLander, where the state space is quite rich.	B-Reply	B-4	Reply	20625
As you pointed out, Pong is not a basic environment, but an attacker could use the same methodology to other types of environments and reduce the dimensionality of the state (notice that in the case of Pong we even obtain a small finite state space).	I-Reply	I-4	Reply	20625

Summary:	O	O	Review	20625
<sep> The authors of this paper propose a novel adversarial attack for deep reinforcement learning.	O	O	Review	20625
Different from the classical attacks, e.g., FGSM, they explicitly minimize the reward collect by the agent in a form of Markov decision process.	O	O	Review	20625
Experiment results demonstrate that the proposed approach can damage the well-performed policy with a much bigger performance drop than gradient-based attacks.	O	O	Review	20625
<sep> <sep> Paper strength:	O	O	Review	20625
<sep> 1.	O	O	Review	20625
<tab>The paper is well-organized and easy to follow.	O	O	Review	20625
<sep> 2.	O	O	Review	20625
<tab>Model the adversary of reinforcement learning (RL) system as another MDP and solve it with RL is novel and interesting.	O	O	Review	20625
The proposed attacking diagram can be devised in a pure black-box setting and also can be incorporated with white-box attacks.	O	O	Review	20625
<sep> 3.	O	O	Review	20625
<tab>With such a strong attack, the authors derive an upper bound on the impact of attacks and shed light on new research studying the robustness of deep RL approach.	O	O	Review	20625
<sep> <sep> Paper weakness:	O	O	Review	20625
1.	O	O	Review	20625
<tab>The author should give more details about how you use a gradient-based exploration to guide the adversary.	B-Review	B-1	Review	20625
From my point of view, I think the black-box attack is more practical and interesting.	I-Review	I-1	Review	20625
I would like to see the clearer comparison of optimal attack in a pure black-box setting with gradient-based attacks.	I-Review	I-1	Review	20625
<sep> 2.	O	O	Review	20625
<tab>Though FGM is not as efficient as the proposed optimal attack, they are simpler than a learning-based approach.	B-Review	B-2	Review	20625
Please describe the details and cost of training the attack agency, e.g., the hyper-parameter, number of training iterations.	I-Review	I-2	Review	20625
<sep> 3.	O	O	Review	20625
<tab>While the conclusion of smooth policies is more resilience for adversaries is interesting, I would like to see the evaluation results of such a novel finding.	B-Review	B-3	Review	20625
<sep> <sep> We would like to thank the reviewer for valuable and constructive comments.	O	O	Reply	20625
We also appreciate the	O	O	Reply	20625
concise summary of the paper.	O	O	Reply	20625
<sep> <sep> 1.	O	O	Reply	20625
Rev#3: The author should give more details about how you use a gradient-based exploration to guide the adversary.	O	O	Reply	20625
[‚Ä¶], I think the black-box attack is more &gt;practical and interesting.	O	O	Reply	20625
I would like to see the clearer comparison of  optimal attack in a pure black-box setting with gradient-based attacks.	O	O	Reply	20625
<sep> <sep> We agree that the design of black-box attacks is more practical and interesting, and such a design  constitutes the main contribution of our paper.	B-Reply	B-1	Reply	20625
We did not have much space left to investigate white-box attacks, where the main-agent policy could  be known.	I-Reply	I-1	Reply	20625
Nevertheless, we wanted to add a short discussion on how we could exploit this knowledge  to cast attacks.	I-Reply	I-1	Reply	20625
This is done at the bottom of page 5 (‚ÄúGradient-based exploration‚Äù) and pages 13-14 in the appendix.	I-Reply	I-1	Reply	20625
<sep> <sep> To leverage the knowledge of the main-agent policy, we propose a heuristic, consisting in modifying  the way the attacker explores when learning the optimal attack.	I-Reply	I-1	Reply	20625
More precisely, the proposed gradient-based exploration is a combination of the usual noise used to explore in RL and of a term that is inspired by FGM.	I-Reply	I-1	Reply	20625
The idea is that when exploring, we should to put a higher emphasis in the direction  of the gradient of the loss function.	I-Reply	I-1	Reply	20625
We hope that this leads to a faster learning process.	I-Reply	I-1	Reply	20625
You can find a precise description of this heuristic in pages 13-14 in appendix.	I-Reply	I-1	Reply	20625
Exploring in preferred directions introduces a bias.	I-Reply	I-1	Reply	20625
To deal with this, we make use of a Bernoulli random variable that dictates when to use the usual exploration noise, and the ‚Äúguided‚Äù exploration noise.	I-Reply	I-1	Reply	20625
Finally, observe  that we should follow the direction pointed out by FGM only when this is strictly necessary.	I-Reply	I-1	Reply	20625
To do so,  we consider the gap.	I-Reply	I-1	Reply	20625
This gap term multiplies the direction given by the gradient.	I-Reply	I-1	Reply	20625
Intuitively, the lower this gap is, the less impact the optimal action has in that state.	I-Reply	I-1	Reply	20625
This guarantees that we follow the gradient of J mostly when we are in critical states.	I-Reply	I-1	Reply	20625
We have tested this type of exploration on Mountaincar, which is an environment that is usually hard to attack.	I-Reply	I-1	Reply	20625
In Figure 10, we can see a significant increase in the training speed using gradient-based exploration.	I-Reply	I-1	Reply	20625
Given the same number of training episodes, a usual exploration achieves a mean reward of -163, whilst gradient-based exploration achieves -173.	I-Reply	I-1	Reply	20625
FGM achieves -134, and without perturbation, the average score is -100.	I-Reply	I-1	Reply	20625
<sep> <sep> 2.	O	O	Reply	20625
Rev.#3: Though FGM is not as efficient as the proposed optimal attack, they are simpler than a &gt;learning-based approach.	O	O	Reply	20625
Please describe the details and cost of training the attack agency, e.g., the hyper-parameter, number of training iterations.	O	O	Reply	20625
<sep> <sep> FGM indeed looks simpler to implement.	B-Reply	B-2	Reply	20625
However, FGM requires to compute a gradient (e.g. that of  the Q function w.r.t.the state) each time a control action is selected by the main agent.	I-Reply	I-2	Reply	20625
Computing  such a gradient can be involved, for example in environments with a continuous action space.	I-Reply	I-2	Reply	20625
It may not even be feasible to use FGM in real attack scenarios, since computing this gradient may take an  amount of time greater than the control period.	I-Reply	I-2	Reply	20625
Evaluating FGM actually took a longer time than training and evaluating our attack when the action  space is continuous.	I-Reply	I-2	Reply	20625
Unlike FGM, our attacks need to be trained before the attack actually takes place.	I-Reply	I-2	Reply	20625
<sep> <sep> To train the attack, we use an actor-critic architecture, shown in Figure 11.	I-Reply	I-2	Reply	20625
The actor-network is augmented with a projection layer to ensure a small perturbation.	I-Reply	I-2	Reply	20625
In Table 3, we show the hyper-parameters for the main agent, and in Table 4, the hyper-parameters for the adversary.	I-Reply	I-2	Reply	20625
We used roughly the same number of  training steps to train both the adversary and the main agent, and similar replay memory size.	I-Reply	I-2	Reply	20625
<sep> <sep> 3.	O	O	Reply	20625
Rev.#3: While the conclusion of smooth policies is more resilience for adversaries is interesting, I would like to see the evaluation results of such a novel finding	O	O	Reply	20625
<sep> To test Proposition 5.1, we compare the results obtained when attacking a policy trained using DQN	B-Reply	B-3	Reply	20625
and DDPG.	I-Reply	I-3	Reply	20625
DDPG is known to output smooth policies for continuous systems.	I-Reply	I-3	Reply	20625
And indeed, as shown In Figures 1 and 9, policies trained with DDPG are more robust than other policies.	I-Reply	I-3	Reply	20625
<sep> In a revised version of the paper, we plan to further illustrate the result of Proposition 5.1 by computing the smoothness of the various policies that we attack.	I-Reply	I-3	Reply	20625
This smoothness can be quantified by the best constant (defined in Proposition 5.1).	I-Reply	I-3	Reply	20625

This paper investigates the design of adversarial policies (where the action of the adversarial agent corresponds to a perturbation in the state perceived by the primary agent).	O	O	Review	20625
In particular it focuses on the problem of learning so-called optimal adversarial policies, using reinforcement learning.	O	O	Review	20625
<sep> <sep> I am perplexed by this paper for a few reasons:	O	O	Review	20625
1)<tab>What is the real motivation for this work?	B-Review	B-1	Review	20625
The intro argues ‚Äúcasting optimal attacks is crucial when assessing the robustness of RL policies, since ideally, the agent should learn and apply policies that resist *any* possible attack‚Äù.	I-Review	I-1	Review	20625
If the goal is to have agents that are robust to *any* attacks, then they cannot be robust just to so-called optimal attacks.	I-Review	I-1	Review	20625
And so what is really the use of learning so-called optimal attacks?	I-Review	I-1	Review	20625
<sep> 2)<tab>The notion itself of ‚Äúoptimal‚Äù attack is not clear.	B-Review	B-2	Review	20625
The paper does not properly discuss this.	I-Review	I-2	Review	20625
It quickly proposes one possible definition (p.4): ‚Äúthe adversary wishes to minimize the agent‚Äôs average cumulative reward‚Äù.	I-Review	I-2	Review	20625
This is indeed an interesting setting, and happens to have been studied extensively in game-theoretic multi-agent systems, but the paper does not make much connection with that literature (apart from a brief mention at bottom of p.2 / top of p.3), so it‚Äôs not clear what is new here compared to this.	I-Review	I-2	Review	20625
It‚Äôs also not discussed whether it would ever be worthwhile considering other notions of optimality for the adversary, and what would be the properties of those.	I-Review	I-2	Review	20625
<sep> <sep> So overall, while I find the general area of this work to be potentially interesting, the current framing is not well motivated enough, and not sufficiently differentiated from other work in robust MDPs and multi-agent RL to make a strong contribution yet.	B-Review	B-3	Review	20625
<sep> <sep> More minor comments:	B-Review	B-5	Review	20625
-<tab>P.3: ‚Äúvery different setting where the adversary has a direct impact on the system‚Äù =&gt; Clarify what are the implications of this in terms of framework, theory, algorithm.	I-Review	I-5	Review	20625
<sep> -<tab>P.4: You assume a valid Euclidean distance for the perturbed state.	I-Review	I-5	Review	20625
Is this valid in most MDP benchmarks?	I-Review	I-5	Review	20625
How is this implemented for the domains in the experiments?	I-Review	I-5	Review	20625
What is the action space considered?	I-Review	I-5	Review	20625
Do you always assume a continuous action space for the attacker?	I-Review	I-5	Review	20625
<sep> -<tab>P.5: ‚Äúwe can simply not maintain distributions over actions‚Äù -&gt; Why not?	I-Review	I-5	Review	20625
Given the definition of perturbation, this seems feasible.	I-Review	I-5	Review	20625
<sep> -<tab>P.5:  Eqn 4 is defined for a very specific adversarial reward function.	I-Review	I-5	Review	20625
Did you consider others?	I-Review	I-5	Review	20625
Is the gradient always easy to derive?	I-Review	I-5	Review	20625
<sep> -<tab>P.6: Eqn (5) &amp; (6): What is ‚ÄúR‚Äù here?	I-Review	I-5	Review	20625
<sep> -<tab>P.7: Figure 1, top right plot.	I-Review	I-5	Review	20625
Seems here that the loss is above 0 for small \epsilon.	I-Review	I-5	Review	20625
Is this surprising?	I-Review	I-5	Review	20625
Actually improving the policy?	I-Review	I-5	Review	20625
<sep> -<tab>P.7: What happens if you consider even greater \epsilon?	I-Review	I-5	Review	20625
I assume the loss is greater.	I-Review	I-5	Review	20625
But then the perturbation would be more detectable?	I-Review	I-5	Review	20625
How do you think about balancing those 2 requirements of adversarial attacks?	I-Review	I-5	Review	20625
How should we formalize detectability in this setting?	I-Review	I-5	Review	20625
<sep> -<tab>Fig.2: Bottom plots are too small to read.	I-Review	I-5	Review	20625
<sep> -<tab>Sec.6:  Can you compare to multi-agent baselines, e.g. Morimoto &amp; Doya 2005.	I-Review	I-5	Review	20625
<sep> -<tab>P.8: ‚ÄúWe also show that Lipschitz policies have desirable robustness properties.	B-Review	B-4	Review	20625
‚Äù Can you be more specific about where this is shown formally?	I-Review	I-4	Review	20625
Or are you extrapolating from the fact that discrete mountain car suffers more loss than continuous mountain car?	I-Review	I-4	Review	20625
I would suggest making that claim more carefully.	I-Review	I-4	Review	20625
<sep> <sep> <sep> 10.	O	O	Reply	20625
Rev#1: P.8: ‚ÄúWe also show that Lipschitz policies have desirable robustness properties.	O	O	Reply	20625
‚Äù Can you be more specific about where this is shown formally?	O	O	Reply	20625
Or are you extrapolating from the fact that discrete mountain car suffers more loss than continuous mountain car?	O	O	Reply	20625
I would suggest making that claim more carefully.	O	O	Reply	20625
<sep> <sep> As pointed out also by the other reviewers, Proposition 5.1.	B-Reply	B-4	Reply	20625
shows this property.	I-Reply	I-4	Reply	20625
It helps understanding	I-Reply	I-4	Reply	20625
how to train resilient agent policies.	I-Reply	I-4	Reply	20625
To test Proposition 5.1, we compare the results obtained when attacking a policy trained using DQN and DDPG.	I-Reply	I-4	Reply	20625
DDPG is known to output smooth policies for continuous systems.	I-Reply	I-4	Reply	20625
And indeed, as shown in Figures 1 and 9, policies trained with DDPG are more robust than other policies.	I-Reply	I-4	Reply	20625
In a revised version of the paper, we plan to further illustrate the result of Proposition 5.1 by computing the smoothness of the various policies that we attack.	I-Reply	I-4	Reply	20625
This smoothness can be quantified by the best constant (defined in Proposition 5.1).	I-Reply	I-4	Reply	20625

The paper proposed an interesting continual learning approach for sequential data processing with recurrent neural network architecture.	O	O	Review	20335
<sep> The authors provide a general application on sequential data for continual learning, and show their proposed model outperforms baseline.	O	O	Review	20335
<sep> <sep> It is natural that their naive baseline shows poor performance since they do not consider any continual learning issues like the catastrophic forgetting problem.	B-Review	B-1	Review	20335
Then, I hesitate to evaluate the model in terms of performance.	I-Review	I-1	Review	20335
In that sense, it would be much crucial to show more meaningful ablation studies and analysis for proposed model.	I-Review	I-1	Review	20335
However, there is a few of thing about them.	I-Review	I-1	Review	20335
<sep> <sep> Then, I decide to give a lower score that even the authors suggest that the main contribution is a definition of problem setting.	B-Review	B-1	Review	20335
It requires more detailed and sophisticated analysis.	I-Review	I-1	Review	20335
<sep> <sep> The baselines do not employ CL techniques since the main motivation behind the baseline experiments was to assess the impact and extent of catastrophic forgetting in RNNs, which we believed to be a necessary first step to highlight continual learning issues in the context of sequential data processing (being the literature on this topic still in its infancy, differently from what occurs with feedforward networks and machine vision applications).	B-Reply	B-1	Reply	20335
Results show that, unsurprisingly, the standard models are severely affected by catastrophic forgetting, supporting our claim for novel architectures and approaches addressing the issue for sequential models.	I-Reply	I-1	Reply	20335
It is within this context, that we introduce GIM as a possible solution to the issue: of course, there can be others and based on different approaches, e.g. an adaptation of elastic weight consolidation.	I-Reply	I-1	Reply	20335
Nevertheless, to the extent of our knowledge, there is, yet, no work in literature tackling catastrophic forgetting in continual learning for sequential problems.	I-Reply	I-1	Reply	20335
Nevertheless, we are taking in the reviewer suggestion and we will expand the analysis by adapting standard CL techniques to the recurrent scenario, assessing their performance in this novel context.	I-Reply	I-1	Reply	20335
<sep> We will provide ablation studies with respect to Augmented architectures and GIM architectures in future versions.	I-Reply	I-1	Reply	20335

The goal of this work is to best understand the performance and benchmarking of continual learning algorithms when applied to sequential data processing problems like language or sequence data sets.	O	O	Review	20335
The contributions of the paper are 3 fold - new benchmarks for CL with sequential data for RNN processing, new architecture introduced for more effective processing and a thorough empirical evaluation.	O	O	Review	20335
<sep> <sep> Introduction:	O	O	Review	20335
I think a little more insight into why the sequential data processing CL scenario is any different than the vision scenario would be quite helpful.	B-Review	B-1	Review	20335
Specifically, it would be quite impactful to tell us more about what the additional challenges with RNNs for CL vs feedforward for CL are in the intro.	I-Review	I-1	Review	20335
<sep> <sep> The paper is written as if the benchmark is the main contribution and the architecture improvement is just a delta on top of this, but it gets confusing when the methods section starts off with just directly stating the new architecture.	B-Review	B-2	Review	20335
<sep> <sep> The algorithm seems like a straightforward combination of recurrent progressive nets and gated autoencoders for CL.	B-Review	B-3	Review	20335
Can the authors provide more justification if that is the contribution or there is more to the insight than has been previously suggested in prior work?	I-Review	I-3	Review	20335
<sep> <sep> Figure 1 has a very uninformative caption.	B-Review	B-4	Review	20335
It also doesn‚Äôt show how modules feed into one another properly.	I-Review	I-4	Review	20335
<sep> <sep> The motivation for why one needs GIM after one already has A-LSTM or A-LMN is not very clear?	B-Review	B-5	Review	20335
<sep> <sep> Overall the contribution does seem a bit incremental based on prior work and the description lacks enough detail to properly indicate why this is a very important contribution?	B-Review	B-6	Review	20335
<sep> <sep> Experiments:	O	O	Review	20335
What does it mean to be application agnostic but restricted to particular datasets and losses?	B-Review	B-7	Review	20335
This doesn‚Äôt quite parse to me.	I-Review	I-7	Review	20335
<sep> <sep> The description of the tasks is very informal and hard to follow.	B-Review	B-8	Review	20335
It‚Äôs not clear what exactly the tasks and datasets look like	I-Review	I-8	Review	20335
<sep> ‚Äúusing morehidden units can bridge this gap‚Äù -&gt; why not just do it?	I-Review	I-8	Review	20335
Its a benchmark after all.	I-Review	I-8	Review	20335
<sep> <sep> Overall the task descriptions should be in a separate section where the setup is described in a lot of detail and motivated properly.	B-Review	B-9	Review	20335
<sep> <sep> The results in the experiments section are very hard to parse.	B-Review	B-10	Review	20335
The captions need much more detail for eg Table 2.	I-Review	I-10	Review	20335
<sep> <sep> Could we also possibly have more baselines from continual learning?	B-Review	B-11	Review	20335
For instance EWC (Kirkpatrick) or generative replay might be competitive baselines.	I-Review	I-11	Review	20335
<sep> <sep> Overall I think that the GIM and A-LMN and A-LSTM methods are reasonable although somewhat incremental.	B-Review	B-12	Review	20335
But the proposed benchmarks are pretty unclear and the results are a bit hard to really interpret well.	I-Review	I-12	Review	20335
It would also be important to run comparisons with more baselines and to provide more ablation/analysis experiments to really see the benefit of GIM/A-LMN or A-LSTM.	I-Review	I-12	Review	20335
I also think that the task descriptions should be much earlier in the paper and desribed in much more rigorous detail.	I-Review	I-12	Review	20335
<sep> <sep> The main difference between the sequential data processing scenario and the vision scenario is related to the fact that sequential processing requires the use of a memory that embeds the history of past inputs.	B-Reply	B-1	Reply	20335
Such memories have to be appropriately learned and preserved, making the sequential processing tasks clearly different than the vision tasks.	I-Reply	I-1	Reply	20335
When it comes to CL, drifts in the input distribution could affect the hidden memory of RNNs.	I-Reply	I-1	Reply	20335
Additional works will be needed in order to clarify this phenomenon.	I-Reply	I-1	Reply	20335
We will clarify this point in the Introduction.	I-Reply	I-1	Reply	20335
<sep> <sep> The main concern of this work was to provide a set of common benchmarks for CL in sequential domains that are independent of domain-specific applications (e.g. NLP) against which existing and future models can compare their performances.	B-Reply	B-2	Reply	20335
We will better describe the experimental settings, reserving a specific section to the description of the tasks and datasets.	I-Reply	I-2	Reply	20335
Since they are the main contribution of this work, we agree that they should be better highlighted.	I-Reply	I-2	Reply	20335
<sep> In addition, we extend the progressive approach and the gating autoencoder to the recurrent domain.	I-Reply	I-2	Reply	20335
At the best of our knowledge, no previous work proposed these two extensions for recurrent neural networks, nor they combine both into one end-to-end model.	I-Reply	I-2	Reply	20335
<sep> <sep> The reason why the Augmented models need the autoencoders (e.g. from A-LSTM to GIM-LSTM) is that without the autoencoders is not possible to avoid the use of task labels at inference time.	B-Reply	B-5	Reply	20335
GIM architectures can detect the correct module for inference, while Augmented modules alone only allow the transfer of useful, learned features from one module to the others.	I-Reply	I-5	Reply	20335
<sep> <sep> The experimental protocol is task-agnostic in the sense that we do not restrict the choice of datasets to a particular application (e.g. NLP), but instead, we proposed a set of general datasets (Copy and SSMNIST) that do not require any domain-specific technique.	B-Reply	B-7	Reply	20335
Using this benchmarks, we can evaluate CL models while eliminating the idiosyncrasies of specific application domains.	I-Reply	I-7	Reply	20335
<sep> <sep> In future versions, we will extend standard CL techniques to the RNN scenario and we will compare their performances against both naive RNNs and GIM.	B-Reply	B-1	Reply	20335
<sep> We will also provide ablation studies highlighting the effects that autoencoders and inter-modules connections have on the overall performance of GIM.	B-Reply	B-12	Reply	20335

Summary:	O	O	Review	20335
<sep> In this paper, the authors propose a new method to apply continual learning on sequential data.	O	O	Review	20335
The model is constructed by combining an Autoencoder and LSTM/LMN for each task.	O	O	Review	20335
The experiments on several datasets show the proposed model outperforms basic LSTM/LMN.	O	O	Review	20335
<sep> <sep> <sep> Strength:	O	O	Review	20335
<sep> + Sequential data widely exist in the real world, e.g., text, health records.	O	O	Review	20335
Thus, It is interesting to see that continual learning is used in sequential data.	O	O	Review	20335
<sep> <sep> + The motivation of the proposed model is clear.	O	O	Review	20335
The authors save the learned knowledge in the hidden representation of LSTM/LMN.	O	O	Review	20335
<sep> <sep> Weakness:	O	O	Review	20335
- In this paper, the model size linearly increases since the number of LSTM/LMN and AE increases when a new task comes in.	B-Review	B-1	Review	20335
Thus, if the number of tasks is too large, the model size is quite big.	I-Review	I-1	Review	20335
In traditional continual learning settings, researchers may not always increase the model size for overcoming catastrophic forgetting.	I-Review	I-1	Review	20335
For example, if task 1 and task 2 sample from the same distribution, they can share the same LSTM/LMN and AE.	I-Review	I-1	Review	20335
Thus, it would be better if the authors can consider how to reduce the model size in the future version.	I-Review	I-1	Review	20335
<sep> <sep> - In the experiments, the authors only compare the proposed model with simple LSTM or LMN.	B-Review	B-2	Review	20335
However, most continual learning methods can still be applied in this scenario, at least regularization based methods [1,2] can be simply applied in this scenario.	I-Review	I-2	Review	20335
The authors may need to compare the proposed method with them in the future version.	I-Review	I-2	Review	20335
<sep> <sep> - It is better to compare it with a larger dataset.	B-Review	B-3	Review	20335
For example, in the natural language processing field, we can regard sentiment analysis on one language as one task.	I-Review	I-3	Review	20335
Then, we can construct the continual learning dataset for sentiment analysis.	I-Review	I-3	Review	20335
<sep> <sep> Minor Comments:	O	O	Review	20335
It is better to improve Figure 3 by adding the x-axis label and y-axis label.	B-Review	B-4	Review	20335
<sep> <sep> <sep> [1] Kirkpatrick, James, et al "Overcoming catastrophic forgetting in neural networks."	O	O	Review	20335
Proceedings of the national academy of sciences 114.13 (2017): 3521-3526.	O	O	Review	20335
<sep> [2] Zenke, Friedemann, Ben Poole, and Surya Ganguli. "	O	O	Review	20335
Continual learning through synaptic intelligence."	O	O	Review	20335
Proceedings of the 34th International Conference on Machine Learning-Volume 70.	O	O	Review	20335
JMLR.	O	O	Review	20335
org, 2017.	O	O	Review	20335
We agree that the model size is the main limitation GIM.	B-Reply	B-1	Reply	20335
However, as you say, it is reasonable to assume that the number of hidden units of each module could decrease as the number of modules increases.	I-Reply	I-1	Reply	20335
Inter-modules connections can foster reuse of previous features, thus reducing the need to learn them from scratch.	I-Reply	I-1	Reply	20335
As far as we know, our work is the first example of a progressive model + gating AE applied to sequential data.	I-Reply	I-1	Reply	20335
Therefore, we decided to leave this extension out of the proposed paper, since we prefer to focus more on the benchmark design and the sequential nature of the data rather than the model architecture.	I-Reply	I-1	Reply	20335
We would like to propose GIM as a simple baseline that can be improved upon in several different directions.	I-Reply	I-1	Reply	20335
<sep> <sep> We agree that it would be valuable to compare current CL techniques (e.g EWC) with GIM in order to further assess our approach.	B-Reply	B-2	Reply	20335
We will integrate some of the main techniques into our analysis and we will highlight the main differences between their application on a computer vision scenario and a sequential data processing scenario.	I-Reply	I-2	Reply	20335
<sep> <sep> We struggle to understand what the use of a larger dataset (e.g. NLP / sentiment analysis) would add to our analysis.	B-Reply	B-3	Reply	20335
We recognize that it will be an important step in the development of full-fledged CL systems for sequential data processing, but we believe that in this first phase it would be better to focus on task-agnostic benchmarks before moving on to more complex scenarios.	I-Reply	I-3	Reply	20335
This choice allows us to highlight the CL properties of the model without the need to tailor it on a specific field of application, which often requires a complex preprocessing or the use of intermediate embeddings.	I-Reply	I-3	Reply	20335
By using simpler benchmarks, we reduce the probability to misinterpretation of results.	I-Reply	I-3	Reply	20335
This approach also makes it easier for other researchers to compare their results against our benchmark, since we do not require a large computational infrastructure to manage the experiments.	I-Reply	I-3	Reply	20335

The paper presents an approach to infer optimal strategies by learning the payoff function of 2 player games with a neural network Q(s, a), where a are the agent actions and s the context (e.g., action of the other player).	O	O	Review	871
The strategy is inferred by considering the inputs as free variables at test time and maximizing the learnt Q over its input variables by backpropagation.	O	O	Review	871
<sep> <sep> The structure of the neural network in itself is not particularly original.	O	O	Review	871
The originality of the paper is to show that experimentally, in some 2-player games (and small sequential games, using an RNN), the policy that is inferred is close to a Nash equilibrium.	O	O	Review	871
While this is an interesting result in itself, the games used in the experiment are pretty easy to solve with existing algorithms, so the experimental evidence that this approach can work in practice in difficult cases is weak.	B-Review	B-1	Review	871
<sep> <sep> The motivation and intuition fail to be convincing.	B-Review	B-2	Review	871
There is an excessive usage of analogies with intelligence and life in general that are not particularly enlighting (e.g., "Even though its hardware is damaged, the software in	I-Review	I-2	Review	871
the cloud (or the eternal soul, arguably) of the mosquito [...]", the value of the analogy between the cloud and the soul is unclear), and in the end there is no clear explanation of why it should work in practice.	I-Review	I-2	Review	871
<sep> <sep> I think the paper in its current form is not ready for publication.	O	O	Review	871
More formal arguments and/or stronger experimental evidence are necessary.	O	O	Review	871
<sep> Thank you for your opinion.	O	O	Reply	871
Indeed, there is much need to be done.	O	O	Reply	871
We agree with your opinion.	O	O	Reply	871
<sep> <sep> (1) The name of this machine is inappropriate since we didn't really invent a new kind of neural network, and we only exploit back propagation in an nontraditional way.	B-Reply	B-3	Reply	871
We will cherish your opinion and re-coin the name of the machine.	I-Reply	I-3	Reply	871
<sep> <sep> (2) The experiment result is not enough, indeed.	B-Reply	B-1	Reply	871
We are working on the experiment result.	I-Reply	I-1	Reply	871
The experiment result requires some time to come by (if there are randomly generated 100 tables, it takes quite a time), and we are working on it.	I-Reply	I-1	Reply	871
<sep> <sep> Thank you again for your time reviewing this paper.	O	O	Reply	871
We sincerely thank you for your time and precious opinion.	O	O	Reply	871
Thank you again.	O	O	Reply	871

The authors describe a method for endowing an artificial agent with causal reasoning  when completing goal-directed tasks.	O	O	Review	10003
Causal reasoning knowledge is encoded in a directed acyclic bipartite graph or slightly more complicated "master switch" variation.	O	O	Review	10003
<sep> <sep> Essentially the method is:	O	O	Review	10003
- train a model F to predict causal graphs (for which we have ground truth data) from trajectories generated with a heuristic,	O	O	Review	10003
- train an policy \pi_G attending over the causal graph to solving tasks.	O	O	Review	10003
<sep> <sep> At inference time F an \pi_G are frozen and are evaluated on similar tasks to the ones in training, where however the (unseen) causal graph is new.	O	O	Review	10003
Thus the evaluation is in a meta-learning scenario, where the model has to learn how to learn to solve tasks.	O	O	Review	10003
<sep> <sep> The experimental setting is an agent controlling 5 or 7 switches in a simulated environment and observing 32x32x3 images of the environment.	O	O	Review	10003
<sep> <sep> The authors report significant improvements over an existing baseline (Dasgupta et al (2019)).	O	O	Review	10003
The key to the improvements is in the iterative prediction of the causal graph (for F) and in having attention over the causal graph (in \pi_G).	O	O	Review	10003
<sep> <sep> The paper is describes a very nice new method and makes interesting points about the role that causal reasoning can play in modeling agents in goal-directed tasks.	O	O	Review	10003
The paper is strengthened by improvements on existing baselines based on their intuitions.	O	O	Review	10003
<sep> <sep> Questions:	O	O	Review	10003
<sep> * The authors claim that constructing an explicit causal structure, instead of a latent feature encoding, leads to better generalization in ‚Äúlong-horizon‚Äù tasks -- but they seem to only test on one task, fairly limited in complexity.	B-Review	B-1	Review	10003
<sep> <sep> * On page 1, the authors claim that empirical evidence suggests the lack of correct causal modeling is an important factor for lack of generalization, generation of unrealistic captions, and difficulties in transfer learning.	B-Review	B-2	Review	10003
This seems to be a bit of an overreach.	I-Review	I-2	Review	10003
It‚Äôs possible that many empirical problems could be solved to a large degree by advances in machine learning without having to resort to explicit causal modeling.	I-Review	I-2	Review	10003
<sep> <sep> * On page 2, is the reward function r the same for all MDPs?	B-Review	B-3	Review	10003
<sep> <sep> * Could it be said from the start that pi_I is heuristic and described in section 4.1?	B-Review	B-4	Review	10003
<sep> <sep> * There seem to be strong assumptions on the structure of C that are only stated late in the paper.	B-Review	B-5	Review	10003
C is initially presented as an arbitrary acyclic graph, but from Figure 2 it appears to instead be a bipartite graph with N source nodes and N target nodes, and potential connections from any source node to any target node, where N is the number of actions.	I-Review	I-5	Review	10003
This should be explained early on.	I-Review	I-5	Review	10003
The ‚Äúmaster switch‚Äù variation does not seem to exactly fit the mathematical descriptions from the ‚ÄúMethods‚Äù section.	I-Review	I-5	Review	10003
<sep> <sep> * \hat{C}_H does not seem to be defined except inside Figure 2.	B-Review	B-6	Review	10003
It should be defined in the text.	I-Review	I-6	Review	10003
<sep> <sep> We thank reviewer 3 for their comments.	O	O	Reply	10003
We address each comment below:	O	O	Reply	10003
<sep> ‚ÄúLong-horizon tasks‚Äù: By long-horizon we meant that our causal inference task consists of sequential decision making, as opposed to the one-step querying of previous work (Dasgupta et al 2019).	B-Reply	B-1	Reply	10003
We have rephrased to "multi-step" tasks in the revision.	I-Reply	I-1	Reply	10003
<sep> <sep> ‚ÄúIt‚Äôs possible that many empirical problems could be solved to a large degree by advances in machine learning without having to resort to explicit causal modeling‚Äù: Absolutely.	B-Reply	B-2	Reply	10003
Lack of causal reasoning is one of the hypotheses for weak generalization.	I-Reply	I-2	Reply	10003
Our method provided one way to address this problem by constructing an explicit causal model; it could also be addressed by other advances in machine learning.	I-Reply	I-2	Reply	10003
<sep> <sep> ‚ÄúIs the reward function r the same for all MDPs?‚Äù: Yes, the reward function is the difference between the current state and goal state across all MDPs.	B-Reply	B-3	Reply	10003
<sep> <sep> ‚ÄúCould it be said from the start that pi_I is heuristic and described in section 4.1?‚Äù: Yes we have added this when we first mention pi_I in the problem statement.	B-Reply	B-4	Reply	10003
<sep> <sep> ‚ÄúThere seem to be strong assumptions on the structure of C that are only stated late in the paper.	O	O	Reply	10003
‚Äù: Thank you for pointing this out.	B-Reply	B-5	Reply	10003
For clarity, we have updated the problem statement to mention that in this work we focus on bipartite graphs, and also expand on the details of C in Section 4.1.	I-Reply	I-5	Reply	10003
<sep> <sep> ‚Äú\hat{C}_H does not seem to be defined except inside Figure 2.‚Äù: \hat{C}_i, corresponds to the estimate of \hat{C} at the ith iteration.	B-Reply	B-6	Reply	10003
We have added a description of \hat{C}_i in the caption to clarify this - thank you for pointing this out.	I-Reply	I-6	Reply	10003

[Summary]	O	O	Review	10003
<sep> This paper proposes an interactive agent that tries to infer the underlying causal structure by interacting with the environment; the authors called it "causal induction."	O	O	Review	10003
The inferred graph will later help the agent complete goal-directed tasks referred to as a "causal inference" stage.	O	O	Review	10003
Notably, the agent directly learns from visual inputs.	O	O	Review	10003
<sep> <sep> Both the induction and inference phases heavily rely upon the attention mechanism, which ensures that the agent only focuses on the relevant components of the causal graph.	O	O	Review	10003
During the induction phase, the agent incrementally updates the predicted causal graph through each interaction using an attention-based edge decoder.	O	O	Review	10003
During the inference phase, the attention bottleneck also showed to improve the agent's generalization ability.	O	O	Review	10003
<sep> They have shown that the proposed model outperforms several baselines in a synthetic environment that uses switches to control lights.	O	O	Review	10003
They have also demonstrated the model's generalization ability by operating on unseen causal graphs and new task goals.	O	O	Review	10003
<sep> <sep> <sep> [Major Comments]	O	O	Review	10003
<sep> My primary concern about this work is the scope of its applicability.	B-Review	B-1	Review	10003
<sep> <sep> For the causal induction phase, the proposed method makes a strong assumption that it can access the ground truth causal relationship during training.	I-Review	I-1	Review	10003
The authors can directly read this information from the synthetic environments used in this paper, yet, in more complex real-world situations, we might not know the underlying causal structure for supervised training the induction model.	I-Review	I-1	Review	10003
<sep> <sep> For learning the goal-conditioned policies, the authors also assume that they have access to the ground truth causal graph.	I-Review	I-1	Review	10003
They use this information to generate the expert demonstrations, which, I presume, are deterministic and unimodal (correct me if I'm wrong).	I-Review	I-1	Review	10003
In the real world, a human may be able to infer the underlying causal structure from the observations by interacting with the environment and provide the demonstration data.	I-Review	I-1	Review	10003
However, the demonstration may be noisy or form a multi-modal distribution.	I-Review	I-1	Review	10003
While I agree that learning from demonstration is an effective way of guiding the learning of the policy, I'm not sure if the method can generalize to more realistic scenarios.	I-Review	I-1	Review	10003
<sep> <sep> For inferring the causal graph, the authors also assume that they know the "cause" set and the "effect" set, which is already a DAG by construction.	I-Review	I-1	Review	10003
Instead of inferring the direction of the edge, they are solving an easier problem of deciding whether a directed edge between a "cause" node and an "effect" node exists or not.	I-Review	I-1	Review	10003
The assumption on the graph structure also limits the method's applicability, as, in the real world, the direction of the edge is not always known in advance.	I-Review	I-1	Review	10003
Smoking may cause lung cancer, but it is possible that lung cancer may make people smoke more.	I-Review	I-1	Review	10003
<sep> <sep> I feel this paper makes strong assumptions on both the induction and inference stages, as well as the structure of the causal graph, which greatly limits the applicability of the approach.	O	O	Review	10003
<sep> <sep> [Detailed Comments]	O	O	Review	10003
<sep> I also have a few questions regarding the details of this paper.	O	O	Review	10003
<sep> <sep> In Section 3.1, the authors said that "N is the number of actions in the environments," which is a bit confusing.	B-Review	B-2	Review	10003
Before this point, the authors did not discuss the relationship between the size of the graph and the size of the action set.	I-Review	I-2	Review	10003
Only until Section 3.2 did I realize that N is the number of both "cause" set and "effect" set.	I-Review	I-2	Review	10003
It would be better to discuss the size of the graph and the action set at an earlier position.	I-Review	I-2	Review	10003
<sep> <sep> How is the expert planner implemented?	B-Review	B-3	Review	10003
Is the expert's policy deterministic and unimodal?	I-Review	I-3	Review	10003
I feel this is an important detail to include.	I-Review	I-3	Review	10003
<sep> <sep> It is related to the previous question.	B-Review	B-4	Review	10003
What will happen if we learn the goal-conditional policy from scratch?	I-Review	I-4	Review	10003
How much does imitation learning help with policy learning?	I-Review	I-4	Review	10003
Again, the assumption that we know the ground truth causal graph may not be feasible in the real world.	I-Review	I-4	Review	10003
<sep> <sep> In Section 3.3, the authors said that "the expert's action is added to the memory of the policy."	B-Review	B-5	Review	10003
However, the authors also noted that "the policy has no memory" in Section 3.2, which seems to contradict each other.	I-Review	I-5	Review	10003
Does the "memory" mean replay buffer in Section 3.3?	I-Review	I-5	Review	10003
<sep> <sep> Does the number of switches fixed across all environments and always the same as the number of lights?	B-Review	B-6	Review	10003
Also, are all the lights mounted in the same location?	I-Review	I-6	Review	10003
I'm wondering if the model is invariant to the order of the cause nodes and effects nodes in the graph, and can it generalize to larger environments, more lights, and different room configurations.	I-Review	I-6	Review	10003
<sep> <sep> In Figure 4, TCIN seems to have the best performance in the "Masterswitch" environment when there are 500 seen causal structures.	B-Review	B-7	Review	10003
What might be the reason?	I-Review	I-7	Review	10003
We thank reviewer 1 for their thoughtful comments.	O	O	Reply	10003
We address each comment below:	O	O	Reply	10003
<sep> Scope of applicability: It is correct that we assume access to the ground-truth causal structure in the training of our final model.	B-Reply	B-1	Reply	10003
We also experimented with different setups, where we trained causal induction without ground-truth causal graph in the ‚ÄúMemory‚Äù baseline and trained policy without ground-truth causal graph in the ‚ÄúMemory (RL/Low Dim)‚Äù baseline.	I-Reply	I-1	Reply	10003
However, both baselines failed to match the performance of our final model (see Figure 5).	I-Reply	I-1	Reply	10003
It implies that the use of ground-truth causal graph is crucial for learning efficiency and high performance of our model.	I-Reply	I-1	Reply	10003
In more realistic scenarios, we would have to investigate more effective reinforcement learning algorithms as a replacement to imitation learning to reduce the reliance on expert demonstrations.	I-Reply	I-1	Reply	10003
<sep> <sep> In addition, it is true that we assume that the graph nodes are known and focus on predicting the directed edges.	I-Reply	I-1	Reply	10003
Under this assumption, our core technical contribution is using attention mechanisms to selectively read and update the causal graph.	I-Reply	I-1	Reply	10003
We plan to explore the joint learning of nodes and edges of a causal graph in future work.	I-Reply	I-1	Reply	10003
<sep> <sep> ‚ÄúOnly until Section 3.2 did I realize that N is the number of both ‚Äòcause‚Äô set and ‚Äòeffect‚Äô set‚Äù: Thanks for pointing this out.	B-Reply	B-2	Reply	10003
We have also added a brief description of the graphs we consider in the problem statement, as well as a more in-depth description of the causal graphs in Section 4.1.	I-Reply	I-2	Reply	10003
<sep> <sep> ‚ÄúHow is the expert planner implemented?‚Äù: Using the goal state and current state, the expert computes the necessary change in state, and using the ground truth causal graph plans a sequence of actions which would achieve this change.	B-Reply	B-3	Reply	10003
Hence the expert policy is deterministic and unimodal - however note we train using DAgger with epsilon greedy exploration, so rather than receiving demonstrations, we query the expert online while training the policy.	I-Reply	I-3	Reply	10003
We have added this clarification to Section 3.3.	I-Reply	I-3	Reply	10003
<sep> <sep> ‚ÄúWhat will happen if we learn the goal-conditional policy from scratch?‚Äù: We tried to train the policy with reinforcement learning (RL) on image inputs, but it did not converge.	B-Reply	B-4	Reply	10003
Therefore, we trained an RL baseline which learned a single policy using memory and ground-truth low-dimensional states (no images) called ‚ÄúMemory (RL/Low dim)‚Äù, and its performance was still low (See Figure 5).	I-Reply	I-4	Reply	10003
This suggests that imitation learning is crucial for handling high-dimensional observations and improving sample efficiency in our problem setup.	I-Reply	I-4	Reply	10003
<sep> <sep> ‚ÄúDoes the ‚Äòmemory‚Äô mean replay buffer in Section 3.3?‚Äù: Correct, the experts action is added to the policy replay buffer.	B-Reply	B-5	Reply	10003
When we say the policy has no memory we mean it is a feed-forward network.	I-Reply	I-5	Reply	10003
We have corrected this term in Section 3.3.	I-Reply	I-5	Reply	10003
<sep> <sep> ‚ÄúIs the number of switches fixed across all environments and always the same as the number of lights?	O	O	Reply	10003
Also, are all the lights mounted in the same location?‚Äù: Our experiments look at environments with 5 switches 5 lights or 7 switches 7 lights.	B-Reply	B-6	Reply	10003
And yes for one environment the position of the lights are the same, but the mapping between switches and lights changes.	I-Reply	I-6	Reply	10003
So one trained model is not invariant to the ordering of cause/effect nodes in the graph, but the method in general should extend to larger environments/lights/room configurations (assuming you train one model per configuration).	I-Reply	I-6	Reply	10003
<sep> <sep> ‚ÄúIn Figure 4, TCIN seems to have the best performance in the "Masterswitch" environment when there are 500 seen causal structures.	O	O	Reply	10003
What might be the reason?‚Äù: This is likely because with 500 training structures the inductive bias of attention is no longer necessary to successfully generalize, and the end-to-end method with temporal convolutions can generalize well.	B-Reply	B-7	Reply	10003

This is a paper about a very interesting topic, involving both learning (in a supervised way) to induce a causal graph and taking advantage of it in a goal-conditioned policy.	O	O	Review	10003
<sep> <sep> This is clearly a timely topic and I loved the motivations of the paper.	O	O	Review	10003
My main difficulty was with understanding the actual architecture and its motivation, but I believe this is fixable but is a serious impediment to being able to evaluate the paper, as it stands.	O	O	Review	10003
I was a bit disappointed to see that training is mostly supervised (both providing the ground truth causal graph and an oracle policy as target) but on the other hand it is impressive to obtain these results with raw images as input and the comparative results are good.	O	O	Review	10003
<sep> <sep> First, I would like to better understand the insight behind the architecture of F and several things would need to be clarified to enable reproducibility and making sense of the equations.	B-Review	B-1	Review	10003
I would start by suggesting to add an example illustrating why simply seeing a (state,next-state,action) triplet is sufficient to obtain a bit of evidence in favour of a particular edge of the graph.	B-Review	B-2	Review	10003
Since this is supervised learning of the causal graph, I imagine that the semantics of the node is predetermined, which is a bit disappointing (but doing otherwise would be understandably much more challenging).	I-Review	I-2	Review	10003
Second, I don't understand the structure of the causal graph C. What are the input nodes?	B-Review	B-3	Review	10003
action values?	I-Review	I-3	Review	10003
action x state cross-product?	I-Review	I-3	Review	10003
What are the output nodes?	I-Review	I-3	Review	10003
Effect variables?	I-Review	I-3	Review	10003
Why would C be NxN and not have different input and output dimensions?	I-Review	I-3	Review	10003
All this really needs to be clarified.	I-Review	I-3	Review	10003
Based on the 1st eqn of page 4 (PLEASE NUMBER YOUR EQUATIONS!!!)	I-Review	I-3	Review	10003
it looks like C is number of actions by number of actions, which does not seem consistent with any reasonable interpretation.	I-Review	I-3	Review	10003
The authors should also clarify how R is computed (if it is a straight difference of the encoder output, put up an equation for example) and how delta e is computed.	B-Review	B-4	Review	10003
<sep> <sep> Then in sec 3.2 the authors talk about a weighted sumn involving selected edges.	B-Review	B-5	Review	10003
I imagine this is soft-attenetion but it needs to be clarified with equations and explanations.	I-Review	I-5	Review	10003
What is the "content" associated with each edge e which gets averaged in the soft attention?	I-Review	I-5	Review	10003
<sep> <sep> I found a possibly interesting parallel between the focus of attention on one edge of the graph  at a time (figure 3) and the ideas of the "Consciousness Prior" (Bengio 2017, on arXiv) bottleneck (where only a small tuple of variables, corresponding to an edge here, is considered at each time step in order to reason, plan, decide etc).	B-Review	B-6	Review	10003
The fact that in the experiments this attention mechanism helps seems to support the sparsity of dependencies hypothesis underlying the consciousness prior.	O	O	Review	10003
<sep> <sep> My rating is weak reject but I am ready to upgrade with appropriate explanations answering the above questions.	O	O	Review	10003
<sep> <sep> --- post-rebuttal  addition ---	O	O	Review	10003
<sep> The authors have satisfied most of my concerns and I have upgraded my rating to weak-accept.	O	O	Review	10003
<sep> <sep> <sep> We thank reviewer 2 for their comments and questions.	O	O	Reply	10003
We attempt to clarify them below.	O	O	Reply	10003
<sep> <sep> ‚ÄúI would start by suggesting to add an example illustrating why simply seeing a (state,next-state,action) triplet is sufficient to obtain a bit of evidence in favour of a particular edge of the graph.	O	O	Reply	10003
‚Äù: Figure 6 in the Appendix includes a qualitative example of the graph induction, including how a specific change in state can map to a predicted edge update to the graph.	B-Reply	B-1	Reply	10003
The core idea is that from state and next-state one can compute the change in state which came from the action, which would imply a certain edge should exist in the graph.	I-Reply	I-1	Reply	10003
<sep> <sep> ‚ÄúI imagine that the semantics of the node is predetermined:‚Äù Correct, the semantics of the node are predetermined to be one of the switches or one of the lights.	B-Reply	B-2	Reply	10003
The causal induction stage amounts to predicting the directed edges between switch nodes and light nodes from visual observations.	I-Reply	I-2	Reply	10003
<sep> <sep> ‚ÄúI don't understand the structure of the causal graph C:‚Äù We have restructured section 4.1 to have a paragraph titled ‚ÄúCausal Graph‚Äù which describes the causal graph in more depth.	B-Reply	B-3	Reply	10003
We include the following details: First, in the One-to-One, One-to-Many, and Many-to-One settings the graphs are bipartite, consisting of N ‚Äúcause‚Äù nodes corresponding to the switches, and M ‚Äúeffect‚Äù nodes corresponding to lights.	I-Reply	I-3	Reply	10003
In practice in our experiments we use M=N, hence the N x N space of mappings between causes and effects.	I-Reply	I-3	Reply	10003
We agree the without this description the fact that the graph is N x N may be confusing, and we have made sure to clarify this in the text.	I-Reply	I-3	Reply	10003
The causal induction stage corresponds to identifying the correct edges out of the possible N x N relationships.	I-Reply	I-3	Reply	10003
In the Masterswitch stage, the graph is tripartite, with an additional mapping between one ‚Äúmaster‚Äù switch to all other switches.	I-Reply	I-3	Reply	10003
<sep> <sep> ‚ÄúThe authors should also clarify how R is computed (if it is a straight difference of the encoder output, put up an equation for example) and how delta e is computed.	O	O	Reply	10003
‚Äù: Yes, R is computed by computing the straight difference between the encoder output, we have added an equation (Equation 1) for this in Section 3.1.	B-Reply	B-4	Reply	10003
Delta e is the output of a fully connected layer which has shape 1xN, which is a mapping of edge strengths to the N effect variables (lights).	I-Reply	I-4	Reply	10003
Then this is combined with the attention as described in Equation 3 (We have now numbered our equations).	I-Reply	I-4	Reply	10003
<sep> <sep> ‚ÄúWhat is the ‚Äòcontent‚Äô associated with each edge e which gets averaged in the soft attention?‚Äù: For the goal conditioned policy, the soft-attention is over the N ‚Äúeffect‚Äù variables (lights), which is applied in a weighted sum resulting in N edge strengths from the N ‚Äúcause‚Äù variables, which is what the policy uses when picking actions.	B-Reply	B-5	Reply	10003
Essentially, this is focusing only on the edges which go into the relevant ‚Äúeffect‚Äù variable based on the current state and goal.	I-Reply	I-5	Reply	10003
<sep> <sep> ‚ÄúI found a possibly interesting parallel between the focus of attention on one edge of the graph  at a time (figure 3) and the ideas of the ‚ÄòConsciousness Prior‚Äô‚Äù: There certainly are parallels between the proposed ideas in ‚ÄòConsciousness Prior‚Äô.	B-Reply	B-6	Reply	10003
In particular, the idea that using attention to focus on only relevant parts of data given the current timestep can improve performance is very similar to our proposed approach, and seems to be supported by our empirical findings.	I-Reply	I-6	Reply	10003
We have added citation to this work.	I-Reply	I-6	Reply	10003
Thank you for pointing this out.	I-Reply	I-6	Reply	10003

The paper introduces a fairly simple yet seemly effective method for quantizing GAN.	O	O	Review	20632
Existing quantization methods (namely minmax, log, and tanh quantization) for CNN/RNN fail brutally under GAN setting.	O	O	Review	20632
From empirical observation of the distribution of quantized weights, the authors conjecture the reason being under-utilization of the low-bit representation, called under-representation in the paper.	O	O	Review	20632
Based on such observation, linear scaling with EM is proposed and experimental results seem to be effective.	O	O	Review	20632
<sep> <sep> [Advantage]	O	O	Review	20632
The paper is clearly written and easy to follow.	O	O	Review	20632
The proposed method is well-motivated from the empirical observation presented in Sec 3, and seems to mitigate the difficulties from the discussion in Sec 5.	O	O	Review	20632
<sep> <sep> [Disadvantage &amp; Improvement]	O	O	Review	20632
While I am not a direct expert in this area, I do have some concerns regarding the novelty of the method and comparison to previous works.	B-Review	B-1	Review	20632
Linear quantization seems to be a common/intuitive method and there are various improvement techniques built upon it (e.g. cliping, ocs,... etc [1,2]).	I-Review	I-1	Review	20632
These are related works, yet neither included nor discussed in this paper.	I-Review	I-1	Review	20632
How is the presented linear+EM method comparing with these variants, in term of effectiveness on training GAN and the reported test-time metrics?	I-Review	I-1	Review	20632
In short, the comparison to previous works seems insufficient in my point of view.	I-Review	I-1	Review	20632
<sep> <sep> Also, can you comment on Defensive Quantization (DQ) [3]?	B-Review	B-2	Review	20632
The quantization method is specifically designed for adversarial attack/perturbation setting and seems applicable under GAN setting.	I-Review	I-2	Review	20632
<sep> <sep> Last, there is a typo at the end of Sec 4.2: should it be f_{em}(x) instead of f_{e}m(x)?	B-Review	B-3	Review	20632
<sep> <sep> [1] Low-bit Quantization of Neural Networks for Efficient Inference	O	O	Review	20632
[2] Improving Neural Network Quantization using Outlier Channel Splitting	O	O	Review	20632
[3] Defensive Quantization: When Efficiency Meets Robustness	O	O	Review	20632
<sep> <sep> Thank you for your valuable comments!	O	O	Reply	20632
<sep> <sep> Q1: Comparison to previous work	O	O	Reply	20632
A1: There are truly various complexed quantization methods based on linear functions that work well on CNN, like clip or OCS as you mentioned.	B-Reply	B-1	Reply	20632
We add extra experiments on Outlier Channel Splitting (OCS)[1] and Analytical Clipping for Integer Quantization (ACIQ)[2] to do a more comprehensive comparison.	I-Reply	I-1	Reply	20632
Due to the OCS do not need finetuning, we just implement it directly to the pre-trained model like the original paper.	I-Reply	I-1	Reply	20632
For ACIQ, we use the same experimental setup in Section 5, i.e. quantize a pre-trained model and then finetune 20 epochs.	I-Reply	I-1	Reply	20632
The results are shown below and we copy our results in Table 2 for ease of comparison.	I-Reply	I-1	Reply	20632
Compared to OCS and ACIQ, QGAN still gets the best or comparable results in all cases.	I-Reply	I-1	Reply	20632
The performance of ACIQ is similar to Minmax-Q, but it doesn't support the 1-bit case.	I-Reply	I-1	Reply	20632
In the 4-bit case, QGAN still performs as good as ACIQ with a little bit lower IS but better FID.	I-Reply	I-1	Reply	20632
<sep> We will add these related work experiments and discussion to our paper later according to your kind suggestions, and we hope these results can eliminate your concerns.	I-Reply	I-1	Reply	20632
<sep> --------------------------------------------------------------------------------------	I-Reply	I-1	Reply	20632
|       1-bit      |    2-bit        |     3-bit       |  4-bit       |	I-Reply	I-1	Reply	20632
--------------------------------------------------------------------------------------	I-Reply	I-1	Reply	20632
|      IS/FID    |     IS/FID    |     IS/FID    |  IS/FID    |	I-Reply	I-1	Reply	20632
--------------------------------------------------------------------------------------	I-Reply	I-1	Reply	20632
Minmax-Q | 1.16/407.9 | 2.65/132.4 | 4.35/65.1   | 4.74/40.3   |	I-Reply	I-1	Reply	20632
Log-Q         |     N/A         | 1.17/421.9 | 1.16/440.3 | 4.15/60.6   |	I-Reply	I-1	Reply	20632
Tanh-Q       |    N/A          | 1.28/437.8 | 1.20/466.7 | 1.13/460.2 |	I-Reply	I-1	Reply	20632
OCS             | 1.00/438.9 | 2.22/283.0 | 3.16/133.3 | 3.80/138.4 |	I-Reply	I-1	Reply	20632
ACIQ           |    N/A          | 3.87/65.9   | 4.30/51.6   | 4.80/40.4   |	I-Reply	I-1	Reply	20632
QGAN         |  3.32/96.7   |  4.15/54.3  | 4.46/51.4   | 4.60/39.6   |	I-Reply	I-1	Reply	20632
-----------------------------------------------------------------------------------------	I-Reply	I-1	Reply	20632
<sep> Q2: Comments on Defensive Quantization	O	O	Reply	20632
A2: Firstly, Defensive Quantization (DQ) focus on CNN quantization, and the adversarial attacks apply to classification tasks.	B-Reply	B-2	Reply	20632
Our QGAN is a quantization method on the GAN model, and the major task of quantized GAN is generating image samples.	I-Reply	I-2	Reply	20632
The adversarial example generation in the attack scenario is different from image generation using GAN.	I-Reply	I-2	Reply	20632
The adversarial example is obtained by adding subtle perturbations on the original input image, while GAN generates images using the generator networks.	B-Reply	B-2	Reply	20632
Secondly, the robustness mentioned in DQ refers to attack accuracy, while the robustness in GAN means the unstable training process.	I-Reply	I-2	Reply	20632
The concerns and application scenarios of DQ and QGAN are different, and it is difficult to directly apply DQ to GAN quantization.	I-Reply	I-2	Reply	20632
<sep> <sep> Besides, thank you for pointing out the typo and we will modify it later.	B-Reply	B-3	Reply	20632
<sep> <sep> [1] Improving Neural Network Quantization using Outlier Channel Splitting	O	O	Reply	20632
[2] ACIQ: Analytical Clipping for Integer Quantization of neural networks	O	O	Reply	20632

This paper propose to study the quantization of GANs parameters.	O	O	Review	20632
They show that standard methods to quantize the weights of neural networks fails when doing extreme quantization (1 or 2-bit quantization).	O	O	Review	20632
They show that when using low-bit representation, some of the bits are used to model extremal values of the weights which are irrelevant and lead to numerical instability.	O	O	Review	20632
To fix this issue they propose a new method based on Expectation-Maximization to quantify the weights of the neural networks.	O	O	Review	20632
They then show experimentally that this enables them to quantize the weights of neural networks to low bit representation without a complete drop of performance and remaining stable.	O	O	Review	20632
<sep> <sep> I'm overall in favour of accepting this work.	O	O	Review	20632
The paper is well motivated, the authors clearly show the benefits of the proposed approach compared to other approach when using extreme quantization.	O	O	Review	20632
<sep> <sep> Main argument:	O	O	Review	20632
+ Great overview of previous methods and why they fail when applying extreme quantization	O	O	Review	20632
+ Great study of the influence of the sensitivity to the number of bits used for quantization	O	O	Review	20632
- It would have been nice if the author had provided standard deviation for the results by running each method several times.	B-Review	B-1	Review	20632
In particular figure 2.c seem to show that they might be a lot of variance in the results when using low bit quantization.	I-Review	I-1	Review	20632
<sep> - I feel some details are missing or at least lack some precision.	B-Review	B-2	Review	20632
For example are the networks pre-trained with full precision in all experiments ?	I-Review	I-2	Review	20632
if so can you precise it in section 3.1 also ?	I-Review	I-2	Review	20632
<sep> - The proposed approach seem very similar in spirit to vector quantization, can the author contrast their method to vector quantization ?	B-Review	B-3	Review	20632
<sep> - In equation (7) doesn't the constant C also depend on alpha and beta ?	B-Review	B-4	Review	20632
<sep> - In section 5.1 do you also use the two phase training described in section 4.2 ?	B-Review	B-5	Review	20632
<sep> - Figure 4.c seems to indicate that quantize the generator only is no more a problem ?	B-Review	B-6	Review	20632
Can you explain why this figure is very different from figure 2.c	I-Review	I-6	Review	20632
- In table 3 how is the number of bits chosen, did you try several different values and report the best performance ?	B-Review	B-7	Review	20632
<sep> <sep> Minor:	O	O	Review	20632
- Some of the notations are a bit confusing.	B-Review	B-8	Review	20632
You call X the tensor of x, I think it would be more clear to say that X is the domain of x.	I-Review	I-8	Review	20632
- I'm surprised by the results in section 3.1, wouldn't the issue described in this section when training standard neural networks ?	B-Review	B-9	Review	20632
wasn't this known before ?	I-Review	I-9	Review	20632
<sep> - There is some typos in the text	B-Review	B-10	Review	20632
Thank you for your valuable comments!	O	O	Reply	20632
<sep> <sep> Q1: Standard deviation for results	O	O	Reply	20632
A1: We add the standard deviation for the results of Minmax-Q and QGAN in Table 2 in Section 5.1.	B-Reply	B-1	Reply	20632
Here we quantize both generators and discriminators, thus the standard deviation is not too large.	I-Reply	I-1	Reply	20632
Comparing the standard deviation for the results of Minmax-Q and QGAN, we can figure out QGAN is more stable as an additional benefit.	I-Reply	I-1	Reply	20632
We will add the standard deviation for other results in our paper later.	I-Reply	I-1	Reply	20632
<sep> ----------------------------------------------------------	I-Reply	I-1	Reply	20632
|  Minmax-Q |  QGAN     |	I-Reply	I-1	Reply	20632
----------------------------------------------------------	I-Reply	I-1	Reply	20632
1-bit | IS (dev)   | 1.16(0.36)  | 3.32(0.23) |	I-Reply	I-1	Reply	20632
| FID(dev) | 407.9(67.4) | 96.7(9.8)  |	I-Reply	I-1	Reply	20632
----------------------------------------------------------	I-Reply	I-1	Reply	20632
2-bit | IS (dev)   | 2.65(0.18)  | 4.15(0.21) |	I-Reply	I-1	Reply	20632
| FID(dev) | 132.4(26.1) | 54.3(4.9)  |	I-Reply	I-1	Reply	20632
----------------------------------------------------------	I-Reply	I-1	Reply	20632
3-bit | IS (dev)   | 4.35(0.31)  | 4.46(0.15) |	I-Reply	I-1	Reply	20632
| FID(dev) | 65.1(9.8)    | 51.4(3.9)  |	I-Reply	I-1	Reply	20632
----------------------------------------------------------	I-Reply	I-1	Reply	20632
4-bit | IS (dev)   | 4.74(0.11)  | 4.60(0.20) |	I-Reply	I-1	Reply	20632
| FID(dev) | 40.3(2.9)    | 39.6(4.7)  |	I-Reply	I-1	Reply	20632
----------------------------------------------------------	I-Reply	I-1	Reply	20632
<sep> Q2: Details of experiments implementations	O	O	Reply	20632
A2: In Section 3.1 we also quantize the pre-trained full precision model.	B-Reply	B-2	Reply	20632
We will describe the experimental methods clearly in the paper.	I-Reply	I-2	Reply	20632
<sep> <sep> Q3: Difference with vector quantization	O	O	Reply	20632
A3: The main difference between VQ and QGAN is the optimization objective.	B-Reply	B-3	Reply	20632
VQ uses k-means to optimize the quantization levels directly, while QGAN adopts an EM algorithm to optimize the coefficient of linear quantization.	I-Reply	I-3	Reply	20632
<sep> <sep> Q4: Question on the Equation(7)	O	O	Reply	20632
A4: is proportional to, thus, in equation(7), C means the log term for the coefficient, which is a constant.	B-Reply	B-4	Reply	20632
<sep> <sep> Q5: Experiments in Section 5.1	O	O	Reply	20632
A5: In Section 5.1 we only use the EM-based quantization method proposed in Section 4.1.	B-Reply	B-5	Reply	20632
The two-phase training described in Section 4.2 are evaluated in Section 5.2, and Table 3 shows the final results combining the methods proposed in 4.1 and 4.2.	I-Reply	I-5	Reply	20632
<sep> <sep> Q6: Question on Figure 2c and 4c	O	O	Reply	20632
A6: We show the trend of IS over training epoch in Figure 2c, while in Figure 4c we only draw the best IS that can be obtained for a given number of bits.	B-Reply	B-6	Reply	20632
Therefore, the thrashing is not shown in Figure 4 but still exists.	I-Reply	I-6	Reply	20632
For example, only quantizing the generator to 4 bits using Log-Q can get IS up to over 4.5 but the lowest is only 1.0 (This case is shown in green line in Figure 2c).	I-Reply	I-6	Reply	20632
For more precise and clear analysis, we will add standard deviation for results as you suggested later.	I-Reply	I-6	Reply	20632
<sep> <sep> Q7: Results in Table 3	O	O	Reply	20632
A7: We use the two-phase quantization method proposed in 4.2 to obtain the quantized bits in Table 3, that is to say, we greedily first quantize the discriminator and then quantize the generator.	B-Reply	B-7	Reply	20632
This method reduces search times in the solution space efficiently and finally gives the lowest number of bits needed by the generator to meet the given requirement.	I-Reply	I-7	Reply	20632
We did traverse all cases in extreme low-bit (&lt;= 4-bit) and verified the bit configurations given by our proposed methods are the best performance.	I-Reply	I-7	Reply	20632
<sep> <sep> Q8: Results in Section 3.1	O	O	Reply	20632
A8: GAN is unstable during training.	B-Reply	B-9	Reply	20632
It is more sensitive to quantized errors, which may result in non-convergence, mode collapse, or other problems during training, which motivates us to develop QGAN that quantizes weights more accurately to reduce errors, ensuring training quantized GAN stably.	I-Reply	I-9	Reply	20632
<sep> <sep> Furthermore, we will modify the typos and notations in our paper later.	B-Reply	B-10	Reply	20632
Thank you again for your constructive feedback!	O	O	Reply	20632

Summary:	O	O	Review	20632
The authors address the quantization of Generative Adversarial Networks (GANs).	O	O	Review	20632
The paper first performs a sensitivity study for both the generator and the discriminator to quantization methods.	O	O	Review	20632
Building upon the conclusion of this study, the authors propose a scalar quantization method (QGAN) and compress models to 1 bit of 2 bits weights and show generated images and metrics by the compressed models.	O	O	Review	20632
<sep> <sep> Strengths of the paper:	O	O	Review	20632
- As well stated in the introduction, the compression of GANs (in particular the generator, which is used at inference time) is of practical interest and, to the best of my knowledge, novel.	O	O	Review	20632
This novelty can be explained by (1) the fact that it takes tome for quantization methods to percolate the entire deep learning field and/or (2) the fact that quantizing GANs has its specificities and own challenges that have not been yet addressed (this is the claim of the authors).	O	O	Review	20632
<sep> - The sensitivity study is of interest for the community that can build upon this work.	O	O	Review	20632
The conclusions (discriminator more sensitive than generator to quantization, quantizing both generator and discriminator helps) are sensible and interesting.	O	O	Review	20632
<sep> <sep> Weaknesses of the paper:	O	O	Review	20632
- The related work section could be greatly improved, thereby showing the limited novelty of the proposed method (QGAN).	B-Review	B-1	Review	20632
Indeed, the authors propose to learn the optimal scaling parameters alpha and beta.	I-Review	I-1	Review	20632
Many works perform this already and are currently missing in this section, see for instance the two recent surveys: "A Survey on Methods and Theories of Quantized Neural Networks", Guo, "A Survey of Model Compression and Acceleration for Deep Neural Networks", Cheng et al	I-Review	I-1	Review	20632
- Results.	B-Review	B-2	Review	20632
The results are not sufficient to justify the performance of the method for two reasons. (	I-Review	I-2	Review	20632
1) First, the scale is crucial in assessing the performance of a quantization method.	I-Review	I-2	Review	20632
As an example, it is easier to quantize small ResNets on CIFAR-10 than large ResNets on ImageNet.	I-Review	I-2	Review	20632
Thus, scales enables to better discriminate between various approaches.	I-Review	I-2	Review	20632
I acknowledge that this requires large computational resources but this would greatly strengthen the paper (2) Second, GAN metrics have known shortcomings (see for instance "How good is my GAN?",	I-Review	I-2	Review	20632
Shmelkov et al), so the strength of Table 2 is limited.	I-Review	I-2	Review	20632
This is in part alleviated by the authors by showing generated images (which is a good practice), but again echoing point (1), larger images would have helped assess better the quality of the quantization.	I-Review	I-2	Review	20632
<sep> <sep> Justification of rating:	O	O	Review	20632
The authors propose a sensitivity study that is interesting for the community.	B-Review	B-1	Review	20632
However, the proposed method lacks novelty and the results are not convincing enough.	B-Review	B-2	Review	20632
I encourage the authors to pursue in this interesting direction which has important practical implications.	O	O	Review	20632
Thank you for your valuable comments!	O	O	Reply	20632
<sep> <sep> Q1: Related work	O	O	Reply	20632
A1: We add extra experiments on the other two related work, Outlier Channel Splitting (OCS) and Analytical Clipping for Integer Quantization (ACIQ).	B-Reply	B-1	Reply	20632
The results can be seen in the A1 in response to Reviewer #1.	I-Reply	I-1	Reply	20632
OCS duplicates channels containing outliers then halve the channel values, ACIQ uses an approximate closed-form solution to decide the clip threshold.	I-Reply	I-1	Reply	20632
The results shown in the above table indicate QGAN still gets the best or comparable results in all cases.	I-Reply	I-1	Reply	20632
We will add more related work and experiment results as you kindly suggested.	I-Reply	I-1	Reply	20632
<sep> <sep> Q2: Result validity	O	O	Reply	20632
A2:	O	O	Reply	20632
- Scale	B-Reply	B-2	Reply	20632
We have shown the results on different image scale, i.e. 32x32 in cifar-10, 64x64 in celebA, and 128x128 in celebA. QGAN performs similarly on different scales compared with the baselines.	I-Reply	I-2	Reply	20632
Due to limited computational resources, it's very difficult for us to try a much larger model or dataset.	I-Reply	I-2	Reply	20632
On the other hand, the GAN quantization field is still in the early stage, and we believe some basic problems exist in both small scale and large scale models/datasets.	I-Reply	I-2	Reply	20632
For example, the unstable training of quantized GAN model, the accuracy loss of quantization.	I-Reply	I-2	Reply	20632
We believe our work has made initial steps on these problems and can motivate our research community.	I-Reply	I-2	Reply	20632
<sep> - Metrics	B-Reply	B-2	Reply	20632
The GAN metrics have known shortcomings, thus we use both Inception Score (IS) and Frchet Inception Distance (FID) as numerical evaluation, which is widely used in GAN-related papers.	I-Reply	I-2	Reply	20632
At the same time, we show the generated samples as well to give the results as convincing as possible.	I-Reply	I-2	Reply	20632
We use all metrics as far as we know, and we hope the results can be accepted by the community.	I-Reply	I-2	Reply	20632
<sep> <sep> Q3: Novelty	O	O	Reply	20632
A3:	O	O	Reply	20632
- Our detailed sensitivity analysis brings insights for GAN quantizations.	B-Reply	B-1	Reply	20632
<sep> - The main contribution of our work is to propose a quantization method for GAN models.	B-Reply	B-1	Reply	20632
From the study in 3.1, results in Table 2, as well as the extra experiments we added in the table above, we can figure out directly apply the quantization methods which work well in CNN to GAN leads to huge quality loss.	I-Reply	I-1	Reply	20632
Our EM-based quantization is more accurate and narrows quantized errors.	I-Reply	I-1	Reply	20632
Smaller errors not only enable quantized GAN to be successfully trained but also improve the qualities of the result.	I-Reply	I-1	Reply	20632
It solves the unstable training problem of extreme low-bit quantized GAN, which is the biggest challenge compared to CNN.	I-Reply	I-1	Reply	20632
<sep> - Our multi-precision method gives solutions in smaller bits and reduces the search space effectively	B-Reply	B-1	Reply	20632
<sep> Thank you again for the detailed review.	O	O	Reply	20632
We believe the observations and claims in our paper can help the community moving on the study on GAN quantization, which is an important problem in real-world deployment on edge devices.	B-Reply	B-1	Reply	20632

This paper proposes a way of training neural nets on analog-circuit based chips, which are cursed with uncertainties.	O	O	Review	20480
Such uncertainties are deeply rooted in the way neural nets are implemented on such chips.	O	O	Review	20480
Take [c = a x b] as an example.	O	O	Review	20480
In order to perform this operation, one can set the electric potential to a and the conductance to b and c will be the output current.	O	O	Review	20480
The problem here is that we cannot set the conductance precisely, which often encodes the weights of a neural net.	O	O	Review	20480
This implies we cannot precisely program a neural net into these chips.	O	O	Review	20480
This paper proposes to train a neural net with the presence of such noise, by treating weight as a random variable during training.	O	O	Review	20480
The experimental results based on simulation suggest this is a much better strategy than programming a neural net into chips imprecisely.	O	O	Review	20480
<sep> <sep> Overall, this paper touches upon an important research problem towards running neural nets on neuromorphic computing chips, which is how to deal with the underlying uncertainties.	B-Review	B-6	Review	20480
The proposed algorithm is reasonable and the experimental results look encouraging.	I-Review	I-6	Review	20480
However, I would like to ask a few clarification questions.	O	O	Review	20480
Given authors‚Äô response, I will be willing to adjust my score.	O	O	Review	20480
<sep> <sep> (1) For the baseline, have you tried randomly jittering the network weights after every training iteration in a way that is ‚Äúblind‚Äù to the source of the uncertainties (i.e. conductance)?	B-Review	B-1	Review	20480
I would like to understand in what degree modeling the noise helps.	I-Review	I-1	Review	20480
If this works out, it implies, (1) we do not have to pay much cost in sampling; (2) there is a simpler way to train neural nets that behave robust when deploying onto neuromorphic computing chips despite the uncertainties.	I-Review	I-1	Review	20480
<sep> <sep> (2) Is there any intuition behind replacing every weight after every k epochs with new samples (Sec.	B-Review	B-2	Review	20480
2.3)?	I-Review	I-2	Review	20480
<sep> <sep> (3) The paper does not mention the overhead of estimating the loss with n feed-forward passes dramatically slows the training process.	B-Review	B-3	Review	20480
I assume it will slow down training by n times?	I-Review	I-3	Review	20480
<sep> <sep> (4) There is a comparison between retraining and fine-tuning.	B-Review	B-4	Review	20480
Despite being less accurate, is fine-tuning faster to train in terms of the actual training time?	I-Review	I-4	Review	20480
<sep> <sep> (5) Here I quote the paper ‚ÄúThe UATS performs better when the neural network has more layers‚Äù (Sec.	B-Review	B-5	Review	20480
3.2).	I-Review	I-5	Review	20480
I cannot find an empirical comparison that supports this claim.	I-Review	I-5	Review	20480
<sep> <sep> Thanks for the acknowledgement of our work.	O	O	Reply	20480
We believe that the neuromorphic computing is a promising way to introduce AI into people‚Äôs daily life with its high energy efficiency.	B-Reply	B-6	Reply	20480
We hope that this work can pave a way forward to improve the performance of the neural network on the neuromorphic computing chips.	I-Reply	I-6	Reply	20480
The responses for the questions is as follows.	O	O	Reply	20480
<sep> <sep> (1)<tab>We have tried randomly jittering the weights after every iteration.	B-Reply	B-1	Reply	20480
The results on CIFAR-10 are better than the baseline, but worse than the UATS‚Äôs result with n=1 shown in Figure 4 even with a carefully tuned jitter amplitude.	I-Reply	I-1	Reply	20480
Furthermore, if we training the neural networks on the neuromorphic chips, there is no additional cost in sampling the weights.	I-Reply	I-1	Reply	20480
<sep> (2)<tab>The replacement simulates the weight transfer to the neuromorphic computing chips.	B-Reply	B-2	Reply	20480
The larger k, the higher training speed of the algorithm, but the worse the adaptability to the chip.	I-Reply	I-2	Reply	20480
<sep> (3)<tab>It will slow down the training.	B-Reply	B-3	Reply	20480
However, this is a onetime cost.	I-Reply	I-3	Reply	20480
And we plan to improve the training speed in the future work.	I-Reply	I-3	Reply	20480
<sep> (4)<tab>The fine-tuning takes much less epochs to achieve similar accuracy than retraining.	B-Reply	B-4	Reply	20480
Thus, it‚Äôs faster.	I-Reply	I-4	Reply	20480
<sep> (5)<tab>We have compared the accuracies on CIFAR-10 with ResNets that have different layers (20, 44, and 110 layers).	B-Reply	B-5	Reply	20480
The UATS performs better when comparing the 20-layer network and the 44-layer network.	I-Reply	I-5	Reply	20480
However, we didn‚Äôt obtain the result of the 110-layer network in time.	I-Reply	I-5	Reply	20480
Thus, we omitted that part of results but forgot to omit this sentence.	I-Reply	I-5	Reply	20480

The authors propose an "uncertainty adaptation training scheme" (UATS) that describes the uncertainty of the neural network in the training process.	O	O	Review	20480
The authors present experimental results on MNIST and CIFAR-10 demonstrating the utility of their approach.	O	O	Review	20480
<sep> <sep> Overall the quality of the presentation and the exposition in the paper is poor.	B-Review	B-1	Review	20480
I am also not convinced about the novelty and importance of this work.	I-Review	I-1	Review	20480
Calibrating neural network uncertainty has been explored quite thoroughly in the bayesian neural nets community - I do not see comparisons with existing work on this subject or justification/explanation of why this work is better than other prior work on this topic.	I-Review	I-1	Review	20480
In Bayesian neural network, the uncertainty of the weight, such as the standard deviation, is usually a trainable parameter.	B-Reply	B-1	Reply	20480
However, in neuromorphic computing chip, this is a fixed restriction, which is determined by the device or the circuit.	I-Reply	I-1	Reply	20480
Our method is to deal with this underlying uncertainties.	I-Reply	I-1	Reply	20480

Summary:	O	O	Review	1388
In this paper the authors engineer a method for fully automatic de-identification, which can also be applied to videos by applying it separately frame-by-frame.	O	O	Review	1388
The process utilizes an encoder-decoder architectures, which is trained using a combination of adversarial, reconstruction, and perceptual losses.	O	O	Review	1388
The model also leverages features from a pre-trained face recognition model.	O	O	Review	1388
Visually, the results look promising, but do occasionally contain some small artifacts or blurriness (albeit only noticeable when zoomed in).	O	O	Review	1388
The de-identification process appears to work well, and with minimal change in the appearance of the face.	O	O	Review	1388
Head pose and the majority of facial expression is also well preserved.	O	O	Review	1388
Resulting images are evaluated using human evaluation and pretrained identity recognition models, which demonstrate quantitatively that de-identification is successful.	O	O	Review	1388
Pixel-wise difference from the original image is also shown to be less compared to previous methods.	O	O	Review	1388
Video samples look good and successive frames flow well with no visible flickering.	O	O	Review	1388
<sep> <sep> Pros:	O	O	Review	1388
-face images appear to be successfully de-identified, while face pose and expression is preserved	O	O	Review	1388
-produces smooth videos without flickering, even though applied per-frame	O	O	Review	1388
-paper is well written	O	O	Review	1388
-very good at including details needed for reproduction, such as hyperparameter settings	O	O	Review	1388
-contains ablation study	O	O	Review	1388
<sep> Cons:	O	O	Review	1388
-some faint blurriness still can be found in the resulting images	B-Review	B-1	Review	1388
-large number of hyperparamters that must be tuned	B-Review	B-2	Review	1388
-only compares with a single alternative de-identification method from 4 years ago (no comparison against modern GAN based methods)	B-Review	B-3	Review	1388
-ablation study has no quantitative metrics, so it is difficult to tell how much impact any individual component of the system had on the overall performance	B-Review	B-4	Review	1388
<sep> Comments:	O	O	Review	1388
While the proposed system achieves its goal of de-identified videos, its novelty is somewhat limited.	B-Review	B-5	Review	1388
Performance is achieved mainly through clever application of many existing methods, rather than any singular new idea or technique.	I-Review	I-5	Review	1388
That being said, I think that this work does present some significant improvement over previous de-identification methods, but it needs to prove it better.	I-Review	I-5	Review	1388
In the related work the authors mention several alternative de-identification methods, but they only compare with a single method from 2014.	I-Review	I-5	Review	1388
I think the paper could be made much stronger if the authors could compare against more recent techniques, especially those that also utilize an adversarial component.	I-Review	I-5	Review	1388
<sep> <sep> The ablation study does a good job of demonstrating the impact of each component of the system visually.	B-Review	B-6	Review	1388
However, I think it could be improved if some quantitative metrics were included to measure how much improvement each component contributes to the overall performance of the system.	I-Review	I-6	Review	1388
<sep> <sep> Questions:	O	O	Review	1388
How sensitive are the results to the hyperparameter settings?	B-Review	B-7	Review	1388
Does it require a lot of tuning in order to get good results, or is it fairly robust to the settings?	I-Review	I-7	Review	1388
Thank you for your constructive review.	O	O	Reply	1388
Below we address your concerns one by one.	O	O	Reply	1388
Please let us know if these are appropriate.	O	O	Reply	1388
<sep> <sep> Blurriness: this is mostly a result of limited resolution and we have just uploaded to the supplementary website (<a href="https://anonymous-deid-iclr2019submission.github.io/)" target="_blank" rel="nofollow">https://anonymous-deid-iclr2019submission.github.io/)</a> a new video obtained with a higher resolution model (256x256).	B-Reply	B-1	Reply	1388
In this model we replaced the decoder with six repetitions of an upscale block followed by a residual block.	I-Reply	I-1	Reply	1388
These results are sharper and contain less artifacts.	I-Reply	I-1	Reply	1388
In addition we present numerical results that show that the new model also performs strong de-identification.	I-Reply	I-1	Reply	1388
<sep> <sep> Large number of hyperparameters: In practice, the only hyperparameter that needs to be carefully set during training is the distancing strength \lambda.	B-Reply	B-2	Reply	1388
All other parameters were either set to 1 (or 0.5 in case they are shared between the raw and masked generated output) or to their default value without any further tuning.	I-Reply	I-2	Reply	1388
<sep> <sep> Network robustness vs. hyperparameter tuning:  The network is robust to small changes in parameter tuning, with an exception in the range of the distancing strength \lambda, for which any value in the range of [0,2*10^-6] provides natural looking results.	B-Reply	B-7	Reply	1388
With a value of zero a reconstruction is performed, and the value of 2*10^-6 provides maximal de-ID effect (within the range), which is why we use it in our experiments.	I-Reply	I-7	Reply	1388
This is illustrated in Fig.7.	I-Reply	I-7	Reply	1388
<sep> <sep> No comparison to current GAN methods: In the paper, we compared our work to the one of (Samarzija & Ribaric, '14), since that was the only work to provide high-resolution results in color and varying poses.	B-Reply	B-3	Reply	1388
Following your comment, we have added a comparison of our method to the most recent de-identification work, that apply GANs as well.	I-Reply	I-3	Reply	1388
The results are now in the revised version (Fig.5) and show a clear advantage to our method in terms of maintaining expression.	I-Reply	I-3	Reply	1388
<sep> <sep> Quantitative ablation study results: we have added to the revised version a quantitative comparison between the different models shown in the ablation study.	B-Reply	B-6	Reply	1388
For each, we compare the mean pixel-level distance and the mean ID distance (as evaluated by the differences in the last layer of the VGGFace2 classifier), both in L1.	I-Reply	I-6	Reply	1388
The first should be low, while the second should be high.	I-Reply	I-6	Reply	1388
As can be seen in the results plot, the model we use (b) is very high in the ID distance axis, while considerably low in the pixel-level distance.	I-Reply	I-6	Reply	1388
The raw (unmasked) model (c) achieves an even higher ID distance, but this is anticipated, since it is not blended with the source image.	I-Reply	I-6	Reply	1388

This work presents an encoder-decoder network architecture that is conditioned on the high-level representation of a person‚Äôs facial image for face de-identification that enables fully automatic video modification.	O	O	Review	1388
The effectiveness of the proposed method is verified qualitatively and quantitatively.	O	O	Review	1388
Although the novelty of the method is not impressive, the proposed method seems to be useful for face-related applications and the experimental results are convincing to me.	O	O	Review	1388
<sep> <sep> Pros:	O	O	Review	1388
- This method is simple, apparently effective and is a nice use of adversarial encoder-decoder for a practical task.	O	O	Review	1388
The paper is written clearly and the English is fine.	O	O	Review	1388
<sep> <sep> Cons:	O	O	Review	1388
- My main concern with this paper is regarding the novelty.	B-Review	B-1	Review	1388
The authors seem to claim a novel GAN architecture by using an auto-encoder-based network architecture with a pre-trained face recognition network and multi-image perceptual loss.	I-Review	I-1	Review	1388
However, it is not clear to me what aspect of their GAN is particularly new.	I-Review	I-1	Review	1388
<sep> <sep> - Missing experimental comparisons with state-of-the-arts.	B-Review	B-2	Review	1388
The most recent work that compared in the Experiment section is the work of Samarzija & Ribaric (2014).	I-Review	I-2	Review	1388
Detailed experimental comparisons with more recent state-of-the-arts are needed to justify the superiority of the proposed method.	I-Review	I-2	Review	1388
<sep> <sep> - Missing ablation study and more in-the-wild comparisons in the Experiment section.	B-Review	B-3	Review	1388
The proposed framework contains several modules, an ablation study is needed to verify the separate contribution of each component.	I-Review	I-3	Review	1388
Moreover, more in-the-wild qualitative and quantitative experiments on recent benchmarks with large facial variations (e.g., expression, occlusion, blur, etc.)	I-Review	I-3	Review	1388
are needed to verify the efficacy of the proposed method.	I-Review	I-3	Review	1388
<sep> <sep> Additional comments:	O	O	Review	1388
- How did authors update each component and ensure stable yet fast convergence while optimising the whole GAN-based framework?	B-Review	B-4	Review	1388
<sep> <sep> - How did authors choose the value of \alpha in Eq. (2-4)?	B-Review	B-5	Review	1388
Thank you for your comments.	O	O	Reply	1388
<sep> <sep> Novelty:	O	O	Reply	1388
The main novel aspects are:	B-Reply	B-1	Reply	1388
1.	I-Reply	I-1	Reply	1388
The concatenation of an independent face-recognition network descriptor into the latent space.	I-Reply	I-1	Reply	1388
<sep> 2.	I-Reply	I-1	Reply	1388
The use of a distancing loss to define the target image and the real-time control it enables over the perceived identity.	I-Reply	I-1	Reply	1388
<sep> 3.	I-Reply	I-1	Reply	1388
The partition of a multi-level perceptual loss into sub-domains (distancing the high-levels, while bringing the low/medium-levels closer).	I-Reply	I-1	Reply	1388
<sep> 4.	I-Reply	I-1	Reply	1388
Various masking techniques.	I-Reply	I-1	Reply	1388
<sep> <sep> These technical novelties translate to the following application novelties in the field of image and video translation:	B-Reply	B-1	Reply	1388
1.	I-Reply	I-1	Reply	1388
Domain translation networks are commonly re-trained for every pair of domains (specifically in the case of face translation).	I-Reply	I-1	Reply	1388
In our case, the output domain is the same as the input domain.	I-Reply	I-1	Reply	1388
<sep> 2.	I-Reply	I-1	Reply	1388
Our network is trained once and can then be applied universally to any face, and in real-time,  without adaptation to the new face.	I-Reply	I-1	Reply	1388
<sep> 3.	I-Reply	I-1	Reply	1388
Previous work mainly relied on face-swapping for the task of de-identification (i.e. rely on other identities for this task), while our network depends solely on the identity of interest.	I-Reply	I-1	Reply	1388
<sep> 4.	I-Reply	I-1	Reply	1388
Previous works were not able to maintain the expression, pose, illumination conditions and handle occlusions over the source image/frame - hence our work is the first to address de-identification in video.	I-Reply	I-1	Reply	1388
<sep> 5.	I-Reply	I-1	Reply	1388
We handle varying backgrounds, considerable scene motion, and occlusions without difficulty.	I-Reply	I-1	Reply	1388
<sep> <sep> State-of-the-art comparisons:	O	O	Reply	1388
<sep> For our comparison, we selected the literature work that presented results with the highest quality (Samarzija & Ribaric, '14).	B-Reply	B-2	Reply	1388
More recent de-identification works (Jourabloo et al '15; Wu et al '18) present lower quality results (only black and white images, low resolution).	I-Reply	I-2	Reply	1388
Following the review, we tried to extract from their figures face images in order to perform this comparison, but the quality is too low to handle and the crops of the input faces are such that we would need to do special adjustments.	I-Reply	I-2	Reply	1388
<sep> <sep> More generally, we detail the advantages of each work in Tab.1.	I-Reply	I-2	Reply	1388
As can be seen, the literature methods, including the latest ones, are not-competitive (regardless of our improved quality, a larger diversity of output, much-reduced runtime) due to the fact that they do not preserve expression and pose.	I-Reply	I-2	Reply	1388
<sep> <sep> Ablation study:	O	O	Reply	1388
<sep> We present an ablation study in Fig.7.	B-Reply	B-3	Reply	1388
The 6 ablation results presented were selected both due to their corresponding components importance and due to the results visibility in images.	I-Reply	I-3	Reply	1388
For example, result (c) emphasizes the importance of the masking component for handling occlusion and seamlessly blend between the source and generated image, and can be easily observed in images.	I-Reply	I-3	Reply	1388
On the other hand, we omitted the ablation on the edge-preserving losses since they do not result in lower quality output.	I-Reply	I-3	Reply	1388
However, in our experience, they are important for fast convergence.	I-Reply	I-3	Reply	1388
<sep> <sep> More in-the-wild comparisons:	O	O	Reply	1388
<sep> Our experiments were done both on images and videos.	B-Reply	B-3	Reply	1388
The images used in our experiments were specifically selected to provide challenging scenarios (e.g. the subset of images from the NIST Face recognition challenge known to be the most difficult, which include challenging illumination conditions and blurriness).	I-Reply	I-3	Reply	1388
The images use to compare with other methods also present challenging pose and expression.	I-Reply	I-3	Reply	1388
<sep> <sep> For video samples, we selected challenging videos with a large amount of motion and sizable intra-video variation in the expression, pose, occlusion and illumination conditions.	I-Reply	I-3	Reply	1388
<sep> <sep> We provide a host of qualitative and quantitative experiments, all on real-world images and challenging videos.	I-Reply	I-3	Reply	1388
The qualitative results are presented as sample images and videos, while the quantitative results are presented in term of MOS, confusion matrices, automated identity ranking and pixel-level similarity vs. perceived identity distance.	I-Reply	I-3	Reply	1388
There are no controlled images or videos -- it is all ‚Äúin the wild‚Äù.	I-Reply	I-3	Reply	1388
The specific ‚Äúlabeled faces in the wild‚Äù dataset is part of the training dataset and cannot be used for testing.	I-Reply	I-3	Reply	1388
However, the images we use, and especially the videos, are just as challenging if not more.	I-Reply	I-3	Reply	1388
<sep> <sep> (continued below)	O	O	Reply	1388

The submission proposes a method for face de-identification.	O	O	Review	1388
<sep> A network is trained to transform an input face image to simultaneously stay close to the low- and mid-level representations  while maximising the distance of the high-level representation of the input image in a face recognition network.	O	O	Review	1388
Additionally an adversarial loss and reconstruction losses both in terms of the input image as well as its horizontal and vertical gradients are employed.	O	O	Review	1388
<sep> The network learns to transform faces to be maximally different in identity from a given reference image while preserving low-level features.	O	O	Review	1388
Thus, at inference the network can de-identify face images from arbitrary new people given a single reference image of each person.	O	O	Review	1388
<sep> <sep> The method is evaluated in three different ways.	O	O	Review	1388
<sep> a) It is shown that humans have difficulties discriminating between transformed and non-transformed videos.	O	O	Review	1388
<sep> b) In a fine-discrimination experiment human subjects are asked to re-identify faces from a given reference image among five dark-haired caucasian males.	O	O	Review	1388
The subjects could re-identify the images without face de-identification but had substantial problems after the transformation was applied.	O	O	Review	1388
<sep> c) In a quantitative study it is shown that a state-of-the-art face recognition network cannot recognise faces of celebrities after the de-identification is applied while it recognise it fairly well before the transformation	O	O	Review	1388
<sep> I have some questions and remarks:	O	O	Review	1388
<sep> 1.)	O	O	Review	1388
How long are the videos used for evaluation a), what is the exact study protocol ?	B-Review	B-1	Review	1388
<sep> <sep> 2.)	O	O	Review	1388
Are the evaluation networks trained on the same dataset as the loss network?	B-Review	B-2	Review	1388
If yes it is not surprising that the generated images can fool the networks as they represent the same data as the loss network and I would like to see the evaluation for networks not trained on the same dataset as the loss network.	I-Review	I-2	Review	1388
<sep> <sep> 3.)	O	O	Review	1388
The method is optimised to maximise confusion of the identity while preserving low and mid level features.	B-Review	B-3	Review	1388
This leads to good de-identification if the set of identities from which to retrieve is densely sampled in the space of low-level features.	I-Review	I-3	Review	1388
I.e. if in the set of identities from which to identify a person there exist many people with similar low-level features.	I-Review	I-3	Review	1388
However, there are many conceivable scenarios in which the number of possible identities from which to retrieve is far smaller.	I-Review	I-3	Review	1388
To de-identify in such scenarios, it is necessary to apply much stronger transformations to the face to obscure the identity of a person.	I-Review	I-3	Review	1388
It would be great if this dependency between the strength of the transformation that needs to be applied and the reference set of identities from which to retrieve the identity of a given person could be explicitly discussed in the submission.	I-Review	I-3	Review	1388
<sep> <sep> 4.)	O	O	Review	1388
The emphasis on performance for video de-identification is somewhat misleading as the method does not seem to include any particular effort to explicitly improve video performance.	B-Review	B-4	Review	1388
It is great that the method also seems to work for video, but I cannot see strong evidence that it strongly outperforms pre-existing methods on video performance (they might also just work well out-of-the-box).	I-Review	I-4	Review	1388
<sep> <sep> Nevertheless, I believe the submission addresses an interesting topic and shows non-trivial results.	O	O	Review	1388
While I have some questions about the evaluation and minor concerns about the presentation I would overall recommend acceptance of the submission.	O	O	Review	1388
Thank you very much for your supportive review.	O	O	Reply	1388
To address your questions:	O	O	Reply	1388
<sep> 1.	O	O	Reply	1388
The non-celeb videos used for evaluation item (a) on your list, are of length 15-20 seconds each.	B-Reply	B-1	Reply	1388
A total of 9 non-celeb videos are used.	I-Reply	I-1	Reply	1388
<sep> <sep> 2.	O	O	Reply	1388
To make sure that we cover the intent of the question, we provide two answers.	O	O	Reply	1388
<sep> I. We train on completely different datasets from the evaluation ones.	B-Reply	B-2	Reply	1388
As mentioned in the manuscript, training is done only on image based datasets, which are conventional datasets used for face recognition.	I-Reply	I-2	Reply	1388
No training is performed on video.	I-Reply	I-2	Reply	1388
<sep> II.	B-Reply	B-2	Reply	1388
The VGGFace network and the two ArcFace networks are trained on different datasets, with an overlap in identities.	I-Reply	I-2	Reply	1388
The ArcFace network is considerably more accurate and employs a much larger training dataset (100,000 identities vs. 9,000), a different architecture, and different losses.	I-Reply	I-2	Reply	1388
Therefore, we believe that removing the persons that VGGFace was trained on from the ArcFace training dataset would not have changed the results in a significant way.	I-Reply	I-2	Reply	1388
<sep> <sep> 3.	B-Reply	B-3	Reply	1388
Consider the experiment mentioned in your review as (b).	I-Reply	I-3	Reply	1388
Humans were asked to identify between a small group of five men of similar ethnicity and were not able to identify in this small-set scenario.	I-Reply	I-3	Reply	1388
<sep> The question, as we understand it, is what would happen for persons of different ethnicity.	I-Reply	I-3	Reply	1388
<sep> As can be seen in supplementary video #7, distinctive ethnic features are changed by our system (eyes, nose, lips).	I-Reply	I-3	Reply	1388
<sep> Identification based on skin-tone or hair color would still be possible.	I-Reply	I-3	Reply	1388
However, the literature of cross domain image translation has many solutions that change hair color (the well known blond to black hair example), and skin tone would probably behave similarly.	I-Reply	I-3	Reply	1388
<sep> <sep> 4.	O	O	Reply	1388
Our observation is that our method works without artifacts on video, which is not obvious.	B-Reply	B-4	Reply	1388
With regards to previous work: (1) Face replacement methods are discrete by design and would result in non-smooth videos with noticeable temporal artifacts. (	I-Reply	I-4	Reply	1388
2) As listed in Tab.1, the previous work do not preserve pose, expression, gaze, and mouth position, which are crucial for video applications.	I-Reply	I-4	Reply	1388
For example, if a person is speaking in a video, the literature methods would not generate naturally looking mouth motion, and cannot generate a video where the lips are in synch with the audio.	I-Reply	I-4	Reply	1388

This paper outlines a new method that allows using a variety of precision in the numerical representation of the network to increase performance (both in terms of accuracy and speed).	O	O	Review	20025
They learn a threshold value for which all activation values above the threshold are learned at full precision, while all below are learned at reduced precision.	O	O	Review	20025
This enables substantial performance gains.	O	O	Review	20025
<sep> <sep> The authors summary of the contributions made in the paper is accurate.	O	O	Review	20025
<sep> <sep> The paper is well written and clearly articulates a contribution to the literature.	O	O	Review	20025
As such, I think it should be accepted.	B-Review	B-9	Review	20025
However, the major question I had as I read the paper was the efficacy on GPU, which the paper discusses, but does not implement, nor show any empirical results for, which weakens the paper.	I-Review	I-9	Review	20025
Most deep learning happens on GPUs (or similar accelerators), so until this technique is implemented there, it is of limited use.	I-Review	I-9	Review	20025
It is still a contribution to the literature, but the paper would be significantly strengthened with a GPU implementation.	I-Review	I-9	Review	20025
Additionally, the experimental evidence is lacking.	I-Review	I-9	Review	20025
More experiments would also strengthen the paper.	I-Review	I-9	Review	20025
<sep> <sep> If these changes were made I would change my score to 8 (accept).	I-Review	I-9	Review	20025
I do think that the work is slightly premature, and would benefit significantly from adding GPU results and additional experiments.	I-Review	I-9	Review	20025
The contribution is strong, however, and should be published in some form, either now, or at a future date.	I-Review	I-9	Review	20025
<sep> <sep> For the experimental setup, I had a few questions:	O	O	Review	20025
<sep> 1) What happens with fixed thresholds?	B-Review	B-1	Review	20025
E.g. doing a sweep over fixed values.	I-Review	I-1	Review	20025
<sep> <sep> 2) How do the results vary for different initialization schemes?	B-Review	B-2	Review	20025
<sep> <sep> 3) How do the results vary with the 5 hyperparameters listed?	B-Review	B-3	Review	20025
How were they chosen?	I-Review	I-3	Review	20025
<sep> <sep> 4) How consistent are the results?	B-Review	B-4	Review	20025
i.e. what happens if the experiments are repeated N times?	I-Review	I-4	Review	20025
Do we see the same values?	I-Review	I-4	Review	20025
<sep> <sep> In short, I would like to see more experiments.	I-Review	I-4	Review	20025
The results are encouraging, but brief.	I-Review	I-4	Review	20025
Evaluating on more architectures would strengthen the paper.	I-Review	I-4	Review	20025
<sep> <sep> Overall questions:	O	O	Review	20025
<sep> - How well does the 1.2% improvement in perplexity compare to SOTA?	B-Review	B-5	Review	20025
Please add context for the numbers reported.	I-Review	I-5	Review	20025
It's not at all clear how good of an improvement is seen.	I-Review	I-5	Review	20025
<sep> - How do the results change with top-5 accuracy vs top-1 accuracy?	B-Review	B-6	Review	20025
<sep> <sep> <sep> Notes which did not affect the review score:	O	O	Review	20025
<sep> - There are some typos, e.g. ‚ÄúPG computes most features in a low precision and only a small proportion of important features in a higher precision.	B-Review	B-7	Review	20025
‚Äù Saying ‚ÄúPG computes most features using reduced precision and only a small proportion of important features using high precision‚Äù would be more correct.	I-Review	I-7	Review	20025
There are similar typos throughout that I have not listed.	I-Review	I-7	Review	20025
<sep> - Tables 3 &amp; 4, and Figure 4, are very cramped and hard to read.	B-Review	B-8	Review	20025
<sep> Table 1 and 2 are quite crowded; can you rearrange them so they‚Äôre easier to read?	I-Review	I-8	Review	20025
<sep> <sep> <sep> We continue to address the questions here.	O	O	Reply	20025
<sep> <sep> Q7: "How well does the 1.2% improvement in perplexity compare to SOTA?"	O	O	Reply	20025
<sep> <sep> Reply: There are a large variety of RNN models, but the LSTM network is a popular one and is widely adopted in the literature, for example, by Hubara et al (2017) and He et al (2016), as the benchmark.	B-Reply	B-5	Reply	20025
To show the effect of PG on RNNs, we modify the linear layers in the LSTM model to support PG.	I-Reply	I-5	Reply	20025
The baseline floating point result reported in the paper (PPW 110) are at the same level of accuracy as that in the literature (PPW 109).	I-Reply	I-5	Reply	20025
In this work we focus on reducing the compute in a neural network.	I-Reply	I-5	Reply	20025
The 1.2% PPW improvement is an extra benefit obtained while PG achieves a 2.7x compute saving compared to the 8-bit uniform quantization baseline.	I-Reply	I-5	Reply	20025
<sep> <sep> Q8: "How do the results change with top-5 accuracy vs top-1 accuracy?"	O	O	Reply	20025
<sep> <sep> Reply: In the latest revision, we add the top-5 model accuracy measurements for ResNet-18 on CIFAR-10 and ShuffleNet V2 0.5x on ImageNet, and report them in Table 9 in Section A.2.	B-Reply	B-6	Reply	20025
<sep> <sep> The change of the top-5 accuracy aligns well with the top-1 accuracy.	I-Reply	I-6	Reply	20025
The magnitude of the change in the top-5 accuracy, however, is  smaller than the top-1.	I-Reply	I-6	Reply	20025
Especially for the ResNet-18 CIFAR-10 model, the top-5 accuracy has barely changed a little before and after adding PG.	I-Reply	I-6	Reply	20025
<sep> <sep> Q9: "There are some typos."	O	O	Reply	20025
<sep> <sep> Reply: Thank you for pointing out the typos!	O	O	Reply	20025
We‚Äôll correct them in the future revision.	B-Reply	B-7	Reply	20025
<sep> <sep> Q10: "Tables 3 &amp; 4, and Figure 4, are very cramped and hard to read.	O	O	Reply	20025
Table 1 and 2 are quite crowded."	O	O	Reply	20025
<sep> <sep> Reply: Thank you for the suggestion.	O	O	Reply	20025
We realize that the tables and Figure 4 are dense and could be hard to read.	B-Reply	B-8	Reply	20025
We‚Äôll reorganize them and make them easier to read.	I-Reply	I-8	Reply	20025

This paper introduces Precision Gating, a novel mechanism to quantize neural network activations to reduce the average bitwidth, resulting in networks with fewer bitwise operations.	O	O	Review	20025
The idea is to have a learnable threshold Delta that determines if an output activation should be computed in high or low precision, determined by the most significant bits of the value.	O	O	Review	20025
Assuming that high activations are more important, these are computed at higher precision.	O	O	Review	20025
<sep> <sep> I agree that the following three key contributions listed in the paper are (slightly re-formulated):	O	O	Review	20025
1.	O	O	Review	20025
Introducing Precision Gating (PG), the first end-to-end trainable method that enables dual-precision execution of DNNs and is applicable to a wide variety of network architectures.	O	O	Review	20025
<sep> 2.	O	O	Review	20025
Precision gating enables DNN computation with a better average bitwidth to accuracy tradeoff than other state-ofthe-	O	O	Review	20025
art quantization methods.	O	O	Review	20025
Combined with its lightweight gating logic, PG demonstrates the potential to reduce DNN execution costs in both commodity and dedicated hardware.	O	O	Review	20025
<sep> 3.	O	O	Review	20025
Unlike prior works that focus only on inference, precision gating achieves the same sparsity during back-propagation as forward propagation, which reduces the computational cost for both passes.	O	O	Review	20025
<sep> <sep> These contributions are novel and experimental evidence is provided for multiple networks and datasets.	O	O	Review	20025
The paper is well-written and provides insightful figures to showcase the strengths of the present method.	O	O	Review	20025
Related work is adequately cited.	O	O	Review	20025
The paper does not contain much theory, but wherever possible equations are provided to illustrate in detail how the method works.	B-Review	B-9	Review	20025
<sep> <sep> Experimental results are shown for the datasets CIFAR-10 with ResNet-18 and ShiftNet-20, and ImageNet with ShuffleNet V2 0.5x.	O	O	Review	20025
On both datasets, PG outperforms uniform quantization, PACT, Fix-Threshold and SeerNet in terms of top-1 accuracy and average bitwidth.	O	O	Review	20025
<sep> What I am missing is information about the variability of results, since there are no error bars.	B-Review	B-1	Review	20025
Are the results averaged over multiple trials (if yes how many?),	I-Review	I-1	Review	20025
and is there a difference in variance between the methods?	I-Review	I-1	Review	20025
I realize that adding standard deviations to all results in the tables might be infeasible, but a qualitative statement would be interesting.	I-Review	I-1	Review	20025
In particular, the random initialization of the hb bits could play a bigger role than lb bits.	I-Review	I-1	Review	20025
<sep> <sep> The two variants of PG, with and without sparse backpropagation are also investigated, showing that sparse backpropagation leads to more sparsity.	O	O	Review	20025
To show that the resulting lower average bitwidth gained with PG leads to increased performance, the authors implement it in Python (running on CPU) and measure the wall clock time to execute the ResNet-18 model.	O	O	Review	20025
Speedups are shown for every layer when using PG.	O	O	Review	20025
Evidence from other papers is cited to argue that similar speedups are expected on GPUs.	O	O	Review	20025
<sep> <sep> Even though at the moment it is unclear to me how statistically significant the results are, and I strongly recommend commenting on this in the paper, I think the idea of PG and the demonstrated benefits make the paper interesting enough to be accepted at ICLR.	O	O	Review	20025
<sep> <sep> I also have a few questions that I could not get completely from the paper:	O	O	Review	20025
1.	O	O	Review	20025
I am a bit confused by what you call features.	B-Review	B-2	Review	20025
Fig.2 shows by example how the method works for an input.	I-Review	I-2	Review	20025
Is, a single number, i.e. a single entry of your input vector, or do you mean the complete input vector?	I-Review	I-2	Review	20025
<sep> 2.	O	O	Review	20025
Could you give a bit more insight, how you tuned your hyperparameters, especially and?	B-Review	B-3	Review	20025
<sep> 3.	O	O	Review	20025
What exactly does e.g. mean?	B-Review	B-4	Review	20025
The network ideally should compute at high precision, when the result when only considering the most significant bits is above -1?	I-Review	I-4	Review	20025
<sep> <sep> From a hardware point of view, the paper focuses on GPU implementations.	B-Review	B-5	Review	20025
I would have hoped for a discussion of suitable custom hardware that could support PG most efficiently.	I-Review	I-5	Review	20025
<sep> <sep> <sep> Minor comments that I would be interested in but did not influence my score	O	O	Review	20025
- It seems to me that on the top-left image of Fig.3, one blue circle (the second largest) is too much?	B-Review	B-6	Review	20025
First part shows 8 dots, middle and right only seven?	I-Review	I-6	Review	20025
<sep> - Can you please cite a source that DNN activations have outliers (Sec.	B-Review	B-7	Review	20025
3.4)?	I-Review	I-7	Review	20025
<sep> - You could also define e.g. one and per layer, couldn't you?	B-Review	B-8	Review	20025
Would be interesting to see if  e.g. thinning out the precision over depth is possible / has advantages.	I-Review	I-8	Review	20025
Thank you for being positive towards our paper and providing insightful comments.	O	O	Reply	20025
Below are our answers to your questions.	O	O	Reply	20025
<sep> <sep> Q1: "The variability of results."	O	O	Reply	20025
<sep> <sep> Reply: To show the variability of the results, we repeat the training for the ResNet-18 model in the 5th row of Table 1 (i.e.	B-Reply	B-1	Reply	20025
,=3/2) 10 times.	I-Reply	I-1	Reply	20025
Since the Fix-Threshold scheme is non-trainable (i.e., no variance), we only compare the variability of PG, UQ and PACT.	I-Reply	I-1	Reply	20025
<sep> <sep> The results show that the mean of the model accuracy for PG, UQ and PACT are roughly the same as reported in the paper.	I-Reply	I-1	Reply	20025
The variance of the model accuracy of PG, UQ, PACT is 0.041%, 0.083% and 0.048%, respectively.	I-Reply	I-1	Reply	20025
The empirical results suggest that the variability of the accuracy of PG and UQ are at the same level and lower than that of PACT.	I-Reply	I-1	Reply	20025
The variance of  the average bitwidth of PG is 0.00015 bit across all trials.	I-Reply	I-1	Reply	20025
<sep> <sep> The random initialization of hb bits does affect the accuracy of the first few iterations.	I-Reply	I-1	Reply	20025
As we train the model for more epochs, the learning process will eventually adjust the weights and gating thresholds to achieve similar accuracy and average bitwidth.	I-Reply	I-1	Reply	20025
<sep> <sep> Q2: "Is a single number, i.e. a single entry of your input vector, or do you mean the complete input vector?"	O	O	Reply	20025
<sep> <sep> Reply: Sorry about the confusion.	B-Reply	B-2	Reply	20025
The input feature map is a third-order tensor.	I-Reply	I-2	Reply	20025
In Fig.2 we split each element in the input tensor to the MSB part and the LSB part.	I-Reply	I-2	Reply	20025
We will improve this figure in the future revision.	I-Reply	I-2	Reply	20025
<sep> <sep> Q3&amp;4: "What exactly does e.g. mean?" "	O	O	Reply	20025
How you tuned your hyperparameters, especially and?"	O	O	Reply	20025
<sep> <sep> Reply: The MSB result (i.e.,) is compared against the learnable threshold ) to determine whether we compute the output features in high precision or not.	B-Reply	B-4	Reply	20025
A higher threshold indicates less features are computed in high precision.	I-Reply	I-4	Reply	20025
The here is the target value for the.	I-Reply	I-4	Reply	20025
We add a threshold loss term into the objective function to let approach during training, where the is the penalty factor that balances the threshold loss and the original accuracy loss.	I-Reply	I-4	Reply	20025
<sep> <sep> In your example, is -1, meaning that we want to make be close to -1.	I-Reply	I-4	Reply	20025
The output features are computed at high precision when the MSB result is above.	I-Reply	I-4	Reply	20025
The final value of the thresholds ) are optimized by jointly minimizing the threshold loss and the accuracy loss.	I-Reply	I-4	Reply	20025
<sep> <sep> Practically we look at the distribution of the activations and select a in [0, 5] for CNNs and in [-3, 3] for RNNs.	I-Reply	I-4	Reply	20025
We set a small (typically in the magnitude of 0.001) for the penalty term.	I-Reply	I-4	Reply	20025
<sep> <sep> Q5: "I would have hoped for a discussion of suitable custom hardware that could support PG most efficiently."	O	O	Reply	20025
<sep> <sep> Reply: PG is a hardware friendly dynamic quantization scheme as it only requires adding extra comparators to implement dual-precision.	B-Reply	B-5	Reply	20025
It can be directly deployed on recent proposed architectures by Song et al (2018) and Lin et al (2017).	I-Reply	I-5	Reply	20025
It is estimated to get at least 3x speedup and 5x energy efficiency with the level of sparsity reported for ResNet-18 CIFAR-10.	I-Reply	I-5	Reply	20025
Moreover, there is a line of research on DNN hardware acceleration that proposes to use bit serial / bit parallel execution (Lee et al UNPU: A 50.6TOPS/W unified deep neural network accelerator with 1b-to-16b fully-variable weight bit-precision, ISSCC‚Äô2018) to accelerate ultra low precision networks, which is also a good fit for the precision gating networks.	I-Reply	I-5	Reply	20025
We will add additional discussions on the custom hardware in the future revision.	I-Reply	I-5	Reply	20025
<sep> <sep> Q6: "On the top-left image of Fig.3, one blue circle (the second largest) is too much?"	O	O	Reply	20025
<sep> <sep> Reply: Yes, thank you for pointing this out!	B-Reply	B-6	Reply	20025
The second largest blue circle needs to be deleted.	I-Reply	I-6	Reply	20025
Fig.3 is fixed in the latest revision.	I-Reply	I-6	Reply	20025
<sep> <sep> Q7: "Can you please cite a source that DNN activations have outliers (Sec.	O	O	Reply	20025
3.4)?"	O	O	Reply	20025
<sep> <sep> Reply: (1) Choi et al PACT: Parameterized Clipping Activation for Quantized Neural Networks, arxiv:1805.06085, May 2018:  It clips the outliers of activations as discussed in section 3.4.	B-Reply	B-7	Reply	20025
<sep> (2) Park et al Value-aware Quantization for Training and Inference of Neural Networks, ECCV‚Äô2018: This paper discusses the outlier in neural networks and proposes to assign higher precision to these outliers.	B-Reply	B-7	Reply	20025
<sep> (3) Zhao et al Improving Neural Network Quantization using Outlier Channel Splitting, ICML‚Äô2019: This paper proposes to split the channels to decrease the outlier by half.	B-Reply	B-7	Reply	20025
<sep> <sep> We will also add these citations when we revise the paper.	O	O	Reply	20025
<sep> <sep> Q8: "You can also define one and per layer, couldn't you?"	O	O	Reply	20025
<sep> <sep> Reply: Right, it‚Äôs possible to define a single delta and sigma per layer.	B-Reply	B-8	Reply	20025
This would reduce the hardware cost as we can store fewer thresholds.	I-Reply	I-8	Reply	20025
We plan to run more experiments to understand if this simplification would degrade the accuracy.	I-Reply	I-8	Reply	20025
In this paper we investigated a more general and fine-grained case to show the potential of computing with dual precisions in DNNs.	I-Reply	I-8	Reply	20025

This paper presents an interesting quantization technique that is, unusually, end-to-end trainable and not just an inference technique.	O	O	Review	20025
According to the experiments, the method achieves better performance and computational savings as compared to other quantization method baselines.	O	O	Review	20025
The results are admirably demonstrated on a variety of models, including CNN and RNN-based neural nets, as well as on several datasets in different domains, including ImageNet, CIFAR10, and PTB.	O	O	Review	20025
We see the method seems to generalize across all of these.	O	O	Review	20025
<sep> <sep> Nevertheless, while I found this is very interesting work, I have a number of issues with the experiments, which I'll go into below.	O	O	Review	20025
I feel this work is being released prematurely and could use some more polish to help sell the method better.	O	O	Review	20025
Below are a few remarks and questions for the authors that would be helpful to be answered.	O	O	Review	20025
<sep> <sep> * Why only report on ResNet-18?	B-Review	B-1	Review	20025
It would be far more useful to show numbers against ResNet-50.	I-Review	I-1	Review	20025
It would also be useful to show the non-quantized best results on these models and datasets.	I-Review	I-1	Review	20025
<sep> * I wish more effort had been spent to analyze the experiments.	B-Review	B-2	Review	20025
For example, I am not sure I understand the effects of the threshold on this method.	I-Review	I-2	Review	20025
What happens when it's set manually?	I-Review	I-2	Review	20025
<sep> * How exactly is computation cost savings calculated so crudely?	B-Review	B-3	Review	20025
If it uses B_avg, why not calculate the bitwidth per layer and sum things up?	I-Review	I-3	Review	20025
Using B_avg strikes me as being quite crude.	I-Review	I-3	Review	20025
<sep> * When the authors address runtime changes except in table 6, they changed their baseline to a vanilla ResNet-18 with dense weights.	B-Review	B-4	Review	20025
What are the runtime effects relative to ShuffleNet and ShiftNet?	I-Review	I-4	Review	20025
Thank you for the insightful comments that have led to improvements in our paper.	O	O	Reply	20025
Below are our answers to your questions.	O	O	Reply	20025
<sep> <sep> Q1: "Why only report on ResNet-18?	O	O	Reply	20025
It would be far more useful to show numbers against ResNet-50.	O	O	Reply	20025
It would also be useful to show the non-quantized best results on these models and datasets."	O	O	Reply	20025
<sep> <sep> Reply: In Table 1, we report the results of the floating point baseline for the three models in the first column as ‚Äúfp‚Äù.	B-Reply	B-1	Reply	20025
For example, the floating-point ShiftNet-20 CIFAR-10 model has an accuracy of 89.4%.	I-Reply	I-1	Reply	20025
In Table 4, we report the floating-point PPW of the LSTM PTB model in the caption.	I-Reply	I-1	Reply	20025
<sep> <sep> To empirically show PG works on more models, we apply PG to ResNet-56 and ResNet-32, then train it on the CIFAR-10 dataset.	I-Reply	I-1	Reply	20025
The training settings are the same as described in Section 4.	I-Reply	I-1	Reply	20025
In the latest revision, the additional results are shown in Table 7 in Section A.2.	I-Reply	I-1	Reply	20025
<sep> <sep> Compared to the 8-bit PACT baseline, PG achieves 4x computational cost reduction on both models at the same level of prediction accuracy.	I-Reply	I-1	Reply	20025
The sparsity in ResNet-56 (98.2%) and ResNet-32 (96.3%) are higher than that (90.1%) in ResNet-18 for CIFAR-10 dataset.	I-Reply	I-1	Reply	20025
Compared to the fix-threshold baseline, the accuracy of PG increases by 42.5% for ResNet-56 and 46.4% for ResNet-32 with the same computational cost.	I-Reply	I-1	Reply	20025
This increasing accuracy gap empirically shows that PG also works well on larger DNN models.	I-Reply	I-1	Reply	20025
<sep> <sep> Q2: " I am not sure I understand the effects of the threshold on this method.	O	O	Reply	20025
What happens when it's set manually?"	O	O	Reply	20025
<sep> <sep> Reply: We can consider the threshold in PG as a measurement of the importance of an output feature.	B-Reply	B-2	Reply	20025
If the MSB result exceeds the threshold, it means that the corresponding output feature is important.	I-Reply	I-2	Reply	20025
We will then compute this important feature in high precision.	I-Reply	I-2	Reply	20025
In the bell shaped activation distribution, the larger a threshold is, the less likely an output feature will exceed the threshold, and thus the more output features will be computed using reduced precision.	I-Reply	I-2	Reply	20025
Hence a large threshold is desired to reduce the computational cost.	I-Reply	I-2	Reply	20025
We introduce a threshold loss to make the threshold approach a large value.	I-Reply	I-2	Reply	20025
Moreover, the threshold is also optimized by minimizing the accuracy loss.	I-Reply	I-2	Reply	20025
As a result, the trainable thresholds are learned to jointly minimize the threshold loss and the accuracy loss.	I-Reply	I-2	Reply	20025
<sep> <sep> We‚Äôve already compared PG to manually set thresholds.	I-Reply	I-2	Reply	20025
The results of which are shown  in Table 1 under columns of ‚ÄúFix-Threshold‚Äù.	I-Reply	I-2	Reply	20025
We notice that manually set thresholds yield a much lower model accuracy compared to PG at a similar computational cost.	I-Reply	I-2	Reply	20025
<sep> <sep> In the latest revision, we also show the results of sweeping a series of manually set thresholds on the ResNet-18 for CIFAR-10 with=3/2 in Table 8 in Section A.2.	I-Reply	I-2	Reply	20025
As the threshold decreases from 3 to -4, the average bitwidth in the update phase consistently increases.	I-Reply	I-2	Reply	20025
This is expected because we compute more output features in high precision.	I-Reply	I-2	Reply	20025
The model prediction accuracy therefore increases.	I-Reply	I-2	Reply	20025
However, compared to the manually set threshold, PG achieves a much better model accuracy (91.2%) with a larger sparsity (90.1%).	I-Reply	I-2	Reply	20025
<sep> <sep> Q3: "How exactly is computation cost savings calculated so crudely?	O	O	Reply	20025
If it uses B_avg, why not calculate the bitwidth per layer and sum things up?"	O	O	Reply	20025
<sep> <sep> Reply: The average bitwidth is a good indicator for the compute efficiency when we run PG on customized hardware as it reflects the energy consumption per arithmetic operation.	B-Reply	B-3	Reply	20025
Prior art proposed by Song et al (ISCA‚Äô2018) cited in the paper also adopts the same metric of compute efficiency.	I-Reply	I-3	Reply	20025
<sep> <sep> We agree that calculating the bitwidth per layer and summing them up is another good metric.	I-Reply	I-3	Reply	20025
However, it is essentially equivalent to the average bitwidth reported in the paper.	I-Reply	I-3	Reply	20025
The average bitwidth is obtained by normalizing the sum of the bitwidth per layer using the total number of features in the network.	I-Reply	I-3	Reply	20025
<sep> <sep> Q4: "When the authors address runtime changes except in table 6, they changed their baseline to a vanilla ResNet-18 with dense weights.	O	O	Reply	20025
What are the runtime effects relative to ShuffleNet and ShiftNet?"	O	O	Reply	20025
<sep> <sep> Reply: In Section 4.3, we show the kernel speedup of applying PG to the ResNet-18 model on CIFAR-10 dataset.	B-Reply	B-4	Reply	20025
Since PG works by modifying linear layers (i.e., convolutional layers or fully connected layers) instead of the model architectures, it generalizes to other models containing linear layers.	I-Reply	I-4	Reply	20025

This paper considers the neural architecture search (NAS) problem under the out-of-distribution (OoD) environment.	O	O	Review	396
As the OoD problem is not visited in the current NAS literature, this paper proposes replacements for each of the three standard components in NAS, i.e., the proxy task, the search space, and the optimization algorithm; and each replacement is built upon an ensemble of existing techniques.	B-Review	B-9	Review	396
Experiments are further verified on CelebA, CIFAR-10, SVHN, and MNIST.	I-Review	I-9	Review	396
<sep> <sep> Overall, the novelty in this paper is limited and experiments are not very convincing.	I-Review	I-9	Review	396
Please see the questions below:	O	O	Review	396
<sep> Q1.	B-Review	B-1	Review	396
In the introduction, the authors write "Machine learning systems often encounter OoD errors when dealing with testing data coming from a different distribution from the one used for training".	I-Review	I-1	Review	396
<sep> - What is the validation set used in this paper?	I-Review	I-1	Review	396
<sep> - For the NAS problem, the architectural parameters must be guided by the validation set.	I-Review	I-1	Review	396
So, does the validation set follows the same distribution as the training data set or the testing data set?	I-Review	I-1	Review	396
<sep> - If the validation set and the testing set have the same distribution, is it still a meaningful OoD problem?	I-Review	I-1	Review	396
<sep> <sep> Q2. "	B-Review	B-2	Review	396
For example, naively using data likelihood maximization as a proxy task would run into the issue pointed out by Nalisnick et al (2019a), with models assigning higher likelihoods to OoD data".	I-Review	I-2	Review	396
<sep> - How can I see this point from the given experiments?	I-Review	I-2	Review	396
<sep> - Is it better adding this into an ablation study?	I-Review	I-2	Review	396
<sep> <sep> Q3.	B-Review	B-3	Review	396
Except for WAIC, what other metrics can we consider?	I-Review	I-3	Review	396
The authors should have a more comprehensive related work section, which includes discussion on this part.	I-Review	I-3	Review	396
<sep> - Is it more meaningful to search a better metric than search architectures (which is just a standard applicaiton)?	I-Review	I-3	Review	396
<sep> <sep> Q4.	O	O	Review	396
In Section 3.4:  "CelebA (Liu et al), CIFAR-10 (Krizhevsky et al 2009), SVHN (Netzer et al 2011), and MNIST (LeCun)" are used.	B-Review	B-4	Review	396
<sep> - Could the authors explain more tasks and details on these data sets?	I-Review	I-4	Review	396
Specifically, why they are OoD problems.	I-Review	I-4	Review	396
<sep> - Based on the descriptions from the authors, these data sets seem to be standard ones.	I-Review	I-4	Review	396
<sep> <sep> Q5.	B-Review	B-5	Review	396
Variation is already considered in (1), I mean the second term there.	I-Review	I-5	Review	396
<sep> - Why should we still consider an ensemble of models?	I-Review	I-5	Review	396
<sep> - Is it better adding an ablation study on M about " ROC and PR curve"? (	I-Review	I-5	Review	396
not Figure 13, 14 in the appendix)	I-Review	I-5	Review	396
<sep> Q6.	O	O	Review	396
Is it better to have a comparison with standard NAS in the experiments?	B-Review	B-6	Review	396
<sep> - While authors argue they are not applicable here, it is still good to demonstrate how not applicable they are.	I-Review	I-6	Review	396
<sep> - If the validation set follows the same distribution as the testing set, gradient signals on architectural parameters perhaps can still be helpful.	I-Review	I-6	Review	396
<sep> <sep> Q7.	O	O	Review	396
Can natural gradient descent be applied to (4)?	B-Review	B-7	Review	396
<sep> - "First, optimizing p(Œ±), a probability over ..., each network‚Äôs optimal parameters would need to be individually".	I-Review	I-7	Review	396
The first problem is not a really challenging problem please have a check at "Adaptive Stochastic Natural Gradient Method for One-Shot Neural Architecture Search".	I-Review	I-7	Review	396
<sep> <sep> Q8.	O	O	Review	396
What is the searching time of the proposed method?	B-Review	B-8	Review	396
How's it compared with recent NAS methods?	I-Review	I-8	Review	396
e.g. DARTS (DARTS: Differentiable Architecture Search).	I-Review	I-8	Review	396
Thank you very much for your review of our paper.	O	O	Reply	396
We emphasize that the novelty of the presented work is the search for a distribution of architectures that are tailored to the tasks with Out-of-Distribution (OoD) testing examples.	B-Reply	B-9	Reply	396
To the best of our knowledge, existing neural architecture search (NAS) methods only optimize for maximum likelihood problems with point estimates, which is not appropriate in the OoD environment.	I-Reply	I-9	Reply	396
Below please find our response to your questions/comments:	O	O	Reply	396
<sep> Q1:	O	O	Reply	396
As we search for a neural architecture distribution instead of tuning specific hyperparameters, we did not use any validation set for model selection in our work.	B-Reply	B-1	Reply	396
With our method, we are able to optimize the neural architecture without using a validation set.	I-Reply	I-1	Reply	396
However, it is true that other authors have used a validation set for NAS to prevent overfitting.	I-Reply	I-1	Reply	396
Our NADS can be considered as a Bayesian version of previous NAS methods.	I-Reply	I-1	Reply	396
It naturally enables uncertainty quantification and alleviates potential overfitting issues.	I-Reply	I-1	Reply	396
We note again that the training procedure of our NADS does not see any testing data.	I-Reply	I-1	Reply	396
<sep> <sep> Q2:	O	O	Reply	396
This issue has been discussed by several previously published papers, such as the one you cited.	B-Reply	B-2	Reply	396
When we wrote the paper, we did not think that this issue needed further restatement.	I-Reply	I-2	Reply	396
The issue can be seen in Figure 3(c), where some samples of SVHN are incorrectly given higher likelihood than CIFAR10 for M=1, the original training data.	I-Reply	I-2	Reply	396
We have modified our manuscript to include an additional figure in the appendix to show this issue more clearly.	I-Reply	I-2	Reply	396
More comprehensive discussions of the problem can be found in the following papers:	I-Reply	I-2	Reply	396
<sep> Choi, Hyunsun, Eric Jang, and Alexander A. Alemi. "	I-Reply	I-2	Reply	396
Waic, but why?	I-Reply	I-2	Reply	396
generative ensembles for robust anomaly detection."	I-Reply	I-2	Reply	396
arXiv preprint arXiv:1810.01392 (2018).	I-Reply	I-2	Reply	396
<sep> <sep> Hendrycks, Dan, et al "Using self-supervised learning can improve model robustness and uncertainty."	I-Reply	I-2	Reply	396
arXiv preprint arXiv:1906.12340 (2019).	I-Reply	I-2	Reply	396
<sep> <sep> Shafaei, Alireza, Mark Schmidt, and James J. Little. "	I-Reply	I-2	Reply	396
A Less Biased Evaluation of Out-of-distribution Sample Detectors."	I-Reply	I-2	Reply	396
<sep> <sep> Q3:	O	O	Reply	396
As we are investigating likelihood-based models, other metrics that can be considered would be other forms of penalized likelihood.	B-Reply	B-3	Reply	396
WAIC has been shown to be robust to the issue of assigning high likelihoods to OoD data, as likelihoods of OoD data have been shown to have higher variance compared with that of the training data.	I-Reply	I-3	Reply	396
WAIC is uncertainty-aware for training Bayesian ensembles and WAIC-based training leads to more robust performance with respect to potential uncertainty.	I-Reply	I-3	Reply	396
Hence, it is the most appropriate metric for our NADS training.	I-Reply	I-3	Reply	396
This was actually observed empirically as we have tried other penalized likelihood methods that computes the likelihood through adversarial perturbations, and they do not perform as well as WAIC-based NADS does.	I-Reply	I-3	Reply	396
<sep> <sep> Q4:	O	O	Reply	396
As stated in our manuscript, we trained a likelihood estimation model on these 4 datasets.	B-Reply	B-4	Reply	396
The likelihood estimation model is then used to discriminate OoD samples from other datasets.	I-Reply	I-4	Reply	396
For example, the model trained on MNIST was used to discriminate MNIST from the OoD datasets K-MNIST, F-MNIST, and NotMNIST.	I-Reply	I-4	Reply	396
Again, our NADS only sees the training dataset and the other datasets are hence considered as OoD data.	I-Reply	I-4	Reply	396
<sep> <sep> Q5:	O	O	Reply	396
- It is true that variation is already considered in (1).	B-Reply	B-5	Reply	396
However, (1) was estimated by sampling.	I-Reply	I-5	Reply	396
In the search stage, this was done by sampling multiple architectures.	I-Reply	I-5	Reply	396
In the evaluation stage, the sampling was done by considering an ensemble of architectures, each architecture giving a sample to estimate (1).	I-Reply	I-5	Reply	396
<sep> - As our NADS aims to search for a distribution of architectures that can better estimate the estimation uncertainty, the ensemble of models can be considered the empirical estimates from NADS.	I-Reply	I-5	Reply	396
- We have added additional ROC and PR curves (Figure 4, page 7) to our manuscript to more clearly show the effect of the ensemble size on the model's performance.	I-Reply	I-5	Reply	396
<sep> <sep> Q6:	O	O	Reply	396
Standard NAS algorithms do not search for a distribution of architectures.	B-Reply	B-6	Reply	396
As such, they are not able to optimize the WAIC as it needs to be approximated through sampling, or further approximated to make optimization tractable.	I-Reply	I-6	Reply	396
Moreover, as we are not constructing any validation set from OoD data, they should not perform well in OoD detection, as they will likely run into the problem of assigning high likelihood to OoD data.	I-Reply	I-6	Reply	396
We believe that searching for architecture distributions is indeed one of the unique contributions of our NADS.	I-Reply	I-6	Reply	396
<sep> <sep> Q7:	O	O	Reply	396
We agree on this.	B-Reply	B-7	Reply	396
Our statement in the manuscript is that the NAS problem is intractable in general.	I-Reply	I-7	Reply	396
Various relaxations to the original problem can be done to make it more computationally feasible, such as the Gumbel-Softmax reparameterization we used, or using the method referred above.	I-Reply	I-7	Reply	396
We will revise our manuscript to make this statement clearer.	I-Reply	I-7	Reply	396
<sep> <sep> Q8:	O	O	Reply	396
Using our setup, we find that we are able to find good performing architectures in less than 1 GPU day.	B-Reply	B-8	Reply	396
We have modified our manuscript to include this detail.	I-Reply	I-8	Reply	396

The authors propose a neural architecture search (NAS) method to construct a Bayesian ensemble of deep learning models.	O	O	Review	396
This ensemble is then employed to detect out-of-distribution examples.	O	O	Review	396
<sep> <sep> <sep> The authors propose to use a differentiable architecture search method which model the architectural parameters using a concrete distribution.	B-Review	B-1	Review	396
This idea was originally proposed by Xie et al (2019) but this work was not discussed.	I-Review	I-1	Review	396
Similarly, the work by Chang et al (2019) is not discussed.	I-Review	I-1	Review	396
In my opinion the novelty with respect to NAS is the WAIC objective function and its application to out-of-distribution detection.	I-Review	I-1	Review	396
<sep> <sep> <sep> The idea of using ensemble to detect out-of-distribution examples is not new.	B-Review	B-2	Review	396
The authors already refer to the works by Choi &amp; Jang (2018) and Lakshminarayanan et al (2017).	I-Review	I-2	Review	396
I'd like to add MC-Dropout (Gal et al 2016) to this list which was used e.g. to detect adversarial examples.	I-Review	I-2	Review	396
<sep> <sep> <sep> The experimental section is well-written and the proposed method is able to outperform the chosen baselines.	B-Review	B-3	Review	396
Obvious baselines are missing.	I-Review	I-3	Review	396
There is no experiment that proof that this way of searching architectures finds better suited ensembles.	I-Review	I-3	Review	396
How about maximizing the cross-entropy and train the discovered architecture multiple times from scratch and use these models in an ensemble to detect out-of-distribution examples?	I-Review	I-3	Review	396
How about any ensemble-based method mentioned in the previous paragraph?	I-Review	I-3	Review	396
<sep> <sep> <sep> Concluding, the idea is nice but based on the current state of the paper it seems incremental.	B-Review	B-4	Review	396
Experiments to back the usefulness of the described method are missing.	I-Review	I-4	Review	396
<sep> <sep> <sep> Sirui Xie, Hehui Zheng, Chunxiao Liu, Liang Lin: SNAS: stochastic neural architecture search.	O	O	Review	396
ICLR 2019	O	O	Review	396
Jianlong Chang, Xinbang Zhang, Yiwen Guo, Gaofeng Meng, Shiming Xiang, Chunhong Pan: Differentiable Architecture Search with Ensemble Gumbel-Softmax.	O	O	Review	396
arXiv (2019)	O	O	Review	396
Yarin Gal, Zoubin Ghahramani: Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning.	O	O	Review	396
ICML 2016: 1050-1059	O	O	Review	396
We thank the reviewer for the critiques, but have to emphasize the differences regarding the novelty and contributions of our presented work.	B-Reply	B-1	Reply	396
We emphasize that the novelty of the presented work is the search for a distribution of architectures that are tailored to the tasks with Out-of-Distribution (OoD) testing examples.	I-Reply	I-1	Reply	396
We also note that previous ensemble methods are not competitive against current OoD classification models such as Outlier Exposure (OE).	I-Reply	I-1	Reply	396
To address concerns regarding the efficacy of our ensemble search method compared to using ensembles of a fixed model, we have included an additional ablation study (page 13, Table 2) comparing the two methods.	B-Reply	B-4	Reply	396
Below, we address your questions and comments in detail.	I-Reply	I-4	Reply	396
<sep> <sep> "This idea was originally proposed by Xie et al (2019) but this work was not discussed.	O	O	Reply	396
Similarly, the work by Chang et al (2019) is not discussed.":	O	O	Reply	396
<sep> <sep> We apologize that we did not discuss these two papers but we were not aware of these two previous works when we wrote the paper.	B-Reply	B-1	Reply	396
We have updated our manuscript to include these citations.	I-Reply	I-1	Reply	396
Although the relaxation method to the optimization problem is similar to ours in these papers, but they are still for maximum-likelihood-based neural architecture search.	I-Reply	I-1	Reply	396
As we tried to emphasize in the original paper and response here to all the reviewers, compared to these two papers, the task, objective function, family of models, and our consideration to derive a Bayesian ensemble is novel.	I-Reply	I-1	Reply	396
Specifically, to our knowledge, our formulation is the first work to apply NAS on likelihood estimation models, as well as on OoD detection.	I-Reply	I-1	Reply	396
Our formulation is not supervised, as also noted by the third reviewer, compared to other NAS methods which mainly consider supervised classification models.	I-Reply	I-1	Reply	396
Also, learning a distribution of architectures for generative models and using it for OoD detection has never been investigated before.	I-Reply	I-1	Reply	396
<sep> <sep> "The idea of using ensemble to detect out-of-distribution examples is not new.	O	O	Reply	396
The authors already refer to the works by Choi &amp; Jang (2018) and Lakshminarayanan et al (2017).	O	O	Reply	396
I'd like to add MC-Dropout (Gal et al 2016) to this list which was used e.g. to detect adversarial examples."	O	O	Reply	396
<sep> <sep> We have tried the referred methods and they didn't perform competitively.	B-Reply	B-2	Reply	396
For example, the likelihood score and WAIC score of MC-Dropout samples on OoD data were very similar to that of the training data.	I-Reply	I-2	Reply	396
Comparing the results of Choi &amp; Jang's (2018) work showed that their method is not competitive to ours on some testing configurations.	I-Reply	I-2	Reply	396
To our knowledge, Outlier Exposure (OE), to which our method is compared against, is currently the most competitive method for OoD detection.	I-Reply	I-2	Reply	396
<sep> <sep> "There is no experiment that proof that this way of searching architectures finds better suited ensembles."	O	O	Reply	396
<sep> <sep> We did not compare against other ensemble methods because, to our knowledge, Outlier Exposure is currently the most competitive method for OoD detection.	B-Reply	B-3	Reply	396
However, your concern is valid.	I-Reply	I-3	Reply	396
To address this, we have included an additional ablation study in the appendix (page 13, Table 2) to show the effect of learning a distribution over the architecture space to better capture model architecture uncertainty.	I-Reply	I-3	Reply	396
In this new experiment, we compared our proposed method against an ensemble of models with fixed architectures trained under different random initializations.	I-Reply	I-3	Reply	396
The experiment clearly shows the improved performance of our proposed method.	I-Reply	I-3	Reply	396

This paper needs crucial, quick fixes.	O	O	Review	396
<sep> <sep> This paper throws neural architecture search at the problem of out-of-distribution detection.	B-Review	B-1	Review	396
Rather than searching over multi-class classifier architectures, and using the result for OOD detection, they instead search for generative model architectures.	I-Review	I-1	Review	396
<sep> The approach appears to work on some of their cherry-picked OOD datasets.	I-Review	I-1	Review	396
<sep> <sep> I give this paper a 3 because they are quite possibly only showing their strongest results and not giving a complete picture, and there are numerous small errors throughout the paper.	O	O	Review	396
<sep> After a more thorough evaluation, the technique will likely not look strong on datasets such as CIFAR-10 vs CIFAR-100.	B-Review	B-7	Review	396
<sep> This is acceptable since they are comparing density estimators vs multi-class OOD detectors, the latter of which has been vastly superior for many years.	I-Review	I-7	Review	396
<sep> Their technique brings density estimators within striking distance of multi-class classifier perofrmance, but the paper must give a complete picture.	I-Review	I-7	Review	396
If these issues are fixed, the paper is easily a 6 or an 8, depending on the results of currently unshown OOD datasets.	I-Review	I-7	Review	396
It is acceptable if their technique gets and 55% AUROC for CIFAR-10 vs CIFAR-100 while multi-class classifiers with Outlier Exposure get 96%.	I-Review	I-7	Review	396
It is OK because this technique appears superior to other generative models, which have lagged far behind.	I-Review	I-7	Review	396
Currently the paper leaves the impression that this is not only leapfrogging past previous density estimators, but that it also is beating multi-class classifiers.	I-Review	I-7	Review	396
This likely isn't true.	I-Review	I-7	Review	396
We need to see performance on other OOD datasets.	I-Review	I-7	Review	396
<sep> I am willing to increase my score from a 6 to an 8 even if the results are negative.	I-Review	I-7	Review	396
<sep> <sep> The CIFAR-10 model should have to detect OOD samples from CIFAR-100, Rademacher/Bernoulli noise, and Gaussian noise.	I-Review	I-7	Review	396
In addition, they should train a model on CIFAR-100 since many OOD detection techniques exhibit much worse behavior on CIFAR-100, compared to CIFAR-10 or MNIST or SVHN.	I-Review	I-7	Review	396
<sep> <sep> In summary, I give this a 3 due to critical flaws, but if these are rectified, the paper will likely deserve a 6 or 8.	O	O	Review	396
<sep> <sep> Miscellaneous Points:	O	O	Review	396
<sep> Please include CIFAR-10/100 code.	B-Review	B-2	Review	396
Currently the code is for MNIST.	I-Review	I-2	Review	396
<sep> <sep> There are several errors in discussing related work.	O	O	Review	396
<sep> <sep> &gt; Moreover, previous work on deep uncertainty quantification shows that a single model may not suffice to quantify uncertainty and detect OoD samples (Lakshminarayanan et al 2017; Choi &amp; Jang, 2018)	B-Review	B-3	Review	396
<sep> Ensembles do not perform appreciably better at OOD detection under systematic OOD benchmarking when using multi-class classifiers.	I-Review	I-3	Review	396
For generative models, ensembles can help.	I-Review	I-3	Review	396
Ensembles mainly help multi-class classifier _calibration_ on in-distribution in-class data, but they have miniscule to nonexistent utility in classifier OOD detection.	I-Review	I-3	Review	396
Please add appropriate qualifiers.	I-Review	I-3	Review	396
<sep> <sep> &gt; "With no access to OoD data, unsupervised/self-supervised generative models which maximize the likelihood of in-distribution data become the primary tools for uncertainty quantification."	B-Review	B-4	Review	396
<sep> I think they mean "with access to labels."	I-Review	I-4	Review	396
Multi-class classifiers are the most performant tool for OOD detection, and unsupervised generative models are around chance-levels. _	I-Review	I-4	Review	396
Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty_ (NeurIPS) uses self-supervised learning for OOD detection and achieves good performance, but this work is not cited.	I-Review	I-4	Review	396
<sep> <sep> &gt; "However, these models counter-intuitively assign high likelihoods to OoD data (Nalisnick et al 2019a; Choi &amp; Jang, 2018)"	I-Review	I-4	Review	396
This was shown in previous work, such as Shafaei et al 2019 and Hendrycks et al 2019, and hence deserve mention.	I-Review	I-4	Review	396
<sep> <sep> &gt; "Moreover, existing methods to calibrate model uncertainty estimates assume access to OoD data during training (Lee et al 2018; Hendrycks et al 2019).	B-Review	B-5	Review	396
This is flawed when anomalous data is rare or not known ahead of time"	I-Review	I-5	Review	396
Lee et al does not assume access to OOD data during training; they synthesize their own.	I-Review	I-5	Review	396
Hendrycks et al does assume access to OOD data, but not OOD data seen during evaluation; in this way, they do not assume data is "known ahead of time," which they reiterate throughout their paper.	I-Review	I-5	Review	396
This sentence is painting with too broad a brush.	I-Review	I-5	Review	396
<sep> <sep> There is a smaller experimental problem.	B-Review	B-6	Review	396
They compare to ODIN, but ODIN assumes access to OOD data from the test distribution.	I-Review	I-6	Review	396
While this assumption is clearly questionable, their evaluation does not use the assumption they did, so their technique is not actually ODIN.	I-Review	I-6	Review	396
I suggest just comparing against the Maximum Softmax Probability Baseline in Table 1 since the rest of this paper assumes OOD examples are not known ahead of time.	I-Review	I-6	Review	396
<sep> <sep> Update: I have changed my score to an 8.	O	O	Review	396
Thank you so much for taking time to review our paper.	O	O	Reply	396
We do appreciate your recognition of the contributions of our NADS for OoD tasks with generative models.	O	O	Reply	396
<sep> <sep> We would like to guarantee the reviewer that we did not ‚Äúcherry-pick‚Äù the results to present.	B-Reply	B-1	Reply	396
We presented the results in the original submission due to the consideration that the trends would be similar across datasets and that their presentation would be redundant.	I-Reply	I-1	Reply	396
We have now included all the results together with the new experiments suggested by the reviewers.	I-Reply	I-1	Reply	396
<sep> <sep> Following your suggestions, we have added additional testing configurations for our CIFAR-10 model, testing on Gaussian and Rademacher distributions generated the same way as was done on the Outlier Exposure (OE) paper, as well as on the CIFAR-100 dataset (page 8, Table 1).	B-Reply	B-7	Reply	396
We have also trained a CIFAR-100 model and tested on configurations similar to their CIFAR-10 counterpart.	I-Reply	I-7	Reply	396
Our results still show the competitive performance of our method.	I-Reply	I-7	Reply	396
However, we agree that adding these additional testing configurations showed more failure cases of our proposed method.	I-Reply	I-7	Reply	396
<sep> <sep> ‚ÄúPlease include CIFAR-10/100 code.	O	O	Reply	396
Currently the code is for MNIST.‚Äù:	O	O	Reply	396
<sep> We have added this in the link.	B-Reply	B-2	Reply	396
The code is the same as the one for MNIST but applied to a different dataset.	I-Reply	I-2	Reply	396
<sep> <sep> "Moreover, previous work on deep uncertainty quantification shows that a single model may not suffice to quantify uncertainty and detect OoD samples":	O	O	Reply	396
<sep> We have modified our manuscript to make this statement more specifically refer to generative models.	B-Reply	B-3	Reply	396
<sep> <sep> "With no access to OoD data, unsupervised/self-supervised generative models which maximize the likelihood of in-distribution data become the primary tools for uncertainty quantification.":	O	O	Reply	396
<sep> <sep> You are correct, this is what we meant by our statement.	B-Reply	B-4	Reply	396
We have modified it in the revised manuscript to make this clearer.	I-Reply	I-4	Reply	396
<sep> <sep> ‚ÄúUsing Self-Supervised Learning Can Improve Model Robustness and Uncertainty_ (NeurIPS) uses self-supervised learning for OOD detection and achieves good performance, but this work is not cited.	O	O	Reply	396
‚Äù	O	O	Reply	396
"This was shown in previous work, such as Shafaei et al 2019 and Hendrycks et al 2019, and hence deserve mention.	O	O	Reply	396
<sep> ":	O	O	Reply	396
<sep> We have added the works above as additional citations in our manuscript.	B-Reply	B-4	Reply	396
<sep> <sep> "but not OOD data seen during evaluation; in this way, they do not assume data is "known ahead of time,"":	O	O	Reply	396
<sep> We feel that by assuming access to any OoD data, we are directly constraining the model's capacity from learning more unseen OoD data in future.	B-Reply	B-5	Reply	396
Such an assumption can be incorrect when dealing with active/online learning situations where new training distributions are regularly encountered.	I-Reply	I-5	Reply	396
However, we agree that the above statement slightly misrepresents current work on multi-class OoD classifiers.	I-Reply	I-5	Reply	396
We have modified our wording to make it more appropriate.	I-Reply	I-5	Reply	396
<sep> <sep> "There is a smaller experimental problem.	O	O	Reply	396
They compare to ODIN, but ODIN assumes access to OOD data from the test distribution.":	O	O	Reply	396
<sep> <sep> In our implementation of ODIN, we tuned with one OoD dataset 1000 samples.	B-Reply	B-6	Reply	396
This is in line with what the ODIN authors suggested, as they state that the hyperparameters are not very sensitive to specific OoD datasets.	I-Reply	I-6	Reply	396
We believe that this is an accurate implementation of ODIN.	I-Reply	I-6	Reply	396
However, following your suggestion, we have added the MSP method as a baseline and moved our ODIN results to the appendix (page 13, Table 3) due to space constraints.	I-Reply	I-6	Reply	396

[Overview]	O	O	Review	471
<sep> In this paper, the authors proposed a new format of representation called scene programs, to describe the visual scenes.	O	O	Review	471
To extract the scene programs from scenes, the authors exploited the off-the-shelf object detection and segmentations model, mask r-cnn to extract all objects and the corresponding attributes from the images, and then detect groups for those objects, which are then used to generate the programs which matches the input scenes.	O	O	Review	471
The experiments are performed on a synthetics datasets which consists of multiple shapes with different attributes.	O	O	Review	471
The experiments shows that the proposed model can infer more accurate programs from the scenes, and those generated programs can be used to recover the input scenes more accurately.	O	O	Review	471
Besides, the authors also showed that the generated scene programs can be used for image editing and making visual analogy.	O	O	Review	471
<sep> <sep> [Strengthes]	O	O	Review	471
<sep> 1.	O	O	Review	471
The authors proposed a new representation, called scene programs, to describe the visual scenes with some textual program.	O	O	Review	471
This is a new scene representation, which could be potentially used in various scenarios, such as the image synthesis in graphics.	O	O	Review	471
<sep> <sep> 2.	O	O	Review	471
The authors proposed a hierarchical method to model the structures in scenes.	O	O	Review	471
Specifically, the objects in a scene are first extracted and then grouped into multiple clusters, which will be used to guide the scene program synthesis.	O	O	Review	471
<sep> <sep> 3.	O	O	Review	471
The experimental results demonstrate the effectiveness of the proposed method both qualitatively and quantitatively.	O	O	Review	471
The authors also showed the the programs generated  can be sued for image editing and cross-modality matching.	O	O	Review	471
<sep> <sep> [Weaknesses]	O	O	Review	471
<sep> 1.	B-Review	B-1	Review	471
It is a bit unfair to compare the proposed method with the two baseline methods listed in Table 2.	I-Review	I-1	Review	471
The authors used a pre-trained mask-rcnn to detect all objects and predict the attributes for all objects.	I-Review	I-1	Review	471
However, the counterpart methods have no access to this supervision.	I-Review	I-1	Review	471
Even in this case, CNN-LSTM seems achieve comparable performance on the first three metrics.	I-Review	I-1	Review	471
<sep> <sep> 2.	O	O	Review	471
The advantage of scene program compared with scene graph (Johnson et al) are not clear to me.	B-Review	B-2	Review	471
Scene graph is also a symbolic representation for images.	I-Review	I-2	Review	471
Also, for all the tasks mentioned in this paper, such as image editing and visual analogy, scene graph can probably also complete well.	I-Review	I-2	Review	471
The authors should comment about the specific advantages of scene program in comparison with scene graph.	I-Review	I-2	Review	471
<sep> <sep> 3.	O	O	Review	471
All the images shown in the paper seems arranged uniformly, which I think contains some bias to the proposed grouping strategy.	B-Review	B-4	Review	471
I would like to see more diverse configurations of the foreground objects.	I-Review	I-4	Review	471
It would be good to see if the proposed model can describe more complicated scenes.	I-Review	I-4	Review	471
<sep> <sep> [Summary]	O	O	Review	471
<sep> This paper proposed a novel scene representations, called scene program.	O	O	Review	471
To extract the scene program, the authors proposed a hieratchical inference method.	O	O	Review	471
The resulting scene programs based on the proposed model outperforms several baseline models quantitatively.	O	O	Review	471
The authors also showed the proposed scene program is suitable for image editing and visual analogy making.	B-Review	B-5	Review	471
However, as pointed above, there are some unclear points to me, especially the advantages of scene program compared with scene graph, and the representation power of scene program for complicated scenes.	I-Review	I-5	Review	471
Thank you for your thoughtful review.	O	O	Reply	471
<sep> <sep> 1.	O	O	Reply	471
Comparing with baseline methods	O	O	Reply	471
<sep> We agree on the importance of a fair comparison.	O	O	Reply	471
We‚Äôd like to clarify that	O	O	Reply	471
1) The derender-LSTM baseline requires the same supervision as ours.	B-Reply	B-1	Reply	471
<sep> 2) We acknowledge the fact that our method requires more supervision than the CNN-LSTM baseline method, and will revise the paper to clearly state that.	B-Reply	B-1	Reply	471
Note the situation is different when we consider generalization to data where program supervision is hard to obtain (e.g. real images).	I-Reply	I-1	Reply	471
Because our program synthesizer works on abstract object attribute space, it does not require any fine-tuning to work on real images, where the end-to-end CNN-LSTM approach would require (image, program) pairs.	I-Reply	I-1	Reply	471
Disentangling vision recognition and program synthesis is a key to our model‚Äôs success on real images (Fig.7).	I-Reply	I-1	Reply	471
<sep> <sep> Our method achieves higher test accuracy and better generalization performance than both baseline, and more importantly, it generalizes better to real images.	I-Reply	I-1	Reply	471
As synthetic data can be easily obtained, we believe that the comparison in Table 2 is fairly established.	I-Reply	I-1	Reply	471
These results and the experiments on real images demonstrate the significant advantage of our method.	I-Reply	I-1	Reply	471
<sep> <sep> 2.	O	O	Reply	471
Scene graphs	O	O	Reply	471
<sep> We thank the reviewer for bringing up scene graphs, which is another important high-level representation of scenes.	B-Reply	B-2	Reply	471
Here we would like to emphasize that the roles of scene graphs and the proposed scene programs are complementary: scene graphs focus on the pairwise relationships, e.g. an object can be on, in, or under another object; in contrast, scene programs focus on the higher-order, program-like regularity among multiple objects (e.g., repetition).	I-Reply	I-2	Reply	471
<sep> <sep> Compared with scene graphs, scene programs (i) explicitly capture these regularities, modeling correlations among multiple objects; and (ii) are more efficient in terms of description length.	I-Reply	I-2	Reply	471
For tasks such as editing structured images, scene programs are a more suitable representation, because editing can be performed on the program space for higher efficiency, as displayed in Fig.6.	I-Reply	I-2	Reply	471
With scene graphs, we would have to edit each object one by one.	I-Reply	I-2	Reply	471
<sep> <sep> 3.	O	O	Reply	471
Scene complexity	O	O	Reply	471
<sep> In our main experiment, we place objects on a grid and then jitter their positions and orientations.	B-Reply	B-3	Reply	471
Results on these data suggest that scene programs describe these structured images well.	I-Reply	I-3	Reply	471
We agree with reviewers on the importance of handling more complex data.	I-Reply	I-3	Reply	471
In the revision by Nov. 26, we will add results on scenes where objects are placed at random.	I-Reply	I-3	Reply	471
<sep> <sep> Please don‚Äôt hesitate to let us know for any additional comments on the paper or on the planned changes.	I-Reply	I-3	Reply	471

This paper investigates a descriptive representation of scenes using programs.	O	O	Review	471
Given an input image and an initial set of detections obtained from bottom-up detectors a sequence to sequence network is used to generate programs in a domain specific language (DSL).	O	O	Review	471
The authors consider a dataset where simple primitives are arranged in layouts in 3D scenes with varying material and color properties.	O	O	Review	471
They argue that the scene representation lead to better generalization on novel scene types and improve over baselines on image analogy tasks.	O	O	Review	471
The paper is well written but the evaluation and technical novelty is weak.	O	O	Review	471
<sep> <sep> First, the use of scene programs is not a contribution of this paper.	B-Review	B-1	Review	471
Going beyond the works cited in the related work section, several recent works have proposed and investigated the advantages of program synthesis for shape generation (e.g., CSGNet Sharma et al CVPR 2018 and Scene derendering, Wu et al CVPR 2017), visual reasoning (Modular networks, Andreas et al 2015), among others.	I-Review	I-1	Review	471
<sep> <sep> At a high-level the motivation of the program level representation for the considered tasks is not highlighted.	B-Review	B-2	Review	471
It seems that an attribute-based representation, i.e., the output of the mask R-CNN detector that describes the image as a collection of objects, material properties, and their positions and scales is a sufficient representation.	I-Review	I-2	Review	471
The higher-order relationships can be relatively easily extracted from the detections since the images are clean and clutter free.	I-Review	I-2	Review	471
A baseline approach where the program synthesis was performed using search and grouping should be compared with.	I-Review	I-2	Review	471
<sep> <sep> The considered tasks are relatively simple achieving 99.5% token-level accuracy.	B-Review	B-3	Review	471
The evaluation beyond the synthetic datasets is fairly limited and it is unclear how well the method generalizes to novel images in clutter and occlusion.	I-Review	I-3	Review	471
<sep> <sep> In summary, the paper makes a number of observations that have been motivated in a number of prior works, but the contributions of this paper is not highlighted (e.g., over neural scene derendering).	O	O	Review	471
The main claim that higher-order relationships are being modeled is not apparent due to the simplicity of the scenes being considered.	B-Review	B-4	Review	471
For example, the program blocks being considered are somewhat arbitrary and a comparison with a clustering based grouping approach should have been evaluated.	I-Review	I-4	Review	471
The experimental evaluation is weak in several aspects.	I-Review	I-4	Review	471
The generalization to real images is anecdotal with only two examples shown in the Figure 7.	I-Review	I-4	Review	471
Thank you for your thoughtful review.	O	O	Reply	471
<sep> <sep> 1.	O	O	Reply	471
Scene program as a contribution	O	O	Reply	471
<sep> Thanks for suggesting the related work, which we‚Äôll cite and discuss.	B-Reply	B-1	Reply	471
Our paper is new and different from all these papers.	I-Reply	I-1	Reply	471
Most importantly, our scene programs focus on modeling the high-level structural relationships among multiple objects, building upon and extending CSGNet and De-rendering, which only explored sequential, primitive-level programs.	I-Reply	I-1	Reply	471
Only with our scene programs and the loop structure, may we efficiently describe patterns that involve higher-order, program-like regularity among multiple objects (e.g., repetition) and edit images with minimal interactions (Fig.6,7).	I-Reply	I-1	Reply	471
<sep> <sep> 2.	O	O	Reply	471
High-level motivations	O	O	Reply	471
<sep> As mentioned above, many tasks become possible only with our program representations, not an attribute-based representation.	B-Reply	B-2	Reply	471
For example, for the image in Fig.6(a), it is natural for one to imagine how could we add another row of cylinders on the right side, or change cylinders to cubes.	I-Reply	I-2	Reply	471
Scene programs allow us to perform such tasks in an efficient and intuitive way.	I-Reply	I-2	Reply	471
However, if we represent the scene by its objects and attributes, we would have to individually edit each object, losing the benefit from their high-level correlations.	I-Reply	I-2	Reply	471
<sep> <sep> We agree that it‚Äôs important to discuss the alternative approach, where the program synthesis is performed using search and grouping.	I-Reply	I-2	Reply	471
There are two possible approaches for a structured search over the space of programs, both of which would be too slow for our task:	I-Reply	I-2	Reply	471
- Constraint solving: we would have to use an SMT solver.	I-Reply	I-2	Reply	471
Ellis et al [1] used SMT solvers to infer 2D graphics programs, and takes on the order of minutes per program.	I-Reply	I-2	Reply	471
As 3D scenes (with attributes) have a much larger search space, such an approach would not be able to find a solution in reasonable time.	I-Reply	I-2	Reply	471
<sep> - Stochastic search: Here the problem would be at least as tough as doing inverse graphics, so we can safely assume that this would work no better than MCMC for inverse graphics.	I-Reply	I-2	Reply	471
In Picture (Kulkarni et al [2]), their approach takes minutes for a 2D image with simple contours.	I-Reply	I-2	Reply	471
<sep> <sep> We have contacted the authors of these two papers, who confirmed our estimates of the efficiency of their methods.	O	O	Reply	471
In comparison, on average our neural program synthesis model takes less than 0.4 second to generate scene programs for an image.	O	O	Reply	471
<sep> <sep> [1] Ellis, Kevin, Armando Solar-Lezama, and Josh Tenenbaum. "	O	O	Reply	471
Unsupervised learning by program synthesis."	O	O	Reply	471
NIPS 2015.	O	O	Reply	471
<sep> [2] Kulkarni, Tejas D., et al "Picture: A probabilistic programming language for scene perception."	O	O	Reply	471
CVPR 2015.	O	O	Reply	471
<sep> <sep> 3.	O	O	Reply	471
Experimental evaluation	O	O	Reply	471
<sep> In our main experiment, we place objects on a grid and then jitter their positions and orientations.	B-Reply	B-3	Reply	471
Results on these data suggest that scene programs describe these structured images well.	I-Reply	I-3	Reply	471
We agree with reviewers on the importance of handling more complex data.	I-Reply	I-3	Reply	471
In the revision by Nov. 26, we will add results on scenes where objects are placed at random.	I-Reply	I-3	Reply	471
<sep> <sep> Following your suggestion, we have also experimented with a simple heuristic grouping algorithm: we start with a random object which forms a group.	I-Reply	I-3	Reply	471
As long as there are objects of distance less than a threshold from this group, we add them into the group.	I-Reply	I-3	Reply	471
It performs well in general, but cannot resolve difficult instances, such as when a group is surrounded by other objects.	I-Reply	I-3	Reply	471
This justifies the need to use a deep model to learn from the data distribution.	I-Reply	I-3	Reply	471
We‚Äôll include the results in the revision.	I-Reply	I-3	Reply	471
<sep> <sep> To summarize, our main contribution is to propose scene programs as a novel representation of scenes, modeling high-level relations beyond individual objects and pairwise relations.	B-Reply	B-1	Reply	471
The scene program representation demonstrates strong advantages in tasks such as image editing and analogy making, compared with attribute-based representations.	I-Reply	I-1	Reply	471
We also propose effective methods to generate accurate program descriptions from input images, which can be applied to real images without additional program supervision.	I-Reply	I-1	Reply	471
While tackling in-the-wild scenes is an important future direction, we consider our efforts an important step towards high-level scene understanding via program synthesis.	I-Reply	I-1	Reply	471
<sep> <sep> Please don‚Äôt hesitate to let us know for any additional comments on the paper or on the planned changes.	O	O	Reply	471

This paper presents a system that infers programs describing 3D scenes composed of simple primitives.	O	O	Review	471
The system consists of three stages each of which is trained separately.	O	O	Review	471
First, the perceptual module extracts object masks and their attributes.	O	O	Review	471
The objects are then are split into several groups.	O	O	Review	471
Finally, each group is mapped to a corresponding DSL program using a sequence-to-sequence network similar to the ones typically employed in neural machine translation.	O	O	Review	471
<sep> <sep> Pros:	O	O	Review	471
+ The paper is written clearly and easy to read.	O	O	Review	471
<sep> + Visual program synthesis is very exciting and important direction both for image understanding and generation.	O	O	Review	471
<sep> + The results on synthetic datasets are good.	O	O	Review	471
The authors also demonstrate the applicability of the approach to real-world data (albeit significantly constrained).	O	O	Review	471
<sep> + I find it surprising that a seq2seq is good at producing an accurate program for a group of objects.	O	O	Review	471
<sep> + Visual analogy making experiments are impressive.	O	O	Review	471
<sep> <sep> Cons:	O	O	Review	471
- The proposed model requires rich annotation of training data since all the components of the systems are trained in a supervised fashion.	B-Review	B-1	Review	471
It‚Äôs not clear how to use the method on the in-the-wild data without such annotation.	I-Review	I-1	Review	471
<sep> - Related to the previous point, even when it‚Äôs possible to synthesize data, it is non-trivial to obtain the ground-truth grouping of objects.	B-Review	B-2	Review	471
Judging by Table 2, it seems that the system breaks in absence of the grouping information.	I-Review	I-2	Review	471
<sep> - The data used in the paper is quite simplistic (limited number of primitives located in a regular grid).	B-Review	B-3	Review	471
I‚Äôm wondering if there is a natural way to extend the approach to more complex settings.	I-Review	I-3	Review	471
My guess is that the performance will drop significantly.	I-Review	I-3	Review	471
<sep> <sep> Notes/questions:	O	O	Review	471
* Section 2, paragraph 1: The paper by [Ganin et al 2018] presents both a system for reproducing an image as well as for sampling from a distribution; moreover, it presents experiments on 3D data (i.e., not limited to drawing).	B-Review	B-4	Review	471
<sep> * Section 3.4, paragraph 2: I‚Äôm not sure I understand the last sentence.	B-Review	B-5	Review	471
How can we know that we successfully recovered the scene at test time?	I-Review	I-5	Review	471
Could the authors elaborate on the stopping criterion for sampling?	I-Review	I-5	Review	471
<sep> * Section 4.2, paragraph 2: Do I understand correctly that the main difference between the test set and the generalization set is the number of groups? (	B-Review	B-6	Review	471
i.e., 2 vs 3).	I-Review	I-6	Review	471
If so, it‚Äôs a fairly limited demonstration of generalization capabilities of the system.	I-Review	I-6	Review	471
<sep> * Section 4.2, paragraph 4: ‚Äúwe search top 3 proposals ...‚Äù ‚Äì How do we decide which one is better?	B-Review	B-7	Review	471
Do we somehow have an access to the ground truth program at test time?	I-Review	I-7	Review	471
<sep> * Could the authors explain the representation of a program more clearly?	B-Review	B-8	Review	471
How are loops handled?	I-Review	I-8	Review	471
How can one subtract/add programs in the analogy making experiment?	I-Review	I-8	Review	471
<sep> <sep> Overall, I think it is a interesting paper and can be potentially accepted on the condition that the authors address my questions and concerns.	O	O	Review	471
Thank you for your thoughtful review.	O	O	Reply	471
<sep> <sep> 1.	O	O	Reply	471
Data annotations	O	O	Reply	471
<sep> Our model requires supervised training data in the pre-training stage for each of its components, but the program synthesizer needs no further training when generalizing to other data distributions since it works on object attribute space.	B-Reply	B-1	Reply	471
We consider this as an advantage of our model, as it is easy to get synthetic data, but much harder to obtain annotations (in particular program annotations) on in-the-wild images.	I-Reply	I-1	Reply	471
Disentangling vision recognition and program synthesis is a key to our model‚Äôs success on real images (Fig.7): our model accurately predicts programs for the test set with only 90 labeled real images for fine-tuning.	I-Reply	I-1	Reply	471
<sep> <sep> The group information is inherently included in the program and easy to obtain: when synthesizing data, we first sample several program blocks from our DSL, where each block corresponds to a set of objects that form a group.	I-Reply	I-1	Reply	471
These program blocks are then combined into the overall program description of the scene.	I-Reply	I-1	Reply	471
Our model explicitly learns the group information and shows advantages over baseline methods which learn directly from the overall program.	I-Reply	I-1	Reply	471
<sep> <sep> 2.	O	O	Reply	471
Scene complexity	O	O	Reply	471
<sep> In our main experiment, we place objects on a grid and then jitter their positions and orientations.	B-Reply	B-3	Reply	471
Results on these data suggest that scene programs describe these structured images well.	I-Reply	I-3	Reply	471
We agree with reviewers on the importance of handling more complex data.	I-Reply	I-3	Reply	471
In the revision by Nov. 26, we will add results on scenes where objects are placed at random.	I-Reply	I-3	Reply	471
<sep> <sep> 3.	O	O	Reply	471
Specific questions	O	O	Reply	471
<sep> 1) Ganin et al: We will revise the description of this work in the updated draft.	B-Reply	B-4	Reply	471
<sep> <sep> 2) The stopping criterion is whether the scene has been successfully reconstructed, i.e., when the execution results of the program are the same as the object parsing results obtained from the vision module.	B-Reply	B-5	Reply	471
<sep> <sep> 3) Generalization: Yes, the main difference is the number of groups.	B-Reply	B-6	Reply	471
This is only one of our experiments on generalization.	I-Reply	I-6	Reply	471
The experiments on real image show our model‚Äôs ability to generalize to new data distributions.	I-Reply	I-6	Reply	471
<sep> <sep> 4) Top proposals: Note that the group detector also outputs the classification result of the group category.	B-Reply	B-7	Reply	471
Here ‚Äútop‚Äù refers to the softmax score.	I-Reply	I-7	Reply	471
We don‚Äôt have any information of the ground truth program at test time.	I-Reply	I-7	Reply	471
<sep> <sep> 5) Program representations: We will give detailed definitions in the Appendix.	B-Reply	B-8	Reply	471
In short, a program is represented as a matrix, where each row contains a program command, which is a program token followed by its parameters.	I-Reply	I-8	Reply	471
<sep> <sep> Thanks!	O	O	Reply	471
Please don‚Äôt hesitate to let us know for any additional comments on the paper or on the planned changes.	O	O	Reply	471

Overview	O	O	Review	471
This paper proposes a type of regularization for recurrent networks, with the goal of encouraging particular dynamical structures (in this case, line attractors) in the dynamics of the networks.	O	O	Review	471
The proposed regularization penalty is only applied to a subset of the recurrent units; the motivation for this is to allow neurons not contained in the subset to learn different structures.	O	O	Review	471
The paper applies this regularization method on three example machine learning sequence tasks: an addition task, a multiplication task, and sequential MNIST classification, as well as on learning a 2-D dynamical system model of a bursting neuron with two different timescales.	O	O	Review	471
<sep> <sep> Major comments	O	O	Review	471
I have a number of serious concerns about the paper's motivation, logic, and experiments:	O	O	Review	471
<sep> - First, the paper motivates the proposed regularization as a way to encourage the network to have line attractor dynamics.	B-Review	B-1	Review	471
In particular, the paper dismisses gated architectures as not being interpretable, stating that LSTMs and GRUs "are complicated and tedious to analyze from a DS perspective." (	I-Review	I-1	Review	471
pg 2).	I-Review	I-1	Review	471
However, there is recent work both theoretical (<a href="https://arxiv.org/abs/1906.01005)" target="_blank" rel="nofollow">https://arxiv.org/abs/1906.01005)</a> and empirical (<a href="https://arxiv.org/abs/1907.08549)" target="_blank" rel="nofollow">https://arxiv.org/abs/1907.08549)</a> that analyzes these gated architectures from a DS perspective.	I-Review	I-1	Review	471
In particular, these papers demonstrate that LSTMs and GRUs are perfectly capable of learning line attractors.	I-Review	I-1	Review	471
Given that it is possible to analyze gated architectures as dynamical systems, the overall motivation of the paper is much weaker.	I-Review	I-1	Review	471
<sep> <sep> - The paper proposes a squared penalty on subsets of the weights in the recurrent network as a way to encourage line attractor dynamics.	B-Review	B-2	Review	471
However, it is not clear to me that this is sufficient.	I-Review	I-2	Review	471
In particular, unless the subset of the network that implements the line/plane attractor is completely disconnected from the rest of the network, then the overall dynamics may not contain a line attractor (the units will interact with the unregularized units).	I-Review	I-2	Review	471
Also, the proposed regularization penalty only penalizes the diagonal elements of the A matrix to be close to 1--but shouldn't the off diagonal elements also be penalized to be close to zero?	I-Review	I-2	Review	471
<sep> <sep> - Moreover, the paper makes no mention of the Jacobian of these recurrent networks.	B-Review	B-3	Review	471
The eigenvalues of the Jacobian of the recurrent networks determine the behavior of the linearized system around fixed points--specifically, eigenvalues with real part close to 1 will exhibit slow dynamics (approximate line attractors along those dimensions).	I-Review	I-3	Review	471
It seems to me that a much more natural way of encouraging line attractor dynamics is to place a regularization penalty on the Jacobian itself (which is analytically tricky, but numerically more plausible with modern autodifferentiation software).	I-Review	I-3	Review	471
Regardless, the authors should compare the eigenvalues of the recurrent networks' Jacobian when using their regularization method vs without it.	I-Review	I-3	Review	471
Does the proposed regularization encourage the Jacobian of the resulting networks to have eigenvalues close to 1?	I-Review	I-3	Review	471
<sep> <sep> - The paper compares the proposed method with a number of vanilla RNNs with different initializations, and an LSTM.	B-Review	B-4	Review	471
However, a critical missing baseline is simply an RNN with l2 regularization on the weights (standard regularization in the literature).	I-Review	I-4	Review	471
This baseline is important to determine if the proposed regularization simply helps because it is an l2 penalty on the weights (note that none of the other baselines have regularization).	I-Review	I-4	Review	471
<sep> <sep> - The paper motivates the method as trying to study line attractor dynamics, but then does not apply them to tasks where line attractors are required.	B-Review	B-5	Review	471
For example, the addition and multiplication tasks require discrete memories, not line attractors.	I-Review	I-5	Review	471
The bursting neuron approximation (2D dynamical system) also does not involve a line attractor.	I-Review	I-5	Review	471
However, there definitely exist tasks both in neuroscience (e.g. sensory integration in decision making, path integration in navigation, etc.)	I-Review	I-5	Review	471
and in machine learning (c.f.	I-Review	I-5	Review	471
<a href="https://arxiv.org/abs/1906.10720)" target="_blank" rel="nofollow">https://arxiv.org/abs/1906.10720)</a> that use or require line attractors.	I-Review	I-5	Review	471
The motivation of the paper would be much better tested on these tasks.	I-Review	I-5	Review	471
<sep> <sep> Minor comments	O	O	Review	471
- The authors comment at the beginning of page 4 that by setting A=I, W=0, and h=0, the network contains a line attractor, but the more precise language would be to state that the network contains an N-dimensional plane attractor, where N is the number of units.	B-Review	B-6	Review	471
Typically, 'line attractor' refers to a 1-dimensional manifold of fixed points along which the system can integrate inputs, but perturbations off of the line attractor are not remembered (decay back to the line attractor).	I-Review	I-6	Review	471
- Of course it is possible to analyze GRU and LSTM networks from a dynamical systems (DS) perspective, and of course they could be trained to exhibit line attractors, limit cycles, chaos, and all of that ‚Äì no surprise, since after all, formally speaking, they are powerful discrete-time nonlinear DS themselves!	B-Reply	B-1	Reply	471
<sep> Our point, however, is that they are much more tedious to analyze and understand than the PLRNN architecture we are propagating, for reasons we had given in the 3rd pg.of sect.	I-Reply	I-1	Reply	471
3.1: For the PLRNN we can track fixed points, limit cycles, and their stability *analytically*, and we can rather easily translate them into equivalent continuous time systems which brings additional advantages for analysis (see Suppl.	I-Reply	I-1	Reply	471
6.1.2); none of this is easily possible for LSTM or GRU!	I-Reply	I-1	Reply	471
<sep> We are also not the first to point out the complexities of LSTM/GRU as a caveat to their training and analysis: In fact, to a large degree this motivated also the development of identity-initialized (e.g. Le, Jaitly, Hinton 2015) and orthogonal/ unitary RNN (e.g. Arjovsky, Shah, Bengio 2016) for solving long-dependency problems!	I-Reply	I-1	Reply	471
<sep> <sep> - 'A' is a diagonal matrix (see below eq.1), so off-diagonal elements *are* zero.	B-Reply	B-2	Reply	471
The ‚Äòtrue‚Äô off-diagonal elements are in W, and these are indeed regularized toward zero (see eq.4).	I-Reply	I-2	Reply	471
Hence, the configuration is indeed driven toward forming a line attractor subspace (see also Suppl.	I-Reply	I-2	Reply	471
Fig.S4).	I-Reply	I-2	Reply	471
<sep> Besides, we show in our numerical experiments (Figs.	I-Reply	I-2	Reply	471
2 &amp; 3) that the method *does work* and that its success is dependent on the regularization!	I-Reply	I-2	Reply	471
<sep> As another note on the side, even if there would be a *perfect* line attractor subspace, it would still integrate external inputs (see eq.1) and form an internal memory of them, and this memory could still be read out by the other units which receive inputs from this subspace!	I-Reply	I-2	Reply	471
<sep> <sep> - First, please note that a line attractor is a continuous set of neutrally stable fixed points, not just a single fixed point (and hence not just a single Jacobian to be evaluated).	B-Reply	B-3	Reply	471
More importantly, because our model is piecewise linear, all Jacobians in our case are strictly given by the matrices ‚ÄòA+W*D‚Äô as defined in Suppl.	I-Reply	I-3	Reply	471
sect.	I-Reply	I-3	Reply	471
6.1.2 &amp; 6.1.3.	I-Reply	I-3	Reply	471
Hence, our regularization is essentially a regularization of the Jacobians.	I-Reply	I-3	Reply	471
If the regularization objective would be exactly met (as it will be for tau --&gt; inf), there would be at least one eigenvalue exactly equal to 1.	I-Reply	I-3	Reply	471
Please see also Suppl.	I-Reply	I-3	Reply	471
Fig.S4.	I-Reply	I-3	Reply	471
<sep> Also note that we have been careful to talk only about ‚Äòline attractor dimensions‚Äô ‚Äì the overall dynamics *should not* be a line attractor, as this would rule out phenomena like chaos or limit cycles.	I-Reply	I-3	Reply	471
<sep> <sep> - Except for vanilla RNN, we have included into our comparison only other methods that have been explicitly devised to exhibit long short-term memory properties, and hence these are the crucial comparisons in our minds.	B-Reply	B-4	Reply	471
A simple L2 penalty on the weights would not convey any such mechanism, but of course it‚Äôs easy to do and we are happy to add it to the revised manuscript.	I-Reply	I-4	Reply	471
<sep> <sep> - This last statement may reveal a fundamental misunderstanding about the aims of our work: The motivation of our method is *not* the study of line attractors (or systems based on them), we merely use line attractors as an effective mechanism for storing continuously valued variables in memory!!	B-Reply	B-5	Reply	471
Figs.	I-Reply	I-5	Reply	471
2 &amp; 3 moreover clearly demonstrate that it works ‚Äì with this mechanism in place, we can actually outperform LSTMs on the addition and multiplication tasks; with this mechanism removed, performance breaks down!	I-Reply	I-5	Reply	471
<sep> That we can successfully train our RNN even on challenging systems like the bursting neuron (3D, see 6.1.5), which the RNN then freely (!)	I-Reply	I-5	Reply	471
reproduces when simulated, we think is actually a major feat (not a flaw), and something we have not quite seen elsewhere in the literature so far.	I-Reply	I-5	Reply	471
<sep> Besides, recent proposals (see ref.	I-Reply	I-5	Reply	471
above) for battling the vanishing/exploding gradient problem like orthogonal/unitary RNN or initialization-based approaches effectively use line attractors as well for their long-term memory (even LSTM and GRU essentially employ line attractors for their memory cells, at least that is what it comes down to in dynamical systems terms; i.e., linear recursive operations which map the values onto themselves).	I-Reply	I-5	Reply	471
Our approach is clearly more along the lines of the recent orthogonal and identity-initialized RNNs that attempt to avoid the complexities of LSTM/GRU networks.	I-Reply	I-5	Reply	471
However, orthogonal RNNs *cannot* produce many dynamical systems phenomena (like chaos; see e.g. Kerg et al 2019), and this is what motivates our specific approach which is expressive enough to reproduce chaotic phenomena, multi-stability etc.	I-Reply	I-5	Reply	471
<sep> We will attempt to make this clearer in the revision.	I-Reply	I-5	Reply	471
<sep> <sep> Minor: For N&gt;2 it is also not a plane anymore, that is why we used the term ‚Äòline attractor dimensions‚Äô initially, although, admittedly, we sometimes referred to this simply as ‚Äòline attractors‚Äô for short later in the text.	B-Reply	B-6	Reply	471
We are happy to change this in the revision.	I-Reply	I-6	Reply	471

The paper proposes a regularization scheme to improve the ability of RNNs in capturing long-range dependency in the latent space.	O	O	Review	471
The proposed model then uses EM for inference and achieves superior performance in sequence modeling tasks over LSTMs and iRNNs.	O	O	Review	471
<sep> <sep> + The motivation of the line attractor is novel and effective.	O	O	Review	471
The special RNN model studied in the paper has strong connections with neuro-dynamics models.	O	O	Review	471
<sep> + The paper is well motivated and clearly written.	O	O	Review	471
The illustration about the line attractor is particularly interesting.	O	O	Review	471
<sep> + Good experimental performance on multiple sequence modeling tasks including addition, multiplication and sequence MNIST.	O	O	Review	471
<sep> <sep> - The paper is building a generative model for sequences.	B-Review	B-1	Review	471
It‚Äôs not clear to me why VAE or variational RNN type of approaches cannot be used in this setting.	I-Review	I-1	Review	471
One might think of replacing the Gaussian prior with more complex distributions.	I-Review	I-1	Review	471
The inference procedure can also be significantly simplified with variational inference.	I-Review	I-1	Review	471
<sep> - The step-wise annealing together with EM inference is not scalable, which prohibits the model from applying to large-scale sequence modeling tasks.	B-Review	B-2	Review	471
<sep> <sep> Minor comments	O	O	Review	471
- " All code used in this work is freely available on the github site ... . "	B-Review	B-3	Review	471
Remove this sentence	I-Review	I-3	Review	471
<sep> At least one referee seems to somewhat like our approach, thank you!	O	O	Reply	471
<sep> <sep> Re the ‚Äò-‚Äò points:	O	O	Reply	471
<sep> - Absolutely, VAE/var.	B-Reply	B-1	Reply	471
RNN could be used as well, and in fact we have already implemented &amp; tested this in our group.	I-Reply	I-1	Reply	471
However, at this point EM produces much better results regarding reconstruction of the underlying dynamical system, possibly because in our algorithm &amp; model we can compute expectations over latent states, as well as parameters given these expectations (M-step), exactly &amp; analytically, and rely on efficient fixed-point iterations for maximizing the ELBO in the E-step (see sect.	I-Reply	I-1	Reply	471
6.1.3).	I-Reply	I-1	Reply	471
Hence our algorithm is sort of optimized for this problem of reconstructing nonlinear dynamical systems, exploiting the piecewise linear formulation (PLRNN), and therefore is to be preferred for smaller-scale problems as often encountered in physics or neuroscience.	I-Reply	I-1	Reply	471
In fact, we observed that it gets away with much less data than what we would need for our VAE implementation!	I-Reply	I-1	Reply	471
<sep> <sep> - Yes, this is the downside of our algorithm (and also what ultimately motivated us to re-implement the whole approach in a VAE framework).	B-Reply	B-2	Reply	471
We point out, however, that our algorithm is still linear in T (the length of the time series) since we can effectively exploit the block-tridiagonal structure of the Hessian for inversion (see also Paninski et al 2010, J of Comput.	I-Reply	I-2	Reply	471
Neurosci.).	I-Reply	I-2	Reply	471
So for smaller-size problems as in physics or neuroscience experiments, we clearly recommend using EM for the reasons mentioned above (the more exact approach requiring less data), but for larger-scale problems one probably would need to switch to a variational framework.	I-Reply	I-2	Reply	471
<sep> <sep> We are happy to include this discussion of up- &amp; downsides of the different approaches in the revision.	I-Reply	I-2	Reply	471

This paper presents a regulariser that encourages the formation of line attractors in RNNs.	O	O	Review	471
This regulariser works on a neuroscience-motivated formulation of RNN, bringing the Jacobian of the dynamic system close to identity.	O	O	Review	471
This paper is well-written, with a good coverage of background material from machine learning to computational neuroscience.	B-Review	B-1	Review	471
While the alleviating the exploding and vanishing gradient problem for simple RNNs is an interesting direction, I think the empirical results are not sufficient to support claims in the paper.	I-Review	I-1	Review	471
<sep> <sep> The paper starts by criticising initialisation and reparametrisation-based techniques.	B-Review	B-2	Review	471
However, I am not convinced why such methods limit the expressive power of RNNs.	I-Review	I-2	Review	471
In fact, one may argue that initialisation is a milder constraint compared with an explicit regulariser, since regularisation affects the entire learning process.	I-Review	I-2	Review	471
It seems that such initialisation requires less tuning (i.e., just identity) compared with the regulariser weights (a rather wide range of choices).	I-Review	I-2	Review	471
Either a theoretical justification or strong empirical results are required to support this claim.	I-Review	I-2	Review	471
However, both are missing in the current paper.	I-Review	I-2	Review	471
<sep> <sep> Experiments:	O	O	Review	471
<sep> First, the baseline results for even toy problems (e.g., addition) are unclear.	B-Review	B-3	Review	471
Despite the results in the paper show the advantage of the proposed method, direct comparison with results from other papers are missing.	I-Review	I-3	Review	471
For example,  when the T &gt; 150 the results from Le et al, 2015 (A Simple Way to Initialize Recurrent Networks of	I-Review	I-3	Review	471
Rectified Linear Units) were much better compared with baseline results in the paper.	I-Review	I-3	Review	471
This could be due to the smaller size of the models (40 vs 100 hidden units in Le et al).	I-Review	I-3	Review	471
For clear and direct comparison in this case, models with comparable size should be used in these experiments.	I-Review	I-3	Review	471
Despite this, I wonder why the performance of addition and multiplication seem even worse than the much smaller model reported in Hochreiter and Schmidhuber 1997? (	I-Review	I-3	Review	471
see table 7 and 8)?	I-Review	I-3	Review	471
<sep> <sep> Actually, it would be helpful to test the proposed method on more practical tasks such as language (at least synthetic ones) and speech modelling, which would bring more impact on the wider community.	B-Review	B-4	Review	471
<sep> <sep> A few technical questions:	O	O	Review	471
<sep> - Is the form of eq.1 necessary, or can the method be adapted for the more standard formulation of RNN used in machine learning?	B-Review	B-5	Review	471
It seems that A can be interpreted as a skip connection	I-Review	I-5	Review	471
<sep> - Eq.3 can simply be referred to as ‚Äúsoftmax‚Äù	B-Review	B-6	Review	471
<sep> - Please comment on the algorithm in section 3.4 in comparison with more standard variational approaches, such as stochastic variational inference with reparametrisation as in variational RNNs (e.g., Chung, et al 2015, A Recurrent Latent Variable Model for Sequential Data).	B-Review	B-7	Review	471
Is ‚Äústepwise annealling‚Äù always necessary?	I-Review	I-7	Review	471
<sep> <sep> - Eq.7 as a measurement of the match between trajectories still depends on z. Is there an additional expectation over p(z)?	B-Review	B-8	Review	471
Is ‚Äúfreely simulated trajectories‚Äù the prior over trajectories?	I-Review	I-8	Review	471
If so, what‚Äôs the form of this prior?	I-Review	I-8	Review	471
The limitations of orthogonal/unitary RNN are well illustrated in the recent work by Kerg et al (<a href="https://arxiv.org/abs/1905.12080)," target="_blank" rel="nofollow">https://arxiv.org/abs/1905.12080),</a> but we also have a formal proof that orthogonal RNN cannot exhibit certain dynamical systems phenomena like, e.g., chaos (briefly, among other things, because they do not have diverging eigen-directions).	B-Reply	B-2	Reply	471
We would be happy to add this proof to the manuscript if that is considered useful.	I-Reply	I-2	Reply	471
<sep> <sep> Regarding initialization, in all our experiments all the initialization-based approaches always performed worse than the regularization, and we suspect this is the case since over the course of training the initial condition often simply gets lost (after all, the training [parameter updating] constitutes a stochastic dynamical systems process as well), and with it the ability to express long short-term memory.	I-Reply	I-2	Reply	471
This certainly will depend on the complexity of the task, the length of the delays used, and the amount of noise/stochasticity in the process, however, where we‚Äôd expect that our approach gains more and more of an edge as T, noise, and task complexity increase (playing against pure initialization-based approaches).	I-Reply	I-2	Reply	471
<sep> <sep> Re experiments, we will attempt to add runs with 100 units at least for iRNN and rPLRNN, and comparable # of parameters for LSTM, if we‚Äôll manage in the time available for the revision!	B-Reply	B-3	Reply	471
<sep> We emphasize, however, that we settled on 40 units since this appeared to optimize the bias-variance tradeoff in our case, and hence is a reasonable choice from a statistical learning perspective.	I-Reply	I-3	Reply	471
Given this, we put all different models on equal footing by equalizing their degrees of freedom as much as possible.	I-Reply	I-3	Reply	471
<sep> We are not quite sure why the results for LSTMs in H&amp;S97 are better than ours, but will surely look into this ‚Äì perhaps it‚Äôs related to the optimizer we used (Adam) or the specific learning protocol or ‚Ä¶; we note that we will provide all our code (now available via the Dropbox link) publicly on github, so anyone is free to check our code and results for possible clues.	I-Reply	I-3	Reply	471
<sep> We aimed to standardize and make comparable the protocols &amp; conditions among all RNN models tested to the largest degree possible, however, so specific performance differences we get in comparison to the literature are likely to affect all models in our competition, including the one advocated by us.	I-Reply	I-3	Reply	471
<sep> <sep> While language modeling would certainly be interesting, it‚Äôs probably not something we‚Äôll achieve in the short time available for revision; we used the three benchmarks which we feel are the ones most widely used in the literature on the vanish./expl.	B-Reply	B-4	Reply	471
grad.	I-Reply	I-4	Reply	471
problem, with language modeling less commonly employed.	I-Reply	I-4	Reply	471
<sep> Ultimately, however, our interest is much more in recovering underlying nonlinear dynamical systems in a fully generative sense (Fig.3).	I-Reply	I-4	Reply	471
In our minds we have achieved a major step here, but it appears this point unfortunately got somewhat lost perhaps by the focus on machine learning benchmarks in the first part.	I-Reply	I-4	Reply	471
<sep> <sep> On the technical questions:	O	O	Reply	471
<sep> Yes, the model could largely be rewritten in ‚Äòstandard machine learning form‚Äô (see lines below eq.1, by a change of variables).	B-Reply	B-5	Reply	471
However, the specific separation of A and W we chose, at least in theory enables a line attractor to be formed across the whole support of the variables (the whole real line), and therefore should be beneficial for this purpose.	I-Reply	I-5	Reply	471
Moreover, it makes an explicit connection to models used in computational neuroscience, a feature it appears that referee #3 liked.	I-Reply	I-5	Reply	471
<sep> <sep> Softmax: Yes, true; we wanted to be explicit here, but are happy to change this and spare one standard equation.	B-Reply	B-6	Reply	471
<sep> <sep> Comparison to var.	O	O	Reply	471
RNN: Very fair point, please see our reply to referee #3 who brought up the same issue.	B-Reply	B-7	Reply	471
<sep> In brief, we actually did implement the same model using a variational approach and the re-parameterization trick, but it performs (much) worse than the EM-based algorithm which is specifically designed for nonlinear dynamical systems reconstruction, and which also requires (much) less data.	I-Reply	I-7	Reply	471
The annealing may not always be necessary, but at least for the purpose of reconstructing dynamical systems it improves performance by orders of magnitude (see Koppe et al 2019 PLoS Comp.	I-Reply	I-7	Reply	471
Biol.)!	I-Reply	I-7	Reply	471
<sep> As already mentioned in our reply to referee #3, we will discuss pro‚Äôs and con‚Äôs of the different approaches in the revised manuscript as requested.	I-Reply	I-7	Reply	471
<sep> <sep> Re eq.7, measure of match between attractor geometries: Yes it depends on z, but the whole ‚Äòmeasure‚Äô is across state space, not time.	O	O	Reply	471
And yes, by freely simulated we mean drawing samples from the generative model, i.e. the prior p(z), and using that to produce samples from p(x|z).	I-Reply	I-8	Reply	471
The prior is determined by our specific model formulation, eq.1, i.e. at each time step t it is conditionally (on z_{t-1}) Gaussian, but overall the prior across latent trajectories will be a high-dimensional mixture of piecewise Gaussians (owing to the piecewise linear, ReLU-based structure of the RNN).	I-Reply	I-8	Reply	471
<sep> We will try to clarify all these points in Suppl.	I-Reply	I-8	Reply	471
sect.	I-Reply	I-8	Reply	471
6.1.4.	I-Reply	I-8	Reply	471

This paper presents and interesting twist to adversarial examples: given a trained neural segmentation model, with slight changes to the input image that given a segmentation model, it is possible to change the segmentation prediction of certain classes or even individual objects without significantly changing the predictions to anything else.	O	O	Review	105
This is useful direction to explore and understand better.	O	O	Review	105
<sep> <sep> Weaknesses: the methods utilized are relatively similar to earlier works on adversarial examples, so the novelty of the approach is not very high.	B-Review	B-1	Review	105
However The main weakness of the work is that the demonstration comes without any meaningful quantitative comparisons.	I-Review	I-1	Review	105
Thank you very much for your review and feedback.	O	O	Reply	105
<sep> <sep> We would like to address the point of meaningful quantitative comparisons:	O	O	Reply	105
* One main reason we used no other adversarial attacks in comparison was that we were restricted to targeted attacks (in order to achieve a specific target segmentation) and related work is typically non-targeted.	B-Reply	B-1	Reply	105
<sep> * We validated our findings statistically on a subset of the cityscapes validation dataset (images containing enough pixels of person class, which were over half the validation images) also comparing the influence of different noise-sizes \epsison (please also compare Fig.2).	B-Reply	B-1	Reply	105
<sep> * We plan to give a more sophisticated analysis / comparison in future work which we were not able due to the 3 page restriction for workshop submissions.	B-Reply	B-1	Reply	105
<sep> <sep> We want to thank the review again for their comments and hope this response clarifies the main point of concern.	O	O	Reply	105

-- Update --	O	O	Review	105
Thank you for the detailed response and updates.	O	O	Review	105
The quality has improved but as mentioned in the original review, it would be good to see results on a more significant non-synthetic task before I would argue for acceptance.	B-Review	B-1	Review	105
<sep> <sep> ------------------	O	O	Review	105
The authors propose a generative model with a hierarchy of latent variables corresponding to a scene, objects, and object parts.	O	O	Review	105
The method is evaluated on a synthetic dataset with manual inspection, MSE, and object counting performance.	O	O	Review	105
The method can form bounding boxes around objects and parts in the examples that are shown, and the MSE is similar to that of a VAE.	O	O	Review	105
<sep> <sep> The idea of decomposing a probabilistic model hierarchically is potentially interesting, but this paper has drawbacks in terms of experimental quality, significance, and presentation.	O	O	Review	105
<sep> <sep> -- Experiments --	O	O	Review	105
The experiments are done on a manually constructed synthetic dataset, so it is not clear whether the proposed method would work in more realistic or more challenging settings.	B-Review	B-1	Review	105
For instance, the dataset was constructed using a recursive process which probably does not resemble a realistic distribution of objects and their parts, and the parts are well-separated within the object.	I-Review	I-1	Review	105
<sep> <sep> The experiments on the synthetic dataset are not thorough, and could be more interesting with ablations, evaluating performance as the dataset parameters vary (e.g. number of objects, amount of occlusion), better baselines, and an evaluation metric rather than manual inspection.	I-Review	I-1	Review	105
<sep> <sep> -- Significance --	O	O	Review	105
With respect to significance, the formulation is fairly straightforward and builds off of previous techniques introduced in e.g. SPAIR.	B-Review	B-2	Review	105
The lack of demonstrating usefulness on a downstream application limits this paper's significance; for instance the SPAIR paper used the generative model as a front-end for a card game and Atari game.	I-Review	I-2	Review	105
The paper should more clearly demonstrate the benefits/tradeoffs of the hierarchical aspect.	I-Review	I-2	Review	105
<sep> <sep> -- Presentation --	O	O	Review	105
The paper leaves many terms undefined so the paper is not self contained, e.g. the 'problem of routing', 'memory buffer', 'memory template', 'variational memory addressing', 'spatial transformer' (missing a reference here).	B-Review	B-3	Review	105
I suspect the related work is missing references, e.g. "Unsupervised Discovery of Parts, Structure, and Dynamics" Xu et al ICLR 2019.	I-Review	I-3	Review	105
Finally, the paper should be proof-read for grammatical errors.	I-Review	I-3	Review	105
<sep> <sep> Thank you for the constructive review.	O	O	Reply	105
We will respond in order.	O	O	Reply	105
<sep> <sep> -- Experiments --	O	O	Reply	105
Our problem setting is already challenging: (i) We use generative modeling, which learns both representation and rendering process; (ii) Our latent representation is hierarchical, compositional, and interpretable at the same time, which no prior work has achieved; (iii) Our model is end-to-end trainable via purely unsupervised learning.	B-Reply	B-1	Reply	105
We believe that research under such problem setting has not been close to the level of applying to real-world datasets.	I-Reply	I-1	Reply	105
We also would like to note that our datasets, though manually constructed, present challenges of multi-scale and multi-pose entities with occlusion and compositional ambiguity.	I-Reply	I-1	Reply	105
Specifically, in our 3D dataset, there is occlusion between parts, so parts are not well-separated.	I-Reply	I-1	Reply	105
In our revised paper, we have shown promising results on a compositional MNIST dataset that presents an additional challenge of shape variation.	I-Reply	I-1	Reply	105
<sep> <sep> Regarding empirical evaluation and ablations / baselines, please kindly refer to general response [A5] - [A8]. We have actually provided NLL, counting error, precision, and recall as evaluation metrics.	I-Reply	I-1	Reply	105
We appreciate your suggestion to evaluate performance as the dataset parameters vary.	I-Reply	I-1	Reply	105
In the generalization experiments, we have already tested performance on different number of objects.	I-Reply	I-1	Reply	105
<sep> <sep> -- Significance --	O	O	Reply	105
Thanks for your suggestion.	B-Reply	B-2	Reply	105
We have included experiments on downstream tasks in our revised paper.	I-Reply	I-2	Reply	105
We show that compared to SPAIR, our proposed hierarchical representation approximately doubles the data efficiency on these downstream tasks.	I-Reply	I-2	Reply	105
Please also refer to general response [A1] - [A2] for the contribution and novelty of our paper.	I-Reply	I-2	Reply	105
<sep> <sep> -- Presentation --	O	O	Reply	105
Thanks for the feedback.	B-Reply	B-3	Reply	105
We have improved our presentation quality and included more discussion on related work.	I-Reply	I-3	Reply	105
Please kindly refer to general response [A10] for a brief comparison with Xu et al	I-Reply	I-3	Reply	105

Update: I thank the auhors for the detailed response.	O	O	Review	105
The updated paper does look more convincing, but my main concern remains - all considered datasets and tasks are synthetic and specifically made for the method.	B-Review	B-2	Review	105
I think experiments on more real data would be crucial to show the potential of the method.	I-Review	I-2	Review	105
Some examples I can imagine would be part segmentation in images or 3D models, or robotic control.	I-Review	I-2	Review	105
<sep> <sep> ---	O	O	Review	105
<sep> The paper proposes an unsupervised approach to learning objects and their parts from images.	O	O	Review	105
The method is based on the "Attend, Infer, Repeat" (AIR) line of work and adds a new hierarchy level to the approach, corresponding to object parts.	O	O	Review	105
The method is evaluated on two custom synthetic dataset: one composed of simple 2D geometric shapes and another one with 3D geometric shapes.	O	O	Review	105
On these datasets the method successfully infers the object-part structure and can parse and reconstruct provided images.	O	O	Review	105
<sep> <sep> While the general topic of the paper is interesting, I do not think it is fit for publication.	O	O	Review	105
First and foremost, the experiments are very incomplete: the method is only evaluated on two custom synthetic datasets and not compared against any baselines or ablated versions of the method.	B-Review	B-1	Review	105
Moreover, the proposed approach seems like a relatively minor modification of SPAIR (Crawford &amp; Pineau).	I-Review	I-1	Review	105
<sep> <sep> Pros:	O	O	Review	105
1) The topic is interesting and the method generally makes sense.	O	O	Review	105
<sep> 2) The method works on the tasks studied in the paper, including relatively challenging scenarios with 3D occlusions or ambiguity in assigning parts to objects.	O	O	Review	105
<sep> 3) The paper shows generalization to a number of objects different from that seen during training.	O	O	Review	105
<sep> <sep> Cons:	O	O	Review	105
1) Experiments are limited:	O	O	Review	105
1a) The method is evaluated on custom and relatively toy datasets.	B-Review	B-2	Review	105
It is unclear if it would apply to more practical situations.	I-Review	I-2	Review	105
While I agree that at the high level the question of decomposition of object into parts is interesting, it is still important to connect research in this direction to potential practical applications.	I-Review	I-2	Review	105
Where could the proposed method be used?	I-Review	I-2	Review	105
Perhaps in some control tasks, such as robotics?	I-Review	I-2	Review	105
Could it be applied to more realistic data, such as for instance ShapeNet objects?	I-Review	I-2	Review	105
<sep> 1b) There are no comparisons to baselines.	B-Review	B-2	Review	105
One might argue that baselines do not exist since there are no methods addressing the same task.	I-Review	I-2	Review	105
Generally, it is the job of the authors to come up with relevant baselines to show that the proposed model actually improves upon some simpler methods.	I-Review	I-2	Review	105
One variant of obtaining baselines is via ablating the proposed model.	I-Review	I-2	Review	105
Another is by taking prior approaches, for instance object-based ones without the part decomposition, and showing that the part decomposition allows to improve upon those in some sense.	I-Review	I-2	Review	105
<sep> <sep> 2) The novelty is somewhat limited: the method seems like a relatively straightforward extension of SPAIR by adding another hierarchy layer.	B-Review	B-3	Review	105
It might be sufficient if the experimental results would be strong, but given that they are not, becomes somewhat concerning.	I-Review	I-3	Review	105
If the method does indeed include significant technical innovation, it might be helpful to better highlight it.	I-Review	I-3	Review	105
<sep> <sep> 3) The related work overview is extremly limited.	B-Review	B-4	Review	105
It is authors' job to provide a comprehensive ovreview of prior literature and I cannot do it for them here, but below are a few papers that come to mind.	I-Review	I-4	Review	105
This is by no means a complete list.	I-Review	I-4	Review	105
<sep> <sep> [1] Zhenjia Xu, Zhijian Liu, Chen Sun, Kevin Murphy, William T. Freeman, Joshua B. Tenenbaum, Jiajun Wu.	O	O	Review	105
Unsupervised Discovery of Parts, Structure, and Dynamics.	O	O	Review	105
ICLR 2019	O	O	Review	105
[2] Shubham Tulsiani, Hao Su, Leonidas J. Guibas, Alexei A. Efros, Jitendra Malik.	O	O	Review	105
Learning Shape Abstractions by Assembling Volumetric Primitives.	O	O	Review	105
CVPR 2017	O	O	Review	105
[3] Jun Li, Kai Xu, Siddhartha Chaudhuri, Ersin Yumer, Hao Zhang, Leonidas Guibas.	O	O	Review	105
GRASS: Generative Recursive Autoencoders for Shape Structures.	O	O	Review	105
SIGGRAPH 2017.	O	O	Review	105
<sep> [4] Gopal Sharma, Rishabh Goyal, Difan Liu, Evangelos Kalogerakis, Subhransu Maji.	O	O	Review	105
CSGNet: Neural Shape Parser for Constructive Solid Geometry.	O	O	Review	105
CVPR 2018.	O	O	Review	105
<sep> [5] Adam R. Kosiorek, Hyunjik Kim, Ingmar Posner, Yee Whye Teh.	O	O	Review	105
Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects.	O	O	Review	105
NeurIPS 2018.	O	O	Review	105
<sep> <sep> 4) Presentation is at times suboptimal:	O	O	Review	105
4a) It would be very helpful to have more visuals and intuitions about the functioning of the method, as opposed to equations.	B-Review	B-5	Review	105
Equations are definitely good to have, but they are not the easiest to parse, especially by those not intimately familiar with this specific line of work.	I-Review	I-5	Review	105
<sep> 4b) It is quite unclear to me how and why is the memory used in the model.	B-Review	B-6	Review	105
If this is described in another paper, it would be useful to point there, but still briefly summarize in this paper to make it self-contained.	I-Review	I-6	Review	105
Thank you for your constructive review and for taking the time to provide a reference list.	O	O	Reply	105
We will respond in order.	O	O	Reply	105
<sep> <sep> 1a) We agree that it is important to connect to practical applications.	B-Reply	B-2	Reply	105
However, this line of research has not been close to the level of applying to robotics or real-world datasets.	I-Reply	I-2	Reply	105
This is due to the challenging problem setting: (i) We use generative modeling, which learns both representation and rendering process; (ii) Our latent representation is hierarchical, compositional, and interpretable at the same time, which no prior work has achieved; (iii) Our model is end-to-end trainable via purely unsupervised learning.	I-Reply	I-2	Reply	105
In our revised paper, we have introduced a compositional MNIST dataset that presents an additional challenge of shape variation compared to our 2D and 3D datasets.	I-Reply	I-2	Reply	105
We think this is one characteristic of more realistic data, and we have shown promising results.	I-Reply	I-2	Reply	105
<sep> <sep> 1b) Regarding empirical evaluation and ablations / baselines, please kindly refer to general response [A5] - [A8].	B-Reply	B-2	Reply	105
<sep> 2) Thanks for the suggestion.	B-Reply	B-3	Reply	105
We have revised our paper to better highlight the significance.	I-Reply	I-3	Reply	105
Please also refer to general response [A1] - [A2] for a summary of the contribution and novelty of our paper.	I-Reply	I-3	Reply	105
<sep> <sep> 3) We totally agree and have included more discussion on related work.	B-Reply	B-4	Reply	105
Please kindly refer to general response [A10] - [A13] for a brief comparison.	I-Reply	I-4	Reply	105
<sep> <sep> 4a) Thanks for the suggestion.	O	O	Reply	105
We have updated the notation and equations to make them more accessible.	B-Reply	B-5	Reply	105
We have also added more intuitive explanation and illustrations to clarify the formulation and contribution of our model.	I-Reply	I-5	Reply	105
<sep> <sep> 4b) We have included a dedicated paragraph in Section 3.3 to describe the memory.	B-Reply	B-6	Reply	105
In short, memory is able to capture the canonical pose, which is essential to the scene graph that describes composition based on pose transformations.	I-Reply	I-6	Reply	105
The learned memory templates also bring additional interpretability to our model.	I-Reply	I-6	Reply	105

Contributions: this submission proposes a generative framework which employs a hierarchical decomposition of scene, objects and parts.	O	O	Review	105
It modifies the SPAIR framework (Crawford &amp; Pineau) and replaces the recurrent generation with parallel generation, by assuming the number of objects is known and fixed.	O	O	Review	105
Results are presented on two synthetic datasets with 2D or 3D shapes.	O	O	Review	105
<sep> <sep> Assessment:	O	O	Review	105
- The proposed model and learning framework are closely related to previous work (AIR, SPAIR).	B-Review	B-1	Review	105
The authors replaced the "sequential processing ... with single forward pass", which requires the number of objects to be fixed.	I-Review	I-1	Review	105
<sep> - In the proposed model, there is no constraint on the part-object hierarchy, and it is unclear whether it can learn to discover such hierarchies directly by reconstructing single static images.	B-Review	B-2	Review	105
It is also not evaluated in the submission.	I-Review	I-2	Review	105
<sep> - There are no comparisons with AIR or SPAIR on the two datasets the authors created.	B-Review	B-3	Review	105
<sep> - The authors are recommended to compare with previous work on hierarchical generative modelings with objects and parts, such as (Xu et al, ICLR 2019), and other related work, such as SPIRAL (Ganin et al)	B-Review	B-4	Review	105
<sep> Due to the limited contribution, lack of comparison with related work and limited empirical evaluation, I recommend rejection of the submission.	B-Review	B-4	Review	105
<sep> <sep> [1] Xu el al, Unsupervised Discovery of Parts, Structure, and Dynamics, ICLR 2019.	O	O	Review	105
<sep> [2] Ganin et al Synthesizing Programs for Images using Reinforced Adversarial Learning.	O	O	Review	105
<sep> <sep> <sep> --------------------------------	O	O	Review	105
Post-rebuttal:	O	O	Review	105
Thank you for your detailed answers to my questions and updated manuscript.	O	O	Review	105
The writing has indeed significantly improved and some questions (e.g. varying number of objects) have been addressed.	O	O	Review	105
After reading the rebuttal, my concerns remain that: (1) lack of empirical evaluation on more complex real / synthetic datasets; (2) it is still unclear to me how such hierarchy is inferred from single images.	B-Review	B-3	Review	105
Thank you for the helpful comments.	O	O	Reply	105
We will respond in order.	O	O	Reply	105
<sep> <sep> 1) We believe the key to dealing with variable number of objects is the z_pres variable.	B-Reply	B-1	Reply	105
It can turn on/off individual object representations.	I-Reply	I-1	Reply	105
Although we use parallel inference, we still have the z_pres variable, so we do not require the number of objects to be fixed.	I-Reply	I-1	Reply	105
Also, our datasets do contain variable number of objects.	I-Reply	I-1	Reply	105
We have clarified this in the first paragraph of Section 3.3.	I-Reply	I-1	Reply	105
We conjecture that our top-down inference approach enables the parallel inference to perform well, since higher-level appearance information can guide lower-level decomposition.	I-Reply	I-1	Reply	105
Please also kindly refer to general response [A1] - [A2] for the main contribution and novelty of our paper.	I-Reply	I-1	Reply	105
<sep> <sep> 2) We have updated the paper to clarify our representation of the compositional hierarchy.	B-Reply	B-2	Reply	105
As shown in Figure 1A, the compositional hierarchy is represented as a latent tree.	I-Reply	I-2	Reply	105
Both the tree structure and the latent variables are inferred for each static image in the dataset.	I-Reply	I-2	Reply	105
One way to visualize the tree is to draw bounding boxes around objects and their constituent parts according to the inferred tree structure and pose vectors.	I-Reply	I-2	Reply	105
Figure 1B illustrates this, and our qualitative results should be interpreted in the same way.	I-Reply	I-2	Reply	105
Since we recursively apply spatial transformer during inference, we have the implicit constraint that parts should be within the object bounding box.	I-Reply	I-2	Reply	105
<sep> <sep> 3) Regarding empirical evaluation and ablations / baselines, please kindly refer to general response [A5] - [A8].	B-Reply	B-3	Reply	105
<sep> 4) Please kindly refer to general response [A10] - [A11] for a brief comparison.	B-Reply	B-4	Reply	105

This paper proposes a method to create adversarial perturbations whose target labels are similar to their ground truth.	O	O	Review	10157
The target labels are selected using an existing perceptual similarity measure for images.	O	O	Review	10157
Perturbations are generated using a DeepFool-like algorithm.	O	O	Review	10157
Human evaluation supports that the pair of the generated images and target labels are more natural to humans than prior attack algorithms.	O	O	Review	10157
<sep> <sep> This paper should be rejected due to the lack of motivation to create adversarial examples less detectable by humans automatically.	B-Review	B-1	Review	10157
Attackers can manually select target labels and apply targeted attacks.	I-Review	I-1	Review	10157
In the target label selection, attackers can choose less detectable labels if necessary.	I-Review	I-1	Review	10157
It is encouraged to provide some applications where attackers want to create less detectable adversarial examples in label space without manually assigning target labels.	I-Review	I-1	Review	10157
<sep> <sep> ==========	O	O	Review	10157
Update:	O	O	Review	10157
<sep> After reading the authors' responses, the motivation of the paper became clearer.	O	O	Review	10157
I will not get surprised if this paper is accepted.	O	O	Review	10157
However, all reviewers still share concerns about the importance of the problem tackled.	B-Review	B-1	Review	10157
I think the paper needs to suggest more applications and emphasize the value of the goal in the main paper before being published.	I-Review	I-1	Review	10157
We thank the reviewer for the time , and would like to answer the reviewer‚Äôs questions as follows:	O	O	Reply	10157
<sep> First, we want to explain our motivation for this work.	B-Reply	B-1	Reply	10157
Our method is an untargeted attack, not a targeted attack.	I-Reply	I-1	Reply	10157
To the best of our knowledge, most papers in adversarial attack community focus on untargeted attacks.	I-Reply	I-1	Reply	10157
But exiting untargeted attacks don‚Äôt care about the misclassified-label in the label space so that the misclassified-label may be very unreasonable.	I-Reply	I-1	Reply	10157
However, many effective defense methods [1,2] have been published.	I-Reply	I-1	Reply	10157
Unreasonable labels will cause the users detect the attack and take defensive measures to let the attack fail (just as introduced in Section 1).	I-Reply	I-1	Reply	10157
So creating an attack without regards to the target label is adverse for an attacker.	I-Reply	I-1	Reply	10157
Therefore, we propose this LabelFool method in order to help an untargeted attack not to be defensed.	I-Reply	I-1	Reply	10157
We recommend to create carefully automatically designed target label when doing untargeted attacks	I-Reply	I-1	Reply	10157
<sep> Second, there are many applications where ‚Äúattackers want to create less detectable adversarial examples in label space without manually assigning target labels‚Äù.	B-Reply	B-1	Reply	10157
Please see Figure 9 in Appendix E in the new version.	I-Reply	I-1	Reply	10157
Taking face recognition system for entrance as an example, there will usually be a guard as ‚Äúa human inspector‚Äù to check whether the man A who is entering the gate is the same as the system shows.	I-Reply	I-1	Reply	10157
In this case, if the model just misclassifies A and C, the person who looks totally different from A, the attack will be detected easily.	I-Reply	I-1	Reply	10157
But LabelFool aims to let the model misclassify A and B who looks like A as shown in Figure 9.	I-Reply	I-1	Reply	10157
If the guard doesn‚Äôt identify carefully, he will let a fake B in and this error brings great potential security risks.	I-Reply	I-1	Reply	10157
So as an attacker, it is necessary to generate imperceptible examples in the label space for this task.	I-Reply	I-1	Reply	10157
But how does the attacker know who is the one looks like A in such a huge face database?	I-Reply	I-1	Reply	10157
LabelFool can help him much in this application.	I-Reply	I-1	Reply	10157
<sep> <sep> Third, we appreciate your suggestion about applying this method to other applications, we will do this in our future work, but now, we just introduce this idea, provide a tool and conduct experiments on simple tasks to prove the feasibility of this idea.	B-Reply	B-1	Reply	10157
<sep> <sep> If you still have questions about our motivation, please don‚Äôt hesitate to let us know.	O	O	Reply	10157
We are here to answer your questions all the time.	O	O	Reply	10157
<sep> <sep> References:	O	O	Reply	10157
[1] Jia X, et al ComDefend: An Efficient Image Compression Model to Defend Adversarial Examples. (	O	O	Reply	10157
CVPR 2019)	O	O	Reply	10157
[2] Dubey, Abhimanyu, et al Defense against adversarial images using web-scale nearest-neighbor search. (	O	O	Reply	10157
CVPR 2019)	O	O	Reply	10157

This paper describes a technique for creating adversarial images where the added perturbations are not only imperceptible to machines, but also to human observers.	O	O	Review	10157
The authors describe why this might be beneficial.	O	O	Review	10157
The method works by finding labels that are not too far from the source image's ground-truth labels, and moving the source image in that direction.	O	O	Review	10157
To find the target label, the authors use a threshold on the confidence of predicted ground-truth labels.	O	O	Review	10157
The authors test their algorithm using a newly proposed metric of how much a method allows imperceptibility for a human observer.	O	O	Review	10157
They show that their method creates images whose perturbations are more impercetible to humans, compared to other methods, but are also imperceptible to machines.	O	O	Review	10157
<sep> <sep> My concern is as follows: If the misclassification is between A and B, and they are related classes, is the attack so bad?	B-Review	B-1	Review	10157
And what are the scenarios in practice when a user simply wants to create an attack, without regards to the target label chosen?	I-Review	I-1	Review	10157
I imagine normally the attacker has a target label in mind, so the part of the paper that chooses a target label is not very useful; and this is the main element of novelty, since the rest of the method is from DeepFool, as the authors explain.	I-Review	I-1	Review	10157
Some specific use cases of this methods should be discussed.	I-Review	I-1	Review	10157
<sep> <sep> Minor suggestion: It would be useful to see examples like in Fig.5 but with the classes (true/target) listed.	B-Review	B-2	Review	10157
We thank the reviewer for the time and concern, and would like to answer the reviewer‚Äôs questions as follows:	O	O	Reply	10157
<sep> First, let‚Äôs clarify the concept of adversarial examples.	B-Reply	B-1	Reply	10157
The concept of ‚Äúadversarial examples‚Äù was first proposed in 2014 [1] and defined as ‚ÄúWe find that applying an imperceptible non-random perturbation to a test image, it is possible to arbitrarily Change the Network‚Äôs Prediction. ‚	I-Reply	I-1	Reply	10157
Ä¶ We term the so perturbed examples ‚Äòadversarial examples‚Äô.	I-Reply	I-1	Reply	10157
‚Äù That is to say, adversarial examples are the ones misclassified by the network (by adding imperceptible perturbations).	I-Reply	I-1	Reply	10157
As long as the prediction is changed by the perturbation, the perturbed example is called ‚Äúadversarial example‚Äù no matter how the prediction is far from the ground truth.	I-Reply	I-1	Reply	10157
Therefore, we think that each adversarial example should be treated equally.	I-Reply	I-1	Reply	10157
There is no ‚Äúgood‚Äù or ‚Äúbad‚Äù attack.	I-Reply	I-1	Reply	10157
There is only ‚Äúsuccessful‚Äù and ‚Äúfailed‚Äù attack.	I-Reply	I-1	Reply	10157
<sep> <sep> Second, to the best of our knowledge, most papers in adversarial attack community focus on untargeted attacks.	B-Reply	B-1	Reply	10157
Unfortunately, exiting untargeted attacks just focus on getting the networks failed (with imperceptible perturbations in the image space).	I-Reply	I-1	Reply	10157
They don‚Äôt care about the misclassified-label in the label space so that the misclassified-label may be very unreasonable.	I-Reply	I-1	Reply	10157
However, many effective defense methods [2,3] have been published.	I-Reply	I-1	Reply	10157
Unreasonable labels will cause the users detect the attack and take defensive measures to let the attack fail (just as introduced in Section 1).	I-Reply	I-1	Reply	10157
So ‚Äúcreating an attack without regards to the target label‚Äù is adverse for an attacker.	I-Reply	I-1	Reply	10157
Therefore, our method is applicable when an attacker conducts untargeted attack and hope it not to be detected.	I-Reply	I-1	Reply	10157
We recommend to create carefully automatically designed target label when doing untargeted attacks.	I-Reply	I-1	Reply	10157
<sep> <sep> Third, in Figure 7 in Appendix B of the original version, there are some figures as you suggested.	B-Reply	B-1	Reply	10157
In Appendix E of our new version, we add more examples in Figure 9.	I-Reply	I-1	Reply	10157
We also add true/target labels in Figure 5 as you suggested.	B-Reply	B-2	Reply	10157
<sep> <sep> If you still have questions about our motivation, please don‚Äôt hesitate to let us know.	O	O	Reply	10157
We are here to answer your questions all the time.	O	O	Reply	10157
<sep> <sep> References:	O	O	Reply	10157
[1] Szegedy et al Intriguing properties of neural networks. (	O	O	Reply	10157
ICLR 2014)	O	O	Reply	10157
[2] Jia X, et al ComDefend: An Efficient Image Compression Model to Defend Adversarial Examples. (	O	O	Reply	10157
CVPR 2019)	O	O	Reply	10157
[3] Dubey, Abhimanyu, et al Defense against adversarial images using web-scale nearest-neighbor search. (	O	O	Reply	10157
CVPR 2019)	O	O	Reply	10157

This paper proposes a method for constructing adversarial attacks that are less detectable by humans, by changing the target class to be a class similar to the original class of the image.	O	O	Review	10157
The resulting attack methodology is then studied in terms of its imperceptibility in label space, and shown to be less perceptible in label space to human observers, while not coming at a cost in image space.	O	O	Review	10157
<sep> <sep> The paper presents compelling evaluation of the method and does seem to succeed in proving that their proposed attack satisfies the stated goal.	B-Review	B-1	Review	10157
However, it appears as though this goal is somewhat counter to the main point of adversarial examples---indeed, if the label is reasonable to a human, then what makes the adversarial example adversarial?	I-Review	I-1	Review	10157
The main threat in adversarial examples research seems to be that it is possible to induce predictions that are arbitrarily different from humans' on natural-looking in puts.	I-Review	I-1	Review	10157
Thus, changing the label to something that a human actually agrees with would actually reduce the impact of the adversarial attack.	I-Review	I-1	Review	10157
<sep> <sep> In order to improve the paper, I would suggest applying the same (or similar) methodologies to other areas of ML security where imperceptibility in label space is commonly desired---for example, in data poisoning attacks or backdoor attacks.	B-Review	B-2	Review	10157
In general, such attacks are much more likely to be "inspected" by humans, and so imperceptibility in both label and image space is very desirable.	I-Review	I-2	Review	10157
However, I suspect that this would require significant effort and changes to the paper, and so for now I recommend rejection.	I-Review	I-2	Review	10157
We thank the reviewer for the time and some good suggestions, and would like to answer the reviewer‚Äôs questions as follows:	O	O	Reply	10157
<sep> First, there is some misunderstanding about ‚Äúadversarial examples‚Äù.	B-Reply	B-1	Reply	10157
This concept was first proposed in 2014 [1]. It is defined as ‚ÄúWe find that applying an imperceptible non-random perturbation to a test image, it is possible to arbitrarily Change the Network‚Äôs Prediction. ‚	I-Reply	I-1	Reply	10157
Ä¶ We term the so perturbed examples ‚Äòadversarial examples‚Äô.	I-Reply	I-1	Reply	10157
‚Äù in work [1]. Many other works [2,3] follow this definition that adversarial examples are the ones misclassified by the network Ôºàby adding imperceptible perturbationsÔºâ.	I-Reply	I-1	Reply	10157
Meanwhile, to the best of our knowledge, all works in adversarial attack community report the ‚Äúsuccess rate of attack‚Äù as the misclassification rate of their target model without checking whether the generated examples are reasonable to humans or not.	I-Reply	I-1	Reply	10157
As long as the prediction is different from the ground truth, the perturbed example is ‚Äúadversarial‚Äù no matter it is reasonable to human or not.	I-Reply	I-1	Reply	10157
<sep> <sep> Second, we think there are two evaluations of ‚Äúthe impact of the adversarial attack‚Äù.	B-Reply	B-1	Reply	10157
One is whether the error happens, it is evaluated by the success rate of attack (misclassification rate of the target model).	I-Reply	I-1	Reply	10157
The other is how long the error lasts, it is evaluated by the time that a human user detects the attack.	I-Reply	I-1	Reply	10157
LabelFool does as well as other attacks on the first evaluation, but does better on the second evaluation because it is less detectable by a human user.	I-Reply	I-1	Reply	10157
<sep> <sep> Third, we only conduct experiments on the image classification task and you think this task is less likely to be ‚Äúinspected‚Äù by humans.	B-Reply	B-2	Reply	10157
But the fact is, this task is widely used in many fields in our life.	I-Reply	I-2	Reply	10157
Please see Figure 9 in Appendix E in the new version.	I-Reply	I-2	Reply	10157
Taking face recognition system for entrance as an example, there will usually be a guard as ‚Äúa human inspector‚Äù to check whether the man A who is entering the gate is the same as the system shows.	I-Reply	I-2	Reply	10157
In this case, if a model just misclassifies A and C, the person who looks totally different from A, the attack will be detected easily.	I-Reply	I-2	Reply	10157
But LabelFool aims to let the model misclassify A and B who looks like A as shown in Figure 9.	I-Reply	I-2	Reply	10157
If the guard doesn‚Äôt identify carefully, he will let a fake B in and this error brings great potential security risks.	I-Reply	I-2	Reply	10157
So as an attacker, it is necessary to generate imperceptible examples in the label space for this task.	I-Reply	I-2	Reply	10157
<sep> <sep> Fourth, we appreciate your suggestion about applying this method to other areas of ML security, we will do this in our future work, but now, we just introduce this idea, provide a tool and conduct experiments on simple tasks to prove the feasibility of this idea.	B-Reply	B-2	Reply	10157
<sep> <sep> If we misunderstood you in this rebuttal or you still have questions about our motivation, please don‚Äôt hesitate to let us know.	O	O	Reply	10157
We are here to answer your questions all the time.	O	O	Reply	10157
<sep> <sep> References:	O	O	Reply	10157
[1] Szegedy et al Intriguing properties of neural networks. (	O	O	Reply	10157
ICLR 2014)	O	O	Reply	10157
[2] Kurakin et al Adversarial examples in the physical world[J]. arXiv preprint arXiv:1607.02533, 2016.	O	O	Reply	10157
<sep> [3] Goodfellow et al Explaining and harnessing adversarial examples. (	O	O	Reply	10157
ICLR 2015)	O	O	Reply	10157

This is a strong paper.	O	O	Review	365
It focuses on an important problem (speeding up program synthesis), it‚Äôs generally very well-written, and it features thorough evaluation.	O	O	Review	365
The results are impressive: the proposed system synthesizes programs from a single example that generalize better than prior state-of-the-art, and it does so ~50% faster on average.	O	O	Review	365
<sep> <sep> In Appendix C, for over half of the tasks, NGDS is slower than PROSE (by up to a factor of 20, in the worst case).	B-Review	B-1	Review	365
What types of tasks are these?	I-Review	I-1	Review	365
In the results, you highlight a couple of specific cases where NGDS is significantly *faster* than PROSE‚ÄîI would like to see some analysis of the cases were it is slower, as well.	I-Review	I-1	Review	365
I do recognize that in all of these cases, PROSE is already quite fast (less than 1 second, often much less) so these large relative slowdowns likely don‚Äôt lead to a noticeable absolute difference in speed.	I-Review	I-1	Review	365
Still, it would be nice to know what is going on here.	I-Review	I-1	Review	365
<sep> <sep> Overall, this is a strong paper, and I would advocate for accepting it.	O	O	Review	365
<sep> <sep> <sep> A few more specific comments:	O	O	Review	365
<sep> <sep> Page 2, ‚ÄúNeural-Guided Deductive Search‚Äù paragraph: use of the word ‚Äúimbibes‚Äù - while technically accurate, this use doesn‚Äôt reflect the most common usage of the word (‚Äúto drink‚Äù).	B-Review	B-2	Review	365
I found it very jarring.	I-Review	I-2	Review	365
<sep> <sep> The paper is very well-written overall, but I found the introduction to be unsatisfyingly vague‚Äîit was hard for me to evaluate your ‚Äúkey observations‚Äù when I couldn‚Äôt quite yet tell what the system you‚Äôre proposing actually does.	B-Review	B-3	Review	365
The paragraph about ‚Äúkey observation III‚Äù finally reveals some of these details‚ÄîI would suggest moving this much earlier in the introduction.	I-Review	I-3	Review	365
<sep> <sep> Page 4, ‚ÄúAppendix A shows the resulting search DAG‚Äù - As this is a figure accompanying a specific illustrative example, it belongs in this section, rather than forcing the reader to hunt for it in the Appendix.	B-Review	B-4	Review	365
<sep> <sep> <sep> Thank you for the constructive feedback!	O	O	Reply	365
We‚Äôll add more details and clarify the introduction in the next revision.	O	O	Reply	365
<sep> <sep> Q: Which factors lead to NGDS being slower than PROSE on some tasks?	O	O	Reply	365
<sep> Our method is slower than PROSE when the predictions do not satisfy the requirements of the controller i.e. all the predicted scores are within the threshold or they violate the actual scores in branch and bound exploration.	B-Reply	B-1	Reply	365
This leads to NGDS evaluating the LSTM for branches that were previously pruned.	I-Reply	I-1	Reply	365
This can be especially harmful when branches that got pruned out at the very beginning of the search need to be reconsidered -- as it could lead to evaluating the network many times.	I-Reply	I-1	Reply	365
While evaluating the network leads to minor additions in run-time, there are many such additions, and since PROSE performance is already < 1s for such cases, this results in considerable relative slowdown.	I-Reply	I-1	Reply	365
<sep> <sep> Why do the predictions violate the controller's requirements?	B-Reply	B-1	Reply	365
This happens when the neural network is either indecisive (its predicted scores for all branches are too close) or wrong (its predicted scores have exactly the opposite order of the actual program scores).	I-Reply	I-1	Reply	365
<sep> We will update the draft with this discussion and present some examples below	I-Reply	I-1	Reply	365
<sep> Some examples:	I-Reply	I-1	Reply	365
A) "41.711483001709,-91.4123382568359,41.6076278686523,-91.6373901367188"  ==>  "41.711483001709"	I-Reply	I-1	Reply	365
<tab>The intended program is a simple substring extraction.	I-Reply	I-1	Reply	365
However, at depth 1, the predicted score of Concat is much higher than the predicted score of Atom, and thus we end up exploring only the Concat branch.	I-Reply	I-1	Reply	365
The found Concat program is incorrect because it uses absolute position indexes and does not generalize to other similar extraction tasks with different floating-point values in the input strings.	I-Reply	I-1	Reply	365
<sep> We found this scenario relatively common when the output string contains punctuation - the model considers it a strong signal for Concat.	I-Reply	I-1	Reply	365
<sep> B) "type size =  36: Bartok.	I-Reply	I-1	Reply	365
Analysis.	I-Reply	I-1	Reply	365
CallGraphNode type size =  32: Bartok.	I-Reply	I-1	Reply	365
Analysis.	I-Reply	I-1	Reply	365
CallGraphNode CallGraphNode"  ==> "36->32"	I-Reply	I-1	Reply	365
<tab>We correctly explore only the Concat branch, but the slowdown happens at the level of the `pos` symbol.	I-Reply	I-1	Reply	365
There are many different logics to extract the ‚Äú36‚Äù and ‚Äú32‚Äù substrings.	I-Reply	I-1	Reply	365
NGDS explores RelativePosition branch first, but the score of the resulting program is less then the prediction for RegexPositionRelative.	I-Reply	I-1	Reply	365
Thus, the B&B controller explores both branches anyway and we end up with a relative slowdown caused by the network inference time.	I-Reply	I-1	Reply	365

This paper extends and speeds up PROSE, a programming by example system, by posing the selection of the next production rule in the grammar as a supervised learning problem.	O	O	Review	365
<sep> <sep> This paper requires a large amount of background knowledge as it depends on understanding program synthesis as it is done in the programming languages community.	B-Review	B-1	Review	365
Moreover the work mentions a neurally-guided search, but little time is spent on that portion of their contribution.	I-Review	I-1	Review	365
I am not even clear how their system is trained.	I-Review	I-1	Review	365
<sep> <sep> The experimental results do show the programs can be faster but only if the user is willing to suffer a loss in accuracy.	B-Review	B-2	Review	365
It is difficult to conclude overall if the technique helps in synthesis.	I-Review	I-2	Review	365
> Q: Please clarify how the system is trained.	O	O	Reply	365
<sep> <sep> 1) We use the industrially collected set of 375 string transformation tasks.	B-Reply	B-1	Reply	365
Each task is a single input-output examples and 2-10 unseen inputs for evaluating generalization.	I-Reply	I-1	Reply	365
Further, we split the 375 tasks into 65% train, 15% validation, and 20% test ones.	I-Reply	I-1	Reply	365
<sep> 2) We run PROSE on each of those tasks and collect the (symbol, production, spec input, spec output -> best program score after learning) information on all nodes of the search tree.	B-Reply	B-1	Reply	365
As mentioned in the introduction, such traces provide a rich description of the synthesis problem thanks to the Markovian nature of deductive search in PROSE and enabling the creation of large datasets required for learning deep models.	I-Reply	I-1	Reply	365
As a result, we obtain a dataset of ~450,000 search outcomes from mere 375 tasks.	I-Reply	I-1	Reply	365
<sep> 3) We further split all the search outcomes by the used symbol or its depth in the grammar.	B-Reply	B-1	Reply	365
In our final evaluation, we present the results for the models trained on the decisions on the `transform` (depth=1), `pp`, `pos` symbols.	I-Reply	I-1	Reply	365
We have also trained other symbol models as well as a single common model for all symbols/depths, but they didn‚Äôt perform as well.	I-Reply	I-1	Reply	365
<sep> 4) We employ Adam (Kingma and Ba, 2014) to optimize the objective.	B-Reply	B-1	Reply	365
We use a batch size of 32 and a learning rate of 0.01 and use early stopping to pick the final model.	I-Reply	I-1	Reply	365
The model architecture and the corresponding loss function (squared error) are discussed in Section 3.1.	I-Reply	I-1	Reply	365
We will add the specific training details in the next revision of the paper.	I-Reply	I-1	Reply	365
<sep> 5) As discussed in Section 3.3, the learned models are integrated in the corresponding PROSE controller when the current search tree node matches the model's conditions (i.e. it is on the same respective symbol or depth).	B-Reply	B-1	Reply	365
<sep> <sep> > Q: Is the approach useful for synthesis when there is a loss in program accuracy?	O	O	Reply	365
<sep> <sep> In fact, NGDS achieves higher average test accuracy than baseline PROSE (68.49% vs. 67.12%), although with slightly lower validation accuracy (63.83% vs. 70.21%) which effectively corresponds to 4 tasks.	B-Reply	B-2	Reply	365
<sep> <sep> However, this is not the most important factor: PBE is bound to often fail in synthesizing the _intended_ program from a single input-output example.	I-Reply	I-2	Reply	365
Even a machine-learned ranking function picks the wrong program 20% of the time (Ellis & Gulwani, IJCAI 2017).	I-Reply	I-2	Reply	365
<sep> <sep> Thus, the main goal of this work is speeding up the synthesis process on difficult scenarios without sacrificing the generalization accuracy too much.	I-Reply	I-2	Reply	365
As a result, we achieve on average 50% faster synthesis time, with 10x speed-ups for many difficult tasks that require multiple seconds while still retaining competitive accuracy.	I-Reply	I-2	Reply	365
Appendix C shows the breakdown of time and accuracy: out of 120 validation/test tasks, there are:	I-Reply	I-2	Reply	365
- 76 tasks where both systems are correct,	I-Reply	I-2	Reply	365
- 7 tasks where PROSE learns a correct program and NGDS learns a wrong one,	I-Reply	I-2	Reply	365
- 4 tasks where PROSE learns a wrong program and NGDS learns a correct one,	I-Reply	I-2	Reply	365
- 33 tasks where both systems are wrong.	I-Reply	I-2	Reply	365

The paper presents a branch-and-bound approach to learn good programs	O	O	Review	365
(consistent with data, expected to generalise well), where an LSTM is	O	O	Review	365
used to predict which branches in the search tree should lead to good	O	O	Review	365
programs (at the leaves of the search tree).	O	O	Review	365
The LSTM learns from	O	O	Review	365
inputs of program spec + candidate branch (given by a grammar	O	O	Review	365
production rule) and ouputs of quality scores for programms.	O	O	Review	365
The issue	O	O	Review	365
of how greedy to be in this search is addressed.	O	O	Review	365
<sep> <sep> In the authors' set up we simply assume we are given a 'ranking	O	O	Review	365
function' h as an input (which we treat as black-box).	O	O	Review	365
In practice	O	O	Review	365
this will simply be a guess (perhaps a good educated one) on which	O	O	Review	365
programs will perform correctly on future data.	O	O	Review	365
As the authors	B-Review	B-2	Review	365
indicate, a more ambitious paper would consider learning h, rather	I-Review	I-2	Review	365
than assuming it as a given.	I-Review	I-2	Review	365
<sep> <sep> The paper has a number of positive features.	O	O	Review	365
It is clearly written	O	O	Review	365
(without typo or grammatical problems).	O	O	Review	365
The empirical evaluation	O	O	Review	365
against PROSE is properly done and shows the presented method working	O	O	Review	365
as hoped.	O	O	Review	365
This was a competent approach to an interesting (real)	O	O	Review	365
problem.	O	O	Review	365
However, the 'deep learning' aspect of the paper is not	B-Review	B-1	Review	365
prominent: an LSTM is used as a plug-in and that is about it.	I-Review	I-1	Review	365
Also,	I-Review	I-1	Review	365
although the search method chosen was reasonable, the only real	I-Review	I-1	Review	365
innovation here is to use the LSTM to learn a search heuristic.	I-Review	I-1	Review	365
<sep> <sep> <sep> The authors do not explain what "without attention" means.	B-Review	B-3	Review	365
<sep> <sep> <sep> I think the authors should mention the existence of (logic) program	B-Review	B-4	Review	365
synthesis using inductive logic programming.	I-Review	I-4	Review	365
There are also (closely	I-Review	I-4	Review	365
related) methods developed by the LOPSTR (logic-based program	I-Review	I-4	Review	365
synthesis and transformation) community.	I-Review	I-4	Review	365
Many of the ideas here are	I-Review	I-4	Review	365
reminiscent of methods existing in those communities (e.g. top-down search	I-Review	I-4	Review	365
with heuristics).	I-Review	I-4	Review	365
The use of a grammar to define the space of programs	I-Review	I-4	Review	365
is similar to the "DLAB" formalism developed by researchers at KU	I-Review	I-4	Review	365
Leuven.	I-Review	I-4	Review	365
<sep> <sep> ADDED AFTER REVISIONS/DISCUSSIONS	O	O	Review	365
<sep> The revised paper has a number of improvements which had led me to give it slightly higher rating.	O	O	Review	365
<sep> <sep> <sep> Thank you for the related work suggestions -- we will update this discussion in the next draft.	O	O	Reply	365
We address your concerns below:	O	O	Reply	365
<sep> > Q: Limited innovation in terms of deep learning:	O	O	Reply	365
<sep> Rather than being a pure contribution to deep learning, this work applies deep learning to the important field of program synthesis, where statistical approaches are still underexplored.	B-Reply	B-1	Reply	365
Our main contribution is a hybrid approach to program synthesis that utilizes the best of both neural and symbolic synthesis techniques.	I-Reply	I-1	Reply	365
Combining insights from both worlds in this way achieves a new milestone in program synthesis performance: from a single example it generates programs that generalize better than prior state-of-the-art (including neural RobustFill, symbolic PROSE, and hybrid DeepCoder), the generated program is provably correct, and the generation is 50% faster on average	I-Reply	I-1	Reply	365
<sep> DeepCoder (Balog et al ICLR 2017) first explored a hybrid approach last year by first predicting the likelihood of various operators and then using it to guide an external symbolic synthesis engine.	I-Reply	I-1	Reply	365
Since deep networks are data-hungry, Balog et al obtain training data by randomly sampling programs from the DSL and generating satisfying random strings as input-output examples.	I-Reply	I-1	Reply	365
As noted in Section 1 and as evidenced by its inferior performance against our method, the generated programs tend to be unnatural leading to poor generalization.	I-Reply	I-1	Reply	365
In contrast, NGDS closely integrates neural models at each step of the synthesis and so, it is possible to obtain large amounts of training data while utilizing a relatively small number of real-world examples.	I-Reply	I-1	Reply	365
<sep> <sep> > Q: Learning the ranking function instead of taking it as a given:	O	O	Reply	365
<sep> While related, this problem is orthogonal to our work: a ranking function evaluates whether a given full program generalizes well, whereas we aim to predict the generalization of the best program produced from a given partial search state.	B-Reply	B-2	Reply	365
<sep> <sep> Importantly, the proposed technique, NGDS is independent of the ranking function and can be trivially integrated with any high-quality ranking function.	I-Reply	I-2	Reply	365
For instance, the manually written ranking function of FlashFill in PROSE that we use is a result of 7 years of engineering and heavy fine-tuning for industrial applications.	I-Reply	I-2	Reply	365
An even better-quality learned ranking function would only improve the accuracy of predictions, which are already on par with baseline PROSE (68.49% vs 67.12%).	I-Reply	I-2	Reply	365
<sep> <sep> In fact, a lot of recent prior work focuses on learning a ranking function for program induction, see (Singh & Gulwani, CAV 2015) and (Ellis & Gulwani, IJCAI 2017).	I-Reply	I-2	Reply	365
For comparison, we are currently performing a set of experiments with an ML-learned ranking function; we'll update with the new results once it's done.	I-Reply	I-2	Reply	365
<sep> <sep> > Q: What does "without attention" mean?	O	O	Reply	365
<sep> <sep> All the models we explore encode input and output examples using (possibly multi-layered, bi-directional) LSTMs with or without an attention mechanism (Bahdanau et al ICLR 2015).	B-Reply	B-3	Reply	365
As mentioned in Section 8, the most accurate predictions arise when we attend to the input string while encoding the output string similar to the attention-based models proposed by Devlin et al 2017.	I-Reply	I-3	Reply	365
We will make this clearer in the next version of the paper.	I-Reply	I-3	Reply	365
<sep> <sep> Such an attention mechanism allows the network to learn complex features like "whether the output is a substring of the input".	I-Reply	I-3	Reply	365
Unfortunately, such accuracy comes at a cost of increasing the network evaluation time to quadratic instead of linear.	I-Reply	I-3	Reply	365
As a result, prediction time at every node of the search tree dominates the search time, and NGDS is slower than PROSE even when its predictions are accurate.	I-Reply	I-3	Reply	365
Therefore, we only use LSTM models without any attention mechanism in our evaluations.	I-Reply	I-3	Reply	365

The article "PairNorm: Tackling Oversmoothing in GNNs" considers the interesting phenomenon of performance degradation of graph neural network when the depth of the network increases beyond the values of 2-4.	O	O	Review	365
The authors argue that one of the reasons for such behavior is so-called "oversmoothing", when intermediate representations become similar for all the nodes in the graph.	O	O	Review	365
The authors propose the special NN layer "PairNorm", which aims to battle with this issue.	O	O	Review	365
<sep> <sep> The proposed PairNorm approach boils down to the recentering and normalization of all the representations after each graph-convolutional layer of the network.	O	O	Review	365
The authors consider 2 variants of choosing normalization constant:	O	O	Review	365
1.	O	O	Review	365
The one which multiplies all the embeddings for the layer by the same number.	O	O	Review	365
This operation allows to keep the average squared pairwise distance between node representations constant.	O	O	Review	365
<sep> 2.	O	O	Review	365
The one which makes the norms of all the representations equal to pre-specified constant, i.e. just projection of all the embeddings on the sphere.	O	O	Review	365
<sep> <sep> I should note that the two proposed approaches are very different in nature, though the latter one is introduced without much additional discussion.	O	O	Review	365
The benefits of approach 1 are not entirely clear as it basically just scales the whole embedding population.	B-Review	B-1	Review	365
Such a scaling doesn't affect the relative distances between points and thus should not have major effect on the performance.	I-Review	I-1	Review	365
Approach 2 is completely different due to the projection on the sphere of each embedding independently.	B-Review	B-2	Review	365
However, the reasons why it is a good idea or not are not discussed in the paper.	I-Review	I-2	Review	365
<sep> <sep> The experimental part of the paper considers several standard graph data sets.	O	O	Review	365
The authors report that the proposed normalization schemes do not improve the quality of classification in the standard semi-supervised learning setting.	B-Review	B-3	Review	365
They additionally consider artificially created missing features and observe increasing quality in such a scenario.	B-Review	B-4	Review	365
<sep> <sep> To sum up, I think that while the motivation behind the paper is very natural, it doesn't look like the paper finds the solution both theoretically and experimentally.	B-Review	B-5	Review	365
Thank you for giving us feedback and raising questions that help us clarify our work further.	O	O	Reply	365
We have done additional measurements and experiments to address your concerns, and these results are included in the last section of the Appendix (please see A.6 in the updated paper).	O	O	Reply	365
<sep> <sep> We address the reviewer's questions one-by-one in the following.	O	O	Reply	365
<sep> <sep> &gt;&gt; "The benefits of approach 1 are not entirely clear as it basically just scales the whole embedding population.	O	O	Reply	365
Such a scaling doesn't affect the relative distances between points and thus should not have major effect on the performance."	O	O	Reply	365
<sep> <sep> The second step (Eq.11) of PairNorm scales the length of each node representation by multiplying by a scalar calculated from all node representations, the L2-distance between any two node representations is also scaled accordingly.	B-Reply	B-1	Reply	365
If we understand correctly, the "relative distances among points" is referring to the ratio between any two distances.	I-Reply	I-1	Reply	365
We claim that although PairNorm itself does not change the ratio, GraphConv + PairNorm does change it: the ratios are not the same across all layers‚Äô representations.	I-Reply	I-1	Reply	365
In Appendix A.6 we also empirically plot the distributions of pairwise distances, where one could see how all pairwise distances change with increasing number of layers.	I-Reply	I-1	Reply	365
&gt;&gt; "Approach 2 is completely different due to the projection on the sphere of each embedding independently.	O	O	Reply	365
However, the reasons why it is a good idea or not are not discussed in the paper."	O	O	Reply	365
<sep> <sep> PairNorm-SI (approach 2) achieves a similar goal of making total pairwise distances stable, by adding more restrictions: instead of normalizing by the sum of all squared lengths, it normalizes any squared length directly.	B-Reply	B-2	Reply	365
It is true that total pairwise squared distances is not exactly constant mathematically in that case, however approach 2 nevertheless does keep it stable empirically.	I-Reply	I-2	Reply	365
We have put a lot effort to analyzing PairNorm-SI in the new section A.6 of the Appendix ‚Äî please have a look and read it through; we believe it provides the the answer you are looking for.	I-Reply	I-2	Reply	365
<sep> <sep> &gt;&gt; "The authors report that the proposed normalization schemes do not improve the quality of classification in the standard semi-supervised learning setting."	O	O	Reply	365
<sep> ‚Ä®	O	O	Reply	365
Yes, this is correct.	B-Reply	B-3	Reply	365
We find that solving oversmoothing problem would not improve the performance of SSL on the standard benchmark datasets.	I-Reply	I-3	Reply	365
The reasons are two-fold.	I-Reply	I-3	Reply	365
First, the best performance of SSL on standard datasets is achieved within less than 3 layers, at which oversmoothing does not happen.	I-Reply	I-3	Reply	365
Rather, we obtain a smoothing effect, which is in fact beneficial.	I-Reply	I-3	Reply	365
In such cases, clearly PairNorm is not needed as it is designed to solve the oversmoothing issue for deep GNNs.	I-Reply	I-3	Reply	365
Second, smoothing is the key effect of Graph Convolution to achieve good performance for SSL, as it improves the generalization ability of the model by reducing the gap between training loss and validation loss.	I-Reply	I-3	Reply	365
This is clearly shown in Figure 1, where the gap between training loss and validation/test loss shrinks with increasing number of layers.	I-Reply	I-3	Reply	365
Generalization ability is the most important factor for improving performance, and this is true particularly for SSL where we only have a very small training set, which makes the empirical risk not reliable for estimating true risk.	I-Reply	I-3	Reply	365
Empirically, we often see the training loss for SSL goes to 0 easily while validation loss is still large. ‚	I-Reply	I-3	Reply	365
Ä®‚Ä®	O	O	Reply	365
<sep> &gt;&gt; "They additionally consider artificially created missing features and observe increasing quality in such a scenario."	O	O	Reply	365
<sep> <sep> ‚Ä®We should state that although SSNC-MF is created by randomly removing features, this scenario is generally existing in the real-world.	B-Reply	B-4	Reply	365
We have given example scenarios in our paper, another example would be privacy-related problems: for training ML algorithms, many companies can only release/use small fraction of users' data based on the privacy agreement.	I-Reply	I-4	Reply	365
PairNorm is designed to solve oversmoothing, and SSNC-MF is such a problem where oversmoothing does happen as this scenarios necessitates training deep GNNs.	I-Reply	I-4	Reply	365
While for SSL on standard datasets oversmoothing has no relationship with the best performance, in order to show the power and ability of PairNorm at solving oversmoothing, we needed to showcase a scenario where oversmoothing hurts the best possible performance.	I-Reply	I-4	Reply	365
<sep> <sep> _____	O	O	Reply	365
We hope our answers sufficiently addresses your concerns.	B-Reply	B-5	Reply	365
To wrap up, we would like to to re-emphasize the contributions of PairNorm:	I-Reply	I-5	Reply	365
<sep> 1.	I-Reply	I-5	Reply	365
Solving oversmoothing problem and making training deep GNNs possible for the node-classification scenario,  having solid theoretical analysis over SGC.	I-Reply	I-5	Reply	365
<sep> 2.	I-Reply	I-5	Reply	365
PairNorm is a general "patch" -- applicable to any GNN.	I-Reply	I-5	Reply	365
It can also be applied in any layer, even if say we change the graph structure at each layer.	I-Reply	I-5	Reply	365
<sep> 3.	I-Reply	I-5	Reply	365
PairNorm is the first normalization layer specifically designed for graph neural networks.	I-Reply	I-5	Reply	365
We hope that more researchers can delve into this area.	I-Reply	I-5	Reply	365
4.	I-Reply	I-5	Reply	365
We are also the first to investigate a new scenario, such as the SSNC-MF problem.	I-Reply	I-5	Reply	365

Summary	O	O	Review	365
<sep> It is known that GNNs are vulnerable to the oversmoothing problem, in which feature vectors on nodes get closer as we increase the number of (message passing type graph convolution layers).	O	O	Review	365
This paper proposed PairNorm, which is a normalization layer for GNNs to tackle this problem.	O	O	Review	365
The idea is to pull apart feature vectors on a pair of non-adjacent nodes (based on the interpretation of Laplace-type smoothing by NT and Maehara (2019)).	O	O	Review	365
To achieve this approximately with low computational complexity, PairNorm keeps the sum of distances of feature vectors on all node pairs approximately the same throughout layers.	O	O	Review	365
The paper conducted empirical studies to evaluate the effectiveness of the method.	O	O	Review	365
PairNorm improved the prediction performance and enabled make GNNs deep, especially when feature vectors are missing in the large portion of nodes (the SSNC-MV problem).	O	O	Review	365
<sep> <sep> <sep> Decision	O	O	Review	365
<sep> I want to recommend to accept the paper because, in my opinion, this paper contributes to deepening our understanding of graph NNs by giving new insights into what causes the oversmoothing problem and which types problem (deep) graph NNs can solve.	O	O	Review	365
<sep> The common myth about graph NNs is that they cannot make themselves deep due to the oversmoothing.	O	O	Review	365
Therefore, oversmoothing is one of the big problems in the graph NN field and has been paid attention from both theoretical and empirical sides.	O	O	Review	365
This paper found that the deep structures do help to improve (or at least worsen) the predictive performance when the significant portion of nodes in a graph does not have input signals.	O	O	Review	365
To the best of our knowledge, this is the first paper that showed the effectiveness of deep structures in citation network datasets (Deep GCNs [Li et al 2019] successfully improved the prediction performance of (residual) graph NNs using as many as 56 layers for point cloud datasets).	O	O	Review	365
The proposed method is theoretically backboned, easy to implement, and applicable to (theoretically) any graph NNs.	O	O	Review	365
Taking these things into account, I would like to judge the contribution of this paper is sufficiently significant to accept.	O	O	Review	365
<sep> <sep> <sep> Minor Comments	O	O	Review	365
<sep> <tab>- Table 3.	B-Review	B-1	Review	365
Remove s in the entry for GAT-t2 Citeseer 0%.	I-Review	I-1	Review	365
<sep> <sep> <sep> Questions	O	O	Review	365
<sep> <tab>- Can we interpret PairNorm (or the optimization problem (6)) from the viewpoint of graph spectra?	B-Review	B-2	Review	365
<sep> <tab>- Although the motivation of Centering (10) is to ease the computation of TPD, I am curious how this operation contributes to performance.	B-Review	B-3	Review	365
Since the constant signal does not have information for distinguishing nodes, eliminating it by Centering might result in emphasizing the signal component for nodes classification tasks.	I-Review	I-3	Review	365
From a spectral point of view, Centering corresponds to eliminating the lowest frequency of a signal.	I-Review	I-3	Review	365
<sep> <tab>- Figures 3 and 7 have shown that GCN and GAT did not perform well compared to SGC when the layer size increases.	B-Review	B-4	Review	365
The authors discussed that this is because GCN and GAT are easier to overfit.	I-Review	I-4	Review	365
However, SGC chose the hyperparameter from, whereas the authors examined a single for GCN and GAT.	I-Review	I-4	Review	365
Therefore, I think there is another hypothesis that simply the choice was misspecified.	I-Review	I-4	Review	365
If this is the case, I am interested in the effect of on predictive performance.	I-Review	I-4	Review	365
<sep> <sep> [Li et al 2018] Li, Qimai, Zhichao Han, and Xiao-Ming Wu. "	O	O	Review	365
Deeper insights into graph convolutional networks for semi-supervised learning."	O	O	Review	365
Thirty-Second AAAI Conference on Artificial Intelligence.	O	O	Review	365
2018.	O	O	Review	365
Thank you very much for reading our paper thoroughly and giving constructive feedback, and we are glad that you found our paper interesting and contributing to a deeper understanding of the field.	O	O	Reply	365
We respond to your questions one-by-one in the following.	O	O	Reply	365
<sep> <sep> &gt;&gt; Can we interpret PairNorm (or the optimization problem (6)) from the viewpoint of graph spectra?	O	O	Reply	365
<sep> That is a great question that we have not thought about before.	B-Reply	B-2	Reply	365
We are doing new work towards understanding stacking GraphConv operations in the spectral domain, but currently we do not have a complete answer for your question.	I-Reply	I-2	Reply	365
To give some initial thought: The operation is working on features directly.	I-Reply	I-2	Reply	365
Since it does not change the graph structure, it does not affect the eigenvectors or spectrum of the graph.	I-Reply	I-2	Reply	365
However, it will affect the alignment/interaction between structure and features.	I-Reply	I-2	Reply	365
Understanding the fusion between graph structure and features in spectral domain should be investigated more carefully.	I-Reply	I-2	Reply	365
<sep> <sep> <sep> &gt;&gt; Although the motivation of Centering (10) is to ease the computation of TPD, I am curious how this operation contributes to performance.	O	O	Reply	365
<sep> <sep> We have tested adding the mean back after Scale operation, and for SGC the performance remained the same.	B-Reply	B-3	Reply	365
However for GCN and GAT, because of the activation function there will be a big difference.	I-Reply	I-3	Reply	365
Empirically, they have similar performance but sometimes one is better and the other is worse.	I-Reply	I-3	Reply	365
One does not seem to dominate the other.	I-Reply	I-3	Reply	365
<sep> <sep> <sep> &gt;&gt;  Therefore, I think there is another hypothesis that simply the choice was misspecified.	O	O	Reply	365
If this is the case, I am interested in the effect of on predictive performance.	O	O	Reply	365
<sep> <sep> ‚Ä®We did several tests using different for the SSNC problem, and we found that does not affect performance much for GCN and GAT.	B-Reply	B-4	Reply	365
We think this is because the parameter learning has some connection with the scale, so setting different is not that important.	I-Reply	I-4	Reply	365
We do not have enough time for doing a thorough testing for all settings, as GCN and GAT are much slower to train than SGC.	I-Reply	I-4	Reply	365
To sum up, we think it is not surprising that SGC works very well for these settings, which is also demonstrated in the original SGC paper (Wu et al 2019).	I-Reply	I-4	Reply	365

Authors improve upon dynamic routing between capsules by removing the squash function (norm normalization) and apply a layerNorm normalization instead.	O	O	Review	365
Furthermore, they experiment with concurrent routing rather than sequential routing (route all caps layers once, then all layers concurrently again and again).	O	O	Review	365
This is an interesting development since provides better gradient in conjunction with layerNorm.	O	O	Review	365
They report results on Cifar10 and Cifar100 and achieve similar to CNN (resnet) performance.	O	O	Review	365
<sep> <sep> First, I want to point out that inverted attention is exactly what happens in dynamic routing (sabour et al 2017), proc.	B-Review	B-1	Review	365
1 line 4,5, and 7.	I-Review	I-1	Review	365
In dynamic routing the dot product with the next layer capsule is calculated and then normalized over all next layer capsules.	I-Review	I-1	Review	365
The only difference that I notice between alg.	I-Review	I-1	Review	365
1 here and proc.	I-Review	I-1	Review	365
1 there is replacement of squash with layer norm.	I-Review	I-1	Review	365
There is no "reconstructing the layer bellow" in Dynamic routing as authors suggest in intro.	I-Review	I-1	Review	365
<sep> <sep> Second, the Capsules are promised to have better viewpoint generalizability than CNNs while having comparable performance.	B-Review	B-2	Review	365
Replacing the 1 convolution layer with a ResNet backbone and replacing the activation with a classifier on top seems reducing the proposed CapsNet to the level of CNNs in terms of Viewpoint Generalization.	I-Review	I-2	Review	365
Why should someone use this network rather than the ResNet itself?	I-Review	I-2	Review	365
Fewer number of parameters by itself is not interesting, the reason it is reported usually is that it indicates lower memory consumption or fewer flops.	I-Review	I-2	Review	365
Is that the case when comparing the baseline ResNet with the proposed CapsNet?	I-Review	I-2	Review	365
Otherwise, a set of experiments showcasing the viewpoint generalizability of proposed CapsuleNetworks might only justify the switch between resnets to the proposed capsnets.	I-Review	I-2	Review	365
<sep> <sep> Thirdly, Fig.4 top images seems to indicate all 3 routing procedures are following the same Learning Rate schedule.	B-Review	B-3	Review	365
In the text it is said that optimization hyperparameters are tuned individually.	I-Review	I-3	Review	365
Did authors tune learning rate schedule individually?	I-Review	I-3	Review	365
<sep> <sep> Forth, the proper baseline for the current study is the dynamic routing CapsNet.	B-Review	B-4	Review	365
Why the multiMNIST experiment lacks comparison with dynamic routing capsnet?	I-Review	I-4	Review	365
<sep> <sep> For the reasons above, the manuscript in its current format is not ready for publication.	O	O	Review	365
<sep> <sep> ------------------------------------------------------rebuttal	O	O	Review	365
Thank you for your response.	B-Review	B-1	Review	365
I acknowledged the novel contributions of this work.	I-Review	I-1	Review	365
My comment was that some claims in the paper are not right.	I-Review	I-1	Review	365
i.e. "inverted dot-product attention" is not new and "reconstructing the layer bellow" does not happen in Sabour et al .	I-Review	I-1	Review	365
Parallel execution + layer norm definitely is novel and significant.	I-Review	I-1	Review	365
<sep> <sep> Regarding the LR-schedule, I am not sure how fair it is to use same hyper-params tuned for the proposed method on the baselines.	B-Review	B-3	Review	365
<sep> <sep> Regarding the viewpoint, the diverseMultiMNIST is two over lapping MNIST digits shifted 6 pixels.	B-Review	B-4	Review	365
There is no rotation or scale in this dataset.	I-Review	I-4	Review	365
An example experiment verifying the viewpoint generalizability of the proposed model is training on MNIST testing on AFFNIST.	I-Review	I-4	Review	365
<sep> <sep> We thank the Reviewer for constructive feedback.	O	O	Reply	365
We hope the following response will address the concerns of the Reviewer.	O	O	Reply	365
<sep> [Remarks on Inverted Dot-Product Attention Routing]	O	O	Reply	365
We agree that our routing method has similar components to Dynamic Routing (Sabour et al 2017), and we would like to emphasize their differences : 1) Sequential iterative routing is replaced with concurrent iterative routing, 2) Squash activation is replaced with Layer Normalization, and 3) We use cross-entropy loss instead of margin loss.	B-Reply	B-1	Reply	365
The comparison is summarized in Section 4.3.	I-Reply	I-1	Reply	365
<sep> <sep> We humbly argue that these modifications are not trivial and stabilize the training, which leads to improved performance.	I-Reply	I-1	Reply	365
For example, we observe that only our model has improved performance when the routing iteration number increases (CIFAR10 classification Table of Figure 4).	I-Reply	I-1	Reply	365
<sep> ============================================	I-Reply	I-1	Reply	365
Method   | Iteration=1 | Iteration = 3 | Iteration = 5	I-Reply	I-1	Reply	365
Dynamic  |    84.08%     |    82.88%       |    82.11%	I-Reply	I-1	Reply	365
EM            |    58.08%     |    78.43%       |    31.41%	I-Reply	I-1	Reply	365
Ours         |    84.24%     |    84.83%       |    85.09%	I-Reply	I-1	Reply	365
============================================	I-Reply	I-1	Reply	365
<sep> [Remarks on using ResNet]	O	O	Reply	365
We agree that using a deeper CNN such as a ResNet (vs. a single convolutional layer) to produce primary capsules makes our model inherit the disadvantages of CNNs (such as less view-point generalizability) and blunts the potential impact of capsules.	B-Reply	B-2	Reply	365
However, at this stage, our intent is not to replace CNNs completely with CapsNets, but take a meaningful step towards building a routing mechanism that can at least do the job of the higher layers of a CNN.	I-Reply	I-2	Reply	365
Previously proposed routing algorithms fail to do so and perform worse than their baseline CNNs.	I-Reply	I-2	Reply	365
<sep> ==================================================	I-Reply	I-2	Reply	365
Method                                                                      |  Accuracy	I-Reply	I-2	Reply	365
-----------------------------------------------------------------------------	I-Reply	I-2	Reply	365
Dynamic routing with DenseNet backbone [1]  |   89.71%	I-Reply	I-2	Reply	365
-----------------------------------------------------------------------------	I-Reply	I-2	Reply	365
Dynamic routing with ResNet backbone             |   92.65%	I-Reply	I-2	Reply	365
EM routing with ResNet backbone                       |   92.15%	I-Reply	I-2	Reply	365
Our routing with ResNet backbone                      |   95.14%	I-Reply	I-2	Reply	365
-----------------------------------------------------------------------------	I-Reply	I-2	Reply	365
Original ResNet                                                        |   95.11%	I-Reply	I-2	Reply	365
==================================================	I-Reply	I-2	Reply	365
[1] Phaye et al ‚ÄúDense and Diverse Capsule Networks: Making the Capsules Learn Better.	O	O	Reply	365
‚Äù Arxiv 2018.05.	O	O	Reply	365
<sep> <sep> [Remarks on Memory Consumption]	O	O	Reply	365
<sep> Ôº∑e agree with the Reviewer that reporting only the number of parameters may not be satisfying.	B-Reply	B-2	Reply	365
Therefore, in Figure 5, we report the memory consumption comparisons between CapsNets and CNNs given the same model architecture.	I-Reply	I-2	Reply	365
Please see the response to Reviewer #1, where we outline the reasons for why CapsNets consume more memory compared to CNNs even with fewer parameters, and we also suggest some possible solutions on reducing memory consumption, which we leave as our future work.	I-Reply	I-2	Reply	365
<sep> <sep> We also like to point out that the networks with fewer model parameters but larger runtime memory footprint may still be preferable for certain IC designs, where the L1 cache can store all the parameters.	I-Reply	I-2	Reply	365
<sep> [Learning Rate Scheduler]	O	O	Reply	365
We use the same learning rate scheduler for all three models.	B-Reply	B-3	Reply	365
The learning rate degrades by 0.1 on the 150th and 250th epochs.	I-Reply	I-3	Reply	365
In the original submission, we have included these details in Section A.1 in Supplementary.	I-Reply	I-3	Reply	365
<sep> <sep> [Dynamic Routing Methods for DiverseMultiMNIST]	O	O	Reply	365
We provide the results for the Dynamic routing method by applying it on the DiverseMultiMNIST dataset.	B-Reply	B-4	Reply	365
For a fair comparison, we consider the same optimizer, the same number of layers, and the same number of neurons per layer for the Dynamic routing method and the other methods.	I-Reply	I-4	Reply	365
<sep> <sep> The results are highlighted below (CapsNet denotes our routing method):	I-Reply	I-4	Reply	365
================================================	I-Reply	I-4	Reply	365
Method    |  Pose Structure  | Test Acc.	I-Reply	I-4	Reply	365
|   # params.	I-Reply	I-4	Reply	365
<sep> -----------------------------------------------------------------------------	I-Reply	I-4	Reply	365
Dynamic  |      vector              |  83.39%    |   42.48M	I-Reply	I-4	Reply	365
-----------------------------------------------------------------------------	I-Reply	I-4	Reply	365
CapsNet   |      matrix             |  80.59%    |   9.96M	I-Reply	I-4	Reply	365
CapsNet   |      vector              |  85.74%    |   42.48M	I-Reply	I-4	Reply	365
-----------------------------------------------------------------------------	I-Reply	I-4	Reply	365
BaselineCNN                |  79.81%    |   19.55M	I-Reply	I-4	Reply	365
================================================	I-Reply	I-4	Reply	365
<sep> Compared to the Baseline CNN, both our routing method and the Dynamic routing method achieve better performance on the DiverseMultiMNIST dataset.	I-Reply	I-4	Reply	365
This result suggests a better viewpoint generalization from CNNs to the Capsule networks.	I-Reply	I-4	Reply	365
Furthermore, our routing method outperforms the Dynamic routing one.	I-Reply	I-4	Reply	365
We have updated our manuscript with these results.	I-Reply	I-4	Reply	365

<sep> This paper presents a new simpler routing mechanism for capsule networks and achieves good performance on real world data sets making use of this new capsule structure along with a restnet backbone.	O	O	Review	365
Strong performance on the cifar10 and cifar100 datasets are presented and the network outperforms earlier versions of capsule networks.	O	O	Review	365
This new structure also performs well on an augmented MNIST dataset of overlapping digits (similar to the one used by Sabour et al 2017).	O	O	Review	365
<sep> <sep> Overall the paper is well written and presents solid results.	O	O	Review	365
The paper also presents a thorough comparison of two earlier versions of capsules which is a worthwhile contribution in its own right.	O	O	Review	365
<sep> <sep> The paper could be improved by clearing up a few ambiguities:	O	O	Review	365
<sep> - is the learning rate schedule the same for all three models?	B-Review	B-1	Review	365
in figure 4 it looks like the learning rate is decayed at two distinct points for your model, but only one distinct point for both the EM and Dynamic routing models.	I-Review	I-1	Review	365
<sep> -"Notably, the prediction becomes random guess when the iteration number increases to 5."	B-Review	B-2	Review	365
this sentence is a little confusing.	I-Review	I-2	Review	365
Do you mean when the iteration number the performance is equivalent to not random assignments?	I-Review	I-2	Review	365
<sep> - This new algorithm requires that the capsules in L+1 have initialized poses with which to compare agreement between the poses in L. This is initial value seems like it may greatly effect the performance of the model.	B-Review	B-3	Review	365
In the paper it is set to 0 and not expanded upon.	I-Review	I-3	Review	365
It would be interesting to see if randomizing this value, or learning a bias for it would effect performance.	I-Review	I-3	Review	365
<sep> -unlike the two previous versions of capsules, the inverted dot product capsules show in figure 4 sudden huge decreases in test accuracy while training.	B-Review	B-4	Review	365
These moments seem to be overcome quite quickly and the model ends up outperforming the other two.	I-Review	I-4	Review	365
But it would be worth mentioning this behavior and perhaps attempting to explain it.	I-Review	I-4	Review	365
<sep> <sep> We thank the Reviewer for the valuable feedback.	O	O	Reply	365
<sep> <sep> [Learning Rate Scheduler]	O	O	Reply	365
We use the same learning rate scheduler for all three models.	B-Reply	B-1	Reply	365
The learning rate degrades by 0.1 on the 150th and 250th epochs.	I-Reply	I-1	Reply	365
There are two distinct points for both the EM and Dynamic routing models, yet the second point is more noticeable when zooming in the convergence plot in Figure 4.	I-Reply	I-1	Reply	365
<sep> <sep> The difference between all three models is the type of optimization method used.	I-Reply	I-1	Reply	365
We use SGD for our model, and we use Adam for Dynamic and EM routing models.	I-Reply	I-1	Reply	365
The type of the optimization method is selected to reach the best performance for each model.	I-Reply	I-1	Reply	365
For example, SGD leads to worse performance than Adam for the Dynamic routing model.	I-Reply	I-1	Reply	365
<sep> <sep> In the original submission, we have included these details in Section A.1 in Supplementary.	I-Reply	I-1	Reply	365
<sep> <sep> [Uniform Prediction in Table in Figure 4]	O	O	Reply	365
For Inverted Dot-Product Attention-A, when routing iteration increases to 5, we observe NaN values in neural network parameters.	B-Reply	B-2	Reply	365
The prediction result becomes uniform across all classes.	I-Reply	I-2	Reply	365
Since we consider a 10-class classification, the prediction accuracy becomes 10.00%.	I-Reply	I-2	Reply	365
We rephrase the ‚Äúrandom guess‚Äù to ‚Äúuniform prediction‚Äù in the revised manuscript.	I-Reply	I-2	Reply	365
<sep> <sep> [Non-zero Pose Initilization]	O	O	Reply	365
We thank the Reviewer for raising the discussion about the capsule's initialization.	B-Reply	B-3	Reply	365
As compared to 0 initialization, we observe that a random initialization leads to a similar converged performance but slower convergence speed.	I-Reply	I-3	Reply	365
On the other hand, learning biases for capsules results in similar converged performance and same convergence speed.	I-Reply	I-3	Reply	365
As a summary, we initialize the capsule's value to 0 for simplicity.	I-Reply	I-3	Reply	365
We include the discussion in the revised manuscript.	I-Reply	I-3	Reply	365
<sep> <sep> [Sudden Performance Jump in Convergence Plot in Figure 4]	O	O	Reply	365
The phenomenon of the performance jump is due to applying LayerNorm on the low-dimensional pose.	B-Reply	B-4	Reply	365
To be more precise, the dimension of the pose used in the convergence plot is 16, and we apply LayerNorm to these 16 units.	I-Reply	I-4	Reply	365
When increasing the pose‚Äôs dimension, the jittering no longer existed.	I-Reply	I-4	Reply	365
Nevertheless, we empirically find that it does not affect the model‚Äôs prediction result once the model converges.	I-Reply	I-4	Reply	365
<sep> <sep> In the original submission, we have included these details in the last few sentences of the Convergence Analysis in Section 5.	I-Reply	I-4	Reply	365

In this paper, the authors propose a simple and effective routing algorithm for capsule networks.	O	O	Review	365
The paper is well written.	O	O	Review	365
A nice analysis of the proposed routing algorithm is provided.	O	O	Review	365
Experiments of varying the routing iterations demonstrate the stableability of proposed routing algorithm compared to others.	O	O	Review	365
<sep> <sep> Here are some issues:	O	O	Review	365
1.	O	O	Review	365
Would the authors release the code for reproducing the results in the paper?	B-Review	B-1	Review	365
It will be helpful for future research in this area.	I-Review	I-1	Review	365
<sep> <sep> 2.	B-Review	B-2	Review	365
In Fig.5, it would be better to give some brief explanations about why CasNet (Matrix) occupies much more memory while possessing less parameters.	I-Review	I-2	Review	365
We thank the Reviewer for their valuable feedback.	O	O	Reply	365
<sep> <sep> [Code]	O	O	Reply	365
We will release the code.	B-Reply	B-1	Reply	365
Reproducibility is our priority.	I-Reply	I-1	Reply	365
<sep> <sep> [Higher Memory Usage than CNNs]	O	O	Reply	365
Two main reasons result in higher memory usage than CNNs.	B-Reply	B-2	Reply	365
<sep> <sep> The first reason is that we perform iterative routing, which means that we perform routing multiple times.	I-Reply	I-2	Reply	365
Since CapsNet is a weight-tied architecture, the memory usage scales linearly with the number of iterations.	I-Reply	I-2	Reply	365
The details can be found in the illustration in Figure 3 and the bar plot of memory usage in Figure 4.	I-Reply	I-2	Reply	365
Note that this phenomenon is also observed in Deep Equilibrium Models (DEQs) [1]. Inspired by DEQs, a potential solution is to refer to a fixed-point optimization for finding equilibrium points of the routing updates.	I-Reply	I-2	Reply	365
Then, we can enjoy the benefits of constant memory.	I-Reply	I-2	Reply	365
<sep> <sep> The second reason is that CapsNet uses the routing mechanism.	I-Reply	I-2	Reply	365
As compared to the operations in CNNs, the routing mechanism performs agreement calculation between layers.	I-Reply	I-2	Reply	365
This calculation introduces additional memory usage.	I-Reply	I-2	Reply	365
However, we note that the routing mechanism is a dense operation, which means that we need to perform routing between all lower-layer capsules and all higher-layer capsules.	I-Reply	I-2	Reply	365
We can instead randomly sample the capsules for routing, making the routing mechanism a sparse operation.	I-Reply	I-2	Reply	365
We leave this dense-to-sparse modification as our future work.	I-Reply	I-2	Reply	365
<sep> <sep> <sep> [1] ‚ÄúDeep equilibrium models‚Äù, S Bai, JZ Kolter, and V Koltun.	O	O	Reply	365
NeurIPS 2019.	O	O	Reply	365

This paper proposes a type of conditional Information Bottleneck (IB) that addresses the following problem: given that some features may be expensive to obtain for use in prediction, when should they be obtained such that the overall benefit outweighs the cost?	O	O	Review	20645
A variant of the IB is proposed to model this question.	O	O	Review	20645
However, optimization is intractable.	O	O	Review	20645
The paper replaces a certain non-differentiable operation by a deterministic neural network which outputs the probability of seeking the expensive features.	O	O	Review	20645
The main application here is reinforcement learning, where an agent could compute some plan or communicate with other agents at a cost, and the goal is to solve the task more efficiently while making use of this additional information.	O	O	Review	20645
It is shown that the proposed method, VBB, makes judicious use of the limited number of costly feature acquisitions it makes, resulting in improved task performance across 3 tasks.	O	O	Review	20645
<sep> <sep> I am not an expert on the topic, but I find that this paper is well-written and tackles a basic question with effective methods that work well in practice.	O	O	Review	20645
<sep> <sep> However, since the problem is so basic, I wonder how it connects to active learning or more specifically "active feature acquisition":	B-Review	B-1	Review	20645
<sep> -Saar-Tsechansky, Maytal, Prem Melville, and Foster Provost. "	B-Review	B-3	Review	20645
Active feature-value acquisition."	I-Review	I-3	Review	20645
Management Science 55.4 (2009): 664-684.	I-Review	I-3	Review	20645
<sep> -Shim, Hajin, Sung Ju Hwang, and Eunho Yang. "	I-Review	I-3	Review	20645
Joint active feature acquisition and classification with variable-size set encoding."	I-Review	I-3	Review	20645
Advances in Neural Information Processing Systems.	I-Review	I-3	Review	20645
2018.	I-Review	I-3	Review	20645
<sep> -Ma, Chao, et al "Eddi: Efficient dynamic discovery of high-value information with partial VAE."	I-Review	I-3	Review	20645
arXiv preprint arXiv:1809.11142 (2018).	I-Review	I-3	Review	20645
<sep> <sep> Minor:	B-Review	B-2	Review	20645
- "((Bahdanau et al 2014; Mnih et al 2014; Xu et al 2015))": double parentheses	I-Review	I-2	Review	20645
- "minimizing unnecessary access? .	I-Review	I-2	Review	20645
We compare": drop the .	I-Review	I-2	Review	20645
after ?	I-Review	I-2	Review	20645
<sep> - "to dynamically adjusts" --&gt; "to dynamically adjust"	I-Review	I-2	Review	20645
- "The agent always access the" --&gt; "The agent always accesses the"	I-Review	I-2	Review	20645
- "Tables 3a, 3b compares": no such tables in the paper	I-Review	I-2	Review	20645
- "each method acsess the" --&gt; "each method accesses the"	I-Review	I-2	Review	20645
We thank the reviewer for their feedback and their generally positive assessment of our work.	O	O	Reply	20645
<sep> <sep> ‚ÄúI wonder how it connects to active learning or more specifically "active feature acquisition"	O	O	Reply	20645
<sep> We thank the reviewer for pointing this out.	B-Reply	B-1	Reply	20645
We agree that their are some intriguing connections to ‚Äúactive feature acquisition‚Äù.	I-Reply	I-1	Reply	20645
More generally, the  efficient use of limited computational resources is probably an important ingredient.	I-Reply	I-1	Reply	20645
There‚Äôs a whole field of rational meta-reasoning which decide which computations to perform but this is computationally intractable.	I-Reply	I-1	Reply	20645
VBB provides a tractable way to maintain a trade-off b/w ‚Äúcost‚Äù of performing a computation, and ‚Äúvalue‚Äù of computation, in the sense perform a computation if value of computation exceeds that of the cost of computation.	I-Reply	I-1	Reply	20645
Future work would be to rigorously study this in active feature acquisition scenario.	I-Reply	I-1	Reply	20645
<sep> <sep> <sep> ‚ÄúTypos‚Äù	O	O	Reply	20645
<sep> We thank the reviewer for pointing out these corrections.	B-Reply	B-2	Reply	20645
We would update it in the next version of the paper.	I-Reply	I-2	Reply	20645
<sep> <sep> ‚ÄúReferences‚Äù	O	O	Reply	20645
<sep> We thank the reviewer for those references.	B-Reply	B-3	Reply	20645
We‚Äôll look into them.	I-Reply	I-3	Reply	20645
<sep> <sep> Are there any other experiments or clarifications that we can provide such that would help to improve the understanding of our work and hence making it more likely for you to raise your score?	B-Reply	B-4	Reply	20645
<sep> <sep> Thanks again for your time in reviewing our submission.	O	O	Reply	20645
We really appreciate it.	O	O	Reply	20645

Summary - The paper proposes an approach, called the Variational Bandwidth Bottleneck (VBB), capable of compressing only a part of the input and still learn representations that are informative of the output.	O	O	Review	20645
The approach is motivated from the following perspective -- there might be situations where a ``part‚Äô‚Äô of the input is privileged in the sense that it may be costly / wasteful to maintain access to all the time, thereby rendering the standard IB pipeline infeasible (as it requires unrestricted access to the entire input).	O	O	Review	20645
By breaking down the input into standard (always available) and privileged (not always available) components, the paper proposes a module that decides whether to access the privileged input during compression based on the standard input.	O	O	Review	20645
The goal is to be able to decide when to access privileged information and not how to break the overall input into standard and privileged components.	O	O	Review	20645
The approach tackles a narrow subset of problems compared to the standard information bottleneck.	O	O	Review	20645
The authors show the applicability of the proposed approach in reinforcement learning setups -- specifically, (1) when to access an expensive model-based planner for goal-driven navigation; (2) when to access goal-information in goal-driven navigation and (3) treating communication in a multi-agent cooperative setting as ``privileged‚Äô‚Äô information.	O	O	Review	20645
The experimental results demonstrate that VBB accesses privileged information in a feasible and minimal manner and results in better generalization performance.	O	O	Review	20645
<sep> <sep> Strengths	O	O	Review	20645
<sep> - Apart from the flaws (highlighted in weaknesses), the paper is well-written and generally easy to follow.	O	O	Review	20645
<sep> <sep> - The problem statement is well-motivated.	O	O	Review	20645
The authors did a good job of first identifying when the standard IB approach would be infeasible / costly -- even though representations are compressed and relevant, computing them still requires unrestricted access to input -- and then motivating the need for selective access to information while decision-making.	O	O	Review	20645
The problem is well-grounded in the experimental settings the authors provide results for.	O	O	Review	20645
<sep> <sep> - Apart from the concerns (highlighted in weaknesses), the experimental results generally support the claims of the paper.	O	O	Review	20645
Results in Sec.7.1 (loosely) demonstrate that VBB accesses privileged information states where degree of freedom in terms of possible trajectories is higher -- this result, although not explored in it‚Äôs entirety, also correlates with notions of decision-states (as pointed out by authors) and bottleneck states in the existing literature.	O	O	Review	20645
Results in Sec.7.2 demonstrate improved generalization performance in terms of transfer.	O	O	Review	20645
Additionally, results in Table.3 suggest that VBB accesses privileged information the least number of times.	O	O	Review	20645
Similarly, results in Sec.7.3 indicate VBB results in improvements in performance in the multi-agent setting while resulting in minimal communication among the agents.	O	O	Review	20645
The baselines being compared with in the paper are also reasonable.	O	O	Review	20645
<sep> <sep> - The problem statement and the proposed approach have some degree of novelty.	O	O	Review	20645
Most works along the lines of restricting access to relevant information still assume unrestricted access to the `entire‚Äô information.	O	O	Review	20645
<sep> <sep> Weaknesses	O	O	Review	20645
<sep> That being said, the paper does have some flaws / clarity issues that make several associated details confusing when judged in context of prior work.	O	O	Review	20645
These concerns (in addition to the strengths highlighted above) mostly surrounding experiments form the basis of my rating and addressing these would definitely make the paper stronger.	O	O	Review	20645
<sep> <sep> - One of the underlying motivations / intuitions behind restricting access to the privileged information is that fact that -- ‚Äú..avoid accessing the privileged input because we want to generalize with respect to it..‚Äù.	B-Review	B-1	Review	20645
This statement in isolation is misleading and makes things unclear.	I-Review	I-1	Review	20645
From a complete generalization standpoint, preventing the encoder from overfitting to the input (‚Äòprivileged‚Äô or ‚Äòstandard‚Äô) can be addressed by just tracking the relevance (predictive performance) based on the representations on a held-out set.	I-Review	I-1	Review	20645
Unless I am missing something, generalization of the learned representations in standard IB becomes major problem only when we restrict (costly or otherwise) access to the privileged input.	I-Review	I-1	Review	20645
The statement seems to suggest that learning representations completely and generally agnostic to the privileged input is a good idea.	I-Review	I-1	Review	20645
However, this is only true when at test-time, the privileged input may be significantly different than what was seen during training time -- a different model-based planner / entirely different goal-specifications, etc.	I-Review	I-1	Review	20645
Could the authors comment more on this and reframe the intuition wherever applicable?	I-Review	I-1	Review	20645
<sep> <sep> - Last 3 lines of the 1st paragraph in section 3 (page 2) are incomplete -- ‚Äú...constraining the channel capacity .. is permitted to differ from the prior r(Z)....‚Äù.	B-Review	B-2	Review	20645
The difference in the posterior p(Z|X) and the prior r(Z) quantify the channel capacity only under expectation over the distribution over inputs -- p(X).	I-Review	I-2	Review	20645
Therefore, in practice, it is also governed by the empirical distribution of the data (see page 4 of <a href="https://arxiv.org/pdf/1612.00410.pdf)."	I-Review	I-2	Review	20645
target="_blank" rel="nofollow">https://arxiv.org/pdf/1612.00410.pdf).</a> The authors should change the lines to reflect the same.	I-Review	I-2	Review	20645
<sep> <sep> - One of the key contributions of the paper is to develop a mechanism where one isn‚Äôt required to access the privileged input all the time -- depending on the standard input, one can decide whether to access the privileged information.	O	O	Review	20645
This manifests in form of a mixture-distribution over a dirac-delta transformation of the deterministic encoder and a prior distribution.	O	O	Review	20645
At inference-time, the channel capacity (d_cap, based on the standard input) can be used to decide whether to access the privileged information or not.	O	O	Review	20645
There‚Äôs lack of clarity in terms of what happens at training time -- is it the case that (1) d_cap is computed, f(s, g) is also computed and based on the KL-term in Eq (3), B(S) is incentivized to generate d_cap that results in less frequent access the privileged information (d_cap &lt; 0.5 for the most part) or (2) d_cap is computed, a sample is drawn from the bernoulli and z is sampled from either r(Z) or \del_(f(S, G) and KL is either 0 (if z ~ r(Z)) or a finite value (if z ~  \del_(f(S, G))? (	B-Review	B-3	Review	20645
1) involves an exact computation and always requires access to G (privileged input) during training whereas (2) is approximate and does not always require access to G. It‚Äôs unclear what the pipeline is from the paper.	I-Review	I-3	Review	20645
Can the authors clarify this?	I-Review	I-3	Review	20645
Are there specific reasons why (1) / (2) was chosen?	I-Review	I-3	Review	20645
<sep> <sep> - Experimental Results: Highlighting these below:	O	O	Review	20645
- In the experimental setting of Figure 2, do the authors notice any (1) qualitative differences in terms of where the agent accesses the output of the planner when InfoBot is used (adapted to this setting) and (2) quantitative differences (Table.	B-Review	B-4	Review	20645
2) in terms of how often does InfoBot and the other proposed baselines access the planner output at junctions and hallways?	I-Review	I-4	Review	20645
Junctions in 2D mazes can potentially be identified as important decision states using simpler approaches.	I-Review	I-4	Review	20645
As a demonstrative experiment, the key point to be made using this experiment seems to be how often does VBB access the planner output compared to InfoBot and other baselines.	I-Review	I-4	Review	20645
<sep> <sep> - In Sec.7.2, it is unclear how VBB is being used to generalize to novel environments -- as in, is the pipeline same as InfoBot, where a frozen encoder is used to provide an exploration incentive?	B-Review	B-5	Review	20645
<sep> <sep> - While the generalization results in Table.	O	O	Review	20645
2 are impressive in terms of success values, I think it lacks a few numbers (assuming the transfer pipeline to novel environments is same as InfoBot) -- given that the environments being tested on are different from InfoBot, how well do count-based exploration and goal-conditioned A2C baselines perform?	B-Review	B-6	Review	20645
This is to understand whether InfoBot is the right thing to compare with in these environments.	I-Review	I-6	Review	20645
<sep> <sep> - Furthermore, for the goal-driven navigation set of experiments can the authors report comparisons in terms of sample-efficiency as well -- how do success-rates and average task-returns vary with time-steps of training?	B-Review	B-7	Review	20645
<sep> <sep> - For results in Sec.7.3, Table.	B-Review	B-8	Review	20645
4, I would encourage the authors to compare with IC3Net (<a href="https://arxiv.org/pdf/1812.09755.pdf)" target="_blank" rel="nofollow">https://arxiv.org/pdf/1812.09755.pdf)</a> which learns ‚Äúwhen to communicate‚Äù in a multi-agent setting irrespective of whether it‚Äôs a cooperative situation or not.	I-Review	I-8	Review	20645
<sep> <sep> Reasons for rating	O	O	Review	20645
<sep> Apart from the points mentioned above, I don‚Äôt have major weaknesses to point out.	O	O	Review	20645
The paper is generally easy to follow and the proposed approach and problem statement is well-grounded and somewhat novel.	O	O	Review	20645
However, the paper suffers from lack of experimental details and comparisons (and other weaknesses highlighted above) and therefore I am inclined towards my current rating.	B-Review	B-9	Review	20645
Addressing those would significantly benefit the paper and help me in  increasing my score.	O	O	Review	20645
<sep> <sep> Thanks to the authors for providing detailed comments and justifications wherever applicable and apologies for the late reply.	O	O	Reply	20645
I'll discuss / respond to the comments of the authors below.	O	O	Reply	20645
<sep> <sep> &gt; The VBB is indeed meant to provide robustness to distributional shift.	B-Reply	B-1	Reply	20645
While this can happen, as the reviewer says, in cases where there "a different model-based planner / entirely different goal-specifications," this kind of distributional shift more commonly occurs when we study generalization to related but distinct problem instances.	I-Reply	I-1	Reply	20645
For example, in the settings considered in our experiments, we train on procedurally generated mazes with different sizes (like different number of rooms, and size of different rooms) during training and testing.	I-Reply	I-1	Reply	20645
<sep> <sep> Thanks for responding to this.	I-Reply	I-1	Reply	20645
Just to clarify, my point here was that the degree to which a model / algorithm should be agnostic to the privileged input depends on the problem setting (as rightly pointed out by the authors).	I-Reply	I-1	Reply	20645
My intention behind the comment was to encourage the authors to soften the statement / claims around the robustness aspect of the motivation since beyond "the cost of accessing privileged input", robustness w.r.t.privileged input doesn't seem to be the problem in the experimental settings presented in the paper.	I-Reply	I-1	Reply	20645
<sep> <sep> Thanks for clarifying the training pipeline and making it clear that access to privileged information is still always required during training (but not during testing).	B-Reply	B-3	Reply	20645
I think out of the two options that I discussed in the comment, (1) seems the more reasonable thing to try first.	I-Reply	I-3	Reply	20645
My comment was motivated by trying to draw parallels with sampling procedures in mixture models.	I-Reply	I-3	Reply	20645
<sep> <sep> Thanks for making the transfer pipeline clear.	I-Reply	I-3	Reply	20645
<sep> <sep> Thanks for presenting the comparisons to the count-based and goal-conditioned A2C baseline in terms of success values.	B-Reply	B-6	Reply	20645
<sep> <sep> Thanks for including the comparison with IC3Net.	B-Reply	B-8	Reply	20645
Comparisons across a range over the number of agents is especially interesting.	I-Reply	I-8	Reply	20645
The fact that VBB scales better relative to IC3Net with number of agents does indeed demonstrate the utility of VBB.	I-Reply	I-8	Reply	20645
<sep> <sep> The response provided by the authors cover most of my points, except for one -- comparisons w.r.t.sample-efficiency of VBB versus InfoBot (and other approaches).	B-Reply	B-4	Reply	20645
While success and frequency of accessing privileged information are interesting metrics to look at, comparisons w.r.t.sample-efficiency would reflect if restricted access to privileged information via VBB results in faster training -- by very carefully accessing privileged information only at specific states.	I-Reply	I-4	Reply	20645
<sep> <sep> Given the responses to my comments, I am generally supportive of the paper.	O	O	Reply	20645

The authors proposed meta domain adaptation to address domain shift scenario in meta learning setup.	O	O	Review	820
The proposed model combines few shot meta-learning with the adversarial domain adaptation to demonstrate performance improvements in several experiments.	O	O	Review	820
<sep> <sep> Pros:	O	O	Review	820
1.	O	O	Review	820
A new few shot learning with domain shift problem is studied in the paper.	O	O	Review	820
<sep> 2.	O	O	Review	820
A new model combining prototypical network with GAN and cycle-consistency loss for addressing meta-learning domain shift scenario.	O	O	Review	820
The experimental improvements on omniglot seem quite substantial.	O	O	Review	820
<sep> <sep> Cons:	O	O	Review	820
1.	O	O	Review	820
Can you clarify why the proposed approach is better than the Meta-RevGrad baseline?	B-Review	B-1	Review	820
It seems that both are using meta-learning with domain adaptation technique.	I-Review	I-1	Review	820
What happen for Meta-RevGrad + idt or Meta-RevGrad + revMap?	I-Review	I-1	Review	820
I feel the baseline in domain adaptation area is a bit limited.	I-Review	I-1	Review	820
<sep> 2.	O	O	Review	820
How is the performance of a simpler baseline such as combining a subset of new domain as training set to train MAML or PN (probably in 5-shot, 5-class case)?	B-Review	B-2	Review	820
<sep> 3.	O	O	Review	820
It seems the domain shift in the paper is less dramatic.	B-Review	B-3	Review	820
i.e., omniglot <-> omniglot-M. I wonder whether the proposed approach can still work in large domain shift such as omniglot to fashion-mnist etc.	I-Review	I-3	Review	820
<sep> 4.	O	O	Review	820
The novelty of the model is relatively limited as it is a combination of previous techniques on a new problem.	B-Review	B-4	Review	820
<sep> <sep> Minor:	O	O	Review	820
1.	O	O	Review	820
Where is L_da in Figure 2?	B-Review	B-5	Review	820
In Figure 2, what‚Äôs the unlabelled data from which testing tasks are drawn?	I-Review	I-5	Review	820
Is it from meta-test data training set?	I-Review	I-5	Review	820
<sep> 2.	O	O	Review	820
In the caption of figure 2, there should be a space after `":".	B-Review	B-6	Review	820
Overall:	O	O	Reply	820
We thank you for your time and appreciating the strengths of our work.	O	O	Reply	820
Based on your guidance and suggestions, we have tried to do additional experiments to improve the quality of our work.	O	O	Reply	820
<sep> <sep> Concern 1: Comparison to Meta-RevGrad	O	O	Reply	820
Meta-RevGrad tries to achieve feature invariance at the embedding level.	B-Reply	B-1	Reply	820
Achieving such feature invariance for high-dimensional feature mapping can be a very weak constraint [1], causing limitation in performance.	I-Reply	I-1	Reply	820
Recently, generative approaches, following image-to-image translation have been shown achieve better domain adaptation, as this constrains the feature embedding to generate the data in a new domain.	I-Reply	I-1	Reply	820
Being a non-GAN based approach, concepts such idt (encouraging the styling network to behave as an identity when given a target domain instance as input) and revMap (constructing source instance back from generated target instance) are not applicable in this scenario, as no instances or images are being generated from a feature embedding.	I-Reply	I-1	Reply	820
<sep> Concern 1, 2, 3: Experiments	O	O	Reply	820
Thank you for these suggestions.	O	O	Reply	820
Taking your comments and comments from other reviewers into account, we have made improvements to the experimental section.	O	O	Reply	820
Specifically:	O	O	Reply	820
<sep> ‚ÄúDomain Adaptation Baselines‚Äù,	O	O	Reply	820
We have now added additional domain adaptation baselines, designed in the setting suggested by Reviewer 2.	B-Reply	B-1	Reply	820
<sep> <sep> ‚ÄúSimple baseline ‚Äì combining a subset of a new domain as training set‚Äù	O	O	Reply	820
We see the merit of this baseline, but there are several challenges in executing this.	B-Reply	B-2	Reply	820
Designing it in a fair way is tricky.	I-Reply	I-2	Reply	820
Using some labelled data in target domain maybe unfair, as we are not allowed to see meta-test data.	I-Reply	I-2	Reply	820
Moreover, this is likely to not work, as the meta-train data would be too large, and would dominate, and we do not have a clear way to set the weights.	I-Reply	I-2	Reply	820
<sep> <sep> ‚ÄúDramatic Domain Shift, Omniglot to Fashion-MNIST‚Äù	O	O	Reply	820
This could be an interesting setting, but we don‚Äôt think this will work very well, as the tasks are themselves completely different.	B-Reply	B-3	Reply	820
We would not expect a character recognition model to transfer to a object recognition task, as the visual features are very different.	I-Reply	I-3	Reply	820
<sep> <sep> <sep> Minor:	O	O	Reply	820
Thanks for this; we have updated the draft to make the presentation clearer.	B-Reply	B-5	Reply	820
Unlabelled data refers to only the domain of the meta-test data, but the meta-test data is never used in meta-training.	I-Reply	I-5	Reply	820
<sep> L_da is essentially the sum of L_gan and L_cycle.	I-Reply	I-5	Reply	820
<sep> <sep> <sep> [1] Shu, R., Bui, H.H., Narui, H. and Ermon, S. A DIRT-T Approach to Unsupervised Domain Adaptation.	O	O	Reply	820
ICLR 2018	O	O	Reply	820

This paper proposes to combine unsupervised adversarial domain adaptation with prototypical networks and finds that the proposed model performs well on few-shot learning task with domain shift, much better than other few-shot learning baselines that do not consider.	O	O	Review	820
Specifically it tests on Omniglot with natural image background and cliparts to real images.	O	O	Review	820
<sep> <sep> It is true that current meta-learning approaches do not address the problem of domain shift, and as a result, the testing domain has to be the same with the training domain.	O	O	Review	820
However, this paper rather than proposing solution address the meta-learning problem, albeit the title ‚Äúmeta domain adaptation‚Äù, only brings few-shot learning to domain adaptation.	O	O	Review	820
Here‚Äôs why:	O	O	Review	820
<sep> In order for a meta-learning model to be called ‚Äúmeta domain adaptation,‚Äù the type of adaptation cannot be seen during training, and the goal is to test on adaptation that the model has not seen before.	O	O	Review	820
Indeed, each task in meta domain adaptation should be seen as a pair of source task and target task.	O	O	Review	820
<sep> <sep> The problem with the current model is that during training, it is trained to target at one specific type of test domain--the generator network G aims to generated images that align with the unsupervised  test domain X_test.	B-Review	B-1	Review	820
Thus, the trained model will also only be able to handle one test domain, not much different than regular meta-learning models.	I-Review	I-1	Review	820
<sep> <sep> In short, the meta-learning part stays in the regular few-shot learning module (which is implemented as a prototypical network), and has nothing related to domain adaptation.	B-Review	B-2	Review	820
Therefore, the paper cannot be qualified for ``meta domain adaptation‚Äô‚Äô and has very limited novelty in terms of its contribution to meta-learning; however, the combination of domain adaptation and few-shot learning is fair.	I-Review	I-2	Review	820
For the rest of my review, I will treat the paper as ‚Äúfew-shot learning with domain adaptation‚Äù for more appropriate analysis.	I-Review	I-2	Review	820
<sep> <sep> For the experiments, there seems to have a great win of the proposed algorithm against the baselines.	B-Review	B-3	Review	820
However, I think since this is few-shot learning with domain adaptation, there is no domain adaptation baselines being mentioned in comparison.	I-Review	I-3	Review	820
Specifically, what if the few-shot learning component is removed, and the network is trained with standard domain adaptation.	I-Review	I-3	Review	820
Then use the same network to extract the features and then using the nearest neighbor to retrieve the classes.	I-Review	I-3	Review	820
Also it seems that the regular batch normalization could be very sensitive to domain shifts, and it would be good if the authors can test other normalization schemes such as layer/group normalization as baselines.	I-Review	I-3	Review	820
<sep> <sep> Another concern is that the evaluation of domain adaptation does not have much varieties.	B-Review	B-4	Review	820
Only two domains shifts are evaluated in the paper, specifically Omniglot + BSD500 and Office-Home.	I-Review	I-4	Review	820
BSD 500 only contains 500 images, and it would be good if more diverse set of images are considered.	I-Review	I-4	Review	820
Other domain transfer settings such as synthetic rendered vs. real (e.g. visDA challenge) could have been considered.	I-Review	I-4	Review	820
<sep> <sep> In conclusion, the paper presents a interesting combination of ProtoNet + Adversarial DA + Cycle consistency.	B-Review	B-5	Review	820
However, unlike as advertised, the paper does not address the domain shift issue in meta-learning, and the experiments lack thorough evaluation as the paper considers itself as a meta-learning paper and only compares to other meta-learning approaches without much comparison to domain adaptation papers.	I-Review	I-5	Review	820
Therefore, I recommend reject.	I-Review	I-5	Review	820
<sep> <sep> ---	O	O	Review	820
Note: after reading the comments updated by authors, I remain my opinions: even though exact meta-testing data is unseen during training, the domain is seen during training, and therefore it cannot be qualified for being "meta domain adaptation".	O	O	Review	820
<sep> <sep> ===	O	O	Review	820
After rebuttal:	O	O	Review	820
<sep> I would like to thank the authors for the response and updating the draft.	O	O	Review	820
They have addressed 1) the title issue and 2) adding domain adaptation baselines.	O	O	Review	820
Considering these improvements, I would like to raise the score to 5, since the setting of combining few-shot learning and domain adaptation is interesting and the proposed model outperforms the baselines.	O	O	Review	820
<sep> <sep> However, my criticisms remain that the paper is a simple combination of cycle GAN and prototypical networks, and lacks new insights/novelty.	B-Review	B-6	Review	820
The experiments use fairly small datasets, where the performance can be largely influenced by how good the feature extractor backbone is (e.g. training on more data and using deeper architecture would warrant better performance, and thus may change the conclusion).	B-Review	B-7	Review	820
We thank you for considering our rebuttal and updating the score.	O	O	Reply	820
We are grateful for your time and advice, and would appreciate if we could further extend the discussion.	O	O	Reply	820
<sep> <sep> <sep> We appreciate the concern in the updated comments, but would like to point out that the novelty in our work should be viewed from two angles: the need to study this problem (i.e., the problem setting), and the proposed solution.	B-Reply	B-6	Reply	820
We have identified a novel problem setting, which is closer to the real world setting, than what has been studied so far under the meta-learning paradigm.	I-Reply	I-6	Reply	820
Existing solutions are not effective in this setting, restricting their use in the real world.	I-Reply	I-6	Reply	820
Addressing this setting in our framework gives us a direction to improve the practical utility of meta-learning solutions for few-shot learning.	I-Reply	I-6	Reply	820
Specifically, we identify that the principle of image-to-image translation is very suitable for this setting, and apply those concepts to boost the performance of few-shot learning under domain shift.	I-Reply	I-6	Reply	820
As a combination of problem setting and proposed solution, we do believe we have addressed an important problem, and made a novel contribution.	I-Reply	I-6	Reply	820
<sep> <sep> As regards the experiments: ‚Äúfairly small datasets ‚Ä¶ feature extractor backbone‚Äù	O	O	Reply	820
<sep> Most domain adaptation experiments use MNIST, USPS, SVHN, which are comparable in size to our Omniglot experiments.	B-Reply	B-7	Reply	820
The other popular benchmark is using the Office-dataset, which also we have used (although a more recent version of a similar dataset, i.e., office-home ‚Äì more suitable for meta-learning evaluation, as it has larger number of classes).	I-Reply	I-7	Reply	820
See for example some of the recent domain adaptation papers [1, 2, 3].	I-Reply	I-7	Reply	820
<sep> While a feature extractor backbone network may have some influence, we would like to highlight three points.	B-Reply	B-7	Reply	820
First, when networks are trained in one domain, and evaluated in another, regardless of the backbone network, it is the domain-shift that dominates the performance.	I-Reply	I-7	Reply	820
For example, no matter how large the network is, if it is trained to recognize black and white digits, it will still struggle to recognize colored digits.	I-Reply	I-7	Reply	820
Second, any benefit of a larger backbone network will likely also enhance the performance of our model.	I-Reply	I-7	Reply	820
Third, we just wanted to clarify (if there was a misunderstanding), unlike domain adaptation papers, we do not use a pretrained network ‚Äì we train the full network from scratch (following traditional meta-training settings).	I-Reply	I-7	Reply	820
<sep> <sep> [1] Ganin, Yaroslav, et al "Domain-adversarial training of neural networks."	O	O	Reply	820
The Journal of Machine Learning Research 17.1 (2016): 2096-2030	O	O	Reply	820
[2] Tzeng, Eric, et al "Adversarial discriminative domain adaptation."	O	O	Reply	820
Computer Vision and Pattern Recognition (CVPR).	O	O	Reply	820
Vol.1.	O	O	Reply	820
No.	O	O	Reply	820
2.	O	O	Reply	820
2017	O	O	Reply	820
[3] Hoffman, J., Tzeng, E., Park, T., Zhu, J. Y., Isola, P., Saenko, K. & Darrell, T. Cycada: Cycle-consistent adversarial domain adaptation.	O	O	Reply	820
ICML 2018	O	O	Reply	820

The authors consider the few-shot / meta-learning scenario in which the test set of interest is drawn from a different distribution from the training set.	O	O	Review	820
This scenario is well-motivated by the "researcher example" given throughout the paper.	O	O	Review	820
The authors assume access to a large unlabelled set in test (target) domain, and a large labelled (few-shot) set in the source domain.	O	O	Review	820
Thus, the paper is concerned with unsupervised version of the meta-learning problem under domain shift (i.e., a large amount of data unlabelled are available from the target domain).	O	O	Review	820
<sep> <sep> The key idea is to learn a mapping from the source domain to the target domain.	O	O	Review	820
This mapping is learned jointly with the meta-learner, who performs the meta-learning in the target domain, on examples from the labelled domain.	O	O	Review	820
In practice however, it appears from the experimental section that the domain mapping is learned offline, and then frozen for the meta-learning phase.	O	O	Review	820
Thus, at test time, given examples from the target domain, the meta-learner can perform few-shot learning.	O	O	Review	820
<sep> <sep> Pros:	O	O	Review	820
- The paper addresses an important scenario which has not been addressed to this point: namely, meta-learning without the assumption that the train and test sets are drawn from the same domain/distribution.	O	O	Review	820
<sep> - The authors propose a novel task and experimental framework for considering their method, and show (somewhat unsurprisingly) that their method outperforms standard meta-learning methods that do not properly account for domain shift.	O	O	Review	820
<sep> - The paper reads well and is easy to follow.	O	O	Review	820
<sep> <sep> Cons:	O	O	Review	820
- My main concern is reproducibility: the authors employ a number of large architectures, complex loss functions, and regularizers / "additional improvements".	B-Review	B-1	Review	820
Further, there a number of experimental details that need to be further elaborated upon.	I-Review	I-1	Review	820
e.g., architectures and hyper-parameters used, and training procedures (I encourage the authors to utilize the appendices for this).	I-Review	I-1	Review	820
It is unclear to me how difficult/easy these results would be to reproduce.	I-Review	I-1	Review	820
Do the authors intend to release code for their implementations and experiments?	I-Review	I-1	Review	820
<sep> - Some assumptions are not explicitly stated.	B-Review	B-2	Review	820
In particular, it is unclear what the assumption on the size of the unlabelled test set is.	I-Review	I-2	Review	820
This is also lacking from the description of the experimental protocol, which does not address the data-splits (how many classes were used for each) and size of the unlabelled test set.	I-Review	I-2	Review	820
<sep> - While the method is presented as jointly learning all the components, in the experimental section it is stated that the embedding network (the meta-learner) and the GAN-based domain adaptation are done separately.	B-Review	B-3	Review	820
Can the authors comment on this further?	I-Review	I-3	Review	820
Is this different from first learning a image translation mapping (using the unlabelled data in the target domain), and then applying existing meta-learning models/algorithms to the labelled data in the target domain?	I-Review	I-3	Review	820
<sep> - The overall method seems to be not very principled, and requires a lot of "tweaks and tunes", with additional losses and regularizers, to work.	B-Review	B-4	Review	820
<sep> <sep> Overall, the paper proposes a method combining a number of existing useful works (prototypical networks for meta-learning and image-to-image translation for domain adaptation) to tackle an important problem setting that is not currently addressed in existing meta-learning research.	O	O	Review	820
Further, it establishes a useful experimental benchmark for this task, and provides what appear to be reasonable results (though this is somewhat difficult to judge due to the lack of baseline approaches).	O	O	Review	820
Hopefully, such a benchmark will inspire more researchers to explore this setting, and perhaps propose simpler, more principled approaches to perform this task.	O	O	Review	820
It is my impression that, if the authors elaborate on the experimental protocol and implementation details, this paper would be a good fit for the venue.	O	O	Review	820
<sep> <sep> Overall	O	O	Reply	820
We thank you for your kind comments, in acknowledging that the work is well motivated, and the problem is an important one, currently not studied under the meta-learning paradigm.	O	O	Reply	820
We have made substantial improvements based on your suggestions, and other reviewers‚Äô comments, and hopefully we are able to address most of your concerns.	O	O	Reply	820
<sep> <sep> Concern 1: Reproducibility	O	O	Reply	820
Our code is built on top of existing code (Prototypical Networks and Image-to-Image Translation from CycleGAN).	B-Reply	B-1	Reply	820
Thus, we adopt the same hyperparameters and architectures as the prior work, and as a result our work is fairly easy to reproduce.	I-Reply	I-1	Reply	820
We will of course release the code.	I-Reply	I-1	Reply	820
As suggested, we have utilized the appendices to give detailed information about the experimental setup.	I-Reply	I-1	Reply	820
<sep> <sep> Concern 2: Size of unlabelled test set, data-split information	O	O	Reply	820
We did provide some details on the first version (in the appendix).	B-Reply	B-2	Reply	820
In light of the reviews, in the revised version, we have expanded the appendix to give more details on the experimental protocol.	I-Reply	I-2	Reply	820
<sep> <sep> Concern 3: Jointly learning vs Freezing GAN	O	O	Reply	820
Training in joint manner can be very tricky, and may often cause stability issues.	B-Reply	B-3	Reply	820
You are right in your suggestion, that it is similar to first styling, and then applying meta-learning.	I-Reply	I-3	Reply	820
Having said that, this is a common strategy in several state of the art domain adaptation techniques, where the GAN-based domain adaptation and task-specific classifier are trained in multiple steps.	I-Reply	I-3	Reply	820
For example, see training protocol in [1,2,3, etc.].	I-Reply	I-3	Reply	820
<sep> <sep> [1] Judy Hoffman, Eric Tzeng, Taesung Park, Jun-Yan Zhu, Phillip Isola, Kate Saenko, Alyosha Efros, and Trevor Darrell.	O	O	Reply	820
Cycada: Cycle-consistent adversarial domain adaptation.	O	O	Reply	820
In ICML, 2018	O	O	Reply	820
[2] Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell.	O	O	Reply	820
Adversarial discriminative domain adaptation.	O	O	Reply	820
In Computer Vision and Pattern Recognition (CVPR), volume 1, pp.4, 2017.	O	O	Reply	820
<sep> [3] Bousmalis, K., Silberman, N., Dohan, D., Erhan, D., & Krishnan, D. Unsupervised pixel-level domain adaptation with generative adversarial networks.	O	O	Reply	820
In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017	O	O	Reply	820

This paper proposes a differentially private version of the lottery ticket mechanism using the exponential mechanism, thus improving the utility of DPSGD by reducing the number of parameters.	O	O	Review	20140
It provides the privacy guarantee of the proposed algorithm and shows experimentally that the proposed algorithm outperforms DPSGD across datasets and privacy parameters.	O	O	Review	20140
<sep> <sep> The proposed algorithm seems quite interesting.	O	O	Review	20140
Though it is more of a simple combination of the non-private lottery ticket mechanism and the exponential mechanism, improving utility for DPSGD is a very important topic in differentially private machine learning.	O	O	Review	20140
The experimental results seem pretty strong.	O	O	Review	20140
<sep> <sep> My only concern is on the aspect of privacy, specially Lemma 1.	B-Review	B-1	Review	20140
I think if you‚Äôre only using the fact that A and C are in [0, 1], then A*(1-nu*C) can change by 1 if you go from (A=0, C=0) to (A=1, C=0).	I-Review	I-1	Review	20140
In the last step of equation (5), you replaced A-A‚Äô by 1, which I think needs to be double-checked since there is the absolute value outside (and I guess the equality should  be &lt;=).	I-Review	I-1	Review	20140
<sep> If the calculation is correct, I‚Äôm still a bit concerned that the sensitivity is a bit too high compared to the signal.	I-Review	I-1	Review	20140
A and C are in [0, 1], and it seems like the sensitivity may not be much smaller than 1, which means the exponential mechanism can be pretty random.	I-Review	I-1	Review	20140
To that end, I think you may consider experimentally comparing with DPSGD with a randomly selected ticket, or a ticket with a moderate number of parameters kept.	I-Review	I-1	Review	20140
<sep> <sep> <sep> ----- Post-rebuttal response -----	O	O	Review	20140
I still don't see why the sensitivity is |1-\nu|. (Doesn't that mean sensitivity is 0 when \nu=1?)	B-Review	B-1	Review	20140
If we have (A=1, C=0) and (A'=0, C'=0), we have S(A,C)-S(A',C')=1-0=1; if we have (A=1, C=0) and (A'=1, C'=1), we have S(A,C)-S(A',C')=1-(1-\nu)=\nu.	I-Review	I-1	Review	20140
Yet for \nu&lt;1, |1-\nu|&lt;1 and for \nu&gt;1, |\nu-1|&lt;\nu.	I-Review	I-1	Review	20140
I believe the sensitivity should be something like max(\nu, 1).	I-Review	I-1	Review	20140
You may want to further check that.	I-Review	I-1	Review	20140
And I still think this is because the last step in (5) is not correct.	I-Review	I-1	Review	20140
Since you have absolute sign, you can't do |A-A'-X| \leq ||A-A'|-X|.	I-Review	I-1	Review	20140
<sep> I'm also confused by the range of \nu I should think of.	B-Review	B-2	Review	20140
<sep> If \nu &lt;= 1, then in the example you give (A = 0.8, C=0.9,0.7,0.4,0.1, eps=0.1), I think the probability distribution used by exponential mechanism is not much higher for 0.9 than 0.1 (I think it's roughly 0.22 vs. 0.29?)	I-Review	I-2	Review	20140
with sensitivity |1-\nu|.	I-Review	I-2	Review	20140
If \nu &gt; 1, then I don't quite understand the score function S(A,C) = A*(1-\nu*C), since for C &gt; 1/\nu, (1-\nu*C) is negative and S would thus penalize higher A. The higher \nu is, the wider the range of C that S will penalize.	I-Review	I-2	Review	20140
I can sort of understand this as setting a threshold such that any C above that threshold is just considered useless, but I still think it's a bit unreasonable to penalize higher accuracy, even for very complex model.	I-Review	I-2	Review	20140
You may want to explain more on that end.	I-Review	I-2	Review	20140
<sep> <sep> Thanks for the experiments!	O	O	Review	20140
They're very useful in supporting your proposed algorithm.	O	O	Review	20140
<sep> <sep> We thank the reviewer for their time and for appreciating the simplicity and significance of our proposed method.	O	O	Reply	20140
Next, we provide answers to the specific questions raised by the reviewer.	O	O	Reply	20140
<sep> <sep> Q) My only concern is on the aspect of privacy, specially Lemma 1.	O	O	Reply	20140
I think if you‚Äôre only using the fact that A and C are in [0, 1], then A*(1-nu*C) can change by 1 if you go from (A=0, C=0) to (A=1, C=0).	O	O	Reply	20140
In the last step of equation (5), you replaced A-A‚Äô by 1, which I think needs to be double-checked since there is the absolute value outside (and I guess the equality should be &lt;=).	O	O	Reply	20140
If the calculation is correct, I‚Äôm still a bit concerned that the sensitivity is a bit too high compared to the signal.	O	O	Reply	20140
A and C are in [0, 1], and it seems like the sensitivity may not be much smaller than 1, which means the exponential mechanism can be pretty random.	O	O	Reply	20140
To that end, I think you may consider experimentally comparing with DPSGD with a randomly selected ticket, or a ticket with a moderate number of parameters kept.	O	O	Reply	20140
<sep> <sep> A) Yes, you are correct, the equality should be, we apologize for the oversight and we have changed it in the revised version.	B-Reply	B-1	Reply	20140
Regarding the, we claim that the final sensitivity is "proportional" to, where is a much larger number compared to ), hence any change in does not impact our final results.	I-Reply	I-1	Reply	20140
<sep> <sep> As for the sensitivity and its impact on the utility.	I-Reply	I-1	Reply	20140
We have designed the score function in such a way that our outcomes of interest (models with a small number of parameters and high utility) have a high probability of selection (we discuss this briefly in Section 3.4).	I-Reply	I-1	Reply	20140
Consider this simple example: Let's say we have four models, all with the same utility (accuracy score of 0.8), but a varying number of model parameters (proportion of retained parameters is 0.9,0.7,0.4,0.1).	I-Reply	I-1	Reply	20140
Using our custom score function with, we can observe that the probability of selection for the model with 0.1 proportion of the original model‚Äôs parameters is the highest.	I-Reply	I-1	Reply	20140
That is, our custom score function ensures that the Exponential Mechanism in our case does not degenerate to uniform random sampling, we have added this detail in Section 3.4 of our revision.	I-Reply	I-1	Reply	20140
<sep> <sep> The smallest ticket with the highest accuracy provides the best "end-utility" for our method, as we have discussed at length in our paper.	I-Reply	I-1	Reply	20140
With the design of the score function specifically geared towards the selection of such tickets with high probability, randomly sampled tickets in expectation will not provide good utility compared to the winners selected by our method.	I-Reply	I-1	Reply	20140
However, to support our claim, we have added extra results.	I-Reply	I-1	Reply	20140
Please see the table below for such comparison, where we compare the two methods (selecting the best ticket with our method and a randomly selected ticket) at the tightest reported privacy budget ), showing the positive impact of winners selected via our proposed method.	I-Reply	I-1	Reply	20140
<sep> <sep> ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî--	I-Reply	I-1	Reply	20140
Dataset                 DPLTM        Random Ticket	I-Reply	I-1	Reply	20140
‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî--	I-Reply	I-1	Reply	20140
MNIST                    0.84             0.79	I-Reply	I-1	Reply	20140
HAR                        0.61             0.56	I-Reply	I-1	Reply	20140
Fashion-MNIST    0.77              0.73	I-Reply	I-1	Reply	20140
Kuzushiji-MNIST  0.60              0.54	I-Reply	I-1	Reply	20140
ISOLET                   0.58              0.33	I-Reply	I-1	Reply	20140
<sep> We have added the results in the appendix of the revised paper (Section A.2).	I-Reply	I-1	Reply	20140

The existing differentially private training mechanism of deep neural networks includes a step that applies L2 normalization to gradient vectors.	O	O	Review	20140
The authors argued that such norm clipping could lead to a small norm model parameter at the end, and the noise can thus overwhelm the accumulated gradient, leading to a substantial loss in terms of utility.	O	O	Review	20140
To mitigate such utility loss, the authors proposed to use the lottery ticket mechanism to train a smaller network with similar utility and design an end-to-end differentially private mechanism for the whole process, including the selection of sub-network and the re-training of the selected sub-network.	O	O	Review	20140
The general idea is quite interesting, but I have the following concerns.	O	O	Review	20140
<sep> <sep> -   From Algorithm 1 of Abadi et al 2016, one could see that the norm of per instance gradient is at least C, and the added noise has standard deviation of \sigma C. Furthermore, since the final gradient step is an accumulation of all the per instance gradient in the mini-batch, this means that the scale of the final gradient is roughly, where is the batch size.	B-Review	B-1	Review	20140
Note that since the noise is added to the accumulation gradient, so the scale of the noise should be roughly 1/B of the accumulated gradient.	I-Review	I-1	Review	20140
It seems to me that in this case the injected noise shouldn't overwhelm the gradient vector.	I-Review	I-1	Review	20140
Could the authors have a comment on this?	I-Review	I-1	Review	20140
<sep> <sep> -   The overall algorithm can be understood as a simple composition of the Exponential Mechanism algorithm and the DPSGD algorithm.	B-Review	B-2	Review	20140
Both of them satisfy differential privacy, so by a simple composition theorem argument the whole process also satisfies DP.	I-Review	I-2	Review	20140
This all makes sense, but the novelty is quite limited.	I-Review	I-2	Review	20140
The authors claim that the proposed mechanism is	I-Review	I-2	Review	20140
"different from DPSGD's naive implementation".	I-Review	I-2	Review	20140
This is not true, since at the end the original DPSGD algorithm is still used, just on a subnetwork.	I-Review	I-2	Review	20140
<sep> <sep> -   If the goal is to train a model with fewer parameters and comparable utility, why not simply starting from a small model with DPSGD and then use the large model as a teaching model?	B-Review	B-3	Review	20140
This simple strategy naturally gives DP guarantee without worrying about the LTH, hence you can also get same privacy guarantee with less injected noise.	I-Review	I-3	Review	20140
<sep> <sep> -   The experimental results basically confirm the expectation that with less injected noise, the model achieves better utility as compared with the DPSGD applied on the original large model.	B-Review	B-4	Review	20140
We thank the reviewer for their time and comments, and for appreciating the importance of our work.	O	O	Reply	20140
We provide our answers next.	O	O	Reply	20140
<sep> <sep> Q1)  From Algorithm 1 of Abadi et al 2016, one could see that the norm of per instance gradient is at least C, and the added noise has standard deviation of \sigma C....	O	O	Reply	20140
<sep> A1) Yes, in Abadi et al‚Äôs [1] Algorithm 1, we know that the norm of the per-observation gradient is bounded by, which enforces the sensitivity required for differential privacy.	B-Reply	B-1	Reply	20140
However, as the reviewer has mentioned, the noise reduction (in Algorithm 1 of [1]) depends on the group size (minibatch) (i.e. large group size provides a ‚Äúnoise reduction‚Äù effect), but at the same time, large group size also directly adversely impacts the noise scale ), see Theorem 1 of [1], where has a scaling effect on, where we get a smaller with smaller group size and vice-versa, this makes the naive DPSGD perform particularly worse on ‚Äúsmaller‚Äù datasets, see the performance gap for dataset ISOLET and HAR as an example (Figure 1 of our paper).	I-Reply	I-1	Reply	20140
<sep> <sep> This phenomenon creates an interesting dilemma, where increasing batch size provides a "noise reduction" effect due to summation in Algorithm 1 [1], but at the same time increases the noise scale (Theorem 1 [1]).	I-Reply	I-1	Reply	20140
Abadi et al in the paper recommend using a smaller batch size for the same reason.	I-Reply	I-1	Reply	20140
In our case, as we are working with a very small fraction of model parameters compared to the full model, our method enjoys significantly better utility while simultaneously providing tight privacy.	I-Reply	I-1	Reply	20140
We have added this detail to our main comparison (Section 4.3).	I-Reply	I-1	Reply	20140
<sep> <sep> <sep> Q2) The overall algorithm can be understood as a simple composition of the Exponential Mechanism algorithm and the DPSGD algorithm.....	O	O	Reply	20140
<sep> A2) We consider DPSGD as a generic training algorithm, which has been used widely across models (such as differentially private GANs [2][3], adversarial examples [4], various versions of differentially private neural networks [5], etc.).	B-Reply	B-2	Reply	20140
Our contribution is not based on the argument that we propose a radical new paradigm, but it is that we show how to significantly improve the existing method, which has direct implications on a wide array of methods using the naive method.	I-Reply	I-2	Reply	20140
We endeavored to make the algorithm and the paper as clear and as simple as possible, to ensure that it is easily accessible and applicable by a wide variety of practitioners, with a goal to boost the privacy-preserving machine learning in practice, prior successes of which have been limited, mainly due to the privacy-utility trade-offs of the current methods (which we propose to significantly improve upon).	I-Reply	I-2	Reply	20140
<sep> <sep> <sep> <sep> Q3)  If the goal is to train a model with fewer parameters and comparable utility, why not simply starting from a small model with DPSGD and then use the large model as a teaching model? ....	O	O	Reply	20140
<sep> <sep> A3) There are several issues with this approach.	B-Reply	B-3	Reply	20140
First, starting from a random small model does not guarantee that the small model will provide good utility.	I-Reply	I-3	Reply	20140
This was the driving force behind the lottery ticket hypothesis (to find small, high utility models that can be trained from scratch in isolation).	I-Reply	I-3	Reply	20140
Second, when we move to the student-teacher paradigm, it is a different research direction, not our focus in this work, we propose methods to significantly improve the performance of DPSGD, without constraining the training setup, so that our approach can be used anywhere, where DPSGD is applicable.	I-Reply	I-3	Reply	20140
<sep> <sep> Further, the student-teacher methods explored in previous models such as PATE [6] have their limitations.	I-Reply	I-3	Reply	20140
Such as the utility in PATE depends on the number of disjoint partitions, and the availability of public data to start the training process.	I-Reply	I-3	Reply	20140
This does not work in settings where we only have private sensitive data (in most scenarios requiring privacy protection), and in scenarios where the datasets are small (creating many disjoint partitions is not feasible).	I-Reply	I-3	Reply	20140
Our proposed method does not have any such limitations.	I-Reply	I-3	Reply	20140
<sep> <sep> <sep> [1] Abadi, Martin, et al "Deep learning with differential privacy."	O	O	Reply	20140
Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security.	O	O	Reply	20140
ACM, 2016.	O	O	Reply	20140
<sep> [2] Esteban, Crist√≥bal, Stephanie L. Hyland, and Gunnar R√§tsch. "	O	O	Reply	20140
Real-valued (medical) time series generation with recurrent conditional gans."	O	O	Reply	20140
arXiv preprint arXiv:1706.02633 (2017).	O	O	Reply	20140
<sep> [3] Beaulieu-Jones, Brett K., et al "Privacy-preserving generative deep neural networks support clinical data sharing."	O	O	Reply	20140
Circulation: Cardiovascular Quality and Outcomes 12.7 (2019): e005122.	O	O	Reply	20140
<sep> [4] Lecuyer, Mathias, et al "Certified robustness to adversarial examples with differential privacy."	O	O	Reply	20140
2019 IEEE Symposium on Security and Privacy (SP).	O	O	Reply	20140
IEEE, 2019.	O	O	Reply	20140
<sep> [5] McMahan, H. Brendan, et al "Learning differentially private recurrent language models."	O	O	Reply	20140
arXiv preprint arXiv:1710.06963 (2017).	O	O	Reply	20140
<sep> [6] Papernot, Nicolas, et al "Scalable private learning with pate."	O	O	Reply	20140
arXiv preprint arXiv:1802.08908 (2018).	O	O	Reply	20140

This paper is a mash-up of recent work on differentially private stochastic gradient descent (DPSGD) and the lottery ticket hypothesis.	O	O	Review	20140
Differential privacy is a paradigm for ensuring that statistical models learned from a large dataset do not disclose any particulars of individual elements of that dataset.	O	O	Review	20140
DPSGD is a technique that applies differential privacy ideas to models trained with stochastic gradient descent, where privacy is guaranteed by clipping and adding noise to gradients.	O	O	Review	20140
On the other hand, the lottery ticket hypothesis is a method for finding sparse sub-networks contained in larger dense neural network models that are at least as accurate as the underlying dense model.	O	O	Review	20140
The authors propose and demonstrate that by combining DPSGD with the lottery ticket hypothesis that they can train end-to-end differentially private models that outperform the DPSGD technique.	O	O	Review	20140
<sep> <sep> I am up in the air about whether or not to accept this paper.	B-Review	B-4	Review	20140
I have trouble assessing the originality and significance of this work, the former since it seems to be a simple combination of two recent ideas, and the latter because I don't really have a context for how important the development of differentially-private optimization strategies are.	I-Review	I-4	Review	20140
I also didn't really find the experimental results to be that extensive, but I don't have a real sense of what state of the art is for differential privacy.	I-Review	I-4	Review	20140
Perhaps some of these issues could be mitigated by some additional exposition?	I-Review	I-4	Review	20140
I think one of my problems is that most of the paper is written to show that this new technique is superior to DPSGD, but I don't really have a good sense if either of them are sufficient as a practical solution of this problem.	I-Review	I-4	Review	20140
<sep> <sep> Some additional questions I had are as follows:	O	O	Review	20140
<sep> 1) One of the reasons given for combining the lottery ticket hypothesis with DPSGD is that DPSGD scales poorly as models get larger due to clipping by the norm of the gradient.	B-Review	B-1	Review	20140
Could you not compensate for this by scaling the norm by the number of parameters, or does that mess up the differential-privacy calculation?	I-Review	I-1	Review	20140
<sep> <sep> 2) I don't understand how the winning ticket selection portion is differentially privacy.	B-Review	B-2	Review	20140
I understand that they use the exponential mechanism, but I would have assumed that the dataset needs to be varied in addition to the model.	I-Review	I-2	Review	20140
Is there an intuitive explanation for how privacy is achieved essentially just by varying the initialization and not actually adding noise to the data?	I-Review	I-2	Review	20140
<sep> <sep> 3) Are there any datasets or methods where the effectiveness of the differential privacy technique could be directly assessed?	B-Review	B-3	Review	20140
For example, is there a way of testing whether the model is memorizing specific data elements, and then further showing that these differential privacy techniques mitigate this?	I-Review	I-3	Review	20140
This would be a nice check to have in addition to the plots of accuracy vs. privacy budget.	I-Review	I-3	Review	20140
We thank the reviewer for their time and we sincerely hope we can clarify all doubts and provide clear answers to all questions.	O	O	Reply	20140
<sep> <sep> To start, we would like to emphasize the significance of our work, our work is more than a mere mash-up of recent works.	B-Reply	B-4	Reply	20140
Our contribution lies in developing an end-to-end differentially private training paradigm for neural networks, which significantly improves upon the current state-of-the-art, both in terms of utility and privacy, using a fraction of the parameters of the full model.	I-Reply	I-4	Reply	20140
One of the main goals and a core research area in differentially private machine learning is to investigate and improve the privacy-utility trade-off.	I-Reply	I-4	Reply	20140
Our method, being accessible and providing significantly better utility with tight privacy guarantees aims to boost the real-world applicability of differentially private machine learning methods, which to date has enjoyed limited success, mainly due to the problems with limited utility.	I-Reply	I-4	Reply	20140
<sep> <sep> Next, we provide answers to the specific questions raised by the respected reviewer.	O	O	Reply	20140
<sep> <sep> Q1) One of the reasons given for combining the lottery ticket hypothesis with DPSGD is that DPSGD scales poorly as models get larger due to clipping by the norm of the gradient.	O	O	Reply	20140
Could you not compensate for this by scaling the norm by the number of parameters, or does that mess up the differential-privacy calculation?	O	O	Reply	20140
<sep> <sep> A1) Differential privacy guarantees in DPSGD [1] are based on bounding the impact of per-observation gradient via gradient clipping using the l2 norm, scaled by a constant, which then has a multiplicative effect on total noise ).	B-Reply	B-1	Reply	20140
Using a larger scaling parameter will directly lead to larger noise, thus diminishing utility.	I-Reply	I-1	Reply	20140
<sep> <sep> <sep> Q2) I don't understand how the winning ticket selection portion is differentially privacy.	O	O	Reply	20140
I understand that they use the exponential mechanism, but I would have assumed that the dataset needs to be varied in addition to the model.	O	O	Reply	20140
Is there an intuitive explanation for how privacy is achieved essentially just by varying the initialization and not actually adding noise to the data?	O	O	Reply	20140
<sep> <sep> A2) We would like to emphasize that this step is just selecting the winning architecture, that is then trained with differential privacy from scratch.	B-Reply	B-2	Reply	20140
To ensure that the selection of the architecture is done in a differentially private fashion, we use the exponential mechanism with our custom score function.	I-Reply	I-2	Reply	20140
The exponential mechanism selects the winner with probability defined by the score function, in which the design of our custom score function ensures that we select "good" candidates with high probability.	I-Reply	I-2	Reply	20140
Simply put, the exponential mechanism selects the winners with "noisy" probability, not a "noisy winner" [2]. This is the part of the appeal of using the exponential mechanism, leading to its applicability in problems such as selecting max, top-k items, etc.	I-Reply	I-2	Reply	20140
with differential privacy.	I-Reply	I-2	Reply	20140
<sep> <sep> <sep> Q3) Are there any datasets or methods where the effectiveness of the differential privacy technique could be directly assessed?	O	O	Reply	20140
For example, is there a way of testing whether the model is memorizing specific data elements, and then further showing that these differential privacy techniques mitigate this?	O	O	Reply	20140
This would be a nice check to have in addition to the plots of accuracy vs. privacy budget.	O	O	Reply	20140
<sep> <sep> A3) There are some proposed methods such as the membership inference attack [3], that have been studied with DPSGD [4] and that have shown that DPSGD does indeed offer privacy protection to the contributing users in the training dataset, when the privacy guarantees are tight (small), but this also leads to the utility degradation, result of the privacy-utility trade-off, which our proposed method significantly improves upon.	B-Reply	B-3	Reply	20140
As our final winning ticket trains using the DPSGD method, we do not find it is necessary to evaluate the models against such attacks, especially when the results are already readily available.	I-Reply	I-3	Reply	20140
Instead, we focus on investigating and providing details on the significantly improved utility compared to the naive DPSGD.	I-Reply	I-3	Reply	20140
<sep> <sep> [1] Abadi, Martin, et al "Deep learning with differential privacy."	O	O	Reply	20140
Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security.	O	O	Reply	20140
ACM, 2016.	O	O	Reply	20140
<sep> [2] Dwork, Cynthia, and Aaron Roth. "	O	O	Reply	20140
The algorithmic foundations of differential privacy."	O	O	Reply	20140
Foundations and Trends¬Æ in Theoretical Computer Science 9.3‚Äì4 (2014): 211-407.	O	O	Reply	20140
<sep> [3] Shokri, Reza, et al "Membership inference attacks against machine learning models."	O	O	Reply	20140
2017 IEEE Symposium on Security and Privacy (SP).	O	O	Reply	20140
IEEE, 2017.	O	O	Reply	20140
<sep> [4] Rahman, Md Atiqur, et al "Membership Inference Attack against Differentially Private Deep Learning Model."	O	O	Reply	20140
Transactions on Data Privacy 11.1 (2018): 61-79.	O	O	Reply	20140

The authors present an online learning method for learning the structure of sum-product networks.	O	O	Review	382
The algorithm assumes Gaussian coordinate-wise marginal distributions, and learns both parameters and structure online.	O	O	Review	382
The parameters are updated by a recursive procedure that reweights nodes in the network that most contribute to the likelihood of the current data point.	O	O	Review	382
The structure learning is done by either merging independent product Gaussian nodes into multivariate leaf nodes, or creating a mixture over the two nodes when the multivariate would be too large.	O	O	Review	382
<sep> <sep> The fact that the dataset is scaled to some larger datasets (in terms of the number of datapoints) is promising, although the number of variables is still quite small.	O	O	Review	382
Current benchmarks for tractable continuous density modeling with neural networks include the NICE and Real-NVP families of models, which can be scaled to both large numbers of datapoints and variables.	O	O	Review	382
Intractable methods like GAN, GenMMN, VAE have the same property.	O	O	Review	382
<sep> <sep> The main issue with this work for the ICLR audience is the use of mainly a set of SPN-specific datasets that are not used in the deep learning generative modeling literature.	B-Review	B-1	Review	382
The use of GenMMN as a baseline is also not a good choice to bridge the gap to the neural community, as its Parzen-window based likelihood evaluation is not really meaningful.	I-Review	I-1	Review	382
Better ways to evaluate the likelihood through annealed importance sampling are discussed in "On the Quantitative Analysis of Decoder-Based Generative Models" by Wu et al I would recommend the use of a simple VAE type model to get a lower bound on the likelihood, or something like Real-NVP.	I-Review	I-1	Review	382
<sep> <sep> Most neural network density models are scalable to large numbers of observations as well as instances, and it is not clear that this method scales well "horizontally" like this.	B-Review	B-2	Review	382
Evaluating the feasibility of modeling something like MNIST would be interesting.	I-Review	I-2	Review	382
<sep> <sep> SPNs have the strength that not only marginal but also various type of conditional queries are tractable, but performance on this is not evaluated or compared.	B-Review	B-3	Review	382
One interesting application could be in imputation of unknown pixels or color channels in images, for which there is not currently a high-performing tractable model.	I-Review	I-3	Review	382
<sep> <sep> Despite the disconnect from other ICLR generative modeling literature, the algorithm here seems simple and intuitive and convincingly works better than the previous state of the art for online SPN structure learning.	B-Review	B-4	Review	382
I think VAE is a much better baseline for continuous data than GenMMN when attempting to compare to neural network approaches.	I-Review	I-4	Review	382
Further, the sum-product network could actually be combined with such deep latent variable models as an observation model or posterior, which could be a very powerful combination.	I-Review	I-4	Review	382
<sep> <sep> I would like it if these SPN models were better known by the ICLR probabilistic modeling community, but I do not know if this paper does enough to make them relevant.	O	O	Review	382
As with the other reviewers, I am not an expert on SPNs.	O	O	Review	382
However, this seems to be a simple and effective algorithm for online structure induction, and the scalability aspect is something that is important in much recent work in the learning of representations.	O	O	Review	382
I think it is good enough for publication, although I would prefer to see many of the above additions to more clearly bridge the gap with other literature in deep generative modeling.	O	O	Review	382
Thank you for your review.	O	O	Reply	382
We just uploaded a new version f the paper that addresses many of the concerns raised.	O	O	Reply	382
We included an empirical comparison with RealNVP and we explained that the algorithm scales quadratically with the number of features.	B-Reply	B-1	Reply	382
<sep> <sep> We note the request for more comparisons to more types of generative deep neural networks.	B-Reply	B-4	Reply	382
However, it is important to not loose track of the main contribution of the paper: an online structure learning algorithm for SPNs with Gaussian leaves.	I-Reply	I-4	Reply	382
By comparing SPNs to other generative models, we are not comparing different structure learning techniques, but simply different models.	I-Reply	I-4	Reply	382
In fact, no structure learning technique has been proposed for generative models other than SPNs (as far as we know).	I-Reply	I-4	Reply	382
<sep> We also not the insistence on scalability with respect to the number of features.	B-Reply	B-2	Reply	382
As mentioned above, oSLRAU scales quadratically with respect to the number of features.	I-Reply	I-2	Reply	382
While this does not permit to scale to large images with many pixels, please remember that this is the first online structure learning technique for SPNs with Gaussian leaves while other types of networks do not have any online structure learning technique.	I-Reply	I-2	Reply	382
A fair comparison would be to compare the scalablity of parameter learning techniques for different types of neural nets.	I-Reply	I-2	Reply	382
Since SPNs can be trained by SGD just like any other type of deep neural net, SPNs are as scalable as other types of network when the structure is fixed.	I-Reply	I-2	Reply	382
In fact, Poon and Domingos; UAI-2011 paper showed results where SPNs beat other types of deep neural nets on an image completion task.	I-Reply	I-2	Reply	382

# Summary	O	O	Review	382
This paper proposes an algorithm to learn the structure of continuous SPNs in a single pass through the data,	O	O	Review	382
basically by "growing" the SPN when two variables are correlated.	O	O	Review	382
<sep> <sep> ## NOTE	O	O	Review	382
I am not an expert on SPNs, and can not really judge how impressive the presented results are due to lack of familiarity with the datsets.	O	O	Review	382
<sep> <sep> # Pro	O	O	Review	382
- This looks like possibly impactful work, proposing a simple and elegant algorithm for learning SPN structure single-pass, rather than just using random structure which has been done in other work in the online settings.	O	O	Review	382
<sep> <sep> # Con	O	O	Review	382
- The paper is heavily updated between submission deadline and submission of reviews.	B-Review	B-1	Review	382
<sep> - The paper reads like a rush job, sloppily written - at least the first version.	B-Review	B-5	Review	382
<sep> - Comparison to literature is severely lacking; eg "several automated structure learning techniques have been proposed" followed by 6 citations but no discussion of any of them, which one is most related, which ideas carry over from the offline setting to this online setting, etc.	B-Review	B-2	Review	382
Also since this work presents both joint structure & *parameter* learning, comparison to the online parameter learning papers (3 cited) would be appreciated, specifically since these prior approaches seem to be more principled with Bayesian Moment Matching in Jaini 2016 for example.	I-Review	I-2	Review	382
<sep> - I do not know enough about SPNs and the datasets to properly judge how strong the results are, but they seem to be a bit underwhelming on the large datasets wrt Random	B-Review	B-6	Review	382
<sep> # Remaining questions after the paper updates	O	O	Review	382
- Table 3: Random structure as baseline ok, but how were the parameters here learned?	B-Review	B-3	Review	382
Your simple running average or with more advanced methods?	I-Review	I-3	Review	382
<sep> - Table 1: you are presenting *positive* average log-likelihood values?	B-Review	B-4	Review	382
This should be an average of log(p<=1) < 0 values?	I-Review	I-4	Review	382
What am I missing here?	I-Review	I-4	Review	382
<sep> <sep> I recommend reject mostly because this paper should have been finished and polished at submission time, not at review deadline time.	O	O	Review	382
Thank you for the review.	O	O	Reply	382
We just uploaded a new version that addresses many of the concerns raised.	O	O	Reply	382
<sep> <sep> "The paper is heavily updated between submission deadline and submission of reviews."	O	O	Reply	382
<sep> <sep> We realize that the paper has evolved substantially since the first submission.	B-Reply	B-1	Reply	382
All the revisions were done in response to requests by the reviewers.	I-Reply	I-1	Reply	382
ICLR differs from other conferences since authors are encouraged to submit revisions that address the reviewers's concerns.	I-Reply	I-1	Reply	382
This is better since the reviewers can evaluate the final version as it is instead of wondering whether the authors will fulfill the requests of the reviewers in the final version.	I-Reply	I-1	Reply	382
<sep> <sep> "Comparison to literature is severely lacking"	O	O	Reply	382
<sep> We added a new subsection about parameter learning in the background  section and expanded the subsection about structure learning.	B-Reply	B-2	Reply	382
The main characteristics of each algorithm are now described.	I-Reply	I-2	Reply	382
We also added some text in the section where we describe the new parameter and structure learning technique to clarify the differences with the closest algorithms.	I-Reply	I-2	Reply	382
<sep> <sep> "Table 3: Random structure as baseline ok, but how were the parameters here learned? "	O	O	Reply	382
<sep> <sep> The parameters are updated using the same parameter learning technique as in oSLRAU.	B-Reply	B-3	Reply	382
<sep> <sep> "Table 1: you are presenting *positive* average log-likelihood values?	O	O	Reply	382
This should be an average of log(p<=1) < 0 values?	O	O	Reply	382
What am I missing here?"	O	O	Reply	382
<sep> <sep> Log likelihood is positive when the density is higher than 1.	B-Reply	B-4	Reply	382
Recall that we are working with continuous variables and therefore we have a density function (instead of probabilities) and that a density function can have values higher than 1.	I-Reply	I-4	Reply	382

The authors contribute an algorithm for building sum-product networks (SPNs) from data, assuming a Gaussian distribution for all dimensions of the observed data.	O	O	Review	382
Due to the restricted structure of the SPN architecture, building a valid architecture that is tailored to a specific dataset is not an obvious exercise, and so structure-learning algorithms are employed.	O	O	Review	382
For Gaussian distributed observations, the authors state that the previous state of the art is to chose a random SPN that satisfies the completeness and decomposibility constraints that SPNs must observe, and to then learn the parameters (as done in Jaini 2016).	O	O	Review	382
In the contributed manuscript, the algorithm begins with a completely factorized model, and then by passing through the data, builds up more structure, while updating appropriate node statistics to maintain the validity of the SPN.	O	O	Review	382
<sep> <sep> The above Jaini reference figures heavily into the reading of the paper because it is (to my limited knowledge) the previous work SOTA on SPNs applied to Gaussian distributed data, and also because the authors of the current manuscript compare performance to datasets studied in Jaini et al  I personally was unfamiliar with most of these datasets, and so have no basis to judge loglikelihoods, given a particular model, as being either good or poor.	B-Review	B-2	Review	382
Nevertheless, the current manuscript reports results on these datasets that better (5 / 7) than other methods, such as SPNS (constructed randomly), Stacked Restricted Boltzmann Machines or Generative Moment Matching networks.	I-Review	I-2	Review	382
<sep> <sep> Overall:	O	O	Review	382
First let me say, I am not really qualified to make a decision on the acceptance or rejection of this manuscript (yet I am forced to make just such a choice) because I am not an expert in SPNs.	O	O	Review	382
I was also unfamiliar with the datasets, so I had no intuitive understanding of the algorithms performance, even when viewed as a black-box.	O	O	Review	382
The algorithm is presented without theoretical inspiration or justification.	B-Review	B-1	Review	382
These latter are by no means a bad thing, but it again gives me little hold onto when evaluating the manuscript.	I-Review	I-1	Review	382
The manuscript is clearly written, and to my limited knowledge novel, and their algorithm does a good job (5/7) on selected datasets.	O	O	Review	382
<sep> My overall impression is that there isn't very much work here (e.g., much of the text is similar to Jaini, and most of the other experiments are repeated verbatim from Jaini), but again I may be missing something (this manuscript DOES mostly Jaini).	O	O	Review	382
I say this mostly because I am unfamiliar with the datasets.	O	O	Review	382
Hopefully my reviewing peers will have enough background to know if the results are impressive or not, and my review should be weighted minimally.	O	O	Review	382
<sep> <sep> Smallish Problems	B-Review	B-3	Review	382
I wanted to see nonuniform covariances in the data of the the toy task (Fig 3) for each gaussian component.	I-Review	I-3	Review	382
<sep> <sep> The SPN construction method has two obvious hyper parameters, it is important to see how those parameters affect the graph structure. (	I-Review	I-3	Review	382
I submitted this as a pre-review question, to which the authors responded that they would look into this.)	I-Review	I-3	Review	382
Thank you for the review.	O	O	Reply	382
We just uploaded a revised version of the paper.	O	O	Reply	382
Regarding the lack of theoretical justification, we included an explanation about how we derived the parameter update algorithm, including a theorem that shows that it necessarily increases the likelihood of the last data point processed.	B-Reply	B-1	Reply	382
<sep> <sep> Regarding the similarities between this paper and Jaini et al's paper, the only content that was copied from Jaini are the results for alternative approaches in Table 1.	B-Reply	B-2	Reply	382
This saved us the trouble of re-implementing these approaches and re-running them.	I-Reply	I-2	Reply	382
This is common practice when a set of benchmarks can be reused.	I-Reply	I-2	Reply	382
Note also that the background section in both papers introduces some basics about SPNs, but this is necessary for completeness.	I-Reply	I-2	Reply	382
The contributions of both papers are different.	I-Reply	I-2	Reply	382
Jaini et al introduced an online parameter update algorithm (Bayesian moment matching).	I-Reply	I-2	Reply	382
There was no structure learning algorithm and therefore random structures were used.	I-Reply	I-2	Reply	382
In our paper, we introduce an online structure learning algorithm.	I-Reply	I-2	Reply	382
The algorithm is simple and therefore it might be tempting to write that there is not enough work for a publication, but simple is good in practice.	I-Reply	I-2	Reply	382
Its simplicity is indeed what allows it to scale.	I-Reply	I-2	Reply	382
We also hope that its simplicity will incite others to use it and perhaps enhance it.	I-Reply	I-2	Reply	382

This paper introduces an encoder-decoder as a differentiable loss function for sequential autoregressive generation tasks and more specifically for summarization.	O	O	Review	382
<sep> This is done by adding a recorder network that that takes the decoded sequence from the summarizer as input and is trained to output the reference summary.	O	O	Review	382
<sep> <sep> I see a fundamental issue with this work:	O	O	Review	382
<sep> * During inference, authors decode from the probability distribution of the seq2seq model using beam search.	B-Review	B-1	Review	382
<sep> * But for training (original seq2seq + recorder) authors backpropagate the NLL loss (which is fully differentiable) of the recorder on reference summaries through the softmax probabilities of outputs from the seq2seq model.	I-Review	I-1	Review	382
<sep> <sep> &gt;&gt; This whole architecture can be seen as a traditional end-to-end seq2seq model with non-linearity and normalization (softmax) in the middle.	I-Review	I-1	Review	382
<sep> <sep> Additionally:	O	O	Review	382
&gt;&gt; "backpropagating through the softmax weights during training and using the argmax during inference" falls into a long line of work for propagating non-differential objective functions through continuous relaxations	B-Review	B-2	Review	382
of categorical latent variables, more specifically the "straight through"  and "gumbel-softmax" (see refs.)	I-Review	I-2	Review	382
<sep> These methods have proven to be a strong alternative to reinforcement learning to train non-differential objectives and have been implemented quite a lot for sequence generation mainly for SeqGANs and even for text summarization connections to this line of work must be established in this paper.	I-Review	I-2	Review	382
<sep> <sep> references	O	O	Review	382
- Estimating or propagating gradients through stochastic ¬¥neurons for conditional computation.	O	O	Review	382
<sep> Bengio et al 2013 arXiv preprint arXiv:1308.3432, 2013.	O	O	Review	382
<sep> - CATEGORICAL REPARAMETERIZATION WITH GUMBEL-SOFTMAX	O	O	Review	382
Jang et al 2018 <a href="https://arxiv.org/pdf/1611.01144.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1611.01144.pdf</a>	O	O	Review	382
- GANS for Sequences of Discrete Elements with the Gumbel-softmax Distribution	O	O	Review	382
<a href="https://arxiv.org/pdf/1810.05739.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1810.05739.pdf</a>	O	O	Review	382
- Learning to Ask Questions in Open-domain Conversational Systems with Typed Decoders	O	O	Review	382
<a href="https://arxiv.org/pdf/1805.04843.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1805.04843.pdf</a>	O	O	Review	382
- MeanSum : A Neural Model for Unsupervised Multi-Document Abstractive Summarization	O	O	Review	382
<a href="https://arxiv.org/pdf/1810.05739.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1810.05739.pdf</a>	O	O	Review	382
<sep> <sep> <sep> <sep> <sep> Thanks for your comments.	O	O	Reply	382
I believe there is a core misunderstanding in how the recoder helps train the summarizer, so let me clarify.	B-Reply	B-1	Reply	382
The key contribution is the recoder as a *loss function* for the summarizer's beam decoded outputs.	I-Reply	I-1	Reply	382
What you referred to:	O	O	Reply	382
<sep> &gt; "backpropagating through the softmax weights during training and using the argmax during inference"	O	O	Reply	382
<sep> is to help train the summarizer through beam search decoding, which is not an element of our work.	B-Reply	B-2	Reply	382
The recoder helps train the summarizer only by exposing it to its own output (y1...yt-1), without backpropagation to previous timesteps through beam search decoding.	I-Reply	I-2	Reply	382
We tried to make this subtle point clear in Section 3.1, where we said "propagating errors to P_t improves the summarizer via exposure to what it would see at test time, even if the summarizer is not 'aware' of the search mechanism and cannot optimize for it".	I-Reply	I-2	Reply	382
<sep> <sep> Propagating through beam search decoding would be accomplished by techniques such as Straight Through Gumbel-Softmax that you cited, or such as Goyal et al (2017) that we cited.	I-Reply	I-2	Reply	382
These would be complementary additions to the recoder, as discussed in Section 4.2.	I-Reply	I-2	Reply	382
We also discussed how our work differs from approaches such as reinforcement learning in Section 4.1.	I-Reply	I-2	Reply	382
Other models that re-encode their output are discussed in Section 4.3.	I-Reply	I-2	Reply	382
<sep> <sep> The MeanSum work you cited is a related work in a different problem space; thanks for this reference.	I-Reply	I-2	Reply	382
They also use the idea of re-encoding an output summary, but they differ in that their loss function l_sim is based on cosine distance in the hidden space, in contrast with our recoder loss J^R. Their "reconstruction cycle loss" variant is closer to our work, except they reconstruct the original reviews, which would be analogous in our problem to training the recoder to output the original article instead of the reference summary.	I-Reply	I-2	Reply	382
We decided against doing this because in general the summary is a lossy representation of the original (mentioned in Section 4.3), an incongruence MeanSum also mentioned as a shortcoming.	I-Reply	I-2	Reply	382
We will add a citation to MeanSum and Straight Through Gumbel-Softmax and bring up these differences in the paper.	I-Reply	I-2	Reply	382
<sep> <sep> I understand it is difficult to parse out such complexities given a terse presentation, and would appreciate it if you could review the paper again after this very important clarification.	O	O	Reply	382
Thank you.	O	O	Reply	382

This paper proposed an encoder-decoder-based summarization network as a loss function within a similar encoder-decoder-based summarization framework to demonstrate that the proposed model obtains better automatic and human evaluation scores compared to the baseline model of See et al (2017) with just traditional loss functions.	O	O	Review	382
Overall, the paper is well-written and the presented results, analyses, and comparisons appear to be reasonable.	O	O	Review	382
One notable advantage of the proposed model would be to circumvent the approaches that rely on the evaluation metric, ROUGE as a reward component e.g. in a reinforcement learning setting, although with the expense of additional memory and time complexity.	O	O	Review	382
<sep> Few comments:	O	O	Review	382
<sep> - "A presents either a word ...." --&gt; this sentence is not clear.	B-Review	B-1	Review	382
<sep> <sep> - "Embedded representations ... differ somewhat from w_i"--&gt; Please clarify this aspect with more details.	B-Review	B-2	Review	382
<sep> <sep> - In Figure 1, the proposed model with recoder seems to be suffering from issues related to redundancy and referential clarity, as it repeats the name "malia" several times.	B-Review	B-3	Review	382
Would you comment on why this is the case?	I-Review	I-3	Review	382
<sep> <sep> - It would be great if you could provide more details on the selection criteria/qualifications of the mechanical turk workers.	B-Review	B-4	Review	382
Also, it is not clear why each example was given to only one worker and not to multiple workers.	I-Review	I-4	Review	382
Wouldn't it be ideal to evaluate each example by multiple workers to get a sense of the inter-rater agreement?	I-Review	I-4	Review	382
Please clarify.	I-Review	I-4	Review	382
Thanks for your comments.	O	O	Reply	382
<sep> <sep> &gt; "A presents either a word ...." --&gt; this sentence is not clear.	O	O	Reply	382
<sep> <sep> Thanks for catching this.	B-Reply	B-1	Reply	382
It should be "A token represents either a word ....".	I-Reply	I-1	Reply	382
Will correct.	I-Reply	I-1	Reply	382
<sep> <sep> &gt; "Embedded representations ... differ somewhat from w_i"--&gt; Please clarify this aspect with more details.	O	O	Reply	382
<sep> <sep> Thanks for this suggestion.	O	O	Reply	382
We'll add a sentence to clarify that w^R_t is a weighted sum of embedding vectors instead of an individual one like w_i.	B-Reply	B-2	Reply	382
<sep> <sep> &gt; In Figure 1, the proposed model with recoder seems to be suffering from issues related to redundancy and referential clarity, as it repeats the name "malia" several times.	O	O	Reply	382
Would you comment on why this is the case?	O	O	Reply	382
<sep> <sep> In many cases the coverage mechanism reduces repetition at the phrase level, but usually not down to the level of individual words such as malia.	B-Reply	B-3	Reply	382
There is no special penalty for redundancy in the standard ml loss, and the same is true for the recoder except from verbosity due to the length loss.	I-Reply	I-3	Reply	382
Moreover, this dataset's reference summaries, which are usually 3 individual sentences intended as bullet points, may not always resemble a coherent paragraph.	I-Reply	I-3	Reply	382
<sep> <sep> &gt; It would be great if you could provide more details on the selection criteria/qualifications of the mechanical turk workers.	O	O	Reply	382
Also, it is not clear why each example was given to only one worker and not to multiple workers.	O	O	Reply	382
Wouldn't it be ideal to evaluate each example by multiple workers to get a sense of the inter-rater agreement?	O	O	Reply	382
Please clarify.	O	O	Reply	382
<sep> We required workers to be Masters (a common requirement), which the Mechanical Turk system had identified to be "high performers".	B-Reply	B-4	Reply	382
<sep> <sep> As mentioned in Section 5.2, we do not need a confident score for any one example, since we are assessing the quality of the algorithm.	I-Reply	I-4	Reply	382
Ideally we would sample from the space of all (viewer, example) pairs, so limiting each example to one worker allows us to sample a wider diversity of examples using a given number of workers -- we used 300 (viewer, example) pairs for 11490 examples.	I-Reply	I-4	Reply	382
We could also have limited each worker to 1 example instead of 5 to get a greater diversity of viewers, but we felt that may expose us to a higher fraction of ratings from workers making mistakes on their first and only example.	I-Reply	I-4	Reply	382
<sep> <sep> Confident results for each example would only be needed if the ratings were to be used as training data for another algorithm, which is not the case for us.	I-Reply	I-4	Reply	382

This paper proposes to use an additional component to the commonly used encoder-decoder approach for summarization, which is referred to as the recoder, which is an RNN-syle component that takes the output of the decoder.	O	O	Review	382
The intuition offered in the paper is that a good summary should produce itself via the recoder network, and in training it together with the original encoder-decoder it should improve its performance as it would be able to capture more than what the word-level loss does.	O	O	Review	382
<sep> <sep> I have the following objections to this paper:	O	O	Review	382
- I can't see why this extra component should improve the quality of the summary produced.	B-Review	B-1	Review	382
If say our encoder-decoder architecture models the training data perfectly, then a recoder that does not do anything would be the right choice.	I-Review	I-1	Review	382
Taking this further, a recoder could actually be fixing problems in the output of the decoder, and thus not providing a good training signal.	I-Review	I-1	Review	382
It doesn't make sense to my that a summary should produce itself via a neural network, unless we are training an auto-encoder.	I-Review	I-1	Review	382
The experiments validate this; the difference in ROUGE score are less than a point, which is the kind of fluctuation one expects due to random seed differences, etc.	I-Review	I-1	Review	382
<sep> <sep> - I find it odd that ROUGE score is dismissed as a loss to train against (referred to as a heuristic in the end of section 4.1), but then 1 ROUGE point difference is considered a "significant" improvement (making such claims without statistical significance testing is misleading).	B-Review	B-2	Review	382
Sure it has flaws, if there is something better why not use it for evaluation?	I-Review	I-2	Review	382
Furthermore, claiming that the recoder does a better job requires evidence.	I-Review	I-2	Review	382
Why not train this extra function against human judgements?	I-Review	I-2	Review	382
Assuming that what is wanted is to train a model that estimates the quality of the summary, it would make sense to look at the approaches used for the similar task of machine translation quality estimation: <a href="https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00056" target="_blank" rel="nofollow">https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00056</a>	I-Review	I-2	Review	382
<sep> - The approach is in my view a kind of actor-critic approach; the recoder could play that role, and in fact the Bahdanau et al 2016 paper cited does this.	B-Review	B-3	Review	382
However no comparison is offered, be it theoretical or experimental.	I-Review	I-3	Review	382
Furthermore, the criticism that sequence-level training requires differentiable losses is incorrect; MIXER for example does train against scores such as ROUGE that are not differentiable.	I-Review	I-3	Review	382
Furthermore, the BSO approach by Wiseman and Rush (2016) cited does give a continuous output to optimize for seq2seq that is asked for in the beginning of page 4.	I-Review	I-3	Review	382
<sep> <sep> - In the experiments, how was the length penalty determined to be the graduated curve mentioned in section 5?	B-Review	B-4	Review	382
I would expect to have comparison against other approaches that try to train encoder-decoder to improve summarization, such as those mentioned in section 4.1.	I-Review	I-4	Review	382
<sep> <sep> - On the human evaluation experiments: the difference between the two models is quite small, especially given that the workers were not allowed to say that the models were equally good/bad.	B-Review	B-4	Review	382
Furthermore, there is no inter-annotator agreement, as each comparison was done by a single crowd worker.	I-Review	I-4	Review	382
Showing only the first 400 tokens of the original document would incorrectly disadvantage models selecting content from later in the articles.	I-Review	I-4	Review	382
Finally, showing the reference summary creates another bias, since equally good summaries can disagree on what content to include.	I-Review	I-4	Review	382
It might be helpful to look at some recent work on manual evaluation of summarization that tried to address these issues: <a href="https://arxiv.org/abs/1906.01361" target="_blank" rel="nofollow">https://arxiv.org/abs/1906.01361</a>	I-Review	I-4	Review	382
<sep> <sep> You appear to have misunderstood the recoder and how it helps the summarizer, and this is causing confusion for the questions below.	O	O	Reply	382
<sep> <sep> <sep> &gt; The intuition offered in the paper is that a good summary should produce itself via the recoder network.... It doesn't make sense to my that a summary should produce itself via a neural network, unless we are training an auto-encoder.	O	O	Reply	382
<sep> <sep> The intuition behind the recoder is that a good summary should be *useful as input for producing the reference summary*, not necessarily *equal* the reference or "produce itself".	B-Reply	B-1	Reply	382
This is exactly why we need the recoder.	I-Reply	I-1	Reply	382
The decoder's output summaries will almost never equal the reference summary, causing a disparity between the sequence prefix that the summarizer sees in training versus test.	I-Reply	I-1	Reply	382
<sep> <sep> This is discussed in the Introduction, so please review that section for further clarification.	I-Reply	I-1	Reply	382
<sep> <sep> <sep> &gt; I find it odd that ROUGE score is dismissed as a loss to train against ... but then 1 ROUGE point difference is considered a "significant" improvement....	O	O	Reply	382
<sep> We never dismissed ROUGE, which is why we evaluated using ROUGE in Section 5.1.	B-Reply	B-2	Reply	382
We said that the recoder can in principle capture more complex notions of quality than ROUGE, so ROUGE *alone* is not enough, and that's why we presented human evaluations in Section 5.2.	I-Reply	I-2	Reply	382
<sep> <sep> I would also say that 1 point is not an insignificant improvement.	I-Reply	I-2	Reply	382
Most of the reported ROUGE scores for the near state-of-the-art models cited vary within a range of about 2 points, such as 39.47 to 41.69 for ROUGE-1.	I-Reply	I-2	Reply	382
<sep> <sep> <sep> &gt; making such claims without statistical significance testing is misleading.	O	O	Reply	382
<sep> I do not see how what we presented is misleading, especially when confidence intervals output by the ROUGE tool was always available in our submitted code and results: <a href="https://github.com/iclr2020recoder/code_for_paper" target="_blank" rel="nofollow">https://github.com/iclr2020recoder/code_for_paper</a> .	B-Reply	B-2	Reply	382
We did not list them in the paper to reduce clutter in the limited space available.	I-Reply	I-2	Reply	382
This omission is in line with other papers such as Celikyilmaz et al (2018).	I-Reply	I-2	Reply	382
<sep> <sep> One reason to omit them is that the confidence intervals are generally small (+/- 0.2 points).	I-Reply	I-2	Reply	382
As an example, here are the results for pgen_cov+recoder (lambda=0.1), which can be seen in the github repository link:	I-Reply	I-2	Reply	382
<sep> ROUGE-1: 0.4044 with confidence interval (0.4022, 0.4065)	I-Reply	I-2	Reply	382
ROUGE-2: 0.1815 with confidence interval (0.1793, 0.1838)	I-Reply	I-2	Reply	382
ROUGE-3: 0.3690 with confidence interval (0.3668, 0.3712)	I-Reply	I-2	Reply	382
<sep> <sep> &gt; Sure it has flaws, if there is something better why not use it for evaluation?	O	O	Reply	382
Furthermore, claiming that the recoder does a better job requires evidence.	O	O	Reply	382
Why not train this extra function against human judgements?	O	O	Reply	382
<sep> <sep> We did evaluate using human evaluations as a way to improve on the limitations of the ROUGE heuristic, so I'm not sure what you're asking here.	B-Reply	B-2	Reply	382
Together these evaluations are evidence of the recoder's improvement.	I-Reply	I-2	Reply	382
<sep> <sep> I'm also not sure what you mean by training "this extra function" against human judgements.	I-Reply	I-2	Reply	382
It would not make sense to train the recoder using human judgements.	I-Reply	I-2	Reply	382
You may be thinking of reinforcement learning style algorithms, discussed in Related Work, that train toward a metric.	I-Reply	I-2	Reply	382
<sep> <sep> <sep> &gt; The approach is in my view a kind of actor-critic approach; the recoder could play that role, and in fact the Bahdanau et al 2016 paper cited does this.	O	O	Reply	382
However no comparison is offered, be it theoretical or experimental.	O	O	Reply	382
Furthermore, the criticism that sequence-level training requires differentiable losses is incorrect; MIXER for example does train against scores such as ROUGE that are not differentiable.	O	O	Reply	382
Furthermore, the BSO approach by Wiseman and Rush (2016) cited does give a continuous output to optimize for seq2seq that is asked for in the beginning of page 4.	O	O	Reply	382
<sep> <sep> This is all addressed in the Related Work section, which I kindly request that you review, after you have corrected the misunderstandings I noted above.	B-Reply	B-3	Reply	382
Actor-critic and other reinforcement learning approaches such as REINFORCE are discussed to an extent that we feel adaquate to address what you brought up here.	I-Reply	I-3	Reply	382
There we discussed how Bahdanau et al (2016),  Ranzato et al (2016)'s MIXER, and Wiseman and Rush (2016) are relevant yet different from our work.	I-Reply	I-3	Reply	382
In Section 5.2 our experimental results are also compared against approaches that use reinforcement learning, such as Chen &amp; Bansal (2018).	I-Reply	I-3	Reply	382
<sep> <sep> You may also have the same misunderstanding as Official Blind Review #3, so please see my response to that review.	I-Reply	I-3	Reply	382
<sep> <sep> &lt;continued in next comment&gt;	B-Reply	B-4	Reply	382

This work builds on recent object-segmentation work by Farabet et al by augmenting the pixel-processing pathways with ones that processes a depth map from a Kinect RGBD camera.	O	O	Review	7
This work seems to me a well-motivated and natural extension now that RGBD sensors are readily available.	O	O	Review	7
<sep> <sep> The incremental value of the depth channel is not entirely clear from this paper.	B-Review	B-1	Review	7
In principle, the depth information should be valuable.	I-Review	I-1	Review	7
However, Table 1 shows that for the majority of object types, the network that ignores depth is actually more accurate.	I-Review	I-1	Review	7
Although the averages at the bottom of Table 1 show that depth-enhanced segmentation is slightly better, I suspect that if those averages included error bars (and they should), the difference would be insignificant.	I-Review	I-1	Review	7
In fact, all the accuracies in Table 1 should have error bars on them.	I-Review	I-1	Review	7
The comparisons with the work of Silberman et al are more favorable to the proposed model, but again, the comparison would be strengthened by discussion of statistical confidence.	I-Review	I-1	Review	7
<sep> <sep> Qualitatively, I would have liked to see the ouput from the convolutional network of Farabet et al without the depth channel, as a point of comparison in Figures 2 and 3.	B-Review	B-2	Review	7
Without that point of comparison, Figures 2 and 3 are difficult to interpret as supporting evidence for the model using depth.	I-Review	I-2	Review	7
<sep> <sep> Pro(s)	O	O	Review	7
- establishes baseline RGBD results with convolutional networks	O	O	Review	7
Con(s)	O	O	Review	7
- quantitative results lack confidence intervals	B-Review	B-1	Review	7
- qualitative results missing important comparison to non-rgbd network	B-Review	B-2	Review	7
Thank you for your review and  helpful comments.	B-Reply	B-1	Reply	7
We computed and added error bars as suggested in Table 1.	I-Reply	I-1	Reply	7
However, computing standard deviation for the individual means per class of objects does not apply here: the per class accuracies are not computed image per image.	I-Reply	I-1	Reply	7
Each number corresponds to a ratio of the total number of correctly classified pixels as a particular class, on the number of pixels belonging to this class in the dataset.	I-Reply	I-1	Reply	7
<sep> For the pixel-wise accuracy, we now give the standard deviation in Table 1, as well as the median.	I-Reply	I-1	Reply	7
As the two variances are equal using depth or not, we computed the statistical significance using a two sample t-test, that results in a t statistic equal to 1.54, which is far from the mean performance of 52.2 and thus we can consider that the two reported means are statistically significant.	I-Reply	I-1	Reply	7
<sep> <sep> About the class-by class improvements displayed in Table 1, we discuss the fact that objects having a constant appearance of depth are in general more inclined to take benefit from depth information.	I-Reply	I-1	Reply	7
As the major part of the scenes contains categories that respect this property, the improvements achieved using depth involve a smaller number of categories, but a larger volume of data.	I-Reply	I-1	Reply	7
<sep> To strengthen our comparison of the two networks using or not depth information, we now display the results obtained using only the multiscale network without depth information in Figure 2.	B-Reply	B-2	Reply	7
<sep> <sep> We hope that the changes that we made in the paper (which should be updated within the next 24 hours) answer your concerns.	O	O	Reply	7

This work applies convolutional neural networks to the task of RGB-D indoor scene segmentation.	O	O	Review	7
The authors previously evaulated the same multi-scale conv net architecture on the data using only RGB information, this work demonstrates that for most segmentation classes providing depth information to the conv net increases performance.	O	O	Review	7
<sep> <sep> The model simply adds depth as a separate channel to the existing RGB channels in a conv net.	B-Review	B-1	Review	7
Depth has some unique properties e.g. infinity / missing values depending on the sensor.	I-Review	I-1	Review	7
It would be nice to see some consideration or experiments on how to properly integrate depth data into the existing model.	I-Review	I-1	Review	7
<sep> <sep> The experiments demonstrate that a conv net using depth information is competitive on the datasets evaluated.	B-Review	B-2	Review	7
However, it is surprising that the model leveraging depth is not better in all cases.	I-Review	I-2	Review	7
Discussion on where the RGB-D model fails to outperform the RGB only model would be a great contribution to add.	I-Review	I-2	Review	7
This is especially apparent in table 1.	I-Review	I-2	Review	7
Does this suggest that depth isn't always useful, or that there could be better ways to leverage depth data?	I-Review	I-2	Review	7
<sep> <sep> <sep> Minor notes:	O	O	Review	7
'modalityies' misspelled on page 1	O	O	Review	7
<sep> Overall:	O	O	Review	7
- A straightforward application of conv nets to RGB-D data, yielding fairly good results	O	O	Review	7
- More discussion on why depth fails to improve performance compared to an RGB only model would strengthen the experimental findings	O	O	Review	7
Thank you for your review and helpful comments.	O	O	Reply	7
<sep> The missing values in the depth acquisition were pre-processed using inpainting code available online on Nathan Siberman‚Äôs web page.	B-Reply	B-1	Reply	7
We added the reference to the paper.	I-Reply	I-1	Reply	7
<sep> In the paper, we made the observation that the classes for which depth fails to outperform the RGB model are the classes of object for which the depth map does not vary too much.	B-Reply	B-2	Reply	7
We now stress out better this observation with the addition of some depth maps at Figure 2.	I-Reply	I-2	Reply	7
<sep> <sep> The question you are raising about whether or not the depth is always useful, or if there could be better ways to leverage depth data is a very good question, and at the moment is still un-answered.	O	O	Reply	7
The current RGBD  multiscale network is the best way we found to learn features using depth, now maybe we could improve the system by introducing an appropriate contrast normalization of the depth map, or maybe we could combine the learned features using RGB and the learned features using RGBD‚Ä¶	O	O	Reply	7

Segmentation with multi-scale max pooling CNN, applied to indoor vision, using depth information.	O	O	Review	7
Interesting paper!	O	O	Review	7
Fine results.	O	O	Review	7
<sep> <sep> Question: how does that compare to multi-scale max pooling CNN for a previous award-winning application, namely, segmentation of neuronal membranes (Ciresan et al, NIPS 2012)?	B-Review	B-1	Review	7
Thank you for your review and pointing out the paper of Ciresan et al that we added to our list of references.	B-Reply	B-1	Reply	7
Similarly to us, they apply the idea of using a kind of multi-scale network.	I-Reply	I-1	Reply	7
However, Ciseran's approach to foveation differs from ours: where we use a multiscale pyramid to provide a foveated input to the network, they artificially blur the input's content, radially, and use non-uniform sampling to connect the network to it.	I-Reply	I-1	Reply	7
The major advantage of using a pyramid is that the whole pyramid can be applied convolutionally, to larger input sizes.	I-Reply	I-1	Reply	7
Once the model is trained, it must be applied as a sliding window to classify each pixel in the input.	I-Reply	I-1	Reply	7
Using their method, which requires a radial blur centered on each pixel, the model cannot be applied convolutionally.	I-Reply	I-1	Reply	7
This is a major difference, which dramatically impacts test time.	I-Reply	I-1	Reply	7
<sep> <sep> Note: Ciseran's 2012 NIPS paper appeared after our first paper (ICML 2012) on the subject.	O	O	Reply	7

Learning Information Spread	O	O	Review	7
<sep> The ms considers the interesting question of diffusion and information spreading in content networks.	O	O	Review	7
The modeling is performed by a diffusion kernel with ranking and classification constraints; having both is an innovation.	O	O	Review	7
<sep> <sep> While the paper is generally clear, I miss details on how this is exactly done and how this is optimized.	B-Review	B-1	Review	7
The optimization problem seems nontrivial, so it would be nice to know the computational effort.	I-Review	I-1	Review	7
<sep> While first experiments show encouraging results, it is unclear whether in a simple toy problem the proposed estimation algorithm will find the ground truth consistently.	B-Review	B-2	Review	7
<sep> Furthermore no comparison to other models that consider information spread are given, neither in speed/scaling nor accuracy/severity of errors.	B-Review	B-3	Review	7
<sep> Concluding, the paper is interesting but somewhat preliminary; it consists in a small increment over Bourigault et al 2014 and lacks many  details.	B-Review	B-4	Review	7
Dear reviewer,	O	O	Reply	7
<sep> Thank you for your comments.	O	O	Reply	7
<sep> <sep> The lack of details was mainly due to the official paper size limitation (3 pages), but submitting longer papers seem to be possible.	B-Reply	B-4	Reply	7
<sep> <sep> We have posted a new version of the paper on Arixv that contains:	O	O	Reply	7
* the pseudo-code of the SGD algorithm	B-Reply	B-1	Reply	7
* A paragraph concerning the learning and inference complexity of the model, showing its efficiency w.r.t existing discrete approaches	B-Reply	B-2	Reply	7
* A comparison with state of the art baselines in the experimental section	B-Reply	B-3	Reply	7
<sep> Ludovic	O	O	Reply	7

The paper investigates methods to train neural networks so the final network has sparse weights, both in convolutional layers and in fully connected layers.	O	O	Review	20401
In particular, the paper focuses on modifying the training so that the network is first trained without sparsification for a certain number of epochs, then trained to be increasingly sparse, and then fine-tuned with a fixed sparsity pattern at the end.	O	O	Review	20401
<sep> <sep> While I find the overall approach of the paper interesting, currently the experiments are not systematic enough to derive clear insights from the paper.	O	O	Review	20401
Hence I unfortunately recommend rejecting the paper at this point.	B-Review	B-10	Review	20401
I hope the authors find time to conduct more systematic experiments for a future version of the paper.	I-Review	I-10	Review	20401
<sep> <sep> Concretely, the following would be interesting experiments / questions:	O	O	Review	20401
<sep> - How effective is the proposed training method on architectures other than ResNets?	B-Review	B-1	Review	20401
<sep> <sep> - What happens if the "pruning era" is made longer, started substantially earlier, or started substantially later?	B-Review	B-2	Review	20401
Currently it is not clear if the epoch 30 - 50 pruning era is (approximately) optimal and how much performance varies with begin and end of the pruning era.	I-Review	I-2	Review	20401
<sep> <sep> - Due to the small variation between some of the methods, it would be good to investigate how robust the ordering is when the experiment is re-ran with different random seeds etc.	B-Review	B-3	Review	20401
<sep> <sep> <sep> In addition, I have the following suggestions:	O	O	Review	20401
<sep> - The authors may want to remove or enhance the adversarial robustness evaluation.	B-Review	B-4	Review	20401
Currently the authors only evaluate robustness against FGSM, but it is well known that iterative attacks such as PGD are more effective.	I-Review	I-4	Review	20401
<sep> <sep> - Instead of "intra-epoch pruning" or "intra", the name "combined" may be more clear for the combined method.	B-Review	B-5	Review	20401
<sep> <sep> - In the description of the experimental setup, it could be good to specify what GPUs were used (since this lead to the smaller batch size).	B-Review	B-6	Review	20401
<sep> <sep> - It could be helpful for the reader to discuss how predictive results on Tiny-ImageNet are for results on ImageNet.	B-Review	B-7	Review	20401
<sep> <sep> - In Table 2, it would be good to add context by comparing to prior work with sparsity level 60% and some of the compression-focused methods from Table 4.	B-Review	B-8	Review	20401
<sep> <sep> - In the comparison to Mao et al (2017), it could be good to clarify that they also work with ResNet models on ImageNet.	B-Review	B-9	Review	20401
<sep> <sep> (1) Our argument for only using one architecture is that Resnet networks are the benchmark for MLPerf and the hardest/longest networks to train.	B-Reply	B-1	Reply	20401
All other recent work on CNNs use Resnet, on Imagenet and some smaller datasets, as well.	I-Reply	I-1	Reply	20401
However, to address this concern we will add experiments on VGG.	I-Reply	I-1	Reply	20401
<sep> (2) The main goal of this approach is to restrict the pruning era to reduce complexity especially on accelerators.	B-Reply	B-2	Reply	20401
We also aimed to reach a fixed sparsity mask as early as possible.	I-Reply	I-2	Reply	20401
Keeping the above goal in mind, we did perform sensitivity analysis (shown in Table 1) keeping the final convergence accuracy as high as possible.	I-Reply	I-2	Reply	20401
We demonstrated that shrinking the pruning era damages the accuracy.	I-Reply	I-2	Reply	20401
On top of that we moved the pruning era 10 epochs earlier or later in training and studied wider pruning schedules.	I-Reply	I-2	Reply	20401
<sep> (3) This is a good suggestion; however, what prevented us from doing this is that these experiments we demonstrated each take several days of training per data point.	B-Reply	B-3	Reply	20401
To just perform the sensitivity analysis on the width of the pruning era it took us several months.	I-Reply	I-3	Reply	20401
We can definitely perform these analysis for smaller networks and datasets.	I-Reply	I-3	Reply	20401
<sep> (4) Thanks for the suggestion regarding adversarial attacks.	B-Reply	B-4	Reply	20401
We will investigate PGD.	I-Reply	I-4	Reply	20401
However, we believe that finding that structured sparse training is robust for FGSM is still valuable as other work show.	I-Reply	I-4	Reply	20401
<sep> (5) Thanks we will fix the name of intra-epoch pruning to combined method to improve clarity.	B-Reply	B-5	Reply	20401
<sep> (6) We used RTX2080 instances.	B-Reply	B-6	Reply	20401
We will add that to the paper.	I-Reply	I-6	Reply	20401
<sep> (7) Very valid point regarding the productivity of the Tiny-Imagenet results.	B-Reply	B-7	Reply	20401
We will add this.	I-Reply	I-7	Reply	20401
<sep> (8) Regarding Table2, compression focused methods take around 180 epochs of training if aiming for levels of accuracy that reported.	B-Reply	B-8	Reply	20401
If not, they have much worse accuracy numbers without providing structured sparsity and without the potential of computation savings during training.	I-Reply	I-8	Reply	20401
So, we chose to only compare with sparse training methods.	I-Reply	I-8	Reply	20401
<sep> (9) Thanks, we will clarify that Mao et al (2017) worked with Resnet/Imagenet.	B-Reply	B-9	Reply	20401

SUMMARY	O	O	Review	20401
-------	O	O	Review	20401
This paper explores a series of incremental variations of existing pruning techniques for compressing Resnet-50 for ImageNet.	O	O	Review	20401
Specifically, it proposes concentrating all pruning during an early "era" of training (the first 20-50 epochs out of 100 total).	O	O	Review	20401
It also explores hybrids between sparse pruning and structured pruning.	O	O	Review	20401
Finally, it considers the adversarial robustness of the resulting networks to the FGSM attack.	O	O	Review	20401
This paper makes no novel proposals and experiments are minimal.	O	O	Review	20401
There are no clear takeaways from the results of these experiments.	O	O	Review	20401
The goals of the paper are unclear, and it is difficult to compare this paper to existing work.	O	O	Review	20401
This paper has no clear motivation and makes no tangible contributions to the literature and, therefore, I recommend a rejection.	O	O	Review	20401
CONTRIBUTIONS	O	O	Review	20401
-------------	O	O	Review	20401
1) A study of the appropriate window ("pruning era") for pruning Resnet-50 on ImageNet and TinyImageNet	O	O	Review	20401
2) A study of the tradeoffs between various forms of structured and unstructured pruning.	O	O	Review	20401
3) An analysis of the adversarial robustness of the pruned networks.	O	O	Review	20401
DETAILED COMMENTS	O	O	Review	20401
------	O	O	Review	20401
PROBLEMS ADDRESSED	O	O	Review	20401
It was challenging to discern the specific problems that this paper sought to address and, relatedly, the goals that the paper sought to achieve.	O	O	Review	20401
The introduction of the paper lists a wide variety of problems in the existing literature:	O	O	Review	20401
1) Paragraph 3: Structured sparsity introduces "regularization and computational overhead."	O	O	Review	20401
2) Paragraph 3: "Coarse-grained sparsity" cannot eliminate enough parameters to perform well on "edge devices."	O	O	Review	20401
3) Paragraph 4: Dynamic sparsity techniques require more training epochs.	O	O	Review	20401
4) Paragraph 4: Dynamic sparsity techniques do not preserve network accuracy (1-2 percentage point drop at 80% sparsity).	O	O	Review	20401
5) Paragraph 4: Dynamic sparsity requires reconfiguring the sparsity pattern frequently, which is computationally expensive.	O	O	Review	20401
The paper does not justify the fact that any of these are actually problems, nor does it make any attempt to quantify the extent of these problems.	O	O	Review	20401
Moreover, the proposed techniques do not resolve any of these problems.	O	O	Review	20401
Corresponding to the numbers above:	O	O	Review	20401
1) The paper never measures this overhead nor justifies that it is a problem in practice.	O	O	Review	20401
Meanwhile, the techniques proposed in the paper introduce substantial overhad of their own, including training for an extra ten epochs.	O	O	Review	20401
It is possible that the techniques proposed in this paper have worse overhead than the techniques that are criticized in the introduction.	O	O	Review	20401
Since the paper provides on numbers either way, it is impossible to tell.	O	O	Review	20401
In short, computational cost is a key part of the author's argument despite the fact that there is no empirical support for any of these claims.	O	O	Review	20401
2) I believe the paper means that, in order to get to sufficient levels of sparsity to work on "edge devices," accuracy drops unacceptably far.	O	O	Review	20401
What does the paper mean by "edge devices," what are sufficient levels of sparsity, and what does it mean for accuracy to drop unacceptably far?	O	O	Review	20401
The paper has numbers for the proposed methods, so it should be possible to make this comparison if such baselines are explicit.	O	O	Review	20401
3) The proposed techniques also require the same number of additional training epochs, so this complaint is unaddressed.	O	O	Review	20401
4) The proposed techniques show a 2-3 percentage point drop at 80% sparsity (Table 1), which is actually worse than the technique that the authors criticize.	O	O	Review	20401
5) The proposed techniques require pruning after every single training step during the "pruning era."	O	O	Review	20401
This is likely to be more computationally expensive than any of the other gradual pruning and dynamic sparsity techniques listed, which prune at intervals of hundreds or thousands of iterations.	O	O	Review	20401
In addition, the authors never justify why changing the sparsity pattern frequently throughout training will affect performance.	O	O	Review	20401
On GPUs with modern frameworks, I see no reason why this should matter so long as the sparsity pattern does not change too frequently (although that is exactly what this paper proposes to do during the "pruning era").	O	O	Review	20401
GOALS	O	O	Review	20401
It was also challenging to discern the goals of the paper.	O	O	Review	20401
Was it:	O	O	Review	20401
1) To produce the smallest possible trained networks with the highest possible accuracy?	O	O	Review	20401
2) To reduce the cost of obtaining a pruned network for inference-time? (	O	O	Review	20401
Or to reduce the cost of obtaining a sufficiently efficient pruned network for inference-time?)	O	O	Review	20401
3) To reduce the cost of training neural networks in general by pruning them during training?	O	O	Review	20401
In the introduction and the related work section, these goals go unstated, making it difficult to determine how this paper compares to existing work.	O	O	Review	20401
The comparisons provided in the paper focus on specific aspects of each related work rather than the entire picture.	O	O	Review	20401
For example, in comparison to Mao et al the authors claim better accuracy at one sparsity level, implying goal 1.	O	O	Review	20401
However, for to Lym et al the paper focuses on the computational costs of training the network, implying goal 3.	O	O	Review	20401
UNJUSTIFIED CLAIMS ABOUT NEURAL NETWORK COMPUTATION	O	O	Review	20401
Throughout the paper, there are a number of unjustified claims about which neural network configurations will perform better on contemporary hardware.	O	O	Review	20401
Considering computational efficiency appears to be a key element of the paper's argument, these claims require citations or - particularly when various configurations are compared to one another - empirical support.	O	O	Review	20401
Some examples:	O	O	Review	20401
* Section 1, Paragraph 3: "The regularization term [of structured sparsity] modifies the original training and can be expensive in hardware."	O	O	Review	20401
* Section 1, Paragraph 3: "The final network [from Lym et al 2019] contains an insufficient degree of sparsity for deployment on edge devices."	O	O	Review	20401
* Section 1, Paragraph 4: "Continuous reconfiguration of the sparsity pattern is expensive as it does not allow for compression of weights during training"	O	O	Review	20401
* Section 1, Paragraph 5: "having a fixed sparse multiply-accumulate pattern allows weight compression during training and can save compute and energy in hardware"	O	O	Review	20401
* Section 5, Paragraph 2: "A strict parameter allows the hardware mapping to plan for a fixed number of multiply-accumulate operations."	O	O	Review	20401
* Section 5, Paragraph 2: "Regularization, although useful in forcing the network to learn prunable weights, adds more irregularity to computation flow."	O	O	Review	20401
PRUNING TECHNIQUES	O	O	Review	20401
* Recomputing the pruning mask at every training step seems gratuitously inefficient.	O	O	Review	20401
* Sorting the weights in the entire network shouldn't be particularly inefficient if it isn't done on every single iteration. (	O	O	Review	20401
Section 2.1 paragraph 1)	O	O	Review	20401
* Why do you maintain the same number of weights in each convolutional filter with window pruning? (	O	O	Review	20401
Presumably for performance reasons, but you never say that.)	O	O	Review	20401
* None of the pruning methods are novel.	O	O	Review	20401
They're simply various permutations of structured and unstructured magnitude pruning as proposed by many others in the literature.	O	O	Review	20401
EXPERIMENTS	O	O	Review	20401
* Section 3.1 Paragraph 2: It appears that you are exploring the best "pruning era."	O	O	Review	20401
If you are to do so, you will have to sweep over (1) the length of the pruning era (2) the starting epoch of the pruning era, and (3) the shape of the function used to determine sparsity.	O	O	Review	20401
Instead, it sounds like you tried two arbitrary pruning eras (0-30 and 30-50).	O	O	Review	20401
Likewise, in Paragraph 3, you test only a small number of possible scenarios.	O	O	Review	20401
* Section 3.1 is generally hard to parse.	O	O	Review	20401
It is unclear what you are studying.	O	O	Review	20401
The ideal pruning era?	O	O	Review	20401
The relative performance of the pruning methods introduced in section 2?	O	O	Review	20401
* How many times did you replicate each experiment?	O	O	Review	20401
You should ideally include at least 3 (and preferrably 5) replicates with mean and stddev reported.	O	O	Review	20401
* What baselines are you including?	O	O	Review	20401
You should include a random pruning baseline and you should ideally replicate any methods that you compare to.	O	O	Review	20401
RESULTS	O	O	Review	20401
* Section 4.1: The data you refer to is in an appendix even though it is crucial to the main body of the paper.	O	O	Review	20401
The appendices should contain material that is nonessential for making sense of the paper.	O	O	Review	20401
* Section 4.2 Paragraph 1: Are these numbers good?	O	O	Review	20401
A standard sparse pruning technique (Gale et al 2019, <a href="https://arxiv.org/pdf/1902.09574.pdf)" target="_blank" rel="nofollow">https://arxiv.org/pdf/1902.09574.pdf)</a> achieve 70% sparsity without any change in accuracy.	O	O	Review	20401
Please include baselines comparing to other methods in the literature.	O	O	Review	20401
* Table 2: It is difficult to compare the results in these papers.	O	O	Review	20401
PruneTrain aims to reduce the cost of training and measures cost reductions in FLOPS.	O	O	Review	20401
If you intend to compare against this paper, you should quantify the cost of training using your method against that of PruneTrain.	O	O	Review	20401
Merely presenting sparsity and accuracy numbers is insufficient.	O	O	Review	20401
Likewise for the dynamic sparsity experiments.	O	O	Review	20401
What is your goal in showing this comparison, and did Mostafa and Wang share that goal when they justified their technique?	O	O	Review	20401
* You do not describe the hyperparameters for Intraepoch pruning (the balance between window and CK - last paragraph of 2.1.1)	O	O	Review	20401
ADVERSARIAL ROBUSTNESS	O	O	Review	20401
Considering the fact that this paper focuses on proposing new variations of existing pruning techniques, any discussion of adversarial robustness seems to be (1) out of place and (2) an afterthought.	O	O	Review	20401
If the authors delete a half-page of content (one phrase from the abstract, a paragraph and bullet from the introduction, and a paragraph each from sections 3 and 4), this content could be removed with minimal impact to the paper's main contributions.	O	O	Review	20401
The content on adversarial robustness is cursory, uses a weak and out-of-date attack (FGSM), and does not compare to any other pruning methods.	O	O	Review	20401
In fact, the one comparison is to the results in a paper (Wang et al, 2018) that looks at both FGSM and PGD (a stronger attack) on completely different networks and tasks (MNIST and CIFAR10).	O	O	Review	20401
The paper would be stronger if content on adversarial robustness was removed entirely.	O	O	Review	20401
OTHER MINOR COMMENTS	O	O	Review	20401
* The title includes the word "starfire," but it never appears again in the paper.	O	O	Review	20401
The paper proposes no specific technique, so there isn't anything to name.	O	O	Review	20401
* Use the \ begin{appendix} command before you create the appendices and the \ end{appendix} command when you are done.	O	O	Review	20401
You can then use \section normally and each section so-created will appear with a letter rather than a number.	O	O	Review	20401
* Figure 4 is very hard to read.	O	O	Review	20401
(1) This paper studies the sparse training for maximum convergence accuracy of Resnet50  with Imagenet and delivers the best result for sparse training with static mask for over 70-80 epochs of training schedule in terms accuracy and acceleration potential.	O	O	Reply	20401
The experiments performed all the sensitivity studies and report over 34 experiments covering various levels of sparsity, length pruning era, start epoch of pruning era, both Resnet50 v1 and v1.5, and various sparsity granularities just in Table 1 alone.	O	O	Reply	20401
To give a context some of the main references in Table 2 report less than 10 data points.	O	O	Reply	20401
(2) Thanks for you for comment regarding the problems we highlighted with current literature.	O	O	Reply	20401
We will cite literature to address all the above.	O	O	Reply	20401
Just to give context:	O	O	Reply	20401
1) Regularization contains operations such as vector norm (normalization, divide, square root) that are not typically multiply accumulate nature and hence are expensive for accelerators and GPUs as they are atypical with high latency.	O	O	Reply	20401
2) Sorry for the miscommunication, our meaning with this sentence was that the levels of sparsity in previous coarse grain sparsity methods were not high-enough for a given convergence accuracy.	O	O	Reply	20401
Therefore, the overheads incurred to handle sparsity (indexing/compression/decompression) were not justified.	O	O	Reply	20401
Our main point is that edge devices are one example area where a high level of coarse grained sparsity while maintaining accuracy is desirable, and this paper achieved this goal.	O	O	Reply	20401
This paper also achieves similar goals for sparse training that we will address below.	O	O	Reply	20401
3-4) This is supported by Table 2: given a target convergence accuracy Mostafa and Wang had to train for an extra 10 epochs (100 epochs) to be able to reach within 1% of a 90 epoch baseline.	O	O	Reply	20401
We showed our results at all relevant epochs and the difference to baseline both at 90 and 100 epochs.	O	O	Reply	20401
5) This reconfiguration happens throughout the whole network.	O	O	Reply	20401
Restructuring the sparsity masks is extremely expensive in any system.	O	O	Reply	20401
It includes decompression and recompression which in turn triples memory accesses.	O	O	Reply	20401
Replacing the non-zeros and refreshing the indexes is a memory intensive operation.	O	O	Reply	20401
It has high latencies and high energy consumption.	O	O	Reply	20401
However ours only happens after every epoch.	O	O	Reply	20401
This was represented as after every step in Algorithm 1, and we will correctly update the figure to accurately represent our mask update schedule.	O	O	Reply	20401
(3) We can show the nature of the computation incurred for reparametrization.	O	O	Reply	20401
While the point is taken that we have no empirical study to support this, we make the argument that our overheads are minimal given that they are only incurred during 20% of total training schedule and that we eliminated regularization overheads.	O	O	Reply	20401
Also, we update the sparsity only for a total of 20 times once/epoch during pruning era (again this was misrepresented in Algorithm 1 and will be corrected).	O	O	Reply	20401
(4) The reason we mentioned edge devices was to highlight that the accuracy drop does not justify using low levels of sparsity because the overheads of indexing/compression/decompression are higher than just keeping data dense. [	O	O	Reply	20401
<a href="https://en.wikipedia.org/wiki/Sparse_matrix]" target="_blank" rel="nofollow">https://en.wikipedia.org/wiki/Sparse_matrix]</a> [<a href="https://kkourt.io/phd/phd-en.pdf]," target="_blank" rel="nofollow">https://kkourt.io/phd/phd-en.pdf],</a> [<a href="https://arxiv.org/pdf/1901.07827.pdf]." target="_blank" rel="nofollow">https://arxiv.org/pdf/1901.07827.pdf].</a>	O	O	Reply	20401
For example, CUSparse library performs only better than CUBLAS when degrees of sparsity are over 90% (<a href="https://developer.nvidia.com/cusparse)" target="_blank" rel="nofollow">https://developer.nvidia.com/cusparse)</a>	O	O	Reply	20401
(5) We show both convergence at epoch 90 and 100 for comparison to baseline and all other methods.	O	O	Reply	20401
The argument here is that those extra 10 epochs with high degrees of sparse training are much cheaper.	O	O	Reply	20401
The epoch 90 results are in Table 6 in the appendix.	O	O	Reply	20401
Even compared to 90 epoch baseline we drop less than 1% in accuracy.	O	O	Reply	20401
(6) Dynamic sparse reparametrization is impossible to implement on any target architecture because it changes sparsity mask every step.	O	O	Reply	20401
This means changing indexes of non-zeros and decompression/recompression at every step.	O	O	Reply	20401
This is basically infeasible on any accelerator.	O	O	Reply	20401
We contacted the authors and they told us they trained the network like a dense network.	O	O	Reply	20401
Our goals are clear: we want fixed sparsity mask after certain epoch and we wanted to eliminate any irregular computation that is expensive on accelerators.	O	O	Reply	20401
(7) This a mistake on our behalf in the algorithm text and it is actually after each epoch in our code.	O	O	Reply	20401
Thank you for pointing this out.	O	O	Reply	20401
We only prune total of 20 times (length of pruning era).	O	O	Reply	20401

This paper introduces a strategy to prune a convolutional neural network during training.	O	O	Review	20401
To speed up training, the proposed method prunes the weights with the smallest magnitude during only a small number of epochs at the beginning of training, later on continuing training with a fixed sparsity pattern.	O	O	Review	20401
Several granularity levels for convolutional and fully-connected layers are studied.	O	O	Review	20401
Furthermore, the robustness of the resulting pruned networks to adversarial attacks is investigated.	O	O	Review	20401
<sep> <sep> Originality:	O	O	Review	20401
- As acknowledged at the beginning of section two, the general pruning strategy used here is very similar to that introduced by Narang et al 2017.	B-Review	B-1	Review	20401
While the authors argued that the threshold is computed in a different manner, it also increases gradually during training, as in Narang et al 2017.	I-Review	I-1	Review	20401
<sep> - I acknowledge that Narang et al 2017 focuses on RNNs, while here the focus is on CNNs.	B-Review	B-1	Review	20401
However, the originality of the different pruning strategies used here for convolutional and fully-connected layers is very limited.	I-Review	I-1	Review	20401
In essence, these strategies directly follow those studied by Mao et al 2017.	I-Review	I-1	Review	20401
<sep> - The study of robustness to adversarial attacks, while interesting, is also not novel per se, as the idea of performing such a study was proposed in Wang et al  2018.	B-Review	B-1	Review	20401
I acknowledge that the conclusions drawn here differ from those in Wang et al 2018.	I-Review	I-1	Review	20401
However, there are no explanations for this different behavior.	I-Review	I-1	Review	20401
<sep> <sep> Methodology:	O	O	Review	20401
- While the beginning of Section 2 states that the pruning threshold gradually increases during training, the specific way this is achieved is not clearly explained.	B-Review	B-2	Review	20401
<sep> - The pruning strategies depicted by Fig.2, whether for convolutional layers or for fully-connected ones, never aim to remove entire output channels.	B-Review	B-2	Review	20401
However, the only way to truly end up with a smaller network is to remove entire channels and/or layers, as argued in Wen et al 2016 and in Alvarez &amp; Salzmann, NIPS 2016, as well as studied in Mao et al 2017 via the filter-level granularity.	I-Review	I-2	Review	20401
It is unclear to me how speed would be affected by having a network with the same number of channels and layers, but many parameters set to zero.	I-Review	I-2	Review	20401
<sep> <sep> Experiments:	O	O	Review	20401
- The experiments show the good behavior of the proposed algorithm in terms of sparsity vs accuracy tradeoff.	B-Review	B-3	Review	20401
However, while the introduction seems to focus on the benefits of the proposed method in terms of training speed, these benefits are not demonstrated in the experiments, where no timings (neither for training not for inference) are reported.	I-Review	I-3	Review	20401
<sep> - As mentioned above, it is not clear to me that the speedup will be significant if the sparsity pattern does not remove entire channels, but I am willing to be proven wrong.	B-Review	B-3	Review	20401
<sep> <sep> Summary:	O	O	Review	20401
My main concern about this paper is its novelty, as the method essentially uses the method of Narang et al 2017, albeit with a different threshold, with the sparsity patterns of Mao et al 2017.	B-Review	B-1	Review	20401
The experiments demonstrate that the method is effective at pruning, but do not provide any timings to evaluate the resulting speedups.	I-Review	I-1	Review	20401
(1) We agree that our method is similar to Narang et al; however, achieving high levels of accuracy and high levels of structured sparsity for CNNs was missing; we contribute substantial experiments to find the limits of the final level of sparsity and how few epochs we can train for CNN.	B-Reply	B-1	Reply	20401
Also, Narang et al prune after every iteration while we prune after every epoch (for as little as 20 epochs out of 90), so there are much fewer updates in our method.	I-Reply	I-1	Reply	20401
We grant that the adversarial is not exactly novel.	I-Reply	I-1	Reply	20401
However, our goal was to investigate the robustness in presence of structured sparsity.	I-Reply	I-1	Reply	20401
<sep> (2) Thank you for pointing out that this is unclear.	B-Reply	B-2	Reply	20401
The gradual pruning is done as shown in Fig 1, but we will add prose to explain the process.	I-Reply	I-2	Reply	20401
Our goal is to provide structured sparsity, rather than speed up training, that is we would like to reduce the memory footprint but also structure it in a highly regular way that could be exploited by a hardware accelerator.	I-Reply	I-2	Reply	20401
As you say, this is setting parameters to 0, which is the goal of many.	I-Reply	I-2	Reply	20401
Please see Table 4 for a number of them.	I-Reply	I-2	Reply	20401
On top of that, all the hardware accelerators put mechanisms to skip computations with zeros please see reference [Han 2015b] for an example.	I-Reply	I-2	Reply	20401
<sep> (3) The background in the introduction regarding speedup seems to have mischaracterized our main intentions, so we will clarify that it is mainly to provide structured sparsity while maintaining accuracy.	B-Reply	B-3	Reply	20401
However, we would like to note that we noted we would get speedups from sparsification because we would reduce the total number of computations [Zhu et al 2019] [Parashar et al 2017] by having a small number of epochs in which we do pruning and fixing the sparsity masks to their final values early in training rather than sparsifying until the end of training or after training.	I-Reply	I-3	Reply	20401
<sep> Parashar, Angshuman, et al "SCNN: An accelerator for compressed-sparse convolutional neural networks."	O	O	Reply	20401
2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA).	O	O	Reply	20401
IEEE, 2017.	O	O	Reply	20401
<sep> Zhu, Maohua, et al "Sparse Tensor Core: Algorithm and Hardware Co-Design for Vector-wise Sparse Neural Networks on Modern GPUs."	O	O	Reply	20401
Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture.	O	O	Reply	20401
ACM, 2019.	O	O	Reply	20401

-Demonstrates that the sign approximation method slightly improves test error.	B-Review	B-1	Review	78
<sep> I'm not sure where you're seeing this -- on the test set, the sign approximation always increased the test error (as a function of how poor the approximation was).	I-Review	I-1	Review	78
One should e	I-Review	I-1	Review	78
I don't think the revised paper really addresses my main concern, which is that it's extremely difficult to get a speedup in practice from the proposed method.	B-Reply	B-1	Reply	78
I think you'll have quite a lot of difficulty doing so with cuda-convnet, since GPUs generally do not handle applications with a lot of branching well.	I-Reply	I-1	Reply	78
<sep> <sep> While I understand that you're trying to see how much your method degrades neural net performance rather than trying to get a new state of the art result, I think it is important to work with state of the art methods and large models.	I-Reply	I-1	Reply	78
When starting with a small or underperforming baseline, you might obtain a result showing that your method doesn't harm performance, merely because the base performance was poor and easily captured by a simpler model family.	I-Reply	I-1	Reply	78
<sep> <sep> The paper by Leonard et al is quite a bit different than what you are doing.	I-Reply	I-1	Reply	78
You are trying to learn which values are zero after using a standard training procedure.	I-Reply	I-1	Reply	78
Leonard et al are training a net to intentionally *make more of the activations zero*. Their procedure explicitly groups the zeros into contiguous blocks, so that the indexing logic required to ignore the zeros is cheap.	I-Reply	I-1	Reply	78
Also, the secondary network used to determine which blocks should be computed is significantly smaller than the primary classification network.	I-Reply	I-1	Reply	78
In your case, the secondary network has the same number of outputs as the primary network has hidden units.	I-Reply	I-1	Reply	78
Despite all of these advantages over your approach, Leonard et al still didn't demonstrate a speedup, so I think your approach will really be fighting an uphill battle to get one.	I-Reply	I-1	Reply	78
<sep> <sep> Getting 1.05% or below on MNIST is not hard with dropout.	I-Reply	I-1	Reply	78
Grad students from both Nando de Freitas and Yoshua Bengio's lab have replicated that result without any trouble.	I-Reply	I-1	Reply	78

This paper presents a convLSTM based audio frame prediction approach as a method of unsupervised learning of representative audio features.	O	O	Review	78
Proposed model is  trained using a combination of mean squared error as well as a pair wise similarity measure.	O	O	Review	78
Model and the training approach are evaluated on the task of audio event classification.	O	O	Review	78
<sep> <sep> While the combination of the ideas is novel, the individual elements model and training approach are previously known.	B-Review	B-1	Review	78
It is also not intuitively clear why a predictive auto-encoding would be a good unsupervised feature learning approach for the task of audio event classification, thus I‚Äôd like to see comparisons with some well known basic unsupervised feature learning approaches (e.g. VAE, ladder networks, etc.).	I-Review	I-1	Review	78
<sep> <sep> Results are presented on an audio event detection dataset which is relatively new and not many reference comparisons are available.	B-Review	B-2	Review	78
To make the paper stronger I‚Äôd also advise authors provide comparisons with other known results on this task, and also to apply their feature learning approach to other well established sound classification tasks (e.g. phone classification in TIMIT).	I-Review	I-2	Review	78
<sep> <sep> Overall I feel the paper is not strong enough in current shape for ICLR.	B-Review	B-3	Review	78
Thank you very much for the valuable feedback.	O	O	Reply	78
<sep> <sep> In contrast to images or videos, acoustic events are almost solely characterized by temporal changes.	B-Reply	B-1	Reply	78
Considering this temporal change is necessary for a good classification (see references in the paper) whereas much information about a video can already be identified from still images.	I-Reply	I-1	Reply	78
The predictive autoencoder was used instead of a normal autoencoder to exploit this time dependency and has shown better results.	I-Reply	I-1	Reply	78
These experiments are not part of the current version of the paper due to the page limit.	I-Reply	I-1	Reply	78
<sep> <sep> The submitted paper reflects the state of the work and its core idea and thus has been submitted to the Workshop Track.	I-Reply	I-1	Reply	78
Therefore the comparison to other methods is missing but indeed necessary for a full evaluation of the proposed method.	I-Reply	I-1	Reply	78
This is being worked on at the moment.	I-Reply	I-1	Reply	78
However, we see a fundamental difference to the mentioned approaches (VAE, ladder networks).	I-Reply	I-1	Reply	78
Due to the pairwise loss an inter-sample comparison is achieved, while the mentioned methods only optimize for the current input sample.	I-Reply	I-1	Reply	78
From the paper it can be seen that due to this inter-sample comparison we can not only extract features but can make them distinct, which helps for the intended exploration of a dataset.	I-Reply	I-1	Reply	78
Having said this, a comparison to these other approaches will definitely strengthen the paper.	I-Reply	I-1	Reply	78
<sep> <sep> The dataset has been chosen to be close to the designated application.	B-Reply	B-2	Reply	78
Therefore key aspects of the presented work rely on the specific application scenario (e.g. time-dependency, variety of sound sources).	I-Reply	I-2	Reply	78
Available references like for the TIMIT dataset are not suitable for a fair comparison, since the applied algorithms are optimized for speech/phonetic classification while our proposed approach is designed to work for general audio analysis without prior knowledge.	I-Reply	I-2	Reply	78
<sep> <sep> Despite its relation to the application the used AED dataset has been chosen because it contains a large number of samples per category (around 20 minutes/category), which is beneficial to train the network, whereas ESC-50 ( <a href="https://github.com/karoldvl/ESC-50" target="_blank" rel="nofollow">https://github.com/karoldvl/ESC-50</a> ) and DCASE2016 ( <a href="http://www.cs.tut.fi/sgn/arg/dcase2016/" target="_blank" rel="nofollow">http://www.cs.tut.fi/sgn/arg/dcase2016/</a> ) contain less training samples (3 minutes/category and <1 minute/category, respectively).	I-Reply	I-2	Reply	78
Therefore a meaningful comparison between the different datasets with the settings from the current paper was not possible.	I-Reply	I-2	Reply	78
However, the recently released AudioSet ( <a href="https://research.google.com/audioset/" target="_blank" rel="nofollow">https://research.google.com/audioset/</a> ) can fill this gap.	I-Reply	I-2	Reply	78

This paper combines several ideas, ConvLSTM autoencoders and a pairwise lose.	O	O	Review	78
The idea is to do sound classification/clustering.	O	O	Review	78
<sep> <sep> I feel this paper is more suited towards the signal processing community (i.e., ICASSP/INTERSPEECH).	O	O	Review	78
The main problem I have with this paper/task it seems too specific and there isn't enough core-ML contributions for this round of ICLR workshop acceptance.	B-Review	B-1	Review	78
Sequence autoencoders (see Dai et al) and ConvLSTM (as cited by authors Zhang et al) and pair wise losses (see SIGIR) are not new.	I-Review	I-1	Review	78
Merging all these ideas together is a contribution, but I am not sure it would generate a lot of interest in the ICLR community.	I-Review	I-1	Review	78
<sep> <sep> Note:	O	O	Review	78
This reviewer is unfamiliar w/ the "acoustic event dataset (AED) from Takahashi et al (2016)" used in evaluation.	O	O	Review	78
<sep> <sep> Citations Missing:	B-Review	B-2	Review	78
<a href="https://arxiv.org/pdf/1511.01432.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1511.01432.pdf</a> (for sequence autoencoders which this model is quite similar).	I-Review	I-2	Review	78
Thank you for your review and your feedback.	O	O	Reply	78
The missing citation will be corrected in the next paper revision.	B-Reply	B-2	Reply	78
<sep> <sep> We understand your point that the paper is quite specific in its application, which might not be the preferred application for some people at ICLR, but we submitted the paper to ICLR Workshop Track because the conference topics in the Call for Abstracts include	B-Reply	B-1	Reply	78
<sep> + Unsupervised, semi-supervised, and supervised representation learning	I-Reply	I-1	Reply	78
+ Applications in vision, audio, speech, natural language processing, robotics, neuroscience, or any other field	I-Reply	I-1	Reply	78

SUMMARY: Unsupervised/Self-supervised generative model for image synthesis using 3D depth and RGB consistency across camera views	O	O	Review	78
<sep> CLAIMS:	O	O	Review	78
- New technique for RGBD synthesis using loss in 3D space	O	O	Review	78
- Can disentangle camera parameters from content (I disagree slightly with "disentangle" since you are conditioning on camera parameters in the first place)	O	O	Review	78
- Different generator architectures can be used	O	O	Review	78
<sep> METHOD:	O	O	Review	78
Generate RGBD images of 2 different views, have an adversarial loss on the RGB image, have a content loss between RGB1 and warp(RGB2), have a depth loss between D1 and warp(D2)	O	O	Review	78
Equation 5:	O	O	Review	78
- Possibly either "c_{1-&gt;2}" needs to be replaced by "c_{2-&gt;1}", or "G_{RGB}(z, c_1) - warp(G_{RGB}(z, c_2), c_{1-&gt;2})" needs to be replaced by "warp(G_{RGB}(z, c_1), c_{1-&gt;2}) - G_{RGB}(z, c_2)" (or am I missing something?)	B-Review	B-1	Review	78
<sep> - Not entirely sure why there is a different "projection" operation, since both "warp" and "projection" are calculated from Equation 3.	B-Review	B-2	Review	78
I understand that "warp" is the combined Rt matrix that is estimated using the two views and Equation 3, assuming that the "d"s are correct.	I-Review	I-2	Review	78
Not sure what "projection" does though, possibly explain it better?	I-Review	I-2	Review	78
<sep> <sep> DECISION: Very clearly written paper, simple idea executed well	O	O	Review	78
<sep> The paper is clearly written and well organized.	O	O	Review	78
It uses a simple idea, and performs sufficient number of experiments to explore the idea.	O	O	Review	78
It is not very novel, but the paper shows its applicability with multiple architectures as a bonus.	O	O	Review	78
<sep> <sep> The figures showed results almost only from their method.	B-Review	B-3	Review	78
It would be great to pick one generator architecture, and elucidate more on the differences between not using their 3D loss and using it.	I-Review	I-3	Review	78
Good attempt though.	I-Review	I-3	Review	78
<sep> <sep> ADDITIONAL FEEDBACK:	O	O	Review	78
- Might not be "representation learning", instead it is learning a generative model.	B-Review	B-4	Review	78
<sep> - "3 EXPERIMETNS" -&gt; "3 EXPERIMENTS"	B-Review	B-5	Review	78
- The appendix should have more details on the equations and the specific formulations of warp  and projection operations	B-Review	B-6	Review	78
We would like to thank the reviewer for valuable comments. ‚	O	O	Reply	78
Ä®	O	O	Reply	78
<sep> Equation 5:	O	O	Reply	78
- Figure 3 in [1] shows the detailed illustration of the "warp" operation.	B-Reply	B-1	Reply	78
First, we calculate the position of pixels in G_{RGB}(z, c_1) when they are viewed from c_2 (c_{1-&gt;2} is used here), and warp G_{RGB}(z, c_2) according to the calculated positions with bilinear interpolation.	I-Reply	I-1	Reply	78
Therefore, the relative transformation matrix we need is c_{1-&gt;2}. We will add more explanation in the paper.	I-Reply	I-1	Reply	78
<sep> - Since the depth values in warp(G_{D}(z, c_2), c_{1-&gt;2}) are sampled from the depth values viewed from c_2, to compare G_{D}(z, c_1) with warp(G_{D}(z, c_2), c_{1-&gt;2}), we need to project the depth values of each pixel in G_{D}(z, c_1) to the viewpoint c_2.	B-Reply	B-2	Reply	78
This is what we call "projection".	I-Reply	I-2	Reply	78
We will add the explanation in the paper.	I-Reply	I-2	Reply	78
<sep> <sep> Differences between not using 3D loss and using it	O	O	Reply	78
- I will pick one generator and compare the generative results qualitatively in the paper.	B-Reply	B-3	Reply	78
Because PGGAN and StyleGAN without 3D loss cannot control camera poses, we can only compare the random generation results.	I-Reply	I-3	Reply	78
Comparisons on the 3D-latent-feature-based methods are already provided in Figure 4, 5 and Table 1, but we will add more results in the appendix.	I-Reply	I-3	Reply	78
<sep> <sep> Representation learning	O	O	Reply	78
- Learning generative models is often called "representation learning" because it can learn latent representations of the images [2, 3, 4, ...].	B-Reply	B-4	Reply	78
We will add a discussion about this in the paper.	I-Reply	I-4	Reply	78
<sep> ‚Ä®	O	O	Reply	78
[1] Tinghui Zhou, Matthew Brown, Noah Snavely, and David G Lowe.	O	O	Reply	78
Unsupervised learning of depth and ego-motion from video.	O	O	Reply	78
In CVPR, 2017.&nbsp;	O	O	Reply	78
[2] Alec Radford, Luke Metz, and Soumith Chintala.	O	O	Reply	78
Unsupervised representation learning with deep convolutional generative adversarial networks.	O	O	Reply	78
In ICLR, 2016.&nbsp;	O	O	Reply	78
[3] Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel.	O	O	Reply	78
Infogan: Interpretable representation learning by information maximizing generative adversarial nets.	O	O	Reply	78
In NIPS, 2016.	O	O	Reply	78
<sep> [4] Thu Nguyen-Phuoc, Chuan Li, Lucas Theis, Christian Richardt, and Yong-Liang Yang.	O	O	Reply	78
Hologan: Unsupervised learning of 3d representations from natural images.	O	O	Reply	78
2019.	O	O	Reply	78

The submission proposes a technique to learn RGBD image synthesis from RGB images.	O	O	Review	78
A distinctive feature proposed by the technique is the user-controllable camera rotation parameters, learned in an unsupervised manner.	O	O	Review	78
The technique can be used in conjunction with various models, such as PGGAN, StyleGAN, and DeepVoxels.	O	O	Review	78
<sep> <sep> This paper provides an interesting approach that can be a useful building block for future investigations.	O	O	Review	78
<sep> <sep> The main issue I see with the paper is the number of results provided.	B-Review	B-1	Review	78
Only 2 different images are shown per combination of model and dataset, limiting the reader's ability to assess the technique's performance.	I-Review	I-1	Review	78
Would it be possible to provide a large number of results in a supplementary material or appendix?	I-Review	I-1	Review	78
<sep> <sep> In my opinion, this may be due to a difference in writing style, but the paper, in general, is slightly hard to read.	B-Review	B-2	Review	78
<sep> <sep> The depth in figures 1, 4, 5, 7 and 9 would be easier to read if it was displayed as a colormap (with the corresponding color bar) instead of grayscale.	B-Review	B-3	Review	78
Additionally, a reference sphere would be appreciated near the normal maps shown in fig.6 to inform the reader of the coordinates system used.	I-Review	I-3	Review	78
<sep> <sep> Sec.6 seems to show the contrary.	B-Review	B-4	Review	78
3.3 states that ‚Äúthe depth of the background is smaller than that of the face [for DeepVoxels]; however, this does not occur when the proposed loss is used‚Äù, however fig.	I-Review	I-4	Review	78
Is it due to the depth discontinuity?	I-Review	I-4	Review	78
<sep> <sep> Minor details	B-Review	B-5	Review	78
- Sec.3 ‚ÄúExperimetns‚Äù: typo.	I-Review	I-5	Review	78
<sep> - Sec.3.3, ‚Äú[...] use the 2D CNN‚Äù: I would replace ‚Äúthe‚Äù by ‚Äúa‚Äù.	I-Review	I-5	Review	78
<sep> - Sec.3.3, Third paragraph, the first sentence is hard to read.	I-Review	I-5	Review	78
<sep> - Sec.B ‚Äúthe later voxels are ignore[d]‚Äù	I-Review	I-5	Review	78
<sep> We would like to thank the reviewer for valuable comments.	O	O	Reply	78
<sep> <sep> Additional results	O	O	Reply	78
- We will add a large number of results to the appendix	B-Reply	B-1	Reply	78
<sep> Writing style	O	O	Reply	78
- We will get English proofreading for our paper.	B-Reply	B-2	Reply	78
If you do not mind, please let us know concretely which parts are difficult to read.&nbsp;	I-Reply	I-2	Reply	78
<sep> Depth visualization	O	O	Reply	78
- For all depth images, we will normalize them (as reviewer1 says) and visualize them with colormap.	B-Reply	B-3	Reply	78
Moreover, we will add a reference sphere in Figure 6.	I-Reply	I-3	Reply	78
<sep> <sep> Background depth	O	O	Reply	78
- Figure 6 shows the results on StyleGAN.	B-Reply	B-4	Reply	78
The background depth seems small in Figure 6, but it does not cover foregrounds even if the image is rotated (within the angle range during training).	I-Reply	I-4	Reply	78
This is contrary to the results of DeepVoxels in Figure 4, where the background pixels hide foregrounds when the generated image is rotated.	I-Reply	I-4	Reply	78
I will add this explanation in Section 3.3, and comparison experiments in the appendix.	I-Reply	I-4	Reply	78

# Review ICLR20, RGBD-GAN	O	O	Review	78
<sep> This review is for the originally uploaded version of this article.	O	O	Review	78
Comments from other reviewers and revisions have deliberately not been taken into account.	O	O	Review	78
After publishing this review, this reviewer will participate in the forum discussion and help the authors improve the paper.	O	O	Review	78
<sep> <sep> ## Overall	O	O	Review	78
<sep> The article proposes a method of modifying image-generating networks to also produce depth maps in an unsupervised way by enforcing rotational consistency.	O	O	Review	78
<sep> <sep> I enjoyed reading this work and I'm recommending it to be accepted.	O	O	Review	78
However, first there are some (in my opinion straight-forward) changes that need to be made to this work before I can recommend its publication:	O	O	Review	78
<sep> - The common "Related Works" section is missing and some of the literature is taking place in the introduction.	B-Review	B-1	Review	78
I find this unorganized and I'd recommend keeping the intro shorter and just moving the literature either behind the intro or to the end of the paper.	I-Review	I-1	Review	78
<sep> - Most figures and especially your headline figure (1) suffer from not having the depth normalized and not having a scale to it.	B-Review	B-2	Review	78
The fix for this is simple and two-fold: for each depth image, subtract the minimum value and divide by the range (to normalize it and increase contrast), then write in the caption or as a legend that white is closer to the camera and black is further back.	I-Review	I-2	Review	78
<sep> - 3D vs. 2.5D - If the common geometric definition of "3D" was applied here, the article's title was correct.	B-Review	B-3	Review	78
However, in computer vision and especially 3D vision, the term is commonly used to refer only to models that include full scene geometry, including the occluded backs of objects and the term 2.5D is used to describe assigning depth values to pixels in an RGB image (and therefore only covering the view-dependent front of the object), which I think is the case here.	I-Review	I-3	Review	78
However, this is not a hill that I'll die on so if you insist on that terminology, I won't block acceptance.	I-Review	I-3	Review	78
<sep> - When you first discuss HoloGAN, you mention one of its main downsides being scalability and then proceed to not only explain that but also use a HoloGAN-like architecture in one of your experiments.	B-Review	B-4	Review	78
I'd either remove the scalability argument or justify not just that but also how that's not relevant to your experiments.	I-Review	I-4	Review	78
<sep> - The following phrase occurs multiple times throughout: "camera parameter conditional image generation".	B-Review	B-5	Review	78
I _think_ you're missing a dash between "parameter" and "conditional".	I-Review	I-5	Review	78
<sep> <sep> <sep> ## Specific comments and questions	O	O	Review	78
<sep> ### Abstract	O	O	Review	78
<sep> All good.	O	O	Review	78
<sep> <sep> ### Intro	O	O	Review	78
<sep> - Fig.1 normalize image	B-Review	B-6	Review	78
- The literature section in intro mentions "For all methods, 3D annotations must be used..." - that's not true.	B-Review	B-7	Review	78
See [Rezende, 2016][1] and [Rajeswar, 2018][2]	I-Review	I-7	Review	78
- I understand how some literature is required to position your method, but I think it's better to not have the entire literature section in the center of the introduction	B-Review	B-8	Review	78
<sep> [1]: <a href="https://arxiv.org/abs/1607.00662" target="_blank" rel="nofollow">https://arxiv.org/abs/1607.00662</a>	O	O	Review	78
[2]: <a href="https://openreview.net/forum?id=BJeem3C9F7" target="_blank" rel="nofollow">https://openreview.net/forum?id=BJeem3C9F7</a>	O	O	Review	78
<sep> ### Method	O	O	Review	78
<sep> - 2.1 clear + nicely written	B-Review	B-9	Review	78
- Figure 2 good, caption a bit too short - figure+caption should be able to stand on their own	B-Review	B-10	Review	78
- Illustration of Figure 3 nice, except for unclear DeepVoxel part: what's the wavy orange flag stand for?	B-Review	B-11	Review	78
<sep> <sep> ### Experiments	O	O	Review	78
<sep> - You mention K is fixed, but where does the initial K come from?	B-Review	B-12	Review	78
I assume it's just neglected (since it's not important for StyleGAN/PGGAN), but then this needs to be mentioned in the methods sections closer to the formulas dealing with K.	I-Review	I-12	Review	78
- Figure 4 - the depth maps need to be normalized.	B-Review	B-13	Review	78
All we see here is a grey mush, even worse in Fig.7	I-Review	I-13	Review	78
- For ShapeNet cars, the model seems to suffer from not having a reference for the top and bottom of the image - have you tried adding floor/sky?	B-Review	B-14	Review	78
<sep> - Figure 6, the tire marker is a good idea but image still unclear - I recommend slightly less rotation or an intermediate step between generated image and e.g. front view	B-Review	B-15	Review	78
- For quantitative results/FID: try using Hausdorff or Chamfer distance on the rendered scenes' pixels.	B-Review	B-16	Review	78
We don't care about the goodness of the RGB generation but the depth.	I-Review	I-16	Review	78
<sep> <sep> ### Conclusion	O	O	Review	78
<sep> All good, albeit a bit short.	B-Review	B-17	Review	78
<sep> <sep> ### Appendix	O	O	Review	78
<sep> I don't think I saw any references to the appendix in the main paper.	B-Review	B-18	Review	78
We would like to thank the reviewer for valuable comments.	O	O	Reply	78
<sep> <sep> Related works	O	O	Reply	78
- We will separate the related work section from the introduction section.	B-Reply	B-1	Reply	78
<sep> <sep> Depth visualization	O	O	Reply	78
- We will normalize the depth maps and visualize it in colormap (as reviewer2 says) for better visualization.	B-Reply	B-2	Reply	78
<sep> <sep> 3D vs. 2.5D	O	O	Reply	78
- Our model can not only generate RGBD images, which is commonly considered 2.5D, but also explicitly control camera poses while preserving the image content.	B-Reply	B-3	Reply	78
Therefore, it can be regarded that the model can learn full 3D geometry implicitly, though the output is not fully 3D. This is the intuition to use the word "3D".	I-Reply	I-3	Reply	78
<sep> <sep> Scalability of HoloGAN	O	O	Reply	78
- We agree that the badness of the scalability of HoloGAN is not supported by our experimental results.	B-Reply	B-4	Reply	78
Therefore, we will delete the scalability part from the introduction.	I-Reply	I-4	Reply	78
<sep> <sep> Necessity for 3D annotations	O	O	Reply	78
- Thank you for introducing related papers.	B-Reply	B-7	Reply	78
Though they do not need annotations, both methods can only deal with synthetic primitive datasets.	I-Reply	I-7	Reply	78
Our method, however, can work on natural images.	I-Reply	I-7	Reply	78
We will add the discussion to the related works section.	I-Reply	I-7	Reply	78
<sep> <sep> wavy flag	O	O	Reply	78
- This is a conceptual figure of learned DeepVoxels.	B-Reply	B-11	Reply	78
DeepVoxels are implicit representations, and we cannot visualize what is acquired.	I-Reply	I-11	Reply	78
We agree that the figure is ambiguous, we will replace the figure.	I-Reply	I-11	Reply	78
<sep> <sep> About K	O	O	Reply	78
- Because learning K from single images is difficult, we initialize K with [[2s, 0, s/2], [0, 2s, s/2], [0, 0, 1]] (numpy-style order), where is image size.	B-Reply	B-12	Reply	78
We will add the explanation in the paper.	I-Reply	I-12	Reply	78
<sep> <sep> floor/sky	O	O	Reply	78
- We did not try adding floor or sky to render the ShapeNet car dataset.	B-Reply	B-14	Reply	78
We think adding simple sky or floor will help learning depth information to some extent, but it is difficult to learn consistent depth.	I-Reply	I-14	Reply	78
This is because foreground regions have common salient concepts across views (eg.tire, headlight, window, ...) but the background does not.	I-Reply	I-14	Reply	78
This is also problematic when we train the model on a car image dataset, which has floor and sky, as shown in Figure 7.	I-Reply	I-14	Reply	78
<sep> <sep> Evaluation for depth	O	O	Reply	78
- Evaluating the generated depth is difficult because we cannot obtain ground truth depth for the generated images.	B-Reply	B-16	Reply	78
A possible approach to evaluate depth images without ground truth images is calculating the inception score (IS) [5] or FID on the generated depth images, but we do not think it is appropriate.	I-Reply	I-16	Reply	78
This is because IS and FID are estimated in the feature space of a pre-trained CNN, and they cannot consider the geometry in the 3D world.	I-Reply	I-16	Reply	78
Therefore it is almost impossible to evaluate how the generated depth is plausible in 3D space.	I-Reply	I-16	Reply	78
Instead, we will evaluate the depth consistency across views to quantitatively compare the generated depth among different methods.	I-Reply	I-16	Reply	78
When we plot point clouds generated from the same but different, all points should be on a single surface.	I-Reply	I-16	Reply	78
Therefore, by calculating the variation of the generated depth, we can quantitatively evaluate the 3D consistency across views.	I-Reply	I-16	Reply	78
It is expected that 3D-latent-feature-based models have better performance than other models.	I-Reply	I-16	Reply	78
We will add the results in the paper.	I-Reply	I-16	Reply	78
<sep> <sep> [5] Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen.	O	O	Reply	78
Improved techniques for training gans.	O	O	Reply	78
In NIPS, 2016.	O	O	Reply	78

This paper presents a method for unsupervised representation learning of speech.	O	O	Review	219
The idea is to first learn discrete representation (vector quantization is done by Gumbel softmax or k-means) from audio samples with contrastive prediction coding type objective, and then perform BERT-style pre-training (borrowed from NLP).	O	O	Review	219
The BERT features are used as inputs to ASR systems, rather than the usual log-mel features.	O	O	Review	219
The idea, which combines those of previous work (wav2vec and BERT) synergetically, is intuitive and clearly presented, significant improvements over log-mel and wav2vec were achieved on ASR benchmarks WSJ and TIMIT.	O	O	Review	219
Based on these merits, I suggest this paper to be accepted.	O	O	Review	219
<sep> <sep> On the other hand, I would suggest directions for investigation and improvements as follows.	O	O	Review	219
<sep> <sep> 1.	B-Review	B-1	Review	219
While I understand that vector quantization makes the use of NLP-style BERT-training possible (as the inputs to NLP models are discrete tokens),  there are potential disadvantages as well.	I-Review	I-1	Review	219
One observation from the submission is that the token set may need to very large (from tens of thousands to millions) for the system to work well, making the BERT training computationally expensive (I noticed that the BERT model is trained on 128 GPUs).	I-Review	I-1	Review	219
Also, without BERT pre-training, using directly the discrete tokens seems to consistently give worse performance for ASR.	I-Review	I-1	Review	219
I think some more motivations or explorations (what kind of information did BERT learn) are needed to understand why that is the case.	I-Review	I-1	Review	219
<sep> <sep> 2.	O	O	Review	219
Besides the computational expensive-ness of the three-step approach (vector quantization, BERT, acoustic model training), the combined model complexity is large because these steps do not share neural network architecture.	B-Review	B-2	Review	219
A more economical approach is to use BERT-trained model as initialization for acoustic model training, which is the classical way how RBMs pre-training were used in ASR.	I-Review	I-2	Review	219
<sep> <sep> 3.	O	O	Review	219
One concern I have with discrete representation is how robust they are wrt different dataset.	B-Review	B-3	Review	219
The ASR datasets used in this work are relatively clean (but there does exists domain difference between them).	I-Review	I-3	Review	219
It remains to see how the method performs with more acoustically-challenging speech data, and how universally useful the learned features are (as is the case for BERT in NLP).	I-Review	I-3	Review	219
<sep> <sep> 4.	B-Review	B-4	Review	219
Another curious question is whether the features would still provide as much improvement when a stronger ASR system than AutoSeg (e.g., Lattice-free MMI) is used.	I-Review	I-4	Review	219
<sep> <sep> Overall, while I think the computational cost of the proposed method is high, rendering it less practical at this point, I believe the approach has potential and the result obtained so far is already significant.	O	O	Review	219
Thank you for your fruitful comments.	O	O	Reply	219
<sep> <sep> &gt;&gt; 1. [...]	O	O	Reply	219
One observation from the submission is that the token set may need to be very large (from tens of thousands to millions) for the system to work well, making the BERT training computationally expensive [...] I think some more motivation or exploration (what kind of information did BERT learn) is needed to understand why that is the case.	O	O	Reply	219
<sep> <sep> Our BERT vocabulary sizes (13.5k for the gumbel version and 23k for the k-means version) compare favorably to the setups commonly used in NLP where vocabularies are double or triple of our sizes.	B-Reply	B-1	Reply	219
<sep> <sep> We agree that it would be interesting to perform an in-depth analysis on the embeddings learned by BERT and we will investigate this in future work.	I-Reply	I-1	Reply	219
Here we focus on a new quantization method evaluated via downstream performance in phone and speech recognition settings by employing models that worked well (and were extensively tuned) in NLP contexts.	I-Reply	I-1	Reply	219
<sep> <sep> <sep> &gt;&gt; 2.	O	O	Reply	219
A more economical approach is to use BERT-trained model as initialization for acoustic model training, which is the classical way how RBMs pre-training were used in ASR.	O	O	Reply	219
<sep> <sep> Yes, this is an interesting avenue for future work!	B-Reply	B-2	Reply	219
We did not follow this direction due to two motivations: first, our aim is to contribute a new quantization scheme for audio data that is trained to predict the context in a self-supervised way.	I-Reply	I-2	Reply	219
Second, we wanted to show that good performance can be achieved with discretized audio on actual speech tasks.	I-Reply	I-2	Reply	219
<sep> <sep> <sep> &gt;&gt; 3.	O	O	Reply	219
One concern I have with discrete representation is how robust they are wrt different dataset.	O	O	Reply	219
<sep> We agree that an ablation study on robustness of the embeddings across different datasets would be very interesting.	B-Reply	B-3	Reply	219
<sep> <sep> Here we are mostly focusing on relatively clean data (WSJ, TIMIT, Librispeech) following the original wav2vec paper but we would be interested in exploring robustness in the future.	I-Reply	I-3	Reply	219
However we note that representations transfer at least well across datasets from the ‚Äúclean speech‚Äù domain: vq-wav2vec and BERT is only trained on Librispeech and never tuned on TIMIT/WSJ.	I-Reply	I-3	Reply	219
<sep> <sep> &gt;&gt; 4.	O	O	Reply	219
Another curious question is whether the features would still provide as much improvement when a stronger ASR system than AutoSeg (e.g., Lattice-free MMI) is used.	O	O	Reply	219
<sep> <sep> The original wav2vec paper (Schneider et al 2019) reports better results than LF-MMI on the WSJ benchmark, however, the two setups are not strictly comparable.	B-Reply	B-4	Reply	219
In some sense, the LF-MMI result has an edge because it is based on a phoneme-based ASR system which is typically stronger than the character-based ASR system used with wav2vec.	I-Reply	I-4	Reply	219
We agree that evaluation on stronger baselines is an important future direction though.	I-Reply	I-4	Reply	219

Though rather dense in its exposition, this paper is an interesting contribution to the area of self-supervised learning  based on discrete representations.	O	O	Review	219
What would make it stronger imo is to address the issue of how much is gained from a discrete vs. continuous representation.	B-Review	B-1	Review	219
The authors take it as a given that discrete is good because it allows us to leverage work in NLP.	B-Review	B-2	Review	219
That makes sense -- but at what cost?	I-Review	I-2	Review	219
<sep> <sep> "Table 4 shows that our first results are promising, even though they are not as good as the state of the art."	B-Review	B-3	Review	219
The state of the art on LibriSpeech is not Mohamed at al.	I-Review	I-3	Review	219
2019.	I-Review	I-3	Review	219
See e.g. Irie et al Interspeech 2019 for better result	I-Review	I-3	Review	219
<sep> The Conclusion is very sparse. "	B-Review	B-4	Review	219
In future work, we are planning to apply other algorithms requiring discrete inputs to audio data": can  you elaborate?	I-Review	I-4	Review	219
Thank you for your fruitful comments.	O	O	Reply	219
<sep> <sep> &gt;&gt; What would make it stronger imo is to address the issue of how much is gained from a discrete vs. continuous representation.	O	O	Reply	219
<sep> Discrete representations by themselves are not better than continuous ones (cf.	B-Reply	B-1	Reply	219
Table 1, wav2vec vs. vq-wav2vec).	I-Reply	I-1	Reply	219
However, discretization enables the application of existing algorithms from the NLP literature which were designed for discrete inputs.	I-Reply	I-1	Reply	219
We show that the BERT model can be directly applied to discretized speech.	I-Reply	I-1	Reply	219
BERT can better model context than (vq-)wav2vec.	I-Reply	I-1	Reply	219
<sep> <sep> &gt;&gt; The authors take it as a given that discrete is good because it allows us to leverage work in NLP.	O	O	Reply	219
That makes sense -- but at what cost?	O	O	Reply	219
<sep> Chaining vq-wav2vec and BERT requires more computational effort than just wav2vec, however, it does improve accuracy as our results show (cf.	B-Reply	B-2	Reply	219
Table 1).	I-Reply	I-2	Reply	219
Running BERT requires roughly as much computational overhead as just vq-wav2vec.	I-Reply	I-2	Reply	219
<sep> <sep> &gt;&gt; The state of the art on LibriSpeech is not Mohamed at al.	O	O	Reply	219
2019.	O	O	Reply	219
See e.g. Irie et al Interspeech 2019 for better result.	O	O	Reply	219
<sep> Thanks for pointing this out, we fixed this in the updated version of the paper we just posted.	B-Reply	B-3	Reply	219
<sep> <sep> &gt;&gt; The Conclusion is very sparse.	O	O	Reply	219
<sep> We broadened conclusion and delineated additional future work.	B-Reply	B-4	Reply	219

The paper proposes a way to pre-train quantized representations for speech.	O	O	Review	219
The approach proposed is a two-stage process: 1.	O	O	Review	219
train a quantized version of wav2vec [my understanding is that wav2vec is the same thing as CPC for Audio except for using a binary cross-entropy loss instead of InfoNCE softmax-cross entropy loss]. the authors propose to use gumbel softmax / VQ codebook for the vector quantization.	O	O	Review	219
2.	O	O	Review	219
once you have a discrete representation, you could train BERT (as if it were a seq of language tokens).	O	O	Review	219
this makes a lot of sense especially given that CPC / wav2vec recovers phonemes and quantizing the phonemes will recover a language-like version of the raw audio.	O	O	Review	219
And running BERT across those tokens will allow you to capture the dependencies at the phoneme level.	O	O	Review	219
After pre-training, the authors use the learned representations for speech recognition.	O	O	Review	219
They compare this to using log-mel filterbanks.	O	O	Review	219
The results (WER / LER) is lower for the proposed pipeline compared to using dense wav2vec representation for n-gram and character LM.	O	O	Review	219
It also makes sense that BERT helps for the k-means (vq) setting since the number of codes is large.	O	O	Review	219
The authors also cleverly adopt/adapt span-BERT which is more suited to this setting.	O	O	Review	219
I think this paper presents a useful contribution as far as improving speech / phoneme recognition using self-supervised learning goes, and also has useful engineering aspects in terms of combining CPC and BERT.	O	O	Review	219
I would like to see this paper accepted.	O	O	Review	219
Thank you for your comments!	O	O	Reply	219

<sep> Overview:	O	O	Review	219
<sep> This paper considers unsupervised (or self-supervised) discrete representation learning of speech using a combination of a recent vector quantized neural network discritization method and future time step prediction.	O	O	Review	219
Discrete representations are fine-tuned by using these as input to a BERT model; the resulting representations are then used instead of conventional speech features as the input to speech recognition models.	O	O	Review	219
New state-of-the-art results are achieved on two datasets.	O	O	Review	219
<sep> <sep> Strengths:	O	O	Review	219
<sep> The core strength of this paper is in the results that are achieved on standard speech recognition benchmarks.	O	O	Review	219
The results indicate that, while discritization in itself does not give improvements, coupling this with the BERT-objective results in speech features which are better in downstream speech recognition than standard features.	O	O	Review	219
I think the main technical novelty is in combining discritization with future time step prediction (but see the weakness below).	O	O	Review	219
<sep> <sep> Weaknesses:	O	O	Review	219
<sep> The main weakness of the paper is that it does not situate itself within existing literature in this area.	B-Review	B-1	Review	219
Over the last few years, researchers in the speech community have invested significant effort in learning better speech representations, and this is not discussed.	I-Review	I-1	Review	219
See e.g. [1]. Even more importantly, very recently there has been a number of papers investigating discrete representations of speech; see the review [2]. Some of these papers specifically use VQ-VAEs [3]. [4] actually compares VQ-VAE and the Gumbel-Softmax approach.	I-Review	I-1	Review	219
These studies should be mentioned.	I-Review	I-1	Review	219
This paper is different in that it incorporates future time step prediction.	I-Review	I-1	Review	219
But context prediction has also been considered before, also for speech [5, 6, 7]. This paper can be situated as a new contribution combining these two strands of research.	I-Review	I-1	Review	219
In the longer run it would be extremely beneficial to the community if this approach is applied to the standard benchmarks as set out in [2].	I-Review	I-1	Review	219
<sep> As a minor weakness, some parts of the paper is not described in enough detail and the motivation is weak or not exactly clear (see detailed comments below).	B-Review	B-2	Review	219
<sep> <sep> Overall assessment:	O	O	Review	219
<sep> I think the results as well as the new combination of existing approaches in the paper warrants publication.	B-Review	B-10	Review	219
But it should be amended significantly to situate itself within the existing literature.	I-Review	I-10	Review	219
I therefore award a "weak accept".	O	O	Review	219
<sep> <sep> Detailed questions and suggestions:	O	O	Review	219
<sep> - Section 1: As motivation for this work, it is stated that "we aim to make well performing NLP algorithms more widely applicable".	B-Review	B-3	Review	219
As noted above, some NLP-like ideas (such as prediction of future speech segments, stemming from text-based language modelling) have already been considered within the speech community.	I-Review	I-3	Review	219
Rather than motivating the work in this way, it might be helpful to focus the contribution as a combination of future time step prediction and discretization (both of which have been considered in previous work, but not in combination).	I-Review	I-3	Review	219
<sep> - Section 4: Would it be possible to train the vq-wav2vec model jointly with BERT, i.e. as one model?	B-Review	B-4	Review	219
I suspect it would be difficult since, for the masking objective, the discrete units are already required, but maybe there is a scheme where this could work.	I-Review	I-4	Review	219
<sep> - Section 2.2: Similarly to the above question, would there be a way to incorporate the BERT principles directly into an end-to-end model, e.g. by randomly masking some of the continuous input speech?	B-Review	B-5	Review	219
<sep> - Section 3.3: What exactly does "mode collapse" refer to in this context?	B-Review	B-6	Review	219
Would this be using only one codebook entry, for instance?	I-Review	I-6	Review	219
<sep> - Section 6: It seems that in all cases to obtain improvements from discritization, BERT is required on top of the vq-wav2vec discrete symbols.	B-Review	B-7	Review	219
Is it possible that the output acoustic model is simply better-matched to continuous rather than discrete input (direct vq-wav2vec gives discrete while BERT gives continuous)?	I-Review	I-7	Review	219
Would it make sense to train the wav2vec acoustic model on top of the vqvae codebook entries (e) instead of directly on the symbols?	I-Review	I-7	Review	219
<sep> <sep> Typos, grammar and style:	B-Review	B-8	Review	219
<sep> - "gumbel" -&gt; "Gumbel" (throughout; or just be consistent in capitalization)	I-Review	I-8	Review	219
- "which can be mitigated my workarounds" -&gt; "which can be mitigated *by* workarounds"	I-Review	I-8	Review	219
- "work around" -&gt; "workaround"	I-Review	I-8	Review	219
<sep> Missing references:	B-Review	B-9	Review	219
<sep> 1.	I-Review	I-9	Review	219
Versteegh, M., Anguera, X., Jansen, A. &amp; Dupoux, E. (2016).	I-Review	I-9	Review	219
The Zero Resource Speech Challenge 2015: Proposed Approaches and Results.	I-Review	I-9	Review	219
In SLTU-2016 Procedia Computer Science, 81, (pp 67-72).	I-Review	I-9	Review	219
<sep> 2.	I-Review	I-9	Review	219
<a href="https://arxiv.org/abs/1904.11469" target="_blank" rel="nofollow">https://arxiv.org/abs/1904.11469</a>	I-Review	I-9	Review	219
3.	I-Review	I-9	Review	219
<a href="https://arxiv.org/abs/1905.11449" target="_blank" rel="nofollow">https://arxiv.org/abs/1905.11449</a>	I-Review	I-9	Review	219
4.	I-Review	I-9	Review	219
<a href="https://arxiv.org/abs/1904.07556" target="_blank" rel="nofollow">https://arxiv.org/abs/1904.07556</a>	I-Review	I-9	Review	219
5.	I-Review	I-9	Review	219
<a href="https://arxiv.org/abs/1904.03240" target="_blank" rel="nofollow">https://arxiv.org/abs/1904.03240</a>	I-Review	I-9	Review	219
6.	I-Review	I-9	Review	219
<a href="https://arxiv.org/abs/1807.03748" target="_blank" rel="nofollow">https://arxiv.org/abs/1807.03748</a> (this paper is cited)	I-Review	I-9	Review	219
7.	I-Review	I-9	Review	219
<a href="https://arxiv.org/abs/1803.08976" target="_blank" rel="nofollow">https://arxiv.org/abs/1803.08976</a>	I-Review	I-9	Review	219
<sep> Edit: Based on the feedback from the authors, I changed my rating from a 'weak accept' to an 'accept'.	O	O	Review	219
Thank you for the fruitful comments!	O	O	Reply	219
<sep> <sep> We addressed your main concern and updated Section 1 of the paper to better situate it in the existing literature.	B-Reply	B-1	Reply	219
<sep> <sep> &gt;&gt; Would it be possible to train the vq-wav2vec model jointly with BERT, i.e. as one model? [...]	O	O	Reply	219
Similarly to the above question, would there be a way to incorporate the BERT principles directly into an end-to-end model, e.g. by randomly masking some of the continuous input speech?	O	O	Reply	219
<sep> <sep> The focus of this paper is a quantization approach for audio.	B-Reply	B-5	Reply	219
Replacing the two-step training process by an adaptation of BERT to continuous data (using a wav2vec/CPC-like objective function instead of the cross entropy) is an interesting direction for future work (and we amended the future work section accordingly).	I-Reply	I-5	Reply	219
However, our current paper is a proof of concept that a pre-training scheme based on masked inputs (BERT) can improve over previous methods in the speech domain.	I-Reply	I-5	Reply	219
<sep> <sep> <sep> &gt;&gt; What exactly does "mode collapse" refer to in this context?	O	O	Reply	219
<sep> <sep> In several configurations (especially for one and two groups) considerably less codewords than theoretically possible are used.	B-Reply	B-6	Reply	219
We loosely refer to mode collapse as the phenomenon when very few codewords per group are used (cf.	I-Reply	I-6	Reply	219
Appendix A).	I-Reply	I-6	Reply	219
<sep> <sep> We updated the paper to also refer to the appendix where we outline the number of codewords that the model uses.	I-Reply	I-6	Reply	219
We observed that in the ‚Äúfew group regime‚Äù (G=1...4), only a few of the available centroids per group are used and refer to this phenomenon as mode collapse ‚Äî for BERT training, this is actually favorable e.g. in the G=2, V=320 setting as it yields a codebook of acceptable size for NLP model training (13.5k/23k).	I-Reply	I-6	Reply	219
<sep> Mode collapse could potentially be circumvented by strategies like embedding re-initialization used in classical k-means and this is an interesting avenue for future work.	I-Reply	I-6	Reply	219
<sep> <sep> <sep> &gt;&gt; [...] BERT is required on top of the vq-wav2vec discrete symbols.	O	O	Reply	219
Is it possible that the output acoustic model is simply better-matched to continuous rather than discrete input (direct vq-wav2vec gives discrete while BERT gives continuous)?	O	O	Reply	219
Would it make sense to train the wav2vec acoustic model on top of the vqvae codebook entries (e) instead of directly on the symbols?	O	O	Reply	219
<sep> <sep> We actually did what you suggest: when we train acoustic models on top of vq-wav2vec, we input the dense embedding vectors corresponding to the discrete codewords.	B-Reply	B-7	Reply	219
On the other hand, we also trained an NLP sequence to sequence (Section 6.3) which takes the quantized audio codes as input and then generates the transcriptions.	I-Reply	I-7	Reply	219
This gives reasonable accuracy and suggests that the discrete codes by themselves, and without the learned continuous representations, are useful.	I-Reply	I-7	Reply	219
We clarified this in the updated version of the paper.	I-Reply	I-7	Reply	219
<sep> <sep> We believe the reason the dense embeddings for the discrete codewords work less well is because they do not encode as much detailed context information as a representation built by wav2vec or BERT.	I-Reply	I-7	Reply	219
The information in the codebook is ultimately less detailed than a context vector specific to the current input sequence.	I-Reply	I-7	Reply	219

(Originally my score was a weak reject.)	O	O	Review	219
<sep> <sep> This paper aims to study whether a learned reward function can serve as a locus of knowledge about the environment, that can be used to accelerate training of new agents.	O	O	Review	219
The authors create an algorithm that learns an intrinsic reward function, that when used to train a new agent over a ‚Äúlifetime‚Äù (which consists of multiple episodes), leads to the best cumulative reward over the lifetime.	O	O	Review	219
As a result, the learned intrinsic reward is incentivized to quickly ‚Äúteach‚Äù the agent when and where to explore to find out as-yet unknown information, and then exploit that information once there is no more to be had.	O	O	Review	219
Experiments on gridworlds demonstrate that these learned intrinsic rewards: 1.	O	O	Review	219
switch between early exploration and later exploitation, 2.	O	O	Review	219
explore only for information that is relevant for optimal behavior, 3.	O	O	Review	219
capture invariant causal relationships, and 4.	O	O	Review	219
can anticipate and adapt to changes in the extrinsic reward within a lifetime.	O	O	Review	219
<sep> <sep> I very much appreciated the design of the environments to test for specific properties within the learning algorithm: I think these experiments provide a very useful conceptual analysis of what learned intrinsic rewards can do.	O	O	Review	219
<sep> <sep> My main qualm with the paper is with its significance -- the authors claim that the goal is to find out whether reward functions can be loci of knowledge, but we already know the answer is yes: the whole point of reward shaping is to improve training dynamics by building in knowledge into the reward function.	B-Review	B-1	Review	219
It is not a surprise that learned reward functions can be loci of knowledge if our hand-designed reward functions already do so.	I-Review	I-1	Review	219
<sep> <sep> To me, the more interesting aspect of this paper is how much benefit we can get by learning intrinsic reward functions, relative to other ways of improving training dynamics.	B-Review	B-2	Review	219
The authors do show that by allowing the intrinsic reward to be recurrent (and so dependent on past episodes), it is able to first incentivize exploration and later exploitation, which standard reward shaping cannot do (since usually reward shaping still maintains the assumption that the reward is a function of the state).	I-Review	I-2	Review	219
However, given this motivation, it would be important to see comparisons between the proposed method of learning intrinsic rewards, and other methods for fast adaptation in the literature, such as MAML, which as I understand also has many of the properties highlighted in this paper.	I-Review	I-2	Review	219
<sep> <sep> Ideally there would also be experiments on more complex environments: the environments in the paper have 104, 25, and 49 states.	B-Review	B-3	Review	219
If we in the ABC environments if you count ‚Äúwhether or not reward(object) is known‚Äù as part of the state, that multiplies it by 2^3 = 8 giving 200 and 392 states, if you then further add the ordering of r(A), r(B), and r(C), that multiplies by a factor of 3!	I-Review	I-3	Review	219
= 6 giving 1200 and 2352 states.	I-Review	I-3	Review	219
These environments are excellent for demonstrating the properties of learned intrinsic rewards and I am glad the authors have done these experiments and analyzed the results.	I-Review	I-3	Review	219
However, given that the paper aims to scale the optimal reward problem, it would have been useful to see examples where the state space cannot be fully enumerated to evaluate scalability.	I-Review	I-3	Review	219
<sep> <sep> Questions:	O	O	Review	219
<sep> In Figure 5, in episode 1, why is the learned intrinsic reward heavily penalizing the path to C, but not penalizing the path to B?	B-Review	B-4	Review	219
In the initial episode, the intrinsic reward should only know that B is to be avoided; it doesn‚Äôt yet know whether A or C is the better object.	I-Review	I-4	Review	219
I would expect the learned intrinsic reward to put similar positive rewards on the path to C and the path to A, and negative reward on the path to B. (It is slightly more likely that C is the best object.	I-Review	I-4	Review	219
This probably changes things slightly, but not significantly.)	I-Review	I-4	Review	219
<sep> <sep> Also in Figure 5, by episode 3, shouldn‚Äôt the final states (A or C) have intrinsic rewards of larger magnitude?	B-Review	B-5	Review	219
Otherwise the agent can go back and forth on the path to collect lots of intrinsic reward without terminating the episode, even though this wouldn‚Äôt get extrinsic reward.	I-Review	I-5	Review	219
Thank you very much for constructive comments.	O	O	Reply	219
We address the questions below and reflected some of the suggestions in the revision (see the common response above).	O	O	Reply	219
<sep> <sep> # Regarding ‚Äúthe goal is to find out whether reward functions can be loci of knowledge‚Äù	O	O	Reply	219
We clarify that our goal is not just finding out whether it is possible to store knowledge into rewards.	B-Reply	B-1	Reply	219
In fact, we acknowledge in the introduction that existing hand-designed rewards already show that they can be a locus of knowledge.	I-Reply	I-1	Reply	219
Instead, our goal is to find out 1) whether it is feasible to capture knowledge in reward functions in a data-driven from the agent‚Äôs own experience rather than hand-designing them, 2) what kind of knowledge can be captured when they are ‚Äúlearned‚Äù rather than ‚Äúhand-designed‚Äù, and 3) to show that reward knowledge can generalise to new dynamics and new learning algorithms.	I-Reply	I-1	Reply	219
We clarified this in the revision.	I-Reply	I-1	Reply	219
<sep> <sep> # Regarding the benefits of learning intrinsic rewards in comparison to other methods	O	O	Reply	219
In Section 5, we added a comparison to RL^2 and MAML and added one more experiment demonstrating that the intrinsic rewards learned from actor-critic agents can generalise to a different kind of learning agents, i.e. Q-learning agents.	B-Reply	B-2	Reply	219
Please see the common response for details.	I-Reply	I-2	Reply	219
<sep> <sep> # Regarding more complex domains	O	O	Reply	219
We revised the paper with a new version of the key-box domain, where the map is a 9x9 grid world and objects are randomly placed for each episode.	B-Reply	B-3	Reply	219
Due to the random placement, there are more than 3 billion distinct states.	I-Reply	I-3	Reply	219
We acknowledge that this number is still tiny in comparison to domains with high-dimensional visual observations, but this shows that our method can scale up to larger domains, where it is infeasible to fully enumerate the entire state space.	I-Reply	I-3	Reply	219
<sep> <sep> # Regarding questions about Figure 5	O	O	Reply	219
Regarding your question about episode 1, we conjecture that it is more optimal for the intrinsic reward to encourage the agent to commit to one particular object (either A or C) at the beginning of training.	B-Reply	B-4	Reply	219
Otherwise, if the reward is equal for A and C, it would take more time for a ‚Äúrandomly-initialised‚Äù policy to learn to collect any of them, because going towards both objects are encouraged (and they are placed in the opposite positions).	I-Reply	I-4	Reply	219
<sep> Regarding your question about episode 3, the colors represent the return for each trajectory not per-step reward.	B-Reply	B-5	Reply	219
Therefore, the agent would not gain more rewards by moving back and forth.	I-Reply	I-5	Reply	219
Also, it is important to note that the intrinsic reward is a function of the agent‚Äôs history.	I-Reply	I-5	Reply	219
So, it is very likely that the intrinsic reward would penalise if the agent keeps going back and forth without proper exploration/exploitation, which would be an interesting analysis to be done.	I-Reply	I-5	Reply	219

<sep> The paper proposes a meta-learning approach to learn reward functions for reinforcement learning agents.	O	O	Review	219
It defines an algorithm to optimize an intrinsic reward function for a distribution of tasks in order to maximise the agent‚Äôs lifetime rewards.	O	O	Review	219
The properties of this reward function and meta-learning algorithm  are investigated through a number of proof-of-concept experiments.	O	O	Review	219
<sep> <sep> The meta-learning algorithm and the corresponding empirical investigation are the main contributions of the paper.	B-Review	B-6	Review	219
The algorithm seems to be similar to previous meta-learning approaches, but differs by introducing a lifetime value function.	I-Review	I-6	Review	219
While I thought the paper raises some interesting possibilities, I am currently leaning towards rejection.	O	O	Review	219
The proposed algorithm does not seem like a major innovation over cited previous work.	O	O	Review	219
The empirical evaluation provides a number of proof-of-concept ideas, but no in depth investigation of the properties of the approach.	O	O	Review	219
The theoretical properties of the approach are barely discussed.	O	O	Review	219
<sep> <sep> Detailed remarks:	O	O	Review	219
<sep> * The main addition to the meta-learning algorithm is the lifetime value function.	B-Review	B-1	Review	219
The authors mention multiple times that this is crucial to learning, but the properties of this value function are not really investigated or discussed in depth:	I-Review	I-1	Review	219
<sep> - The authors mention that the value function must take into account changing future policies, but do not discuss this further.	I-Review	I-1	Review	219
The value function update seems to be a standard on-policy TD update with the lifetime return and the complete history as input.	I-Review	I-1	Review	219
The policy for this value function, however, is still a standard policy with only state as input (but it will be non-stationary over the agent lifetime).	I-Review	I-1	Review	219
It would be good to discuss this learning problem in more detail.	I-Review	I-1	Review	219
<sep> - The algorithm uses an n-step return.	I-Review	I-1	Review	219
Is this important?	I-Review	I-1	Review	219
What effect does n have on learning?	I-Review	I-1	Review	219
<sep> <sep> * Another issue which I would have liked being discussed in more detail is the non-stationarity of the learning problem in general.	B-Review	B-2	Review	219
Most of the approaches discussed in related work (e.g. shaping)  are aimed at learning/designing more informative reward functions.	I-Review	I-2	Review	219
These reward functions still fit in the MDP framework, however, and map from states and actions to rewards.	I-Review	I-2	Review	219
In the case of shaping approaches guarantees can be given that this does not alter the learning problem.	I-Review	I-2	Review	219
The intrinsic reward functions used in this paper map the full life-time history of the agent to rewards.	I-Review	I-2	Review	219
While this is a richer framework that can express more complicated tasks (like exploration over multiple episodes), it also invalidates many of the basic assumptions of reinforcement learning.	I-Review	I-2	Review	219
The rewards are now no longer Markovian when only observing the current state.	I-Review	I-2	Review	219
Moreover, the reward function will change over time.	I-Review	I-2	Review	219
To what extent does this require non-stationary / history-based policy and value function learning to solve these issues?	I-Review	I-2	Review	219
While some of these issues also apply to count based exploration strategies, (Strehl and Littman,2008 ) provided results that the  exploration bonuses result a Bellman Equation that accounts for uncertainties.	I-Review	I-2	Review	219
No real guarantees seem to exist here.	I-Review	I-2	Review	219
<sep> <sep> * The empirical contribution focuses on trying to answer a number of questions regarding the properties of the learnt intrinsic rewards.	B-Review	B-3	Review	219
I found these questions to be very broad, while the answers are mostly anecdotal evidence through proof-of-concept examples.	I-Review	I-3	Review	219
These examples do show potential benefits of meta-learning intrinsic rewards, but I was somewhat disappointed that there was no more systematic investigation.	I-Review	I-3	Review	219
For example, questions like ‚Äòhow does the distribution of tasks affect intrinsic rewards‚Äô or ‚Äòdoes intrinsic reward generalise‚Äô are not really answered by providing metrics of performance or generalisation in controlled experiments, but by providing some example cases.	I-Review	I-3	Review	219
Several of these questions (including optimising exploration and dealing with non-stationarity) also seem to have been investigated to some extent in the original Optimal reward papers (Singh, 2009/2010).	I-Review	I-3	Review	219
It would be good to clearly indicate what we have learned beyond these previous results.	I-Review	I-3	Review	219
<sep> <sep> * There seems to be a bit of a mismatch between the learning objective for intrinsic rewards in the optimal reward framework and the results shown in the experiments.	B-Review	B-4	Review	219
The learning objective aims to optimise lifetime rewards for a distribution of tasks.	I-Review	I-4	Review	219
Most of the experiments seem to analyse episodic reward performance and compare against single-task (or task agnostic) methods.	I-Review	I-4	Review	219
<sep> <sep> Minor comments:	B-Review	B-5	Review	219
<sep> - The architecture / parameterization of the lifetime value function does not seem to be defined anywhere.	I-Review	I-5	Review	219
Given that it takes histories as input I assume this is another RNN?	I-Review	I-5	Review	219
<sep> - There seems to be some small overloading in the notation with \eta occasionally being used to denote the parameters of the reward function r_eta or the reward function itself.	I-Review	I-5	Review	219
<sep> <sep> Thank you very much for constructive comments.	O	O	Reply	219
We address the questions below and reflected some of the suggestions in the revision (see the common response above).	O	O	Reply	219
<sep> <sep> # Regarding the non-stationary learning problem and theoretical guarantee	O	O	Reply	219
As the reviewer pointed out, the problem is indeed non-stationary from the memoryless policy‚Äôs perspective.	B-Reply	B-2	Reply	219
However, we can also view the combination of the intrinsic reward function and the policy as a joint lifetime-history-based policy parameterised by and (see derivation in Appendix A).	I-Reply	I-2	Reply	219
From this perspective, the overall learning problem can be formulated as an MDP with history as state (recall, we use RNNs for the intrinsic reward function).	I-Reply	I-2	Reply	219
We revised the paper to make this  point clear. (	I-Reply	I-2	Reply	219
see Section 3.4)	I-Reply	I-2	Reply	219
<sep> # Regarding systematic investigation of the learned intrinsic rewards	O	O	Reply	219
We showed that the intrinsic reward captures quite different but appropriate knowledge by varying reward functions in ABC domain (i.e., Fixed ABC in Figure 10 ‚Üí Random ABC ‚Üí Non-stationary ABC).	B-Reply	B-3	Reply	219
We agree that further systematic investigation could help and would appreciate if the reviewer makes a concrete suggestion on this.	I-Reply	I-3	Reply	219
<sep> <sep> # Regarding what we learned beyond previous work	O	O	Reply	219
We revised the abstract to further highlight our contribution.	B-Reply	B-6	Reply	219
Specifically, we learned the following beyond previous work as follows. (	I-Reply	I-6	Reply	219
1) It is possible to learn good reward functions via gradient-based meta-learning, which is much more scalable than exhaustive search (prior work). (	I-Reply	I-6	Reply	219
2) The meta-learned reward functions can capture interesting kinds of ``what'' knowledge, which includes long-term exploration and exploitation. (	I-Reply	I-6	Reply	219
3) Because of the indirectness of this form of knowledge the learned reward functions can generalise to other kinds of agents and to changes in the dynamics of the environment.	I-Reply	I-6	Reply	219
<sep> <sep> # Regarding mismatch between the learning objective and the experimental results	O	O	Reply	219
The objective for training the intrinsic reward function is to maximise cumulative lifetime rewards.	B-Reply	B-4	Reply	219
By looking at the area-under-the-curve in our evaluation results, we can observe lifetime rewards.	I-Reply	I-4	Reply	219
Thus, we believe that the evaluation curves show both metrics (i.e., episodic return and lifetime return).	I-Reply	I-4	Reply	219
Our paper also acknowledges that the baseline reward functions are task-independent (Section 4).	I-Reply	I-4	Reply	219
<sep> <sep> # Regarding missing architecture details and overloaded notations	O	O	Reply	219
We added some missing details about the lifetime value function architecture and revised the notations in the revised paper.	B-Reply	B-5	Reply	219

Summary	O	O	Review	219
The paper evaluates the intrinsic reward as a way of storing information about episodes.	O	O	Review	219
It adopts the optimal intrinsic reward setting (Singh'09), and extends its recent policy gradient implementation, LIRPG, to lifetime settings.	O	O	Review	219
The task in the lifetime setting is to learn an intrinsic reward such that when trained with it, the agent maximizes its total return over its lifetime.	O	O	Review	219
A lifetime is defined as a sequence of episodes, where the agent does not have memory of previous episodes, however, the function computing the intrinsic reward does.	O	O	Review	219
In proof-of-concept experiments, the paper demonstrates that the learned intrinsic reward captures properties of several gridworld environments and induces meaningful behavior in the agent, successfully transferring information from previous episodes.	O	O	Review	219
Interestingly, a state-based reward function also generalizes to agents with perturbed action spaces, showing that this way of storing information is agnostic to the agent‚Äôs action space.	O	O	Review	219
<sep> <sep> Decision	O	O	Review	219
The paper proposal is interesting and adequately evaluated, however, the impact of the paper might be limited by its limited technical novelty and lack of comparisons to strong baselines.	O	O	Review	219
I recommend marginal accept.	O	O	Review	219
<sep> <sep> Pros	O	O	Review	219
- The paper is well-motivated.	O	O	Review	219
<sep> - The paper is well-written and the method is clearly explained.	O	O	Review	219
The literature review is thorough.	O	O	Review	219
<sep> - The experimental evaluation demonstrates several interesting and potentially promising phenomena.	O	O	Review	219
<sep> <sep> Cons	O	O	Review	219
- The novelty of the paper is limited as it is a somewhat straightforward extension of prior work.	B-Review	B-1	Review	219
<sep> - The impact of the paper is hard to judge as the experimental evaluation does not focus on potential usecases.	B-Review	B-2	Review	219
<sep> <sep> Questions.	O	O	Review	219
Here, I will focus on scientific questions, answering which would significantly improve the quality of the paper.	O	O	Review	219
<sep> - The biggest drawback of the paper is that the proposed method has an unfair advantage as it has a way of transmitting information across episodes, which the baselines do not (as stated on the bottom of page 5).	B-Review	B-3	Review	219
While the findings of this paper are interesting, it is unclear how it compares to methods that have memory of previous episodes, such as agents with non-episodic recurrent policies, or meta-learning agents such as Duan‚Äô16, Finn‚Äô17.	I-Review	I-3	Review	219
Is it possible that the proposed method e.g. scales better than recurrent policies due to compact representations or provides better generalization to things like action space changes?	I-Review	I-3	Review	219
<sep> - How does the method compare to hand-designed intrinsic rewards on hard exploration games (such as montezuma‚Äôs revenge or pitfall Atari games)?	B-Review	B-4	Review	219
Since it can only learn to explore on games that it previously successfully solved, it is possible that a hand-designed intrinsic reward such as RND (Burda‚Äô19) would perform better on these hard games.	I-Review	I-4	Review	219
On the other hand, it is possible that the method will in fact perform better on these games due to more directed exploration.	I-Review	I-4	Review	219
<sep> - How does the method compare to hand-designed intrinsic reward on out-of-distribution tasks?	B-Review	B-5	Review	219
Intuitively, the method should perform the worse the further from the training distribution the task is, while the hand-designed rewards will always perform similarly.	I-Review	I-5	Review	219
However, what is the extent to which the proposed method generalizes?	I-Review	I-5	Review	219
It is possible that this method would be very useful in practice if it generalized well.	I-Review	I-5	Review	219
<sep> <sep> Other potentially related work.	B-Review	B-6	Review	219
<sep> - Xu‚Äô18, Learning to Explore with Meta-Policy Gradient, is a relevant work that proposes a meta-learning framework for training an exploration policy.	I-Review	I-6	Review	219
<sep> - Metz‚Äô19, Meta-Learning Update Rules for Unsupervised Representation Learning, is a conceptually relevant work that proposes to meta-learn loss functions for unsupervised learning (and there is more recent related work on this topic too).	I-Review	I-6	Review	219
<sep> <sep> Thank you very much for constructive comments.	O	O	Reply	219
We address the questions below and reflected some of the suggestions in the revision (see the common response above).	O	O	Reply	219
<sep> <sep> # Regarding comparison to other meta-learning methods	O	O	Reply	219
We added a comparison to two meta-learning methods (RL^2 and MAML).	B-Reply	B-3	Reply	219
Please see the details in the common response (see Section 5).	I-Reply	I-3	Reply	219
<sep> <sep> # Regarding comparison to hand-designed intrinsic rewards on hard exploration problems	O	O	Reply	219
The goal of this paper is to show that interesting kinds of ‚Äúwhat‚Äù knowledge can be captured by learned intrinsic rewards such as exploring uncertainty and provide in-depth analysis of the approach.	B-Reply	B-4	Reply	219
We would like to explore scaling to hard exploration tasks like Montezuma‚Äôs Revenge as future work.	I-Reply	I-4	Reply	219
<sep> <sep> # Regarding comparison to hand-designed intrinsic rewards on out-of-distribution tasks	O	O	Reply	219
We demonstrated that the intrinsic reward can interpolate successfully within the same task distribution.	B-Reply	B-5	Reply	219
However, it is unclear whether it can extrapolate to out-of-distribution tasks, as the neural network representation should successfully handle extrapolation, which is an active research topic in deep learning (e.g., disentangled representation).	I-Reply	I-5	Reply	219
We believe that more research including representation learning is needed to learn intrinsic rewards that can generalise well to out-of-distribution tasks.	I-Reply	I-5	Reply	219
We would like to investigate in this direction in the future.	I-Reply	I-5	Reply	219
<sep> <sep> # Regarding missing references	O	O	Reply	219
We added missing references mentioned by the reviewer in the revision.	B-Reply	B-6	Reply	219

In this paper, the authors propose a novel segmentation scheme that combines the block motion vectors for feature warping, bi-directional propagation, and feature fusion.	O	O	Review	734
Experiments demonstrate its effectiveness compared with alternative methods.	O	O	Review	734
However, I still have several concern:	O	O	Review	734
1.	O	O	Review	734
As  the block motion vectors are generally rough estimation, it may damage the performance of the tasks.	B-Review	B-1	Review	734
The authors should further clarify how the imperfect estimation influence the performance, e.g., the Blocking artifacts.	I-Review	I-1	Review	734
<sep> 2.	O	O	Review	734
The features are actually abstract representation of an image while the motion vectors are actually obtained via the pixel comparison.	B-Review	B-2	Review	734
The authors should further justify the motion estimation could be used to the latent feature directly.	I-Review	I-2	Review	734
<sep> 3.	O	O	Review	734
The authors are expected to conduct more comprehensive experiments.	B-Review	B-3	Review	734
Motion vectors are consistent in the current dataset.	I-Review	I-3	Review	734
The authors are expected to demonstrate when the motion are chaotic.	I-Review	I-3	Review	734
<sep> <sep> Thanks very much for taking the time to review our paper.	O	O	Reply	734
<sep> <sep> (1) The fact that block motion vectors (BMVs) are rougher motion estimates than optical flow is actually discussed in our results section (Sec.	B-Reply	B-1	Reply	734
4.1.2):	I-Reply	I-1	Reply	734
<sep> ‚ÄúWhile motion vectors are slightly less accurate than optical flow in general, by cutting inference times by 53% on	I-Reply	I-1	Reply	734
intermediate frames (Sec.	I-Reply	I-1	Reply	734
3.3.1), prop-BMV enables operation at much lower keyframe intervals than optical flow to	I-Reply	I-1	Reply	734
achieve the same inference speeds.	I-Reply	I-1	Reply	734
This results in a much more favorable accuracy-throughput curve.	I-Reply	I-1	Reply	734
‚Äù	I-Reply	I-1	Reply	734
<sep> As a specific example (from Table 1), to achieve throughput of ~13.5 fps on CamVid requires operating at keyframe interval 10 with prop-flow (63.1 mIoU) but only keyframe interval 5 with prop-BMV (65.9 mIoU), which enables ~3% higher mIoU.	I-Reply	I-1	Reply	734
<sep> In essence, because motion estimation with block motion vectors is *much* cheaper than motion estimation with optical flow, block motion vectors allow us to operate at lower keyframe intervals, and thus achieve *higher accuracy*, for a given inference speed, than optical flow.	I-Reply	I-1	Reply	734
This holds even given the small head-to-head accuracy difference between flow and BMV.	I-Reply	I-1	Reply	734
<sep> <sep> This is one of the key findings of our paper, and we would be happy to clarify further.	I-Reply	I-1	Reply	734
<sep> <sep> As for blocking artifacts, these are minor, but visible in our qualitative outputs (Fig.8) -- for example, optical flow is better at preserving thin details, such as the street sign on the left (yellow in the segmentation output).	I-Reply	I-1	Reply	734
In contrast, forward flow warping causes drastic distortion of moving objects (e.g. the ‚ÄúADAC‚Äù taxi), occluding objects in the background (e.g. the pedestrians).	I-Reply	I-1	Reply	734
This is reflected in much lower *overall* quantitative accuracy (mIoU) for prop-flow than for inter-BMV.	I-Reply	I-1	Reply	734
We will add a note about blocking artifacts to the caption of Fig.8 in our revision.	I-Reply	I-1	Reply	734
<sep> <sep> <sep> (2) Our choice is inspired by the use of optical flow, in previous work (e.g. DFF), to warp deep features.	B-Reply	B-2	Reply	734
Like block motion, optical flow is also computed directly on image pixels (albeit with more complex methods, e.g. Lukas-Kanade [i] or Farneback [ii]), but is still able to effectively warp the intermediate representations of ResNet-based image/video recognition networks.	I-Reply	I-2	Reply	734
The core reason that pixel-level motion estimates suffice for feature warping is that fully convolutional architectures, such as e.g. FCN [iii] or DeepLab [iv] for segmentation, *preserve spatial structure* in their intermediate representations.	I-Reply	I-2	Reply	734
<sep> <sep> [i] B. Lucas and T. Kanade.	I-Reply	I-2	Reply	734
An iterative image registration technique with an application to stereo vision.	I-Reply	I-2	Reply	734
In DARPA Image Understanding Workshop, pages 121‚Äì130, 1981.	I-Reply	I-2	Reply	734
<sep> [ii] G. Farneback.	I-Reply	I-2	Reply	734
Two-frame motion estimation based on polynomial expansion.	I-Reply	I-2	Reply	734
In SCIA, 2003.	I-Reply	I-2	Reply	734
<sep> [iii] J. Long et al Fully convolutional networks for semantic segmentation.	I-Reply	I-2	Reply	734
CVPR 2015.	I-Reply	I-2	Reply	734
<sep> [iv] Chen et al Rethinking atrous convolution for semantic image segmentation.	I-Reply	I-2	Reply	734
TPAMI 2017.	I-Reply	I-2	Reply	734
<sep> <sep> <sep> (3) We evaluated on two datasets (CamVid, Cityscapes).	B-Reply	B-3	Reply	734
These are the two most popular benchmarks for segmentation research, and are representative of *realistic video*, which demonstrates strong temporal structure (i.e. lack of random motion from frame-to-frame).	I-Reply	I-3	Reply	734
Our key point is that we exploit this temporal continuity to accelerate segmentation for practical applications, such as video analytics, interactive film editing, and autonomous perception.	I-Reply	I-3	Reply	734
<sep> <sep> To directly address the reviewer‚Äôs point that ‚Äúthe authors are expected to demonstrate when the motion [is] chaotic‚Äù, our techniques are not dependent on any particular structure in the motion vectors.	I-Reply	I-3	Reply	734
We apply a well-known warping operator that spatially transforms the features with a bilinear upsampling of the motion vector maps [i]. This operation applies even if the vector maps are highly dense or irregular.	I-Reply	I-3	Reply	734
<sep> <sep> Please also see our responses to other reviewers, which contain e.g. more extensive comparison with other state-of-the-art techniques!	O	O	Reply	734
<sep> <sep> [i] Jaderberg et al Spatial Transformer Networks.	O	O	Reply	734
NIPS 2015.	O	O	Reply	734
<sep> <sep> <sep> Thanks once again for reading through our paper.	O	O	Reply	734
We look forward to hearing back!	O	O	Reply	734

This paper presents a feature interpolation strategy for fast semantic segmentation in videos.	O	O	Review	734
They first compute features of keyframes, then interpolate intermediate frames based on block-motion vectors (BMV), and finally fuse the interpolated features as input to the prediction network.	O	O	Review	734
The experiments show that the model outperforms one recent, closely related work wrt inference time while preserving accuracy.	O	O	Review	734
<sep> <sep> Positive:	O	O	Review	734
1.	O	O	Review	734
Efficient inference.	O	O	Review	734
The strategy cuts inference time on intermediate frames by 53%, while achieves better accuracy and IOU compared to the one recent closely related work.	O	O	Review	734
<sep> <sep> 2.	O	O	Review	734
The ablation study seems sufficient and well-designed.	O	O	Review	734
The paper presents two feature propagation strategies and three feature fusion methods.	O	O	Review	734
The experiments compare these different settings, and show that interpolation-BMV is indeed a better feature propagation.	O	O	Review	734
<sep> <sep> Negative:	O	O	Review	734
<sep> 1.	B-Review	B-1	Review	734
Limited novelty.	I-Review	I-1	Review	734
The algorithm is close to the optical-flow based models Shelhamer et al (2016) and Zhu et al (2017).	I-Review	I-1	Review	734
The main difference is that the optical-flow is replaced with BMV, which is a byproduct of modern cameras.	I-Review	I-1	Review	734
<sep> 2.	O	O	Review	734
Insufficient experimental comparison with other baselines.	B-Review	B-2	Review	734
In experiments, the paper compares the proposed model with only one baseline Prop-flow, which is not a sufficient comparison to show that the paper really outperforms the state-of-art model.	I-Review	I-2	Review	734
For example, the authors should also compare with ‚ÄúClockwork convnets for video semantic segmentation.	I-Review	I-2	Review	734
‚Äù	O	O	Review	734
<sep> 3.	B-Review	B-3	Review	734
Some technical details are not clear.	I-Review	I-3	Review	734
For example, in section 3.1, the paper mentions that the task network is built by concatenating three components but never clarifies them.	I-Review	I-3	Review	734
Also, in algorithm 2, line 13 shows that F is a function with two entries, but line 8 indicates that F is a feature.	I-Review	I-3	Review	734
<sep> <sep> <sep> <sep> <sep> <sep> Thanks a lot for taking the time to review our paper.	O	O	Reply	734
<sep> <sep> (1) Limited novelty -- Our paper is very keen on the distinction between our work and Shelhamer et al (2016) and Zhu et al (2017).	B-Reply	B-1	Reply	734
First, Shelhamer et al (2016) does not use optical flow, and instead simply copies features from frame to frame (and schedules this copying).	I-Reply	I-1	Reply	734
Zhu et al (2017) then proposes an improvement to this scheme, forward feature warping with optical flow.	I-Reply	I-1	Reply	734
In general, both these techniques fail to achieve speedups beyond small multiples of the baseline (< 3x), without impacting accuracy.	I-Reply	I-1	Reply	734
The key reason for this is that both feature copying and forward warping are unable to capture *new scene content*. In fast moving footage (e.g. driving footage), copied and warped features quickly become obsolete, and warping error compounds significantly (see e.g. qualitative outputs, Fig.8, in our paper).	I-Reply	I-1	Reply	734
<sep> <sep> In Inter-BMV, we exploit the observation that scenes tend to have semantic start and end points -- e.g. a pedestrian walking across a crosswalk, a car turning a street corner.	I-Reply	I-1	Reply	734
This allows us to leverage bi-directional warping, a new idea, to strong effect.	I-Reply	I-1	Reply	734
Our second insight -- that video is compressed by default in a temporally referential manner (e.g. P-/B-frames in H.264 video) -- lends itself to an alternate, computation-free motion estimation scheme.	I-Reply	I-1	Reply	734
This, together with our observation that video can be more efficiently processed in mini-batches, e.g. of 10 frames, enables us to trade-off a small amount of latency for a large gain in throughput.	I-Reply	I-1	Reply	734
Ten video frames consists of 330 ms of footage at 30 fps -- this is comparable to the human visual reaction time (230-400 ms, see studies [i]), yet allows us to accelerate segmentation by almost *6x* over frame-by-frame, while maintaining within 1-2% of baseline accuracy.	I-Reply	I-1	Reply	734
<sep> <sep> To the best of our knowledge, none of our core ideas -- (1) bi-directional feature warping, (2) the use of block motion vectors for deep representation warping, and (3) mini-batch processing of video to accelerate segmentation throughput -- have been proposed or published before.	I-Reply	I-1	Reply	734
<sep> <sep> [i] <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4374455/" target="_blank" rel="nofollow">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4374455/</a>	I-Reply	I-1	Reply	734
<sep> <sep> (2) Here are comparisons with other SoAs (ranked by accuracy).	B-Reply	B-2	Reply	734
Note that we significantly outperform Clockwork Convnets (Shelhamer et al 2016).	I-Reply	I-2	Reply	734
Note also that CC does not report results on CamVid, nor does it report inference times.	I-Reply	I-2	Reply	734
<sep> <sep> Cityscapes<tab><tab><tab>Accuracy (mIoU)<tab>Throughput (fps)<tab>  Key interval	I-Reply	I-2	Reply	734
Clockwork [i]<tab><tab><tab>          64.4<tab><tab><tab> --<tab><tab><tab>           2	I-Reply	I-2	Reply	734
DFF [ii]<tab><tab><tab><tab>          68.7<tab><tab><tab> 4.0<tab><tab><tab>           5	I-Reply	I-2	Reply	734
GRFP [iii]<tab><tab><tab>          69.4<tab><tab><tab> 2.1<tab><tab><tab>           5	I-Reply	I-2	Reply	734
Inter-BMV (us)<tab><tab><tab>  70.5<tab><tab><tab> 4.9<tab><tab><tab>           5	I-Reply	I-2	Reply	734
<sep> CamVid<tab><tab><tab>        Accuracy (mIoU)<tab>Throughput (fps)<tab>  Key interval	I-Reply	I-2	Reply	734
GRFP [iii]<tab><tab><tab>          66.1<tab><tab><tab> --<tab><tab>                   --	I-Reply	I-2	Reply	734
DFF [i]<tab><tab><tab><tab>          67.4<tab><tab><tab> 8.0<tab><tab><tab>           3	I-Reply	I-2	Reply	734
Inter-BMV (us)<tab><tab><tab>  68.7<tab><tab><tab> 9.1<tab><tab><tab>           3	I-Reply	I-2	Reply	734
<sep> [i] Shelhamer et al Clockwork Convnets for Video Semantic Segmentation.	I-Reply	I-2	Reply	734
ECCV Workshops 2016.	I-Reply	I-2	Reply	734
<sep> [ii] Zhu et al Deep Feature Flow for Video Recognition.	I-Reply	I-2	Reply	734
CVPR 2017.	I-Reply	I-2	Reply	734
<sep> [iii] D. Nilsson and C. Sminchisescu.	I-Reply	I-2	Reply	734
Semantic video segmentation by gated recurrent flow propagation.	I-Reply	I-2	Reply	734
CVPR 2018.	I-Reply	I-2	Reply	734
<sep> <sep> For a more extensive comparison with a number of other segmentation architectures, please see our response to AnonReviewer1!	I-Reply	I-2	Reply	734
<sep> <sep> <sep> (3) We describe our task network as follows (Sec.	B-Reply	B-3	Reply	734
3.1, p. 3):	I-Reply	I-3	Reply	734
<sep> ‚ÄúWe identify two logical components in our final model: a feature network, which takes as input an image i ‚àà	I-Reply	I-3	Reply	734
R^{1√ó3√óh√ów} and outputs a representation f_i ‚àà R^{1√óA√óh/16√ów/16}, and a task network, which given the	I-Reply	I-3	Reply	734
representation, computes class predictions for each pixel in the image, p_i ‚àà R^{1√óC√óh√ów}.	I-Reply	I-3	Reply	734
<sep> The task network N_task is built by concatenating three blocks: (1) a feature projection block, which reduces the	I-Reply	I-3	Reply	734
feature channel dimensionality to A/2, (2) a scoring block, which predicts scores for each of the C segmentation	I-Reply	I-3	Reply	734
classes, and (3) an upsampling block, which bilinearly upsamples the score maps to the resolution of the input	I-Reply	I-3	Reply	734
image.	I-Reply	I-3	Reply	734
‚Äù	I-Reply	I-3	Reply	734
<sep> We used the DeepLab segmentation architecture (Chen et al 2017), so we omitted further details about the task network, provided here:	I-Reply	I-3	Reply	734
(1) Feature projection block - R^{1√óA√óh/16√ów/16} -> R^{1√óA/2√óh/16√ów/16}	I-Reply	I-3	Reply	734
(2) Scoring block - R^{1√óA/2√óh/16√ów/16} -> R^{1√óC√óh/16√ów/16}	I-Reply	I-3	Reply	734
(3) Upsampling block - R^{1√óC√óh/16√ów/16} -> R^{1√óC√óh√ów}	I-Reply	I-3	Reply	734
<sep> Regarding Algorithm 2 in the Appendix, good catch!	I-Reply	I-3	Reply	734
<sep> <tab>Line 8 should read f_{k+n} ‚Üê N_{feat} (I_{k+n}) NOT	I-Reply	I-3	Reply	734
<tab><tab><tab>                  f_{k+n} ‚Üê N_{feat} (F_{k+n})	I-Reply	I-3	Reply	734
<tab>where I_{k+n} refers to the k+n-th frame in the video.	I-Reply	I-3	Reply	734
<sep> <sep> We will correct this in our revision.	I-Reply	I-3	Reply	734
<sep> <sep> <sep> Thanks a lot once again for your comments.	O	O	Reply	734
We look forward to your response!	O	O	Reply	734

# Paper summary	O	O	Review	734
This paper advances a method for accelerating semantic segmentation on video content at higher resolutions.	O	O	Review	734
Semantic segmentation is typically performed over single images, while there is un-used redundancy between neighbouring frames.	O	O	Review	734
The authors propose exploiting this redundancy and leverage block motion vectors from MPEG H.264 video codec which encodes residual content between keyframes.	O	O	Review	734
The block motion vectors from H264 are here used to propagate feature maps from keyframes to neighbouring non-keyframe frames (in both temporal directions) avoiding thus an additional full forward pass through the network and integrate this in the training pipeline.	O	O	Review	734
Experimental results on CamVid and Cityscapes show that the proposed method gets competitive results while saving computational time.	O	O	Review	734
<sep> <sep> <sep> # Paper strengths	O	O	Review	734
- This paper addresses a problem of interest for both academic and industrial purposes.	O	O	Review	734
<sep> - The paper is clearly written and the authors argument well their contributions, adding relevant plots and qualitative results where necessary.	O	O	Review	734
<sep> - The two-way interpolation with block motion vectors and the fusion of interpolated features are novel and seem effective.	O	O	Review	734
<sep> - The experimental results, in particular for the two-way BMV interpolation, are encouraging.	O	O	Review	734
<sep> <sep> <sep> # Paper weaknesses	O	O	Review	734
<sep> - The idea of using Block Motion Vectors from compressed videos (x264, xvid) to capture motion with low-cost has been previously proposed and studied by Kantorov and Laptev [i] in the context of human action recognition.	B-Review	B-1	Review	734
Flow vectors are obtained with bilinear interpolation from motion blocks between neighbouring frames.	I-Review	I-1	Review	734
Vectors are then encoded in Fisher vectors and not used with CNNs as done in this paper.	I-Review	I-1	Review	734
In both works, block motion vectors are used as low-cost alternatives to dense optical flow.	I-Review	I-1	Review	734
I would suggest to cite this work and discuss similarities and differences.	I-Review	I-1	Review	734
<sep> <sep> <sep> - Regarding the evaluation of the method, some recent methods dealing with video semantic segmentation, also using ResNet101 as backbone, are missing, e.g. low latency video semantic segmentation[ii]. Pioneer Clockwork convnets are also a worthy baseline in particular in terms of computational time (results and running times on CityScapes are shown in [ii]).	B-Review	B-2	Review	734
It would be useful to include and compare against them.	I-Review	I-2	Review	734
<sep> <sep> - In Section 4.1.2 page 7 the authors mention a few recent single-frame models ((Yu et al (2017); Chen et al (2017); Lin et al (2017); Bilinski & Prisacariu (2018)) as SOTA methods and the current method is competitive with them.	B-Review	B-3	Review	734
However I do not see the results from the mentioned papers in the referenced Figures.	I-Review	I-3	Review	734
Is this intended?	I-Review	I-3	Review	734
<sep> <sep> - On a more general note related to this family of approaches, I feel that their evaluation is usually not fully eloquent.	B-Review	B-4	Review	734
Authors compare against similar pipelines for static processing and show gains in terms of computation time.	I-Review	I-4	Review	734
The backbone architecture, ResNet-101 is already costly for high-resolution inputs to begin with and avoiding a full-forward pass brings quite some gains (though a part of this gain is subsequently attenuated by the latency caused by the batch processing of the videos).	I-Review	I-4	Review	734
There are recent works in semantic segmentation that focus on architectures with less FLOPs or memory requirements than ResNet101, e.g. Dilated ResNets [iii], LinkNet[iv]. So it could be expected that image-based pipelines to be getting similar or better performance in less time.	I-Review	I-4	Review	734
I expect the computational gain on such architectures when using the proposed video processing method to be lower than for ResNet101, and it would make the decision of switching to video processing or staying with frame-based predictions more complex.	I-Review	I-4	Review	734
<sep> The advantage of static image processing is simpler processing pipelines at test time without extra parameters to tune.	I-Review	I-4	Review	734
It would be interesting and useful to compare with such approaches on more even grounds.	I-Review	I-4	Review	734
<sep> <sep> <sep> # Conclusion	O	O	Review	734
This paper takes on an interesting problem and achieves interesting results.	O	O	Review	734
The use of Block Motion Vectors has been proposed before in [i] and the main novelty of the paper remains only the interpolation of feature maps using BMVC.	O	O	Review	734
The experimental section is missing some recent related methods to benchmark against.	O	O	Review	734
<sep> This work has several strong and weak points.	O	O	Review	734
I'm currently on the fence regarding my decision.	O	O	Review	734
For now I'm rating this work between Weak Reject and Borderline	O	O	Review	734
<sep> # References	O	O	Review	734
<sep> [i] V. Kantorov and I. Laptev, Efficient feature extraction, aggregation and classification for action recognition, CVPR 2014	O	O	Review	734
[ii] Y. Li et al Low-Latency Video Semantic Segmentation, CVPR 2018	O	O	Review	734
[iii] F. Yu et al Dilated Residual Networks, CVPR 2017	O	O	Review	734
[iv] A. Chaurasia and E. Culurciello, LinkNet: Exploiting Encoder Representations for Efficient Semantic Segmentation, arXiv 2017	O	O	Review	734
<sep> Thanks very much for your thoughtful comments on our paper.	O	O	Reply	734
<sep> <sep> (1) Thanks for pointing our attention to Kantorov and Laptev 2014.	B-Reply	B-1	Reply	734
While Kantorov and Laptev do explore MPEG block motion vectors, they do so in a very different context, treating motion vectors as low-level video features (‚Äúdescriptors‚Äù) to learn more effectively on video.	I-Reply	I-1	Reply	734
This is a very similar idea to that proposed in CoViAR [i], which trains directly on video I-frames, motion vectors, and residuals (also in the context of action recognition).	I-Reply	I-1	Reply	734
CoViAR (Wu et al 2018) is cited and discussed in our paper (Sec.	I-Reply	I-1	Reply	734
2.3):	I-Reply	I-1	Reply	734
<sep> ‚ÄúWu et al (2018) train a network directly on compressed video to improve both accuracy and performance on video	I-Reply	I-1	Reply	734
action recognition... Unlike these works, our main focus is not efficient training, nor reducing the physical size of	I-Reply	I-1	Reply	734
input data to strengthen the underlying signal for video-level tasks, such as action recognition.	I-Reply	I-1	Reply	734
‚Äù	I-Reply	I-1	Reply	734
<sep> In contrast, we center our efforts on efficient, frame-level inference (Sec.	I-Reply	I-1	Reply	734
2.3 cont‚Äôd):	I-Reply	I-1	Reply	734
<sep> ‚ÄúWe instead focus on a class of dense prediction tasks, notably semantic segmentation, that involve high-	I-Reply	I-1	Reply	734
dimensional output (e.g. a class prediction for every pixel in an image) generated on the original uncompressed	I-Reply	I-1	Reply	734
frames of a video.	I-Reply	I-1	Reply	734
This means that we must still process each frame in isolation.	I-Reply	I-1	Reply	734
To the best of our knowledge, we	I-Reply	I-1	Reply	734
are the first to propose the use of compressed video artifacts to warp deep neural representations, with the goal of...	I-Reply	I-1	Reply	734
improved inference throughput on realistic video.	I-Reply	I-1	Reply	734
‚Äù	I-Reply	I-1	Reply	734
<sep> We will add a citation to Kantorov and Laptev 2014 in our paper revision.	I-Reply	I-1	Reply	734
Thanks once again for the reference.	I-Reply	I-1	Reply	734
<sep> <sep> [i] Wu et al Compressed Video Action Recognition.	I-Reply	I-1	Reply	734
CVPR 2018.	I-Reply	I-1	Reply	734
<sep> <sep> <sep> (2) We compare to these methods in the table below.	B-Reply	B-2	Reply	734
<sep> <sep> <sep> (3) Here are comparisons to CC, the single-frame models we cited, and other SoA methods.	B-Reply	B-3	Reply	734
Note that even while none of these schemes report inference times, we still outperform (or are competitive) on accuracy.	I-Reply	I-3	Reply	734
We‚Äôd be happy to include this table in the revised paper, if helpful.	I-Reply	I-3	Reply	734
<sep> <sep> Cityscapes<tab><tab>        Accuracy (mIoU)<tab> Throughput (fps)     Model notes	I-Reply	I-3	Reply	734
DFF [i]<tab><tab><tab>                 72.0<tab><tab><tab>    3.0<tab><tab>     KI=3*	I-Reply	I-3	Reply	734
Inter-BMV (us)<tab><tab><tab> 72.5<tab><tab><tab>    3.4<tab><tab>     KI=3	I-Reply	I-3	Reply	734
<sep> Clockwork (2016) [ii]<tab><tab> 64.4<tab><tab><tab>     --<tab><tab>     Alternating (best)	I-Reply	I-3	Reply	734
Yu et al (2017)<tab><tab>         70.9<tab><tab><tab>     --<tab><tab>     DRN-C-42 (best)	I-Reply	I-3	Reply	734
Chen et al (2017)<tab><tab>         71.4<tab><tab><tab>     --<tab>             DL-101 (best)	I-Reply	I-3	Reply	734
Lin et al (2017)<tab><tab>         73.6<tab><tab><tab>     --<tab><tab>     RN-101 (best)	I-Reply	I-3	Reply	734
<sep> CamVid  <tab><tab><tab>Accuracy (mIoU)<tab> Throughput (fps)     Notes	I-Reply	I-3	Reply	734
DFF [i]<tab><tab><tab>                 67.4<tab><tab><tab>    8.0<tab><tab>     KI=3	I-Reply	I-3	Reply	734
Inter-BMV (us)<tab><tab><tab> 68.7<tab><tab><tab>    9.1<tab><tab>     KI=3	I-Reply	I-3	Reply	734
<sep> GRFP (2018) [iii]<tab><tab>         66.1<tab><tab><tab>     --<tab><tab>     D8+GRFP (best)	I-Reply	I-3	Reply	734
LinkNet (2017) [iv]<tab><tab> 68.3<tab><tab><tab>     --<tab><tab>     LinkNet (best)	I-Reply	I-3	Reply	734
Bilinski et al (2018)<tab><tab> 70.9<tab><tab><tab>     --<tab>             Single scale (best)	I-Reply	I-3	Reply	734
<sep> *KI = keyframe interval	I-Reply	I-3	Reply	734
<sep> [i] Zhu et al Deep Feature Flow for Video Recognition.	I-Reply	I-3	Reply	734
CVPR 2017.	I-Reply	I-3	Reply	734
<sep> [ii] Shelhamer et al Clockwork Convnets for Video Semantic Segmentation.	I-Reply	I-3	Reply	734
ECCV Workshops 2016.	I-Reply	I-3	Reply	734
<sep> [iii] D. Nilsson and C. Sminchisescu.	I-Reply	I-3	Reply	734
Semantic video segmentation by gated recurrent flow propagation.	I-Reply	I-3	Reply	734
CVPR 2018.	I-Reply	I-3	Reply	734
<sep> [iv] A. Chaurasia and E. Culurciello.	I-Reply	I-3	Reply	734
LinkNet: exploiting encoder representations for efficient semantic segmentation.	I-Reply	I-3	Reply	734
arXiv 2017.	I-Reply	I-3	Reply	734
<sep> <sep> <sep> (4) This is a good suggestion.	B-Reply	B-4	Reply	734
We compare against Dilated ResNets (Yu et al 2017) and LinkNet (Chaurasia et al 2017) in the previous table.	I-Reply	I-4	Reply	734
<sep> <sep> Thanks once again for the taking the time to review our paper.	O	O	Reply	734
We look forward to hearing back!	O	O	Reply	734

This paper shows that a penalty term called rugosity captures the implicit regularization effect of deep neural networks with ReLU (and piecewise affine in general) activation.	O	O	Review	20231
Roughly, rugosity measures how far the function parametrized as a deep network deviates from a locally linear function.	O	O	Review	20231
<sep> <sep> The paper starts by showing that the amount of training loss increased from adding data augmentation is upper bounded in terms of (roughly) a Monte Carlo approximate to a Hessian based measure of rugosity.	O	O	Review	20231
It then formally derives this measure of rugosity for networks with continuous piecewise affine activations.	O	O	Review	20231
Finally, experimental evaluation for classification tasks on MNIST, SVHN and CIFAR shows that data augmentation indeed reduces the rogusity by a significant amount particularly when using the ResNet structure.	O	O	Review	20231
A somehow surprising message is, however, that if one imposes explicit regularization with rugosity in lieu of data augmentation, then the better generalization usually seen from data augmentation no longer presents, though one does get a network with smaller rugosity.	O	O	Review	20231
<sep> <sep> Comments:	O	O	Review	20231
<sep> It is quite interesting to see that the rugosity measure proposed in the paper captures at least some aspects of the implicit regularization effect of data augmentation both in terms of theory (i.e. Theorem 1) and practical observations.	B-Review	B-1	Review	20231
My feeling is that rugosity is mostly a measure of the smoothness of the function parametrized by the neural network.	I-Review	I-1	Review	20231
From that perspective, how is the rugosity as a smoothness measurement for neural networks with piecewise affine activations different from the Lipschitz constant for general neural networks?	I-Review	I-1	Review	20231
My guess is that data augmentation also decreases the Lipschitz constant of a neural network near the training data points, but regardless of whether this is true or not, it is not clear if and how rugosity is better than Lipschitz constant for characterizing the implicit regularization of data augmentation.	I-Review	I-1	Review	20231
<sep> <sep> In addition, there have been many recent studies on showing that gradient penalty / Lipschitz regularization are useful for achieving better generalization and adversarial robustness, see e.g. [a,b,c]. The results in this paper on showing that regularizing rugosity does not improve accuracy seem to contradict with the conclusion of these prior studies.	B-Review	B-2	Review	20231
It is unclear to me whether this is caused by insufficient experimentation or if there is any fundamental difference between rugosity and Lipschitz regularization that I am missing.	I-Review	I-2	Review	20231
<sep> <sep> [a] Finlay et al Lipschitz regularized deep neural networks generalize and are adversarially robust	O	O	Review	20231
[b] Gouk et al Regularisation of Neural Networks by Enforcing Lipschitz Continuity	O	O	Review	20231
[c] Thanh-Tung et al Improving generalization and stability of GANs	O	O	Review	20231
<sep> <sep> <sep> <sep> <sep> We thank the reviewer for their positive comments and useful suggestions.	O	O	Reply	20231
We provide the following response.	O	O	Reply	20231
<sep> <sep> 1&gt; How is the rugosity as a smoothness measurement for neural networks with piecewise affine activations different from the Lipschitz constant for general neural networks?	O	O	Reply	20231
<sep> <sep> Two main features of our measure distinguish it from the Lipschitz constant: 1) Rugosity depends on the Hessian of the function generated by the deep network, which is a second-order smoothness measure.	B-Reply	B-1	Reply	20231
<sep> In contrast, the Lipschitz constant is a first-order measure that depends on the first derivative (Jacobian) of the network.	I-Reply	I-1	Reply	20231
In other words, rugosity quantifies how much the function generated by a deep network differs from an affine mapping over the input space.	I-Reply	I-1	Reply	20231
We believe rugosity provides a better measure for complexity, especially when the network consists of continuous piecewise linear activations that result in a continuous piecewise linear prediction function.	I-Reply	I-1	Reply	20231
2) In many applications, for example when the input data consists of natural images, the training data points lie on a lower-dimensional manifold of dimension.	I-Reply	I-1	Reply	20231
We can exploit this local geometrical structure to evaluate the prediction mapping as a function of the manifold local coordinates and compute the rugosity on the data manifold.	I-Reply	I-1	Reply	20231
This result is a natural data-driven complexity measure for that evaluates its complexity over the signal space of importance.	I-Reply	I-1	Reply	20231
In contrast, the standard Lipschitz constant considers the entire input space, which might be not relevant.	I-Reply	I-1	Reply	20231
<sep> <sep> In addition, as we demonstrate through our empirical results in Section 4.1 and Table 1, for classification tasks on the CIFAR10 and SVHN datasets, rugosity better reflects the difference between training with and without data augmentation.	I-Reply	I-1	Reply	20231
Table 1 shows that data augmentation reduces when used for training on these datasets but has no effect (or increases) the Jacobian measure.	I-Reply	I-1	Reply	20231
This suggests that rugosity is a more informative complexity measure than the Jacobian.	I-Reply	I-1	Reply	20231
<sep> <sep> 2&gt; There have been many recent studies on showing that gradient penalty / Lipschitz regularization are  useful  for  achieving  better  generalization  and  adversarial robustness.	O	O	Reply	20231
The  results  in this  paper  on  showing  that  regularizing  rugosity  does  not  improve  accuracy  seem  to  contradict  with  the conclusion of these prior studies.	O	O	Reply	20231
It is unclear to me whether this is caused by insufficient experimentation or if there is any fundamental difference between rugosity and Lipschitz regularization that I am missing.	O	O	Reply	20231
<sep> <sep> We thank the reviewer for mentioning these interesting works.	B-Reply	B-2	Reply	20231
We plan to apply our rugosity measure as an explicit regularization penalty in the settings discussed in these papers in order to see the effect on generalization and adversarial robustness in our revised paper.	I-Reply	I-2	Reply	20231
In fact, we suspect that using rugosity as an explicit regularization should improve adversarial robustness, and we will include an empirical study of this hypothesis in our next revision.	I-Reply	I-2	Reply	20231
In addition, we should note that there are results in the literature confirming our observation that using the Jacobian as explicit regularization does not have a significant effect on generalization:  Hoffman et al ``Robust Learning with Jacobian Regularization.''	I-Reply	I-2	Reply	20231

The paper aims to explain the regularization and generalization effects of data augmentation commonly used in training Neural Networks.	O	O	Review	20231
<sep> It suggests a novel measure of "rugosity" that measures a function's diversion from being locally linear and explores the connection between data augmentation and the decrease in rugosity.	O	O	Review	20231
<sep> It further suggests the explicit use of rugosity measure as a regularization during training to replace need for data augmentation.	O	O	Review	20231
<sep> The paper is very well written and both the positive and negative findings are clearly presented and discussed.	O	O	Review	20231
<sep> Cons:	O	O	Review	20231
- The main contribution of the paper, in my view, is the suggestion of using rugosity as a explicit regularization for training Neural Networks.	B-Review	B-1	Review	20231
Nevertheless, all the results in the paper show a negative impact of this on the test accuracy which is contradicting to the proposition.	I-Review	I-1	Review	20231
<sep> This result has been discussed in section 5 but without much evidence to the explanations mentioned.	I-Review	I-1	Review	20231
The connection is very interesting but I believe further work is needed to explain those negative results on test accuracy.	I-Review	I-1	Review	20231
<sep> - The difference in finding (Table 1) between the CNN and ResNet networks can be more discussed.	B-Review	B-2	Review	20231
<sep> - Additional tasks (like regression) or even toy examples can be useful in further explaining the connection between rugosity and generalization to test data.	B-Review	B-2	Review	20231
<sep> We thank the reviewer for positive comments and useful suggestions.	O	O	Reply	20231
We provide the following responses for the comments.	O	O	Reply	20231
<sep> <sep> 1&gt; The main contribution of the paper, in my view, is the suggestion of using rugosity as a explicit regularization for training Neural Networks.	O	O	Reply	20231
Nevertheless, all the results in the paper show a negative impact of this on the test accuracy which is contradicting to the proposition.	O	O	Reply	20231
<sep> <sep> We agree that we did not observe a significant improvement in generalization error as a result of using rugosity as an explicit regularization in our experiments.	B-Reply	B-1	Reply	20231
However, this is not the only contribution of our paper.	I-Reply	I-1	Reply	20231
As we show in the paper, rugosity provides a data-driven complexity measure for the prediction function of the deep network that can help demystify generalization and (implicit) regularization.	I-Reply	I-1	Reply	20231
As an example, we show how rugosity can be used to understand the effects of data augmentation.	I-Reply	I-1	Reply	20231
We plan to  perform further exploration on the effects of using rugosity as an explicit regularization in our revised paper.	I-Reply	I-1	Reply	20231
For example, we expect that using rugosity as explicit regularization can improve adversarial robustness.	I-Reply	I-1	Reply	20231
<sep> 2&gt; The difference in finding (Table 1) between the CNN and ResNet networks can be more discussed.	O	O	Reply	20231
Additional tasks (like regression) or even toy examples can be useful in further explaining the connection between rugosity and generalization to test data.	O	O	Reply	20231
<sep> <sep> We appreciate these useful suggestions.	O	O	Reply	20231
We agree that these points require further examination, and we will include this further analysis in our revision.	B-Reply	B-2	Reply	20231

This paper shows (theorem 1) that data augmentation (DA) induces a reduction of rugsity on the loss function associated to the model.	O	O	Review	20231
Here rugosity is defined as a measure of the curvature (2nd order) of the function.	O	O	Review	20231
However, the two concepts seems to be different because the authors empirically show that directly reducing the rugosity of a network does not improve generalization (in contrast to DA).	O	O	Review	20231
<sep> <sep> I lean to reject this paper because the contributions, even if interesting, do not lead to any new understanding of the topic.	O	O	Review	20231
More in detail, data augmentation improves the generalization on deep learning models.	B-Review	B-2	Review	20231
This paper shows that DA induces rugosity (theorem 1), but rugosity does not improve generalization (empirically).	I-Review	I-2	Review	20231
Thus, rugosity is not responsible for generalization, which is the interesting property that we care about.	I-Review	I-2	Review	20231
<sep> <sep> The paper is well written and easy to follow, however I found the actual contribution limited because:	O	O	Review	20231
- The definition of rugosity is an extension of (Donoho &amp; Grimes (2003)) in which the extension is not really improving anything or used anywhere in the paper.	B-Review	B-1	Review	20231
<sep> - The Hessian-based rugosity analysis of DA is correct, but it does not help to understand the generalization performance or any other useful property of DA.	B-Review	B-2	Review	20231
<sep> Additional Comments:	O	O	Review	20231
- In 3.4 second paragraph the authors suggest that reducing rugosity can improve generalization as DA, but later we see that this is not the case.	B-Review	B-3	Review	20231
<sep> - The entire paper seems written with the idea of using rugosity as a surrogate of DA, but at the end it does not work	B-Review	B-4	Review	20231
<sep> We thank the reviewer for positive comments and useful suggestions.	O	O	Reply	20231
We provide the following responses for the comments.	O	O	Reply	20231
<sep> <sep> 1&gt; The definition of rugosity is an extension of (Donoho &amp; Grimes (2003)) in which the extension is not really improving anything or used anywhere in the paper.	O	O	Reply	20231
<sep> <sep> The rugosity measure that we defined and used is in fact inspired by the tangent Hessian measure proposed by (Donoho &amp; Grimes (2003)).	B-Reply	B-1	Reply	20231
We have modified the tangent Hessian integral measure provided in this paper to make it suitable to use for piecewise linear functions and for making it easier to compute.	I-Reply	I-1	Reply	20231
We believe that this measure can provide useful information about the landscape and complexity of the prediction function generated by the deep network.	I-Reply	I-1	Reply	20231
<sep> <sep> 2&gt; Data augmentation improves the generalization on deep learning models.	O	O	Reply	20231
This paper shows that DA induces rugosity (theorem 1), but rugosity does not improve generalization (empirically).	O	O	Reply	20231
Thus, rugosity is not responsible for generalization, which is the interesting property that we care about.	O	O	Reply	20231
The Hessian-based rugosity analysis of DA is correct, but it does not help to understand the generalization performance or any other useful property of DA.	O	O	Reply	20231
<sep> <sep> We agree that our empirical results do not show significant classification performance improvement as a result of using rugosity as explicit regularization.	B-Reply	B-2	Reply	20231
However, the effect of data augmentation on rugosity (and also generalization) is a significant observation and points to the question of what other properties data augmentation possesses that lead to improve generalization.	I-Reply	I-2	Reply	20231
We believe that this is an important question that requires a more thorough and comprehensive understanding of regularization in the overparameterized (interpolating) regime.	I-Reply	I-2	Reply	20231
What our results suggest is that, although there is a close connection between rugosity and data augmentation, rugosity (or smoothness) cannot by itself explain the entire effect of data augmentation on generalization.	I-Reply	I-2	Reply	20231
<sep> <sep> In addition, understanding generalization is not the primary goal of our paper.	I-Reply	I-2	Reply	20231
We believe that our rugosity measure can be a very useful data-driven measure for understanding the prediction function generated by a deep network.	I-Reply	I-2	Reply	20231
One of our applications was understanding data augmentation, which we illustrated through theoretical and empirical analysis.	I-Reply	I-2	Reply	20231
We showed the close connection between data augmentation and rugosity which suggests that rugosity can be a more effective complexity measure than other common complexity measures, e.g., the Jacobian.	I-Reply	I-2	Reply	20231
Further, there can be many other properties of deep networks, such as adversarial robustness, that rugosity can help us to better understand and improve.	I-Reply	I-2	Reply	20231
We believe that our work is only the first step in this direction.	I-Reply	I-2	Reply	20231
<sep> <sep> 3&gt; In 3.4 second paragraph the authors suggest that reducing rugosity can improve generalization as DA, but later we see that this is not the case.	O	O	Reply	20231
<sep> <sep> The effect of rugosity as explicit regularization on improving generalization is what can be initially expected from Theorem 1 and the empirical results showing the connection between data augmentation and rugosity.	B-Reply	B-3	Reply	20231
However, surprisingly, this is not what we observed in our further experiments.	I-Reply	I-3	Reply	20231
This suggests that understanding generalization requires a more comprehensive understanding of properties (other than just the rugosity or smoothness) of the function generated by a deep network.	I-Reply	I-3	Reply	20231
<sep> <sep> 4&gt; The entire paper seems written with the idea of using rugosity as a surrogate of DA, but at the end it does not work.	O	O	Reply	20231
<sep> <sep> We do not suggest to use rugosity as a surrogate for data augmentation.	B-Reply	B-4	Reply	20231
Rather, we propose rugosity as a useful, data-driven measure for studying a deep network and the complexity of the prediction function it produces.	I-Reply	I-4	Reply	20231
While we showed that rugosity has a close connection to data augmentation, our experiments show also that rugosity, by itself, cannot completely explain the generalization properties of deep nets or data augmentation.	I-Reply	I-4	Reply	20231

This paper investigates the hessian of small deep networks near the end of training.	O	O	Review	478
The main result is that many eigenvalues are approximately zero, such that the Hessian is highly singular, which means that a wide amount of theory does not apply.	O	O	Review	478
<sep> <sep> The overall point that deep learning algorithms are singular, and that this undercuts many theoretical results, is important but it has already been made: Watanabe. ‚	B-Review	B-1	Review	478
ÄúAlmost All Learning Machines are Singular‚Äù, FOCI 2007.	I-Review	I-1	Review	478
This is one paper in a growing body of work investigating this phenomenon.	I-Review	I-1	Review	478
In general, the references for this paper could be fleshed out much further‚Äîa variety of prior work has examined the Hessian in deep learning, e.g., Dauphin et al ‚ÄúIdentifying and attacking the saddle point problem in high dimensional non-convex optimization‚Äù NIPS 2014 or the work of Amari and others.	I-Review	I-1	Review	478
<sep> <sep> Experimentally, it is hard to tell how results from the small sized networks considered here might translate to much larger networks.	B-Review	B-2	Review	478
It seems likely that the behavior for much larger networks would be different.	I-Review	I-2	Review	478
A reason for optimism, though, is the fact that a clear bulk/outlier behavior emerges even in these networks.	I-Review	I-2	Review	478
Characterizing this behavior for simple systems is valuable.	I-Review	I-2	Review	478
Overall, the results feel preliminary but likely to be of interest when further fleshed out.	I-Review	I-2	Review	478
<sep> <sep> This paper is attacking an important problem, but should do a better job situating itself in the related literature and undertaking experiments of sufficient size to reveal large-scale behavior relevant to practice.	B-Review	B-3	Review	478
<sep> <sep> Thank you very much for pointing out at the FOCI 2007 paper, it is certainly relevant, even though the main object is the Fisher information matrix rather than the Hessian of the cost function.	B-Reply	B-1	Reply	478
<sep> Dauphin et al is interested only in saddle points near the path of training.	I-Reply	I-1	Reply	478
These two works are indeed remotely related to the line of research that our work is invested in.	I-Reply	I-1	Reply	478
<sep> However, their objective and results are different.	I-Reply	I-1	Reply	478
<sep> <sep> We have added more references and clarified our contributions.	O	O	Reply	478

The paper analyzes the properties of the Hessian of the training objective for various neural networks and data distributions.	O	O	Review	478
The authors study in particular, the eigenspectrum of the Hessian, which relates to the difficulty and the local convexity of the optimization problem.	O	O	Review	478
<sep> <sep> While there are several interesting insights discussed in this paper such as the local flatness of the objective function, as well as the study of the relation between data distribution and Hessian, a somewhat lacking aspect of the paper is that most described effects are presented as general, while tested only in a specific setting, without control experiments, or mathematical analysis.	O	O	Review	478
<sep> <sep> For example, regarding the concentration of eigenvalues to zero in Figure 6, it is unclear whether the concentration effect is really caused by training (e.g. increasing insensitivity to local perturbations), or the consequence of a specific choice of scale for the initial parameters.	B-Review	B-1	Review	478
<sep> <sep> In Figure 8, the complexity of the data is not defined.	B-Review	B-2	Review	478
It is not clear whether two fully overlapping distributions (the Hessian would then become zero?)	I-Review	I-2	Review	478
is considered as complex or simple data.	I-Review	I-2	Review	478
<sep> <sep> Some of the plots legends (Fig.1 and 2) and labels are unreadable in printed format.	B-Review	B-3	Review	478
Plots of Figure 3 don't have the same range for the x-axis.	I-Review	I-3	Review	478
The image of Hessian matrix of Figure 1 does not render properly in printed format.	I-Review	I-3	Review	478
We realized that the text hasn't been clear in the experiments that we performed.	O	O	Reply	478
We clarified the text.	O	O	Reply	478
<sep> <sep> Figure 1 and figure 2 (left) show the beginning and the end of the model with 10-hidden units which is consistent with figure 6.	B-Reply	B-1	Reply	478
In both cases of the simple data and MNIST the initial point is chosen randomly on the surface of a sphere centered at zero with fixed  radius (the radius is depends on the number of hidden units).	I-Reply	I-1	Reply	478
<sep> <sep> The complexity of data can be tricky to describe, a data can be more complex for a certain model but less so for another one.	B-Reply	B-2	Reply	478
Thank you for pointing this out, we clarified this point on the data complexity by the ease of separability in the text.	I-Reply	I-2	Reply	478
<sep> We also updated the axes and labels in fig 1 and 2.	B-Reply	B-3	Reply	478
We changed the rendering format for the Hessian matrix increasing the sharpness and resolution.	I-Reply	I-3	Reply	478
For figure 4 we would like to emphesize the two components of the spectrum, therefore we picked the widest possible representation for each case separately.	I-Reply	I-3	Reply	478
However, we would also like to note that another series of experiments will explore the scale of eigenvalues depending on the iteration number during the training.	I-Reply	I-3	Reply	478

The work presents some empirical observations to support the statement that ‚Äúthe Hessian of the loss functions in deep learning is degenerate‚Äù.	B-Review	B-1	Review	478
But what does this statement refer to?	I-Review	I-1	Review	478
To my understanding, there are at least three interpretations:	I-Review	I-1	Review	478
<sep> (i) The Hessian of the loss functions in deep learning is degenerate at any point in the parameter space, i.e., any network weight matrices.	I-Review	I-1	Review	478
<sep> <sep> (ii) The Hessian of the loss functions in deep learning is degenerate at any critical point.	I-Review	I-1	Review	478
<sep> <sep> (iii) The Hessian of the loss functions in deep learning is degenerate at any local minimum, or any global minimum.	I-Review	I-1	Review	478
<sep> <sep> None of these interpretations is solidly supported by the observations provided in the paper.	I-Review	I-1	Review	478
<sep> <sep> More comments are as follows:	O	O	Review	478
<sep> 1) The authors state that ‚Äúwe don‚Äôt have much information on what the actual Hessian looks like.	B-Review	B-2	Review	478
‚Äù Then I just wonder what Hessian is investigated.	I-Review	I-2	Review	478
Is it the actual one or approximate one?	I-Review	I-2	Review	478
Please clarify and provide the references for computing the actual Hessian.	I-Review	I-2	Review	478
<sep> <sep> 2) It is not clear whether the optimization was done by a batch gradient descent algorithm, i.e., batch back propagation (BP) algorithm, or a stochastic BP algorithm.	B-Review	B-3	Review	478
If the training was done via a stochastic BP algorithm, it is hard to conclude that the the Neural Network has been trained to its local minimum.	I-Review	I-3	Review	478
When it was done by a full-batch BP algorithm, what was the accumulating point?	I-Review	I-3	Review	478
Was it local minimum or global minimum?	I-Review	I-3	Review	478
<sep> <sep> 3) Since the negative log likelihood function was used as at the end of training, it is essentially a joint learning approach in both the Newton weight matrices and the negative log likelihood vector.	B-Review	B-4	Review	478
Certainly, the whole loss function is not convex in these two parameters.	I-Review	I-4	Review	478
But if least squares error function is used at the end, would it make any difference in claiming the degeneracy of the Hessian?	I-Review	I-4	Review	478
<sep> <sep> 4) Finally, the statement ‚ÄúThere are still negative eigenvalues even when they are small in magnitude‚Äù is very puzzling.	B-Review	B-5	Review	478
Potential reasons are:	I-Review	I-5	Review	478
(a) If the training algorithm did converge, the accumulating points were not local minima, i.e., they were saddle points.	I-Review	I-5	Review	478
<sep> (b) Training algorithms did not converge, or have not converged yet.	I-Review	I-5	Review	478
<sep> (c) The calculation of the actual Hessian might be inaccurate.	I-Review	I-5	Review	478
Clearly, we can't say that the Hessian of the loss function is degenerate everywhere in this empirical study in which we don't attempt to check all the points in theoretical or empirical ways.	B-Reply	B-1	Reply	478
What we can say, however, is that the Hessian of the loss function is degenerate at the point where training begins and ends.	I-Reply	I-1	Reply	478
This is indeed the body of our work.	I-Reply	I-1	Reply	478
Moreover, we can presume the statement will be valid for the intermediate points over the course of the training, as well.	I-Reply	I-1	Reply	478
We clarified this further in the text.	I-Reply	I-1	Reply	478
<sep> <sep> 1) The actual one that is computed through the Hessian vector product using Lop: Barak A. Pearlmutter, ‚ÄúFast Exact Multiplication by the Hessian‚Äù, Neural Computation, 1994, -we added the reference in the text. (	B-Reply	B-2	Reply	478
Also the approximate Hessian gives similar results.)	I-Reply	I-2	Reply	478
<sep> <sep> 2) We use gradient descent (the batch method, when the minibatch size is equal to the number of examples in the dataset) in our main expeirments.	B-Reply	B-3	Reply	478
We revised the text to clarify this.	I-Reply	I-3	Reply	478
The only exception is the line interpolation that is presented in the conclusion which compares GD and SGD.	I-Reply	I-3	Reply	478
However, we would like to note that the network is *not* trained to its local minimum.	I-Reply	I-3	Reply	478
We train the network for a long time even after the training cost is stabilized.	I-Reply	I-3	Reply	478
Yet, the norm of the gradient is typically at the order of 10^{-3}. It is pretty laborious to get a network that uses a log-loss to a level where the norm of the gradient is at the order of say 10^{-10} or lower.	I-Reply	I-3	Reply	478
The basin that the point is in at the stopping time is, for all practical purposes, a local minimum (see ICLR 2015 Workshop, Explorations on high dimensional landscapes, Sagun et al).	I-Reply	I-3	Reply	478
<sep> <sep> 3) Thank you for the suggestion!	B-Reply	B-4	Reply	478
Preliminary results with the mean square error also gives singular Hessian, pretty much in line with the observations laid out in our work.	I-Reply	I-4	Reply	478
We added this new experiment in our work, as well.	I-Reply	I-4	Reply	478
<sep> <sep> 4) The short answer is (b).	B-Reply	B-5	Reply	478
We included this in the previous bullet point, and we attempted to clarify it further.	I-Reply	I-5	Reply	478
This point is actually one of the practical challenges in modern day deep learning.	I-Reply	I-5	Reply	478
Pretty much none of the current models *converge* in the sense that they find a local minimum, the models stop way before it finds one, and for all practical purposes the point that did *not* converge doesn't perform any worse when one keeps training the model until it finds a point where the norm of the gradient is zero within the numerical accuracy.	I-Reply	I-5	Reply	478
As references in the paper, there are reasons for GD to converge to a point where its Hessian has only non-negative eigenvalues.	I-Reply	I-5	Reply	478
From a practical point of view, reaching stability in this dynamics would take a long time.	I-Reply	I-5	Reply	478
In our work, we focus on the points we can find in practice, the ones whose grad_norm is relatively small, so that the gradient doesn't give any substantial signal for the gradient based model to move in the weight space.	I-Reply	I-5	Reply	478

Studying the Hessian in deep learning, the experiments in this paper suggest that the eigenvalue distribution is concentrated around zero and the non zero eigenvalues are related to the complexity of the input data.	O	O	Review	478
I find most of the discussions and experiments to be interesting and insightful.	O	O	Review	478
However, the current paper could be significantly improved.	O	O	Review	478
<sep> <sep> Quality:	O	O	Review	478
It seems that the arguments in the paper could be enhanced by more effort and more comprehensive experiments.	O	O	Review	478
Performing some of the experiments discussed in the conclusion could certainly help a lot.	O	O	Review	478
Some other suggestions:	O	O	Review	478
1- It would be very helpful to add other plots showing the distribution of eigenvalues for some other machine learning method for the purpose of comparison to deep learning.	B-Review	B-1	Review	478
<sep> 2- There are some issues about the scaling of the weights and it make sense to normalize the weights each time before calculating the Hessian otherwise the result might be misleading.	B-Review	B-2	Review	478
<sep> 3- It might worth trying to find a quantity that measures the singularity of Hessian because it is difficult to visually conclude something from the plots.	B-Review	B-3	Review	478
<sep> 4- Adding some plots for the Hessian during the optimization is definitely needed because we mostly care about the Hessian during the optimization not after the convergence.	B-Review	B-4	Review	478
<sep> <sep> Clarity:	O	O	Review	478
1- There is no reference to figures in the main text which makes it confusing for the reading to know the context for each figure.	B-Review	B-5	Review	478
For example, when looking at Figure 1, it is not clear that the Hessian is calculated at the beginning of optimization or after convergence.	I-Review	I-5	Review	478
<sep> 2- The texts in the figures are very small and hard to read.	B-Review	B-6	Review	478
Thank you for the comments and the review.	O	O	Reply	478
Quantification of singularity is crucial but it may be tricky and even misleading given the degenerate structure, therefore we thought it would be equally important to lay out the observations first, and then as a separate work consider the quantification.	B-Reply	B-3	Reply	478
<sep> <sep> We revised the paper in an attempt to address most of the issues mentioned above and in other comments.	O	O	Reply	478
<sep> <sep> Also, we will add a comparison with another ML method, very soon.	O	O	Reply	478

In this paper, the authors proposed to combine both NN-based NAS and Aging EVO to get the benefit of both world: good global and local sample efficiency.	O	O	Review	478
The main idea is to use Aging EVO algorithm to guide the overall search process, and a NN predicting the final performance is used to guide the mutation process.	O	O	Review	478
The combined EVO-NAS has showed consistent good performance over a range of tasks.	O	O	Review	478
<sep> <sep> Overall, while the novelty of the paper is not exceptional, since it is a rather straightforward combination of two existing approaches, the end-results is promising.	B-Review	B-1	Review	478
I would like to see more in-depth analysis on the combined algorithm to validate authors' hypothesis on why EVO-NAS works better.	I-Review	I-1	Review	478
More detailed comments can be found below.	O	O	Review	478
<sep> <sep> 1.	O	O	Review	478
The experiment on the synthetic task is not very helpful, since the domain can be far apart from the real NAS applications.	B-Review	B-2	Review	478
One evidence is that the NN significantly outperform EVO in this task but not in the other tasks.	I-Review	I-2	Review	478
<sep> <sep> 2.	B-Review	B-3	Review	478
In difficult tasks, the proposed EVO-NAS and the original Aging EVO are very close in the first few hundreds of trials, however, later the gap remains the same.	I-Review	I-3	Review	478
It would be interesting to see if we can eliminate the gap by adding the NN component in the middle of the Aging EVO experiment (e.g., at the point of 2000 trials).	I-Review	I-3	Review	478
<sep> <sep> 3.	B-Review	B-4	Review	478
I am also curious about the difference between the NN learned from Neural agent vs. those learned from EVO-NAS agent.	I-Review	I-4	Review	478
Moreover, do we need a NN for the EVO-NAS?	I-Review	I-4	Review	478
Or something simpler would be sufficient to guide the search.	I-Review	I-4	Review	478
Thank you for your comments and suggestions!	O	O	Reply	478
Please let us know if you have any more feedback about our work, since we would be happy to use it to make the paper better.	O	O	Reply	478
Below we specifically address each of the points that you made.	O	O	Reply	478
<sep> <sep> 1.	O	O	Reply	478
We agree that the synthetic task is far from real NAS applications.	B-Reply	B-2	Reply	478
In our paper we do focus on NAS, and the other lines of experiments (NAS-Bench, NLP datasets, ImageNet) are all real-life architecture search scenarios.	I-Reply	I-2	Reply	478
However, as we hint in the ‚ÄúConclusion‚Äù section, it is possible to apply Evo-NAS to tasks outside of architecture search.	I-Reply	I-2	Reply	478
Discrete optimization problems such as our toy task could be one example, and we see that Evo-NAS also performs very well in this domain.	I-Reply	I-2	Reply	478
We think that makes the approach even more promising in terms of inspiring future work.	I-Reply	I-2	Reply	478
<sep> <sep> 2.	O	O	Reply	478
As we understand the proposal, you would consider running the NN learning component not from the beginning of the experiment, but start learning later on.	B-Reply	B-3	Reply	478
This would save some computational cost; are we missing any other advantages of this approach?	I-Reply	I-3	Reply	478
Our initial intuition is that the savings might be limited due to low overhead of running the NN compared to the training of candidate architectures.	I-Reply	I-3	Reply	478
However, it would be interesting to experiment further in this direction in the future.	I-Reply	I-3	Reply	478
<sep> <sep> 3.	O	O	Reply	478
You made a good point that we could use something simpler than a Neural Network for the learning part of Evo-NAS.	B-Reply	B-4	Reply	478
Since we wanted our approach to be comparable to existing methods, we used a NN, since it‚Äôs somewhat standard in the NAS community.	I-Reply	I-4	Reply	478
Also, from a theoretical standpoint, a NN has a useful property of being a universal approximator.	I-Reply	I-4	Reply	478
On the other hand, it does seem likely that guiding the evolutionary search (i.e. producing a good prior over mutations) might be an easier problem than learning the structure of all solutions (i.e. producing a good prior over the entire search space).	I-Reply	I-4	Reply	478
<sep> <sep> Therefore, it‚Äôs certainly possible that using something simpler as the learning part of Evo-NAS would be sufficient to get good results.	I-Reply	I-4	Reply	478
However, again note that in terms of computational cost the NN part is negligible - so any gains would not be in terms of compute, but perhaps in enhanced explainability of the learning component.	I-Reply	I-4	Reply	478

This paper is well organized.	O	O	Review	478
The applied methods are introduced in detail.	O	O	Review	478
But it lacks some more detailed analysis.	O	O	Review	478
<sep> <sep> My concerns are as follows.	O	O	Review	478
<sep> 1.	O	O	Review	478
The performance differences between Evolutionary agent and EVO-NAS agent seem not significant.	B-Review	B-1	Review	478
Please conduct additional statistical tests such as the Wilcoxon signed-rank test to verify the performance improvements are significant.	I-Review	I-1	Review	478
<sep> 2.	O	O	Review	478
Many studies have been conducted to automatically adjust control parameters such as crossover and mutation probabilities in evolutionary algorithm literature.	B-Review	B-2	Review	478
It would be better to compare one of these approaches in the experiments.	I-Review	I-2	Review	478
Thank you for your review!	O	O	Reply	478
We address each of your concerns below.	O	O	Reply	478
Please let us know if you have some further comments - we are happy to make changes to the paper to improve it.	O	O	Reply	478
<sep> <sep> 1.	B-Reply	B-1	Reply	478
While the gains are not enormous, we agree with Reviewer #2 in saying that they are consistent across a range of different tasks: both in real-life AS scenarios (NAS-Bench, NLP, ImageNet), and in the synthetic task.	I-Reply	I-1	Reply	478
However, making sure that differences between results are statistically significant is certainly an important point.	I-Reply	I-1	Reply	478
<sep> <sep> For example, note that for NLP (Table 1), we ran 10 runs for each (approach, dataset) pair.	I-Reply	I-1	Reply	478
We claim that Evo-NAS matches the better of the baselines in all cases, and in 3 out of 7 it outperforms the best baseline with statistical significance.	I-Reply	I-1	Reply	478
We made this claim for the three datasets where the difference exceeded twice the standard-error-of-the-mean.	I-Reply	I-1	Reply	478
This can also be easily translated into p-values: for example, for the ConsumerComplaints dataset, the p-value for Evo-NAS‚Äôs gains over either baseline being statistically significant is &lt; 0.02 (so we reject the null hypothesis that there is no gain).	I-Reply	I-1	Reply	478
<sep> <sep> We used simple statistical measures such as the ones described above to assess significance.	I-Reply	I-1	Reply	478
However, we are open to performing additional nonparametric tests, such as the Wilcoxon Signed-Rank Test you proposed.	I-Reply	I-1	Reply	478
Please let us know what would be the exact test that you had in mind (i.e. what would be the null hypothesis).	I-Reply	I-1	Reply	478
For example, we could consider pairs of (average result of Evolution, average result of Evo-NAS) over all benchmarks considered in the paper (there are 10 in total since we should count each NLP dataset separately), and perform the test on these pairs.	I-Reply	I-1	Reply	478
In that case, the Signed-Rank test does show significance, as in all cases the mean result of Evo-NAS is strictly better than the mean result of Evolution.	I-Reply	I-1	Reply	478
<sep> <sep> 2.	O	O	Reply	478
You are right in saying that there are many smart evolutionary algorithms out there.	B-Reply	B-2	Reply	478
However, to our knowledge, the NAS domain is dominated by ‚Äúnon-adaptive‚Äù evolution (i.e. with uniform prior over mutations), which also seems to perform very well across different AS domains.	I-Reply	I-2	Reply	478
Since here we focus on architecture search, we compare our method to two strong, common and most recent baselines (the combination of which gives Evo-NAS).	I-Reply	I-2	Reply	478
<sep> <sep> Note that our hybrid may not necessarily be the best algorithm of this kind; our intention was to show that combining these two worlds (learning-based and evolution-based) in a relatively simple way we can get consistent gains across multiple domains.	I-Reply	I-2	Reply	478
<sep> <sep> One kind of follow-up works that we wish to inspire is exactly what you are proposing: bringing different ‚Äúsmart‚Äù genetic algorithms from the evolution community to the NAS community, and investigating their behavior on architecture search.	I-Reply	I-2	Reply	478
It is surely an exciting direction, although one that is not the focus of our current work.	I-Reply	I-2	Reply	478

It is a nice paper that combines the deep reinforcement learning and evolutionary learning techniques to neural architecture search problem.	O	O	Review	478
Experimental results are promising.	O	O	Review	478
However, I still have some concerns on the current submission.	O	O	Review	478
<sep> 1.In Fig 1,2 &amp;3, it seems that the performances of Neural (PQT) keeps increasing.	B-Review	B-1	Review	478
For better compassion, we recommend the authors reports the performances of compared algorithms until they are convergent.	I-Review	I-1	Review	478
<sep> 2.The different training algorithms (Reinforce and PQT) have difference performances whether because different training algorithms converge to difference local minima or stationary points.	B-Review	B-2	Review	478
<sep> <sep> Thank you for you comments!	O	O	Reply	478
Below we specifically address both of the points that you raised.	O	O	Reply	478
Let us know if you have any more concerns - we are happy to make improvements to the paper.	O	O	Reply	478
<sep> <sep> 1.	O	O	Reply	478
To make the assessment that the methods have converged, we looked at the best reward attained (right plots), not reward running average (left plots).	B-Reply	B-1	Reply	478
By ‚Äúreward running average‚Äù, we mean sliding a constant size window over the reward, and computing the average reward in each such window.	I-Reply	I-1	Reply	478
This measure is not a good metric to compare the algorithms, and we use it just to show how much the reward varies from sample to sample for different methods.	I-Reply	I-1	Reply	478
<sep> <sep> Note that learning-based methods (like Neural PQT which you mentioned) do see small improvements in running average reward even long after they stop exploring new parts of the search space - this is simply because they keep making their distributions over actions ‚Äúsharper‚Äù.	I-Reply	I-1	Reply	478
Therefore, it is more informative to look at best reward attained over time.	I-Reply	I-1	Reply	478
<sep> <sep> With that in mind, we review below the experiments that you pointed to - that is, Figures 2 and 3.	I-Reply	I-1	Reply	478
You also mentioned Figure 1, which does not correspond to any experiment, so we assumed this to be a typo - but let us know if you meant something else there, and we can discuss further.	I-Reply	I-1	Reply	478
<sep> <sep> - For NAS-Bench (Figure 3), the methods see only marginal improvements at the end of the experiment.	I-Reply	I-1	Reply	478
<sep> <sep> - For the synthetic task (Figure 2), all methods see small improvements of the reward if ran longer, but the overall pattern remains the same (Evo-NAS (PQT) attaining the best results, matched by Neural (PQT) from around 4500 trials onward).	I-Reply	I-1	Reply	478
<sep> <sep> 2.	B-Reply	B-2	Reply	478
Our understanding is that PQT provides a stronger training signal than Reinforce.	I-Reply	I-2	Reply	478
This comes at a cost, since Reinforce is known to be unbiased, and therefore it produces gradients that (in expectation) match the gradient of the expected reward.	I-Reply	I-2	Reply	478
On the other hand, PQT is a heuristic, and it gives no theoretical guarantees.	I-Reply	I-2	Reply	478
<sep> <sep> We wouldn‚Äôt say that PQT is always better than Reinforce - this is likely very domain dependent.	I-Reply	I-2	Reply	478
Our focus is architecture search, where the number of trials is typically low given the complexity of the search spaces.	I-Reply	I-2	Reply	478
In this domain, as seen in our experiments, trading off theoretical guarantees and lack of bias for a stronger and more greedy training signal leads to better results.	I-Reply	I-2	Reply	478
<sep> <sep> Nevertheless, comparing PQT to classical RL algorithms (like Reinforce, but also many others) is a very interesting research direction.	I-Reply	I-2	Reply	478
Since our main goal was hybridizing RL-based and Evolution-based approaches to architecture search, we did not explore this direction in our work.	I-Reply	I-2	Reply	478

The authors present an empirical study to evaluate the performance of CNN-based object classifiers for situations in which the object of interest is very small relative to the size of the image.	O	O	Review	209
Two artificial datasets, based on MNIST and histopathological images are introduced to conduct the experiments.	O	O	Review	209
Through empirical evaluation the authors conclude that the size of the dataset required for generalization increases rapidly with the inverse of the O2I ratio, that higher capacity models generalize better, and that accounting for the model's receptive field is key.	O	O	Review	209
<sep> <sep> The contributions of the study are limited: i) The artificial datasets generate images that are small and O2Is that are big for the applications of interest, e.g., gigapixels images in digital pathology (see Figure 1).	B-Review	B-1	Review	209
ii) The dataset based on MNIST is perhaps too artificial (too structured), once one compares their results relative to nCAMELYON.	B-Review	B-2	Review	209
iii) The authors only consider ResNet-50.	B-Review	B-3	Review	209
iv) The authors do not consider multi-instance learning pooling functions, e.g., noisy or, noisy and or attention.	B-Review	B-4	Review	209
v) The authors do not consider performance as a function of the positive instances in the image (number occurrences of 3 in the proposed nMNIST).	B-Review	B-5	Review	209
vi) There is no methodological contribution.	B-Review	B-6	Review	209
Thanks for taking the time to review our paper.	O	O	Reply	209
We respectfully disagree with the reviewer's assessment of the paper since it doesn't do justice to paper's contributions.	O	O	Reply	209
In the rebuttal, we show that not all mentioned limitations are valid concerns.	O	O	Reply	209
However, before addressing the individual concerns we would like to revisit the main points of the paper and highlight our contributions: (1) We identified an unexplored machine learning problem of image classification in low and very low signal-to-noise ratios; this problem has not been discussed in the past and the community seems unaware of it; we feel this as an important contribution as proposing a new method or theory; (2) We carefully designed two image datasets with controlled signal-to-noise ratios and highlighted that CNNs struggle to show good generalization for low and very low signal-to-noise ratios even for a relatively elementary MNIST-based dataset; (3) we ran an extensive series of controlled experiments that explore both a variety of CNNs' architectural choices and the importance of training data scale for the low and very low signal-to-noise classification.	B-Reply	B-5	Reply	209
To the best of our knowledge this is the first, large scale empirical demonstration of optimization and generalization problems of CNNs with very low signal-to-noise classification scenarios.	I-Reply	I-5	Reply	209
Moreover, by opensourcing our testbed framework, we invite the community to contribute to low and very low signal-to-noise classification scenarios either by incorporating new models or by proposing new datasets.	I-Reply	I-5	Reply	209
<sep> <sep> Below, we address the reviewer‚Äôs concerns.	O	O	Reply	209
<sep> i) We use Figure 1 as a motivational example to illustrate the need for an in depth study of low signal-to-noise classification scenarios.	B-Reply	B-1	Reply	209
We run our study on the range of O2I ratios that varies from 0.075% (7e-4) and 19.14% (2e-1), thus, we cover the whole range of MiniMIAS dataset and a significant portion of CAMELYON17 dataset.	I-Reply	I-1	Reply	209
Since we already observed interesting trends as well as optimization and generalization difficulties in the lower spectrum of the tested range, we did not include the O2I range of [10e-6, 7e-4] as it will show similar results to 0.075%.	I-Reply	I-1	Reply	209
Moreover, the scope of the study is to explore the optimization and the generalization properties of CNN as a function of signal-to-noise ratio and not image resolution.	I-Reply	I-1	Reply	209
Nevertheless, our testbed can easily be extended to more challenging O2I ratios and image resolutions.	I-Reply	I-1	Reply	209
<sep> <sep> ii) We would argue that there is a value in showing current methods‚Äô limitations in a simple, large scale dataset such as nMNIST.	B-Reply	B-2	Reply	209
In a series of controlled experiments, we show that even such elementary dataset is very challenging for current CNN architectures.	I-Reply	I-2	Reply	209
<sep> <sep> iii) We explore 48 different variants of ResNets (3 receptive field sizes, 4 different pooling operations and 4 different model capacities - please refer to section B in the supplementary material for the details about the tested model architectures).	B-Reply	B-3	Reply	209
We decided to use ResNet-like backbones due to its versatility in a variety of computer vision tasks.	I-Reply	I-3	Reply	209
These networks have shown very good results in tasks such as image classification and were proven to be very effective backbones in tasks such as object detection and image segmentation.	I-Reply	I-3	Reply	209
<sep> <sep> iv) We refer the reviewer to our experiments using soft attention based pooling that is based on multi-instance learning formulation from Ilse et al 2018.	B-Reply	B-4	Reply	209
For details about pooling operations considered in our study, please see section B1 of the supplementary material.	I-Reply	I-4	Reply	209
<sep> <sep> v) While the question of detection multiple ‚Äò3‚Äôs in a single image is an interesting one, the nMNIST dataset was designed to highlight the limitations of current CNN in a clean and straightforward way‚Äî we wanted to showcase an elementary scenario in which current CNN encounter generalization problems when faced with low and very low signal-to-noise scenarios.	B-Reply	B-5	Reply	209
<sep> <sep> vi) We respectfully disagree.	B-Reply	B-6	Reply	209
The paper makes an important contribution by revealing a substantial limitation of current methods, and provides methodology (a testbed) to empirically study this limitation.	I-Reply	I-6	Reply	209

This paper presents a testbed framework to investigate the limitations of CNN at the classification of tiny objects and the effects of signal to noise ratio has in the task.	O	O	Review	209
The implemented framework will be made available online upon acceptance.	O	O	Review	209
<sep> <sep> I believe that the question the authors try to answer is very interesting and worth of exploration.	B-Review	B-1	Review	209
However, I am a bit less excited about the achieved results since I consider them not to be sufficient to drive conclusions.	I-Review	I-1	Review	209
The experiments proposed by the authors are run on two different datasets created ad-hoc: the nMNIST and the nCAMELYON, both modifications of MNIST and CAMELYON datasets.	I-Review	I-1	Review	209
Over all the experiments run, the behaviors observed on the two datasets are not the same.	I-Review	I-1	Review	209
The explanation provided by the authors is that since nCAMELYON is very small, results are different from the ones of nMNIST.	I-Review	I-1	Review	209
While I consider this a valid explanation, this still limits the overall conclusions of this paper.	I-Review	I-1	Review	209
Therefore, my main recommendation to the authors would be to identify other datasets for their experiment.	I-Review	I-1	Review	209
<sep> <sep> In the dicussion section, the authors argue that MS COCO is not a good candidate since the background usually contains information that allows to infer the label.	B-Review	B-2	Review	209
I wonder if it would be possible to generate a new dataset, starting from MS COCO, that avoids this problem.	I-Review	I-2	Review	209
Using the example of the paper, I would argue that it is possible to obtain images of outdoors with people where there are no balls.	I-Review	I-2	Review	209
Having such a dataset would make your paper much stronger.	I-Review	I-2	Review	209
<sep> <sep> Finally, to some extent, I consider that your problem is strongly linked to anomaly/detection detection.	B-Review	B-3	Review	209
In the end, this is what a needle in a haystack is.	I-Review	I-3	Review	209
How do you position yourselves with respect to the state of the art on this topic?	I-Review	I-3	Review	209
Many thanks for the insightful comments and highlighting the interest in the problem that we aim to address.	O	O	Reply	209
Below we address the concerns of the reviewer:	O	O	Reply	209
<sep> [inconclusive observations on two used datasets]	O	O	Reply	209
This is indeed an important observation that motivates the need for low and very low signal-to-noise classification scenarios testbed and indicates that further research is required.	B-Reply	B-1	Reply	209
We do not see this as a limitation of our paper, but rather an important aspect of the study.	I-Reply	I-1	Reply	209
In this paper, we designed a testbed by including two dataset to showcase the limitation of current CNNs when working with low O2I ratios: 1) nMNIST dataset is an elementary, large scale dataset that highlights that even in relatively simple scenarios current CNNs fail to generalize well when faced with low signal-to-noise images; 2) nCAMELYON highlights how current methods behave when faced with probably the largest (although still small in machine learning terms), publicly available needle-in-a-haystack dataset.	I-Reply	I-1	Reply	209
Finally, we would like to point out, that by opensourcing our testbed framework (that includes data preparation, model architectures and training scripts) we invite the community to contribute new challenging low and very low signal-to-noise classification datasets.	I-Reply	I-1	Reply	209
<sep> <sep> [additional datasets]	O	O	Reply	209
As mentioned in the discussion section, we initially considered other datasets to be a part of our study (including MS-COCO).	B-Reply	B-2	Reply	209
However, what the reviewer suggests is not straightforward at all, since the dataset does not contain an outdoor class it wouldn't be possible to automatically get a subset of images that contain people in outdoor without the ball (it would require additional human labeling).	I-Reply	I-2	Reply	209
One possibility to overcome this issue might be to use another class label as an indication of outdoor class, for example, one could create the dataset for ball vs. no ball classification using a context of people and baseball bat.	I-Reply	I-2	Reply	209
However, the size of such dataset would still be small (similarly to CAMELYON dataset).	I-Reply	I-2	Reply	209
Nevertheless, we adapted the discussion section to suggest such an experiment as a future work.	I-Reply	I-2	Reply	209
<sep> <sep> [connections to outlier detection]	O	O	Reply	209
The low and very low signal-to-noise classification setup could potentially be framed as anomaly detection, e. g. one could use images without the object of interest to fit ‚Äúnormality‚Äù model and, then, use this model to detect regions with anomalies in an image.	B-Reply	B-3	Reply	209
In this setup, one would expect that the anomaly would coincide with the object of interest (needle in a haystack).	I-Reply	I-3	Reply	209
However, if approaching this problem in an ‚Äúunsupervised‚Äù way there is no guarantee that the anomaly would coincide with the object of interest.	I-Reply	I-3	Reply	209
One way to overcome this issue is by incorporating the information about image-level labels (e. g. by merging outlier detection with classification).	I-Reply	I-3	Reply	209
We would argue that when having access to image labels it is more natural to deal with this problem as low and very low signal-to-noise classification.	I-Reply	I-3	Reply	209
Nevertheless, the idea of using anomaly based model inductive biases in CNNs is interesting and we leave it for future work.	I-Reply	I-3	Reply	209

The submission proposes an analysis of the impact of object size in images when performing classification tasks using neural networks of the BagNet family.	O	O	Review	209
The analysis is performed on two datasets, a large resolution cluttered MNIST and a histopathology dataset named nCAMELYON.	O	O	Review	209
<sep> <sep> The paper attack interesting questions and links the size of the object in the image (O2I) to the training dataset size required.	O	O	Review	209
Also, showing that max-pooling is the only pooling operation that converges for very low O2I (but is the slowest to converge at higher O2I) is interesting and encourages discussion about the training (optimization) process.	O	O	Review	209
<sep> <sep> In my opinion, the main issue about the submission is the limited depth in the contributions, analyzing a single family of network architectures (BagNets) over two datasets, one of which is relatively small.	B-Review	B-1	Review	209
The family of R-CNN and its derivatives were especially designed to counter the impact of object size, it would have been interesting to include them in the analysis.	B-Review	B-5	Review	209
Furthermore, limited insights can be carried out for tasks related to classification such as localization and segmentation.	I-Review	I-5	Review	209
Models such as Single Shot Detectors split the image into grids and variable anchor sizes to perform their inference, are they affected to a lesser extent by object size?	I-Review	I-5	Review	209
The limited insights provided to potential future readers prevents me from recommending the submission for acceptance.	I-Review	I-5	Review	209
<sep> <sep> On p. 7 (and fig.7 (b) ), it is said that the lower performance of the larger receptive field suggests that class-relevant information is contained in the texture.	B-Review	B-2	Review	209
I am not sure about this remark, I would have expected the network to learn to focus on the right regions, provided the receptive field is big enough to see the whole object of interest.	I-Review	I-2	Review	209
Could the decrease in performance be attributed to the increased amount of learnable parameters that ended up too large for the ‚Äúrelatively small nCAMELYON dataset used for training‚Äù? (	I-Review	I-2	Review	209
sec.	I-Review	I-2	Review	209
3.1, Global pooling operations)	I-Review	I-2	Review	209
<sep> Fig.16 seems to suggest that multiple numbers can overlap significantly in nMNIST, yielding potentially confusing images even for humans.	B-Review	B-3	Review	209
I am not sure if this is a desirable characteristic for such dataset.	I-Review	I-3	Review	209
<sep> <sep> <sep> Minor details	B-Review	B-4	Review	209
- Please use \cdot instead of the asterisk operator to denote multiplication (sec.	I-Review	I-4	Review	209
3, footnote 3, fig.3.1;	I-Review	I-4	Review	209
5 (b-c) and sec.	I-Review	I-4	Review	209
- Fig.4 uses two different (and non-linear) values for the x-axes, giving the impression that both curves can be compared, that might be confusing to the reader;	I-Review	I-4	Review	209
- Sec 1 and 5 ‚Äúpixel-level level annotations‚Äù: duplicate ‚Äúlevel‚Äù;	I-Review	I-4	Review	209
- p. 6 ‚Äú1 and , 2‚Äù: extraneous comma.	I-Review	I-4	Review	209
<sep> <sep> Many thanks for dedicating time to review our paper.	O	O	Reply	209
We feel the reviewer is missing some important points of our study, which we would like to clarify below:	O	O	Reply	209
<sep> [Depth of the contribution]	O	O	Reply	209
We argue that the depth of our contribution is significant: the paper makes an important contribution by revealing a substantial limitation of current methods, and provides methodology (a testbed) to empirically study this limitation on two datasets.	B-Reply	B-1	Reply	209
We would strongly argue that these contributions can help to advance the field, and should be considered as important as proposing a new method or theory.	I-Reply	I-1	Reply	209
Moreover, the breadth of our analysis is substantial as for each dataset, we explored 48 different variants of ResNets (3 receptive field sizes, 4 different pooling operations and 4 different model capacities - please refer to section B in the supplementary material for the details about the tested model architectures).	I-Reply	I-1	Reply	209
To ensure the robustness of our conclusions we ran more than 750 different hyperparamenter setups (each one run with 6 different random seeds).	I-Reply	I-1	Reply	209
This is not a trivial empirical study, and the insights we can gain from it should be of interest to many in the community.	I-Reply	I-1	Reply	209
<sep> <sep> [Suitability of object detection architectures e. g. R-CNN]	O	O	Reply	209
R-CNN or SSD like architectures were built to tackle object detection problems, whereas we are interested in image classification problem.	B-Reply	B-5	Reply	209
In object detection, one would require access to localized labels such as pixel level annotations in the form of bounding box information.	I-Reply	I-5	Reply	209
Such annotations are not available in many important real-world applications, and hence R-CNN type methods are not applicable.	I-Reply	I-5	Reply	209
Moreover, if bounding box annotations were available one could easily translate the low signal-to-noise classification problem into an imbalanced classification problem (with small number of positive classes and large number of negative classes) ‚Äî as it is done in object detection approaches.	I-Reply	I-5	Reply	209
Therefore, we argue that the problem we are studying in this paper is very different, but equally relevant, from the object detection setup and has different challenges which make object detection pipelines not applicable to our setup.	I-Reply	I-5	Reply	209
<sep> <sep> [fig.7 (b)]	O	O	Reply	209
When designing our experiments we ensured fixed model capacity by increasing the number of filters for the networks with lower receptive fields (see Table 3 in the appendix).	B-Reply	B-2	Reply	209
Therefore, all models have similar capacity (unless specifically stated).	I-Reply	I-2	Reply	209
We agree with the reviewer, that when having access to large dataset one should observe good results for all receptive field sizes that are bigger than the size of an object of interest (as confirmed by our results on nMNIST).	I-Reply	I-2	Reply	209
However, when dataset is relatively small (such as nCAMELYON), we observe that the small receptive field tends to generalize better.	I-Reply	I-2	Reply	209
We attribute this to the fact that within a larger receptive field there are more spurious correlations (more random patterns might look like a class-discriminative ones), as a result the model with larger receptive field overfits.	I-Reply	I-2	Reply	209
We clarified this in the manuscript.	I-Reply	I-2	Reply	209
<sep> <sep> [Digits overlap]	O	O	Reply	209
Although restricting the digits‚Äô overlap might clarify the classification problem for humans, we argue that it is not affecting the generalization of CNNs in large O2I scenarios and as a result the digits‚Äô overlap is not affecting our conclusions.	B-Reply	B-3	Reply	209
For example, we can observe that the tested models for an O2I ratios of 20% reach very good results (90%+ of test set accuracy) - suggesting that the digits‚Äô overlap does not impede good model generalization.	I-Reply	I-3	Reply	209
Moreover, our qualitative results (shown in supplementary material) show that CNNs correctly classify images with overlapping digits (see Figures 16a, 16d, 16e, 16h, 16i, 16l, 16n) while making mistakes in images without any overlap (see Figure 16c).	I-Reply	I-3	Reply	209
Thus, the change of O2I seem to affect the generalization way stronger than the digits‚Äô overlap.	I-Reply	I-3	Reply	209
<sep> <sep> [Minor details]	O	O	Reply	209
Thank you for spotting the typos.	B-Reply	B-4	Reply	209
We fixed those in the manuscript.	I-Reply	I-4	Reply	209

This paper considers the problem of how to improve the performance of an existing DP classifier, with the help of the labelled public data.	O	O	Review	20520
The paper considers the following process: 1.	O	O	Review	20520
find a public dataset containing relevant samples; 2.	O	O	Review	20520
carefully select a subset of public samples that can improve the performance of the classifier; 3 fine-tune the existing classifier on the selected samples.	O	O	Review	20520
Two different techniques from active learning are utilized in order to select representative samples from a public dataset and fine-tune a DP classifier.	O	O	Review	20520
This paper also conducts some experiments on   the MNIST and SVHN datasets and demonstrates improvement compared with the benchmark.	O	O	Review	20520
<sep> <sep> I vote for rejecting for this paper, because of the following two concerns:	O	O	Review	20520
<sep> 1.	O	O	Review	20520
I do not think this paper has made a lot of contribution to either differential privacy or active learning.	B-Review	B-1	Review	20520
It just "borrows" some fine-tuning techniques from active learning and apply it in DP.	I-Review	I-1	Review	20520
There is almost no theoretical contribution made by this paper.	B-Review	B-2	Review	20520
Besides, from the experimental perspective, neither can I see an obvious improvement compared with the benchmarks.	B-Review	B-3	Review	20520
<sep> <sep> 2.	B-Review	B-4	Review	20520
I do not think the privacy analysis of the NearPrivate algorithm (Algorithm 2) is correct.	I-Review	I-4	Review	20520
The paper uses private argmax algorithm and claims that it satisfies-DP.	I-Review	I-4	Review	20520
However, this is only true when.	I-Review	I-4	Review	20520
Generally, it should satisfy-DP.	I-Review	I-4	Review	20520
So if we look at the experimental setting of MNIST, roughly thousand times less noise is added!	I-Review	I-4	Review	20520
Since this amount of noise is non-trivial at all, I can not judge the effectiveness of the algorithm.	I-Review	I-4	Review	20520
<sep> ------------------------------------------------------------------------------------------	O	O	Review	20520
Thanks for the authors' classification.	O	O	Review	20520
I missed the part that each private sample was only assigned to one public sample.	O	O	Review	20520
Now I can confirm the correctness of the algorithm and increase my score accordingly.	O	O	Review	20520
Thanks for updating your review regarding the bounds.	O	O	Reply	20520
<sep> For posterity, we respond to your other points:	O	O	Reply	20520
<sep> &gt; I do not think this paper has made a lot of contribution to either differential privacy or active learning.	O	O	Reply	20520
<sep> Yes, we are not claiming to have made such contributions.	B-Reply	B-1	Reply	20520
<sep> What we claim is having presented a way to substantially reduce the gap between differentially private classifiers and normal classifiers:	I-Reply	I-1	Reply	20520
<sep> If you want to actually use differentially private classifiers in real life, you will be sad,	I-Reply	I-1	Reply	20520
because the accuracy will be poor.	I-Reply	I-1	Reply	20520
<sep> We point out that you can improve accuracy substantially by fine-tuning on public data after the fact.	I-Reply	I-1	Reply	20520
<sep> This is already something that was not in the literature.	I-Reply	I-1	Reply	20520
<sep> I don't think you can credibly claim that it's 'obvious' that fine-tuning on a totally different data-set	I-Reply	I-1	Reply	20520
after the fact will improve performance on your test set;	I-Reply	I-1	Reply	20520
this is not what anyone uses fine-tuning for currently.	I-Reply	I-1	Reply	20520
<sep> We also give two algorithms for doing this fine-tuning (both of which are new, by the way), and we give	I-Reply	I-1	Reply	20520
a privacy analysis for the algorithm that needs it.	I-Reply	I-1	Reply	20520
<sep> <sep> &gt; There is almost no theoretical contribution made by this paper.	O	O	Reply	20520
<sep> Yes, this is not a theory paper.	B-Reply	B-2	Reply	20520
<sep> This is not a theory conference either.	I-Reply	I-2	Reply	20520
<sep> <sep> &gt; Besides, from the experimental perspective, neither can I see an obvious improvement compared with the benchmarks.	O	O	Reply	20520
<sep> We increase the state-of-the-art for differentially private MNIST from 97.5% to 98.8%.	B-Reply	B-3	Reply	20520
<sep> Experimentally, that's a significant jump - it's more than a halving in error-rate.	I-Reply	I-3	Reply	20520
<sep> The improvement in SVHN is even more significant.	I-Reply	I-3	Reply	20520
<sep> Perhaps some of the confusion here is around benchmarks:	I-Reply	I-3	Reply	20520
Most of the benchmarks in the paper are in fact *benchmarks that we have set in this paper*.	I-Reply	I-3	Reply	20520
We claim that a paper that only pointed out how helpful fine-tuning can be for DP classifiers	I-Reply	I-3	Reply	20520
would, by itself, be worth publishing; we have written such a paper, and then added even more things.	I-Reply	I-3	Reply	20520

---SUMMARY---	O	O	Review	20520
This paper gives two methods for improving an existing differentially private model.	O	O	Review	20520
Both methods assume a source of unlabeled data that requires no privacy guarantees.	O	O	Review	20520
The two methods make different uses of this public data to augment the original private model.	O	O	Review	20520
Both preserve (a degree of) privacy for the original model.	O	O	Review	20520
<sep> <sep> The first method is DiversePublic.	O	O	Review	20520
DiversePublic only post-processes the original private model M -- in particular, it does not touch the original data -- and so its privacy is immediate.	O	O	Review	20520
At a high level, DiversePublic works by picking the "best" unlabelled data points for augmenting M. First, it applies M to the unlabeled data and then applies PCA to the result.	O	O	Review	20520
Next, it selects highly "uncertain" points, projects them onto the top k principal components, and clusters the results.	O	O	Review	20520
Finally, it selects samples from each cluster and uses them to augment M. This augmenting process, called FineTune, is left as a black box.	O	O	Review	20520
<sep> <sep> The second method is NearPrivate.	O	O	Review	20520
The given motivation for NearPrivate is that the public dataset may have a different distribution than the original private training data.	O	O	Review	20520
To address this, NearPrivate uses DP-PCA (a pre-existing technique for differentially private PCA) on the private dataset and projects both the private and public data onto the top k principal components.	O	O	Review	20520
Then it compares uncertain points in the public and private dataset projections and only augments M (again using the black box FineTune) using uncertain public examples with many nearby uncertain private samples.	O	O	Review	20520
Intuitively, this should select for points that are not too different than the original private training data.	O	O	Review	20520
<sep> <sep> The paper then evaluates these algorithms with experiments on MNIST and SVHN under reasonable privacy parameters (I think -- see below).	O	O	Review	20520
These experiments compare the performance of DiversePublic and NearPrivate, where both train M using vanilla DP-SGD [Abadi et al 2016]. DiversePublic and NearPrivate trade performances on MNIST and SVHN, but NearPrivate does (as might be expected) better when the public dataset is polluted.	O	O	Review	20520
<sep> <sep> In summary, the paper suggests DiversePublic and NearPrivate as useful ways to augment a given differentially private model M using public data, and their experiments suggest this is reasonable.	O	O	Review	20520
<sep> <sep> ---DECISION---	O	O	Review	20520
Reject.	O	O	Review	20520
<sep> <sep> This is an empirical paper.	O	O	Review	20520
It proposes some algorithms and justifies these algorithms through experiments.	O	O	Review	20520
However, the paper makes a confusing omission: it does not mention PATE [1, 2].	B-Review	B-1	Review	20520
<sep> [1] "Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data".	I-Review	I-1	Review	20520
Papernot et al 2017.	I-Review	I-1	Review	20520
<sep> [2] "Scalable Learning with PATE".	I-Review	I-1	Review	20520
Papernot et al 2018.	I-Review	I-1	Review	20520
<sep> <sep> I am more of a pure differential privacy researcher and am therefore less familiar with this line of mostly empirical work.	B-Review	B-2	Review	20520
But as far as I can tell PATE works in the same setting as that of this paper: there is a private dataset, a public unlabelled dataset, and the goal is to train a model with a differential privacy guarantee for the private dataset.	I-Review	I-2	Review	20520
As a result, PATE seems directly relevant.	I-Review	I-2	Review	20520
In particular, the claim that "there are no published examples of a differentially private SVHN classifier with both reasonable accuracy and non-trivial privacy guarantees" seems wrong, as the PATE papers include just that.	I-Review	I-2	Review	20520
<sep> <sep> Moreover, PATE appears at least competitive with the algorithms here.	B-Review	B-3	Review	20520
For example, the comparison given as Table 1 in [2] suggests that PATE can get 98-99% accuracy on MNIST for privacy parameters at least as low as those used here with only a few hundred new labelings.	I-Review	I-3	Review	20520
In contrast, if I understand the experiments here, they are using thousands of new labelled examples to get the same accuracy and privacy.	I-Review	I-3	Review	20520
Similarly, on SVHN the experiments here get to 84% accuracy with 10,000 new labelled examples, whereas the same Table 1 puts PATE at 90% with almost identical privacy parameters and thousands fewer new labelled examples.	I-Review	I-3	Review	20520
<sep> <sep> That comparison is my main concern.	B-Review	B-4	Review	20520
Perhaps I am missing a reason why PATE is not comparable.	I-Review	I-4	Review	20520
If it is, it should certainly appear in the experiments.	I-Review	I-4	Review	20520
If PATE is indeed comparable, then the main improvement contributed by this paper is the post-processing aspect: PATE is a way to train a private model from scratch, but these methods work on an existing model.	I-Review	I-4	Review	20520
Even then, the question of how exactly the existing model is modified (the FineTune method) is unclear.	I-Review	I-4	Review	20520
<sep> <sep> More broadly, there are several parts of this paper that could be much clearer.	B-Review	B-5	Review	20520
I am sympathetic to paper length limitations, but I am certain many or all of these issues can be addressed in 8 pages.	I-Review	I-5	Review	20520
<sep> <sep> 1.	O	O	Review	20520
DiversePublic description: What does it mean to "obtain the 'embeddings'...E_{public}"?	B-Review	B-6	Review	20520
How is k picked?	I-Review	I-6	Review	20520
<sep> 2.	O	O	Review	20520
How does the private point-public point assignment in NearPrivate work?	B-Review	B-7	Review	20520
Is it just random?	I-Review	I-7	Review	20520
How many points do we pick?	I-Review	I-7	Review	20520
<sep> 3.	B-Review	B-8	Review	20520
In general, how is FineTune meant to work?	I-Review	I-8	Review	20520
I understand it is meant to be an abstract black box in the algorithm descriptions, but the experiment description doesn't explain it either.	I-Review	I-8	Review	20520
How does FineTune work in the experiments?	I-Review	I-8	Review	20520
<sep> 4.	O	O	Review	20520
What does 'headroom' mean in Section 4.2?	B-Review	B-9	Review	20520
<sep> 5.	O	O	Review	20520
The way privacy parameters are specified at various points in the experiment section makes things hard to read.	B-Review	B-10	Review	20520
A concise table summarizing privacy parameters, accuracy, and additional labels would help.	I-Review	I-10	Review	20520
<sep> <sep> But overall, I am most interested in the PATE comparison.	O	O	Review	20520
<sep> <sep> ---EDIT AFTER AUTHOR RESPONSE---	O	O	Review	20520
I missed the data-dependent aspect of PATE's privacy guarantee.	O	O	Review	20520
That is a point in favor of this paper.	O	O	Review	20520
As such, I've increased my score from reject to weak reject.	O	O	Review	20520
<sep> <sep> I actually think a revised version of this paper could reasonably appear in ICLR or similar venues.	O	O	Review	20520
However, I think the necessary revisions are too large/numerous to accept the paper in its current form, even with promises of revisions.	O	O	Review	20520
Here are a few revisions that I think would make the paper a much better submission to future conferences:	O	O	Review	20520
<sep> 1.	O	O	Review	20520
Add discussion of PATE.	B-Review	B-11	Review	20520
The data-dependence of their privacy guarantees is well-taken.	I-Review	I-11	Review	20520
But it is not clear that data-dependent privacy guarantees are as "trivial" as the paper currently claims with "there are no published examples of a differentially private SVHN classifier with both reasonable accuracy and non-trivial privacy guarantees" suggests. (	I-Review	I-11	Review	20520
In fact, I find it confusing that one of the PATE authors agrees with this claim -- they think their own work is trivial?).	I-Review	I-11	Review	20520
I agree that data-independent privacy guarantees are preferable, but this should certainly be discussed.	I-Review	I-11	Review	20520
As the authors themselves note, the original PATE paper was well-received, so if this paper wants to claim its privacy guarantees are somehow meaningless or even just unsatisfactory, that claim needs to be defended.	I-Review	I-11	Review	20520
<sep> <sep> 2.	O	O	Review	20520
Elaborate on the fine-tuning process.	B-Review	B-8	Review	20520
Perhaps "fine tuning" is indeed "super standard in the object recognition literature", but as all three reviews here indicate, the presentation of fine tuning is unclear in this paper.	I-Review	I-8	Review	20520
The author responses also seem to simultaneously claim that fine tuning is  both "super standard" and "[not] obvious".	I-Review	I-8	Review	20520
<sep> <sep> 3.	O	O	Review	20520
To make room for the text above, it's not clear that the material about data pollution or even presenting both methods is necessary.	B-Review	B-12	Review	20520
I would prefer to see a thorough explanation of the active learning/post-processing paradigm through one algorithm.	I-Review	I-12	Review	20520
The authors seem to want to claim that active learning is a useful private approach because it gets data-independent privacy guarantees and performance similar to algorithms with data-dependent privacy guarantees.	I-Review	I-12	Review	20520
A paper that focuses on and thoroughly defends that claim actually sounds pretty good!	I-Review	I-12	Review	20520
Responses to your numbered questions:	O	O	Reply	20520
<sep> 1.	O	O	Reply	20520
These are just the activations for the second to last layer of the classifier.	B-Reply	B-6	Reply	20520
<sep> This terminology is pretty common in the object recognition literature.	I-Reply	I-6	Reply	20520
<sep> k is chosen with standard hyper-parameter optimization.	I-Reply	I-6	Reply	20520
<sep> <sep> 2.	O	O	Reply	20520
From the text:	O	O	Reply	20520
'we assign each uncertain private example to exactly one uncertain public	B-Reply	B-7	Reply	20520
example according to Euclidean distance'	I-Reply	I-7	Reply	20520
<sep> 3.	O	O	Reply	20520
Sorry for the confusion here: 'Fine-tuning' as a term is also super standard in the object	B-Reply	B-8	Reply	20520
recognition literature: it means that you take a trained model and update its weights using	I-Reply	I-8	Reply	20520
new data.	I-Reply	I-8	Reply	20520
Generally, it's understood that you use a lower learning rate, and perhaps 'freeze'	I-Reply	I-8	Reply	20520
some of the weights of the earlier layers of the neural network.	I-Reply	I-8	Reply	20520
<sep> <sep> 4.	B-Reply	B-9	Reply	20520
Just that SVHN accuracy benchmarks are further from being saturated than MNIST ones.	I-Reply	I-9	Reply	20520
<sep> <sep> 5.	B-Reply	B-10	Reply	20520
Understood.	I-Reply	I-10	Reply	20520

This paper investigates the question of internal consistency in emergent communication.	O	O	Review	617
In other words, the paper aims to answer the question ‚Äòhow is emergent communication improved if we enforce the constraint that an agent must speak in the same way that it listens?‚Äô The paper explores three methods of enforcing internal consistency: self-play, shared embeddings, and symmetric encoding/decoding.	O	O	Review	617
They find that, while internal consistency does not help generalization to unseen objects, it does allow agents to generalize over conversational roles (i.e. to perform well as a speaker despite only being trained as a listener).	O	O	Review	617
<sep> <sep> I have been eagerly anticipating a paper on this topic ‚Äì it seems silly that the listening and speaking modules in traditional emergent communication research are completely disjoint.	O	O	Review	617
I think coming up with methods/ architectures that combine these two capabilities is an important research direction.	O	O	Review	617
I also think paper is very well-written and structured, and it reads very well.	O	O	Review	617
<sep> <sep> However, I have several concerns with the paper.	B-Review	B-1	Review	617
First, half of the results center around the hypothesis ‚Äòinternal consistency helps agents generalize to unseen items‚Äô.	I-Review	I-1	Review	617
While ultimately this hypothesis is disproven, it‚Äôs unclear as to why this might be expected in the first place.	I-Review	I-1	Review	617
The only justification of this hypothesis I could find in the paper is the sentence ‚ÄúIt is conceivable that &lt;internal consistency&gt; might improve performance even though each &lt;agent&gt; remains in a fixed role.	I-Review	I-1	Review	617
‚Äù In my view, the fact that this hypothesis is ‚Äòconceivable‚Äô is a rather weak argument for it to be such a prominent part of the paper.	I-Review	I-1	Review	617
Thus, I don‚Äôt think this half of the results add much to the overall paper.	I-Review	I-1	Review	617
<sep> <sep> I also have mixed feelings about the use of ‚Äòself-play‚Äô to enforce internal consistency, and how it relates to the core result of the paper: ‚Äúthe proposed constraints enable models to generalize learned language representations across communicative roles, even in the case of where the agent receives no direct training in the target (test) role‚Äù.	B-Review	B-7	Review	617
In short, I think the phrase ‚Äúno direct training‚Äù is misleading, as the self-play itself is almost a form of direct training, and thus the result isn‚Äôt very surprising.	I-Review	I-7	Review	617
<sep> More specifically, each agent ‚ÄòAlice and Bob‚Äô are composed of two modules: a speaking module and a listening module.	B-Review	B-2	Review	617
During normal training (say, in the shape environment), Alice speaks and Bob listens (achieving a reward if Bob selects the right shape, which is backpropagated to Alice), and thus the Alice‚Äôs speaker module and Bob‚Äôs listener module are updated.	I-Review	I-2	Review	617
Alice‚Äôs listening capabilities will be equivalent to a random agent, as her listening module is still randomly initialized.	I-Review	I-2	Review	617
Now, during self-play, Alice‚Äôs speaker module is trained with her listener module (I believe in the same way as it is trained with Bob‚Äôs listener module) to achieve high reward.	I-Review	I-2	Review	617
This listener module is then tested against Bob‚Äôs speaker module (which is also trained via self-play).	I-Review	I-2	Review	617
To me, this process isn‚Äôt the same as the paper‚Äôs narrative of ‚Äòwe only train Alice to be a speaker, and she learns to listen!‚Äô This is especially true since, without parameter tying, the choice of saying that listener module ‚Äòbelongs to Alice‚Äô is arbitrary (since it‚Äôs completely separate).	I-Review	I-2	Review	617
An equivalent way of framing this result would be ‚Äúlanguage learning is transitive: if we train agent A to speak to agent B who listens, then train agent C to listen to agent A and agent D to speak to agent B, then agents D can perform well with agent C‚Äù.	I-Review	I-2	Review	617
With this framing, the result is much less surprising (in fact, it would be surprising if this weren‚Äôt true).	I-Review	I-2	Review	617
<sep> <sep> <sep> Finally, the three methods of enforcing internal consistency are not tested independently --- shared embeddings are only tested on top of self-play, and symmetric encoding/decoding is only tested on top of the other two.	B-Review	B-3	Review	617
While this does make the paper more concise, I suspect another reason for this is that the self-play is the core driver of performance, and without it the other two methods don‚Äôt do much.	I-Review	I-3	Review	617
I‚Äôd like this to be explained more explicitly in the paper.	I-Review	I-3	Review	617
<sep> <sep> Overall, I really like the problem the paper is tackling, however I have some issues with the framing of the paper in relation to the self-play constraint, and subsequently with the importance of the results.	B-Review	B-7	Review	617
Thus, I do not recommend acceptance in the paper‚Äôs current form.	I-Review	I-7	Review	617
<sep> <sep> <sep> Questions:	O	O	Review	617
-<tab>‚ÄúWe set shared embedding agents to always use the self-play objective, because otherwise its equivalent to the baseline agent‚Äù -&gt; it‚Äôs not clear to me why this is the case.	B-Review	B-4	Review	617
Can this be elaborate on?	I-Review	I-4	Review	617
<sep> -<tab>Shouldn‚Äôt the final row of Table 4 read ‚ÄòTrans, shapes‚Äô?	B-Review	B-5	Review	617
<sep> <sep> Small fixes:	B-Review	B-6	Review	617
-<tab>This assumption is a reasonable -&gt; is reasonable	I-Review	I-6	Review	617
-<tab>Section 5.1.2: ‚ÄúWe observe a no clear trend associated with the shared embedding module (sometimes it helps, sometimes it hurts)‚Äù -&gt; I don‚Äôt see any results on shared embeddings in Table 2?	I-Review	I-6	Review	617
<sep> <sep> Please see our general reply to all reviewers above, as we reply to many of your points there.	O	O	Reply	617
In addition, we provide several direct replies to your comments in this post.	O	O	Reply	617
<sep> <sep> * What is the motivation for the hypothesis that internal consistency will improve generalization to unseen items?	O	O	Reply	617
<sep> <sep> You raised concerns that our first hypothesis (internal consistency can improve generalization to unseen items) is not well motivated.	B-Reply	B-1	Reply	617
We disagree.	I-Reply	I-1	Reply	617
Our initial motivation for this line of work was based largely on evidence from developmental psychology which suggests that pragmatic reasoning may encourage children to develop ‚Äúone-to-one‚Äù mappings between words and referents (see e.g. [1]).	I-Reply	I-1	Reply	617
These types of one-to-one lexicons are what we want to see agents learn in emergent settings, and is often what is actually meant when people use words like ‚Äúcompositional‚Äù or ‚Äúgrounded‚Äù in other similar EC work.	I-Reply	I-1	Reply	617
We deliberately chose *not* to lean on the psychological motivation in this paper because we believe that, presently, the ML field is a bit too quick to try to connect the models we build to arguments about ‚Äúhow the brain works‚Äù.	I-Reply	I-1	Reply	617
We are happy to draw inspiration from evidence in psychology and believe others absolutely should too.	I-Reply	I-1	Reply	617
But we prefer to minimize the risk that papers are misread as evidence for/against a hypothesis about human language acquisition unless the experiment is in fact designed precisely to test psychological theories.	I-Reply	I-1	Reply	617
Thus, we chose to take a more conservative approach to our framing by letting the ML hypotheses speak for themselves, rather than frame them as somehow entwined with hypotheses about human language acquisition.	I-Reply	I-1	Reply	617
We still believe that this was the appropriate choice, but hope you can see that the hypothesis was in fact motivated, not pulled out of thin air.	I-Reply	I-1	Reply	617
We rephrased the first paragraph of Section 5.1.3 to provide a bit more motivation, though still without pulling in psych arguments.	I-Reply	I-1	Reply	617
We hope you are happier with this wording.	I-Reply	I-1	Reply	617
<sep> <sep> [1] Diesendruck and Markson.	O	O	Reply	617
Children's Avoidance of Lexical Overlap: A Pragmatic Account.	O	O	Reply	617
Developmental Psychology 2001.	O	O	Reply	617
Vol 37.	O	O	Reply	617
No.	O	O	Reply	617
5, 630-641.	O	O	Reply	617
<sep> <sep> <sep> * Why are shared embeddings and symmetric (de)encoders not tested in isolation?	O	O	Reply	617
<sep> <sep> We now think our presentation, and perhaps terminology, are not sufficiently clear.	B-Reply	B-3	Reply	617
<sep> <sep> Both shared embedding and symmetric decoders/encoders are instances of parameter-tying.	I-Reply	I-3	Reply	617
Note that parameter-tying only matters if the agents use these tied parameters.	I-Reply	I-3	Reply	617
So, if the agents only ever train/test in a signal role, then the weights tied between roles have no impact.	I-Reply	I-3	Reply	617
Therefore ‚Äúwe set shared embedding agents to always use the self-play objective‚Äù because otherwise the ‚Äúconstrained‚Äù model would be no different from the baseline model.	I-Reply	I-3	Reply	617
<sep> <sep> We realize that this is not the case in a wider range of experimental setups (that go beyond the scope of our paper): for example, if the agents were set to both speak and listen to each other, then indeed there would be a distinction.	I-Reply	I-3	Reply	617
This setup somewhat occurs in our experiment on role generalization where Alice listens to Bob on ‚Äúshapes 1‚Äù, Alice speaks to Bob on ‚Äúshapes 2‚Äù, and then is tested on speaking to Bob on ‚Äúshapes 1‚Äù.	I-Reply	I-3	Reply	617
However, as we noted without self-play all methods achieve poor performance in role generalization, and we now highlight this in the report.	I-Reply	I-3	Reply	617
<sep> <sep> * Are we going beyond determining if language learning is transitive?	O	O	Reply	617
<sep> <sep> In light of the previous question, it is not the same because we evaluate if parameter-tying impacts the result.	B-Reply	B-2	Reply	617
Thus, with this framing in mind, we are investigating if there is any interplay between self-play and parameter-tying that goes beyond transitive language learning.	I-Reply	I-2	Reply	617
It appears, especially for role generalization, internal consistency constraints (self-play + parameter-tying) go beyond transitive language learning in many cases.	I-Reply	I-2	Reply	617
In any case, it‚Äôs not evident (without our evaluation) that the protocols would not drift between roles/agents.	I-Reply	I-2	Reply	617
<sep> <sep> * Further updates	O	O	Reply	617
- We tried to highlight that ‚Äúdirect supervision‚Äù refers to interaction between the agents evaluated at test time.	B-Reply	B-4	Reply	617
We found it apt because the other interaction (self-play) is auxiliary, and from the perspective of the final task it is unsupervised.	I-Reply	I-4	Reply	617
<sep> - Yes, the final row of table 4 should be labeled ‚ÄúTrans, shapes‚Äù ‚Äî thank you, we fixed this in our revised report.	B-Reply	B-5	Reply	617

The paper analyzes if enforcing internal-consistency for speaker-listener setup can (i) improve the ability of the agents to refer to unseen referents (ii) generalize for different communicative roles.	O	O	Review	617
The paper evaluates a transformer and arecurrent model modified with various sharing strategies on a single-turn reference game.	O	O	Review	617
Finally, the paper claims that results with self-play suggest that internal consistency doesn‚Äôt help (i) but improves cross-role performance for (ii).	O	O	Review	617
<sep> <sep> As a reader, the paper doesn‚Äôt provide me a concrete finding which can help in designing future multi-agent systems.	B-Review	B-3	Review	617
Most of the results for the experiments (except self-play) don‚Äôt have a uniform signal across the board to deduce whether the internal-consistency works in all of the cases.	I-Review	I-3	Review	617
Most of the speaker-listener scenarios emerge in dialog based settings which are multi-turn and require agents to act both as speaker and listener.	I-Review	I-3	Review	617
Though paper advocates through some of its results that self-play is helpful in generalization across roles via internal-consistency, without multi-step experiments, qualitative and quantitative analysis of what is happening and why there is so much variation, the paper is weak in its current form.	I-Review	I-3	Review	617
Therefore, I recommend weak reject as my rating.	I-Review	I-3	Review	617
Below I discuss some of the concerns in detail:	I-Review	I-3	Review	617
<sep> Without multi-step evaluation, it is hard to gauge the extent to which self-play for internal consistency help in generalization of the roles.	I-Review	I-3	Review	617
For e.g., task from Das et al (2017) [1] provides a clear signal on how well the agents are able to communicate through dialog evaluation.	I-Review	I-3	Review	617
So in 5.2.1, the setup which requires training in both roles can provide better signal overall if it was trained to do multi-step conversation.	I-Review	I-3	Review	617
<sep> <sep> Paper is missing any kind of quantitative or qualitative analysis.	B-Review	B-1	Review	617
What are the differences between the embeddings of the agent that learned via self-play and the one which learned directly.	I-Review	I-1	Review	617
It also be interesting to see how the shared embeddings and symmetric encoding and decoding affect these embedding and might help explain the drop and randomness.	I-Review	I-1	Review	617
In Table 4.,	I-Review	I-1	Review	617
the results on symmetric encoding suggest that the claim of generalization through internal consistency might not hold everywhere.	I-Review	I-1	Review	617
For Shared Embedding results, on RNN shapes, it is surprising that training in one role improves performance through internal consistency while in both roles it drops.	B-Review	B-2	Review	617
These require further analysis to solidify the claim.	I-Review	I-2	Review	617
Given the flaky results, to boost the claim, have authors tried other settings to test internal-consistency like Predator-Prey?	I-Review	I-2	Review	617
<sep> <sep> Things that didn‚Äôt affect the score:	O	O	Review	617
<sep> Related work section is missing the relevant discussion on continuous communication work and discussion on why internal consistency wasn‚Äôt tested on those settings as well. (	B-Review	B-4	Review	617
See Singh et.al [2]., Sukhbaatar et.al. [	I-Review	I-4	Review	617
3], Das et.al. [	I-Review	I-4	Review	617
4] etc)	I-Review	I-4	Review	617
<sep> The number of pages are above eight, you should reduce the redundancy between table descriptions and text and maybe squeeze Section 2, decrease setup explanation.	B-Review	B-5	Review	617
<sep> <sep> The setup for training and test sets explained at the end of page 7 isn‚Äôt very clear to me and needs to be rephrased.	B-Review	B-6	Review	617
<sep> <sep> [1] Das, Abhishek, Satwik Kottur, Jos√© MF Moura, Stefan Lee, and Dhruv Batra. "	O	O	Review	617
Learning cooperative visual dialog agents with deep reinforcement learning."	O	O	Review	617
In Proceedings of the IEEE International Conference on Computer Vision, pp.2951-2960.	O	O	Review	617
2017.	O	O	Review	617
<sep> [2] Sukhbaatar, Sainbayar, and Rob Fergus. "	O	O	Review	617
Learning multiagent communication with backpropagation."	O	O	Review	617
In Advances in Neural Information Processing Systems, pp.2244-2252.	O	O	Review	617
2016.	O	O	Review	617
<sep> [3] Singh, Amanpreet, Tushar Jain, and Sainbayar Sukhbaatar. "	O	O	Review	617
Learning when to communicate at scale in multiagent cooperative and competitive tasks."	O	O	Review	617
arXiv preprint arXiv:1812.09755 (2018).	O	O	Review	617
<sep> [4] Das, Abhishek, Th√©ophile Gervet, Joshua Romoff, Dhruv Batra, Devi Parikh, Michael Rabbat, and Joelle Pineau. "	O	O	Review	617
Tarmac: Targeted multi-agent communication."	O	O	Review	617
arXiv preprint arXiv:1810.11187 (2018).	O	O	Review	617
<sep> <sep> =========	O	O	Review	617
Post-rebuttal Comments	O	O	Review	617
=========	O	O	Review	617
Thanks for updating the manuscript to resolve my and R2's concerns.	O	O	Review	617
The new analysis section does provide good insights into what exactly is happening.	O	O	Review	617
<sep> <sep> When I was talking about actionable insights, I was talking about both negative and positive insights.	O	O	Review	617
Currently, the only take-away is that self-play helps in generalizing to listener roles as well.	B-Review	B-2	Review	617
For the other negative insight that internal consistency doesn't help with generalization, as R2 suggested, it is unclear why that would be case in the first place (I read the pscyhology arguments, but I am not still not convinced).	I-Review	I-2	Review	617
I still believe that without multi-step communication, the work is as useful as it can be in current form.	B-Review	B-3	Review	617
In real world, no meaningful conversation is usually one step.	I-Review	I-3	Review	617
<sep> <sep> For Predator-Prey setup, I was talking about OpenAI <a href="https://github.com/openai/multiagent-particle-envs" target="_blank" rel="nofollow">https://github.com/openai/multiagent-particle-envs</a> in which multiple tasks can be setup.	B-Review	B-2	Review	617
For e.g. if prey thinks of what action predator might take, does internal consistency help prey to perform better?	I-Review	I-2	Review	617
<sep> <sep> I think most of what you got is correct for multi-step, see second para for more details in this response.	O	O	Review	617
<sep> <sep> Thanks for bringing the manuscript under 8 pages. [	O	O	Review	617
3] is still missing from references.	O	O	Review	617
<sep> <sep> Final comments: I would like to see multi-step experiments due to the reasons I explained above.	B-Review	B-3	Review	617
The scheme of internal-consistency should be applicable beyond conversation to Predator-Prey setups also, thus, I feel experiments are not enough (only on 1 setting) to claim generalization of the hypothesis.	I-Review	I-3	Review	617
Beyond these comments, I feel this is still a step in right direction and I would like to update my rating to weak accept while hoping that authors try to address these issues in camera-ready version if paper gets accepted.	I-Review	I-3	Review	617
<sep> <sep> <sep> <sep> <sep> Please see our general reply to all reviewers above, as we reply to many of your points there.	O	O	Reply	617
We also added several new analysis to the paper in reply to your comments; these can be found in Section 6 of the updated draft.	O	O	Reply	617
In addition, we provide several direct replies to your comments below.	O	O	Reply	617
<sep> <sep> * Why no multi-step communication?	O	O	Reply	617
<sep> <sep> We understand your concern about not using multi-step communication as follows: the agents may behave similarly to agents that self-play if they had to act over multiple turns and correspondingly ‚Äî as part of the game itself ‚Äî both speak and listen.	B-Reply	B-3	Reply	617
<sep> <sep> This is a great idea and may extend the range of the results.	I-Reply	I-3	Reply	617
We‚Äôd love to pursue something along these lines in future work.	I-Reply	I-3	Reply	617
As a starting point, we chose to focus on tasks like reference games, with an applied setting of instruction-following robots.	I-Reply	I-3	Reply	617
In these contexts, there are often no follow ups to ‚Äúget me my coffee cup‚Äù or ‚ÄúI‚Äôd like to buy that red sweatshirt‚Äù other than proffering the predicted item within the context.	I-Reply	I-3	Reply	617
Given that real interactions with humans are expensive (much more so than self-play), it would be beneficial if learning agents could leverage pre-existing data and self-play in order generalize to untrained roles.	I-Reply	I-3	Reply	617
We did not flesh out this viewpoint because this work does not fully extend into this setting, but your concerns suggest that we should have clarified this.	I-Reply	I-3	Reply	617
<sep> <sep> * What are the differences between the embeddings of the agent that learned via self-play and the one which learned directly? (	O	O	Reply	617
e.g more qualitative and quantitative analysis!)	O	O	Reply	617
<sep> <sep> We did not heavily inspect the embeddings of the agents, however we did add a section (now Section 6) of additional qualitative and quantitative analysis that inspects the efficacy of selplay, the agents‚Äô communication, and finally, shows the lexicon the agent‚Äôs produced.	B-Reply	B-1	Reply	617
<sep> <sep> * For Shared Embedding results, on RNN shapes, it is surprising that training in one role improves performance through internal consistency while in both roles it drops.	O	O	Reply	617
Why?	O	O	Reply	617
<sep> <sep> It appears that the additional signal does not provide useful information to the agents: perhaps the resultant protocols do not utilize the lexicon developed by the agents in the original role.	B-Reply	B-2	Reply	617
This would be the case if there were a one-to-one mapping between features and symbols (or something like this).	I-Reply	I-2	Reply	617
In the new analysis section (Section 6), we inspect this further.	I-Reply	I-2	Reply	617
<sep> <sep> * Follow up	O	O	Reply	617
- Can you elaborate the mentioned predator-prey setting (or point us in the direction you were thinking of)?	B-Reply	B-4	Reply	617
<sep> - Is our interpretation of your concern with multi-step games correct?	B-Reply	B-5	Reply	617
<sep> - Thank you for highlighting additional related work and for stressing the 8-pages.	B-Reply	B-6	Reply	617
We worked to amend the report to address both of these concerns.	I-Reply	I-6	Reply	617

While my above review title is too verbose, it would be a more accurate title for the paper than the current one (an overall better title would probably be somewhere in between).	B-Review	B-1	Review	335
<sep> <sep> The overall approach is interesting: all three of the key techniques (aux.	O	O	Review	335
tasks, skip/diagonal connections, and the use of internal labels for the kind of data available) make a lot of sense.	O	O	Review	335
<sep> <sep> I found some of the results hard to understand/interpret.	B-Review	B-2	Review	335
Some of the explanation in the discussion below has been helpful (e.g. see my earlier questions about Fig 4 and 5); the paper would benefit from including more such explanations.	I-Review	I-2	Review	335
<sep> <sep> It may be worthwhile very briefly mentioning the relationship of "diagonal" connections to other emerging terms for similar ideas (e.g. skip connections, etc). "	B-Review	B-3	Review	335
Skip" seems to me to be accurate regardless of how you draw the network, whereas "diagonal" only makes sense for certain visual layouts.	I-Review	I-3	Review	335
<sep> <sep> In response to comment in the discussion below: "leading to less over-segmentation of action bouts" (and corresponding discussion in section 5.1 of the paper): I would be like to have a bit more about this in the paper.	B-Review	B-4	Review	335
I have assumed that "per-bout" refers to "per-action event", but now I am not certain that I have understood this correctly (i.e. can a "bout" last for a few minutes?):	I-Review	I-4	Review	335
given the readership, I think it would not be inappropriate to define some of these things explicitly.	I-Review	I-4	Review	335
<sep> <sep> In response to comment about fly behaviours that last minutes vs milliseconds: This is interesting, and I would be curious to know how classification accuracy relates to the time-scale of the behaviour (e.g. are most of the mistakes on long-term behaviours?	B-Review	B-5	Review	335
i realize that this would only tell part of the story, e.g. if you have a behaviour that has both a long-term duration, but that also has very different short-term characteristics than many other behaviours, it should be easy to classify accuractely despite being "long-term").	I-Review	I-5	Review	335
If easy to investigate this, I would add a comment about it; if this is hard to investigate, it's probably not worth it at this point, although it's something you might want to look at in future.	I-Review	I-5	Review	335
<sep> <sep> In response to comment about scaling to human behavior: I agree that in principle, adding conv layers directly above the sensory input would be the right thing to try, but seriously: there is usually a pretty big gap between what "should" work and what actually works, as I am sure the authors are aware. (	B-Review	B-6	Review	335
Indeed, I am sure the authors have a much more experiential and detailed understanding of the limitations of their work than I do).	I-Review	I-6	Review	335
What I see presented is a nice system that has been demonstrated to handle spatiotemporal trajectories.	I-Review	I-6	Review	335
The claims made should correspond to this.	I-Review	I-6	Review	335
<sep> <sep> I would consider adjusting my rating to a 7 depending on future revisions.	O	O	Review	335
<sep> <sep> Thank you for your review.	O	O	Reply	335
Majority of your comments are addressed in the global response.	O	O	Reply	335
<sep> <sep> Regarding how classification accuracy relates to the time-scale of the behavior, I agree that it would be interesting to further analyze the types of errors we get with respect to timescale and we plan to explore this for future development.	B-Reply	B-5	Reply	335

The paper presents a method for joint motion prediction and activity classification from sequences with two different applications: motion of fruit flies and online handwriting recognition.	O	O	Review	335
<sep> <sep> The method uses a classical encoder-decoder pipeline, with skip connections allowing direct communication between the encoder and the decoder on respective levels of abstraction.	O	O	Review	335
<sep> Motion is discretized and predicted using classification.	O	O	Review	335
The model is trained on classification loss combined with a loss on motion prediction.	O	O	Review	335
The goal is to leverage latter loss in a semi-supervised setting from parts of the data which do not contain action labels.	O	O	Review	335
<sep> <sep> The idea of leveraging predictions to train feature representations for discrimination is not new.	O	O	Review	335
However, the paper presents a couple of interesting ideas, partially inspired from other work in other areas.	O	O	Review	335
<sep> <sep> My biggest concern is with the experimental evaluation.	B-Review	B-1	Review	335
The experimental section contains a large amount of figures, which visualize what the model has learned in a qualitative way.	I-Review	I-1	Review	335
However, quantitative evaluation is rarer.	I-Review	I-1	Review	335
<sep> <sep> - On the fly application, the authors compare the classification performance with another method previously published by the first author.	B-Review	B-2	Review	335
<sep> - Again on the fly application, the performance gain on motion prediction in figure 5c looks small compared to the baseline.	B-Review	B-3	Review	335
I am not sure it is significant.	I-Review	I-3	Review	335
<sep> - I did not see any recognition results on the handwriting application.	B-Review	B-4	Review	335
Has this part not been evaluated?	I-Review	I-4	Review	335
<sep> <sep> Figure 5a is difficult to understand and to interpret.	B-Review	B-5	Review	335
The term "BesNet" is used here without any introduction.	I-Review	I-5	Review	335
<sep> <sep> Figure 4 seems to tell multiple and different stories.	B-Review	B-6	Review	335
I'd suggest splitting it into at least two different figures.	I-Review	I-6	Review	335
<sep> <sep> Thank you for your review.	O	O	Reply	335
To answer your questions:	O	O	Reply	335
<sep> ** I did not see any recognition results on the handwriting application.	O	O	Reply	335
Has this part not been evaluated?	O	O	Reply	335
<sep> - Figure 4 has quantitative results for all 3 labeled datasets, including handwriting, for varying number of training labels.	B-Reply	B-4	Reply	335
<sep> <sep> ** Figure 4 seems to tell multiple and different stories.	O	O	Reply	335
I'd suggest splitting it into at least two different figures.	O	O	Reply	335
<sep> - The 3 plots in Figure 4 are grouped because they all refer to classification performance, in order to make best use of space.	B-Reply	B-6	Reply	335
<sep> - We have added more details to the caption of figure 4 to connect the stories.	I-Reply	I-6	Reply	335
<sep> <sep> ** Figure 5a is difficult to understand and to interpret.	O	O	Reply	335
The term "BesNet" is used here without any introduction.	O	O	Reply	335
<sep> - BESNet and BENet are described on page 7 paragraph 2, before figure 5 on page 8.	B-Reply	B-5	Reply	335
<sep> - We have added more details to the caption of figure 5.	I-Reply	I-5	Reply	335
<sep> <sep> ** The experimental section contains a large amount of figures, which visualize what the model has learned in a qualitative way.	O	O	Reply	335
However, quantitative evaluation is rarer.	O	O	Reply	335
<sep> - Figure 5 shows quantitative 1-step motion prediction performance, and figure 4 quantitatively evaluates classification performance.	B-Reply	B-1	Reply	335
<sep> - For multi-step prediction (i.e. simulation), qualitative results can be more informative than quantitative, as the objective function may not capture what looks realistic to humans.	B-Reply	B-1	Reply	335
This is comparable to image generation where qualitative results and human scoring are standard methods of evaluation, e.g. <a href="https://arxiv.org/pdf/1506.05751v1.pdf."	I-Reply	I-1	Reply	335
target="_blank" rel="nofollow">https://arxiv.org/pdf/1506.05751v1.pdf.</a>	O	O	Reply	335
- The paper does indeed have a lot of qualitative results, which are better demonstrated on our project website as videos: <a href="http://www.vision.caltech.edu/~eeyjolfs/behavior_modeling/" target="_blank" rel="nofollow">http://www.vision.caltech.edu/~eeyjolfs/behavior_modeling/</a>	B-Reply	B-1	Reply	335

This paper proposes a recurrent architecture for simultaneously predicting motion and action states of agents.	O	O	Review	335
<sep> The paper is well written, clear in its presentation and backed up by good experiments.	O	O	Review	335
<sep> They demonstrate that by forcing the network to predict motion has beneficial consequences on the classification of actions states,	O	O	Review	335
allowing more accurate classification with less training data.	O	O	Review	335
<sep> They also show how the information learned by the network is interpretable and organised in a hierarchy.	O	O	Review	335
<sep> <sep> Weaknesses:	O	O	Review	335
- a critical discussion on the interplay between motion an behaviour that is needed to experience the benefits of their proposed model is missing from the paper.	B-Review	B-1	Review	335
<sep> - moreover, a discussion on how this approach could scale to more challenging scenarios "involving animals" and visual input for instance and more general "behaviours" is also missing;	B-Review	B-2	Review	335
The criticism here is pointed at the fact that the title/abstract claim general behaviour modelling, whilst the experiments are focused on two very specific and relatively simple scenarios,	I-Review	I-2	Review	335
making the original claim a little bit far fetched unless its backed up by additional evidence.	I-Review	I-2	Review	335
<sep> Using "Insects", or "fruit flies" would be more appropriate than "animals".	I-Review	I-2	Review	335
Thank you for your review.	O	O	Reply	335
We have added a discussion at the end of the paper about scaling to more complex data.	B-Reply	B-2	Reply	335
<sep> <sep> Regarding a critical discussion on the interplay between motion and behavior, in the introduction we explain that motion trajectories and actions represent behavior at different levels of timescales, and that actions can be detected from motion trajectories.	B-Reply	B-1	Reply	335
If your point refers to a more biological explanation, such as the one we discuss in our global response, I am also happy to add that to the introduction of the paper.	I-Reply	I-1	Reply	335

MAML (Finn+ 2017) is recast as a hierarchical Bayesian learning procedure.	O	O	Review	335
In particular the inner (task) training is initially cast as point-wise max likelihood estimation, and then (sec4) improved upon by making use of the Laplace approximation.	O	O	Review	335
Experimental evidence of the relevance of the method is provided on a toy task involving a NIW prior of Gaussians, and the (benchmark) MiniImageNet task.	O	O	Review	335
<sep> <sep> Casting MAML as HB seems a good idea.	O	O	Review	335
The paper does a good job of explaining the connection, but I think the presentation could be clarified.	O	O	Review	335
The role of the task prior and how it emerges from early stopping (ie a finite number of gradient descent steps) (sec 3.2) is original and technically non-trivial, and is a contribution of this paper.	B-Review	B-1	Review	335
<sep> The synthetic data experiment sec5.1 and fig5 is clearly explained and serves to additionally clarify the proposed method.	B-Review	B-2	Review	335
<sep> Regarding the MiniImageNet experiments, I read the exchange on TCML and agree with the authors of the paper under review.	I-Review	I-2	Review	335
However, I recommend including the references to Mukhdalai 2017 and Sung 2017 in the footnote on TCML to strengthen the point more generically, and show that not just TCML but other non-shallow architectures are not considered for comparison here.	I-Review	I-2	Review	335
In addition, the point made by the TCML authors is fair ("nothing prevented you from...") and I would also recommend mentioning the reviewed paper's authors' decision (not to test deeper architectures) in the footnote.	I-Review	I-2	Review	335
This decision is in order but needs to be stated in order for the reader to form a balanced view of methods at her disposal.	I-Review	I-2	Review	335
<sep> The experimental performance reported Table 1 remains small and largely within one standard deviation of competitor methods.	B-Review	B-3	Review	335
<sep> <sep> I am assessing this paper as "7" because despite the merit of the paper, the relevance of the reformulation of MAML, and the technical steps involved in the reformulation, the paper does not eg address other forms (than L-MAML) of the task-specific subroutine ML-..., and the benchmark improvements are quite small.	B-Review	B-5	Review	335
I think the approach is good and fruitful.	I-Review	I-5	Review	335
<sep> <sep> <sep> # Suggestions on readability	O	O	Review	335
<sep> * I have the feeling the paper inverts from their use in Finn 2017 (step size for meta- vs task-training).	B-Review	B-6	Review	335
This is unfortunate and will certainly confuse readers; I advise carefully changing this throughout the entire paper (eg Algo 2,3,4, eq 1, last eq in sec3.1, eq in text below eq3, etc)	I-Review	I-6	Review	335
<sep> * I advise avoiding the use of the symbol f, which appears in only two places in Algo 2 and the end of sec 3.1.	I-Review	I-6	Review	335
This is in part because f is given another meaning in Finn 2017, but also out of general parsimony in symbol use. (	I-Review	I-6	Review	335
could leave the output of ML-... implicit by writing ML-...(\theta, T)_j in the; if absolutely needed, use another symbol than f)	I-Review	I-6	Review	335
<sep> * Maybe sec3 can be clarified in its structure by re-ordering points on the quadratic error function and early stopping (eg avoiding to split them between end of 3.1 and 3.2).	I-Review	I-6	Review	335
<sep> <sep> * sec6 "Machine learning and deep learning": I would definitely avoid this formulation, seems to tail in with all the media nonsense on "what's the difference between ML and DL ?".	I-Review	I-6	Review	335
In addition the formulation seems to contrast ML with hierarchical Bayesian modeling, which does not make sense/ is wrong and confusing.	I-Review	I-6	Review	335
<sep> <sep> # Typos	O	O	Review	335
<sep> * sec1 second parag: did you really mean "in the architecture or loss function"?	B-Review	B-7	Review	335
unclear.	I-Review	I-7	Review	335
<sep> * sec2: over a family	I-Review	I-7	Review	335
* "common structure, so that" (not such that)	I-Review	I-7	Review	335
* orthgonal	I-Review	I-7	Review	335
* sec2.1 suggestion: clarify that \theta and \phi are in the same space	I-Review	I-7	Review	335
* sec2.2 suggestion: task-specific parameter is distinct from ... parameters\phi_j$ (I would avoid writing just \phi altogether to distinguish in usage from \theta)	I-Review	I-7	Review	335
* Gaussian-noised	I-Review	I-7	Review	335
* approximation of the it objective	I-Review	I-7	Review	335
* before eq9: "that solves": well, it doesn't really "solve" the minimisation, in that it is not a minimum; reformulate this?	B-Review	B-4	Review	335
<sep> * sec4.1 innaccurate	B-Review	B-7	Review	335
* well approximated	I-Review	I-7	Review	335
* sec4.2 an curvature	I-Review	I-7	Review	335
* (Amari 1989)	I-Review	I-7	Review	335
* For the the Laplace	I-Review	I-7	Review	335
* O(n^3) : what is n ?	I-Review	I-7	Review	335
<sep> * sec5.2 (Ravi and L 2017)	I-Review	I-7	Review	335
* for the the	I-Review	I-7	Review	335
<sep> We thank R3 for thorough and constructive comments!	O	O	Reply	335
We have attempted to address them to the best of our ability.	O	O	Reply	335
<sep> <sep> We agree with R3‚Äôs characterization of the paper, but would like to clarify a small point for completeness:	O	O	Reply	335
<sep> > ‚ÄúIn particular the inner (task) training is initially cast as point-wise max likelihood estimation‚Ä¶‚Äù	O	O	Reply	335
<sep> We cast the task-specific training in the inner loop as maximum a posteriori estimation (instead of max likelihood), in which the induced prior is a result of gradient descent with early stopping (termed ‚Äúfast adaptation‚Äù).	B-Reply	B-1	Reply	335
In particular, the induced prior serves to regularize the task-specific parameters to initial conditions (the parameter initialization).	I-Reply	I-1	Reply	335
<sep> <sep> > ‚ÄúRegarding the MiniImageNet experiments‚Ä¶‚Äù	O	O	Reply	335
<sep> Our detailed discussion with an author of TCML is in the OpenReview comment thread (<a href="https://openreview.net/forum?id=BJ_UL-k0b&noteId=r1aR9l5lG)."	B-Reply	B-2	Reply	335
target="_blank" rel="nofollow">https://openreview.net/forum?id=BJ_UL-k0b&noteId=r1aR9l5lG).</a> In summary, our contribution is to reinterpret MAML as approximate inference in a hierarchical Bayesian model, rather than to provide an exhaustive empirical comparison over neural network architectures (as the choice of architecture is largely orthogonal to the training loss or algorithm).	I-Reply	I-2	Reply	335
Furthermore, the majority of other prior few-shot learning methods used the smaller architecture, so we felt that standardizing the architecture would provide a more informative comparison.	I-Reply	I-2	Reply	335
Since we were able to obtain a number for SNAIL/TCML using the same architecture, we believe that this adequately rounds out the comparisons.	I-Reply	I-2	Reply	335
<sep> <sep> > The experimental performance reported Table 1 remains small and largely within one standard deviation of competitor methods.	O	O	Reply	335
<sep> <sep> We note that Triantafillou et al (2017) in NIPS 2017 reported a similar improvement after MAML was published in ICML 2017, and so the standard seems to be that an improvement of about 1% is publishable.	B-Reply	B-3	Reply	335
<sep> <sep> > before eq9: "that solves": well, it doesn't really "solve" the minimisation, in that it is not a minimum; reformulate this?	O	O	Reply	335
<sep> <sep> In the linear regression case, the iterate indeed solves the *regularized* minimization problem (in particular, it is a solution that obtains the best trade-off (wrt the regularization parameter) between minimal objective and regularization costs).	B-Reply	B-4	Reply	335
However, the iterate indeed does not solve the *unregularized* problem.	I-Reply	I-4	Reply	335
<sep> <sep> > ‚Äú‚Ä¶the paper does not eg address other forms (than L-MAML) of the task-specific subroutine ML-...,‚Äù	O	O	Reply	335
<sep> We could potentially use another inference method (such as the nested Laplace approximation, variational Bayes, expectation propagation, or Hamiltonian Monte Carlo) to compute a more complex posterior distribution over task-specific parameters \phi.	B-Reply	B-5	Reply	335
This is an interesting extension that we leave to future work.	I-Reply	I-5	Reply	335
<sep> <sep> > ‚Äú# Suggestions on readability‚Äù & ‚Äú# Typos‚Äù	O	O	Reply	335
<sep> Many thanks for catching all of these corrigenda ‚Äî we‚Äôve corrected them in the revised paper (as follows for the more major points):	B-Reply	B-6	Reply	335
<sep> - \alpha, \beta ‚Üí \beta, \alpha	I-Reply	I-6	Reply	335
- replaced ‚Äúf‚Äù with ‚ÄúE_{x from task} [-\log p(x | \theta)]	I-Reply	I-6	Reply	335
- We kept the split of early stopping & the quadratic function between 3.1, 3.2 since 3.2 is ‚Äúadditional material‚Äù and 3.1 is already dense.	I-Reply	I-6	Reply	335
But, thank you for the suggestion.	I-Reply	I-6	Reply	335
<sep> - reformulated related work	I-Reply	I-6	Reply	335
- clarified that \theta and \phi are in the same space	I-Reply	I-6	Reply	335
- O(n^3) ‚Üí O(d^3) for d-dimensional Kronecker factor	I-Reply	I-6	Reply	335

The paper reformulates the model-agnostic meta-learning algorithm (MAML) in terms of inference for parameters of a prior distribution in a hierarchical Bayesian model.	O	O	Review	335
This provides an interesting and, as far as I can tell, novel view on MAML.	O	O	Review	335
The paper uses this view to improve the MAML algorithm.	O	O	Review	335
The writing of the paper is excellent.	B-Review	B-1	Review	335
Experimental evalution is well done against a number of recently developed alternative methods in favor of the presented method, except for TCML which has been exluded using a not so convincing argument.	I-Review	I-1	Review	335
The overview of the literature is also very well done.	I-Review	I-1	Review	335
We thank R2 for feedback.	B-Reply	B-1	Reply	335
Regarding R2‚Äôs comment on the exclusion of TCML from the miniImageNet results table: Our detailed discussion with an author of TCML is in the OpenReview comment thread (<a href="https://openreview.net/forum?id=BJ_UL-k0b&noteId=r1aR9l5lG)."	I-Reply	I-1	Reply	335
target="_blank" rel="nofollow">https://openreview.net/forum?id=BJ_UL-k0b&noteId=r1aR9l5lG).</a> In summary, our contribution is to reinterpret MAML as approximate inference in a hierarchical Bayesian model, rather than to provide an exhaustive empirical comparison over neural network architectures (as the choice of architecture is largely orthogonal to the training loss or algorithm).	I-Reply	I-1	Reply	335
Furthermore, the majority of other prior few-shot learning methods used the smaller architecture, so we felt that standardizing the architecture would provide a more informative comparison.	I-Reply	I-1	Reply	335
Since we were able to obtain a number for SNAIL/TCML using the same architecture, we believe that this adequately rounds out the comparisons.	I-Reply	I-1	Reply	335

Summary	O	O	Review	335
The paper presents an interesting view on the recently proposed MAML formulation of meta-learning (Finn et al).	O	O	Review	335
The main contribution is a) insight into the connection between the MAML procedure and MAP estimation in an equivalent linear hierarchical Bayes model with explicit priors, b) insight into the connection between MAML and MAP estimation in non-linear HB models with implicit priors, c) based on these insights, the paper proposes a variant of MALM using a Laplace approximation (with additional approximations for the covariance matrix.	O	O	Review	335
The paper finally provides an evaluation on the mini ImageNet problem without significantly improving on the MAML results on the same task.	O	O	Review	335
<sep> <sep> Pro:	O	O	Review	335
-            The topic is timely and of relevance to the ICLR community continuing a current trend in building meta-learning system for few-shot learning.	O	O	Review	335
<sep> -            Provides valuable insight into the MAML objective and its relation to probabilistic models	O	O	Review	335
<sep> Con:	O	O	Review	335
-            The paper is generally well-written but I find (as a non-meta-learner expert) that certain fundamental aspects could have been explained better or in more detail (see below for details).	B-Review	B-4	Review	335
<sep> -            The toy example is quite difficult to interpret the first time around and does not provide any empirical insight into the converge of the proposed method (compared to e.g. MAML)	B-Review	B-5	Review	335
-            I do not think the empirical results provide enough evidence that it is a useful/robust method.	B-Review	B-6	Review	335
Especially it does not provide insight into which types of problems (small/large, linear/ non-linear) the method is applicable to.	I-Review	I-6	Review	335
<sep> <sep> <sep> Detailed comments/questions:	O	O	Review	335
-            The use of Laplace approximation is (in the paper) motivated from a probabilistic/Bayes and uncertainty point-of-view.	O	O	Review	335
It would, however, seem that the truncated iterations do not result in the approximation being very accurate during optimization as the truncation does not result in the approximation being created at a mode.	O	O	Review	335
Could the authors perhaps comment on:	O	O	Review	335
a) whether it is even meaningful to talk about the approximations as probabilistic distribution during the optimization (given the psd approximation to the Hessian), or does it only make sense after convergence?	B-Review	B-7	Review	335
<sep> b) the consequence of the approximation errors on the general convergence of the proposed method (consistency and rate)	B-Review	B-7	Review	335
<sep> -            Sec 4.1, p5: Last equation: Perhaps useful to explain the term and why it is not in subroutine 4 .	B-Review	B-8	Review	335
Should  be ?	I-Review	I-8	Review	335
<sep> -            Sec 4.2: ‚ÄúA straightforward‚Ä¶‚Äù: I think it would improve readability to refer back to the to the previous equation (i.e. H) such that it is clear what is meant by ‚Äústraightforward‚Äù.	B-Review	B-9	Review	335
<sep> -            Sec 4.2: Several ideas are being discussed in Sec 4.2 and it is not entirely clear to me what has actually been adopted here; perhaps consider formalizing the actual computations in Subroutine 4 ‚Äì and provide a clearer argument (preferably proof) that this leads to consistent and robust estimator of \theta.	B-Review	B-10	Review	335
<sep> -            It is not clear from the text or experiment how the learning parameters are set.	B-Review	B-10	Review	335
<sep> -            Sec 5.1: It took some effort to understand exactly what was going on in the example and particular figure 5.1; e.g., in the model definition in the body text there is no mention of the NN mentioned/used in figure 5, the blue points are not defined in the caption, the terminology e.g.  ‚Äúpre-update density‚Äù is new at this point.	B-Review	B-11	Review	335
I think it would benefit the readability to provide the reader with a bit more guidance.	I-Review	I-11	Review	335
<sep> -            Sec 5.1: While the qualitative example is useful (with a bit more text), I believe it would have been more convincing with a quantitative example to demonstrate e.g. the convergence of the proposal compared to std MAML and possibly compare to a std Bayesian inference method from the HB formulation of the problem (in the linear case)	B-Review	B-12	Review	335
-            Sec 5.2: The abstract clams increased performance over MAML but the empirical results do not seem to be significantly better than MAML ?	B-Review	B-13	Review	335
I find it quite difficult to support the specific claim in the abstract from the results without adding a comment about the significance.	I-Review	I-13	Review	335
<sep> -            Sec 5.2: The authors have left out ‚ÄúMishral et al‚Äù from the comparison due to the model being significantly larger than others.	B-Review	B-1	Review	335
Could the authors provide insight into why they did not use the ResNet structure from the  tcml paper in their L-MLMA scheme ?	I-Review	I-1	Review	335
<sep> -            Sec 6+7: The paper clearly states that it is not the aim to (generally) formulate the MAML as a HB.	B-Review	B-2	Review	335
Given the advancement in gradient based inference for HB the last couple of years (e.g. variational, nested laplace , expectation propagation etc) for explicit models, could the authors perhaps indicate why they believe their approach of looking directly to the MAML objective is more scalable/useful than trying to formulate the same or similar objective in an explicit HB model and using established inference methods from that area ?	I-Review	I-2	Review	335
<sep> <sep> Minor:	O	O	Review	335
-            Sec 4.1 ‚Äú‚Ä¶each integral in the sum in (2)‚Ä¶‚Äù eq 2 is a product	B-Review	B-3	Review	335
<sep> > ‚ÄúSec 5.2: The authors have left out ‚ÄúMishral et al‚Äù from the comparison due to the model being significantly larger than others.	O	O	Reply	335
Could the authors provide insight into why they did not use the ResNet structure from the  tcml paper in their L-MLMA scheme ?‚	O	O	Reply	335
Äù	O	O	Reply	335
<sep> Please see our detailed discussion with an author of TCML in the OpenReview comment thread (<a href="https://openreview.net/forum?id=BJ_UL-k0b&noteId=r1aR9l5lG)."	B-Reply	B-1	Reply	335
target="_blank" rel="nofollow">https://openreview.net/forum?id=BJ_UL-k0b&noteId=r1aR9l5lG).</a> In summary, our contribution is to reinterpret MAML as approximate inference in a hierarchical Bayesian model, rather than to provide an exhaustive empirical comparison over neural network architectures (as the choice of architecture is largely orthogonal to the training loss or algorithm).	I-Reply	I-1	Reply	335
Furthermore, the majority of other prior few-shot learning methods used the smaller architecture, so we felt that standardizing the architecture would provide a more informative comparison.	I-Reply	I-1	Reply	335
Since we were able to obtain a number for SNAIL/TCML using the same architecture, we believe that this adequately rounds out the comparisons.	I-Reply	I-1	Reply	335
<sep> <sep> > ‚ÄúSec 6+7: The paper clearly states that it is not the aim to (generally) formulate the MAML as a HB.	O	O	Reply	335
Given the advancement in gradient based inference for HB the last couple of years (e.g. variational, nested laplace , expectation propagation etc) for explicit models, could the authors perhaps indicate why they believe their approach of looking directly to the MAML objective is more scalable/useful than trying to formulate the same or similar objective in an explicit HB model and using established inference methods from that area ?‚	O	O	Reply	335
Äù	O	O	Reply	335
<sep> We intend the connection between MAML and HB to provide an avenue to incorporate insights from gradient-based inference, not as an explicit alternative to established inference procedures.	B-Reply	B-2	Reply	335
To clarify, with the Laplace approximation, we are making the assumption that the posterior over \phi is a unimodal Gaussian with mean centered at the point estimate computed by a few steps of gradient descent during fast adaptation, and with covariance equal to the inverse Hessian evaluated at that point.	I-Reply	I-2	Reply	335
However, we are not restricted to this assumption ‚Äî we could potentially use another inference method (such as the nested Laplace approximation, variational Bayes, expectation propagation, or Hamiltonian Monte Carlo) to compute a more complex posterior distribution over \phi and to potentially improve performance.	I-Reply	I-2	Reply	335
We may also incorporate insights from the recent literature on interpreting gradient methods as forms of probabilistic inference (e.g., Zhang & Sun et al 2017) due the gradient-based nature of our method.	I-Reply	I-2	Reply	335
This is interesting future work!	I-Reply	I-2	Reply	335
<sep> <sep> If the reviewer has specific suggestions for related works that present generic inference methods (gradient-based or otherwise) that can reliably deal with high-dimensional stimuli and high-dimensional models (especially those that deal with raw images), we would be grateful to hear of them.	O	O	Reply	335
<sep> <sep> > Sec 4.1 ‚Äú‚Ä¶each integral in the sum in (2)‚Ä¶‚Äù eq 2 is a product	O	O	Reply	335
<sep> Fixed ‚Äî thank you!	O	O	Reply	335
<sep> <sep> <sep> We encourage R2 to let us know of any additional questions or concerns about the clarity of the paper (especially things that could make the work clearer to a non-meta-learning audience).	B-Reply	B-3	Reply	335
<sep> <sep> <sep> =========================================	O	O	Reply	335
References	O	O	Reply	335
<sep> Ba (2017). ‚	O	O	Reply	335
ÄúDistributed Second-Order Optimization using Kronecker-Factored Approximations.	O	O	Reply	335
‚Äù In ICLR 2017.	O	O	Reply	335
<sep> Martens (2010). "	O	O	Reply	335
Deep learning via Hessian-free optimization."	O	O	Reply	335
In ICML 2010 <a href="http://www.cs.toronto.edu/~jmartens/docs/Deep_HessianFree.pdf" target="_blank" rel="nofollow">http://www.cs.toronto.edu/~jmartens/docs/Deep_HessianFree.pdf</a>	O	O	Reply	335
Martens (2014). "	O	O	Reply	335
New insights and perspectives on the natural gradient method."	O	O	Reply	335
arXiv preprint arXiv:1412.1193.	O	O	Reply	335
<a href="https://arxiv.org/abs/1412.1193" target="_blank" rel="nofollow">https://arxiv.org/abs/1412.1193</a>	O	O	Reply	335
Pascanu & Bengio (2013). "	O	O	Reply	335
Revisiting natural gradient for deep networks."	O	O	Reply	335
arXiv preprint arXiv:1301.3584.	O	O	Reply	335
<a href="https://arxiv.org/abs/1301.3584" target="_blank" rel="nofollow">https://arxiv.org/abs/1301.3584</a>	O	O	Reply	335
Triantafillou et al (2017). ‚	O	O	Reply	335
ÄúFew-Shot Learning Through an Information Retrieval Lens.	O	O	Reply	335
‚Äù In NIPS 2017.	O	O	Reply	335
<a href="https://arxiv.org/abs/1707.02610" target="_blank" rel="nofollow">https://arxiv.org/abs/1707.02610</a>	O	O	Reply	335
Vinyals & Povey (2012). ‚	O	O	Reply	335
ÄúKrylov Subspace Descent for Deep Learning.	O	O	Reply	335
‚Äù In AISTATS 2012.	O	O	Reply	335
<a href="https://arxiv.org/abs/1111.4259" target="_blank" rel="nofollow">https://arxiv.org/abs/1111.4259</a>	O	O	Reply	335
Zhang & Sun et al (2017). ‚	O	O	Reply	335
ÄúNoisy Natural Gradient as Variational Inference.	O	O	Reply	335
‚Äù <a href="https://arxiv.org/abs/1712.02390" target="_blank" rel="nofollow">https://arxiv.org/abs/1712.02390</a>	O	O	Reply	335

The paper proposes a novel data augmentations approach that improves the robustness of a model on the CIFAR-10 and ImageNet Common Corruptions benchmarks while maintaining training accuracy on clean data.	O	O	Review	335
To achieve this, the paper proposes a rather simple augmentation mechanism that is inspired by CutOut (DeVries &amp; Taylor 2017) and Gaussian (Grandvalet &amp; Kanu, 1997): adding Gaussian noise to random patches in the image.	O	O	Review	335
This simple approach is shown to work surprisingly well on the corruption benchmarks.	O	O	Review	335
It seems reasonable that while adding Gaussian noise makes the model robust to high frequency noise, since Gaussian noise is not added everywhere, the model is able to exploit high frequency signal when available in the input.	B-Review	B-1	Review	335
The paper is reasonably well written and the experimental validation is convincing.	O	O	Review	335
<sep> <sep> Overall, the approach could become one of the standard mechanisms for data augmentation in the toolset of a practical ML engineer.	O	O	Review	335
<sep> <sep> We thank the reviewer for the positive comments and helpful summary of our contributions.	B-Reply	B-1	Reply	335
In particular, we appreciate the summary of the insights demonstrated with the frequency-based analysis (Section 5.1).	I-Reply	I-1	Reply	335
We hope to incorporate a version of this summary in the camera-ready version as we believe it will be valuable to future readers.	I-Reply	I-1	Reply	335

This paper proposes a data augmentation method that interpolates between two existing methods (Cutout and Gaussian), for training robust models towards Gaussian and naturally occurring corruptions.	O	O	Review	335
The method is shown to improve robustness without sacrificing accuracy on clean data.	O	O	Review	335
<sep> Pros:	O	O	Review	335
The proposed method, despite being simple, seems to empirically work well in terms of the mCE criterion evaluated in the experiments.	O	O	Review	335
This does support the authors‚Äô claim that current methods haven‚Äôt reached the robustness/accuracy tradeoff boundary yet.	O	O	Review	335
<sep> Cons:	O	O	Review	335
I‚Äôm a bit concerned about the significance of the work though.	B-Review	B-1	Review	335
The method is a straight-forward combination of existing methods, so methodologically the novelty is kind of limited.	I-Review	I-1	Review	335
Hence, I‚Äôm expecting more insights from the analysis of the results, to gain more understanding of why it works so well.	B-Review	B-2	Review	335
However, the presentation of the experiments just seems to aim for the best numbers one can get (I‚Äôm not certain how significant the numbers are to this field though).	B-Review	B-3	Review	335
A few examples/pictures of success cases (when the method works) and failure cases (when the method doesn‚Äôt work), may help readers (I‚Äôm not an expert) to better understand the approach and get more intuitions?	B-Review	B-4	Review	335
The frequency analysis seems quite intuitive.	I-Review	I-4	Review	335
It‚Äôs obvious that Gaussian filter blocks high-frequency components, and Cutout keeps some original parts of the image which allow high-freq details to be captured.	I-Review	I-4	Review	335
But, considering CIFAR image size is only 32x32, a patch of size 25 is quite large, how much is the method different from plain whole image Gaussian then?	B-Review	B-5	Review	335
<sep> <sep> We thank the reviewer for the thoughtful comments.	O	O	Reply	335
We provide some answers to the concerns raised below:	O	O	Reply	335
<sep> &gt; I‚Äôm a bit concerned about the significance of the work though.	O	O	Reply	335
The method is a straight-forward combination of existing methods, so methodologically the novelty is kind of limited.	O	O	Reply	335
<sep> <sep> We agree that the method presented is very simple.	B-Reply	B-1	Reply	335
However, we‚Äôd like to emphasize that this was done by design.	I-Reply	I-1	Reply	335
In showing that such a simple method can be competitive with state-of-the-art methods in the robustness literature, we show that complex training schemes may not be necessary for training models robust to unseen distributions.	I-Reply	I-1	Reply	335
This is, we believe, where the significance of the work stems.	I-Reply	I-1	Reply	335
Indeed, R1 mentioned that our method ‚Äúcould become one of the standard mechanisms for data augmentation in the toolset of a practical ML engineer,‚Äù especially since it‚Äôs so easy to try.	I-Reply	I-1	Reply	335
<sep> <sep> &gt; I‚Äôm expecting more insights from the analysis of the results, to gain more understanding of why it works so well.	O	O	Reply	335
<sep> <sep> In Section 5.1, we provide an extensive frequency-based analysis and discussion of why Patch Gaussian works well: Patch Gaussian seems to allow high-frequency information through at lower layers, but still encourages relatively lower test error sensitivity at high frequencies.	B-Reply	B-2	Reply	335
Indeed, when we measure accuracy on images filtered with a high-pass filter, we see that Patch Gaussian models can maintain accuracy in a similar way to the baseline and to Cutout, where Gaussian fails to.	I-Reply	I-2	Reply	335
See Figure 5 for full results.	I-Reply	I-2	Reply	335
<sep> <sep> We will re-word this section to clarify these insights to future readers.	I-Reply	I-2	Reply	335
<sep> <sep> &gt; A few examples/pictures of success cases (when the method works) and failure cases (when the method doesn‚Äôt work), may help readers (I‚Äôm not an expert) to better understand the approach and get more intuitions?	O	O	Reply	335
<sep> <sep> We thank the reviewer for the suggestion.	B-Reply	B-3	Reply	335
We have not examined this but we hope to include it in camera-ready.	I-Reply	I-3	Reply	335
In particular, we expect that images with higher Brightness will be among the most common errors, since Patch Gaussian slightly increases error (mCE 0.592) in these corruptions with respect to the Baseline (mCE 0.582). (	I-Reply	I-3	Reply	335
see Table 7 in Appendix).	I-Reply	I-3	Reply	335
<sep> <sep> &gt; It‚Äôs obvious that Gaussian filter blocks high-frequency components, and Cutout keeps some original parts of the image which allow high-freq details to be captured	O	O	Reply	335
<sep> We agree with the reviewer that these insights make intuitive sense.	B-Reply	B-4	Reply	335
Our work provides a quantitative evaluation of this phenomenon to confirm this intuition.	I-Reply	I-4	Reply	335
Further, through rigorous frequency-based sensitivity analysis we show that Patch Gaussian is able to retain both the high frequency sensitivity of Cutout and robustness gains of Gaussian augmentation.	I-Reply	I-4	Reply	335
<sep> <sep> &gt; a patch of size 25 is quite large, how much is the method different from plain whole image Gaussian then?	O	O	Reply	335
<sep> <sep> We remind the reviewer that, while the center of the patch needs to be inside the image, the edges can be outside.	B-Reply	B-5	Reply	335
This means that, with a patch of size 25, 39.55% of the space is covered in expectation for an image of size 32.	I-Reply	I-5	Reply	335
Depending on the location of the patch, 16.50% the space is covered (minimum) and other 61.04% is covered (maximum).	I-Reply	I-5	Reply	335
<sep> <sep> In addition, our experimental results clearly show that patch Gaussian performs significantly differently from adding Gaussian noise to the whole image.	I-Reply	I-5	Reply	335
For example, as shown in Table 1 in our paper, for a Resnet-50 model on ImageNet(-C), Patch Gaussian gets a clean test accuracy of 76% and mCE of 0.714, whereas Gaussian data augmentation gets a clean test accuracy of 75.6% and mCE of 0.739.	I-Reply	I-5	Reply	335

This paper proposes a hybrid approach for adding noise to training images of an image classification model.	O	O	Review	335
Instead of either cutting out a patch or adding gaussian noise, the authors propose to adding a patch of gaussian noise to the images.	B-Review	B-1	Review	335
Although possibly useful practically, this proposal lacks theoretical base on how and why it would be better, besides the claim that hopefully the combination will combine the benefit and subtract the weakness.	B-Review	B-2	Review	335
The experiments are rather limitted to support the claim.	B-Review	B-3	Review	335
&gt; Although possibly useful practically	O	O	Reply	335
<sep> We thank the reviewer for pointing out the practical applications of our method.	B-Reply	B-1	Reply	335
Indeed, because it is so simple, ‚Äúthe approach could become one of the standard mechanisms for data augmentation in the toolset of a practical ML engineer,‚Äù as R1 puts it.	I-Reply	I-1	Reply	335
<sep> <sep> &gt; this proposal lacks theoretical base on how and why it would be better	O	O	Reply	335
<sep> We grant that our work started from an empirical observation.	B-Reply	B-2	Reply	335
However, we provided an experimental analysis to gain a better understanding of why it works.	I-Reply	I-2	Reply	335
In particular, Section 5.1 shows that Patch Gaussian seems to allow high-frequency information through at lower layers, but still encourages relatively lower test error sensitivity at high frequencies.	I-Reply	I-2	Reply	335
Indeed, when we measure accuracy on images filtered with a high-pass filter, we see that Patch Gaussian models can maintain accuracy in a similar way to the baseline and to Cutout, where Gaussian fails to.	I-Reply	I-2	Reply	335
See Figure 5 for full results.	I-Reply	I-2	Reply	335
<sep> <sep> R1 and R2 agree that our Fourier-theoretic analysis is intuitive.	I-Reply	I-2	Reply	335
In addition, many practically useful techniques, such as Cutout, do not have completely rigorous mathematical analysis.	I-Reply	I-2	Reply	335
<sep> <sep> &gt; The experiments are rather limited to support the claim	O	O	Reply	335
<sep> We show extensive experiments highlighting how Patch Gaussian is the only method that retains the benefits of Cutout and Gaussian:	B-Reply	B-3	Reply	335
* We characterize a trade-off between robustness and accuracy among two standard data augmentations - Cutout and Gaussian (Section 2.1).	B-Reply	B-3	Reply	335
Specifically, Cutout improves accuracy on clean test data.	I-Reply	I-3	Reply	335
Despite this, we find it does not lead to increased robustness.	I-Reply	I-3	Reply	335
Conversely, training with higher sigma of Gaussian can lead to increased robustness to Gaussian noise, but it also leads to decreased accuracy on clean data.	I-Reply	I-3	Reply	335
Therefore, any robustness gains are offset by poor overall performance.	I-Reply	I-3	Reply	335
<sep> * We show that our method (Patch Gaussian) allows us to interpolate between the two augmentations above (Section 3.1), and to overcome the observed trade-off, yielding models that are robust to unseen corruptions, while also maintaining clean accuracy (Figure 1, Section 4.1).	B-Reply	B-3	Reply	335
In doing so, it achieves a new state of the art in the Common Corruptions benchmark on CIFAR-C and ImageNet-C. (Section 4.2), which highlights that simple methods such as ours are competitive with complex training schemes designed for robustness.	I-Reply	I-3	Reply	335
<sep> * We demonstrate that Patch Gaussian can be combined with other regularization strategies (Section 4.3) and data augmentation policies (Section 4.4), and can improve COCO object detection performance as well (Section 4.5).	B-Reply	B-3	Reply	335
<sep> * We perform a frequency-based analysis of models trained with Patch Gaussian and find that they can better leverage high-frequency information in lower layers, while not being too sensitive to them at later ones (Section 5.1)	B-Reply	B-3	Reply	335
<sep> We are open to suggestions of further experiment proposals that could convince the reviewer of this.	O	O	Reply	335

*Summary*	O	O	Review	10028
This paper leverages the piecewise linearity of predictions in ReLU neural networks to encode and learn piecewise constant predictors akin to oblique decision trees (trees with splits made on linear combinations of features instead of axis-aligned splits).	O	O	Review	10028
The core observation is that the Jacobian of a ReLU network is piecewise constant w.r.t to the input.	O	O	Review	10028
This Jacobian is chosen to encode the hard splits of a decision tree.	O	O	Review	10028
The paper establishes an exact equivalence between decision trees and a slightly modified form of the locally constant networks (LCN).	O	O	Review	10028
The LCN used for experiments is slightly relaxed to allow for training, including "annealing" from a the softplus nonlinearity to ReLU during training, adding one or more output layers to perform the final prediction, and training with connection dropout.	O	O	Review	10028
Experiments show LCN models outperform existing methods for oblique decision trees, but ensembles are often matched or outperformed by random forests.	O	O	Review	10028
<sep> <sep> *Rating*	O	O	Review	10028
Perhaps the greatest attribute of decision trees is utter simplicity. (	O	O	Review	10028
The second best attribute the out-of-the-box competitive accuracy of tree ensembles on a wide variety of problems.)	O	O	Review	10028
An argument to be made for this paper is that it leverages the machinery of learning DNNs to learn more powerful, oblique tree-like models.	O	O	Review	10028
The counterpoint is that despite the added complication, it's still often beaten by ensembles of CART trees.	O	O	Review	10028
Overall, the idea is clever, the presentation could be improved slightly, and the experiments raise existential questions for this kind of work.	O	O	Review	10028
My current rating is weak reject.	O	O	Review	10028
<sep> <sep> (1) It's difficult to know how LCNs should be compared to traditional decision trees, with accuracy, number of parameters, prediction speed, and training time/parallelism as viable components.	B-Review	B-1	Review	10028
The paper focuses almost exclusively on accuracy, while cross-validating over model sizes and other hyperparameters.	I-Review	I-1	Review	10028
This is a reasonable choice, though a discussion of model size and prediction speed would be welcome.	I-Review	I-1	Review	10028
I do have two significant questions about the experiments:	I-Review	I-1	Review	10028
<sep> (2) It seems unfair that LCN has access to one or more hidden layers between the splits and the final output, denoted g_\phi.	B-Review	B-2	Review	10028
Would competing decision tree models improve with such a layer learned and appended to the final tree?	I-Review	I-2	Review	10028
Would LCN suffer from using a tabular representation like the others?	I-Review	I-2	Review	10028
<sep> <sep> (3) Despite the assertion that these are datasets that necessitate tree-like predictors, the LLN method outperforms LCN and the trees on 4/5 datasets and is competitive with ensemble methods.	B-Review	B-3	Review	10028
While not explicitly stated, am I correct that LLN is essentially a traditional ReLU-network?	I-Review	I-3	Review	10028
If high accuracy is the goal, then why should I go to the trouble of training LCN when a traditional DNN is better.	I-Review	I-3	Review	10028
And if a tree is needed, then LCNs should be evaluated on more than just accuracy.	I-Review	I-3	Review	10028
<sep> <sep> (4) LCNs seem to present a less bulky alternative to e.g. Deep Neural Decision Trees (<a href="https://arxiv.org/abs/1806.06988)," target="_blank" rel="nofollow">https://arxiv.org/abs/1806.06988),</a> but that work should be cited and discussed	B-Review	B-4	Review	10028
<sep> (5) The proof sketch in Section 3.6 of the equivalence between the "standard architecture" and decision trees is difficult to understand and not convincing. (	B-Review	B-5	Review	10028
On second reading I noticed the subtle vector "\mathbf 0" indicating that all entries of "\grad_x a^i_1" are zero.	I-Review	I-5	Review	10028
Some further exposition and enumeration of steps would clear up confusion.)	I-Review	I-5	Review	10028
<sep> <sep> (6) Overall the presentation is reasonable, other than the notes below.	B-Review	B-6	Review	10028
I did find myself searching back over the (dense) notation section and following sections looking for definitions of variables and terms used later.	I-Review	I-6	Review	10028
Consider better formatting (e.g. more definitions in standalone equations), strategic pruning of some material to make it less dense, and repeating some definitions in line (e.g. see below for "p7:... remind the reader").	I-Review	I-6	Review	10028
<sep> <sep> *Notes*	B-Review	B-6	Review	10028
(Spelling typos throughout; most are noted below)	I-Review	I-6	Review	10028
p3: clarify in 3.1/3.3 that L is the number of outputs	I-Review	I-6	Review	10028
p4: "interpred"	I-Review	I-6	Review	10028
p5: "aother"	I-Review	I-6	Review	10028
p5: Theorem 2 proof: note that the T/T' notation is capturing left/right splits	I-Review	I-6	Review	10028
p5: "netwoworks"	I-Review	I-6	Review	10028
p5: "Remark 5 is important for learning shallow...": should "shallow" be "narrow" instead?	I-Review	I-6	Review	10028
<sep> p7: in the first paragraph, remind the reader of the definitions of √µ^M and J_x √£^M	I-Review	I-6	Review	10028
p7: "Here we provide a sketch of [the] proof"	I-Review	I-6	Review	10028
p7: "unconstraint" should be "unconstrained"	I-Review	I-6	Review	10028
p7: "...can construct a [sufficiently expressive] network g_\theta"	I-Review	I-6	Review	10028
p7: "simlify"	I-Review	I-6	Review	10028
p9: Table 2: instead of "2nd row", ..., use "1st section", ...; also consider noting which methods are introduced in this paper	I-Review	I-6	Review	10028
p9: Figure 2: text is too small	I-Review	I-6	Review	10028
<sep> (2) In short, we have the following ordering of expressiveness *given a fixed depth*: oblique decision trees &gt; canonical (tabular) LCNs &gt;= standard LCNs.	B-Reply	B-2	Reply	10028
<sep> <sep> Note that each activation pattern of f yield a *constant* Jacobian, so we can write the Jacobian as Jacobian(o(x)), where o is the activation pattern of x.	I-Reply	I-2	Reply	10028
<sep> Then, standard LCNs can be written as the mapping:	I-Reply	I-2	Reply	10028
g_\phi(Jacobian(o(x))).	I-Reply	I-2	Reply	10028
<sep> In contrast, canonical (tabular) LCNs yield the mapping:	I-Reply	I-2	Reply	10028
<tab>g(o(x)).	I-Reply	I-2	Reply	10028
<sep> Hence, the tabular case cannot be less powerful than using embeddings (Jacobians), since we can always set the table as g(  ) = g_\phi(Jacobian(  )).	I-Reply	I-2	Reply	10028
<sep> <sep> By the proof of Theorem 3, we can again transform such tabular LCN to a decision tree with the same depth, so the canonical LCNs are not more powerful than oblique decision trees.	I-Reply	I-2	Reply	10028
Furthermore, due to how the locally linear regions of f can be partitioned, canonical LCNs are strictly less powerful than oblique decision trees given a fixed depth M as proved in Sec.3.5.	I-Reply	I-2	Reply	10028
<sep> <sep> Hence, we obtain the claimed ordering.	I-Reply	I-2	Reply	10028
In fact, by Theorem 8 (updated, originally given as a sketch of proof), we can even prove standard LCNs = canonical LCNs.	I-Reply	I-2	Reply	10028
<sep> <sep> <sep> (3) Yes, LLNs are ReLU networks.	B-Reply	B-3	Reply	10028
The point of including LLN is to compare it with ALCN, since both are continuous functions and thus much more powerful than tree methods.	I-Reply	I-3	Reply	10028
We show that ALCN often outperforms LLN.	I-Reply	I-3	Reply	10028
<sep> <sep> If high accuracy is the only goal, currently random forests work well for these chemical/tabular data, outperforming neural networks with ReLU activations by a large margin.	I-Reply	I-3	Reply	10028
However, please see our general response above for why LCN still provides new insights in this setting.	I-Reply	I-3	Reply	10028
<sep> <sep> If a tree model is needed, clearly LCNs are much better than traditional oblique decision trees: we can often get 10% absolute improvements in testing AUC.	I-Reply	I-3	Reply	10028
Since LCN can always be explicitly converted to an oblique decision tree, the only difference *in testing time* between oblique decision trees and LCNs is the accuracy.	I-Reply	I-3	Reply	10028
Other factors are discussed in (1).	I-Reply	I-3	Reply	10028
<sep> <sep> (4) Thank you for the reference.	B-Reply	B-4	Reply	10028
It seems a relevant paper that also uses deep networks to learn decision trees.	I-Reply	I-4	Reply	10028
The paper focused on axis-parallel decisions (traditional decision trees), while we work on oblique decisions.	I-Reply	I-4	Reply	10028
We will cite and discuss the paper in the camera-ready version.	I-Reply	I-4	Reply	10028
<sep> <sep> (5) Thank you for the feedback.	B-Reply	B-5	Reply	10028
The sketch of the proof is now replaced by a formal theorem with proof in Appendix A.2.	I-Reply	I-5	Reply	10028
<sep> <sep> (6) and *Notes*: Thank you for the comments.	B-Reply	B-6	Reply	10028
The typos have been addressed, and we will improve the other presentation issues in later revision.	I-Reply	I-6	Reply	10028
<sep> <sep> Re "Remark 5 is important for learning shallow..." Thank you for pointing this out.	B-Reply	B-6	Reply	10028
Here we meant that given a fixed number of neurons, the one neuron per layer setting is the most powerful architecture.	I-Reply	I-6	Reply	10028
<sep> <sep> Minor technical clarification: we ‚Äúanneal‚Äù LCNs during training, but the LCNs used in testing time are indeed piece-wise constant (not relaxed).	B-Reply	B-6	Reply	10028
Adding any number of layers mapping from the Jacobian to the prediction does not affect the piece-wise constant nature.	I-Reply	I-6	Reply	10028

This paper proposes locally constant network (LCN), which is implemented via the gradient of piece-wise linear networks such as ReLU networks.	O	O	Review	10028
The authors built the equivalence between LCN and decision trees, and also demonstrated that LCN with M neurons has the same representation capability as decision trees with 2^M leaf nodes.	O	O	Review	10028
The experiments conducted in the paper disclose that training LCN outperforms other methods using decision trees.	O	O	Review	10028
<sep> <sep> The detailed comments are as follows:	O	O	Review	10028
<sep> 1) The idea of LCN is very interesting, and the equivalence to decision trees is also very valuable, as it provides interpretability and shines light on new training algorithms.	O	O	Review	10028
<sep> <sep> 2) The derivation of LCN and the equivalence is clear.	O	O	Review	10028
The analysis based on the shared parameterization in Section 3.5 is helpful to understand why LCN with M neurons could be of equal capability to decision trees with 2^M leaf nodes.	O	O	Review	10028
<sep> <sep> 3) One weakness is that the performance of ELCN seems to be very close to RF, as shown in Table 2.	B-Review	B-1	Review	10028
<sep> <sep> I am not sure whether some similar ideas to LCN have been explored in the literature.	O	O	Review	10028
But the topic studied in this work is very valuable, which connects deep neural networks and decision trees.	O	O	Review	10028
<sep> <sep> We thank the reviewer for the insightful comments and suggestions.	O	O	Reply	10028
Please see our response to a common comment above.	O	O	Reply	10028

In this paper, the authors proposed an approach to fit locally constant functions using deep neural networks (DNNs).	O	O	Review	10028
<sep> The idea is based on the fact that DNN consisting of only linear transformations and ReLU activations is piecewise linear.	O	O	Review	10028
<sep> Thus, the derivative of such a network with respect to the input is locally constant.	O	O	Review	10028
<sep> <sep> In the paper, the authors focused on connecting the locally constant network with oblique decision trees.	O	O	Review	10028
<sep> Specifically, they proved that these two models are in some sense equivalent, and one can transform one model to another.	O	O	Review	10028
<sep> This connection enables us to train the oblique decision trees by training the locally constant network instead.	O	O	Review	10028
<sep> Because the locally constant network can be trained using the gradient-based methods, it would be much easier to train than the oblique decision trees.	O	O	Review	10028
<sep> <sep> I think the paper is well-written and the idea is clear.	O	O	Review	10028
<sep> Connecting the locally constant network with oblique decision trees looks interesting.	O	O	Review	10028
<sep> <sep> I have one concern, however.	B-Review	B-1	Review	10028
<sep> The authors mention that the training of oblique decision trees is difficult, and the use of the locally constant network is helpful.	I-Review	I-1	Review	10028
<sep> If I understand correctly, oblique decision tree is one specific instance of the hierarchical mixtures of experts.	I-Review	I-1	Review	10028
<sep> And, [Ref1] pointed out that the hierarchical mixtures of experts can be trained using EM algorithm, which is another type of the gradient-based training.	I-Review	I-1	Review	10028
<sep> The current paper misses such a prior study.	I-Review	I-1	Review	10028
<sep> I am interested in to see if the use of locally constant network is truly effective for training oblique decision trees over the algorithms considered in the literatures of hierarchical mixtures of experts.	I-Review	I-1	Review	10028
<sep> <sep> [Ref1] Hierarchical mixtures of experts and the EM algorithm	I-Review	I-1	Review	10028
<sep> <sep> ### Updated after author response ###	O	O	Review	10028
The authors have successfully demonstrated that the proposed approach is better than the EM-like classical approaches.	B-Review	B-2	Review	10028
I therefore keep my score.	O	O	Review	10028
We thank the reviewer for the insightful comments and suggestions.	O	O	Reply	10028
<sep> <sep> To clarify the concern, there is a fundamental difference between hierarchical mixtures of experts (HMEs) and oblique decision trees.	B-Reply	B-1	Reply	10028
HMEs use softmax units instead of decision units in non-terminal nodes, so HMEs only approach oblique decision trees in the theoretical limit.	I-Reply	I-1	Reply	10028
Hence, HMEs realize continuous functions instead of piece-wise constant functions as oblique decision trees.	I-Reply	I-1	Reply	10028
<sep> <sep> There are some practical advantages of using oblique decision trees over HMEs-style (soft) decision trees.	I-Reply	I-1	Reply	10028
For example, it requires a full tree traversal for HMEs to make a prediction in O(2^M) where M denotes the tree depth, while it only takes O(M) for oblique decision trees to make a prediction.	I-Reply	I-1	Reply	10028
Moreover, being piece-wise constant allows us to tractably compute some useful inference problems like ‚Äúwhat is the feasible region of input space that leads to a specific prediction value / diagnosis‚Äù.	I-Reply	I-1	Reply	10028
<sep> <sep> Nevertheless, we can still do an empirical comparison with HMEs.	I-Reply	I-1	Reply	10028
We use the HME implementation with the most stars on GitHub: <a href="https://github.com/AmazaspShumik/Mixture-Models" target="_blank" rel="nofollow">https://github.com/AmazaspShumik/Mixture-Models</a>	I-Reply	I-1	Reply	10028
<sep> Even with parallel computing on 16 CPUs, the implementation is still prohibitively slow due to the inherent complexity of the HME learning algorithm (exponential to tree depth), and we can only obtain some early results on small datasets.	I-Reply	I-1	Reply	10028
The experiment protocol is the same.	I-Reply	I-1	Reply	10028
We tune the depth in {2,3,...,12} by validation set, and report the testing performance of the tuned model.	I-Reply	I-1	Reply	10028
<sep> <sep> We report (mean ¬± std) of testing AUC score over multiple runs.	I-Reply	I-1	Reply	10028
<sep> Bace:	I-Reply	I-1	Reply	10028
HME (4 runs):    0.706 ¬± 0.009	I-Reply	I-1	Reply	10028
LCN (10 runs):   0.839 ¬± 0.013	I-Reply	I-1	Reply	10028
ALCN (10 runs): 0.854 ¬± 0.007	I-Reply	I-1	Reply	10028
<sep> Sider:	I-Reply	I-1	Reply	10028
HME (1 run):      0.582 ¬± 0.000	I-Reply	I-1	Reply	10028
LCN (10 runs):   0.624 ¬± 0.044	I-Reply	I-1	Reply	10028
ALCN (10 runs): 0.653 ¬± 0.044	I-Reply	I-1	Reply	10028
<sep> Empirically, HME performs much worse than the proposed LCN and ALCN models.	I-Reply	I-1	Reply	10028
<sep> <sep> It takes 4.5 hours to train an HME on the Bace dataset with depth = 12, and it takes 42.3 hours on the HIV dataset with depth = 6, so we cannot report the complete experiments for the other datasets during rebuttal.	I-Reply	I-1	Reply	10028
To see the exponential time complexity:	I-Reply	I-1	Reply	10028
<sep> HMEs training time on the HIV dataset.	I-Reply	I-1	Reply	10028
<sep> Depth = 3:   5.0 hours	I-Reply	I-1	Reply	10028
Depth = 4:  11.1 hours	I-Reply	I-1	Reply	10028
Depth = 5:  23.7 hours	I-Reply	I-1	Reply	10028
Depth = 6:  42.3 hours	I-Reply	I-1	Reply	10028

Overview:	O	O	Review	10041
The authors proposed a weakly-supervised method to localize video moments given text queries.	O	O	Review	10041
The model builds multi-level relational graphs among pairs of word and video frame, and the graph is used to aggregate visual-semantic feature for each word and each frame.	O	O	Review	10041
Then the attentive features are used to localize the sentence query in videos by calculating the similarity of words and frames.	O	O	Review	10041
In summary, the proposed weakly-supervised Moment Alignment Network (wMAN) utilizes a multi-level co-attention mechanism to learn richer multimodal representations for language based video retrieval..	O	O	Review	10041
<sep> Pros:	O	O	Review	10041
1.	O	O	Review	10041
Significant performance improvement on Didemo and Charades-STA datasets.	O	O	Review	10041
The authors achieved very good performance on both dataset, even higher than some of the full-supervision methods, such as CTRL and MLVI.	O	O	Review	10041
<sep> <sep> Cons:	O	O	Review	10041
1.	O	O	Review	10041
The overall novelty of the proposed methods is limited.	B-Review	B-1	Review	10041
Essentially, the key points of the model is hierarchical visual semantic co-attention.	I-Review	I-1	Review	10041
,which is proposed originally in [Hierarchical Question-Image Co-Attention	I-Review	I-1	Review	10041
for Visual Question Answering], although the original application is VQA in image domain.	I-Review	I-1	Review	10041
So in this way, the novelty is only marginal.	I-Review	I-1	Review	10041
<sep> 2.	O	O	Review	10041
Paper writing can be improved.	B-Review	B-2	Review	10041
Figure 2 shows the overall structure of the model, however, the caption doesn't explain all the notations in the figure, such as WCVG, and the equations.	I-Review	I-2	Review	10041
Additionally, the reference is very far away from Figure 2, which makes the whole paper hard to read.	I-Review	I-2	Review	10041
<sep> 3.	O	O	Review	10041
For evaluation part, one important ablation study is missing: the number of steps T for message passing.	B-Review	B-3	Review	10041
This eval is important, as it shows the necessity of using "multi-level" attention.	I-Review	I-3	Review	10041
<sep> <sep> Minor comments:	O	O	Review	10041
1.	B-Review	B-4	Review	10041
Make the caption of Figure 2 self-explainable, e.g. the meaning of LSE.	I-Review	I-4	Review	10041
<sep> 2.	I-Review	I-4	Review	10041
There is a "word-conditioned" visual graph network, why not the other way, "frame-conditioned" semantic graph net and iterate over it?	I-Review	I-4	Review	10041
<sep> <sep> Thank you for your review.	O	O	Reply	10041
We address your concerns below.	O	O	Reply	10041
<sep> <sep> 1) This is addressed in the general response.	B-Reply	B-1	Reply	10041
<sep> <sep> 2) We will update the next version of the paper with the necessary clarifications to the caption and modifications.	B-Reply	B-2	Reply	10041
<sep> <sep> 3) We have updated the submission with an ablation study of how the number of message-passing steps affects the performance of our proposed approach.	B-Reply	B-3	Reply	10041
They are included in Section B of the appendix.	I-Reply	I-3	Reply	10041
In our experiments across both Charades-Sta and DiDeMo, we have observed that 3 steps work the best.	I-Reply	I-3	Reply	10041
<sep> <sep> We hope that we have addressed your concerns satisfactorily.	O	O	Reply	10041
Please let us know if you have any further concerns or questions.	O	O	Reply	10041

This work presents a model for text based video clip (video moments or text-to-clip) retrieval.	O	O	Review	10041
The goal is to identify a video segment within a longer video that is most relevant to an input sentence.	O	O	Review	10041
Authors propose a new model based on a weakly-supervised training approach.	O	O	Review	10041
This model does not require explicit temporal annotations to align text and video, but it only needs as an input the full video and sentence pairs.	O	O	Review	10041
<sep> <sep> Key aspects of the model are: i) A coattention step frame-by-word and word-by-frame that produces the basic embeddings of the model, which is enriched with positional information, and ii) A contextual step that aggregates contextual information from all the frames using graph propagation.	O	O	Review	10041
Afterwards, they use a  LogSumExp pooling strategy to score similarity among the input sentence and video frame.	O	O	Review	10041
<sep> The main contribution of the paper is incremental (specially respect to Mithun et al 2019), I do not see a ground-breaking contribution.	B-Review	B-1	Review	10041
One of the main novelties with respect to previous text-to-clip models is the use of co-attention schemes at the level of words and frames.	I-Review	I-1	Review	10041
However, the idea of co-attention at different grain-levels have been proposed before.	I-Review	I-1	Review	10041
Actually, while the model makes an extensive use of frame-to-word encoding, it is not clear to me what is the role of the word-to-video representation in Eqs.	I-Review	I-1	Review	10041
5 and 6.	I-Review	I-1	Review	10041
<sep> <sep> In general, the paper is well written.	B-Review	B-2	Review	10041
The experimental evaluation is convincing.	I-Review	I-2	Review	10041
However, it is not clear why authors change the structure of the evaluation among the experiments.	I-Review	I-2	Review	10041
As an example, for the experiments in Charades-STA dataset, they include scores for different IOUs levels, but they do not repeat this for DiDeMo dataset.	I-Review	I-2	Review	10041
Similarly, for DiDeMo dataset, results in Table 3 are for the test set, while the ablation study in Table 4 is for the validation set.	I-Review	I-2	Review	10041
I will recommend to standardize the evaluations.	I-Review	I-2	Review	10041
<sep> <sep> Another comment is that in several experiment best performance is obtained using just the FBW module, it will be interesting to further analyze why the contextual cues hurt performance in some cases, maybe at least a qualitative analysis.	B-Review	B-3	Review	10041
Also, in some part of the papers, authors state that the proposed model does better than strongly-supervised state-of-the-art methods on some metrics, looking all the reported tables, I do not think that this is the case.	I-Review	I-3	Review	10041
Authors show qualitative results about cases where the model perform well, it will be good to also analyze failure cases, actually, according to the final scores, there is still lot of cases that the model can't handle properly.	I-Review	I-3	Review	10041
<sep> <sep> I rate the paper as borderline, but there is not such a rating at ICLR 2020, so I will lean to weak reject.	O	O	Review	10041
Thank you for your review.	O	O	Reply	10041
We address your concerns below.	O	O	Reply	10041
<sep> <sep> - The main contribution of the paper is incremental (specially respect to Mithun et al 2019), I do not see a ground-breaking contribution.	O	O	Reply	10041
One of the main novelties with respect to previous text-to-clip models is the use of co-attention schemes at the level of words and frames.	O	O	Reply	10041
<sep> <sep> We address this in the general response.	B-Reply	B-1	Reply	10041
<sep> <sep> - Actually, while the model makes an extensive use of frame-to-word encoding, it is not clear to me what is the role of the word-to-video representation in Eqs.	O	O	Reply	10041
5 and 6.	O	O	Reply	10041
<sep> <sep> We describe its purpose in the beginning paragraph of Section 3.2.	B-Reply	B-1	Reply	10041
It is concatenated with the word embedding to create a new visual-semantic representation, which is next used to update the visual representations iteratively during message-passing as shown in equation 7.	I-Reply	I-1	Reply	10041
The intuition is that the word-specific representations help to convey contextual visual information derived from other video frames.	I-Reply	I-1	Reply	10041
We will update the next version of the paper to make it clearer.	I-Reply	I-1	Reply	10041
<sep> <sep> - However, it is not clear why authors change the structure of the evaluation among the experiments.	O	O	Reply	10041
<sep> <sep> We adopt the same evaluate metrics and practices as prior work to enable direct comparison.	B-Reply	B-2	Reply	10041
Scores for different IOU thresholds are used on the Charades-Sta dataset while scores for only IOU=0.5 are used on DiDeMo.	I-Reply	I-2	Reply	10041
With respect to the ablation experiments not being evaluated on the test set, we followed the standard protocol of finetuning hyperparameters and evaluating model components on the validation set.	I-Reply	I-2	Reply	10041
This is more realistic in the real world where we usually do not have access to the test set in practice.	I-Reply	I-2	Reply	10041
We do have the ablation results on the test set too but we left them out due to space constraints.	I-Reply	I-2	Reply	10041
However, we have added them to the Appendix in Tables 8 and 9.	I-Reply	I-2	Reply	10041
<sep> <sep> - It will be interesting to further analyze why the contextual cues hurt performance in some cases, maybe at least a qualitative analysis.	O	O	Reply	10041
<sep> <sep> It appears that contextual cues generally help to improve retrieval accuracy on harder settings such as higher IOU thresholds and Recall@1 accuracies.	B-Reply	B-3	Reply	10041
Using just the FBW module leads to better performance only on the lowest IOU threshold and Recall@5 and Recall@10 accuracies.	I-Reply	I-3	Reply	10041
We observe the same consistency in our ablation experiments on DiDeMo as well.	I-Reply	I-3	Reply	10041
We hypothesize that these cues help to make our model more discriminative in harder settings which is arguably more practical for real-world applications such as in video search engines.	I-Reply	I-3	Reply	10041
Finally, the overall performance of wMAN is better than that of the FBW module.	I-Reply	I-3	Reply	10041
If we average the scores, we obtain 57.0% and 58.2% for the FBW module and wMAN respectively.	I-Reply	I-3	Reply	10041
<sep> <sep> - In some part of the papers, authors state that the proposed model does better than strongly-supervised state-of-the-art methods on some metrics	O	O	Reply	10041
<sep> In Table 3, we show that we outperform the strongly-supervised methods by 10% on the Recall@1 metric.	B-Reply	B-3	Reply	10041
We have clarified this in the paper.	I-Reply	I-3	Reply	10041
<sep> <sep> We hope that we have addressed your concerns satisfactorily.	O	O	Reply	10041
Please let us know if you have any further concerns or questions.	O	O	Reply	10041

The paper proposed a weakly-supervised wMAN model for moment localization in untrimmed videos.	O	O	Review	10041
Only the video-level annotation is available for training, and the goal is retrieving the video segment described by the sentence.	O	O	Review	10041
The proposed model explored to utilize better context information and captured the relation between video and sentence/word via graph neural networks.	O	O	Review	10041
In particular, instead of modeling the context information between the sentence and each video frame, wMAN tried to learn the representation with multi-level and co-attention, which considers all possible pairs between the word and the frame.	O	O	Review	10041
The proposed model was evaluated on two publicly-available dataset and achieved reasonable results.	O	O	Review	10041
<sep> <sep> Pros:	O	O	Review	10041
- Weakly-supervised method for video moment localization is a reasonable and important direction.	O	O	Review	10041
<sep> - wMAN explicitly utilized multi-level context information between the sentence and the video frame, and used the graph neural network and the message passing to model the representation.	O	O	Review	10041
I think this is a reasonable direction.	O	O	Review	10041
<sep> - wMAN is evaluated with two publicly available datasets, and is compared with state-of-the-art methods and other "oracle" baselines.	O	O	Review	10041
The performance is impressive and could be a better baseline for the future work.	O	O	Review	10041
<sep> <sep> Cons:	O	O	Review	10041
- wMAN model the relation for all possible pairs of the word and the video frame.	B-Review	B-1	Review	10041
However, if the video is quite long, say 10 minutes, 30 minutes, or even few hours, will the method still be efficient and effective?	I-Review	I-1	Review	10041
<sep> - When building the relation between the word and the frame, is there any emphasis on verb, some particular word, or self-learned attention?	B-Review	B-2	Review	10041
For some particular word, say "people" and "cup", won't it have strong connection with many frames?	I-Review	I-2	Review	10041
But for some of the words, say "hold" and "sits", could it play a more important role?	I-Review	I-2	Review	10041
<sep> - Followed by previous question, in the qualitative results, it seems the boundary parts of the predicted video segments are less accurate.	B-Review	B-3	Review	10041
Is it because some of the words case these false positive results?	I-Review	I-3	Review	10041
What do you think the reason is?	I-Review	I-3	Review	10041
<sep> - Experimental results: I suggest the author to provide more ablation analysis to the experiment section.	B-Review	B-4	Review	10041
For example, the full model of wMAN works better than FBW on R@1, but worse on R@5 and R@10.	I-Review	I-4	Review	10041
Is there a particular reason about this?	I-Review	I-4	Review	10041
PE seems to be important for wMAN, and the authors provides few sentences analysis about this, but I don't think I fully understand this part.	I-Review	I-4	Review	10041
Another problem is that there is only few qualitative results, and in both these two examples, predicted results cover the GT segments.	I-Review	I-4	Review	10041
Is this always the case for wMAN?	I-Review	I-4	Review	10041
Why?	I-Review	I-4	Review	10041
Some failure cases could also be very helpful.	I-Review	I-4	Review	10041
<sep> - Less technical comments: The paper writing is fine to me, but I don't like the typesetting.	B-Review	B-5	Review	10041
I suggest to put the model figure more close to the methodology section and the qualitative results on page 8.	I-Review	I-5	Review	10041
<sep> <sep> Overall, I think the paper is marginal above the accept line.	O	O	Review	10041
Thank you for your review.	O	O	Reply	10041
We address your concerns below.	O	O	Reply	10041
<sep> <sep> - wMAN model the relation for all possible pairs of the word and the video frame.	O	O	Reply	10041
However, if the video is quite long, say 10 minutes, 30 minutes, or even few hours, will the method still be efficient and effective?	O	O	Reply	10041
<sep> <sep> Computing effective video representations for long videos efficiently is still an unsolved problem in computer vision.	B-Reply	B-1	Reply	10041
There is a lot of ongoing work in this area.	I-Reply	I-1	Reply	10041
With this said, based on the observed memory requirements of our proposed approach during inference, the efficiency and effectiveness of our method should be scalable to videos lasting a few minutes.	I-Reply	I-1	Reply	10041
As mentioned before, reasoning about videos lasting a few hours efficiently and effectively is still an unsolved research topic.	I-Reply	I-1	Reply	10041
However, with increased computational resources, there is no reason to believe that our method is not scalable to such videos.	I-Reply	I-1	Reply	10041
One possible solution is to reduce the sampling rate of video frame.	I-Reply	I-1	Reply	10041
Another option is to break the video into smaller parts and localize within each part individually.	I-Reply	I-1	Reply	10041
Finding a way to reason about long videos and natural language effectively from a low frame sampling rate in this task provides an interesting avenue for future work.	I-Reply	I-1	Reply	10041
<sep> <sep> - When building the relation between the word and the frame, is there any emphasis on verb, some particular word, or self-learned attention?	O	O	Reply	10041
<sep> <sep> The motivation behind the frame-by-word interaction mechanism in our approach is that it encourages the model to learn the association between words and action sequences in videos.	B-Reply	B-2	Reply	10041
Words such as ‚Äòhold‚Äô and ‚Äòsits‚Äô definitely play a much more important role in localizing the relevant temporal segment in videos.	I-Reply	I-2	Reply	10041
For example, in Figure 3b, we observe that the top 3 weights assigned to each frame for ‚Äòperson‚Äô and ‚Äòchair‚Äô generally occur in tandem with ‚Äòsits‚Äô and ‚Äòdown‚Äô.	I-Reply	I-2	Reply	10041
This demonstrates that our model learns the association between verbs and entities via self-learned attention.	I-Reply	I-2	Reply	10041
This is consistent with our observations in Figure 3a as well.	I-Reply	I-2	Reply	10041
<sep> <sep> - Followed by previous question, in the qualitative results, it seems the boundary parts of the predicted video segments are less accurate.	O	O	Reply	10041
<sep> <sep> One possible reason is that we are using non-overlapping segments as proposals on Charades-Sta to facilitate fair comparison with prior work.	B-Reply	B-3	Reply	10041
Given that these proposals have static boundaries, it will cause the boundary parts of the candidate proposals to be less accurate.	I-Reply	I-3	Reply	10041
<sep> <sep> - Experimental results: I suggest the author to provide more ablation analysis to the experiment section.	O	O	Reply	10041
<sep> <sep> It appears that contextual cues generally help to improve retrieval accuracy on harder settings such as higher IOU thresholds and Recall@1 accuracy.	B-Reply	B-4	Reply	10041
Using just the FBW module leads to better performance only on the lowest IOU threshold and Recall@5 and Recall@10 accuracies.	I-Reply	I-4	Reply	10041
We observe the same consistency in our ablation experiments on DiDeMo as well.	I-Reply	I-4	Reply	10041
We hypothesize that these cues help to make our model more discriminative in harder settings which is arguably more practical for real-world applications such as in video search engines.	I-Reply	I-4	Reply	10041
Finally, the overall performance of wMAN is better than that of the FBW module.	I-Reply	I-4	Reply	10041
If we average the scores, we obtain 57.0% and 58.2% for the FBW module and wMAN respectively.	I-Reply	I-4	Reply	10041
<sep> <sep> - Less technical comments	O	O	Reply	10041
<sep> We will update the next version of the paper with the necessary clarifications and modifications.	B-Reply	B-5	Reply	10041
<sep> <sep> We hope that we have addressed your concerns satisfactorily.	O	O	Reply	10041
Please let us know if you have any further concerns or questions.	O	O	Reply	10041

<sep> Summary:	O	O	Review	10041
This paper proposes a method for aligning an input text with the frames in a video that correspond to what the text describes in a weakly supervised way.	O	O	Review	10041
The authors propose a combination of a ‚ÄúFrame-By-Word‚Äù (FBW) representation and a Word-Conditioned Visual Graph (WCVG).	O	O	Review	10041
The proposed method outperforms the weakly supervised baseline presented in the paper in experiments by a large margin.	O	O	Review	10041
In addition, it quantitatively performs close to previous strongly supervised methods.	O	O	Review	10041
<sep> <sep> <sep> Pros:	O	O	Review	10041
+ New Word-Conditioned Visual Graph representation	O	O	Review	10041
+ Outperforms weakly supervised baseline	O	O	Review	10041
+ Ablation study of the moving parts	O	O	Review	10041
+ Interesting use of positional embeddings for multi-modal learning	O	O	Review	10041
<sep> Weaknesses / comments:	O	O	Review	10041
- What is the processing speed of the method compared to the baseline?	B-Review	B-1	Review	10041
<sep> The proposed method makes multiple comparisons while computing the attention weights over all words and frames.	I-Review	I-1	Review	10041
Does this cause the method to be slower than the baseline?	I-Review	I-1	Review	10041
If so, how much slower is it?	I-Review	I-1	Review	10041
<sep> Answers to these questions can help readers to keep in mind the trade-off of the proposed method for achieving the accuracy presented in the paper.	I-Review	I-1	Review	10041
<sep> <sep> <sep> - Number of parameters comparison with baseline:	B-Review	B-2	Review	10041
Did the authors make sure to have similar number of model parameters for the baselines and the proposed method?	I-Review	I-2	Review	10041
Maybe I missed it, but I couldn‚Äôt see a mention of this anywhere.	I-Review	I-2	Review	10041
It would be useful to state this so that readers are sure that it‚Äôs not the number of parameters that is helping the method.	I-Review	I-2	Review	10041
<sep> <sep> <sep> - Assumption that sentences are only associated with its ground truth video:	B-Review	B-3	Review	10041
The authors mention that they have the same assumption as Mithun et al 2019.	I-Review	I-3	Review	10041
Can this assumption be detrimental if the dataset does not follow it?	I-Review	I-3	Review	10041
Say there are sentences in the dataset that could describe segments in multiple videos.	I-Review	I-3	Review	10041
Could this assumption lead to suboptimal representation learning / relationship learning for words / video frames?	I-Review	I-3	Review	10041
<sep> <sep> - Determining the size of the sliding window:	B-Review	B-4	Review	10041
From reading the paper, it looks like the sliding window used for computing the word / frame relationships has to be manually defined.	I-Review	I-4	Review	10041
This seems a bit suboptimal for the generalizability of this method.	I-Review	I-4	Review	10041
Do the authors have any comments on this?	I-Review	I-4	Review	10041
<sep> <sep> - Can this model be supervised?	B-Review	B-5	Review	10041
If so, how does it compare to the supervised baselines?	I-Review	I-5	Review	10041
<sep> The authors point out that their weakly supervised method performs close to the strongly supervised previously proposed.	I-Review	I-5	Review	10041
This is a nice finding, however, have the authors try to answer the question of what would happen if the proposed model is supervised?	I-Review	I-5	Review	10041
Will the proposed model outperform the strongly supervised baselines?	I-Review	I-5	Review	10041
Or at least perform the same?	I-Review	I-5	Review	10041
<sep> <sep> Conclusion:	O	O	Review	10041
In conclusion, the proposed method makes sense and it has been shown to empirically outperforms a previous weakly supervised baseline.	O	O	Review	10041
The authors also provide an ablation study of the moving parts to show that the entire pipeline is important to achieve the highest performance in the hardest setting.	O	O	Review	10041
It would be nice if the authors successfully answer / address the questions / concerns mentioned above in the rebuttal.	O	O	Review	10041
Thank you for your review.	O	O	Reply	10041
We address your concerns below.	O	O	Reply	10041
<sep> <sep> - What is the processing speed of the method compared to the baseline?	O	O	Reply	10041
<sep> <sep> In our measurements, the TGA method takes approximately 4.725s to process a single query.	B-Reply	B-1	Reply	10041
In contrast, the FBW module and our combined model (wMAN) take 4.329s and 8.102s respectively.	I-Reply	I-1	Reply	10041
As evident, the difference in processing time is not significant.	I-Reply	I-1	Reply	10041
However, if speed were really a huge concern, using the FBW module alone would provide a much faster processing time as well as improved results over the TGA method.	I-Reply	I-1	Reply	10041
For reference, the TGA model obtains an average recall accuracy of 49.8% while the FBW module achieves 57.0%.	I-Reply	I-1	Reply	10041
<sep> <sep> - Number of parameters comparison with baseline	O	O	Reply	10041
<sep> The TGA model contains about 3M parameters while wMAN contains 18M parameters.	B-Reply	B-2	Reply	10041
However, the large performance gains are not directly attributed to the increase in parameters.	I-Reply	I-2	Reply	10041
To prove this, we increase the dimensions of feature representations as well as relevant fully-connected layers in TGA such that the total number of parameters becomes 19M. We evaluate this model on Charades-Sta and the results are provided in Table 5 in the appendix.	I-Reply	I-2	Reply	10041
As evident, even with more parameters than our model, it still does substantially worse than ours.	I-Reply	I-2	Reply	10041
To add on to this, our direct adaptation of the Language-Conditioned Graph Network (also provided in Table 5), which has 152M parameters, also yields results inferior to ours.	I-Reply	I-2	Reply	10041
Finally, we also decrease the number of parameters in the FBW module alone to 3M and its performance gain over the TGA model is still significant.	I-Reply	I-2	Reply	10041
<sep> <sep> - Assumption that sentences are only associated with its ground truth video	O	O	Reply	10041
<sep> This assumption does add random noise to the training process.	B-Reply	B-3	Reply	10041
However, there is a higher probability of assigning a non-relevant sentence that does not correspond to its ground truth video than to the contrary.	I-Reply	I-3	Reply	10041
With that said, this assumption is also often used in tasks such as image-sentence retrieval or phrase grounding.	I-Reply	I-3	Reply	10041
<sep> <sep> - Determining the size of the sliding window	O	O	Reply	10041
<sep> We definitely agree with this.	B-Reply	B-4	Reply	10041
In response to this, we simply adopted the same candidate proposals adopted by the baseline and prior work for fair comparisons.	I-Reply	I-4	Reply	10041
However, this is an interesting avenue for future work and we are actually exploring possible ways of replacing these manually-defined sliding window mechanism with an efficient subwindow search algorithm.	I-Reply	I-4	Reply	10041
<sep> <sep> - Can this model be supervised?	O	O	Reply	10041
If so, how does it compare to the supervised baselines?	O	O	Reply	10041
<sep> <sep> Our model should be easily generalizable to the strongly-supervised setting.	B-Reply	B-5	Reply	10041
Due to time constraints and other commitments, we do not have the time to adapt it to the strongly-supervised setting for this rebuttal, but this is an interesting future work direction.	I-Reply	I-5	Reply	10041
<sep> <sep> We hope that we have addressed your concerns satisfactorily.	O	O	Reply	10041
Please let us know if you have any further concerns or questions.	O	O	Reply	10041

This paper considers the problem of few-shot learning and proposes a new embedding-based approach.	O	O	Review	1616
In contrast to previous work (such as Matching Networks and Prototypical Networks) where distance is computed in pure embedding space, this work proposes computing a low-dimensional subspace to represent a class and using the distance from an embedded query point to this subspace.	O	O	Review	1616
The low-dimensional subspace for a class is computed by running truncated Singular Value Decomposition on the normalized embeddings of all points in the support set for that class and using the top n left singular vectors as the basis for the class's subspace.	O	O	Review	1616
The authors also propose an extension to their model to the semi-supervised few-shot learning setting by incorporating masked-mean computation and zero-mean cluster for distractor items (both ideas borrowed from Renn 2017 for prototypical networks).	O	O	Review	1616
Experiments are conducted on Mini-Imagenet in the few-shot learning setting and on Mini-Imagenet and Tiered-ImageNet in the semi-supervised few-shot learning setting.	O	O	Review	1616
<sep> <sep> Pros:	O	O	Review	1616
- Proposed idea is novel and proposes an interesting change to existing embedding-based few-shot learning techniques.	O	O	Review	1616
<sep> <sep> Cons:	O	O	Review	1616
- Performance benefit is a bit disappointing; Mini-Imagenet few-shot performance improvement relative to Prototypical-Nets is minimal (barely 1% for 5way-5shot and 20way-5shot case).	B-Review	B-1	Review	1616
For semi-supervised experiments, there is bigger improvement for Mini-Imagenet (4% for both without distractors and with distractors) but less so for Tiered-ImageNet (close to 0% for without distractors and with distractors).	I-Review	I-1	Review	1616
<sep> <sep> Remarks:	O	O	Review	1616
- The paper seems to be missing what the dimensionality of the subspace is for the experiments?	B-Review	B-2	Review	1616
Was this picked using validation set performance?	I-Review	I-2	Review	1616
<sep> - In first paragraph of page 2, it seems too strong to say "...this makes our paper unparalleled to previous studies"; maybe change to "...this make our proposed model novel relative to previous work"	B-Review	B-3	Review	1616
- Is there previous work that has involved back-propagating through SVD?	B-Review	B-4	Review	1616
It would be useful to mention these as references.	I-Review	I-4	Review	1616
<sep> - In Figure 1, it is visually shown how outliers can negatively impact Matching-Networks and Prototypical-Networks but not visually shown how PSN is resistant to them?	B-Review	B-5	Review	1616
<sep> - The claim is made that the proposed method is more robust to outliers.	B-Review	B-6	Review	1616
Is there more of a justification that can be given for this?	I-Review	I-6	Review	1616
Either in terms of some intuition or an experiment that can be run?	I-Review	I-6	Review	1616
For example, can it be shown that outliers cause the prototype of a class to move a lot (in terms of distance from original prototype without outliers) whereas the original subspace compared to subspace with outliers is less different by measuring this on Mini-Imagenet?	I-Review	I-6	Review	1616
<sep> - Typo on page 5: "in what follwos" => "in what follows"	B-Review	B-7	Review	1616
- In Discussion, paper states, "Moreover, the Prototypical Network makes use of the class mean and can be easily incorporated in our testbed": what does this mean exactly?	B-Review	B-8	Review	1616
<sep> Q: ``The paper seems to be missing what the dimensionality of the subspace is for the experiments?''	O	O	Reply	1616
<sep> <sep> A: In our initial submission, we used a rule of thumb to set the dimensionality (n is-1 during training and two at the testing time).	B-Reply	B-2	Reply	1616
<sep> To address the reviewer's comment, we studied the effect of subspace dimension in Section 6 and Appendix B. We examined on four different subspace dimensions on 5-way 5-shot and 5-way 20-shot for training and testing stage and found that the performance is not affected badly.	I-Reply	I-2	Reply	1616
<sep> Q: it seems too strong to say "...this makes our paper unparalleled to previous studies"	O	O	Reply	1616
<sep> A: Duly noted.	B-Reply	B-3	Reply	1616
We have rephrased the introduction according to your comment.	I-Reply	I-3	Reply	1616
<sep> <sep> Q: ``Is there previous work that has involved back-propagating through SVD?''	O	O	Reply	1616
<sep> <sep> A: Yes, in particular the work of  Ionescu et al [1], Li et al [2], and Gou et al [3] used backpropagation through SVD to address semantic segmentation, large scale classification, and visual recognition problems.	B-Reply	B-4	Reply	1616
We have revised section 2 to introduce these works.	I-Reply	I-4	Reply	1616
<sep> <sep> [1] Catalin Ionescu, Orestis Vantzos, and Cristian Sminchisescu.	O	O	Reply	1616
Matrix backpropagation for deep networks with structured layers.	O	O	Reply	1616
ICCV, 2015.	O	O	Reply	1616
<sep> <sep> [2] Peihua Li, Jiangtao Xie, Qilong Wang, and Wangmeng Zuo.	O	O	Reply	1616
Is second-order information helpful forlarge-scale visual recognition?.	O	O	Reply	1616
ICCV, 2017.	O	O	Reply	1616
<sep> <sep> [3] Mengran Gou, Fei Xiong, Octavia Camps, and Mario Sznaier.	O	O	Reply	1616
MoNet: Moments Embedding Network.	O	O	Reply	1616
CVPR, 2018.	O	O	Reply	1616
<sep> <sep> Q: ``In Figure 1, ... but not visually shown how PSN is resistant to them?''	O	O	Reply	1616
<sep> <sep> A:   We have added a new figure (Fig.2) to our paper to address this comment.	B-Reply	B-5	Reply	1616
There, we empirically studied the decision boundaries of PSN and PN.	I-Reply	I-5	Reply	1616
The samples (triangle symbols) are drawn from normal distribution with two (column 1 and 2) and three (column 3 and 4) different classes.	I-Reply	I-5	Reply	1616
The outliers (square symbols) are spread around initial samples.	I-Reply	I-5	Reply	1616
The facecolors of the outliers show to which class the outliers are assigned to.	I-Reply	I-5	Reply	1616
<sep> <sep> In addition, we empirically studied the effect of outliers on the Mini-ImageNet dataset (kindly see Section 5.3 and Appendix A).	I-Reply	I-5	Reply	1616
Therein, we considered two types of perturbations on two few-shot learning problems, namely 5-way 5-shot and 5-way 10-shot.	I-Reply	I-5	Reply	1616
In all the aforementioned experiments, we observed that PSN is more robust to outliers as compared to PN.	I-Reply	I-5	Reply	1616
<sep> <sep> Q: In Discussion, paper states, "Moreover, the Prototypical Network makes use of the class mean and can be easily incorporated in our testbed": what does this mean exactly?	O	O	Reply	1616
<sep> <sep> A: We meant that it was possible to design a hybrid model and benefit from the inference mechanism provided by the prototypes along our PSN.	B-Reply	B-8	Reply	1616
However, since our aim in this paper is to show and contrast the advantage of modelling with subspaces, we did not pursue such a development.	I-Reply	I-8	Reply	1616
Thus, we removed the confusing text from our revised paper.	I-Reply	I-8	Reply	1616
<sep> <sep> Q: ``Performance benefit is a bit disappointing''	O	O	Reply	1616
<sep> A: Our experiments show that PSN is superior to Prototypical Networks (PN) in all cases.	B-Reply	B-1	Reply	1616
<sep> More importantly, per our new experiments added to the new draft, PSN is more robust to outliers.	I-Reply	I-1	Reply	1616
Furthermore, PSN copes better with the increasing number of classes (ways) and makes a better use of unlabeled samples (as shown in Section 5).	I-Reply	I-1	Reply	1616
We believe this shows that PSN is a far better model for the problem at hand.	I-Reply	I-1	Reply	1616

This paper proposes a Projective Subspace Network (PSN) for few-shot learning.	O	O	Review	1616
The PSN represents each support set of classes as a subspace obtained by SVD.	O	O	Review	1616
Then the method calculates distances between a query and classes by the projection error to the subspace.	O	O	Review	1616
Instead of using the prototype of the class center, the subspace representation is more robust to outliers.	O	O	Review	1616
Though the contribution seems to be incremental, it is a reasonable improvement upon Matching Networks and Prototypical Networks.	B-Review	B-1	Review	1616
<sep> <sep> Pros.	O	O	Review	1616
<sep> + The proposed subspace method is simple and reasonable	O	O	Review	1616
+ The performance is better than some related works on few-shot learning.	O	O	Review	1616
<sep> <sep> Cos.	O	O	Review	1616
<sep> - The authors claimed that subspace representation is more robust to noise within each class samples.	B-Review	B-2	Review	1616
However, this is not supported by experiments.	I-Review	I-2	Review	1616
The authors evaluated the distractor classes.	I-Review	I-2	Review	1616
However, this is not the case when the outlier existed within each class samples.	I-Review	I-2	Review	1616
<sep> <sep> - For semi-supervised few-shot learning, the authors proposed a fake class with zero means.	B-Review	B-3	Review	1616
The effect of this fake class is not evaluated.	I-Review	I-3	Review	1616
<sep> <sep> - The dimensionality of subspace (n) seems to be not written.	B-Review	B-4	Review	1616
<sep> <sep> - The sensitivity analysis of the dimensionality of subspace is missing.	B-Review	B-5	Review	1616
For subspace methods, it is essential to evaluate the performance w.r.t the dimension.	I-Review	I-5	Review	1616
<sep> <sep> - Descriptions in the related work section should be improved.	B-Review	B-6	Review	1616
It is unclear how the proposed method is related to K-means, K-modes, and K-prototype.	I-Review	I-6	Review	1616
Also, the authors wrote that works (Chan et.	I-Review	I-6	Review	1616
2015, Sun et al 2017) use PCA or SVD to reduce the dimensionality of feature representation in neural networks.	I-Review	I-6	Review	1616
However, both methods do not perform dimensional reduction.	I-Review	I-6	Review	1616
PCANet (Chan et al .	I-Review	I-6	Review	1616
2015) obtains convolutional filters by applying PCA to input images or feature maps.	I-Review	I-6	Review	1616
SVDNet (Sun et al 2017) applies SVD for obtaining decorrelated weights in a neural network.	I-Review	I-6	Review	1616
<sep> <sep> <sep> Q:  The authors claimed that subspace representation is more robust to noise within each class samples.	O	O	Reply	1616
However, this is not supported by experiments.	O	O	Reply	1616
<sep> <sep> A: To address this comment, we have revised our paper and have added a new figure along new experiments to study the effect of outliers.	B-Reply	B-2	Reply	1616
Kindly see our response to AnonReviewer2 which we repeat below for convenience:	I-Reply	I-2	Reply	1616
<sep> We have added a new figure (Fig.2) to our paper to address your comment.	I-Reply	I-2	Reply	1616
There, we empirically studied the decision boundaries of PSN and PN.	I-Reply	I-2	Reply	1616
The samples (triangle symbols) are drawn from the normal distribution with two (column 1 and 2) and three( column 3 and 4) different classes.	I-Reply	I-2	Reply	1616
The outliers (square symbols) are spread around initial samples.	I-Reply	I-2	Reply	1616
The facecolors of the outliers show to which class the outliers are assigned to.	I-Reply	I-2	Reply	1616
<sep> <sep> In addition, we empirically studied the effect of outliers on the Mini-ImageNet dataset (see Section 5.3 and Appendix A).	I-Reply	I-2	Reply	1616
Therein, we considered two types of perturbations on two few-shot learning problems, namely  5-way 5-shot and 5-way 10-shot.	I-Reply	I-2	Reply	1616
In all the aforementioned experiments, we observed that PSN is more robust to outliers compared to PN.	I-Reply	I-2	Reply	1616
<sep> <sep> Q: The dimensionality of subspace (n) seems to be not written.	O	O	Reply	1616
The sensitivity analysis of the dimensionality of subspace is missing.	O	O	Reply	1616
<sep> <sep> A: We have revised our work (section 6) and added	B-Reply	B-4	Reply	1616
an appendix (Appendix B) to our paper and studied the sensitivity of PSN to the dimensionality of subspaces.	I-Reply	I-4	Reply	1616
Based on our experiments, PSN is robust to variations in their subspace dimensionality to a great degree.	I-Reply	I-4	Reply	1616
<sep> <sep> Q: For semi-supervised few-shot learning, the authors proposed a fake class with zero means.	O	O	Reply	1616
The effect of this fake class is not evaluated.	O	O	Reply	1616
<sep> <sep> A: We actually 'borrow' this idea from Ren et al (2018) (fake class with zero mean) but we adapt it to our subspace model.	B-Reply	B-3	Reply	1616
However, unlike the variant of PN for semi-supervised learning proposed by Ren et al(2018), our approach does not need to model any subspaces for the distractor classes.	I-Reply	I-3	Reply	1616
<sep> <sep> Q: Descriptions in the related work section should be improved.	O	O	Reply	1616
<sep> <sep> A: We have taken this advice on board and revised Section 2 accordingly.	B-Reply	B-6	Reply	1616
Aside from rewording, we have added references to methods that use backpropagation through SVD.	I-Reply	I-6	Reply	1616

This paper presents a new method for fully- and semi-supervised few-shot classification that is based on learning a general embedding as usual, and then learning a sub-space of it for each class.	O	O	Review	1616
A query point is then classified as the class whose sub-space is closest to it.	O	O	Review	1616
<sep> <sep> Pros: This is a neat idea and achieves competitive results.	O	O	Review	1616
Learning a sub-space per class makes intuitive sense to me since it‚Äôs plausible that there is a lower-dimensional subspace of the overall embedding space that captures the properties that are common to only examples of a certain class.	O	O	Review	1616
If this is indeed the case, it seems that indeed classifying query examples into classes based on their distances from the corresponding sub-spaces would lead to good discrimination.	O	O	Review	1616
<sep> <sep> Cons: First, an inherent limitation is that this approach is not applicable to one-shot learning, and I have doubts in its merit for very low shot learning (explained below).	B-Review	B-1	Review	1616
Second, I‚Äôm missing the justification behind a key point used to motivate the approach, which requires clarification (explained below).	B-Review	B-2	Review	1616
Third, I feel that certain aspects of the approach were unclear (details to follow).	B-Review	B-3	Review	1616
Finally, I feel more analysis is needed to better understand the differences of this method from previous work (concrete suggestions follow).	B-Review	B-4	Review	1616
For semi-supervised learning, the novelty regarding how the unlabeled examples are incorporated is limited, as the approach used is previously-introduced in Ren et al, 2018.	B-Review	B-5	Review	1616
<sep> <sep> Overall, even though I like the idea and the results are good, there are a few points, mentioned in the above section that I feel require additional work before I can strongly recommend acceptance.	O	O	Review	1616
Most importantly, relating to getting more intuition about why and when this works best, and tying it in better with previous approaches.	O	O	Review	1616
<sep> <sep> A key point requiring clarification.	O	O	Review	1616
<sep> There is a key fact that the authors used to motivate this approach which remains unclear to me: why is it the case that this approach is less sensitive to outliers than previous approaches?	B-Review	B-2	Review	1616
In Figure 1, an outlier is pictured in each of subfigures (a) and (b) corresponding to Matching and Prototypical Networks, but not in subfigure (c) which corresponds to PSN.	I-Review	I-2	Review	1616
No explanation is provided to justify this conjecture, other than empirical evaluation that is based on the overall accuracy only.	I-Review	I-2	Review	1616
In particular, since SVD is used to obtain the sub-spaces, instead of an end-to-end learned projector that directly optimizes the query set accuracy, it‚Äôs not clear why if a support point is an outlier it would not affect the sub-space creation.	I-Review	I-2	Review	1616
If I‚Äôm missing something, please clarify!	I-Review	I-2	Review	1616
<sep> <sep> (A) Comments on the approach.	O	O	Review	1616
<sep> (1) Why define X_k as the support set examples minus the class prototype instead of just the support examples themselves?	B-Review	B-6	Review	1616
The latter seems simpler, and should have all the required information for shaping the class‚Äô subspace.	I-Review	I-6	Review	1616
<sep> (2) Note that if X_k is defined as [x_{k,1}, \dots, x_{k,K}] as proposed in the above point (ie.without subtracting the class mean from each support point) then this method would have been applicable to 1-shot too.	B-Review	B-7	Review	1616
How would it then compare to a 1-shot Prototypical Network?	I-Review	I-7	Review	1616
Notice that in this case the mean of the class is equal to this one example.	I-Review	I-7	Review	1616
<sep> (3) In general, the truncated SVD decomposition for a class can be written using the matrices U, \Sigma and V^T with dimensions [D, n], [n, n] and [n, K] respectively, where D is the embedding dimensionality and K is the number of support points belonging to the given class.	B-Review	B-8	Review	1616
The middle matrix \Sigma in the non-truncated version would have dimensions [D, K]. Does this mean that when truncating, n is enforced to be smaller than each of D and K?	I-Review	I-8	Review	1616
This would mean that the dimensionality n of the sub-space is limited by the number of the support examples, which in some cases may be very small in few-shot learning.	I-Review	I-8	Review	1616
Can you comment on this?	I-Review	I-8	Review	1616
<sep> (4) How to set n (the dimensionality of each subspace) is not obvious.	B-Review	B-9	Review	1616
What values were explored?	I-Review	I-9	Review	1616
Is there a sweet spot in the trade-off between the observed complexity and the final accuracy?	I-Review	I-9	Review	1616
<sep> <sep> (B) Comparison with Prototypical Networks.	B-Review	B-4	Review	1616
<sep> (1) In what situations do we expect learning a sub-space per class to do better than learning a  prototype per class?	I-Review	I-4	Review	1616
For example, Figure 4 shows the test-time performance as a function of the test ‚Äòway‚Äô.	I-Review	I-4	Review	1616
A perhaps more interesting analysis would be to compare the models‚Äô performance as a function of the test *shot*: if more examples are available it may be less appropriate to create a prototype and more beneficial to create a sub-space?	I-Review	I-4	Review	1616
<sep> (2) Can we recover Prototypical Networks as a special case of PSN?	I-Review	I-4	Review	1616
If so, how?	I-Review	I-4	Review	1616
It would be neat to show under which conditions these are equivalent.	I-Review	I-4	Review	1616
<sep> <sep> (C) Clarifications regarding the semi-supervised setup.	B-Review	B-5	Review	1616
<sep> (1) Are distractor classes sampled from a disjoint pool of classes, or is it that, for example, a class which is a distractor in an episode is a non-distractor in another episode.	I-Review	I-5	Review	1616
<sep> (2) Similarly for labeled / unlabaled at training time.	I-Review	I-5	Review	1616
Can the same example appear as labeled in one episode but unlabaled in another?	I-Review	I-5	Review	1616
In Ren et al, 2018, this was prevented by creating an additional labeled/unlabeled split even for the training examples.	I-Review	I-5	Review	1616
Therefore they use strictly less overall information at meta-training time than if that split weren‚Äôt used.	I-Review	I-5	Review	1616
To be comparable with them, it‚Äôs important to apply this same setup.	I-Review	I-5	Review	1616
<sep> <sep> (D) Additional minor comments.	B-Review	B-10	Review	1616
<sep> (1) ‚ÄúTo work at the presence of distractors, we propose to use a fake class with zero mean‚Äù.	I-Review	I-10	Review	1616
Note that this was already proposed in Ren et al, 2018.	I-Review	I-10	Review	1616
They used a zero-mean, high-variance additional cluster whose aim was to ‚Äòsoak up‚Äô the distractor examples to prevent them for polluting legitimate clusters (this was the second model they proposed).	I-Review	I-10	Review	1616
<sep> (2) In the introduction, regarding contribution iii.	I-Review	I-10	Review	1616
A more appropriate way to describe this is as exploring generalization to different numbers of classes, or ‚Äòways‚Äô at test time than what was used at training time.	I-Review	I-10	Review	1616
<sep> (3) Gidaris and Komodakis (2018) is described in the related work as using a more complicated pipeline.	I-Review	I-10	Review	1616
Note however that their pipeline is in place for solving a more challenging problem than standard few-shot classification: they study how a model can maintain the ability to remember training classes while rapidly learning about new ‚Äòtest‚Äô classes.	I-Review	I-10	Review	1616
<sep> (4) In the last line of section 5.3, use N-way instead of K-way since in the rest of the paper K was used to refer to the shot, not the way.	I-Review	I-10	Review	1616
<sep> <sep> <sep> Q: ``Why is it the case that ... less sensitive to outliers ...''	O	O	Reply	1616
<sep> A: A prototype in the Prototypical Networks (PN) is the average of a set and as such is sensitive to any perturbation of the set, outliers being one.	B-Reply	B-2	Reply	1616
On the other hand, in PSN, a set is represented by a subspace.	I-Reply	I-2	Reply	1616
To have a noticeable change in the orientation of the subspace, one needs to induce drastic changes to the set.	I-Reply	I-2	Reply	1616
Having said this, we performed two extra-experiments to reinforce our conjecture here.	I-Reply	I-2	Reply	1616
<sep> <sep> In the first one, depicted in Fig.2, we empirically studied the decision boundaries of PSN and PN.	I-Reply	I-2	Reply	1616
The samples (triangle symbol) are drawn from the normal distribution for a two-class problem (column 1 and 2) and a problem with three classes (column 3 and 4).	I-Reply	I-2	Reply	1616
The outliers (square symbol) are spread around initial samples.	I-Reply	I-2	Reply	1616
The facecolors for outliers indicate to which class they have been assigned.	I-Reply	I-2	Reply	1616
In the odd columns, we can see that the prototypes and subspaces discriminate the classes equally well.	I-Reply	I-2	Reply	1616
<sep> However, in the even columns, it is clearly shown that the outliers sway the prototypes and their decision boundaries while the subspace approach handles them more robustly.	I-Reply	I-2	Reply	1616
<sep> In the second experiment, placed in appendix A, we provide the 5-way 5-shot and 5-way 10-shot results on the Mini-ImageNet by adding outliers and noise to support examples.	I-Reply	I-2	Reply	1616
There are two setups conducted to examine the robustness of PSN to outliers and additive noise.	I-Reply	I-2	Reply	1616
In the first experiment, the support set contains samples from classes absent in this set.	I-Reply	I-2	Reply	1616
We did not split the dataset into disjoint inlier/outlier sets though, as the outliers were only presented at the test time, leading to more realistic experiments.	I-Reply	I-2	Reply	1616
In the second experiment, perturbations were generated from a Gaussian distribution with random mean and predefined	I-Reply	I-2	Reply	1616
variance.	I-Reply	I-2	Reply	1616
The results shown in Fig.4 demonstrate that on both tasks, PSN outperforms PN by a significant gap.	I-Reply	I-2	Reply	1616
Note that, we utilized the same CNN architecture (4-convolutional layers) for both PSN and PN.	I-Reply	I-2	Reply	1616
<sep> <sep> Q: ``Why define as the support set examples minus the class prototype instead of just the support examples themselves?''	O	O	Reply	1616
<sep> <sep> A: Our idea here is to represent a class by an affine subspace which is indeed a generalization of	B-Reply	B-6	Reply	1616
the concept of linear subspace (where the origin is a common point).	I-Reply	I-6	Reply	1616
We indeed started by using linear-subspaces to model each class but empirically found that affine subspaces perform slightly better.	I-Reply	I-6	Reply	1616
To address this comment, we have added a remark to Section 6.	I-Reply	I-6	Reply	1616
<sep> <sep> Q: ``How would it then compare to a 1-shot Prototypical Network?''	O	O	Reply	1616
<sep> <sep> A: We cannot build an affine subspace with only one example per class, as such we cannot use PSN to address 1-shot learning problems per se.	B-Reply	B-7	Reply	1616
However, simply augmenting support images to obtain two or more samples per class alleviates such an issue straight away.	I-Reply	I-7	Reply	1616
However, this simple issue is beyond the points we make in our paper (it is an orthogonal research direction in one- and few-shot learning).	I-Reply	I-7	Reply	1616
We have reflected this in Section 6 of the revised draft to address the reviewer's comment.	I-Reply	I-7	Reply	1616
<sep> <sep> Q: ``Does this mean the dimensionality n of the sub-space is limited by the number of the support examples''	O	O	Reply	1616
<sep> A: Affirmative.	B-Reply	B-8	Reply	1616
Our idea is to construct a subspace representing the set.	I-Reply	I-8	Reply	1616
The reviewer's comment raises an interesting point, whether parts of the orthogonal complement of each subspace can be used to make better decisions.	I-Reply	I-8	Reply	1616
We believe that investigating the effect of orthogonal complements demands a dedicated study and goes beyond our work.	I-Reply	I-8	Reply	1616
Having said this, we reflect this comment in Section 7.	I-Reply	I-8	Reply	1616

This paper proposes a general class of GNN.	O	O	Review	10120
The new model class generalizes the aggregation step to multiple levels of neighbors.	O	O	Review	10120
The new model generalizes existing models.	O	O	Review	10120
Theoretically, the paper shows the generalized models enjoy better discriminative power.	O	O	Review	10120
The paper also conducts experiments to demonstrate the effectiveness of the new model class.	O	O	Review	10120
<sep> <sep> <sep> Comments:	O	O	Review	10120
1.	O	O	Review	10120
The design of new models is straightforward, and the theoretical analysis is trivial, given Xu et al 2019.	B-Review	B-1	Review	10120
The paper would be improved if the author(s) can provide optimization or generalization analysis.	I-Review	I-1	Review	10120
<sep> <sep> 2.	O	O	Review	10120
The statement about experiments is misleading.	B-Review	B-2	Review	10120
The paper claims SOTA results on several datasets.	I-Review	I-2	Review	10120
However, this paper does not report recent SOTA results:	I-Review	I-2	Review	10120
<a href="https://arxiv.org/abs/1809.02670" target="_blank" rel="nofollow">https://arxiv.org/abs/1809.02670</a>	I-Review	I-2	Review	10120
<a href="https://arxiv.org/abs/1810.00826" target="_blank" rel="nofollow">https://arxiv.org/abs/1810.00826</a>	I-Review	I-2	Review	10120
<a href="https://arxiv.org/abs/1905.13192" target="_blank" rel="nofollow">https://arxiv.org/abs/1905.13192</a>	I-Review	I-2	Review	10120
<sep> 3.	B-Review	B-3	Review	10120
The use of the phrase "random walk" is weird.	I-Review	I-3	Review	10120
As there is no randomness at all.	I-Review	I-3	Review	10120
<sep> <sep> <sep> Thank you Reviewer #1 for your review and comments.	O	O	Reply	10120
Here is an initial response:	O	O	Reply	10120
<sep> 1.	O	O	Reply	10120
We completely agree that Xu et al 2019 did fundamental work in this area, and Theorem 3 is a natural extension of the work they did.	B-Reply	B-1	Reply	10120
Xu's original theorem seemed to implicate that GNNs aggregating over the immediate neighborhood are naturally constrained to 1-WL, and we show that by very so slightly changing the definition of the immediate neighborhood (L_1 arguably is still the immediate neighborhood) gives theoretically greater power.	I-Reply	I-1	Reply	10120
Moreover, the fact that it captures triangles leads to favorable performance in many areas.	I-Reply	I-1	Reply	10120
<sep> <sep> Furthermore, we believe Theorem 1 and Theorem 4 bring new contributions: specifically Theorem 1 formalizes what the N-GCN paper was proposing (look at larger aggregation regions) and shows that our hierarchy is complete under any aggregating regions that can be defined under the distance metric.	I-Reply	I-1	Reply	10120
<sep> <sep> Theorem 4 shows that our framework can, in the limit, discriminate between all graphs.	I-Reply	I-1	Reply	10120
Graph discrimination from a local point of view is hard (as from a local point one does not know if there are other disconnected segments), and the proof required the use of a special case of the Graph Reconstruction Conjecture.	I-Reply	I-1	Reply	10120
<sep> <sep> <sep> 2.	O	O	Reply	10120
Thank you for pointing out these works.	O	O	Reply	10120
We are happy to add these works into our comparison.	B-Reply	B-2	Reply	10120
We would like to stress that the results in these papers do not significantly change what we presented.	I-Reply	I-2	Reply	10120
Specifically, it does not appear that any of the papers cited exceed the SOTA benchmarks cited in the paper (specifically the comparable datasets NCI1 (SOTA: 86.1), MUTAG (SOTA: 92.6)), Proteins (SOTA: 76.5), PTC-MR (SOTA: 63.6) ).	I-Reply	I-2	Reply	10120
We do not claim we exceed these SOTA in our paper, and the results in this paper show this.	I-Reply	I-2	Reply	10120
We are happy to be more clear on this.	I-Reply	I-2	Reply	10120
<sep> <sep> Our example architectures performed the best on regression tasks (QM7b, QM9) where we were unable to find better results in the literature, but we were also prudent and did not claim we are setting the new SOTA.	I-Reply	I-2	Reply	10120
<sep> <sep> Further we would like to emphasize that this is a framework and the experiments are intended to show that powerful GNNs can be constructed in a straightforward way, exactly as you pointed out.	I-Reply	I-2	Reply	10120
This is by no means the "maximum" power available under this framework and a lot of what we proposed can be easily combined with the other innovations/advancements (attention, residual, etc) in the literature for even greater performance.	I-Reply	I-2	Reply	10120
The experiments intend to show that using our framework, we are able to achieve greater increase in performance compared to the GCN baseline than the previous SOTA attempts at doing so (N-GCN, k-GNN), despite looking at a smaller region (up to 2 hops) compared to k-GNN (3 hops) and N-GCN (6 hops).	I-Reply	I-2	Reply	10120
This shows the power of systematically adding features to a network.	I-Reply	I-2	Reply	10120
<sep> <sep> 3.	O	O	Reply	10120
The "randomness" refers to the fact that a length-k walk can be any random length-k walk.	B-Reply	B-3	Reply	10120
This follows terminology used in the N-GCN paper and other papers which relate random walks to GNNs.	I-Reply	I-3	Reply	10120
We are happy to update the terminology to the "set of all walks" for clarity.	I-Reply	I-3	Reply	10120

The paper proposes minor modifications to Graph Convolutional Networks (GCNs) that as proven by the authors enable learning of local features in networks, namely the aggregation over powers of the adjacency matrix (effectively counting random walks within the neighborhood) and aggregating over connections within nodes in the neighborhood.	O	O	Review	10120
<sep> <sep> GCNs are of interest to	O	O	Review	10120
The paper is well written and clear.	O	O	Review	10120
<sep> The mathemeatical derivations are clearly structured.	O	O	Review	10120
<sep> The authors provide a large set of experiments on simulated and real data from different domains and relevant supervised tasks (node classifiation, graph classification and graph regression).	O	O	Review	10120
<sep> Source code is provided.	O	O	Review	10120
<sep> <sep> experimental results:	O	O	Review	10120
- For the simulation in Table 2, a 1-layer network seems like it would hield an advantage for the unstructured Erd√∂s Renyi graphs.	B-Review	B-1	Review	10120
As I understand, the proposed GCN should by construction count the triangles (target variable) for each node embedding and then predict a linear function of those aggregated.	I-Review	I-1	Review	10120
My intuition says that this may even be an advantage over adding more layers.	I-Review	I-1	Review	10120
The text states the opposite.	I-Review	I-1	Review	10120
Here it would be interesting to see the effect of adding layers, or aggregating over longer random walks.	I-Review	I-1	Review	10120
<sep> Here, it would be important to get the prediction of an untrained baseline in addition to the GCN baseline (e.g. the expected number of triangles/4cycles based on number of nodes in the Erd√∂s Renyi model) to understand the scale the Mean Squared Error lives on and what the relative improvement means.	B-Review	B-2	Review	10120
Thank you Reviewer #2 for your review and comments.	O	O	Reply	10120
Here is an initial response:	O	O	Reply	10120
<sep> We agree with your intuition that the deeper layers in this case might not be useful because the first layer should be able to count the triangles.	B-Reply	B-1	Reply	10120
We said we "handicapped" the models because deeper/wider models might be able to use higher-order features to reverse predict the number of triangles, which would make the comparison to GCN unfair.	I-Reply	I-1	Reply	10120
<sep> <sep> Our (incomplete) experiments when writing the paper suggest a larger aggregation area does improve the performance on these tasks but not by a lot.	I-Reply	I-1	Reply	10120
Thus we decided to keep our synthetic experiments to 1-layer so that it is also fair to the GCN (i.e. theoretically 3-layer GCN can look 3 hops away).	I-Reply	I-1	Reply	10120
Of course, if you feel like it is needed,  we are happy to add these results.	I-Reply	I-1	Reply	10120
<sep> <sep> We will add the prediction of an untrained baseline.	B-Reply	B-2	Reply	10120
The order is of 10^2 for the MSE of triangles, and 10^5 for the MSE of 4-cycles.	I-Reply	I-2	Reply	10120

The paper proposes a generalized framework for GNN.	O	O	Review	10120
It proposes a representational hierarchy of GNNs. (	O	O	Review	10120
D-1, L-1,..D-n, L-n).	O	O	Review	10120
L-k is the k-hop neighborhood including all edges.	O	O	Review	10120
And D-k is L-k without edges between the outermost nodes.	O	O	Review	10120
The discriminative power of a network using L-1 is &gt; WL-1.	O	O	Review	10120
On various graph classification/regression tasks, the proposed method shows good performance.	O	O	Review	10120
Show promising result on QM7b QM9 graph regression task  (counting triangles, cycles etc) which&nbsp;are highly relevant to the proposed method.	O	O	Review	10120
<sep> <sep> Some concerns:	O	O	Review	10120
<sep> 1, the theoretical results seem a bit incremental compared with (Xu et al 2018).	B-Review	B-1	Review	10120
<sep> <sep> 2.	O	O	Review	10120
it would be nice to comment on how this will affect cases with nontrivial node features and general node classification tasks.	B-Review	B-2	Review	10120
<sep> <sep> 3.&nbsp; the empirical results are not very convincing.	B-Review	B-3	Review	10120
On standard datasets/tasks, the baselines are not state-of-the-arts.	I-Review	I-3	Review	10120
The results only show the advantage of the proposed idea over basic GCNs.	I-Review	I-3	Review	10120
Synthetic and results on QM7b QM9 are specific for triangles and cycles which is the model designed for.	I-Review	I-3	Review	10120
Overall, it is not very clear what the proposed idea brings to GNN in a general setting.	I-Review	I-3	Review	10120
<sep> <sep> Given these concerns, I am leaning toward weak reject at this moment.	O	O	Review	10120
<sep> <sep> Thank you Reviewer #3 for your review and comments.	O	O	Reply	10120
Here is an initial response:	O	O	Reply	10120
<sep> 1.	O	O	Reply	10120
We completely agree that Xu et al 2019 did fundamental work in this area, and Theorem 3 is a natural extension of the work they did.	B-Reply	B-1	Reply	10120
Xu's original theorem seemed to implicate that GNNs aggregating over the immediate neighborhood are naturally constrained to 1-WL, and we show that by very so slightly changing the definition of the immediate neighborhood (L_1 arguably is still the immediate neighborhood) gives theoretically greater power.	I-Reply	I-1	Reply	10120
Moreover, the fact that it captures triangles leads to favorable performance in many areas.	I-Reply	I-1	Reply	10120
<sep> <sep> Furthermore, we believe Theorem 1 and Theorem 4 bring new contributions: specifically Theorem 1 formalizes what the N-GCN paper was proposing (look at larger aggregation regions) and shows that our hierarchy is complete under any aggregating regions that can be defined under the distance metric.	I-Reply	I-1	Reply	10120
<sep> <sep> Theorem 4 shows that our framework can, in the limit, discriminate between all graphs.	I-Reply	I-1	Reply	10120
Graph discrimination from a local point of view is hard (as from a local point one does not know if there are other disconnected segments), and the proof required the use of a special case of the Graph Reconstruction Conjecture.	I-Reply	I-1	Reply	10120
<sep> <sep> 2.	O	O	Reply	10120
We believe this would lead to the ability to better utilize node features in a more nontrivial/nonlinear way (as we can combine node features across greater regions) and should improve results for harder node classification tasks.	B-Reply	B-2	Reply	10120
<sep> <sep> 3.	B-Reply	B-3	Reply	10120
We agree that the baselines are not absolute state-of-the-art in each of these tasks.	I-Reply	I-3	Reply	10120
However, N-GCN and k-GNN represent the SOTA in moving away from immediate node aggregations, and their innovations are not orthogonal to other innovations (attention, residual, etc) in GNNs that would enable it to achieve better results.	I-Reply	I-3	Reply	10120
We chose not to include these to show clearly where the result improvement is coming from.	I-Reply	I-3	Reply	10120
Our results show that just by adding the L1 aggregation region, we are able to exceed results from N-GCN (which were missing the L-type aggregation regions, but theoretically looks at information up to 6 hops) and k-GNN (3 hops), demonstrating the importance of utilizing the hierarchy.	I-Reply	I-3	Reply	10120
<sep> <sep> The QM7b and QM9 datasets are extremely large chemical/biological molecule datasets which are prized as large real-world databases.	I-Reply	I-3	Reply	10120
This datasets were not specifically targeted for our purpose and the molecule dynamics are affected by many highly nonlinear, nontrivial, and nonlocal interactions between the atoms.	I-Reply	I-3	Reply	10120
Therefore, the fact that our models outperforms others in this regime is significant and potentially important for biological applications.	I-Reply	I-3	Reply	10120

This paper is concerned with how to determine whether a set of data points are from a given distribution.	O	O	Review	20633
It uses the so-called typical set to transform the problem to determining whether the data points lie in the typical set of the given distribution.	O	O	Review	20633
It proposes a statistical test using the empirical distribution of model likelihoods to determine whether inputs lie in the typical set if the considered model.	O	O	Review	20633
<sep> <sep> The motivation of the work is very clear, and the paper is well organized.	O	O	Review	20633
The basic idea of using the typical set to check whether given data points are from a given distribution seems sensible, as guaranteed by Theorem 2.1.	O	O	Review	20633
<sep> <sep> My concern is about the performance of the proposed method compared to alternatives.	B-Review	B-1	Review	20633
First, a standard approach to the considered problems seems to be the two-sample tests (or its approximations or variations), so it would be desirable to compare the typical set-based approach with the two-sample test approaches theoretically.	B-Review	B-2	Review	20633
In particular, given that you have to allow some error when using typical sets, what is exactly the advantage of the proposed approach?	B-Review	B-3	Review	20633
Second, according to the empirical results (Section 5), the proposed method does not seem to clearly outperform alternatives such as KS-test.	B-Review	B-1	Review	20633
In this case, a better justification of the reliability of the proposed approach would be helpful.	I-Review	I-1	Review	20633
<sep> <sep> I acknowledge I read the authors' response and other reviews and would like to keep my original rating. (	B-Review	B-1	Review	20633
I agree that the t-Test and KS-test were probably first used by the authors, but at the same time it is natural to adopt them; that is why I considered them as baselines.)	I-Review	I-1	Review	20633
Thank you for your feedback, R3.	O	O	Reply	20633
We are glad that you found the work‚Äôs motivation ‚Äúvery clear‚Äù and the paper ‚Äúwell organized.	O	O	Reply	20633
‚Äù  Hopefully we can dispel your reservations below.	O	O	Reply	20633
<sep> <sep> 1.	O	O	Reply	20633
Performance in Comparison to Baselines:  Firstly, let us clarify that the only relevant baseline from the goodness-of-fit-testing literature is the Kernelized Stein Discrepancy (KSD).	B-Reply	B-1	Reply	20633
As stated in Sec 3.1, we are aware of no other GoF test that can be widely applied across all types of deep generative models.	I-Reply	I-1	Reply	20633
As for our test vs KSD, they perform roughly the same in all cases except for the PixelCNN trained on FashionMNIST.	I-Reply	I-1	Reply	20633
KSD is unable to detect MNIST as OOD, and our test is unable to detect NotMNIST as OOD.	I-Reply	I-1	Reply	20633
Yet an additional factor that differentiates the two is runtime: KSD is drastically slower, requiring an evaluation time (with M representing the batch size) in addition to the cost of computing derivatives through the model.	I-Reply	I-1	Reply	20633
Our method is after the likelihoods have been computed from the model.	I-Reply	I-1	Reply	20633
With runtime considered, the results clearly favor our method.	I-Reply	I-1	Reply	20633
<sep> Secondly, the t-Test and KS-test baselines are not really ‚Äòcompetitors‚Äô as they are (i) proposed by us and (ii) closely based on our typicality test.	B-Reply	B-1	Reply	20633
The t-test is just the typicality test with, and the KS-test is comparing all moments, whereas our typicality test is comparing just the first.	I-Reply	I-1	Reply	20633
Thus, these tests should perform comparably!	I-Reply	I-1	Reply	20633
The fact that the KS-test and ours perform so similarly can be seen as positive evidence for our method since it validates that the first moment (i.e. entropy) is truly the critical one for testing OOD.	I-Reply	I-1	Reply	20633
Thirdly, the Maximum Mean Discrepancy (MMD) baseline is not a `'valid' competitor as it is performing a two-sample test, not a GoF test.	B-Reply	B-1	Reply	20633
We provide MMD only as a reference point to see how testing against compares to testing against.	I-Reply	I-1	Reply	20633
Lastly, the annulus method [Choi et al 2019] is simply what our test reduces to in the special case of the-typical set for isotropic Gaussians (which we state on p 6).	I-Reply	I-1	Reply	20633
<sep> <sep> 2.	O	O	Reply	20633
‚ÄúA standard approach to the considered problems seems to be the two-sample tests‚Äù: This is incorrect.	B-Reply	B-2	Reply	20633
Two-sample tests assume the setting vs, with being the inaccessible underlying generative process.	I-Reply	I-2	Reply	20633
Rather, we are testing  vs, with being a model to which we have access.	I-Reply	I-2	Reply	20633
Yet we do report an MMD baseline in the experiments in anticipation of readers wondering how a two-sample test would perform in the same setting.	I-Reply	I-2	Reply	20633
We find it to perform comparably except in the same setting mentioned for KSD above: for the PixelCNN trained on FashionMNIST, MMD is unable to detect MNIST as OOD, and our test is unable to detect NotMNIST as OOD.	I-Reply	I-2	Reply	20633
Note that this performance was only able to be achieved when we derived the MMD kernel from the generative model.	I-Reply	I-2	Reply	20633
Otherwise, performance was strictly worse than our test.	I-Reply	I-2	Reply	20633
Moreover, MMD is much more expensive to compute as it is (as mentioned on p 6).	I-Reply	I-2	Reply	20633
<sep> 3.	O	O	Reply	20633
‚ÄúGiven that you have to allow some error when using typical sets, what is exactly the advantage of the proposed approach?‚Äù:  We are not sure what you mean exactly by ‚Äúallow for some error.	B-Reply	B-3	Reply	20633
‚Äù  But to summarize our contributions once more: (1) we propose typicality as an explanation for the OOD phenomenon in deep generative models, (2) derive a GoF test widely applicable across all deep generative model classes and with better runtime than KSD, (3) show that this test, despite it using only the first moment of the empirical likelihoods (which makes runtime cheap), is able to detect the OOD set in many of the cases reported by [Nalisnick et al 2019].	I-Reply	I-3	Reply	20633
<sep> Again, thanks for taking the time to read our paper.	O	O	Reply	20633
We look forward to further discussion.	O	O	Reply	20633

Thanks for the authors for your detailed reviews.	O	O	Review	20633
<sep> <sep> My major concerns about the proposed method are whether "the typicality set" could be faithfully applied in the small data regime.	O	O	Review	20633
The authors point me to the interesting Figure 4, which shows that it basically achieves converged performance when or smaller numbers for some problems.	O	O	Review	20633
I think this experiment is a strong support for the proposed method.	O	O	Review	20633
<sep> <sep> However, I don't agree that the M=1 Gaussian case acts as a strong support for the method.	B-Review	B-1	Review	20633
As I said, for some other wired distribution, it is difficult to interpret what the M=1 Typicality set becomes.	I-Review	I-1	Review	20633
<sep> <sep> The authors also clarify the difference between different baselines.	O	O	Review	20633
<sep> <sep> Overall, I will increase my score to "Weak Accept".	O	O	Review	20633
<sep> <sep> ##########################	O	O	Review	20633
<sep> Recent works have shown that out-of-distribution samples can have higher likelihoods than in-distribution samples for some generative models.	O	O	Review	20633
To explain this phenomenon and to tackle the problem for OOD detection, this paper adopts "typical sets" for identifying in-distribution samples.	O	O	Review	20633
Specifically, a "typical set" is a set of examples whose expected log likelihood approximate the model's entropy.	O	O	Review	20633
For a Gaussian distribution, the paper finds that a single point typical set locates exactly in the \sqrt{d} radius, which is usually favored over the high-likelihood origin.	O	O	Review	20633
Then the paper uses the "typical set" to perform OOD for a batch of examples.	O	O	Review	20633
Empirically they demonstrate competitive performance over MNIST and natural image tasks.	O	O	Review	20633
<sep> <sep> Typical set seems natural for out-of-distribution detection.	O	O	Review	20633
An important property is that, if one draws a large number of independent samples from the distribution, it is very likely that these samples belong to the typical set (basically Theorem 2.1).	O	O	Review	20633
However,  for small n, this property doesn't hold anymore, which leaves here a questionmark whether "Typical set" can be used for OOD detection in small n regime.	B-Review	B-1	Review	20633
As the author argues, for Gaussian distribution when n=1 the typical locations are those \sqrt{d} radius points.	I-Review	I-1	Review	20633
But this doesn't justify the "Typical set".	I-Review	I-1	Review	20633
If the distribution is some non-Gaussian wired distribution, the typical locations doesn't seem to make sense at all.	I-Review	I-1	Review	20633
<sep> <sep> Following the previous argument above, the Typical set method requires to perform OOD for a batch of examples.	B-Review	B-2	Review	20633
In contrast, the Annulus method can be directly applied to one single test example.	I-Review	I-2	Review	20633
<sep> <sep> Empirically, the Typically set doesn't demonstrate obvious advantages compared to the baselines.	B-Review	B-3	Review	20633
For both MNIST and natural image tasks, it seems that all methods behave similarly.	I-Review	I-3	Review	20633
For comparing such big tables, I would recommend adding a column showing the average ranks among all methods.	I-Review	I-3	Review	20633
Beyond that, standard OOD tasks usually evaluate methods using AUROC and AUPR (Hendrycks and Gimpel, 2017).	B-Review	B-4	Review	20633
Is it possible to also include such metrics ?	I-Review	I-4	Review	20633
<sep> <sep> Theorem 2.1 is confusing.	B-Review	B-5	Review	20633
It is beneficial to define what P is, and verbally state what the theorem conveys.	I-Review	I-5	Review	20633
Thank you for taking the time to read our paper, R1.	O	O	Reply	20633
We are glad that you found our approach ‚Äúnatural for out-of-distribution detection.	O	O	Reply	20633
‚Äù  Please consider the following rebuttals to your critiques.	O	O	Reply	20633
<sep> <sep> 1.	O	O	Reply	20633
Small Behavior:  You are correct in that Thm 2.1 only holds for sufficiently large, and therefore it is not obvious that a typicality-based test behaves correctly in the small regime.	B-Reply	B-1	Reply	20633
Firstly, we emphasize that GoF testing for deep generative models is still a completely open problem even in the large-M regime.	I-Reply	I-1	Reply	20633
As KSD is the primary competitor and scales as, even a procedure that performs well for large M is a contribution.	I-Reply	I-1	Reply	20633
And as can be seen in Figure 4, our test works near perfectly for, and this prompted us to focus the main experimental section on the regime.	I-Reply	I-1	Reply	20633
Now returning to the main point, we have two pieces of evidence for the test‚Äôs correctness for small.	I-Reply	I-1	Reply	20633
The first is theoretical: examining the Gaussian case, the-typical set is, the shell of radius.	I-Reply	I-1	Reply	20633
This is quite a narrow region of the support, which speaks to the inapplicability of Thm 2.1.	I-Reply	I-1	Reply	20633
Yet as we are given only one test instance, such a restriction seems to be the most appropriate choice.	I-Reply	I-1	Reply	20633
It is clearly better than picking the mode, for instance.	I-Reply	I-1	Reply	20633
Our second piece of evidence is experimental: Our test performs reasonably well in the regime and in cases can achieve near perfect OOD classification for.	I-Reply	I-1	Reply	20633
In the case of Glow trained on SVHN, 98% of CIFAR-10 batches and 100% of ImageNet batches were correctly classified at.	I-Reply	I-1	Reply	20633
Hence, our test must be checking sensible regions of data space or such good results could not be possible.	I-Reply	I-1	Reply	20633
In turn, we find the claim that ‚Äúthe typical locations doesn't seem to make sense at all [for small]‚Äù completely speculative.	I-Reply	I-1	Reply	20633
Can you please provide some reasoning in support of your claim?	I-Reply	I-1	Reply	20633
<sep> 2.	O	O	Reply	20633
Performance in Comparison to Baselines:  Firstly, let us clarify that the only relevant baseline from the goodness-of-fit-testing literature is the Kernelized Stein Discrepancy (KSD).	B-Reply	B-3	Reply	20633
As stated in Sec 3.1, we are aware of no other GoF test that can be widely applied across all types of deep generative models.	I-Reply	I-3	Reply	20633
As for our test vs KSD, they perform roughly the same in all cases except for the PixelCNN trained on FashionMNIST.	I-Reply	I-3	Reply	20633
KSD is unable to detect MNIST as OOD, and our test is unable to detect NotMNIST as OOD.	I-Reply	I-3	Reply	20633
Yet an additional factor that differentiates the two is runtime: KSD is drastically slower, requiring an evaluation time (with M representing the batch size) in addition to the cost of computing derivatives through the model.	I-Reply	I-3	Reply	20633
Our method is after the likelihoods have been computed from the model.	I-Reply	I-3	Reply	20633
With runtime considered, the results clearly favor our method.	I-Reply	I-3	Reply	20633
<sep> Secondly, the t-Test and KS-test baselines are not really ‚Äòcompetitors‚Äô as they are (i) proposed by us and (ii) closely based on our typicality test.	B-Reply	B-3	Reply	20633
The t-test is just the typicality test with, and the KS-test is comparing all moments, whereas our typicality test is comparing just the first.	I-Reply	I-3	Reply	20633
Thus, these tests should perform comparably!	I-Reply	I-3	Reply	20633
The fact that the KS-test and ours perform so similarly can be seen as positive evidence for our method since it validates that the first moment (i.e. entropy) is truly the critical one for testing OOD.	I-Reply	I-3	Reply	20633
Thirdly, the Maximum Mean Discrepancy (MMD) baseline is not a `valid‚Äô competitor as it is performing a two-sample test, not a GoF test, which is the topic of our paper.	B-Reply	B-3	Reply	20633
We provide MMD only as a reference point to see how testing against compares to testing against.	I-Reply	I-3	Reply	20633
Lastly, the annulus method [Choi et al 2019] is simply what our test reduces to in the special case of the-typical set for isotropic Gaussians (which we state on p 6).	I-Reply	I-3	Reply	20633
<sep> <sep> 3.	O	O	Reply	20633
‚ÄúThe Typical set method requires to perform OOD for a batch of examples.	O	O	Reply	20633
In contrast, the Annulus method can be directly applied to one single test example.	O	O	Reply	20633
‚Äù:  Pitting the annulus method vs our typicality test is a false dichotomy.	B-Reply	B-2	Reply	20633
The annulus method (as mentioned above) is a special case of our test, and the only reason it can be used for one-sample is that it‚Äôs assuming the-typical set.	I-Reply	I-2	Reply	20633
<sep> 4.	O	O	Reply	20633
AUROC metrics:  As far as we are aware, AUROC metrics in the literature are computed for point-wise rejection rules.	B-Reply	B-4	Reply	20633
Thus they would not be comparable to our hypothesis testing / batch-wise methodology, which we believe to be the first of its kind for deep generative models.	I-Reply	I-4	Reply	20633
Yet, we thank the reviewer for the suggestion, and we will look into adding ROC-based metrics to our revised draft.	I-Reply	I-4	Reply	20633
<sep> 5.	B-Reply	B-5	Reply	20633
Thm 2.1:  Thank you for the feedback.	I-Reply	I-5	Reply	20633
We will add more discussion of the intuition.	I-Reply	I-5	Reply	20633
<sep> <sep> Again, thanks for sharing your thoughts.	O	O	Reply	20633
We look forward to further discussion.	O	O	Reply	20633

I've read the authors' rebuttal and other reviews; I'd like to keep my score as is.	B-Review	B-1	Review	20633
My main concerns are the novelty of the work, the theoretical soundness of the method for small data settings and its robustness in settings with model misspecification.	I-Review	I-1	Review	20633
<sep> <sep> #################################	O	O	Review	20633
<sep> The paper proposes a new approach based on the notion of typical set in probability and tackles the challenging problem of detecting OOD using deep generative models.	O	O	Review	20633
The main claim of the paper is that assigning high likelihood to OOD samples in DGMs is due to the mismatch between model‚Äôs typical set and its high probability density areas.	O	O	Review	20633
<sep> <sep> I liked the idea of proposing a hypothesis testing approach for finding OOD samples generated from a model; however, my main concern is that the approach has some major practical limitation that the authors have also rightly mentioned in their discussion.	B-Review	B-1	Review	20633
It seems that even with a hypothesis testing tool for OOD detection, the model capacity and other properties of the model are more fundamental and critical for OOD detection in DGMs.	I-Review	I-1	Review	20633
In other words, how this tool can be useful in practice if the models are misspecified and how robust is the tool with respect to model properties.	I-Review	I-1	Review	20633
This major limitation has not been addressed in the experiments.	I-Review	I-1	Review	20633
<sep> <sep> This paper, does a good job in finding the OOD data points if the likelihood histograms do not overlap using the typicality notion.	O	O	Review	20633
However, this idea had already been proposed and explored in Choi.	B-Review	B-2	Review	20633
et al 2019 (although for a flow-based model).	I-Review	I-2	Review	20633
This makes the technical novelty of the work less significant.	I-Review	I-2	Review	20633
<sep> <sep> Overall, I think the paper needs some improvement in terms of discussing the robustness of the test with respect to model properties; otherwise, it is just another typicality set explanation of why DGMs may produce high likelihood values for OOD samples which has already been mentioned in previous work.	B-Review	B-3	Review	20633
Thank you for your comments, R2.	O	O	Reply	20633
We are glad to hear that you ‚Äúliked the idea of proposing a hypothesis testing approach‚Äù and appreciate that the method ‚Äúdoes a good job in finding the OOD data points.	O	O	Reply	20633
‚Äù  We hope to address your doubts below.	O	O	Reply	20633
<sep> <sep> 1.	B-Reply	B-2	Reply	20633
Novelty w.r.t.Annulus Method:  It is incorrect to state that Choi et al [2019] have previously ‚Äúexplored‚Äù a typicality-based solution.	I-Reply	I-2	Reply	20633
Their annulus method is what our test reduces to in the *special case* of the-typical set for isotropic Gaussians (which we state on p 6).	I-Reply	I-2	Reply	20633
Choi et al make no mention of the general entropy-based definition of typicality (our Def 2.1).	I-Reply	I-2	Reply	20633
Nor do they give any methodology for testing the-typical set in Gaussians, let alone any other class of deep generative model (eg PixelCNN, VAEs).	I-Reply	I-2	Reply	20633
Previous to our work, the question of how to test for typicality *in every class of deep generative model except Gaussian flows* was completely wide open and unaddressed.	I-Reply	I-2	Reply	20633
<sep> 2.	B-Reply	B-1	Reply	20633
Behavior Under Misspecified Models:  While model misspecification is certainly a concern when building generative models, the topic of our paper is not model building.	I-Reply	I-1	Reply	20633
Rather, we focus on testing a given, pre-trained generative model.	I-Reply	I-1	Reply	20633
Or to be precise, we are testing, some unknown distribution we observe only through samples, vs, the pre-trained model.	I-Reply	I-1	Reply	20633
Model misspecification tests, the distribution of the training data, vs (or vs).	I-Reply	I-1	Reply	20633
Clearly these are much different settings, making an analysis of misspecification well out-of-scope for our paper.	I-Reply	I-1	Reply	20633
<sep> <sep> Again, thank you for taking the time to read our draft.	O	O	Reply	20633
We look forward to further discussion of these points.	O	O	Reply	20633

This paper introduces a new method to make ensembles of decision trees differentiable, and trainable with (stochastic) gradient descent.	O	O	Review	10099
The proposed technique relies on the concept of "oblivious decision trees", which are a kind of decision trees that use the same classifier (i.e. a feature and threshold) for all the nodes that have the same depth.	O	O	Review	10099
This means that for an oblivious decision tree of depth d, only d classifiers are learned.	O	O	Review	10099
Said otherwise, an oblivious decision tree is a classifier that split the data using d splitting features, giving a decision table of size 2^d.	O	O	Review	10099
To make oblivious decision trees differentiable, the authors propose to learn linear classifiers using all the features, but add a sparsity inducing operator on the weights of the classifiers (the entmax transformation).	O	O	Review	10099
Similarly, the step function used to split the data is replaced by a continuous version (here a binary entmax transformation).	O	O	Review	10099
Finally, the decision function is obtained by taking the outer product of all the scores of the classifiers: [c_1(x), 1-c_1(x)] o [c_2(x), 1-c_2(x)] ... This "choice" operator transforms the d dimensional vectors of the classifier scores to a 2^d dimensional vector.	O	O	Review	10099
Another interpretation of the proposed "differentiable oblivious decision trees" is a two layer neural network, with sparsity on the weights of the first layer,	O	O	Review	10099
and an activation function combining the entmax transformation and the outer product operator.	O	O	Review	10099
The authors then propose to combine multiple differentiable decision trees in one layer, giving the neural decision oblivious ensemble (NODE).	O	O	Review	10099
Finally, several NODE layers can be combined in a dense net fashion, to obtain a deep decision tree model.	O	O	Review	10099
The proposed method is evaluated on 6 datasets (half classification, half regression), and compared to existing decision tree methods such as XGBoost or CatBoost, as well as feed forward neural networks.	O	O	Review	10099
<sep> <sep> The paper is clearly written, ideas are well presented, and it is easy to follow the derivation of the method.	B-Review	B-1	Review	10099
As a minor comment, I would suggest to the authors to give more details on the EntMax method, as it is quite important for the method, but not really introduced in the paper.	I-Review	I-1	Review	10099
The proposed algorithm is sound, and a nice way to make decision trees differentiable.	I-Review	I-1	Review	10099
One concern that I have though, is that it seems that NODE are close to fully connected neural networks, with sparsity on the weights.	I-Review	I-1	Review	10099
Indeed, I think that there are two ingredients in the paper to derive the method: adding sparsity to the weights and the outer product operator (as described in the previous paragraph).	I-Review	I-1	Review	10099
In particular, the improvement over vanilla feed forward neural networks seem small in the experimental section.	I-Review	I-1	Review	10099
I thus believe that it would be interesting to study if both two differences with feed forward networks are important, or if only is enough to get better results.	I-Review	I-1	Review	10099
<sep> <sep> To conclude, I believe that this is a well written paper, proposing a differentiable version of decision trees which is interesting.	B-Review	B-1	Review	10099
However, the proposed method relies on existing techniques, such as EntMax, and I wonder if the (relatively small) improvement compared to feed forward network comes from these.	I-Review	I-1	Review	10099
I believe that it would thus be interesting to compare the method with feed forward network with sparsity on the weights.	I-Review	I-1	Review	10099
For now, I am putting a weak reject decision, but I am willing to reconsider my rating based on the author response.	O	O	Review	10099
<sep> <sep> Questions to the authors:	O	O	Review	10099
(1) do you use the same data preprocessing for all methods (quantile transform)?	B-Review	B-2	Review	10099
<sep> (2) would it make sense to evaluate the effects of each the entmax and the outer product operator separately in the context of fully connected networks?	B-Review	B-3	Review	10099
<sep> <sep> Thank you for the insightful review.	O	O	Reply	10099
We attempt to address your comments below.	O	O	Reply	10099
<sep> <sep> [do you use the same data preprocessing for all methods (quantile transform)?]	O	O	Reply	10099
<sep> <sep> Yes, exactly.	B-Reply	B-2	Reply	10099
We apply the same preprocessing steps for all methods to minimize the effect of built-in preprocessing of GBDT methods like Catboost.	I-Reply	I-2	Reply	10099
While important, such preprocessing steps have been applied to all models including FCNN and NODE for a fair comparison.	I-Reply	I-2	Reply	10099
<sep> <sep> [would it make sense to evaluate the effects of each the entmax and the outer product operator separately in the context of fully connected networks?]	O	O	Reply	10099
<sep> <sep> We agree that such an investigation would be interesting.	B-Reply	B-3	Reply	10099
We have evaluated the oblivious decision trees without sparsity in the ‚Äúsoftmax‚Äù column of Table 3 in the original submission.	I-Reply	I-3	Reply	10099
As for sparse weights without ODTs, we conduct such an experiment and report results below.	I-Reply	I-3	Reply	10099
<sep> <sep> For these experiments we consider three ways to sparsify weight matrices for fully-connected neural networks: row-wise Entmax (Œ±=1.5), column-wise Entmax (Œ±=1.5) and regularization[1]. We tune each setup using standard FCNN tuning procedure from the original submission.	I-Reply	I-3	Reply	10099
<sep> <sep> | Method   | YearPrediction |   Epsilon   |	I-Reply	I-3	Reply	10099
|--------------|---------------------|---------------|	I-Reply	I-3	Reply	10099
| FCNN       |    79.99              |   0.1041    |	I-Reply	I-3	Reply	10099
| L_0 reg    |    80.54              |   0.1132    |	I-Reply	I-3	Reply	10099
| Row-wise|    84.87              |   0.16460   |	I-Reply	I-3	Reply	10099
| Col-wise  |    81.13              |   0.16192   |	I-Reply	I-3	Reply	10099
<sep> Unfortunately, neither of the proposed methods was able to surpass the dense FCNN performance.	I-Reply	I-3	Reply	10099
Our hypothesis is that the sparsity benefits the NODE performance since it learns sparse *choice* functions.	I-Reply	I-3	Reply	10099
Conversely, FCNN sparse weight matrices by themselves do not improve the model‚Äôs performance on tabular data.	I-Reply	I-3	Reply	10099
<sep> <sep> [give more details on the EntMax method]	O	O	Reply	10099
<sep> We have added the brief description of entmax in a new revision.	B-Reply	B-1	Reply	10099
<sep> <sep> [1] Louizos, Christos, Max Welling and Diederik P. Kingma. ‚	O	O	Reply	10099
ÄúLearning Sparse Neural Networks through L0 Regularization.	O	O	Reply	10099
‚Äù ICLR 2018	O	O	Reply	10099

Paper Summary:	O	O	Review	10099
<sep> The paper considers training oblivious trees ensemble with gradient descent by introducing a relaxation for feature selection and node thresholding.	O	O	Review	10099
The relaxation is based on the recently introduced EntMax.	O	O	Review	10099
The approach is compared with standard gradient boosting tree learning on benchmark datasets.	O	O	Review	10099
<sep> <sep> Review Summary:	O	O	Review	10099
<sep> The paper reads well, is technically sound.	O	O	Review	10099
The approach is novel and relevant to ICLR.	O	O	Review	10099
Reference to related work are appropriate.	B-Review	B-2	Review	10099
Experimental comparison with CatBoost, neural nets could be more rigorous, more ablations could give a complete picture.	I-Review	I-2	Review	10099
Overall this is a good paper that gives an extra tool applicable to many practical settings.	O	O	Review	10099
<sep> <sep> Detailed Review:	O	O	Review	10099
<sep> The introduction needs to define "tabular data".	B-Review	B-1	Review	10099
In your case, it seems that you mean mostly numerical heterogeneous features.	I-Review	I-1	Review	10099
Could you comment on using categorical features as well?	I-Review	I-1	Review	10099
<sep> <sep> The method is clearly explained and references are appropriate, so most of my questions relate to the empirical setup and results.	O	O	Review	10099
<sep> <sep> First, it seems to me that the paper would be much stronger if you were to reproduce the results from an established paper.	B-Review	B-2	Review	10099
If you take the catboost paper (arXiv:1706.09516v5 [cs.	I-Review	I-2	Review	10099
LG] 20 Jan 2019), the error on epsilon dataset is 10.9 which is better than the number your report, similarly click reports 15.6 error rate.	I-Review	I-2	Review	10099
To me, the paper would be much better if you simply added an FCNN and a NODE column to Table 2 and 3 of the catboost paper.	I-Review	I-2	Review	10099
It does not mean that your approach has to be better in all cases, but it will give a clear picture of when it is useful and it would clear any doubt on the tuning of the catboost baseline.	I-Review	I-2	Review	10099
<sep> <sep> Second, the model you propose builds upon the densenet idea while the FCNN you compare with has no densenet connections.	B-Review	B-3	Review	10099
It would be fairer to consider neural net with this kind of residual.	I-Review	I-3	Review	10099
<sep> <sep> Third, I feel you need to report results over CPU as well.	B-Review	B-4	Review	10099
Boosted trees primary advantage is their low cost on regular CPU, the entmax formulation requires integrating over more leaves	I-Review	I-4	Review	10099
than typical thresholded trees and it would be interesting to compare the effect on CPU.	I-Review	I-4	Review	10099
Reporting timing with batch and individual sample evaluation would make sense as well.	I-Review	I-4	Review	10099
<sep> <sep> As a side note, I would advise to define entmax with its equation.	B-Review	B-5	Review	10099
It is too recent to consider it should be known by the reader.	I-Review	I-5	Review	10099
<sep> <sep> Overall, this is a good paper than reads well.	O	O	Review	10099
The method is novel, interesting and practical.	O	O	Review	10099
With the extra experiments, it would make an excellent ICLR paper.	O	O	Review	10099
Thank you for your comments, we address your concerns below.	O	O	Reply	10099
<sep> <sep> [add comparison to FCNN with DenseNet connections]	O	O	Reply	10099
We agree and conduct an additional set of experiments focused on densely-connected FCNN models.	B-Reply	B-2	Reply	10099
We use the standard FCNN tuning procedure described in the submission.	I-Reply	I-2	Reply	10099
Numbers in the table below correspond to the performance on the val/test subsets.	I-Reply	I-2	Reply	10099
<sep> <sep> FCNN              |    Epsilon         | YearPrediction |     Higgs           |   Microsoft      |     Yahoo           |     Click             |	I-Reply	I-2	Reply	10099
Sequential     | 0.1041/0.1043 |   70.07/79.99   | 0.2140/0.2140 | 0.5411/0.5608 | 0.5977/0.5773 | 0.3303/0.3325 |	I-Reply	I-2	Reply	10099
DenseNet      | 0.1044/0.1043 |   69.00/81.17   | 0.2146/0.2139 | 0.5403/0.5595 | 0.5899/0.5691 | 0.3302/0.3324 |	I-Reply	I-2	Reply	10099
<sep> As you can see, DenseNet does indeed sometimes outperform the sequential architecture but does not outperform NODE, which indicates that the inductive bias of oblivious decision ensembles is important.	I-Reply	I-2	Reply	10099
We have included dense connections in FCNN parameter tuning scheme and have updated Table 2 in a new revision	I-Reply	I-2	Reply	10099
<sep> [it seems to me that the paper would be much stronger if you were to reproduce the results from an established paper.]	O	O	Reply	10099
<sep> <sep> We agree with this concern.	B-Reply	B-2	Reply	10099
However, the choice of benchmark datasets in the Catboost paper is biased to categorical features as it is the main focus of Catboost.	I-Reply	I-2	Reply	10099
Moreover, most of the datasets are quite small, see Table 7 in <a href="https://arxiv.org/pdf/1706.09516.pdf."	I-Reply	I-2	Reply	10099
target="_blank" rel="nofollow">https://arxiv.org/pdf/1706.09516.pdf.</a> In contrast, we aim to cover different dataset sizes and domain areas.	I-Reply	I-2	Reply	10099
<sep> <sep> [Third, I feel you need to report results over CPU as well]	O	O	Reply	10099
We agree that this would be a valuable addition.	B-Reply	B-4	Reply	10099
However, our pytorch-based implementation specifically targets GPU training and inference.	I-Reply	I-4	Reply	10099
A naive conversion of 8-layer NODE to run on 28-core Xeon E5-2660 v4 has an average training time of 49min 40s and inference time of 1m 4.5s per million predictions on the YearPrediction dataset.	I-Reply	I-4	Reply	10099
<sep> <sep> The majority of this time is spent on multiplying activations by zero - a side-effect of a highly parallel GPU-friendly implementation.	I-Reply	I-4	Reply	10099
We expect that in a CPU-optimized NODE implementation (e.g. with natively compiled C++), inference would take between 100% and 200% of CatBoost inference time.	I-Reply	I-4	Reply	10099
However, development of such optimized implementation would take up immense amounts of time and effort and is not possible till the end of discussion period.	I-Reply	I-4	Reply	10099
<sep> <sep> [I would advise to define entmax with its equation]	O	O	Reply	10099
<sep> We have described entmax with more details in a new revision.	B-Reply	B-5	Reply	10099

The paper tries to ask if there is a good neural net architecture that works as effectively as gradient boosting decision trees on tabular data.	O	O	Review	10099
The authors propose an architecture (NODE) that satisfies this conditions.	O	O	Review	10099
NODE is an architecture consisting of differentiable oblivious decision trees that can be trained end to end via back propagation.	O	O	Review	10099
The paper is readable and the experiments are well presented.	O	O	Review	10099
They make use of an alpha-entmax transformation to obtain a differentiable architecture.	O	O	Review	10099
The approach seems well motivated in the literature.	B-Review	B-1	Review	10099
It is unclear how novel the contribution is.	I-Review	I-1	Review	10099
It is unclear if in the experimental section the datasets used are standard for this classes of tasks.	I-Review	I-1	Review	10099
Would be good to mention if it is the case.	I-Review	I-1	Review	10099
We thank you for the review.	O	O	Reply	10099
<sep> <sep> [It is unclear if in the experimental section the datasets used are standard for this classes of tasks.]	O	O	Reply	10099
<sep> All datasets from our experiments are standard for tabular data processing: each dataset was previously featured in multiple published studies.	B-Reply	B-1	Reply	10099
We deliberately chose these six datasets to cover different domain areas [web, natural sciences, etc.],	I-Reply	I-1	Reply	10099
tasks [classification/regression] and dataset sizes.	I-Reply	I-1	Reply	10099

This paper discusses the old problem of mismatch between the ultimate reward obtained after optimizing a  decision (planning or control) over a probabilistic model (of dynamics) and  the training  objective for the model (log-likelihood).	O	O	Review	20440
Experiments highlight that the NLL and reward can be very poorly correlated, that improvements in NLL initially improve reward but can later degrade it, and that models with similar NLLs can lead to very different rewards.	O	O	Review	20440
A  reweighting trick is proposed and summarily evaluated.	O	O	Review	20440
<sep> <sep> I like the topic of this paper but there are several aspects which I see as making it weaker than my acceptance threshold.	O	O	Review	20440
<sep> <sep> First, the paper overclaims in originality.	B-Review	B-1	Review	20440
This mismatch problem is not new, it is an instance of a more general issue that end-to-end training and meta-learning try to address, and has been already studied in the context of MBRL by many authors, who actually proposed more substantial solutions.	I-Review	I-1	Review	20440
When I read the abstract I had the impression that the paper actually had a theoretical analysis showing the correlation problem, but there is no such thing, only experiments.	I-Review	I-1	Review	20440
Section 3 does not actually provide a new insight.	I-Review	I-1	Review	20440
Still, the experiments are interesting in that they reveal that the magnitude of the mismatch is probably more serious than most RL researchers believed.	I-Review	I-1	Review	20440
<sep> <sep> Second, the 'fix' proposed is not well justified nor well tested (e.g. no quantiative comparisons, no comparisons against existing alternative methods to address the same problem, etc).	B-Review	B-2	Review	20440
This seriously weakens conclusions like "shows improvements in sample efficiency".	I-Review	I-2	Review	20440
<sep> <sep> One concern I have about the experiments of fig 3 is that NLL can be really bad, thus distorting rho, which is not a robust measure.	B-Review	B-3	Review	20440
So I would only look at NLLs of models with good NLLs, to obtain a more interesting analysis.	I-Review	I-3	Review	20440
<sep> <sep> Another concern about experiments is that I am not convinced that they were performed with SOTA MBRL methods and hyper-parameters (as demonstrated by SOTA performance on known benchmarks).	B-Review	B-4	Review	20440
Otherwise I could easily imagine how the mismatch could be much more severe than in the actual scenarios of interest.	I-Review	I-4	Review	20440
<sep> <sep> Minor points:	O	O	Review	20440
<sep> <sep> Bottom of page 6 refers to visualizations but I did not see if or where they were shown.	B-Review	B-5	Review	20440
<sep> <sep> Why the e in the numerator of eq 2e?	B-Review	B-6	Review	20440
Seems useless to put any constant there.	I-Review	I-6	Review	20440
<sep> <sep> The section on 'Shaping the cost or reward' was not clear enough to me (please expand).	B-Review	B-7	Review	20440
<sep> <sep> &gt;&gt; Thank you for your comments.	O	O	Reply	20440
As with all the review, we addressed all of the comments individually, please respond if you would like further clarification.	O	O	Reply	20440
We hope to improve the quality of the final paper.	O	O	Reply	20440
<sep> <sep> R3: First, the paper overclaims in originality.	O	O	Reply	20440
This mismatch problem is not new, it is an instance of a more general issue that end-to-end training and meta-learning try to address, and has been already studied in the context of MBRL by many authors, who actually proposed more substantial solutions.	O	O	Reply	20440
When I read the abstract I had the impression that the paper actually had a theoretical analysis showing the correlation problem, but there is no such thing, only experiments.	O	O	Reply	20440
Section 3 does not actually provide a new insight.	O	O	Reply	20440
Still, the experiments are interesting in that they reveal that the magnitude of the mismatch is probably more serious than most RL researchers believed.	O	O	Reply	20440
<sep> <sep> &gt;&gt; The goal of this paper is to illustrate the scope of the issue of objective mismatch to encourage future work.	B-Reply	B-1	Reply	20440
Due to the many varieties that this paired optimization problem can take, a general theoretical analysis would prove difficult.	I-Reply	I-1	Reply	20440
The goal of section 3 is to summarize the origins of a problem that is widespread in the area of learning in the specific context of model-based reinforcement learning.	I-Reply	I-1	Reply	20440
<sep> <sep> <sep> R3: Second, the 'fix' proposed is not well justified nor well tested (e.g. no quantiative comparisons, no comparisons against existing alternative methods to address the same problem, etc).	O	O	Reply	20440
This seriously weakens conclusions like "shows improvements in sample efficiency".	O	O	Reply	20440
<sep> <sep> &gt;&gt; The fix proposed is an initial attempt to mitigate the problem of objective mismatch, and we hope that better solutions emerge in the future.	B-Reply	B-2	Reply	20440
Due to space limitations, it is also difficult to include more.	I-Reply	I-2	Reply	20440
More thorough methods would be a future paper following this paper proposing the position.	I-Reply	I-2	Reply	20440
<sep> R3: One concern I have about the experiments of fig 3 is that NLL can be really bad, thus distorting rho, which is not a robust measure.	O	O	Reply	20440
So I would only look at NLLs of models with good NLLs, to obtain a more interesting analysis.	O	O	Reply	20440
<sep> <sep> &gt;&gt; During these experiments, the large NLLs are already filtered to partially mitigate this.	B-Reply	B-3	Reply	20440
For cartpole, NLL above 20 is filtered, and for half cheetah NLL above 50 is filtered out.	I-Reply	I-3	Reply	20440
We  can reduce the  region of the fit to that of the X-axis shown if it improve understanding.	I-Reply	I-3	Reply	20440
<sep> <sep> <sep> R3: Another concern about experiments is that I am not convinced that they were performed with SOTA MBRL methods and hyper-parameters (as demonstrated by SOTA performance on known benchmarks).	O	O	Reply	20440
Otherwise I could easily imagine how the mismatch could be much more severe than in the actual scenarios of interest.	O	O	Reply	20440
<sep> <sep> &gt;&gt; In our experiments, we employ a high-quality re-implementation of PETS which has been thoroughly validated (including against the original code).	B-Reply	B-4	Reply	20440
The difference in performance between our paper, and Chua et al depends **exclusively** from the use of a more recent version of the MuJoCo simulator.	I-Reply	I-4	Reply	20440
To validate our code, we verified that we can achieve similar performance to Chua et al when using the older version of MuJoCo, and additionally compared both PETS and SAC with the new MuJoCo simulator to verify that they converge to the same performance (they do).	I-Reply	I-4	Reply	20440
<sep> <sep> <sep> R3: Minor points: Bottom of page 6 refers to visualizations but I did not see if or where they were shown.	O	O	Reply	20440
<sep> <sep> &gt;&gt; Good catch.	B-Reply	B-5	Reply	20440
This plots mirrored the results in Figure 6, but needed to be removed due to space limitations.	I-Reply	I-5	Reply	20440
This will be updated in the final version.	I-Reply	I-5	Reply	20440
<sep> R3: Why the e in the numerator of eq 2e?	O	O	Reply	20440
Seems useless to put any constant there.	O	O	Reply	20440
<sep> <sep> &gt;&gt; You‚Äôre correct, you don‚Äôt need the constant and you could change learning rate in training, but we used to constant to not need to change training parameters with and without weighting.	B-Reply	B-6	Reply	20440
We tried a couple other re-weighting techniques and this yielded the best (slightly so) results.	I-Reply	I-6	Reply	20440
The e in the numerator is for normalization.	I-Reply	I-6	Reply	20440
All the re-weighting techniques attempted gave a weight of 1 to points on the expert trajectory, and had some monotonic decrease in weight away from it.	I-Reply	I-6	Reply	20440
<sep> <sep> <sep> R3: The section on 'Shaping the cost or reward' was not clear enough to me (please expand).	O	O	Reply	20440
<sep> <sep> &gt;&gt; We can improve the prose here.	B-Reply	B-7	Reply	20440
This section is pointing to works that acknowledge there may be weakness in the current setup of the optimization problem.	I-Reply	I-7	Reply	20440
To solve this limitation, they fine tune the cost  or reward function used in control, rather than trying to change the dynamics model.	I-Reply	I-7	Reply	20440

The paper claims that it identifies a fundamental issue in model-based reinforcement learning methods.	O	O	Review	20440
The issue is called objective mismatch, which arises when one objective is optimized (for example, model learning objective) without taking into consideration of another objective (for example policy optimization).	O	O	Review	20440
The author shows several experiments to illustrate the issue and proposes a method to mitigate it by assigning priorities to samples when training the model.	O	O	Review	20440
<sep> <sep> The issue of objective mismatch is not being noticed the first time.	B-Review	B-1	Review	20440
The paper "Reinforcement learning with misspecified model classes" has mentioned similar phenomenon.	I-Review	I-1	Review	20440
And other work such as <a href="https://arxiv.org/abs/1710.08005" target="_blank" rel="nofollow">https://arxiv.org/abs/1710.08005</a> also discussed similar issue.	I-Review	I-1	Review	20440
<sep> <sep> I disliked the way how the paper is motivated.	B-Review	B-2	Review	20440
The paper says ‚Äúin standard MBRL framework‚Äù, what is the standard MBRL framework?	I-Review	I-2	Review	20440
I think there is no such standard so far.	I-Review	I-2	Review	20440
The claim saying that the mismatch is a crucial flaw in current MBRL framework is too strong.	B-Review	B-3	Review	20440
The paper at least completely ignored two broad classes of MBRL methods.	B-Review	B-4	Review	20440
The first is value-aware MBRL (which attempts to take into account decision making when learning a model), there are actually many MBRL methods are in this category.	I-Review	I-4	Review	20440
Some examples: value prediction network, Predictron, Value-Aware Model Learning.	I-Review	I-4	Review	20440
The second class of MBRL approach is Dyna.	B-Review	B-5	Review	20440
Several works (continuous deep q-learning with model based acceleration, Organizing Experience: A Deeper Look at Replay Mechanisms for Sample-based Planning in Continuous State Domains, Efficient Model-Based Deep Reinforcement Learning with Variational State Tabulation, Recall Traces: Backtracking Models for Efficient Reinforcement Learning, Hill Climbing on Value Estimates for Search-control in Dyna) show that even with the same model (hence the same model error), using different simulated experiences play a significant role of improving sample efficiency.	I-Review	I-5	Review	20440
It is unclear whether model-error plays a decisive role in improving sample efficiency.	I-Review	I-5	Review	20440
<sep> <sep> The proposed method in section 5 lacks of justification, even a regular ER buffer is asymptotically on-policy, and hence it is indirectly linked with the control performance.	B-Review	B-6	Review	20440
It is unclear why introducing the weights based on expert trajectory can be helpful ‚Äî it can be worse because it should be far away from on-policy distribution.	I-Review	I-6	Review	20440
&gt;&gt; Thank you for your comments.	O	O	Reply	20440
As with all the review, we addressed all of the comments individually, please respond if you would like further clarification.	O	O	Reply	20440
<sep> R2: The issue of objective mismatch is not being noticed the first time.	O	O	Reply	20440
The paper "Reinforcement learning with misspecified model classes" has mentioned similar phenomenon.	O	O	Reply	20440
And other work such as <a href="https://arxiv.org/abs/1710.08005" target="_blank" rel="nofollow">https://arxiv.org/abs/1710.08005</a> also discussed similar issue.	O	O	Reply	20440
<sep> <sep> &gt;&gt; Thank you for pointing out these papers.	B-Reply	B-1	Reply	20440
If space permits, we will attempt to work them into the related works section.	I-Reply	I-1	Reply	20440
The goal of this paper is to formalize the problem, demonstrate the potential severity of the effects, and call for future research on the topic.	I-Reply	I-1	Reply	20440
We do not claim to be the first to notice this, we are the first to summarize the issue in a complete form so that it is addressed.	I-Reply	I-1	Reply	20440
<sep> <sep> R2:  I disliked the way how the paper is motivated.	O	O	Reply	20440
The paper says ‚Äúin standard MBRL framework‚Äù, what is the standard MBRL framework?	O	O	Reply	20440
I think there is no such standard so far.	O	O	Reply	20440
<sep> <sep> &gt;&gt; Many resources and papers in the area of RL describe the Model-based RL loop as a repetition of collecting data, learning a model, then evaluating a controller, which we are considering.	B-Reply	B-2	Reply	20440
The related work points at new methods where learning a model and a controller simultaneously are considered.	I-Reply	I-2	Reply	20440
<sep> <sep> &gt;&gt; Here are some resources that follow our claims, but we can be clearer in the prose and describe this as batch mode model-based RL, or specifically point to Algorithm 1 more frequently: Chua et al 2018, Berkeley Deep RL course (<a href="http://rail.eecs.berkeley.edu/deeprlcourse/)," target="_blank" rel="nofollow">http://rail.eecs.berkeley.edu/deeprlcourse/),</a> David Silver‚Äôs lectures on RL (<a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/dyna.pdf)," target="_blank" rel="nofollow">http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/dyna.pdf),</a> In these cases, Dyna is often seen as an intermediate between model-based RL and model-free planning.	B-Reply	B-2	Reply	20440
<sep> <sep> <sep> R2:  The claim saying that the mismatch is a crucial flaw in current MBRL framework is too strong.	O	O	Reply	20440
<sep> <sep> &gt;&gt; We will tone this down.	B-Reply	B-3	Reply	20440
The intention is to phrase this as, *it is crucial to understand the underlying mechanism to a process utilized*, rather then, *this is the limiting factor in all MBRL*.	I-Reply	I-3	Reply	20440
<sep> R2:  The paper at least completely ignored two broad classes of MBRL methods.	O	O	Reply	20440
The first is value-aware MBRL (which attempts to take into account decision making when learning a model), there are actually many MBRL methods are in this category.	O	O	Reply	20440
Some examples: value prediction network, Predictron, Value-Aware Model Learning.	O	O	Reply	20440
<sep> <sep> &gt;&gt; Thank you for bringing up these papers.	B-Reply	B-4	Reply	20440
There are many papers that have findings relating to this work, and we are doing our best to incorporate as many as possible while stating the position of the problem to model-based RL.	I-Reply	I-4	Reply	20440
The value-aware methods are an important area to be included in the related works.	I-Reply	I-4	Reply	20440
That section can be reworked to include and explain some of the experiments (e.g. Farahmand et al 2017).	I-Reply	I-4	Reply	20440
<sep> <sep> R2:  The second class of MBRL approach is Dyna.	O	O	Reply	20440
Several works ... show that even with the same model (hence the same model error), using different simulated experiences play a significant role of improving sample efficiency.	O	O	Reply	20440
It is unclear whether model-error plays a decisive role in improving sample efficiency.	O	O	Reply	20440
<sep> <sep> <sep> <sep> &gt;&gt; Dyna could be mentioned as an alternative, but it is a half step removed from model-based RL.	B-Reply	B-5	Reply	20440
It is commonly accepted as a middle ground between a model-free and model-based method.	I-Reply	I-5	Reply	20440
That being said, it does address some of the issues present and could be included.	I-Reply	I-5	Reply	20440
<sep> <sep> &gt;&gt; Specifically the point that ‚Äúusing different simulated experiences play a significant role of improving sample efficiency‚Äù is important and could be further emphasized in our paper.	B-Reply	B-5	Reply	20440
This should partially be addressed by sampling many random seeds in the paper, but this influence should be acknowledged in the paper as we make many claims where we discuss dataset distribution.	I-Reply	I-5	Reply	20440
<sep> <sep> <sep> R2: The proposed method in section 5 lacks of justification, even a regular ER buffer is asymptotically on-policy, and hence it is indirectly linked with the control performance.	O	O	Reply	20440
It is unclear why introducing the weights based on expert trajectory can be helpful ‚Äî it can be worse because it should be far away from on-policy distribution.	O	O	Reply	20440
<sep> <sep> &gt;&gt; We can edit the text to better motivate the solution.	B-Reply	B-6	Reply	20440
This solution is only for the case where we already have an expert trajectory - wrapping this idea into an online algorithm is a direction for future work.	I-Reply	I-6	Reply	20440
The idea is, if we had an expert trajectory for a given task, we should be able to train a model that focuses on relevant transitions.	I-Reply	I-6	Reply	20440
Adding a higher weight to important transitions hopes to capture this behavior, and not removing other data keeps robustness that is needed with a stochastic controller.	I-Reply	I-6	Reply	20440
The subsection of on-policy  data *near* the expert is the most relevant  for robust control; the data collected in early stages of learning not near the expert transitions will not assist the dynamics model.	I-Reply	I-6	Reply	20440

The paper "OBJECTIVE MISMATCH IN MODEL-BASED REINFORCEMENT LEARNING" explores the relationships between model optimization and control improvement in model-based reinforcement learning.	O	O	Review	20440
While it is an interesting problem, the paper fails at demonstrating really useful effects, and the writting needs to be greatly improved to help reader to focus on salient points.	B-Review	B-6	Review	20440
<sep> <sep> From my point of view, the main problem of this paper is that it is too messy and it is very difficult to understand what authors want to show, as i) there is a very important lack of experimental details (e.g., main aspects of models and controllers should be clearly stated) and ii) analysis is to wordy, authors should emphasize the message in each part.	B-Review	B-4	Review	20440
From the experiments in 4.1, the only thing that I got is from the last sentence "noisy trend of higher reward with better model loss".	I-Review	I-4	Review	20440
are these results from LL computed on a validation set ?	I-Review	I-4	Review	20440
If not, this is not reallly meaningfull since high LL may only indicate overfitting.	I-Review	I-4	Review	20440
If yes, how was the validation data collected ?	I-Review	I-4	Review	20440
If the collection is not inline with training it is difficult to understand what we observe since we only need LL to be good on the path from the current to the opitmal policy, not everywhere.	I-Review	I-4	Review	20440
Even if the validation data is inline with training, there remains the difficulty of over-fitting in the policy area (for the on-policy experiments at least).	I-Review	I-4	Review	20440
Is there something else ?	I-Review	I-4	Review	20440
From 4.2 we observe that it is unsurprisingly better to learn the model from the policy trajectories.	B-Review	B-5	Review	20440
From 4.3, we observe that an adversarial is able to reduce rewards without losing in LL.	B-Review	B-1	Review	20440
Ok, the adversarial is able to lock the controler in a sub-optimal area while still being good to model the dynamics elsewhere, but what does it show ?	I-Review	I-1	Review	20440
Finally, proposal to cope with the identified mismatch are not clearly explained and not very convincing.	B-Review	B-2	Review	20440
Is re-weighting helping in collecting higher rewards ?	I-Review	I-2	Review	20440
<sep> <sep> From my point of view, this work is in a too preliminary state to be published at ICLR	O	O	Review	20440
R1: From 4.3, we observe that an adversarial is able to reduce rewards without losing in LL.	O	O	Reply	20440
Ok, the adversarial is able to lock the controler in a sub-optimal area while still being good to model the dynamics elsewhere, but what does it show ?	O	O	Reply	20440
<sep> &gt;&gt; This shows that training a dynamics model to a different local minimum (low NLL) could result in a sub-optimal controller.	B-Reply	B-1	Reply	20440
This effect mirrors the results shown in fig3e where some models with ‚Äúgood‚Äù NLL still achieve low reward.	I-Reply	I-1	Reply	20440
When training a model with stochastic methods there is no way to secure coverage of a specific area of the state space, so similar effects could be observed.	I-Reply	I-1	Reply	20440
<sep> <sep> <sep> R1: Finally, proposal to cope with the identified mismatch are not clearly explained and not very convincing.	O	O	Reply	20440
Is re-weighting helping in collecting higher rewards ?	O	O	Reply	20440
<sep> <sep> &gt;&gt; Multiple reviewers have brought this point up, and we will expand it‚Äôs explanation.	B-Reply	B-2	Reply	20440
Re-weighting is helping to get higher rewards in a particular area of interest ‚Äì low data  amounts near the expert trajectory.	I-Reply	I-2	Reply	20440
In the regime of dataset size of 100 to 1000 points, the re-weighting is able to solve the task for many different epsilons, but the standard training method only does so with the highest end of the dataset size.	I-Reply	I-2	Reply	20440
This is the region showing the impact of our method, and we included the full picture to show two additional points of interest (best illustrated in the standard training method).	I-Reply	I-2	Reply	20440
1) data collected too close to expert will not result in a robust controller ‚Äì seen as the dark area at the bottom of both plots and 2) there is a line where data too far from expert no longer is able to solve the task at a set size ‚Äì seen as the diagonal line of high vs low reward in the center of the standard plot.	I-Reply	I-2	Reply	20440

This paper introduces MusicNet, a new dataset.	O	O	Review	266
Application of ML techniques to music have been limited due to scarcity of exactly the kind of data that is provided here: meticulously annotated, carefully verified and organized, containing enough "hours" of music, and where genre has been well constrained in order to allow for sufficient homogeneity in the data to help ensure usefulness.	O	O	Review	266
This is great for the community.	O	O	Review	266
The description of the validation of the dataset is interesting, and indicates a careful process was followed.	O	O	Review	266
The authors provide just enough basic experiments to show that this dataset is big enough that good low-level features (i.e. expected sinusoidal variations) can indeed be learned in an end-to-end context.	O	O	Review	266
One might argue that in terms of learning representations, the work presented here contributes more in the dataset than in the experiments or techniques used.	O	O	Review	266
However, given the challenges of acquiring good datasets, and given the essential role such datasets play for the community in moving research forward and providing baseline reference points, I feel that this contribution carries substantial weight in terms of expected future rewards. (	O	O	Review	266
If research groups were making great new datasets available on a regular basis, that would place this in a different context.	O	O	Review	266
But so far, that is not the case.)	O	O	Review	266
In otherwords, while the experiments/techniques are not necessarily in the top 50% of accepted papers (per the review criteria), I am guessing that the dataset is in the top 15% or better.	O	O	Review	266
Thank you for your positive comments.	O	O	Reply	266

This paper describes the creation of a corpus of freely-licensed classical music recordings along with corresponding MIDI-scores aligned to the audio.	O	O	Review	266
It also describes experiments in polyphonic transcription using various deep learning approaches, which show promising results.	O	O	Review	266
<sep> <sep> The paper is a little disorganised and somewhat contradictory in parts.	B-Review	B-1	Review	266
For example, I find the first sentence in section 2 (MusicNet) would better be pushed one paragraph below so that the section be allowed to begin with a survey of the tools available to researchers in music.	I-Review	I-1	Review	266
Also, the description for Table 3 should probably appear somewhere in the Methods section.	I-Review	I-1	Review	266
Last example: the abstract/intro says the purpose is note prediction; later (4th paragraph of intro) there's a claim that the focus is "learning low-level features of music...." I find this slightly disorienting.	I-Review	I-1	Review	266
<sep> <sep> Although others (Uehara et al 2016, for example) have discussed collection platforms and corpora, this work is interesting because of its size and the approach for generating features.	O	O	Review	266
I'm interested in what the authors will to do expand the offerings in the corpus, both in terms of volume and diversity.	O	O	Review	266
<sep> <sep> Thank you for your feedback on our writing.	O	O	Reply	266
We agree with your observations and we have addressed some of these issues in the latest revision.	B-Reply	B-1	Reply	266
We will be sure to also clarify that the purpose of our experiments is to understand low-level features of music.	I-Reply	I-1	Reply	266

The paper introduces a new dataset called MusicNet (presumably analogous to ImageNet), featuring dense ground truth labels for 30+ hours of classical music, which is provided as raw audio.	O	O	Review	266
Such a dataset is extremely valuable for music information retrieval (MIR) research and a dataset of this size has never before been publicly available.	O	O	Review	266
It has the potential to dramatically increase the impact of modern machine learning techniques (e.g. deep learning) in this field, whose adoption has previously been hampered by a lack of available datasets that are large enough.	O	O	Review	266
The paper is clear and well-written.	O	O	Review	266
<sep> <sep> The paper also features some "example" experiments using the dataset, which I am somewhat less excited about.	O	O	Review	266
The authors decided to focus on one single task that is not particularly challenging: identifying pitches in isolated segments of audio.	O	O	Review	266
Pitch information is a fairly low-level characteristic of music.	O	O	Review	266
Considering that isolated fragments are used as input, this is a relatively simple problem that probably doesn't even require machine learning to solve adequately, e.g. peak picking on a spectral representation could already get you pretty far.	O	O	Review	266
It's not clear what value the machine learning component in the proposed approach actually adds, if any.	O	O	Review	266
I could be wrong about this as I haven't done the comparison myself, but I think the burden is on the authors to demonstrate that using ML here is actually useful.	O	O	Review	266
<sep> <sep> I would argue that one of the strenghts of the dataset is the variety of label information it provides, so a much more convincing setup would have been to demonstrate many different prediction tasks for both low-level (e.g. pitch, onsets) and high-level (e.g. composer) characteristics, perhaps with fewer and simpler models -- maybe even sticking to spectrogram input and forgoing raw audio input for the time being, as this comparison seems orthogonal to the introduction of the dataset itself.	O	O	Review	266
As it stands, I feel that the fact that the experiments are relatively uninteresting detracts from the main point of the paper, which is to introduce a new public dataset that is truly unique in terms of its scale and scope.	O	O	Review	266
<sep> <sep> That said, the experiments seem to have been conducted in a rigorous fashion and the evaluation and analysis of the resulting models is properly executed.	O	O	Review	266
<sep> <sep> Re: Section 4.5, it is rather unsurprising to me that a pitch detector would learn filters that resemble pitches (i.e. sinusoids), although the observation that this requires a relatively large amount of data is interesting.	B-Review	B-2	Review	266
However, it would be more interesting to demonstrate that this is also the case for higher-level tasks.	I-Review	I-2	Review	266
The authors favourably compare the features learnt by their model with prior work on end-to-end learning from raw audio, but neglect that the tasks considered in this work were much more high-level.	I-Review	I-2	Review	266
<sep> <sep> Some might also question whether ICLR is the appropriate venue to introduce a new dataset, but personally I think it's a great idea to submit it here, seeing as it will reach the right people.	B-Review	B-1	Review	266
I suppose this is up to the organisers and the program committee, but I thought it important to mention this, because I don't think this paper merits acceptance based on its experimental results alone.	I-Review	I-1	Review	266
Thank you for your positive comments regarding the dataset.	O	O	Reply	266
<sep> <sep> We disagree that note identification is ‚Äúnot particularly challenging.	B-Reply	B-1	Reply	266
‚Äù This task is closely related to fundamental frequency estimation, which has been studied extensively in the music information retrieval community.	I-Reply	I-1	Reply	266
For a survey, see	I-Reply	I-1	Reply	266
<sep> <a href="http://www.eecs.qmul.ac.uk/~emmanouilb/papers/JIIS-MIRrors-AMT-postprint.pdf" target="_blank" rel="nofollow">http://www.eecs.qmul.ac.uk/~emmanouilb/papers/JIIS-MIRrors-AMT-postprint.pdf</a>	I-Reply	I-1	Reply	266
<sep> We have updated our related works section on page 5 to give more context for the experiments.	I-Reply	I-1	Reply	266

Summary:	O	O	Review	266
<sep> The paper presents a new set of metrics for evaluating disentangled representations in both supervised and unsupervised settings.	O	O	Review	266
Disentangled representations are evaluated along three dimensions: informativeness, separability, and interpretability.	O	O	Review	266
While previous work offers metrics for similar dimensions (e.g., (Eastwood &amp; Williams, 2018)), the paper suggests that the metrics of the submission are superior to (Eastwood &amp; Williams, 2018), based on a comparison between FactorVAE and Beta-VAE.	O	O	Review	266
<sep> <sep> Strengths:	O	O	Review	266
<sep> (1) The metrics of the paper are well motivated from an information-theoretic standpoint.	O	O	Review	266
While, in some cases, the metrics themselves are straight applications of information theory (e.g., informativeness metric == mutual information), the authors came up with new metrics when existing information-theoretic definitions could be fooled by, e.g., introducing noisy and independent latent representations z.	O	O	Review	266
<sep> (2) Experimental results show that these metrics are better than previous metrics at discriminating between FactorVAE and Beta-VAE (in an experimental setting where the former is clearly superior to the latter).	O	O	Review	266
<sep> <sep> (3) As opposed to much of prior work, these metrics do not require any training, which can be considered a plus as they do not require adaptation for each (sub)domain.	O	O	Review	266
<sep> <sep> (4) The paper is overall well written and clear.	O	O	Review	266
I very much enjoyed reading it.	O	O	Review	266
<sep> <sep> Weaknesses:	O	O	Review	266
<sep> (1) My main concern with the paper, which makes me vote for ‚Äúweak accept‚Äù instead of ‚Äúaccept‚Äù: The metrics of the paper are compared against previous metrics (Eastwood &amp; Williams, 2018) on *only two* types of disentangled representations, namely FactorVAE and Beta-VAE, and in one experimental condition. (	B-Review	B-1	Review	266
There is plenty of other experimental material in the appendix which also introduces AAE, but none of it seems to compare against previous *metrics*).	I-Review	I-1	Review	266
I think comparing metrics on only two systems is somewhat problematic, and we don‚Äôt know how general the results are.	I-Review	I-1	Review	266
I would have preferred to see FactorVAE and Beta-VAE evaluated with fewer hyperparameter choices to allow introducing more variational approaches.	I-Review	I-1	Review	266
Could you (the authors) at least evaluate AAE against Eastwood &amp; Williams too?	I-Review	I-1	Review	266
This concern is not just mere quibbling, as the authors have shown (e.g., in Section 3.2) that specific edge cases can fool na√Øve metrics (e.g., by introducing noisy and independent latent variables), and there may be other edge cases that the authors have not considered.	I-Review	I-1	Review	266
I think evaluating new metrics against previous work (i.e., metrics) on only two underlying systems is not very convincing.	I-Review	I-1	Review	266
I acknowledge that the paper offers *lots* of experiments ‚Äì the full pdf is 30 pages (!) ‚	I-Review	I-1	Review	266
Äì but I think some of the existing ones could go to leave space for evaluations using more underlying VAE/baselines/edge-case systems.	I-Review	I-1	Review	266
<sep> <sep> (2) The paper presents six metrics (MI, MISJED, WSEPIN, WINDIN, RMIG, JEMMIG) along three dimensions.	B-Review	B-2	Review	266
While each individual metric makes sense, I feel the paper lacks a discussion section that ties these pieces together and suggests a way of using these metrics conjointly across the three dimensions towards building better-disentangled representations (the paper has a ‚Äúdiscussion‚Äù section, but it is very short and actually more of a conclusion).	I-Review	I-2	Review	266
The more metrics we have, the more chances each underlying VAE model can ‚Äúwin‚Äù on one of the metrics, which is not particularly enlightening.	I-Review	I-2	Review	266
<sep> <sep> (3) The paper is not self-contained, and some parts are almost impossible to understand without familiarity with (Kim &amp; Mnih, 2018) and (Higgins et al 2017a).	B-Review	B-3	Review	266
It uses technical terms of these papers without explanations (e.g., TC is not even spelled out it seems).	I-Review	I-3	Review	266
Hyperparameters of these papers (e.g., beta, gamma) are used without explanation.	I-Review	I-3	Review	266
<sep> <sep> (4) There is no related work section.	B-Review	B-4	Review	266
Such a section could, e.g., make what is borrowed from (Kim &amp; Mnih, 2018; Higgins et al 2017a) more understandable.	I-Review	I-4	Review	266
<sep> <sep> Overall, I think it is a nice paper that makes significant contributions to the problem of building better disentangles representations thanks to better evaluation metrics.	O	O	Review	266
The empirical support for some of the claims (e.g., superiority to (Eastwood &amp; Williams, 2018)) is a bit weak, but other strengths mentioned above largely make up for that.	O	O	Review	266
<sep> <sep> Minor comments:	O	O	Review	266
<sep> The definitions of SEPIN@k and INDIN@k don‚Äôt seem quite right.	B-Review	B-5	Review	266
The summation iterates over z_0, ‚Ä¶, z_k-1, leaving off z_k, ‚Ä¶, z_L-1, but the latter variables might contain some z‚Äôs with lowest mutual information with x. The way the ‚Äòsorted‚Äô function is written only has the effect of reordering z_0, ‚Ä¶, z_{k-1} among themselves, never considering any of the z_k and above whatever their MI‚Äôs are, which is probably not what the authors meant.	I-Review	I-5	Review	266
Perhaps ‚Äòsorted‚Äô is intended to both sort and rename z‚Äôs, but if z‚Äôs are indeed renamed I think this should be indicated mathematically otherwise the equation is wrong (e.g., (z‚Äô_1, ‚Ä¶, z‚Äô_{L-1}) = sorted_by_MI(z_1, ‚Ä¶, z_{L_1})).	I-Review	I-5	Review	266
<sep> <sep> Typos in WSEPIN and WINDIN definitions: ‚Äú0 = 1‚Äù -&gt; ‚Äúi = 1‚Äù?	B-Review	B-6	Review	266
<sep> <sep> Figure 1: ‚ÄúImage‚Äù?	B-Review	B-7	Review	266
The paper is written in general terms and doesn‚Äôt seem to assume otherwise x is an image representation (or does it?).	I-Review	I-7	Review	266
<sep> <sep> Section 3.4: ‚ÄúTable.	B-Review	B-8	Review	266
1‚Äù -&gt; ‚ÄúTable 1‚Äù	I-Review	I-8	Review	266
<sep> Table 1 vs. title of Section 3.1: The author‚Äôs informativeness metric doesn‚Äôt have a name, but the section title contains ‚Äúinformativeness,‚Äù which could be confusing vs. ‚Äúinformativeness‚Äù in Table 1 which is a completely different metric.	B-Review	B-9	Review	266
<sep> <sep> Page 8, interpretability: ‚ÄúTC=10‚Äù.	B-Review	B-10	Review	266
Do you mean ‚ÄúTC loss‚Äù here?	I-Review	I-10	Review	266
I presume 10 is the value of a hyperparameter of the FactorVAE paper (gamma?),	I-Review	I-10	Review	266
and not the actual value of the TC term.	I-Review	I-10	Review	266
Same question for Figure 9 and later figures of the appendix.	I-Review	I-10	Review	266
Thank you for your detailed comments and suggestions.	O	O	Reply	266
We would like to address your concerns as follows:	O	O	Reply	266
<sep> 1) &gt;&gt; My main concern with the paper, ‚Ä¶	O	O	Reply	266
The main reason for focusing on FactorVAEs and BetaVAEs is that the two models clearly highlight the difference between metrics, and these justify the need for better metrics, which motivated our research in the first place.	B-Reply	B-1	Reply	266
As shown in Figs.	I-Reply	I-1	Reply	266
5a,b and Figs.	I-Reply	I-1	Reply	266
7a,b, RMIG and JEMMIG favor FactorVAEs to BetaVAEs while ‚ÄúDisentanglement‚Äù and ‚ÄúCompleteness‚Äù favor BetaVAEs over FactorVAEs.	I-Reply	I-1	Reply	266
Such contradiction between two evaluation systems allows us to confidently infer that our metrics are more accurate than those in [1] if we can show that FactorVAEs actually learn better disentangled representations than BetaVAEs.	I-Reply	I-1	Reply	266
In our paper, we verify this hypothesis using visualization (Fig.16), and also draw from the support by the work of Kim et al, 2018 [2].	I-Reply	I-1	Reply	266
4 and Fig.	I-Reply	I-1	Reply	266
<sep> The AAE models, on the other hand, do not reveal differences between metrics.	I-Reply	I-1	Reply	266
Both ours and those metrics in [1] show that AAEs are not as good as BetaVAEs but with different gaps (<a href="https://ibb.co/7NxtTvQ" target="_blank" rel="nofollow">https://ibb.co/7NxtTvQ</a> (JEMMIG), <a href="https://ibb.co/g9hKKYJ" target="_blank" rel="nofollow">https://ibb.co/g9hKKYJ</a> (RMIG), <a href="https://ibb.co/gS4fbtm" target="_blank" rel="nofollow">https://ibb.co/gS4fbtm</a> (Disentanglement), <a href="https://ibb.co/PWL83Mm" target="_blank" rel="nofollow">https://ibb.co/PWL83Mm</a> (Completeness)).	I-Reply	I-1	Reply	266
Visualization also provides little help because neither BetaVAEs nor AAEs show good interpretability.	I-Reply	I-1	Reply	266
<sep> <sep> Please note that the experiments on FactorVAEs and BetaVAEs are mainly to show that our metrics produce more accurate and more reasonable results than the metrics in [1]. There are other advantages of our metrics that these metrics do not have.	I-Reply	I-1	Reply	266
For example, our metrics are theoretically sound, our metrics do not use classifiers, our metrics produce a single score (compared to 3 different scores of [1]).	I-Reply	I-1	Reply	266
We refer Reviewer 1 to Table 1, Appdx.	I-Reply	I-1	Reply	266
7, Appdx.	I-Reply	I-1	Reply	266
8 for detailed analyses.	I-Reply	I-1	Reply	266
<sep> <sep> However, we agree with the Reviewer 1 that our work has not covered all possible edge cases and there may exist situations in which our metrics can be fooled (and it does not mean that existing metrics cannot be fooled in these cases).	I-Reply	I-1	Reply	266
We leave this room for future exploration and hope that other researchers can improve upon our work to derive better metrics for disentanglement learning.	I-Reply	I-1	Reply	266
<sep> <sep> 2) &gt;&gt; The paper presents six metrics ‚Ä¶	O	O	Reply	266
We thank Reviewer 1 for pointing that out.	B-Reply	B-2	Reply	266
We have revised the Discussion section to highlight WSEPIN and JEMMIG as our key metrics.	I-Reply	I-2	Reply	266
<sep> <sep> 3) &gt;&gt; The paper is not self-contained, and some parts are almost impossible to understand without ‚Ä¶	O	O	Reply	266
We acknowledge that we assume readers are familiar with FactorVAEs, BetaVAEs, AAEs before reading our paper.	B-Reply	B-3	Reply	266
We have added detailed description of these models in the Appdx.	I-Reply	I-3	Reply	266
1 in the revised version.	I-Reply	I-3	Reply	266
<sep> <sep> &gt;&gt;Some hyperparameters (TC, Beta) were used without explanation‚Ä¶	O	O	Reply	266
In the revised version, we have added a sentence to the second paragraph in the Experiment section to explicitly describe these hyperparameters.	B-Reply	B-3	Reply	266
<sep> <sep> 4) &gt;&gt; There is no related work section.	O	O	Reply	266
Such a section could, e.g., make what is borrowed from (Kim &amp; Mnih, 2018; Higgins et al 2017a) more understandable.	O	O	Reply	266
<sep> Thank you for pointing that out.	B-Reply	B-4	Reply	266
Since the main text is already quite long (Reviewer 2 even advises to cut 2 pages down!),	I-Reply	I-4	Reply	266
we chose to embed related work in Introduction and focus on the metrics.	I-Reply	I-4	Reply	266
More detailed comparisons between our metrics and the existing work are included in Appdx.	I-Reply	I-4	Reply	266
8: Analysis of existing metrics for disentanglement.	I-Reply	I-4	Reply	266
<sep> <sep> 5) &gt;&gt; The definitions of SEPIN@k and INDIN@k don‚Äôt seem quite right‚Ä¶	O	O	Reply	266
In case of SEPIN@k and INDIN@k, we want to do both sorting and re-indexing.	B-Reply	B-5	Reply	266
We have modified our notations in the revised version to resolve the ambiguity pointed out by Reviewer 1.	I-Reply	I-5	Reply	266
<sep> <sep> 6) &gt;&gt; Page 8, interpretability: ‚ÄúTC=10‚Äù.	O	O	Reply	266
Do you ‚Ä¶	O	O	Reply	266
‚ÄòTC‚Äô here refers to the coefficient of the additional TC loss in the FactorVAE model.	B-Reply	B-10	Reply	266
It is the gamma hyperparameter in the original FactorVAE paper (Kim et al, 2018)	I-Reply	I-10	Reply	266
<sep> 7) Finally, we thank Reviewer 1 for pointing out typos in our paper and we have fixed all of them in our revised version.	O	O	Reply	266
<sep> <sep> References	O	O	Reply	266
==========	O	O	Reply	266
[1] A framework for the quantitative evaluation of disentangled representations, Eastwood and Williams, 2018	O	O	Reply	266
[2] Disentangling by factorizing, Kim et al, 2018	O	O	Reply	266

This paper provides a mathematically-grounded set of axes to describe the effectiveness of latent representations: informativeness (as the mutual information between input and z), separability (I(x, zi, zj) = 0, i!=j), and interpretability.	O	O	Review	266
They accompany these with metrics to evaluate representations across those criteria.	O	O	Review	266
<sep> <sep> They use this to evaluate B-VAE, FactorVAE and AAE.	O	O	Review	266
Tl;dr B-VAE are the most separable, FactorVAE are the most interpretable.	O	O	Review	266
<sep> <sep> I think the paper serves as a great primer for people who are not familiar with disentangled representations, and also proposes a necessary vocabulary for understanding the trade-offs of different representation disentangling methods.	O	O	Review	266
<sep> <sep> The paper is too long, you could cut the final paragraph of S2.1 without losing anything (that's half a page already).	B-Review	B-1	Review	266
You can (and should) edit this down.	I-Review	I-1	Review	266
I don't think this paper should be longer than 8 pages.	I-Review	I-1	Review	266
<sep> <sep> P.s.	B-Review	B-2	Review	266
did you really cite "Error Function" to the wikipedia page for Error function?	I-Review	I-2	Review	266
Thank you for your comments.	O	O	Reply	266
<sep> <sep> We agree that our paper (including the appendix) is long because we tried to make the paper as comprehensive and self-contained as possible.	B-Reply	B-1	Reply	266
We hope that Reviewer 2 (and other readers) will find our paper enjoyable to read.	I-Reply	I-1	Reply	266
<sep> For the reason of comprehensiveness, we believe the two paragraphs in Section 2.1 are important to place our concepts in context and highlight the difference between our work and other related works such as [1, 2, 3]. We hope the readers will benefit from being informed, as suggested by Reviewer 1 and Reviewer 3.	I-Reply	I-1	Reply	266
Therefore, we decide to keep them in our revised version.	I-Reply	I-1	Reply	266
<sep> <sep> We would like to say that we do not cite the ‚Äúerror function‚Äù but its approximations that give low errors.	B-Reply	B-2	Reply	266
<sep> <sep> [1] Towards a definition of disentangled representations, Higgins et al, 2018	O	O	Reply	266
[2] A framework for the quantitative evaluation of disentangled representations, Eastwood&amp;Williams, 2018	O	O	Reply	266
[3] Learning deep disentangled embeddings with the f-statistic loss, Ridgeway et al, 2018	O	O	Reply	266

This paper defines precise semantics&nbsp;of disentanglement representations and presents evaluation metrics to evaluate such representations.	O	O	Review	266
The authors provides information-theoretic characterization disentangled representations along three dimensions: informativeness, separability, and interpretability; and propose metrics to measure them.	O	O	Review	266
The authors argue that:- Informativeness can be defined as the mutual information&nbsp;between a particular representation (or a group of representations) w.r.t the data---I(x,z_i)&nbsp;- Separability between two representations can be achieved if they do not share any common information about the data---I(x,z_i,z_j) = 0&nbsp;- Interpretability with respect to a concept is achieved if a representation contains information about the concept---I(z_i, y_k) = H(z_i) = H(y_k).The authors define a disentangled representation as a representation that is fully separable and fully interpretable and propose a suite of metrics to evaluate disentangled representations.	O	O	Review	266
Finally, the authors evaluate several representation learning methods (FactorVAE, betaVAE, AAE) using these metrics on toy and real datasets.	O	O	Review	266
<sep> <sep> I think this paper addresses an important problem of quantifying and measuring disentangled representations.	O	O	Review	266
The proposed metrics are reasonably sound and the authors provide an extensive set of experiments to show how to use them in practice.&nbsp;	O	O	Review	266
<sep> I have one comment regarding the sheer number of metrics that are presented in the paper and their practical usage.	B-Review	B-1	Review	266
How do the authors see them being used in the future to compare models?	I-Review	I-1	Review	266
Is one of the main arguments of the paper to encourage other people to use all of these metrics?	I-Review	I-1	Review	266
Are all of them needed, given some of them seem to correlate with others?	I-Review	I-1	Review	266
I think it would be helpful to highlight a few metrics or aggregates of them to inform future research in this area.	I-Review	I-1	Review	266
<sep> <sep> Also, for the paper to be more self-contained, I think the authors should include a short discussion about models that they compare in the experiments.	B-Review	B-2	Review	266
<sep> <sep> Thank you for your insightful comments.	O	O	Reply	266
<sep> <sep> 1) &gt;&gt; I have one comment regarding the sheer number of metrics ‚Ä¶	O	O	Reply	266
In Table 1 and in the experiment part, we theoretically and empirically show that our proposed metrics are more advanced than the existing metrics for comparing disentanglement learning models.	B-Reply	B-1	Reply	266
We hope that with these advantages, our metrics will be widely used in the future.	I-Reply	I-1	Reply	266
<sep> <sep> The reason we proposed several correlated metrics (e.g. WSPEIN, SEPIN@k, WINDIN, INDIN@k or RMIG, JEMMIG) in our paper is that we want to make our work as comprehensive as possible by considering different scenarios and approaches when designing our metrics.	I-Reply	I-1	Reply	266
<sep> <sep> We agree with Reviewer 3 that we should highlight some key metrics to inform future research.	I-Reply	I-1	Reply	266
Based on our definition of disentangled representations, JEMMIG and WSEPIN are the two keys metrics in case ground truth factors are and are not available, respectively.	I-Reply	I-1	Reply	266
We have added this point to the Discussion part in our revised version.	I-Reply	I-1	Reply	266
<sep> <sep> 2) &gt;&gt; Also, for the paper to be more self-contained, I think the authors should include a short discussion about models that they compare in the experiments.	O	O	Reply	266
<sep> We thank Reviewer 3 for this useful advice.	O	O	Reply	266
We have added a discussion about these models in the Appdx.	B-Reply	B-2	Reply	266
1 of the revised version.	I-Reply	I-2	Reply	266

This work proposes CROWN-IBP - novel and efficient certified defense method against adversarial attacks, by combining linear relaxation methods which tend to have tighter bounds with the more efficient interval-based methods.	O	O	Review	20116
With an attempt to augment the IBP method with its lower computation complexity with the tight CROWN bounds, to get the best of both worlds.	O	O	Review	20116
One of the primary contributions here is that reduction of computation complexity by an order of \Ln while maintaining similar or better bounds on error.	O	O	Review	20116
The authors show compelling results with varied sized networks on both MNIST and CIFAR dataset, providing significant improvements over past baselines.	O	O	Review	20116
<sep> <sep> The paper itself is very well written, lucidly articulating the key contributions of the paper and highlighting the key results.	O	O	Review	20116
The method and rationale behind it quite easy to follow.	O	O	Review	20116
<sep> <sep> <sep> Pros:	O	O	Review	20116
&gt; Show significant benefits over previous baseline with 7.02% verified test error on MNIST at  \epsilon = 0.3, and 66.94% on CIFAR-10 with \epsilon = 8/255	O	O	Review	20116
&gt; The proposed method is computationally viable, with up to 20X faster than linear relaxation methods with similar.	O	O	Review	20116
better test errors and within 5-7X slower than the conventional IBP methods with worse errors	O	O	Review	20116
<sep> Cons:	O	O	Review	20116
&gt; Extensive experiments with more advanced networks/datasets would have been more convincing, esp.	B-Review	B-1	Review	20116
given the computation efficiency that enables such experiments	I-Review	I-1	Review	20116
&gt; More elaborate insights into the choice of the training config/hyper-params esp.	B-Review	B-2	Review	20116
with the choice of \K_start, \K_end across the different datasets	I-Review	I-2	Review	20116
<sep> <sep> Other comments:	O	O	Review	20116
&gt; For the computational efficiency studies, it would be helpful to provide a breakdown of the costs between the different layers and operations, to better asses/confirm that benefits of CROWN-IBP method	B-Review	B-3	Review	20116
&gt; Impact of other complementary techniques such a lower precision/quantization?	B-Review	B-4	Review	20116
One fo the references compared against is the Gowal et al 2018 for the as a baseline, however, it seems to be those results were obtained on a different HW platform (TPUs - motioned in Appendix-B), with potentially different computational accuracies (BFLOAT16 ?).	I-Review	I-4	Review	20116
So, this bears to question of the impact of precision on these methods and also the computation complexity.	I-Review	I-4	Review	20116
<sep> &gt; Since I'm not very well versed with the current baseline and state-of-art for variable robust training of DNN, it would be good to get an additional confirmation on the validity of the used baselines.	B-Review	B-5	Review	20116
We thank the reviewer for the encouraging comments and constructive feedback.	O	O	Reply	20116
We really appreciate the reviewer‚Äôs precise characterization of the contributions in our work.	O	O	Reply	20116
We provide answers to the raised questions/cons below.	O	O	Reply	20116
<sep> <sep> (Q1).	O	O	Reply	20116
Extensive experiments on advanced networks/datasets	O	O	Reply	20116
<sep> In our paper we use the same networks as the previous work (Gowal et al 2018), to stay comparable with their results, which we call DM-Small, DM-Medium, and DM-Large.	B-Reply	B-1	Reply	20116
During the preparation of this submission, we tried much wider networks by increasing the width of the DM-Large model twice and four times, but they did not yield significant performance improvement.	I-Reply	I-1	Reply	20116
Thus we decided to keep models the same as in previous work for a straightforward comparison.	I-Reply	I-1	Reply	20116
We plan to implement more advanced networks (e.g., ResNet, DenseNet, etc) as the next step and scale to larger datasets is our future work.	I-Reply	I-1	Reply	20116
<sep> <sep> Besides the three models presented in the submitted version of the paper, in this revision, we additionally provide more comprehensive experiments on a large range of MNIST and CIFAR-10 models (18 MNIST models + 17 CIFAR models).	I-Reply	I-1	Reply	20116
The purpose of this experiment is to compare model performance statistics (min, median, and max) on a wide range of models, rather than a few hand-selected models.	I-Reply	I-1	Reply	20116
The results are presented in Appendix F, Table D. On all model structures and parameter settings, CROWN-IBP can outperform IBP in terms of best, median and worst verified errors.	I-Reply	I-1	Reply	20116
Especially, in many situations, the worst-case verified error improves significantly using CROWN-IBP because IBP training is not stable on some of the models.	I-Reply	I-1	Reply	20116
<sep> <sep> (Q2).	O	O	Reply	20116
More elaborate insights into the choice of the training config/hyper-params:	O	O	Reply	20116
<sep> This is a very good suggestion.	B-Reply	B-2	Reply	20116
kappa controls the trade-off between verified accuracy and standard (clean) accuracy and we typically recommend kappa_start=1 and kappa_end=0.	I-Reply	I-2	Reply	20116
beta determines if we want to use a convex relaxation-based the bound or IBP based bound; the general recommendation is to set beta_start=1 and beta_end=0.	I-Reply	I-2	Reply	20116
We added three paragraphs at the end of Appendix B to discuss the selection of hyperparameters in detail.	I-Reply	I-2	Reply	20116
<sep> <sep> (Q3).	O	O	Reply	20116
Breakdown of the cost between different layers and operations:	O	O	Reply	20116
<sep> The per-layer cost for propagating the CROWN-IBP bound backward is actually quite simple: in a high level, for all operations in the neural network, it is times  is the number of classes, for MNIST/CIFAR it is 10) more expensive than forward propagation as there are specifications per example.	B-Reply	B-3	Reply	20116
Thus CROWN-IBP is well suited to problems where the number of classes is small (more classes can be done efficiently by subsampling of specifications, which is left to future work).	I-Reply	I-3	Reply	20116
CROWN-IBP is significantly more efficient than CROWN (Zhang et al 2018) and convex adversarial polytope (Wong et al 2018); it is times faster than these approaches, where is the number of layers and is hidden layer size.	I-Reply	I-3	Reply	20116
Generally, (ordinary) CROWN and convex adversarial polytopes are too slow for training.	I-Reply	I-3	Reply	20116
<sep> <sep> Practically, CROWN-IBP training time can be much less than times slower than IBP, as CROWN-IBP is typically only used during the epsilon schedule rather than the entire training process, and CROWN-IBP generally executes more efficiently than IBP on parallel hardware because it packs denser computation that utilizes hardware accelerators better.	I-Reply	I-3	Reply	20116
<sep> <sep> Empirically, we have further optimized the implementation of CROWN-IBP (with roughly 2X reduction in training time in Table G), and we have prepared a multi-GPU version that can train the largest CIFAR-10 model in about 1 day using 4 GPUs.	I-Reply	I-3	Reply	20116
We have provided updated training time measurement in Appendix J and Table G. On the largest CIFAR-10 model, training using CROWN-IBP is actually only about twice slower than IBP.	I-Reply	I-3	Reply	20116
<sep> <sep> <sep> (Q4).	O	O	Reply	20116
Complementary techniques such as lower precision/quantization:	O	O	Reply	20116
<sep> To see if bfloat16 has any impact on training results, we additionally implement CROWN-IBP on multi-GPUs with float32.	B-Reply	B-4	Reply	20116
We train the CIFAR-10 model using the same hyperparameters as on TPUs and we found that the differences between TPU and GPU training results are small.	I-Reply	I-4	Reply	20116
The results are provided in Table H. We see no big difference between bfloat16 and float32 training.	I-Reply	I-4	Reply	20116
<sep> <sep> (Q5).	O	O	Reply	20116
Confirmation on state-of-the-art verifiable training baseline:	O	O	Reply	20116
<sep> For the verification of L infinity norm perturbations, the current best baselines in most settings are IBP (Gowal et al 2018), except on CIFAR 2/255 where (Wong et al 2018) is the best.	B-Reply	B-5	Reply	20116
CROWN-IBP can achieve better-verified accuracy than previous state-of-the-art works in all settings.	I-Reply	I-5	Reply	20116
<sep> <sep> We thank the reviewer again and will be glad to discuss with the reviewer on any parts that are still unclear, or any additional concerns raised.	O	O	Reply	20116

This paper proposes a new variation on certified adversarial training method that builds on two prior works IBP and CROWN.	O	O	Review	20116
They showed the method outperformed all previous linear relaxation and bound propagation based certified defenses.	O	O	Review	20116
<sep> <sep> Pros:	O	O	Review	20116
1.	O	O	Review	20116
The empirical results are strong.	O	O	Review	20116
The method achieved SOTA.	O	O	Review	20116
<sep> <sep> Cons:	O	O	Review	20116
1.	O	O	Review	20116
Novelty seems small.	B-Review	B-1	Review	20116
It is a straightforward combination of prior works, by adding two bounds together.	I-Review	I-1	Review	20116
<sep> 2.	B-Review	B-2	Review	20116
Adds a new hyperparameter for tuning.	I-Review	I-2	Review	20116
<sep> 3.	O	O	Review	20116
Lack of any theoretical insights/motivation for the proposed method.	B-Review	B-3	Review	20116
Why would we want to combine the two lower bounds?	I-Review	I-3	Review	20116
The reason given in the paper is not very convincing:	I-Review	I-3	Review	20116
<sep> "IBP has better learning power at larger epsilon and can achieve much smaller verified error.	I-Review	I-3	Review	20116
<sep> However, it can be hard to tune due to its very imprecise bound at the beginning of training; on the	I-Review	I-3	Review	20116
other hand, linear relaxation based methods give tighter lower bounds which stabilize training, but it	I-Review	I-3	Review	20116
over-regularizes the network and forbids us to achieve good accuracy."	I-Review	I-3	Review	20116
<sep> <sep> My questions with regards to this:	B-Review	B-4	Review	20116
(i) Why does loose bound result in unstable training?	I-Review	I-4	Review	20116
Tighter bound stabilize training?	I-Review	I-4	Review	20116
<sep> (ii) If we're concerned with using a tighter bound could result in over-regularization, then why not just combine the natural loss with the tight bound, as natural loss can be seen as the loosest bound.	I-Review	I-4	Review	20116
Is IBP crucial?	I-Review	I-4	Review	20116
and why?	I-Review	I-4	Review	20116
<sep> <sep> Dear AnonReviewer3,	O	O	Reply	20116
<sep> Thank you again for your constructive review.	O	O	Reply	20116
Since the discussion period is closing soon, we will really appreciate it if you can read our response and provide us some feedback.	O	O	Reply	20116
We will be glad to discuss with you on any further concerns.	O	O	Reply	20116
<sep> <sep> In our response, we have discussed in detail why a tight bound is helpful for training, and the rationales for combining the two bounds behind the scenes.	B-Reply	B-3	Reply	20116
Our paper is not a naive combination of the two bounds, and we took careful design considerations to get the best of both worlds and achieve SOTA.	I-Reply	I-3	Reply	20116
We hope the reviewer can understand our paper better after reading our response.	I-Reply	I-3	Reply	20116
<sep> <sep> Thank you,	O	O	Reply	20116
Paper 1473 Authors	O	O	Reply	20116

This paper proposes a new method for training certifiably robust models that achieves better results than the previous SOTA results by IBP, with a moderate increase in training time.	O	O	Review	20116
It uses a CROWN-based bound in the warm up phase of IBP, which serves as a better initialization for the later phase of IBP and lead to improvements in both robust and standard accuracy.	O	O	Review	20116
The CROWN-based bound uses IBP to compute bounds for intermediate pre-activations and applies CROWN only to computing the bounds of the margins, which has a complexity between IBP and CROWN.	O	O	Review	20116
The experimental results are verify detailed to demonstrate the improvement.	O	O	Review	20116
<sep> <sep> The improvement is significant enough to me and I tend to accept the paper.	O	O	Review	20116
The results on CIFAR10 with epsilon=8/255 is so far the state-of-the-art.	O	O	Review	20116
However, it is far from being scalable enough to large networks and datasets, which has already been achieved by randomized smoothing based approaches.	B-Review	B-1	Review	20116
On CIFAR10, it takes 32 TPU cores to train a 4-conv-layer network.	I-Review	I-1	Review	20116
Still, such an approach has the advantage of making robust inferences much more efficiently than randomized smoothing, and thus still worth further explorations.	I-Review	I-1	Review	20116
Dear AnonReviewer2,	O	O	Reply	20116
<sep> We thank you for recognizing the contributions of our paper and raising the discussions on randomized smoothing and concerns on expensive computations on TPUs.	O	O	Reply	20116
<sep> <sep> (Answer 1) Compared to the randomized smoothing based method, our bound propagation-based approach has several theoretical and practical benefits:	B-Reply	B-1	Reply	20116
<sep> 1.	I-Reply	I-1	Reply	20116
Recent works [1][2] show that randomized smoothing may not scale well for the important case of L infinity robustness.	I-Reply	I-1	Reply	20116
They provided some preliminary theoretical evidence that even the *optimal* robustness certificate for L infinity smoothing has a dependency on dimension d, thus for high dimensional input (e.g., CIFAR with d=3072), randomized smoothing based method cannot give a good quality bound.	I-Reply	I-1	Reply	20116
On the other hand, for L2 norm, the randomized smoothing certificate is dimension-free.	I-Reply	I-1	Reply	20116
This is a fundamental limitation of randomized smoothing.	I-Reply	I-1	Reply	20116
For the L infinity setting like CIFAR epsilon=8/255, bound propagation-based method like CROWN-IBP still gives the best results.	I-Reply	I-1	Reply	20116
<sep> <sep> 2.	I-Reply	I-1	Reply	20116
As also mentioned by the reviewer, randomized smoothing typically needs a large number of samples, e.g., in Cohen et al 100,000 random samples for a *single* image.	I-Reply	I-1	Reply	20116
In contrast, our verification can be computed using IBP very fast, which is only 2x forward propagation time.	I-Reply	I-1	Reply	20116
Randomized smoothing costs 50,000x more during inference, and our training procedure is 500x (pessimistically) slower during training time.	I-Reply	I-1	Reply	20116
So it is really a trade-off here; each method has its own strength.	I-Reply	I-1	Reply	20116
<sep> <sep> Being scalable to large networks on all important norms with less training/inference cost is still an open challenge.	I-Reply	I-1	Reply	20116
It is not solved by randomized smoothing, nor CROWN-IBP.	I-Reply	I-1	Reply	20116
For the next step, our future work will investigate how to combine the strengths from bound propagation-based certified defense (good for L infinity norm, sample free) and randomized smoothing based approach (good for L2 norm, need a lot of samples).	I-Reply	I-1	Reply	20116
Thus, our contribution as the SOTA bound propagation-based certified defense is important, as it can become an ingredient of the next generation certified defense.	I-Reply	I-1	Reply	20116
<sep> <sep> (Answer 2) Regarding computation cost, the use of 32 TPUs is not necessary.	B-Reply	B-1	Reply	20116
We use TPUs mainly for obtaining a completely fair comparison to IBP (Gowal et al, 2018), as their implementation was TPU-based.	I-Reply	I-1	Reply	20116
We additionally implemented CROWN-IBP using multi-GPUs.	I-Reply	I-1	Reply	20116
Training the same largest CIFAR network takes 1 day on 4x 1080 Ti GPUs (using the same hyperparameters), and we can achieve similar accuracy.	I-Reply	I-1	Reply	20116
We think this computational cost is quite reasonable, compared to other SOTA uncertified defense like adversarial training, which is also quite slow (10-20x extra cost for each epoch, and needs much more epochs to converge than natural training).	I-Reply	I-1	Reply	20116
<sep> <sep> We updated new multi-GPU training results in Table H, and we will open source our multi-GPU training code to make our algorithm available to a broader audience.	I-Reply	I-1	Reply	20116
<sep> <sep> We hope our response addresses your concerns on TPU training and randomized smoothing, and please kindly let us know if you have any further questions.	I-Reply	I-1	Reply	20116
<sep> <sep> References:	O	O	Reply	20116
[1] A Unified Framework for Randomized Smoothing based Certified Defense.	O	O	Reply	20116
<a href="https://openreview.net/pdf?id=ryl71a4YPB" target="_blank" rel="nofollow">https://openreview.net/pdf?id=ryl71a4YPB</a>	O	O	Reply	20116
[2] Filling the Soap of Bubbles: Efficient Black-Box Adversarial Certification with Non-gaussian smoothing.	O	O	Reply	20116
<a href="https://openreview.net/pdf?id=Skg8gJBFvr" target="_blank" rel="nofollow">https://openreview.net/pdf?id=Skg8gJBFvr</a>	O	O	Reply	20116

This paper proposes a simple method for stabilizing the off-policy deep reinforcement learning algorithm, which updates the target network only when the online network performs better than the target network in order to ensure the stability guarantees.	O	O	Review	20009
More specifically, at every T time steps, they execute both the online network and the target network so as to evaluate the performance of each policy.	O	O	Review	20009
Then, they update the target network only when the online network outperforms the target network with high probability.	O	O	Review	20009
The experimental results show that the proposed Conservative-TD3 (C-TD3) is less prone to performance degradation during training.	O	O	Review	20009
<sep> <sep> While the stabilizing off-policy reinforcement learning algorithms would be a significant problem, I have some concerns regarding the presentation and the limitation of the proposed method.	B-Review	B-6	Review	20009
<sep> - In p2, 'Value Iteration and Policy Iteration are algorithms for solving tabular RL tasks with convergence guarantee': Basically, exact value iteration and policy iteration are MDP 'planning' algorithms, NOT reinforcement learning algorithms.	B-Review	B-1	Review	20009
VI and PI assume 'known' transition and reward dynamics thus there is no need to learn anything, while RL basically assumes the 'unknown' environment thus the agent should learn by doing.	I-Review	I-1	Review	20009
<sep> - Algorithm 1, 2, 3 and 4 are not directly related to the proposed method, thus they can be omitted from the paper.	B-Review	B-2	Review	20009
Instead, it would be great to devote more space to the proposed method such as a more detailed theoretical analysis or the pseudo-code of the proposed algorithm.	I-Review	I-2	Review	20009
<sep> - It seems that the performance of the online and target networks is evaluated by Monte-Carlo return which is obtained by executing each policy in the real environment.	B-Review	B-3	Review	20009
This requires additional direct interaction with the environment, which can severely hurt the sample complexity of the algorithm.	I-Review	I-3	Review	20009
In Figure 4, does the x-axis of C-TD3 reflect these additional samples for evaluating the performance of two policies?	I-Review	I-3	Review	20009
<sep> - The abstract says 'our proposed method reduces the variance of the process and improves the overall performance'.	B-Review	B-4	Review	20009
This claim is too strong.	I-Review	I-4	Review	20009
If we see Figure 4, in Walker2d, the mean performance of TD3 reaches 4000 at 400k steps, while the performance of C-TD3 is even less than 3000.	I-Review	I-4	Review	20009
Similarly in HalfCheetah and Ant, the asymptotic performance of TD3 is higher than C-TD3.	I-Review	I-4	Review	20009
It would be great to show the learning curves of TD3 and C-TD3 overlapped.	I-Review	I-4	Review	20009
<sep> - In the experiments, 'discarding failure seeds' cannot be a proper treatment.	B-Review	B-5	Review	20009
Instead of discarding the bad results, the reliable algorithm had to be proposed.	I-Review	I-5	Review	20009
Thank you for your review.	O	O	Reply	20009
<sep> <sep> We understand that the main issue is in how the method was presented.	B-Reply	B-6	Reply	20009
As there is a tight connection between VI/PI and Q-learning/Policy Gradient methods, we thought that this explanation would be easier to comprehend and the motivation would be clearer (a similar approach was made in the TRPO work, which built upon Conservative Policy Iteration).	I-Reply	I-6	Reply	20009
<sep> <sep> However, we understand that this caused more harm than good - thus we would like to state that during the rebuttal period we will be working on rewriting the motivational sections.	I-Reply	I-6	Reply	20009
We will post an additional update once this is done.	I-Reply	I-6	Reply	20009
<sep> <sep> Regarding the other remarks.	O	O	Reply	20009
<sep> - Theory: The goal of the theoretical analysis was to provide intuition.	B-Reply	B-1	Reply	20009
Intuitively, as the probability of improvement increases, then the stable distribution will place more probability mass at being at a higher value.	I-Reply	I-1	Reply	20009
<sep> - Pseudocode: As the approach is not complex, we believe that the flow-chart is easier to comprehend, thus we provided the pseudocode in the appendix.	B-Reply	B-2	Reply	20009
However, if we do end up removing Alg.	I-Reply	I-2	Reply	20009
1-4 in the rewrite, we will follow this advice and place it in the main portion of the paper.	I-Reply	I-2	Reply	20009
<sep> - Evaluation: Indeed the evaluation is performed using Monte Carlo sampling.	B-Reply	B-3	Reply	20009
Just as you have stated this leads to additional environment interactions, we will make sure this is clearer.	I-Reply	I-3	Reply	20009
The X axis in this case corresponds to the number of gradient steps.	I-Reply	I-3	Reply	20009
In our opinion, these are intruiging results which give motivation for further research - for instance find ways to perform off-policy policy evaluation in order to determine which policy is better, i.e., removing the additional environment interactions.	I-Reply	I-3	Reply	20009
<sep> - Claim: We will tune down the claim.	B-Reply	B-4	Reply	20009
While the results did reduce variance across all domains and the asymptotic performance across almost all domains was matched/improved, indeed this is not in all domains and the abstract should reflect these results.	I-Reply	I-4	Reply	20009
<sep> - Failure seeds: We also feel somewhat uncomfortable with this approach, but we believe it is better to be up-front rather than hiding it.	B-Reply	B-5	Reply	20009
These failure seeds occurred both in the C-TD3 and TD3, at a similar frequency, where TD3 is the original code provided by the papers authors; as such, since both algorithms received the same "care" and since this is not the focus of our work, we believe that this approach yields a fair comparison.	I-Reply	I-5	Reply	20009

<sep> [Summary]	O	O	Review	20009
This paper proposes an approach called conservative policy gradients to stabilize the training of deep policy gradient methods.	O	O	Review	20009
At fixed intervals, the current policy and a separate target policy are evaluated with a number of rollouts.	O	O	Review	20009
The target policy is then updated to match the current policy only if the current policy is better than the target policy.	O	O	Review	20009
Experiments show that the proposed method, when applied to TD3, reduces the variance in performance through the training.	O	O	Review	20009
<sep> <sep> [Decision]	O	O	Review	20009
I am not convinced that the proposed method is sound and indeed useful and I vote for rejecting this paper.	B-Review	B-8	Review	20009
Experiments show stable performance.	I-Review	I-8	Review	20009
However, this stability comes at the cost of extra computation and interaction with the environment (to evaluate the policies).	I-Review	I-8	Review	20009
Claims about the method's stability guarantees and overall performance are not supported by theory and experiments.	I-Review	I-8	Review	20009
The submitted paper also needs major improvements in presentation.	I-Review	I-8	Review	20009
<sep> <sep> [Explanation]	O	O	Review	20009
While Proposition 1 provides insights on how the policy evolves, it is too limited to serve as a guarantee.	B-Review	B-7	Review	20009
First, performance does not improve or degrade by a constant number.	I-Review	I-7	Review	20009
Second, the time it takes for the policy to improve is not captured by the theory.	I-Review	I-7	Review	20009
In reality, this time can depend on the hyperparameters or the policy's current performance and might even be unbounded.	I-Review	I-7	Review	20009
<sep> <sep> I do not understand why a characterization of the performance in the limit of time in Proposition 1 is called a stability guarantee while in the rest of the paper stability refers to consistent improvements in the interim performance.	B-Review	B-6	Review	20009
Does stability in this proposition mean that the performance will reach a stationary distribution with bounded support?	I-Review	I-6	Review	20009
This property is merely a result of the assumptions that the performance evolves by a constant number at bounded times and that it does not exceed [v_min,v_max].	I-Review	I-6	Review	20009
<sep> The theory studies the stationary distribution of the target policy's performance but the algorithm uses the online policy to interact with the environment.	B-Review	B-5	Review	20009
In Algorithm 5, line 8 (Section D in the Appendix) the target policy is only used for bootstrapping.	I-Review	I-5	Review	20009
How can a stable target policy result in more stable performance if it is not used to take actions?	I-Review	I-5	Review	20009
<sep> <sep> The paper claims that the proposed method results in improvements in stability and overall performance.	I-Review	I-5	Review	20009
In Figure 3, the proposed method is more stable than the baseline but the overall performance is not better.	I-Review	I-5	Review	20009
<sep> <sep> The proposed method requires more computation and interaction with the environment than the baseline.	B-Review	B-1	Review	20009
The experiments do not seem to compare these two methods with the same number of samples or with the same amount of computation.	I-Review	I-1	Review	20009
Perhaps the extra computation and samples are better spent on training TD3 for a longer time.	I-Review	I-1	Review	20009
<sep> <sep> I find Section 2 hard to follow.	B-Review	B-2	Review	20009
This section describes Value Iteration, Policy Iteration, DQN, and DDPG in detail (with pseudocode) along with their convergence rates.	I-Review	I-2	Review	20009
The message that deep RL algorithms generally lack theoretical guarantees can be conveyed by just describing the linear and deep variants of one method.	I-Review	I-2	Review	20009
In fact, the algorithm whose stability is analyzed in the next sections, TD3, is not described in Section 2 or anywhere else in the paper.	I-Review	I-2	Review	20009
<sep> <sep> Later in Section 3, DDPG and DQN are described as off-policy Deep RL variants of Value Iteration and Policy Iteration.	B-Review	B-3	Review	20009
DQN and DDPG are actually built on Q-learning and Deterministic Policy Gradient (DPG).	I-Review	I-3	Review	20009
<sep> <sep> <sep> [Minor comments]	O	O	Review	20009
In the learning curves in Figure 1, what is the measure of performance and how is it estimated?	B-Review	B-4	Review	20009
A description of the plotted measure is necessary to show that the drops in the estimated performance are indeed due to policy degradation rather than poor estimation.	I-Review	I-4	Review	20009
<sep> <sep> --------------------	O	O	Review	20009
After rebuttal: I have read the authors' response, the other reviews, and the revision.	O	O	Review	20009
The revised version has improved presentation, but the proposed method is still introduced as a method with stability guarantees while the proposition in the paper cannot serve as a stability guarantee, and can only provide intuition on the asymptotic performance.	B-Review	B-6	Review	20009
<sep> <sep> Thank you for your thorough review.	O	O	Reply	20009
We will address your points below:	O	O	Reply	20009
<sep> - Proposition: Indeed as you have mentioned, the Proposition analyzes the asymptotic performance.	B-Reply	B-7	Reply	20009
The goal is to provide intuition - by performing these evaluations and ensuring that there is a high enough probability of improvement, the policy is more likely to continue improving and achieve a stable solution.	I-Reply	I-7	Reply	20009
This is in contrast to other deep rl approaches which are highly unstable.	I-Reply	I-7	Reply	20009
<sep> <sep> - Stability: The target policy is used both as a stable measure for training the critic and at line 13,14 when the policies are evaluated and swapped if needed.	B-Reply	B-6	Reply	20009
Line 8 is also the approach in TD3/DDPG, and as we show in the preliminaries it is inspired by policy iteration techniques.	I-Reply	I-6	Reply	20009
<sep> <sep> - Results: While our approach did not improve the mean performance across all domains, this is the case in most of them.	B-Reply	B-5	Reply	20009
Hopper, Inverted Pendulum, Inverted Double Pendulum and Walker saw improvement both in mean performance and in variance reduction.	I-Reply	I-5	Reply	20009
HalfCheetah is slightly worse.	I-Reply	I-5	Reply	20009
And indeed in Ant we saw a reduction in performance.	I-Reply	I-5	Reply	20009
<sep> <sep> - Computation: In Figure 3, the X axis denotes the number of gradient steps.	B-Reply	B-1	Reply	20009
We will also add simulations for TD3 with a longer training regime, to demonstrate that even with a similar number of samples, our approach improves the overall performance.	I-Reply	I-1	Reply	20009
<sep> <sep> - Section 2: This is also a remark we received from the other reviewers - one which we intend to fix.	B-Reply	B-2	Reply	20009
We will rewrite this section in order to make it clearer.	I-Reply	I-2	Reply	20009
As you noted, DQN and DDPG are derived from Q-learning and DPG, but their origins go further back to VI/PI.	I-Reply	I-2	Reply	20009
<sep> <sep> - Figure 1: The performance in all our graphs was estimated over 100 episodes.	B-Reply	B-4	Reply	20009
Meaning, each 1,000 steps we evaluate the policy for 100 episodes and plot the average performance (per seed).	I-Reply	I-4	Reply	20009
As previous works performed either a single evaluation or 10, we see it as highly unlikely that these drops occur due to poor estimation.	I-Reply	I-4	Reply	20009

This paper proposed to use target network policy as a conservative policy for performance evaluation.	O	O	Review	20009
Instead of performing Polyak averaging on the target network, the authors proposed to utilize statistical hypothesis testing to check whether the performance of the online policy is better than the target network policy and update the target network policy according to the results of the hypothesis testing.	O	O	Review	20009
<sep> <sep> The paper is clear written and easy to follow the core idea.	O	O	Review	20009
As for the experiments, the authors evaluate the proposed method on a variant of TD3 (Conservative-TD3) and the experimental results indicate the proposed method indeed reduces the variance of the expected return.	O	O	Review	20009
Ablation studies has been provided in the appendix to show the effectiveness of the proposed method.	O	O	Review	20009
<sep> <sep> Besides the promising results, I believe there are several concerns that should be clarified before we can conclude that the proposed method can improve the stability.	O	O	Review	20009
<sep> <sep> - Stability Measurement: While the experimental results show that the proposed method can reduce the variance of expected return, it is not a direct measurement of the stability or the robustness of the learned policy.	B-Review	B-1	Review	20009
It is better to show whether the proposed method can satisfy stability or robustness definition of RL algorithms. (	I-Review	I-1	Review	20009
For example, whether the proposed method can improve the robustness: Given a policy, by adding a \epsilon perturbation to the input, the output is still \epsilon-robustness) Otherwise, the author should add some discussion to clarify the difference.	I-Review	I-1	Review	20009
<sep> <sep> - Conservative Updates on Q functions.	B-Review	B-2	Review	20009
In Actor critic frameworks such as DDPG or TD3, the performance of the actor is usually determined by the critic.	I-Review	I-2	Review	20009
The proposed method is more likely to ‚Äúselect‚Äù stable actors rather than directly improving the stable of the training process or the stability of the policy.	I-Review	I-2	Review	20009
I wonder whether it is possible to improve the stability of Q updates such that the ‚Äúselection‚Äù process of policy can be easier, which may accelerate the current training process (or making the hypothesis easier to satisfy).	I-Review	I-2	Review	20009
<sep> <sep> - More related work should be compared.	B-Review	B-3	Review	20009
The authors only compare the original version of TD3 and the modified proposed method.	I-Review	I-3	Review	20009
Other recent proposed methods to improve stability should be compared in the experiments, such as Constrained Policy Optimization (Achiam et al 2017), Lypunov-based Safe Policy methods (such as Chow et al 2019).	I-Review	I-3	Review	20009
<sep> <sep> - Noisy Environment.	B-Review	B-4	Review	20009
The authors demonstrate the stability of the proposed method in the ordinary mujoco benchmarks.	I-Review	I-4	Review	20009
How does the proposed method perform in the noisy MDP settings?	I-Review	I-4	Review	20009
Since the original Mujoco implementation is deterministic, the experiments that the author conducted are not enough to show the proposed method can generalize to more realistic settings such as noisy MDPs.	I-Review	I-4	Review	20009
It would be more convincing if the method can still perform well in such settings to support the claim.	I-Review	I-4	Review	20009
<sep> <sep> Overall I think the authors proposed a simple but yet effective method to improve the stability of policy, while the current paper requires more comparison with other methods and more challenging settings to show the effectiveness of the proposed method.	B-Review	B-3	Review	20009
<sep> <sep> --------------------------------	O	O	Review	20009
I will update my score if the author clarify above questions.	O	O	Review	20009
<sep> <sep> <sep> -------------------------------	O	O	Review	20009
The author clarified one of my main concern, but the other reviewers point out that the comparison is not fair (using only 5 seeds and discarding the failure seeds).	B-Review	B-5	Review	20009
<sep> <sep> Related Papers:	O	O	Review	20009
Achiam, Joshua, et al "Constrained policy optimization."	O	O	Review	20009
Proceedings of the 34th International Conference on Machine Learning-Volume 70.	O	O	Review	20009
JMLR.	O	O	Review	20009
org, 2017.	O	O	Review	20009
<sep> <sep> Chow, Yinlam, et al "Lyapunov-based Safe Policy Optimization for Continuous Control."	O	O	Review	20009
arXiv preprint arXiv:1901.10031 (2019).	O	O	Review	20009
We would like to thank the reviewer for the thoughtful review.	O	O	Reply	20009
We will address the various concerns below:	O	O	Reply	20009
<sep> - Stability: The notion of stability in this work is a different notion than robustness.	B-Reply	B-1	Reply	20009
While robustness considers the ability to cope with slight perturbations (e.g., uncertainty in the task), we measure the stability of the learning process.	I-Reply	I-1	Reply	20009
For instance, in Table 2 we analyze the variance of the final 100 evaluations of each environment and show that our conservative update rule stabilizes the performance.	I-Reply	I-1	Reply	20009
<sep> <sep> - Conservative Updates: Unfortunately we did not understand the comment.	B-Reply	B-2	Reply	20009
Could you please elaborate so we could discuss this further?	I-Reply	I-2	Reply	20009
<sep> <sep> - Related work: Safety and stability have certain common aspects but they are fundamentally different.	B-Reply	B-3	Reply	20009
Chow et al and Achiam et al consider the scenario in which there are behavioral constraints on the policy - such as regions which the agent should not enter.	I-Reply	I-3	Reply	20009
Our approach does not limit the policy in any way, but rather aims to ensure that the performance is monotonically increasing.	I-Reply	I-3	Reply	20009
<sep> <sep> - Noisy Environment: This is a great suggestion.	B-Reply	B-4	Reply	20009
We will look into evaluating over stochastic environments.	I-Reply	I-4	Reply	20009
As our approach relies on probabilistic improvement guarantees, as the problem becomes noisier (stochastic) it will simply require additional evaluations in order to ensure high probability improvement.	I-Reply	I-4	Reply	20009

Traditional open-domain QA systems typically have two steps: passage retrieval and aggregating answers extracted from the retrieved passages.	O	O	Review	254
This paper essentially follows the same paradigm, but leverages the state-of-the-art reading comprehension models for answer extraction, and develops the neural network models for the aggregating component.	O	O	Review	254
Although the idea seems incremental, the experimental results do seem solid.	B-Review	B-1	Review	254
The paper is generally easy to follow, but in several places the presentation can be further improved.	B-Review	B-7	Review	254
<sep> <sep> Detailed comments/questions:	O	O	Review	254
1.	O	O	Review	254
In Sec.2.2, the justification for adding H^{aq} and \bar{H}^{aq} is to downweigh the impact of stop word matching.	B-Review	B-2	Review	254
I feel this is a somewhat indirect and less effective design, if avoiding stop words is really the reason.	I-Review	I-2	Review	254
A standard preprocessing step may be better.	I-Review	I-2	Review	254
<sep> 2.	O	O	Review	254
In Sec.2.3, it seems that the final score is just the sum of three individual normalized scores.	B-Review	B-3	Review	254
It's not truly a "weighted" combination, where the weights are typically assumed to be tuned.	I-Review	I-3	Review	254
<sep> 3.	B-Review	B-4	Review	254
Figure 3: Connecting the dots in the two subfigures on the right does not make sense.	I-Review	I-4	Review	254
Bar charts should be used instead.	I-Review	I-4	Review	254
<sep> 4.	O	O	Review	254
The end of Sec.4.2: I feel it's a bad example, as the passage does not really support the answer.	B-Review	B-5	Review	254
The fact that "Sesame Street" got picked is probably just because it's more famous.	I-Review	I-5	Review	254
<sep> 5.	B-Review	B-6	Review	254
It'd be interesting to see how traditional IR answer aggregation methods perform, such as simple classifiers or heuristics by word matching (or weighted by TFIDF) and counting.	I-Review	I-6	Review	254
This will demonstrates the true advantages of leveraging modern NN models.	I-Review	I-6	Review	254
<sep> <sep> Pros:	O	O	Review	254
1.	O	O	Review	254
Updating a traditional open-domain QA approach with neural models	O	O	Review	254
2.	O	O	Review	254
Experiments demonstrate solid positive results	O	O	Review	254
<sep> Cons:	O	O	Review	254
1.	O	O	Review	254
The idea seems incremental	B-Review	B-1	Review	254
2.	B-Review	B-7	Review	254
Presentation could be improved	I-Review	I-7	Review	254
<sep> Thank you for your feedback and thorough review.	O	O	Reply	254
We have revised the paper to address the issues you raised  and fixed the presentation issues.	O	O	Reply	254
<sep> <sep> ABOUT THE NOVELTY:	O	O	Reply	254
<sep> Although traditional QA systems also have the answer re-ranking component, this paper focuses on a novel problem of ``text evidence aggregation'': Here the problem is essentially modeling the relationship between the question and multiple passages (i.e., text evidence), where different passages could enhance or complement each other.	B-Reply	B-1	Reply	254
For example,  the proposed neural re-ranker models the complementary scenario, i.e., whether the union of different passages could cover different facts in a question, thus the attention-based model is a natural fit.	I-Reply	I-1	Reply	254
<sep> <sep> In contrast, previous answer re-ranking research did not address the above problem: (1) traditional QA systems like (Ferrucci et al 2010) used similar passage retrieval approach with answer candidates added to the queries.	I-Reply	I-1	Reply	254
However they usually consider each passage individually for extracting features of answers, whereas we utilize the information of union/co-occurrence of multiple passages by composing them with neural networks. (	I-Reply	I-1	Reply	254
2) KB-QA systems (Bast and Haussmann, 2015; Yih et al 2015; Xu et al 2016) sometimes use text evidence to help answer re-ranking, where the features are also extracted on the pair of a question and a single-passage but ignored the union information among multiple passages.	I-Reply	I-1	Reply	254
<sep> <sep> We have added the above discussion to our paper (Page 11).	O	O	Reply	254
<sep> <sep> RESPONSE TO THE DETAILED QUESTIONS:	O	O	Reply	254
<sep> Q1: In Sec.2.2, the justification for adding H^{aq} and \bar{H}^{aq} is to downweigh the impact of stop word matching.	O	O	Reply	254
I feel this is a somewhat indirect and less effective design, if avoiding stop words is really the reason.	O	O	Reply	254
A standard preprocessing step may be better.	O	O	Reply	254
<sep> A1: We follow the model design in (Wang and Jiang 2017).	B-Reply	B-2	Reply	254
The reason for adding H^{aq} and \bar{H}^{aq} is not only to downweigh the stop word matching, but also to take into consideration the semantic information at each position.	I-Reply	I-2	Reply	254
Therefore, the sentence-level matching model (Eq. (5) in the next paragraph) could potentially learn to distinguish the effects of the element-wise comparison vectors with the original lexical information.	I-Reply	I-2	Reply	254
We‚Äôve clarified this on Page 5.	I-Reply	I-2	Reply	254
<sep> Q2: In Sec.2.3, it seems that the final score is just the sum of three individual normalized scores.	O	O	Reply	254
It's not truly a "weighted" combination, where the weights are typically assumed to be tuned.	O	O	Reply	254
<sep> <sep> A2: We did tune the assigned weights for the three types of normalized scores on the dev set.	B-Reply	B-3	Reply	254
The tuned version gives some improvement on dev and results in slightly better test scores, compared to simply summing up the three scores.	I-Reply	I-3	Reply	254
<sep> Q3: Figure 3: Connecting the dots in the two subfigures on the right does not make sense.	O	O	Reply	254
Bar charts should be used instead.	O	O	Reply	254
<sep> A3: We have changed the subfigures to bar charts in the updated version.	B-Reply	B-4	Reply	254
<sep> Q4: The end of Sec.4.2: I feel it's a bad example, as the passage does not really support the answer.	O	O	Reply	254
The fact that "Sesame Street" got picked is probably just because it's more famous.	O	O	Reply	254
<sep> A4: We agree that the passages in Table 6 do not provide full evidence to the question (unlike the example in Figure 1b where the passages fully support all the facts in the question).	B-Reply	B-5	Reply	254
However, the ‚ÄúSesame Street‚Äù got picked not because it is more famous, but because it has supporting evidence in the form of the  "award-winning" and "children's TV show" facts, while the candidate "Great Dane" only covers "1969".	I-Reply	I-5	Reply	254
<sep> <sep> We selected this example in order to show another common case of realistic problems in Open-Domain QA, where the question is complex and the top-K retrieved passages cannot provide full evidence.	I-Reply	I-5	Reply	254
In this case, our model is able to select the candidate with evidence covering more facts in the question (i.e. the candidate that is more likely to be approximately correct).	I-Reply	I-5	Reply	254
<sep> <sep> Q5: It'd be interesting to see how traditional IR answer aggregation methods perform, such as simple classifiers or heuristics by word matching (or weighted by TFIDF) and counting.	O	O	Reply	254
This will demonstrate the true advantages of leveraging modern NN models.	O	O	Reply	254
<sep> A5: Thank you for the valuable advice!	B-Reply	B-6	Reply	254
We‚Äôve added a baseline method with BM25 value to rerank the answers based on the aggregated passages, together with the analysis about it in the current version.	I-Reply	I-6	Reply	254
In summary, the BM25 model improved the F1 scores but sometimes caused a decrease in the EM scores.	I-Reply	I-6	Reply	254
This is mainly for two reasons: (1) BM25 relies on bag-of-word representation, so context information is not taken into consideration.	I-Reply	I-6	Reply	254
Also it does not model the phrase similarities. (	I-Reply	I-6	Reply	254
2) shorter answers are preferred by BM25.	I-Reply	I-6	Reply	254
For example when answer candidate A is a subsequence of B, then according to our way of collecting pseudo passages, the pseudo passage of A is always a superset of the pseudo passage of B. Therefore F1 scores are often improved while EM declines.	I-Reply	I-6	Reply	254

The authors propose an approach where they aggregate, for each candidate answer, text from supporting passages.	O	O	Review	254
They make use of two ranking components.	O	O	Review	254
A strength-based re-ranker captures how often a candidate answer would be selected while a coverage-based re-ranker aims to estimate the coverage of the question by the supporting passages.	O	O	Review	254
Potential answers are extracted using a machine comprehension model.	O	O	Review	254
A bi-LSTM model is used to estimate the coverage of the question.	O	O	Review	254
A weighted combination of the outputs of both components generates the final ranking (using softmax).	O	O	Review	254
This article is really well written and clearly describes the proposed scheme.	O	O	Review	254
Their experiments clearly indicate that the combination of the two re-ranking components outperforms raw machine comprehension approaches.	O	O	Review	254
The paper also provides an interesting analysis of various design issues.	O	O	Review	254
Finally they situate the contribution with respect to some related work pertaining to open domain QA.	O	O	Review	254
This paper seems to me like an interesting and significant contribution.	O	O	Review	254
Thank you for your kind review.	O	O	Reply	254
We have improved the presentation and added new discussions which we hope will further improve.	O	O	Reply	254

The paper is clear, although there are many English mistakes (that should be corrected).	B-Review	B-1	Review	254
<sep> The proposed method aggregates answers from multiple passages in the context of QA.	O	O	Review	254
The new method is motivated well and departs from prior work.	O	O	Review	254
Experiments on three datasets show the proposed method to be notably better than several baselines (although two of the baselines, GA and BiDAF, appear tremendously weak).	B-Review	B-2	Review	254
The analysis of the results is interesting and largely convincing, although a more dedicated error analysis or discussion of the limitation of the proposed approach would be welcome.	B-Review	B-3	Review	254
<sep> <sep> Minor point: in the description of Quasar-T, the IR model is described as lucene index.	B-Review	B-4	Review	254
An index is not an IR model.	I-Review	I-4	Review	254
Lucene is an IR system that implements various IR models.	I-Review	I-4	Review	254
The terminology should be corrected here.	I-Review	I-4	Review	254
<sep> <sep> Thank you for your valuable comments!	O	O	Reply	254
We corrected the grammar and spelling issues and revised the Lucene description on Page 6.	B-Reply	B-1	Reply	254
<sep> <sep> We provided additional discussion in the conclusion section.	B-Reply	B-3	Reply	254
Our analysis shows that the instances which were  incorrectly  predicted require complex reasoning and sometimes commonsense knowledge to get right.	I-Reply	I-3	Reply	254
We believe that further improvement in these areas has the potential to greatly improve performance in these difficult multi-passage reasoning scenarios.	I-Reply	I-3	Reply	254
<sep> <sep> About baselines:	O	O	Reply	254
The two baselines, GA and BiDAF, came from the dataset papers.	B-Reply	B-2	Reply	254
Besides these two, we also compared with the R^3 baseline.	I-Reply	I-2	Reply	254
This method is from the recent work (Wang et al, 2017), which improves previous state-of-the-art neural-based open-domain QA system (Chen et al 2017) on 4 out of 5 public datasets.	I-Reply	I-2	Reply	254
As a result, we believe that this baseline reflects the state-of-the-art, thus our experimental comparison is reasonable.	I-Reply	I-2	Reply	254

This work builds on a sum(top k) identity to derive a pathwise differentiable sampler of 'unimodal row stochastic' matrices.	O	O	Review	254
The Plackett-Luce family has a tractable density (an improvement over previous works) and is (as developed here) efficient to sample.	O	O	Review	254
<sep> <sep> [OpenReview did not save my draft, so I now attempt to recover it from memory.]	O	O	Review	254
<sep> <sep> Questions:	O	O	Review	254
- How much of the improvement is attributable to the lower dimension of the parameterization? (	B-Review	B-1	Review	254
e.g. all Sinkhorn varients have N^2 params; this has N params) Is there any reduction in gradient variance due to using fewer gumbel samples?	I-Review	I-1	Review	254
<sep> - More details needed on the kNN loss (uniform vs inv distance wt?	B-Review	B-2	Review	254
which one?);	I-Review	I-2	Review	254
and the experiment overall: what k got used in the end?	I-Review	I-2	Review	254
<sep> - The temperature setting is basically a bias-variance tradeoff (see Fig 5).	B-Review	B-3	Review	254
How non-discrete are the permutation-like matrices ultimately used in the experiments?	I-Review	I-3	Review	254
While the gradients are unbiased for the relaxed sort operator, they are still biased if our final model is a true sort.	I-Review	I-3	Review	254
Would be nice to quantify this difference, or at least mention it.	I-Review	I-3	Review	254
<sep> <sep> Quality:	O	O	Review	254
Good quality; approach is well-founded and more efficient than extant solutions.	O	O	Review	254
Fairly detailed summaries of experiments in appendices (except kNN).	O	O	Review	254
Neat way to reduce the parameter count from N^2 to N.	O	O	Review	254
<sep> I have not thoroughly evaluated the proofs in appendix.	O	O	Review	254
<sep> <sep> Clarity:	O	O	Review	254
The approach is presented well, existing techniques are compared in both prose and as baselines.	O	O	Review	254
Appendix provides code for maximal clarity.	O	O	Review	254
<sep> <sep> Originality:	O	O	Review	254
First approach I've seen that reduces parameter count for permutation matrices like this.	O	O	Review	254
And with tractable density.	O	O	Review	254
Very neat and original approach.	O	O	Review	254
<sep> <sep> Significance:	O	O	Review	254
More scalable than existing approaches (e.g: only need N gumbel samples instead of N^2), yields better results.	O	O	Review	254
<sep> <sep> I look forward to seeing this integrated into future work, as envisioned (e.g. beam search)	O	O	Review	254
Thanks for reviewing our paper and the helpful feedback!	O	O	Reply	254
We have addressed your questions below.	O	O	Reply	254
<sep> Q1.	O	O	Reply	254
How much of the improvement is attributable to the lower dimension of the parameterization? (	O	O	Reply	254
e.g. all Sinkhorn varients have N^2 params; this has N params) Is there any reduction in gradient variance due to using fewer gumbel samples?	O	O	Reply	254
<sep> A1.	B-Reply	B-1	Reply	254
Precise quantification of the gains due to lower dimension of the parameterization alone is hard since the relaxation itself is fundamentally different from the Sinkhorn variants.	I-Reply	I-1	Reply	254
In an attempt to get a handle on these aspects (n^2 vs. n parameters and doubly stochastic vs. unimodal matrices), we analyzed the signal-to-noise (SNR) ratio for the Stochastic Sortnet and Gumbel-Sinkhorn approaches with the same number of Gumbel samples (=5).	I-Reply	I-1	Reply	254
Here, we define SNR as the ratio of the absolute value of the expected gradient estimates and the standard deviation.	I-Reply	I-1	Reply	254
For the experiments in Section 6.1, the SNR ratio averaged across all the parameters is shown in Figure 8.	I-Reply	I-1	Reply	254
We observe a much higher SNR for the proposed approach, in line with the overall gains we see on the underlying task.	I-Reply	I-1	Reply	254
<sep> <sep> Q2.	O	O	Reply	254
More details needed on the kNN loss (uniform vs inv distance wt?	O	O	Reply	254
which one?);	O	O	Reply	254
and the experiment overall: what k got used in the end?	O	O	Reply	254
<sep> A2.	B-Reply	B-2	Reply	254
We used a uniformly weighted kNN loss for both the Sortnet approaches, while noting that it is straightforward to extend our framework to use an inverse distance weighting.	I-Reply	I-2	Reply	254
Appendix E.3 includes the formal expressions for the loss functions optimized in our framework.	I-Reply	I-2	Reply	254
Furthermore, we have included new results in Table 5 which show the raw performance of Deterministic and Stochastic Sortnet for all values of k considered.	I-Reply	I-2	Reply	254
<sep> <sep> Q3.	O	O	Reply	254
The temperature setting is basically a bias-variance tradeoff (see Fig 5).	O	O	Reply	254
How non-discrete are the permutation-like matrices ultimately used in the experiments?	O	O	Reply	254
<sep> A3.	O	O	Reply	254
That‚Äôs a great suggestion!	B-Reply	B-3	Reply	254
One way to quantify the non-discreteness could be based on the element-wise mean squared difference between the inferred unimodal row stochastic matrix and its projection to a permutation matrix, for  the test set of instances.	I-Reply	I-3	Reply	254
We have included these results for the sorting experiment in Table 4.	I-Reply	I-3	Reply	254
<sep> <sep> Please let us know if there are any further questions!	O	O	Reply	254

After responses: I now understand the paper, and I believe it is a good contribution.	O	O	Review	254
<sep> <sep> ================================================	O	O	Review	254
<sep> At a high level, the paper considers how to sort a number of items without explicitly necessarily learning their actual meanings or values.	O	O	Review	254
Permutations are discrete combinatorial objects, so the paper proposes a method to perform the optimization via a continuous relaxation.	O	O	Review	254
<sep> <sep> This is an important problem to sort items, arising in a variety of applications, particularly when the direct sorting can be more efficient than the two step approach of computing the values and then sorting.	O	O	Review	254
<sep> <sep> I like both the theoretical parts and the experimental results.	O	O	Review	254
In the context of ICLR, the specific theoretical modules comprise some cute results (Theorem 4; use of past works in Lemma 2 and Proposition 5).	O	O	Review	254
possibly of independent interest.	O	O	Review	254
The connections to the (Gumbel distribution <--> Plackett Luce) results are also nicely used.	O	O	Review	254
This Gumbel<-->PL result is well known in the social choice community but perhaps not so much in the ML community, and it is always nice to see more connections drawn between techniques in different communities.	O	O	Review	254
The empirical evaluations show quite good results.	O	O	Review	254
<sep> <sep> However, I had a hard time parsing the paper.	B-Review	B-1	Review	254
The paper is written in a manner that may be accessible to readers who are familiar with this (or similar) line of research, but for someone like me who is not, I found it quite hard to understand the arguments (or lack of them) made in the paper connecting various modules.	I-Review	I-1	Review	254
Here are some examples:	O	O	Review	254
<sep> - Section 6.1 states "Each sequence contains n images, and each image corresponds to an integer label.	B-Review	B-2	Review	254
Our goal is to learn to predict the permutation that sorts these labels".	I-Review	I-2	Review	254
One interpretation of this statement suggests that each row of Fig 3a is a sequence, that each sequence contains n=4 images (e.g., 4 images corresponding to each digit in 2960), and the goal is to sort [2960] to [0269]. However, according to the response of authors to my earlier comment, the goal is to sort [2960,1270,9803] to [1270,2960,9803].	I-Review	I-2	Review	254
<sep> - I did not understand Section 2.2.	B-Review	B-3	Review	254
<sep> <sep> - I would appreciate a more detailed background on the concrete goal before going into the techniques of section 3 and 4.	B-Review	B-4	Review	254
<sep> <sep> - I am having a hard time in connecting the experiments in Section 6 with the theory described in earlier sections.	B-Review	B-5	Review	254
And this is so even after my clarifying questions to the authors and their responses.	I-Review	I-5	Review	254
For instance, the authors explained that the experiments in Section 6.1 have \theta as vacuous and that the function f represents the cross-entropy loss between permutation z and the true permutation matrix.	I-Review	I-5	Review	254
Then where is this true permutation matrix captured as an argument of f in (6)?	I-Review	I-5	Review	254
Is the optimisation/gradients in (7) over s or over the CNN parameters?	I-Review	I-5	Review	254
<sep> <sep> Thanks for reviewing our paper and the helpful feedback!	O	O	Reply	254
We have addressed your questions and comments below.	O	O	Reply	254
<sep> <sep> Q1.	O	O	Reply	254
Experimental setup for Section 6.1 and Figure 3.	O	O	Reply	254
<sep> A1.	O	O	Reply	254
We can see the source of confusion now, sorry about that!	B-Reply	B-2	Reply	254
We have edited the description in Section 6.1 to clarify this point and replaced what was previously Figure 3 with a more illustrative Figure 4 and a descriptive caption.	I-Reply	I-2	Reply	254
The reviewer‚Äôs understanding of our last response is correct --- we have a sequence of n large-MNIST images (where each large-MNIST image is a 4 digit number) and the goal is to sort the input sequence.	I-Reply	I-2	Reply	254
In Figure 4 for example, the task is to sort the input sequence of n=5 images given as [2960, 1270, 9803, 1810, 7346] to [1270, 1810, 2960, 7346, 9803].	I-Reply	I-2	Reply	254
<sep> Q2.	O	O	Reply	254
Section 2.2.	O	O	Reply	254
<sep> A2.	B-Reply	B-3	Reply	254
In Section 2.2, we intend to provide background on stochastic computation graphs (SCG).	I-Reply	I-3	Reply	254
SCGs are a widely used tool for visualizing and contrasting different approaches to stochastic optimization, especially in the context of stochastic optimization with the backpropagation algorithm since the forward and backward passes can be visualized via the topological sorting of operators in the SCG (e.g., Figures 1, 3).	I-Reply	I-3	Reply	254
Due to the lack of space, we could not include a detailed overview of stochastic computation graphs and pointed the readers to the canonical reference of Schulmann et al 2015.	I-Reply	I-3	Reply	254
The key takeaway is stated in the last paragraph of Section 2.2 --- a sort operator is non-differentiable w.r.t.its inputs and including it in SCGs necessitates the need for relaxations.	I-Reply	I-3	Reply	254
For a more detailed exposition to SCGs, we have included an illustrative example in Figure 6 that grounds the terminology introduced in Section 2.2.	I-Reply	I-3	Reply	254
<sep> <sep> Q3.	O	O	Reply	254
Concrete goal in section 3 and 4.	O	O	Reply	254
<sep> A3.	O	O	Reply	254
At its core, this work seeks to include general-purpose deterministic nodes corresponding to sort operators (Section 3) and stochastic nodes corresponding to random variables defined over the symmetric group of permutations (Section 4) in computational pipelines (represented via a stochastic computation graph).	B-Reply	B-4	Reply	254
Following up on the reviewer‚Äôs feedback, we have significantly expanded the motivating introductions for Section 3 and 4 to clearly state the goal beforehand and how we intend to achieve it.	I-Reply	I-4	Reply	254
<sep> <sep> Q4.	O	O	Reply	254
Connecting theory with experiments.	O	O	Reply	254
Where is this true permutation matrix captured as an argument of f in (6)?	O	O	Reply	254
Is the optimisation/gradients in (7) over s or over the CNN parameters?	O	O	Reply	254
<sep> A4.	B-Reply	B-5	Reply	254
Following up on the reviewer‚Äôs feedback, we have made the following edits in the revised version:	I-Reply	I-5	Reply	254
- Revised Figures 4, 5 (which were Figure 3, 4 in the old version) to clearly indicate the scores ‚Äús‚Äù for each experiment.	I-Reply	I-5	Reply	254
<sep> - Included a new Appendix E which formally states the loss functions optimized by the Sortnet approaches and explains the semantics of each terms for all three experiments.	I-Reply	I-5	Reply	254
<sep> <sep> Regarding the specific follow-up questions with respect to Equation 7 and 8 (which were previously Equation 6 and 7 in the first version of the paper):	B-Reply	B-5	Reply	254
- For the experiments in Section 6.1, the function f would include an additional argument corresponding to the true permutation matrix.	I-Reply	I-5	Reply	254
We did not explicitly include the ground-truth permutation as an argument to the function f in Equation 7 to maintain the generality since such objectives also arise in unsupervised settings e.g., latent variable modeling where there is no ground-truth label.	I-Reply	I-5	Reply	254
See Appendix E.1 for the precise loss function.	I-Reply	I-5	Reply	254
<sep> - The gradients in Equation 8 are w.r.t.the scores s that parameterize a distribution q. In the experiments, the scores s are given as the output of a CNN and the optimization is over the CNN parameters.	I-Reply	I-5	Reply	254
Evaluating gradients w.r.t.the CNN parameters is straightforward via the chain rule/backpropagation.	I-Reply	I-5	Reply	254
<sep> <sep> Please let us know if there is any other detail that needs further clarification!	O	O	Reply	254

In many machine learning applications, sorting is an important step such as ranking.	O	O	Review	254
However, the sorting operator is not differentiable with respect to its inputs.	O	O	Review	254
The main idea of the paper is to introduce a continuous relaxation of the sorting operator in order to construct an end-to-end gradient-based optimization.	O	O	Review	254
This relaxation is introduced as \hat{P}_{sort(s)} (see Equation 4).	O	O	Review	254
The paper also introduces a stochastic extension of its method	O	O	Review	254
using Placket-Luce distributions and Monte Carlo.	O	O	Review	254
Finally, the introduced deterministic and stochastic methods are evaluated experimentally in 3 different applications: 1.	O	O	Review	254
sorting handwritten numbers, 2.	O	O	Review	254
Quantile regression, and 3.	O	O	Review	254
End-to-end differentiable k-Nearest Neighbors.	O	O	Review	254
<sep> <sep> The introduction of the differentiable approximation of the sorting operator is interesting and seems novel.	B-Review	B-1	Review	254
However, the paper is not well-written and it is hard to follow the paper especially form Section 4 and on.	I-Review	I-1	Review	254
It is not clear how the theoretical results in Section 3 and 4 are used for the experiments in Section 6.	I-Review	I-1	Review	254
For instance:	I-Review	I-1	Review	254
** In page 4, what is "s" in the machine learning application?	I-Review	I-1	Review	254
<sep> ** In page 4, in Equation 6, what are theta, s, L and f exactly in our machine learning applications?	I-Review	I-1	Review	254
<sep> <sep> Remark:	O	O	Review	254
** The phrase "Sorting Networks" in the title of the paper is confusing.	B-Review	B-2	Review	254
This term typically refers to a network of comparators applied to a set of N wires (See e.g. [1])	I-Review	I-2	Review	254
** Page 2 -- Section 2 PRELIMINARIES -- It seems that sort(s) must be [1,4,2,3].	B-Review	B-3	Review	254
<sep> [1] Ajtai M, Koml√≥s J, Szemer√©di E. An 0 (n log n) sorting network.	O	O	Review	254
InProceedings of the fifteenth annual ACM symposium on Theory of computing 1983 Dec 1 (pp.1-9).	O	O	Review	254
ACM	O	O	Review	254
<sep> Thanks for reviewing our paper and the helpful feedback!	O	O	Reply	254
We have addressed your questions and comments below.	O	O	Reply	254
<sep> <sep> Q1.	O	O	Reply	254
Clarity in Sections 3, 4.	O	O	Reply	254
Connection with experiments.	O	O	Reply	254
<sep> A1.	B-Reply	B-1	Reply	254
Following up on the reviewer‚Äôs feedback, we have made the following edits in the revised version:	I-Reply	I-1	Reply	254
- Edited and expanded the introductory paragraphs for Section 3 and Section 4 to ensure a smooth transition.	I-Reply	I-1	Reply	254
<sep> - Revised Figures 4, 5 (which were previously Figure 3, 4 in the in the first version of the paper) to clearly indicate the scores ‚Äús‚Äù for each experiment.	I-Reply	I-1	Reply	254
<sep> - Included a new Appendix E which formally states the loss functions optimized by the Sortnet approaches for all three experiments.	I-Reply	I-1	Reply	254
<sep> <sep> For the specific follow-up questions in the review, we first note that Equation (7) (which was previously Equation (6) in the first version of the paper) is the general style of expressions used in the relevant literature on stochastic optimization, see e.g., Section 3 in Jang et al 2017.	I-Reply	I-1	Reply	254
These expressions are succinct, but as the reviewer points out, they need additional clarification when extended to the experiments.	I-Reply	I-1	Reply	254
We hope Appendix E will help clarify these formally.	B-Reply	B-5	Reply	254
For completeness, we address the two questions specifically raised by the reviewer here:	I-Reply	I-5	Reply	254
<sep> In all our experiments, we are dealing with sequences of n objects x = [x1, x2, ‚Ä¶, xn] and trying to sort these objects for an end goal.	I-Reply	I-1	Reply	254
In Section 6.1, the goal is to output the sorted permutation for a sequence of n largeMNIST images; in 6.2, the goal is to output the median value in the sequence; in 6.3, the goal is to sort a sequence of training points as per their distances to a query point for kNN classification.	I-Reply	I-1	Reply	254
We now explain the notation in the context of largeMNIST experiments in Section 6.1/6.2 which share the same experimental setup and dataset; the kNN experiments in Section 6.3 follow similarly.	I-Reply	I-1	Reply	254
<sep> <sep> - s=[s1, s2, ‚Ä¶, sn] corresponds to a vector of scores, one for each largeMNIST image in the input sequence.	I-Reply	I-1	Reply	254
Each score si is the output of a CNN which takes as input an image xi.	I-Reply	I-1	Reply	254
The CNNs across the different largeMNIST images x1, x2, ..., xn share parameters.	I-Reply	I-1	Reply	254
Note that we directly specify the vector s (and skip x as well as the CNN parameters relating x to s) in Equation (7) for brevity.	I-Reply	I-1	Reply	254
In Section 4, we derived gradients of the objective w.r.t.s, which can be backpropagated via chain rule to update the CNN parameters in a straightforward manner.	I-Reply	I-1	Reply	254
<sep> - q is the Plackett-Luce distribution over permutations z and parameterized by scores s.	I-Reply	I-1	Reply	254
- f is any function (that optionally depends on additional parameters \theta) that acts over a permutation matrix P_z.	I-Reply	I-1	Reply	254
In the experiments in Section 6.1, the function f is the element-wise cross-entropy loss between the true permutation matrix that sorts x and P_z.	I-Reply	I-1	Reply	254
Again for the purpose of generality , we do not explicitly include the ground-truth permutation as an argument to the function f in Equation (7) since such objectives also arise in unsupervised settings, e.g., latent variable modeling where there is no ground-truth label.	I-Reply	I-1	Reply	254
<sep> - The parameters \theta for specifying f as a function of P_z are optional and task-specific.	I-Reply	I-1	Reply	254
In particular, the cross-entropy loss function f for experiments in Section 6.1 does not needs any additional parameters \theta.	I-Reply	I-1	Reply	254
For the experiments in Section 6.2, we cannot compute a loss directly with respect to the permutation matrix P_z since we need to regress a scalar value for the median.	I-Reply	I-1	Reply	254
Instead, we feed the predicted median image in the input sequence (can be obtained via sorting x as per P_z) to a neural network (with parameters \theta) to obtain a real-valued, scalar prediction.	I-Reply	I-1	Reply	254
We then compute f as the the MSE regression loss between the true median value and the value predicted by the parameterized neural network.	I-Reply	I-1	Reply	254
<sep> - Lastly, L denotes the expected value of the objective function f w.r.t.the distribution q.	I-Reply	I-1	Reply	254
<sep> Please refer to Figures 4, 5 for the computational pipeline and Appendix E for the precise loss functions for each experiment.	I-Reply	I-1	Reply	254
Let us know if there is any other detail that needs clarification!	I-Reply	I-1	Reply	254
<sep> <sep> Q2.	O	O	Reply	254
Confusing use of the phrase "Sorting Networks" in the title of the paper.	O	O	Reply	254
<sep> A2.	O	O	Reply	254
Thanks for pointing it out!	B-Reply	B-2	Reply	254
If permitted by the conference rules, we will consider substituting ‚Äònetworks‚Äô to ‚Äòoperators‚Äô in the title of the final version of the paper.	I-Reply	I-2	Reply	254
<sep> <sep> Q3.	O	O	Reply	254
Page 2 -- Section 2 PRELIMINARIES -- It seems that sort(s) must be [1,4,2,3].	O	O	Reply	254
A3.	B-Reply	B-3	Reply	254
We believe the sort(s) expression in the paper is correct.	I-Reply	I-3	Reply	254
This is because the largest element (=9) is at index 1, second largest element (=5) is at index 3, third largest element (=2) is at index 4 and the smallest element (=1) is at index 2.	I-Reply	I-3	Reply	254
Hence, sort(s)=[1,3,4,2]^T as indicated in the paper.	I-Reply	I-3	Reply	254

The authors propose several approaches to making a data-to-text generation system more precise, that is, less prone to hallucination.	O	O	Review	254
In particular, they propose an attention score, which attempts to measure to what degree the model is relying on its attention mechanism in making a prediction.	O	O	Review	254
This attention score is used to weight a mixture distribution (a "confidence score") over the generation model's next-word distribution and the next-word distribution of an unconditional language model.	O	O	Review	254
The learned conditional distribution can then be calibrated to the confidence score.	O	O	Review	254
The authors also propose a variational-inference inspired objective, which attempts to allow the model to ignore certain tokens it isn't confident about.	O	O	Review	254
The authors evaluate their approach on the WikiBio dataset, and find that their approaches make their system more precise, at the cost of some coverage.	O	O	Review	254
<sep> <sep> This paper is well motivated, timely, and it presents several interesting ideas.	O	O	Review	254
However, I think parts of the proposed approach need to be better justified.	O	O	Review	254
In particular:	O	O	Review	254
<sep> -  What justifies defining the attention score A_t in this way?	B-Review	B-1	Review	254
First, is there an argument (empirical or otherwise) for using the magnitude of the attention vector (rather than some other statistic)?	I-Review	I-1	Review	254
Is it obvious that if the attention vector has a high magnitude then it ought to be trusted?	I-Review	I-1	Review	254
Note that this might be a reasonable assumption in the case of a pointer-generator style model, where a single attention vector is used both for attending and for copying, but in a model where attention isn't constrained in this way the magnitude of the attention vector may be misleading.	I-Review	I-1	Review	254
<sep> <sep> - The variational objective seems difficult to justify.	B-Review	B-2	Review	254
First, I don't understand what it means for p(y | z, x) to be assumed to 1.	I-Review	I-2	Review	254
Is this for any z (in which case y is independent of z)?	I-Review	I-2	Review	254
Otherwise, how can it be removed from the objective? (	I-Review	I-2	Review	254
Put another way: Equation (17) is not in general true; it neglects an expected log likelihood term).	B-Review	B-5	Review	254
I'm also not entirely clear on how Equation (12) is modeled: do the z's really only rely on the other sampled z's?	B-Review	B-6	Review	254
Doesn't that require a different model than the one that calculates P^{\kappa}?	I-Review	I-6	Review	254
<sep> <sep> - Somewhat minor: the claim that optimizing the joint objective needn't hurt perplexity relies on kappa being 0; have you confirmed empirically that when it isn't zero the perplexity improves over the baseline model?	B-Review	B-3	Review	254
<sep> <sep> - Finally, I'm not sure I understand why there needs to be a stop-gradient in equation (4).	B-Review	B-4	Review	254
It would be nice to also verify empirically that this is important.	I-Review	I-4	Review	254
<sep> <sep> <sep> Thanks for the detailed review.	O	O	Reply	254
In addition to the revisions of our paper, we have also empirically investigated perplexity as suggested by the reviewer.	O	O	Reply	254
<sep> <sep> &gt; What justifies defining the attention score A_t in this way?	O	O	Reply	254
Is it obvious that if the attention vector has a high magnitude then it ought to be trusted?	O	O	Reply	254
<sep> <sep> The attention score A_t measures how much the model actually relies on the source to make a prediction.	B-Reply	B-1	Reply	254
Since the context vector v_t is defined as a_t + h_t in Equation (2), defining A_t in this way as a magnitude ratio measures how much a_t affects v_t.	I-Reply	I-1	Reply	254
In practice, A_t is usually high (~0.9) when the model is copying from the source (e.g. ‚ÄúCampbell‚Äù in Figure 2), medium (~0.4) when the model is generating based on some information from the source (e.g. ‚Äú&lt;unk&gt;‚Äù in Figure 2), and low (~0.2) when the model is generating template elements (e.g. ‚Äúis‚Äù in Figure 2).	I-Reply	I-1	Reply	254
More examples are added to our revised paper.	I-Reply	I-1	Reply	254
This observation does not immediately mean that a generation with higher attention score should be trusted; whether to trust a token or not is assessed by the confidence score.	I-Reply	I-1	Reply	254
We will discuss this next.	I-Reply	I-1	Reply	254
<sep> <sep> Our confidence score depends on both the attention score and generation probabilities.	I-Reply	I-1	Reply	254
The idea of our confidence score was originated from an observation on baseline predictions of Wikibio: Hallucination often occurs when the table lacks some field that usually exists, for example the ‚ÄúOccupation‚Äù field is missing in Figure 1, and the baseline model makes that up.	I-Reply	I-1	Reply	254
In such cases, the conditioned generation probability can still be high (e.g. &gt;0.5), so we cannot tell it from the conditioned generation probability alone.	I-Reply	I-1	Reply	254
But, since some usual field is missing, the attention score as we defined tends to be low, and it might be used to detect such hallucination cases.	I-Reply	I-1	Reply	254
However, the attention score is also low for function words and template elements.	I-Reply	I-1	Reply	254
Thus, we further incorporate an unconditioned generation probability (base-LM) to detect those cases.	I-Reply	I-1	Reply	254
<sep> <sep> This motivation is made clearer in our revised paper.	I-Reply	I-1	Reply	254
<sep> <sep> From a higher point of view, we do not claim that our definition of the confidence and attention scores are optimal; we proposed one way to implement the intuition.	I-Reply	I-1	Reply	254
We have demonstrated several pieces of evidence that this implementation works: Figure 2 qualitatively demonstrates that the scores match human intuition; experiments regarding thresholding and ablation, etc.	I-Reply	I-1	Reply	254
We believe they are all firm justifications for our model design.	I-Reply	I-1	Reply	254
<sep> <sep> Regarding design details, we have tried several other variations of the attention score, the base-LM input-feeding, and the confidence score.	I-Reply	I-1	Reply	254
The current implementation is selected based on PARENT F1 and manually investigating the learned scores.	I-Reply	I-1	Reply	254
<sep> <sep> &gt; what it means for p(y | z, x) to be assumed to 1	O	O	Reply	254
<sep> Intuitively, we are assuming an oracle that can always recover the original target sequence y from its subsequence z; this is reasonable during training because we always know the gold reference for each training example.	B-Reply	B-2	Reply	254
Technically, we note that p(y | z, x) is part of the model rather than the data.	I-Reply	I-2	Reply	254
So this is just a modeling assumption that simplifies the formula.	I-Reply	I-2	Reply	254
We assume p(y | z, x) to be a probability distribution over all possible target sequences, such that the probability is 1 for the gold reference and 0 otherwise.	I-Reply	I-2	Reply	254
Yes, this distribution is the same for all z, as long as z is a subsequence taken from y. We don‚Äôt see any issue here.	I-Reply	I-2	Reply	254
<sep> <sep> &gt; how Equation (12) is modeled: do the z's really only rely on the other sampled z's?	O	O	Reply	254
<sep> <sep> Yes.	B-Reply	B-5	Reply	254
<sep> <sep> &gt; Doesn't that require a different model than the one that calculates P^{\kappa}?	O	O	Reply	254
<sep> <sep> No, we don‚Äôt need a different model.	B-Reply	B-6	Reply	254
We are treating z as if z is the gold reference, and train our model to target this confident subsequence.	I-Reply	I-6	Reply	254
This way, the generation model actually learns to skip unconfident tokens. (	I-Reply	I-6	Reply	254
Reviewer #1 raised concerns about this setting that it might cause disfluent generations; the fact that it does not is also a surprise for us.	I-Reply	I-6	Reply	254
Please see the discussions there.)	I-Reply	I-6	Reply	254
<sep> <sep> &gt; have you confirmed empirically that when it isn't zero the perplexity improves over the baseline model?	O	O	Reply	254
<sep> <sep> This is an interesting question.	B-Reply	B-3	Reply	254
First, we note an issue with perplexity on the WikiBio dataset: there are noisy tokens in the data whose log-likelihood converge to -inf.	I-Reply	I-3	Reply	254
In our implementation, we set the smallest log-likelihood to log(2^{-100})=-69.3.	I-Reply	I-3	Reply	254
Then, we compare the Pointer-Generator baseline with our No-variational model because the variational loss introduces random sampling into the training process.	I-Reply	I-3	Reply	254
We report the log-perplexity as follows:	I-Reply	I-3	Reply	254
<sep> No-variational, kappa learned: 31.19 (Train)  39.24 (Valid)	I-Reply	I-3	Reply	254
No-variational, kappa=0:   31.21 (Train) 39.08 (Valid)	I-Reply	I-3	Reply	254
Pointer-Generator:   32.41 (Train) 40.14 (Valid)	I-Reply	I-3	Reply	254
<sep> So, compared to kappa=0, using learned kappa indeed improves training perplexity, but the validation perplexity gets worse.	I-Reply	I-3	Reply	254
On the other hand, calibration improves the perplexity over the Pointer-Generator baseline, on both training and validation sets.	I-Reply	I-3	Reply	254

This paper presents a method for conditional text generation that has higher factual precision, minimizing hallucination of facts.	O	O	Review	254
The method involves predicting confidence of generation at each time step and using this confidence measure to skip tokens during generation and calibrate output probabilities in test time.	O	O	Review	254
Their method achieves SoTA performance on automatically measured precision and human evaluated "faithfulness."	O	O	Review	254
However their method does see a drop in recall (automatic metric and human evaluation).	O	O	Review	254
<sep> <sep> Comments and issues,	O	O	Review	254
- The intuitive explanation for the confidence score is a little confusing.	B-Review	B-1	Review	254
In Section 4, page 3, you say that "If a token is likely a content word (i.e. when its generation probability by the encoder-decoder is much higher than the unconditioned language model), but the attention score is low, then the token might not be predicted based on the source, and could be hallucination."	I-Review	I-1	Review	254
However, this doesn't seem like an airtight conclusion.	I-Review	I-1	Review	254
Isn't it possible that the base-LM and enc-dec model have similar probabilities for a content word with the enc-dec attention being low?	I-Review	I-1	Review	254
This seems possible given your observation that low attention to the source is what may be causing content hallucination.	I-Review	I-1	Review	254
This same thing is essentially restated in section 4.1 "we expect P(y_t |y_&lt;t, x) to be higher than P(y_t | y_&lt;t) for content words so the confidence score will largely depend on the attention score", which seems more tangled up since P(y_t |y_&lt;t, x) inherently depends on the attention score.	I-Review	I-1	Review	254
This is all clarified when you explain the alteration made to the base-LM.	I-Review	I-1	Review	254
I would recommend rewording/rearranging some of the earlier explanation for the efficacy of the confidence score since it seems that the alteration to the base-LM is an essential part of the explanation.	I-Review	I-1	Review	254
<sep> - Need some explanation for Equation 6.	B-Review	B-2	Review	254
I don't really get the intuition behind it.	I-Review	I-2	Review	254
<sep> - The presented results are pretty good!	B-Review	B-3	Review	254
However, I would like to see some numbers on average score across a few runs.	I-Review	I-3	Review	254
<sep> - It would also be good to see results on one more dataset like E2E.	B-Review	B-4	Review	254
- Provide a little more detail on human evaluation, you don't even mention if the evaluation was done with crowd-workers or another pool of people like grad students.	B-Review	B-5	Review	254
How many annotators?	I-Review	I-5	Review	254
What is the inter-annotator agreement?	I-Review	I-5	Review	254
What was the prompt/structure?	I-Review	I-5	Review	254
Human evaluation of models is notoriously difficult, more details would give some more weight to the results.	I-Review	I-5	Review	254
<sep> <sep> I think this is a well written paper with thought out experiments.	O	O	Review	254
I recommend it be accepted to ICLR.	B-Review	B-7	Review	254
I'd also be curious to see some future work that improves, or at least maintains recall, while keeping the higher precision.	I-Review	I-7	Review	254
<sep> <sep> Minor requests/recommendations:	O	O	Review	254
- Include more examples of generations.	B-Review	B-6	Review	254
Could be an appendix.	I-Review	I-6	Review	254
<sep> <sep> Thanks for the detailed review.	O	O	Reply	254
Reviewer #3 has suggested motivating our model designs better, describing more details about our human evaluation, and adding more generation examples.	B-Reply	B-5	Reply	254
We have added these in our revised paper.	I-Reply	I-5	Reply	254
<sep> <sep> We have also done some extra work on additional runs and more datasets, as discussed below:	O	O	Reply	254
<sep> &gt; I would like to see some numbers on average score across a few runs	O	O	Reply	254
<sep> We do not have an average across multiple runs, but a second run of our model suggests that: similar BLEU and PARENT scores can be achieved by different runs, but the best performing hyper-parameters vary -- the chosen \rho, \gamma and \lambda reported in our paper do not always give the best results; it is better to sweep on these hyper-parameters.	B-Reply	B-3	Reply	254
<sep> <sep> &gt; It would also be good to see results on one more dataset like E2E.	O	O	Reply	254
<sep> Actually, we had results on a second dataset: the RotoWire (Wiseman et al 2017).	B-Reply	B-4	Reply	254
We did not use E2E because E2E seems simpler and has less source-reference divergence; we wanted to test on a more complicated and hallucination-prone dataset.	I-Reply	I-4	Reply	254
Our results on RotoWire are as follows:	I-Reply	I-4	Reply	254
<sep> Entity Modelling (Puduppully et al 2019): BLEU 16.37  PARENT Prec.	I-Reply	I-4	Reply	254
34.68 Rec.	I-Reply	I-4	Reply	254
36.79 F1 34.47 Avg.	I-Reply	I-4	Reply	254
Len.	I-Reply	I-4	Reply	254
295	I-Reply	I-4	Reply	254
Content Planning (Puduppully et al 2018): BLEU 16.85 PARENT Prec.	I-Reply	I-4	Reply	254
35.40 Rec.	I-Reply	I-4	Reply	254
40.41 F1 36.59 Avg.	I-Reply	I-4	Reply	254
Len.	I-Reply	I-4	Reply	254
332	I-Reply	I-4	Reply	254
Pointer-Generator: BLEU 9.15 PARENT Prec.	I-Reply	I-4	Reply	254
37.68 Rec.	I-Reply	I-4	Reply	254
36.48 F1 35.94 Avg.	I-Reply	I-4	Reply	254
Len.	I-Reply	I-4	Reply	254
251	I-Reply	I-4	Reply	254
Confident Pointer-Generator: BLEU 8.40 PARENT Prec.	I-Reply	I-4	Reply	254
42.64 Rec.	I-Reply	I-4	Reply	254
35.23 F1 37.69 Avg.	I-Reply	I-4	Reply	254
Len.	I-Reply	I-4	Reply	254
233	I-Reply	I-4	Reply	254
<sep> It seems that our Confident Pointer-Generator achieves SoTA PARENT Precision on RotoWire as well.	I-Reply	I-4	Reply	254
However, we did not report these results in our paper because we did not conduct human evaluation.	I-Reply	I-4	Reply	254
<sep> <sep> &gt; I'd also be curious to see some future work that improves, or at least maintains recall, while keeping the higher precision.	O	O	Reply	254
<sep> <sep> Absolutely.	B-Reply	B-7	Reply	254
To extend this approach and achieve high precision text generation on more complicated datasets is one of the major topics we are working on.	I-Reply	I-7	Reply	254

This paper aims to solve the unfaithful generation problem for a specific data-to-text generation task, i.e. wikibio dataset.	O	O	Review	254
The wikibio dataset has a specific feature, where the output doesn't often reflect the input info box.	O	O	Review	254
This will cause the traditional seq2seq-style neural generation models to hallucinate frequently since the training objective is often based on word likelihood.	O	O	Review	254
<sep> <sep> The paper thus design a confidence scorer that estimates whether a word should be generated according to the source information.	O	O	Review	254
This score is used in both training and testing.	O	O	Review	254
In training, it helps avoid learn to generate the low confidence words.	O	O	Review	254
In testing, it is used to adjust output probabilities.	O	O	Review	254
<sep> <sep> Overall, I think this is an interesting idea.	O	O	Review	254
However, the design of confidence score highly rely on the attentions calculates from the generation process, and whether attentions can be reliably estimated is questionable.	B-Review	B-1	Review	254
Maybe it would be useful to show some statistics (not just manually picked examples) on the hallucinated words, and see what's the portion of them are due to "flattened" attentions.	I-Review	I-1	Review	254
<sep> <sep> Furthermore, the experimental results are not convincing.	B-Review	B-2	Review	254
The generations of the proposed models are significantly shorter (might be the result of training, see my comment below about 4.3), the results are mixed, both coverage and fluency are worse.	B-Review	B-6	Review	254
Wrt results, since the dataset is from Wiki, BLEU should be pretty indicative of the generation quality.	B-Review	B-7	Review	254
And we do see significant drop of the proposed model.	I-Review	I-7	Review	254
<sep> <sep> <sep> More comments:	O	O	Review	254
- Eq 6 needs to be better explained.	B-Review	B-3	Review	254
I don't know if this is the common way to calculate attentions, or I misunderstood the equation.	I-Review	I-3	Review	254
<sep> <sep> - In 4.3, I'm not sure if I can understand it correctly.	B-Review	B-4	Review	254
When the authors say "minimize the negative log-likelihood on the confidence sub-sequence", does it mean words not in the subsequences are ignored?	B-Review	B-8	Review	254
Won't this hurt the language modeling part?	I-Review	I-8	Review	254
I.e. cause the ungrammaticality?	I-Review	I-8	Review	254
Is this why the fluency scores are low in Table 2?	I-Review	I-8	Review	254
<sep> <sep> - If the authors want to show their model improve faithfulness, sample outputs should be shown.	B-Review	B-5	Review	254
Thanks for the thoughtful review.	B-Reply	B-1	Reply	254
Reviewer #1 has concerns about our model design and does not fully agree with our evaluation.	I-Reply	I-1	Reply	254
We address these below.	I-Reply	I-1	Reply	254
<sep> <sep> In our revised paper, we have added generation examples and more details about our human evaluation process to further strengthen our points.	I-Reply	I-1	Reply	254
We will also release our model predictions and human evaluations soon, and open source the code upon publication of this work.	I-Reply	I-1	Reply	254
<sep> <sep> &gt; whether attentions can be reliably estimated is questionable.	O	O	Reply	254
Maybe it would be useful to show some statistics (not just manually picked examples) on the hallucinated words, and see what's the portion of them are due to "flattened" attentions.	O	O	Reply	254
<sep> <sep> In our revised paper, we have added more examples showing the attention score.	B-Reply	B-1	Reply	254
Typically, the attention score is high (~0.9) when the model is copying from source (e.g. ‚ÄúCampbell‚Äù in Figure 2), medium (~0.4) when the model is generating based on some information from the source (e.g. ‚Äú&lt;unk&gt;‚Äù in Figure 2), and low (~0.2) when the model is generating template elements (e.g. ‚Äúis‚Äù in Figure 2).	I-Reply	I-1	Reply	254
As a quantitative evaluation, please recall that we can boost the faithfulness by four points in human evaluation simply by removing low confidence tokens in post-processing: this clearly demonstrates that low confidence score is strongly correlated with hallucinated words.	I-Reply	I-1	Reply	254
<sep> <sep> &gt; the experimental results are not convincing.	O	O	Reply	254
The generations of the proposed models are significantly shorter	O	O	Reply	254
<sep> We regard generating shorter sentences as a feature rather than shortcome.	B-Reply	B-2	Reply	254
The sentence length itself is not an issue here; in this work we focus on faithfulness.	I-Reply	I-2	Reply	254
We have shown that our novel techniques can improve faithfulness, but sometimes at the cost of slightly reducing coverage.	I-Reply	I-2	Reply	254
These techniques are general in principle so they can potentially be combined with other techniques, for example the ones that increase coverage, to make better systems.	I-Reply	I-2	Reply	254
<sep> <sep> &gt; the results are mixed, both coverage and fluency are worse	O	O	Reply	254
<sep> Actually, our Confident Pointer-Generator model has a better fluency than the baseline Pointer-Generator.	B-Reply	B-6	Reply	254
<sep> <sep> &gt; BLEU should be pretty indicative of the generation quality.	O	O	Reply	254
And we do see significant drop of the proposed model	O	O	Reply	254
<sep> BLEU is a bad metric for measuring faithfulness, and it is strongly correlated with sentence length.	B-Reply	B-7	Reply	254
As a matter of fact, one can simply boost the BLEU score of the baseline Pointer-Generator model from 41 to 45 by setting Wu et al (2016)‚Äôs length penalty to 2.0 at inference time; but this will hurt PARENT precision and decrease the faithfulness by 10 points according to our human evaluation.	I-Reply	I-7	Reply	254
At least for the Wikibio dataset, we should trust PARENT precision more than BLEU score for measuring faithfulness, which we believe is one of the major points established by Dhingra et al (2019).	I-Reply	I-7	Reply	254
<sep> <sep> &gt; Eq 6 needs to be better explained.	O	O	Reply	254
<sep> <sep> Thanks.	O	O	Reply	254
We have edited our paper to make the motivation clearer.	B-Reply	B-3	Reply	254
<sep> <sep> &gt; When the authors say "minimize the negative log-likelihood on the confidence sub-sequence", does it mean words not in the subsequences are ignored?	O	O	Reply	254
<sep> <sep> Yes, exactly.	B-Reply	B-4	Reply	254
<sep> <sep> &gt; Won't this hurt the language modeling part?	O	O	Reply	254
I.e. cause the ungrammaticality?	O	O	Reply	254
Is this why the fluency scores are low in Table 2?	O	O	Reply	254
<sep> <sep> No.	B-Reply	B-8	Reply	254
Surprisingly, this won‚Äôt hurt fluency and mostly doesn‚Äôt cause ungrammaticality.	I-Reply	I-8	Reply	254
Actually, our Confident Pointer-Generator model has a better fluency than the baseline Pointer-Generator.	I-Reply	I-8	Reply	254
We will release data soon including the predictions by our model.	I-Reply	I-8	Reply	254
And we will release our code upon publication of this work.	I-Reply	I-8	Reply	254
<sep> <sep> The fact that it doesn‚Äôt hurt fluency is also a surprise to us.	I-Reply	I-8	Reply	254
The model does seem to generate some ungrammatical sentences when we use greedy search for decoding; but the results become mostly fluent after we adopted beam search with beam size 8.	I-Reply	I-8	Reply	254
<sep> <sep> We have tried more conservative approaches, such as pretraining the base-LM on the training corpus without subsequence sampling.	I-Reply	I-8	Reply	254
Those methods do not necessarily improve fluency, but hurt faithfulness instead.	I-Reply	I-8	Reply	254
<sep> <sep> &gt; If the authors want to show their model improve faithfulness, sample outputs should be shown.	O	O	Reply	254
<sep> <sep> Thanks.	O	O	Reply	254
We have added more generation examples and human evaluation details to our revised paper, and welcome the critical judgement.	B-Reply	B-5	Reply	254
We will also release our human evaluation data soon.	I-Reply	I-5	Reply	254

This paper studies the problem of data-to-text generation so that the generated text stays truthful to the data source.	O	O	Review	254
The idea of the paper is use a learned confidence score as to how much the the encoder-decoder is paying attention to the source.	O	O	Review	254
The paper includes several components, 1.	O	O	Review	254
unconditioned language model to incorporate the confidence score, 2.	O	O	Review	254
use calibration techniques to adjust the output probability; 3.	O	O	Review	254
variational bayes objective to learn the confidence score.	O	O	Review	254
<sep> <sep> The paper has good motivations and is quite well-written.	O	O	Review	254
The problem is of great pragmatic interest.	O	O	Review	254
In the experimental part, the authors demonstrate the effectiveness of the proposed algorithm.	O	O	Review	254
<sep> <sep> 1.	B-Review	B-1	Review	254
For training part, regarding the language model and  variational bayes objective being trained jointly, does it have convergence problem?	I-Review	I-1	Review	254
What is the motivation of not training them jointly?	I-Review	I-1	Review	254
<sep> 2.	O	O	Review	254
Will the code be released and the human evaluation be published?	B-Review	B-2	Review	254
<sep> 3.	B-Review	B-3	Review	254
There are some importance baseline missing, such as [1], [2], [3]	I-Review	I-3	Review	254
<sep> [1] Marcheggiani, Diego, and Laura Perez-Beltrachini. "	O	O	Review	254
Deep graph convolutional encoders for structured data to text generation."	O	O	Review	254
arXiv preprint arXiv:1810.09995 (2018).	O	O	Review	254
<sep> [2] Ratish Puduppully, Li Dong, and Mirella Lapata. "	O	O	Review	254
Data-to-text Generation with Entity Modeling."	O	O	Review	254
arXiv preprint arXiv:1906.03221 (2019).	O	O	Review	254
<sep> [3] Ma, Shuming, et al "Key Fact as Pivot: A Two-Stage Model for Low Resource Table-to-Text Generation."	O	O	Review	254
arXiv preprint arXiv:1908.03067 (2019).	O	O	Review	254
<sep> <sep> Thanks for the informative review.	B-Reply	B-2	Reply	254
Reviewer #2 suggested some more related works and wanted to know if we will publicly release our code and data.	I-Reply	I-2	Reply	254
<sep> <sep> &gt; Regarding our code and human evaluation data:	O	O	Reply	254
<sep> Yes, we will release our model predictions and human evaluations soon, and open source the code upon publication of this work.	B-Reply	B-2	Reply	254
We have also modified our paper and added generation examples and more details about our human evaluation process.	I-Reply	I-2	Reply	254
<sep> <sep> &gt; Regarding related works:	O	O	Reply	254
<sep> [2] has already been cited by the previous version of our paper, and we have added [1] and [3] to the revised version.	B-Reply	B-3	Reply	254
Thanks!	I-Reply	I-3	Reply	254
<sep> <sep> The approaches described in [1][2][3] are not directly comparable to our model: [1] and [2] are not tested on the WikiBio dataset, especially [2] has many data specific model designs that may not be easily applied to WikiBio. (	I-Reply	I-3	Reply	254
However, please see our discussion with Reviewer #3 about results on the RotoWire dataset.) [	I-Reply	I-3	Reply	254
3] has a different focus on low resource table-to-text generation using only limited training data.	I-Reply	I-3	Reply	254
Therefore, we did not compare with them in our experiments.	I-Reply	I-3	Reply	254
<sep> <sep> &gt; regarding the language model and  variational bayes objective being trained jointly, does it have convergence problem?	O	O	Reply	254
<sep> <sep> There seems to be no particular convergence problems; all of our models are tested upon convergence.	B-Reply	B-1	Reply	254
The training process is like, at the beginning all tokens are unconfident, then the entropy term in our variational Bayes loss pushes up the confidence of some tokens; the model learns to generate highly confident tokens first, such as names and birth dates; then, gradually the model learns to generate longer sentences.	I-Reply	I-1	Reply	254
It is quite sensitive to hyper-parameters how conservative the final model becomes.	I-Reply	I-1	Reply	254

The authors address the problem of recovering an underlying signal from lossy and inaccurate measurements in an unsupervised fashion.	O	O	Review	166
They use a GAN framework to recover plausible signals from the measurements in the data.	O	O	Review	166
<sep> <sep> * Authors need to test other datasets, CelebA dataset is too limited.	B-Review	B-1	Review	166
<sep> * Similarly, the experiment with different corruption processes are required.	B-Review	B-2	Review	166
<sep> * What is a definition of F. It is not clear "measurement process".	B-Review	B-3	Review	166
<sep> <sep> Thank you for your feedback.	O	O	Reply	166
We have taken note of your comments and have been actively working to take them into account.	O	O	Reply	166
<sep> You raised two main questions , one concerning the measurement process and the second one concerning the need to test the model on additional datasets.	O	O	Reply	166
<sep> <sep> Concerning the first question, we have rewritten the sections explaining to the measurement process (please, see also the general comments about the measurement process above).	B-Reply	B-2	Reply	166
Below is an extract from Section 2.1. ‚	I-Reply	I-2	Reply	166
ÄúProblem Setting‚Äù of the updated paper version:	I-Reply	I-2	Reply	166
<sep> ‚ÄúSuppose there exists a signal X ~ p_X we wish to acquire, but we only have access to this signal through lossy, inaccurate observation Y ~ p_Y. The measurement process is modeled through a stochastic operator F mapping signals X to their associated observations Y. We will refer to F as the measurement process, which corrupts the input signal.	I-Reply	I-2	Reply	166
F is parameterized by a random variable \Theta ~ p_\Theta following an underlying distribution p_\Theta we can sample from, which represents the factors of corruption.	I-Reply	I-2	Reply	166
Thus, given a specific signal x, we can simulate its measurement by first sampling \theta from p_\Theta, and then computing F(x; \theta).	I-Reply	I-2	Reply	166
Additional sources of uncertainty, e.g. due to unknown factors, can be modeled using additive i.i.d.	I-Reply	I-2	Reply	166
Gaussian noise \Eps ~ \mathcal{N}(0, \sigma^2 I), so that the overall acquisition process becomes:	I-Reply	I-2	Reply	166
Different instances of F will be considered, e.g. like random occlusions, information acquisition from a sparse subset of the signal, overly smoothing out and corrupting the original distribution with additive noise, etc... In such cases, the factors of corruption \Theta might respectively represent the position of the occlusion, the coordinates of the acquired information, or simply the values of the additive noise.	I-Reply	I-2	Reply	166
‚Äù	I-Reply	I-2	Reply	166
<sep> <sep> For different measurement processes instances, also called corruptions, please refer to the Corruptions section (4.2) in the Experiments Section.	B-Reply	B-3	Reply	166
<sep> <sep> As for the second remark, we have added experiments conducted on two additional datasets: LSUN Bedrooms, and Recipe1M. The results are provided in section 5 and in appendix 3.	B-Reply	B-1	Reply	166
Overall this confirms the good results of the model already obtained on the first dataset.	I-Reply	I-1	Reply	166

This is a very interesting paper that achieves something that seems initially impossible:	O	O	Review	166
to learn to reconstruct clear images from only seeing noisy or blurry images.	O	O	Review	166
<sep> <sep> The paper builds on the closely related prior work AmbientGAN which shows that it is possible to learn the *distribution* of uncorrupted samples using only corrupted samples, again a very surprising finding.	O	O	Review	166
<sep> However, AmbientGAN does not try to reconstruct a single image, only to to learn the clear image distribution.	O	O	Review	166
The key idea that makes this is possible is knowledge of the statistics of the corruption process: the generator tries to create images that *after they have been corrupted* they look indistinguishable from real corrupted images.	O	O	Review	166
This surprisingly works and provably recovers the true distribution under a very wide set of corruption distributions, but tells us nothing about reconstructing an actual image from measurements.	O	O	Review	166
<sep> <sep> Given access to a generative model for clear images, an image can be reconstructed from measurements by maximizing the likelihood term.	O	O	Review	166
This method (CS-GAN) was introduced by Bora et al in 2017.	O	O	Review	166
Therefore one approach to solve the problem that this paper tackles is to first use AmbientGAN to get a generative model for clear images and then use CS-GAN using the learned GAN.	O	O	Review	166
If I understand correctly, this is the 'Conditional AmbientGAN' approach that is used as a baseline.	B-Review	B-1	Review	166
This is a sensible approach given prior work.	I-Review	I-1	Review	166
However, the authors show that their method ('Unpaired Supervision') performs significantly better compared to the Conditional AmbientGAN baseline.	I-Review	I-1	Review	166
This is very surprising and interesting to me.	I-Review	I-1	Review	166
Please discuss this a bit more ?	I-Review	I-1	Review	166
As far as I understand the proposed method is a merging of AmbientGAN and CS-GAN, but much better than the naive separation.	I-Review	I-1	Review	166
Could you give a bit more intuition on why ?	I-Review	I-1	Review	166
<sep> <sep> I would like to add also that the authors can use their approach to learn a better AmbientGAN.	B-Review	B-2	Review	166
After getting their denoised images, these can be used to train a new AmbientGAN, with cleaner images as input , which should be even better no ?	I-Review	I-2	Review	166
<sep> <sep> In the appendix where is the proposed method in fig 5- 8 ?	B-Review	B-3	Review	166
<sep> <sep> Does the proposed method outperform Deep Image Prior ?	B-Review	B-4	Review	166
<sep> <sep> <sep> <sep> Thank you very much for your review and comments : they are very much appreciated.	O	O	Reply	166
<sep> <sep> ‚ÄúIf I understand correctly, this is the 'Conditional AmbientGAN' approach that is used as a baseline.	O	O	Reply	166
This is a sensible approach given prior work.	O	O	Reply	166
However, the authors show that their method ('Unpaired Supervision') performs significantly better compared to the Conditional AmbientGAN baseline.	O	O	Reply	166
This is very surprising and interesting to me.	O	O	Reply	166
Please discuss this a bit more ?	O	O	Reply	166
As far as I understand the proposed method is a merging of AmbientGAN and CS-GAN, but much better than the naive separation.	O	O	Reply	166
Could you give a bit more intuition on why ?‚	O	O	Reply	166
Äù	O	O	Reply	166
<sep> <sep> Indeed, this is correct.	B-Reply	B-1	Reply	166
The conditional AmbientGan baseline combines the approaches of AmbientGan and CS-GAN.	I-Reply	I-1	Reply	166
First, a generative model G of the data is learned without having access to samples of the signal distribution using the AmbientGAN framework.	I-Reply	I-1	Reply	166
Then, in order to reconstruct the signal from a corrupted measurement y, we look for an input vector z of G that produces a simulated measurement G(z) that looks like y, by minimizing the Euclidean distance between G(z) and y. This method suffers from several drawbacks, which we believe can explain the poor results:	I-Reply	I-1	Reply	166
<sep> * First drawback: suboptimality of the Generator.	I-Reply	I-1	Reply	166
In theory, if the generator was optimal, under suitable conditions for the measurement process F, it would generate outputs belonging to the manifold of uncorrupted images (that we shall name M).	I-Reply	I-1	Reply	166
Thus, projecting a measurement onto M should recover an uncorrupted image.	I-Reply	I-1	Reply	166
However, this is never the case: in practice, GANs suffer from a number of problems.	I-Reply	I-1	Reply	166
This means that it is possible that images from the manifold of generated images do not correspond to true samples: applying gradient descent to minimize the aforementioned distances, tend to generate  images similar to the corrupted images y, and not to uncorrupted images x. Our model does not suffer from this problem because it maximizes the log-likelihood and the prior term jointly.	I-Reply	I-1	Reply	166
If G generates a signal that does not belong to M in order to maximize the log-likelihood term (similarly to what happens with the ConditionalAmbientGan baseline), the discriminator will easily be able to detect this and consequently, the reconstruction network G is corrected in order to avoid this behaviour.	I-Reply	I-1	Reply	166
<sep> <sep> * Second drawback : Euclidean distance used in ConditionalAmbientGan is not adapted in the general case considered in the paper.	B-Reply	B-1	Reply	166
The natural thing to do would be to find a reconstruction from M that maximizes the likelihood p(y|x).	I-Reply	I-1	Reply	166
If the corruption in the measurement process corresponds to iid additive noise, it is possible to show that the problem reduces to minimizing the euclidean distance between x and y, like in ConditionalAmbientGan.	I-Reply	I-1	Reply	166
However, this is not necessarily the case for other measurement processes.	I-Reply	I-1	Reply	166
Indeed, in the general formulation, the likelihood is intractable;it requires marginalizing on the noise variables \theta, and for each SGD step we would need to approximate it, which would be very costly.	I-Reply	I-1	Reply	166
Our likelihood term in the cost functions better reflects the true likelihood.	I-Reply	I-1	Reply	166
<sep> <sep> <sep> <sep> In the appendix where is the proposed method in fig 5- 8 ?	O	O	Reply	166
<sep> Fig 5-8  (now 11-14 )are samples from our baselines.	B-Reply	B-3	Reply	166
The corresponding samples from our model were in figure 9 to 14.	I-Reply	I-3	Reply	166
We are adding our model to figures 5-8 (11-14).	I-Reply	I-3	Reply	166
Notes that we are now providing samples from other datasets (see general comments).	I-Reply	I-3	Reply	166
<sep> <sep> Does the proposed method outperform Deep Image Prior ?	O	O	Reply	166
<sep> <sep> Our experiments show that for strong corruption function DIP yields poor results compared to our model (see figure 11-14).	B-Reply	B-4	Reply	166
One of the main explanation is that it does not capture semantic information from the other images of the dataset.	I-Reply	I-4	Reply	166
<sep> <sep> For the measurement process Patch-Band, Remove-Pixel and Remove-Pixel-Channel, Deep Image Prior (DIP) has access to the corruption parameter \theta of the associated measurement (we have used the inpainting formulation of DIP).	I-Reply	I-4	Reply	166
In other words, it has access to the mask, as opposed to our model.	I-Reply	I-4	Reply	166
We have conducted experiments where DIP does not have the mask (normal formulation of DIP), and have observed very poor results (which were actually quite similar to the poor results in Conditional AmbientGAN).	I-Reply	I-4	Reply	166

This paper presents a method to reconstruct images using only noisy measurements.	O	O	Review	166
This problem is practically interesting, since the noiseless signal may be unavailable in many applications.	O	O	Review	166
The approach combines ideas from recent development in compressed sensing and GANs.	O	O	Review	166
However, the model‚Äôs presentation is confusing, and many important details of the experiments are missing.	O	O	Review	166
<sep> <sep> Pros:	O	O	Review	166
<sep> * The problem is interesting and important	O	O	Review	166
* The combination of compressed sensing and GANs for image reconstruction is novel	O	O	Review	166
<sep> Cons:	O	O	Review	166
<sep> * The model structure is unclear: for example, what is the role of the variable \theta?	B-Review	B-1	Review	166
Section 2.1 says it is known, but the algorithm samples from its prior(?).	I-Review	I-1	Review	166
Since there is no further explanation with respect to the experiments, I am not sure how the values of \theta or its distributions were determined.	I-Review	I-1	Review	166
Although \theta is formally similar to the \theta parameters of the measurement function in ambientGANs, this interpretation is at odds with the example given in the paper (below eq.1, saying \theta can be positions or sizes).	I-Review	I-1	Review	166
<sep> * A few important details of the model are missing.	B-Review	B-2	Review	166
For example, what is the exact structure of the measurement function F?	I-Review	I-2	Review	166
<sep> * The baseline models are a bit confusing.	B-Review	B-3	Review	166
More detail about unpaired vs paired supervision would also be helpful for understanding how these baseline models use the additional information.	I-Review	I-3	Review	166
<sep> * Although the paper mentioned parameters are obtained from cross-validation, it would still be helpful to describe a few important ones (e.g., neural network size, weight \lambda) for comparison with other models.	B-Review	B-4	Review	166
The experiments on only CelebA dataset are too limited.	I-Review	I-4	Review	166
Thank you for the review.	O	O	Reply	166
We are sorry that you found the overall presentation confusing, and we have been actively working on trying to make the paper much clearer.	O	O	Reply	166
We have thus submitted a revised version of the paper taking into account your comments and answering your questions.	O	O	Reply	166
Please see also the general comments.	O	O	Reply	166
Typically, we have:	O	O	Reply	166
*  Rewritten Section 2.1 (Problem Setting) describing the abstract measurement process and the role of theta, taking into account your comments.	B-Reply	B-1	Reply	166
<sep> * Modified the Method section (Section 3) in order to make the explanations more straightforward and less abstract.	B-Reply	B-5	Reply	166
Typically, we moved some mathematical results in the appendix for a more fluent reading.	I-Reply	I-5	Reply	166
<sep> * Added experiments on two additional datasets: LSUN and Recipe-1M (Section 4.1 + appendix C).	B-Reply	B-4	Reply	166
They illustrate the behavior of the model and of the baselines on image datasets with different characteristics and confirm the good results obtained by our model.	I-Reply	I-4	Reply	166
<sep> * Provided additional details on the hyperparameters and the architecture for overall  reproducibility (Section 4.1).	B-Reply	B-6	Reply	166
Note that we will be releasing the code shortly.	I-Reply	I-6	Reply	166
<sep> * Added details regarding the specific measurement instances (also called corruptions) used in the experiments (Section 4.2 Corruptions),	B-Reply	B-7	Reply	166
* Added details on the different baselines in Section 4.3. (	B-Reply	B-3	Reply	166
+ Figures visually describing them in appendix )	I-Reply	I-3	Reply	166
<sep> To answer your question regarding the structure of the measurement process: the measurement (or corruption) process described in equation (1) is assumed known.	B-Reply	B-2	Reply	166
This means that, as in most of the problem formulations for signal recovery, the structure of the stochastic function F is known.	I-Reply	I-2	Reply	166
For example, let us consider the additive Gaussian noise case.	I-Reply	I-2	Reply	166
F(X, \Theta) = X + \Theta, where X is the signal random variable to be recovered, and \Theta is the noise random variable (also called corruption parameter) whose underlying distribution p_\Theta is Gaussian.	I-Reply	I-2	Reply	166
This distribution  p_\Theta is assumed known, although for a specific measurement, we do not know the precise value \theta that contributed to its corruption.	I-Reply	I-2	Reply	166
In other cases, typically when the measurement process induces a more structured corruption such as in our Patch Band corruption, that randomly places a band occluding the original image (introduced in Section 4.2), \Theta follows a uniform distribution taking its values from the space of pixel coordinates.	I-Reply	I-2	Reply	166
To simulate this corruption process, one samples a \theta from the prior p_\Theta, and uses it to corrupt the signal x, resulting in measurement y = F(x, \theta).	I-Reply	I-2	Reply	166
In this case, F places a band using \theta as the position of the top of the band.	I-Reply	I-2	Reply	166
This is exactly the same formulation as the one used for AmbientGan: the associated corruptions parameter \Theta for ‚ÄúDropPatch‚Äù which is very similar to our ‚ÄúPatchBand‚Äù, corresponds to the position of the occluding patch (refer to the official implementation [1]).	I-Reply	I-2	Reply	166
Note that it would also be possible to sample the size of the box, if its size varies in the corrupted data.	I-Reply	I-2	Reply	166
<sep> <sep> Paired/Unpaired variant explanation :	B-Reply	B-3	Reply	166
<sep> <sep> For the two model variants that use the additional information, *Unpaired and Paired Variant* we have added additional details in the Baseline Section 4.3, and additional Figures describing them in the Baseline appendix C. Below is an extract of the Baselines Section of the updated paper:	I-Reply	I-3	Reply	166
<sep> Unpaired Variant:	I-Reply	I-3	Reply	166
‚ÄúHere, we have access to samples of the signal distribution p_X. This means that although we have no paired  samples from the joint p_X,Y, we have access to unpaired samples from p_X and p_Y. This baseline is similar to our model although, instead of discriminating between a measurement from the data y and a simulated measurement \hat{y}, we directly discriminate between samples from the signal distribution and the output of the reconstruction network \hat{x}.‚Äù	I-Reply	I-3	Reply	166
<sep> Paired Variant:	I-Reply	I-3	Reply	166
‚ÄúThis baseline has access to signal measurement pairs (y, x) from the joint distribution p_X,Y. Given input measurement y, the reconstruction is obtained by regressing to the associated signal x using a MSE loss.	I-Reply	I-3	Reply	166
In order to avoid blurry samples, we add an adversarial term in the objective in order to constrain G to produce realistic samples, as in Pix2Pix [2]. The model is trained using the same architectures as our model, and the hyperparameters have been found using cross-validation. ‚	I-Reply	I-3	Reply	166
Äù	I-Reply	I-3	Reply	166
<sep> <sep> [1]: <a href="https://github.com/AshishBora/ambient-gan/blob/master/src/commons/measure.py#L176" target="_blank" rel="nofollow">https://github.com/AshishBora/ambient-gan/blob/master/src/commons/measure.py#L176</a>	O	O	Reply	166
[2]: <a href="https://phillipi.github.io/pix2pix/" target="_blank" rel="nofollow">https://phillipi.github.io/pix2pix/</a>	O	O	Reply	166

This paper presents a possible way to mitigate catastrophic forgetting by using a k-nearest neighbor (kNN) classifier as the last layer of a neural network as opposed to a SoftMax classifier.	O	O	Review	166
I think this an interesting and possibly novel use of a kNN layer (I haven't seen similar uses although I'm not that familiar with the specific research area).	O	O	Review	166
At the same time it's not presenting a ground breaking new algorithm or anything like that.	B-Review	B-1	Review	166
<sep> <sep> Overall the paper is fairly well written and not too hard to follow.	O	O	Review	166
I would say overall results in Table 1 are positive although the authors' approach has the lowest performance after just training on set A if that initial accuracy is important, and also doesn't have quite as high of an accuracy on test B compared to most of the other baselines.	B-Review	B-2	Review	166
Additionally, if you add the accuracy on both set A and set B after training on set B the sum is slightly higher for Rtf.	I-Review	I-2	Review	166
If you look at the minimum accuracy between set A and set B after training on set B, however, the authors' method has the highest value which might be what someone is looking to maximize.	I-Review	I-2	Review	166
<sep> One weakness of this is paper is that I think there are other baselines that should be compared against in Table 1 such as something as basic as SGD with dropout (some of the baselines that are compared against in Table 1 were compared against SGD with dropout in their citations).	B-Review	B-3	Review	166
There are a number of additional approaches outlined in <a href="https://www.cs.uic.edu/~liub/lifelong-learning/continual-learning.pdf."	I-Review	I-3	Review	166
target="_blank" rel="nofollow">https://www.cs.uic.edu/~liub/lifelong-learning/continual-learning.pdf.</a>  Also maybe even something with self attention such as Serra at al.	I-Review	I-3	Review	166
<a href="https://arxiv.org/pdf/1801.01423.pdf."	I-Review	I-3	Review	166
target="_blank" rel="nofollow">https://arxiv.org/pdf/1801.01423.pdf.</a>	I-Review	I-3	Review	166
<sep> Another potential issue I have with this paper is that it only reports results for the authors' method and the vanilla baseline for more complex CIFAR-10 and ImageNet data sets in Table 2.	B-Review	B-4	Review	166
Assuming there aren't restrictive assumptions for some of the methods that prevent them from being run on the other data sets (at least SI was previously evaluated on CIFAR-10), I would like to see how other baselines perform on these more complex datasets too.	I-Review	I-4	Review	166
<sep> <sep> The lack of some more baselines such as SGD with dropout, and not reporting the performance of the same baselines from Table 1 in Table 2, cause me to be very borderline on this paper.	B-Review	B-3	Review	166
I do appreciate the sensitivity analysis and ablation study provided.	O	O	Review	166
<sep> <sep> As alluded to in future work I'm curious how the authors' approach might be applied to reinforcement learning, and if there could be a way to deal with continuous action spaces in RL.	B-Review	B-5	Review	166
Thanks for your review.	O	O	Reply	166
Below is our response:	O	O	Reply	166
<sep> Q1: Interpretation of results in Table 1	O	O	Reply	166
A1: Our method achieves the second highest absolute performance and also the second smallest drop in performance on Set A after seeing Set B. The only method that achieved better performance on Set A after seeing Set B is LwF, which is because its performance on Set B is very poor.	B-Reply	B-2	Reply	166
This indicates that our method achieves a good balance in learning well on new data and retaining performance on old data.	I-Reply	I-2	Reply	166
It is also a lot less complex than methods that can achieve reasonable retention performance (DGR, DGR + distillation and RtF) - these methods require training a generative model (a VAE) to produce pseudo-training examples, whereas our method does not require training an external model.	I-Reply	I-2	Reply	166
This also makes our method more broadly applicable, since it is more difficult to train high-performing generative models on some datasets, e.g.: CIFAR-10 (more on this below).	I-Reply	I-2	Reply	166
<sep> <sep> Q2: Additional SGD + dropout baseline	O	O	Reply	166
A3: We have added this baseline (with a dropout probability of 0.5, which is standard in literature and recommended by <a href="https://arxiv.org/abs/1312.6211)" target="_blank" rel="nofollow">https://arxiv.org/abs/1312.6211)</a> in Table 1.	B-Reply	B-3	Reply	166
As shown, our method outperforms the baseline in terms of retention ability by a large margin.	I-Reply	I-3	Reply	166
<sep> <sep> Q3: Other baselines for CIFAR-10	O	O	Reply	166
A3: We have added results of other baselines on CIFAR-10 in Table 3.	B-Reply	B-4	Reply	166
As shown, our method achieves the highest absolute performance on Set A after seeing Set B and also the smallest drop in performance on Set A after seeing Set B. Interestingly, on this more complex dataset, none of the baselines (except for LwF) are able to retain significant amounts of knowledge after training on Set B. As discussed above, methods that rely on generative models (DGR, DGR + distillation and RtF) no longer perform well because training high-performing generative models on CIFAR-10 is more difficult due to the increased complexity of the data.	I-Reply	I-4	Reply	166
<sep> <sep> Q4: Extension to the RL setting with continuous action space	O	O	Reply	166
R4: We plan to explore this in future work and consider replacing the k-nearest neighbour classifier with k-nearest neighbour regression.	B-Reply	B-5	Reply	166
This requires changing the triplet loss to encourage samples within the neighbourhood that have similar outputs as the ground truth to be moved closer, and samples within the neighbourhood that have dissimilar outputs as the ground truth to be moved farther.	I-Reply	I-5	Reply	166

This paper applies metric learning to reduce catastrophic forgetting on neural networks.	O	O	Review	166
By improving the expressiveness of the final layer, the authors claim that lower layers do not change weights as much, leading to better results in continual learning.	O	O	Review	166
They provide large-scale experiments on different datasets.	O	O	Review	166
<sep> <sep> I like the idea that the authors propose and the intuition for why it works, and the paper is well-written.	O	O	Review	166
However, I have some concerns and questions.	O	O	Review	166
My main concern is that experiments are only performed in the two-task setting, which is highly restrictive.	B-Review	B-1	Review	166
<sep> <sep> The authors claim that they tackle the general 'continuous task-agnostic learning' setting.	I-Review	I-1	Review	166
However, they only test on the two-task setting.	I-Review	I-1	Review	166
There are various problems with considering only a two-task setting (see for example Farquhar and Gal, "Towards Robust Evaluations of Continual Learning").	I-Review	I-1	Review	166
It is too easy to optimise parameters and methods to work in the two-task setting that will not generalise to more than two tasks, which the authors seem to claim.	I-Review	I-1	Review	166
I would need to see experiments on more than two tasks.	I-Review	I-1	Review	166
Aside from this, the experiments seem detailed, with a reasonable baseline, large-scale experiments (on ImageNet), and with an ablation study.	O	O	Review	166
<sep> <sep> It seems to me like the anchors need to be chosen before training.	B-Review	B-2	Review	166
This means that this method requires memory / storage of past data examples.	I-Review	I-2	Review	166
It is usually fine to do store a small subset of examples in continual learning, but should be made explicit, because it may not always be possible (eg if there are data privacy laws).	I-Review	I-2	Review	166
<sep> <sep> I do not understand the reason why the output embeddings need to be normalised (Section 3.3)?	B-Review	B-3	Review	166
I can see from Table 4 that it improves results, but do not see any intuition.	I-Review	I-3	Review	166
<sep> <sep> I would also like to see the computational cost of this method, perhaps as a run-time compared to the baseline.	B-Review	B-4	Review	166
There are many hyperparameters to tune on the validation set which may slow the method down.	I-Review	I-4	Review	166
The sensitivity analysis did not consider changing 'd' or 'M', which seem like crucial hyperparameters to me.	I-Review	I-4	Review	166
<sep> <sep> ------------	O	O	Review	166
EDIT: I will keep my score after the the discussion with authors.	O	O	Review	166
Although the paper has improved in my opinion, I still recommend Weak Reject.	O	O	Review	166
I very much appreciated the 5-task CIFAR-10 results.	B-Review	B-4	Review	166
However, there are simple baselines in this setting that I believe need to be explored and reported.	I-Review	I-4	Review	166
Namely, baselines but with samples, eg EWC+samples, akin to the RWalk paper that AnonReviewer1 mentions (<a href="https://arxiv.org/pdf/1801.10112.pdf)."	I-Review	I-4	Review	166
target="_blank" rel="nofollow">https://arxiv.org/pdf/1801.10112.pdf).</a> This is because the proposed method also uses samples.	I-Review	I-4	Review	166
Going from the RWalk paper, this improves results for the baselines considerably, but this may depend on number of samples etc.	I-Review	I-4	Review	166
I understand there was not much time during the rebuttal period to include this.	I-Review	I-4	Review	166
I hope that the authors will consider doing so in the future.	I-Review	I-4	Review	166
<sep> <sep> The discussion/explanation regarding 'task-agnostic' (train and test time) and also regarding how the anchors are chosen needs to be made clearer.	B-Review	B-1	Review	166
Thanks for your review.	O	O	Reply	166
Below is our response:	O	O	Reply	166
<sep> Q1: Experiments on more than two tasks	O	O	Reply	166
A1: We added new results on a five-task CIFAR-10 dataset (where each task is a consecutive pair of classes), along with results using the baselines, which are presented in Table 2.	B-Reply	B-1	Reply	166
As shown, our method outperforms all baselines.	I-Reply	I-1	Reply	166
<sep> <sep> Q2: Anchors and requirements for storage	O	O	Reply	166
A2: We only used one anchor per class, so only a minimal number of past data examples need to be stored (we‚Äôve made this clearer in the manuscript).	B-Reply	B-2	Reply	166
The anchor for a class can be chosen the first time an example from that class is encountered.	I-Reply	I-2	Reply	166
<sep> <sep> Q3: Why normalization helps intuitively	O	O	Reply	166
A3: By normalizing vectors, we essentially project them onto a unit sphere.	B-Reply	B-3	Reply	166
The benefit of this is that the sphere is a closed surface, unlike the original Euclidean space the vectors lie in.	I-Reply	I-3	Reply	166
In Euclidean space, all points can easily be pushed very far away from each other, or brought very close together - neither of these scenarios help with classifying points correctly.	I-Reply	I-3	Reply	166
On the other hand, pushing points away from a point on a unit sphere must make them closer to a point on the opposite side of the sphere - this property of the sphere helps us avoid either of the two scenarios above.	I-Reply	I-3	Reply	166
<sep> <sep> Q4: Computational cost of the method	O	O	Reply	166
A4: Our method ~2 minutes on MNIST and ~12 minutes on CIFAR-10, which are comparable to the runtimes of the baselines.	B-Reply	B-4	Reply	166

This paper considers the use of a metric learning approach in a continual/lifelong classification settings.	O	O	Review	166
Experiments show in the case of two tasks forgetting can be minimized by using the approach.	O	O	Review	166
<sep> <sep> Methods	O	O	Review	166
The proposed method appears to be a standard triplet loss.	O	O	Review	166
The authors add a second term to the triplet loss that is essentially making the loss a combination of the triplet and siamese loss.	B-Review	B-1	Review	166
It‚Äôs not really explained anywhere why they do this and whether its essential to the performance.	I-Review	I-1	Review	166
<sep> <sep> Is there anything specific to continual learning done or is the paper essentially pointing out this existing method (metric learning + nearest neighbor) is surprisingly effective for forgetting.	B-Review	B-2	Review	166
If this is the case the authors should present it in this way I think.	I-Review	I-2	Review	166
<sep> <sep> Although triplet loss can often yield reasonably performance on classification problems it tends to not perform as well as cross entropy loss, this is observed in other works as well as this one.	B-Review	B-3	Review	166
<sep> <sep> A major question of mine: it is not clear from the method nor experiments what samples are stored after task A for the kNN classifier.	B-Review	B-4	Review	166
Is it all of the data samples from the previous task?	I-Review	I-4	Review	166
<sep> <sep> Experiments	O	O	Review	166
The experimental results consider a custom continual learning setup where there is two sets of categories.	O	O	Review	166
Overall the experiments seem lacking at the moment in rigorous comparisons.	O	O	Review	166
<sep> <sep> MNIST experimental comparisons are currently suspect.	B-Review	B-5	Review	166
It is  very surprising that LwF does so poorly, do the authors have some explanation for this.	I-Review	I-5	Review	166
LwF is typically a reasonable baseline for these 2 task settings (e.g. <a href="https://arxiv.org/pdf/1704.01920.pdf)."	I-Review	I-5	Review	166
target="_blank" rel="nofollow">https://arxiv.org/pdf/1704.01920.pdf).</a>  Similarly the well known EWC is shown to simply not work at all for the very task it was designed for on the MNIST dataset.	I-Review	I-5	Review	166
LwF and EWC simply not working to any degree seem to me like  rather dramatic claims to make without any explanation.	I-Review	I-5	Review	166
<sep> Cryptically the fine-tuning baseline described in 4.2 is not shown here for MNIST?	I-Review	I-5	Review	166
This seems a major oversight	I-Review	I-5	Review	166
<sep> CIFAR10/Imagenet Experiments	O	O	Review	166
It is not clear if the baseline finetuning is done on only the top weights or the entire network.	B-Review	B-6	Review	166
Both of these baselines should be considered.	I-Review	I-6	Review	166
Another good baseline to consider is finetuning with cosine distance and only the top weights as in <a href="https://arxiv.org/pdf/1804.09458.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1804.09458.pdf</a> and other recent works should also be considered	I-Review	I-6	Review	166
<sep> Why do the authors not include any of the baselines from MNIST experiments here, for example LwF.	B-Review	B-7	Review	166
<sep> Ablations study the need for normalization and dynamic margin, it seems these are helpful for accuracy and forward transfer (and not as critical for minimizing forgetting).	B-Review	B-8	Review	166
<sep> <sep> <sep> The author state their method is agnostic to the task boundaries, its a bit unclear what this means in this context.	B-Review	B-9	Review	166
The procedure is not online and the labels of the samples are being used?	I-Review	I-9	Review	166
If the authors are referring to the need to add additional outputs to the ‚Äúvanilla‚Äù model this seems like it can be trivially addressed by simply saying outputs are added the first time a new class is seen thereby making it agnostic to the boundary in the same sense as this method.	I-Review	I-9	Review	166
<sep> <sep> Clarity	B-Review	B-11	Review	166
Can be problematic at times.	I-Review	I-11	Review	166
Although all the elements of the approach are outlined the motivations are overly wordy and repetitive making them actually hard to follow.	O	O	Review	166
<sep> <sep> -(minor) first/2nd paragraph of 3.1 seems a bit redundant making it hard to follow	B-Review	B-12	Review	166
<sep> Overall I think the idea to consider metric learning and local adaptation for continual learning is interesting, however the current work is currently lacking in both experimental evidence (appropriate comparisons) and clear motivation/difference to existing work  for its particular instantiation of this idea.	B-Review	B-10	Review	166
<sep> <sep> ++++Post Rebuttal++++	O	O	Review	166
<sep> Thank you for your detailed responses.	O	O	Review	166
<sep> <sep> The clarification about ‚Äútask-agnostic‚Äù for the experiments does make them look more relevant than I had previously assessed.	B-Review	B-13	Review	166
I do want to note that the language used for this is inconsistent with the ones used in other papers, which typically calls this a ‚Äúshared-head‚Äù setting (<a href="https://arxiv.org/pdf/1801.10112.pdf," target="_blank" rel="nofollow">https://arxiv.org/pdf/1801.10112.pdf,</a> <a href="https://arxiv.org/pdf/1805.09733.pdf," target="_blank" rel="nofollow">https://arxiv.org/pdf/1805.09733.pdf,</a> <a href="https://arxiv.org/pdf/1903.08671.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1903.08671.pdf</a> ).	I-Review	I-13	Review	166
It is also somewhat inconsistent with the authors own definition of ‚Äútask agnostic learning‚Äù given in the introduction of this paper which implies it is something related to task boundaries at training time, in fact this is something related to availability of the task id at test time.	I-Review	I-13	Review	166
I suggest the authors to make this more clear.	I-Review	I-13	Review	166
Furthermore, the authors should highlight all this in the experiment text, e.g. noting EWC does poorly but this is because we use a different protocol than this and this paper etc.	I-Review	I-13	Review	166
<sep> <sep> Regarding the experiments under this light they do look more reasonable.	O	O	Review	166
Indeed it has been observed that EWC works poorly in the shared-head setting <a href="https://arxiv.org/pdf/1801.10112.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1801.10112.pdf</a>	O	O	Review	166
Regarding the new 5 task CIFAR-10 the results are interesting, however I will point the authors to the work above (Rwalk) which also reports results in this setting better than theirs (but not by too much).	B-Review	B-6	Review	166
<sep> <sep> I do however still have issues regarding the memory usage of the method, specifically which data needs to be stored from previous tasks.	B-Review	B-4	Review	166
It is still not completely clear and I find obfuscated since just one sentence not even fully answering the concern about this was added to the manuscript despite myself and another reviewer asking about it.	I-Review	I-4	Review	166
My understanding based on the (somewhat conflicted responses) of the authors is they store a substantial amount of prior task data, but most of this is only used  at test time.	I-Review	I-4	Review	166
For example for imagenet as much as 1000 images/class are stored for testing time.	I-Review	I-4	Review	166
This begs the question why not use this data for training as well if it is allowed to be used by the model at testing time (and therefore preserved from the first task), why is the storage cost of this data not considered and how do the authors justify this still being a lifelong learning setup.	I-Review	I-4	Review	166
As an alternative, why can't one use a much bigger fully parametric model that uses the same amount of storage as the authors model + stored images.	I-Review	I-4	Review	166
It seems it is not fair to compare these to methods that cant utilize this large storage amount.	I-Review	I-4	Review	166
<sep> <sep> Finally its not clear if this data is stored as raw images or somehow stored as embeddings.	I-Review	I-4	Review	166
If it is stored as embeddings this would require some discussion on how the authors avoid representation drift when the next task is training.	I-Review	I-4	Review	166
If the authors store raw images, it means at evaluation time the entire raw dataset needs to be re-encoded, therefore the model can‚Äôt perform easily anytime inference.	I-Review	I-4	Review	166
<sep> <sep> Unfortunately the discussion period ended but I would have liked more clarification on this, on the other hand these pieces of information should really have been in the manuscript in the first place.	O	O	Review	166
<sep> <sep> Overall, my impression of the paper is improved.	O	O	Review	166
But I do think it could use some further writing revisions to emphasize/clarify key points: a) the method is not new (it says e.g. in abstract ‚Äúnew model‚Äù which is misleading) but its application in CL is under-explored b) the experiments show poor performance on existing methods because most of those are not designed nor work well for the shared head ‚Äútask agnostic‚Äù setting, while metric learning handles it gracefully.	B-Review	B-9	Review	166
c) be explicit about what is the memory being stored when moving onto the next task (this should be somewhere visible and explicit) and how this is justified	B-Review	B-4	Review	166
<sep> <sep> Thanks for your review.	O	O	Reply	166
Below is our response:	O	O	Reply	166
<sep> Q1: ‚ÄúThe authors add a second term to the triplet loss that is essentially making the loss a combination of the triplet and siamese loss.	O	O	Reply	166
It‚Äôs not really explained anywhere why they do this‚Äù	O	O	Reply	166
A1: This is in fact explained in the paper.	B-Reply	B-1	Reply	166
As mentioned at the bottom of page 4, ‚ÄúIn practice, we found that training using L_{triplet} results in overlap between clusters for different classes, as shown in Figure 2.	I-Reply	I-1	Reply	166
To discourage this, we add another term to the loss function to encourage tight clusters‚Äù.	I-Reply	I-1	Reply	166
<sep> <sep> Q2: ‚ÄúIs the paper essentially pointing out this existing method (metric learning + nearest neighbor) is surprisingly effective for forgetting.	O	O	Reply	166
If this is the case the authors should present it in this way I think.	O	O	Reply	166
‚Äù	O	O	Reply	166
A2: As we stated at the end of the introduction section, ‚ÄúWe will show	B-Reply	B-2	Reply	166
that this simple modification is surprisingly effective at reducing catastrophic forgetting‚Äù, which is already in line with this suggestion.	I-Reply	I-2	Reply	166
<sep> <sep> The simplicity of our method is an important advantage compared to other methods that add specialized regularizers, because (1) a simpler method is more broadly applicable because it can be used in settings when the signals required by the regularizers (e.g.: task identity or boundary - more on this later) are unavailable, (2) and is more flexible because it can be combined with other approaches.	I-Reply	I-2	Reply	166
<sep> <sep> The insight that metric learning can be used effectively for continual learning is novel and did not appear in prior work to our knowledge - this represents a new perspective for continual learning research that catastrophic forgetting may be partly caused by limitations in the model itself rather than problems with the training objective.	I-Reply	I-2	Reply	166
<sep> <sep> Q3: ‚ÄúAlthough triplet loss can often yield reasonably performance on classification problems it tends to not perform as well as cross entropy loss, this is observed in other works as well as this one.	O	O	Reply	166
‚Äù	O	O	Reply	166
A3: While this may be true if the goal is to maximize single-task performance, the point of this paper is to demonstrate that metric learning is quite effective if the goal is to minimize catastrophic forgetting.	B-Reply	B-3	Reply	166
Future improvements to metric learning techniques could help narrow the gap between triplet loss and cross-entropy loss on single tasks, but are orthogonal to our method.	I-Reply	I-3	Reply	166
<sep> <sep> Q4: ‚ÄúA major question of mine: it is not clear from the method nor experiments what samples are stored after task A for the kNN classifier.	O	O	Reply	166
Is it all of the data samples from the previous task?‚Äù	O	O	Reply	166
A4: We only store one example from each class (to serve as anchors).	B-Reply	B-4	Reply	166
<sep> <sep> Q5: ‚ÄúMNIST experimental comparisons are currently suspect.	O	O	Reply	166
It is  very surprising that LwF does so poorly, do the authors have some explanation for this.	O	O	Reply	166
LwF is typically a reasonable baseline for these 2 task settings (e.g. <a href="https://arxiv.org/pdf/1704.01920.pdf).‚Äù" target="_blank" rel="nofollow">https://arxiv.org/pdf/1704.01920.pdf).‚Äù</a>	O	O	Reply	166
A5: LwF in the paper the reviewer referenced is evaluated under a different setting than the setting considered in our paper.	B-Reply	B-5	Reply	166
In the referenced paper, the method is assumed to know which dataset (a.k.a.	I-Reply	I-5	Reply	166
task) each test example belongs to (i.e.: the task learning setting).	I-Reply	I-5	Reply	166
As a result, it only needs to discriminate among the classes within that dataset.	I-Reply	I-5	Reply	166
In our paper, the method is not assumed to know which dataset each test example belongs to (i.e.: the task-agnostic learning setting), and so is required to discriminate among the classes across all datasets.	I-Reply	I-5	Reply	166
As shown in various prior papers (e.g.: <a href="https://arxiv.org/pdf/1810.12488.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1810.12488.pdf</a> and <a href="https://arxiv.org/pdf/1904.07734.pdf)," target="_blank" rel="nofollow">https://arxiv.org/pdf/1904.07734.pdf),</a> LwF only achieves an average accuracy in the 20% range under the evaluation setting we consider, whereas it achieves an a near-perfect accuracy in the easier evaluation setting (i.e.: the task learning setting) considered in the original LwF paper.	I-Reply	I-5	Reply	166
<sep> (continued below...)	O	O	Reply	166

This paper draws from concepts and patterns of game theory and economics to re-interpret common machine learning algorithms, and introduces a paradigm of n-player games such that there exists a simple way to study such games where each player is individually optimized by machine learning algorithms.	O	O	Review	20269
<sep> <sep> Overall, this is a very interesting and inspiring paper with its interdisciplinary touch, but at the same time doesn‚Äôt lose readability for audience with mostly machine learning background.	O	O	Review	20269
The paper is clear, concise, and well-written, and hence I do not have any overarching comments.	O	O	Review	20269
There are several suggestions and questions, though, that I‚Äôd like to propose.	O	O	Review	20269
<sep> <sep> 1.	O	O	Review	20269
Since many concepts are not from the machine learning domain, further and more detailed touch on related work are very beneficial.	B-Review	B-1	Review	20269
The current section of related work (Section 1.2) is more succinct than laying the right background information.	I-Review	I-1	Review	20269
Authors could consider giving some examples of ‚Äúmarket mechanism‚Äù, and similarly for ‚Äúdesign pattern‚Äù.	I-Review	I-1	Review	20269
This can give readers some ideas on how this present work‚Äôs use of ‚Äúexisting design pattern‚Äù is different from prior works‚Äô proposals of ‚Äúmarket mechanism‚Äù.	I-Review	I-1	Review	20269
Again for the second paragraph, although these concepts are more familiar to the audience, a short description for each mentioned concept is good to include (e.g. monotone games, etc)	I-Review	I-1	Review	20269
<sep> 2.	O	O	Review	20269
Move Lemma 1 before Definition 2?	B-Review	B-2	Review	20269
Since Lemma 1 is most related to Definition 1 and not related to Definition 2.	I-Review	I-2	Review	20269
<sep> <sep> 3.	O	O	Review	20269
For Definition 2, authors could consider adding ‚Äúthe classic definition [of Nash equilibrium]‚Äù to the list to clarify the difference.	B-Review	B-3	Review	20269
This classic Nash equilibrium definition will be referred to again in later sections.	I-Review	I-3	Review	20269
<sep> <sep> 4.	B-Review	B-4	Review	20269
In Section 2.1, consider giving a formal definition of ‚Äúpotential game‚Äù.	I-Review	I-4	Review	20269
<sep> <sep> 5.	O	O	Review	20269
In Section 2.3, it is not immediately clear after the text why stop_gradient becomes a problem.	B-Review	B-5	Review	20269
<sep> <sep> 6.	B-Review	B-6	Review	20269
In Section 3.1, could we elucidate a bit on what is ‚Äúnear zero sum‚Äù?	I-Review	I-6	Review	20269
<sep> <sep> 7.	B-Review	B-7	Review	20269
In Section 5, why the equation following the text ‚Äúfirm i‚Äôs forecast‚Äù is always positive?	I-Review	I-7	Review	20269
Since by definition, forecast is meant to represent the change of profit, which can be negative?	I-Review	I-7	Review	20269
<sep> <sep> We thank the reviewer for their time and detailed feedback.	O	O	Reply	20269
<sep> <sep> 1.	O	O	Reply	20269
More background material.	O	O	Reply	20269
<sep> The reviewer is correct, the paper covers a wide range of topics quite rapidly.	B-Reply	B-1	Reply	20269
We will provide more discussion in the related work section and also the Appendix to help orient readers.	I-Reply	I-1	Reply	20269
<sep> <sep> 2.	O	O	Reply	20269
Move Lemma 1 before Definition 2?	O	O	Reply	20269
<sep> Yes, will do.	B-Reply	B-3	Reply	20269
<sep> <sep> 3.	O	O	Reply	20269
Use ‚Äúclassic definition of Nash‚Äù.	O	O	Reply	20269
<sep> Yes	O	O	Reply	20269
<sep> 4.	O	O	Reply	20269
Define potential games.	O	O	Reply	20269
<sep> We will put this in the appendix to save space.	B-Reply	B-4	Reply	20269
<sep> <sep> 5.	O	O	Reply	20269
How can stop_grad cause problems?	O	O	Reply	20269
<sep> <sep> Stop_grad can be used to construct essentially any smooth game, see discussion in Appendix C. Stop_grad thus opens the door to a huge variety of pathological behaviors and intractable dynamics.	B-Reply	B-5	Reply	20269
We will provide a more detailed explanation in the final version.	I-Reply	I-5	Reply	20269
<sep> <sep> 6.	O	O	Reply	20269
Near zero-sum.	O	O	Reply	20269
<sep> <sep> Although GANs are adversarial, they are not always zero-sum games.	B-Reply	B-6	Reply	20269
A concrete example is discussed in sections 3.2.2 and 3.2.3 of Goodfellow‚Äôs tutorial (<a href="https://arxiv.org/abs/1701.00160)."	I-Reply	I-6	Reply	20269
target="_blank" rel="nofollow">https://arxiv.org/abs/1701.00160).</a> In short, it turns out that gradients tend to saturate in the original minmax setting, so Goodfellow introduced a ‚Äúheuristic, non-saturating game‚Äù.	I-Reply	I-6	Reply	20269
By now there is a huge number of GANs in the literature, and it is difficult to find any mathematical property that is common to all of them.	I-Reply	I-6	Reply	20269
In particular, we do not have a precise definition of ‚Äúnear zero-sum‚Äù.	I-Reply	I-6	Reply	20269
Nevertheless, GANs do share adversarial dynamics as a unifying theme.	I-Reply	I-6	Reply	20269
Appendix B of the paper contains a brief discussion of some implications of loosening the pairwise zero-sum constraint.	I-Reply	I-6	Reply	20269
I	I-Reply	I-6	Reply	20269
<sep> 7.	O	O	Reply	20269
Why are forecasts always positive?	O	O	Reply	20269
<sep> <sep> Section 5 imposes the condition that ‚Äúproduction updates‚Äù are either gradients or gradients rescaled by positive learning rates.	B-Reply	B-7	Reply	20269
Firms that update their production vectors using gradients will therefore always forecast profits to infinitesimally increase -- precisely because the updates are in the direction of steepest ascent.	I-Reply	I-7	Reply	20269
However, in reality, profits may of course go down due to the actions of other firms.	I-Reply	I-7	Reply	20269

This paper introduces smooth market games (SM-games), a class of smooth games characterized by pairwise zero sum interactions, and show SM-games possess a number of appealing properties:	O	O	Review	20269
- A fixed point is a local Nash equilibrium iff it is stable	O	O	Review	20269
- Local convergence to stable fixed points	O	O	Review	20269
- Unstable fixed points are repellent	O	O	Review	20269
- Dynamics are bounded, assuming diminishing returns-to-scale for sufficiently large vectors.	O	O	Review	20269
<sep> The need for a class of games with such properties is motivated by a discussion of the pathologies of smooth games under simultaneous gradient ascent.	O	O	Review	20269
<sep> <sep> The paper has an extensive literature review, addresses an important problem, and has informative discussions.	O	O	Review	20269
It is well written and there are nice examples to illustrate the central ideas.	O	O	Review	20269
However, I do have some criticisms:	O	O	Review	20269
<sep> 1.	O	O	Review	20269
The writing in this paper is sometimes pompous.	B-Review	B-1	Review	20269
Quoting James Scott has no added value to this work.	I-Review	I-1	Review	20269
Reference to Adam Smith‚Äôs invisible hand not only has no added value but is also confusing and detracts from the paper ‚Äî SM-games are not purporting to be real economic models.	I-Review	I-1	Review	20269
<sep> 2.	O	O	Review	20269
Throughout the paper there is a confusing mix between ideas from economics and ideas from accounting.	B-Review	B-2	Review	20269
For example, it is not correct to say that aggregate revenue is the same as GDP.	I-Review	I-2	Review	20269
Revenue is an accounting term to show how much benefit you record in a year.	I-Review	I-2	Review	20269
GDP measures the value of&nbsp;production.	I-Review	I-2	Review	20269
It would be more accurate to write that aggregate output and GDP are the same.	I-Review	I-2	Review	20269
But if SM-games are reflecting the perspective of an accountant, as is stated, why is GDP being discussed at all?	I-Review	I-2	Review	20269
Similarly, the idea of a dummy player with off the book costs is not consistent with an accounting perspective.	I-Review	I-2	Review	20269
I think that the paper would be clearest if it did not attempt to use terminology from other fields.	I-Review	I-2	Review	20269
But if it is going to do so, it should make a more substantial effort to do so consistently.	I-Review	I-2	Review	20269
We thank the reviewer for their time and feedback.	O	O	Reply	20269
We have two responses:	O	O	Reply	20269
<sep> 1.	O	O	Reply	20269
Pompous writing.	O	O	Reply	20269
<sep> <sep> We agree with R2 and will tone down the writing -- see the next point.	B-Reply	B-1	Reply	20269
<sep> <sep> On the other hand, it‚Äôs worth defending the James Scott quote.	I-Reply	I-1	Reply	20269
As we see it, overly focusing on (Nash) equilibria has been a major blocker for research on n-player games.	I-Reply	I-1	Reply	20269
We find the Scott quote inspiring because it suggests to let go of equilibria and instead search for measurements that can be pieced together to provide a synoptic view (a map) of a game.	I-Reply	I-1	Reply	20269
That is, we don‚Äôt need to find Nash equilibria to understand what is happening or predict what will happen in an interacting population.	I-Reply	I-1	Reply	20269
<sep> <sep> 2.	O	O	Reply	20269
R2 points out that we used a confusing mix of terminology.	B-Reply	B-2	Reply	20269
We agree.	I-Reply	I-2	Reply	20269
In particular, the analogy with GDP adds nothing to the paper.	I-Reply	I-2	Reply	20269
We will edit the paper to make the terminology more clear and consistent.	I-Reply	I-2	Reply	20269

The paper studies the impact of using customized number representations on accuracy, speed, and energy consumption of neural network inference.	O	O	Review	497
Several standard computer vision architectures including VGG and GoogleNet are considered for the experiments, and it is concluded that floating point representations are preferred over fixed point representations, and floating point numbers with about 14 bits are sufficient for the considered architectures resulting in a small loss in accuracy.	O	O	Review	497
<sep> <sep> The paper provides a nice overview of floating and fixed point representations and focuses on an important aspect of deep learning that is not well studied.	O	O	Review	497
There are several aspects of the paper that could be improved, but overall, I am leaned toward weak accept assuming that the authors address the issues below.	O	O	Review	497
<sep> <sep> 1- The paper is not clear that it is only focusing on neural network inference.	B-Review	B-1	Review	497
Please include the word "inference" in the title / abstract to clarify this point and mention that the findings of the paper do not necessarily apply to neural network training as training dynamics could be different.	I-Review	I-1	Review	497
<sep> <sep> 2- The paper does not discuss the possibility of adopting quantization tricks during training, which may result in the use of fewer bits at inference.	B-Review	B-2	Review	497
<sep> <sep> 3- The paper is not clear whether in computing the running time and power consumption, it includes all of the modules or only multiply-accumulate units?	B-Review	B-3	Review	497
Also, how accurate are these numbers given different possible designs and the potential difference between simulation and production?	B-Review	B-7	Review	497
Please elaborate on the details of simulation in the paper.	I-Review	I-7	Review	497
<sep> <sep> 4- The whole discussion about "efficient customized precision search" seem unimportant to me.	B-Review	B-4	Review	497
When such important hardware considerations are concerned, even spending 20x simulation time is not that important.	I-Review	I-4	Review	497
The exhaustive search process could be easily parallelized and one may rather spend more time at simulation at the cost of finding the exact best configuration rather than an approximation.	I-Review	I-4	Review	497
That said, weak configurations could be easily filtered after evaluating just a few examples.	I-Review	I-4	Review	497
<sep> <sep> 5- Nvidia's Pascal GP100 GPU supports FP16.	B-Review	B-5	Review	497
This should be discussed in the paper and relevant Nvidia papers / documents should be cited.	I-Review	I-5	Review	497
<sep> <sep> More comments:	B-Review	B-6	Review	497
<sep> - Parts of the paper discussing "efficient customized precision search" are not clear to me.	I-Review	I-6	Review	497
<sep> <sep> - As future work, the impact of number representations on batch normalization and recurrent neural networks could be studied.	I-Review	I-6	Review	497
<sep> <sep> We thank you for your valuable time and comments.	O	O	Reply	497
<sep> <sep> ===Performance and power methodology	O	O	Reply	497
We evaluate our results based on the multiply-accumulate (MAC) operations, the key building block of any hardware implementation of a DNN.	B-Reply	B-3	Reply	497
The MAC operations capture the majority of the DNN performance and power breakdown [1]. Other units will scale with the customized-precision design as well, so we expect that a full-system implementation would show benefits very similar to our results.	I-Reply	I-3	Reply	497
For example, using 84% [1] as the power used by compute, we find our reported 3.4x savings in energy would become 3.15x (time = 0.84/3.4 + 0.16/(32-bit/14-bit from linear scaling) = 0.31 => speedup = 1/0.31 = 3.15x).	I-Reply	I-3	Reply	497
Similarly, full-system performance is dictated by MAC performance.	I-Reply	I-3	Reply	497
<sep> <sep> ===ASIC design tool details	O	O	Reply	497
Our comparisons are made using designs synthesized with Synopsys Design Compiler and are further verified using Synopsys PrimeTime and SPICE simulations.	B-Reply	B-7	Reply	497
The specific cell library, provided by the manufacturer, which produces area, power, and timing information, cannot be disclosed.	I-Reply	I-7	Reply	497
These cell libraries are used for timing verification for chip tape out, hence, they must (and do) accurately model real hardware.	I-Reply	I-7	Reply	497
<sep> <sep> ===Importance of search	O	O	Reply	497
Our search method‚Äôs 170x speedup mitigates the time-intensive process of emulating customized precision operations, allowing researchers to iteratively adjust DNN topology for optimized hardware efficiency.	B-Reply	B-4	Reply	497
<sep> <sep> ===Suggestions for future work and clarifications	O	O	Reply	497
Thank you for the suggestions.	B-Reply	B-6	Reply	497
We will integrate this feedback into future versions of our work.	I-Reply	I-6	Reply	497
<sep> <sep> [1] ShiDianNao: Shifting Vision Processing Closer to the Sensor.	O	O	Reply	497
ISCA 2015.	O	O	Reply	497
Zidong Du, et al	O	O	Reply	497

This paper explores the performance-area-energy-model accuracy tradeoff encountered in designing custom number representations for deep learning inference.	O	O	Review	497
Common image-based benchmarks: VGG, Googlenet etc are used to demonstrate that fewer than1 6 bits in a custom floating point representation can lead to improvement in runtime performance and energy efficiency with only a small loss in model accuracy.	O	O	Review	497
<sep> <sep> Questions:	O	O	Review	497
<sep> 1.	O	O	Review	497
Does the custom floating point number representation take into account support for de-normal numbers?	B-Review	B-1	Review	497
<sep> 2.	B-Review	B-2	Review	497
Is the custom floating point unit clocked at the same frequency as the baseline 32-bit floating point unit?	I-Review	I-2	Review	497
If not, what are the different frequencies used and how would this impact the overall system design in terms of feeding the data to the floating point units from the memory	I-Review	I-2	Review	497
<sep> Comments:	O	O	Review	497
<sep> 1.	O	O	Review	497
I would recommend using the IEEE half-precision floating point (1bit sign, 5bit exponent, and 10bit mantissa) as a baseline for comparison.	B-Review	B-4	Review	497
At this point, it is well known in both the ML and the HW communities that 32-bit floats are an overkill for DNN inference and major HW vendors already include support for IEEE half-precision floats.	I-Review	I-4	Review	497
<sep> 2.	O	O	Review	497
In my opinion, the claim that switching to custom floating point  lead to a YY.ZZ x savings in energy is misleading.	B-Review	B-5	Review	497
It might be true that the floating-point unit itself might consume less energy due to smaller bit-width of the operands, however a large fraction of the total energy is spent in data movement to/from the memories.	I-Review	I-5	Review	497
As a result, reducing the floating point unit‚Äôs energy consumption by a certain factor will not translate to the same reduction in the total energy.	I-Review	I-5	Review	497
A reader not familiar with such nuances (for example a typical member of the ML community), may be mislead by such claims.	I-Review	I-5	Review	497
<sep> 3.	O	O	Review	497
On a similar note as comment 2, the authors should explicitly mention that the claimed speedup is that of the floating point unit only, and it will not translate to the overall workload speedup.	B-Review	B-7	Review	497
Although the speedup of the compute unit is roughly quadratic in the bit-width, the bandwidth requirements scale linearly with bit-width.	I-Review	I-7	Review	497
As a result, it is possible that these custom floating point units may be starved on memory bandwidth, in which case the claims of speedup and energy savings need to be revisited.	I-Review	I-7	Review	497
<sep> 4.	O	O	Review	497
The authors should also comment on the complexities and overheads introduced in data accesses, designing the various system buses/ data paths when the number representation is not byte-aligned.	B-Review	B-6	Review	497
Moving to a custom 14-bit number representation (for example) can improve the performance and energy-efficiency of the floating point unit, but these gains can be partially eroded due to the additional overhead in supporting non-byte aligned memory accesses.	I-Review	I-6	Review	497
<sep> <sep> We thank you for your valuable time and comments.	O	O	Reply	497
<sep> <sep> ===Denormal floating-point units	O	O	Reply	497
Our evaluated floating-point ALUs do not operate on denormal floating-point representations.	B-Reply	B-1	Reply	497
Aside from minor differences in empirical results that depend on denormal floating-point arithmetic support, we expect that our conclusions hold.	I-Reply	I-1	Reply	497
A different design that operates on denormal floating-point representations will, ideally, allow one less bit in the floating-point exponent for the same accuracy, but will be disadvantaged by increased hardware area, circuit delay, and power.	I-Reply	I-1	Reply	497
<sep> <sep> ===Frequency scaling of customized-precision units	O	O	Reply	497
We scale the ALU frequency with the inverse of the hardware circuit delay, so each customized-precision design can have a different frequency.	B-Reply	B-2	Reply	497
<sep> <sep> ===Frequency of compute compared to storage	O	O	Reply	497
Our DRAM memory and compute clocks (frequencies) are different, which is common across almost all hardware designs (e.g., modern CPU/GPU designs).	B-Reply	B-5	Reply	497
DRAM memory fabrication is primarily optimized for higher transistor density (i.e. memory capacity) rather than higher frequency, which is opposite of computational units.	I-Reply	I-5	Reply	497
<sep> <sep> ===Validity of MAC results	O	O	Reply	497
The MAC operations capture the majority of the DNN performance and power breakdown [1]. Other units will scale with the customized-precision design as well, so we expect that a full-system implementation would show benefits very similar to our results.	B-Reply	B-4	Reply	497
For example, using 84% [1] as the power used by compute, we find our reported 3.4x savings in energy would become 3.15x (time = 0.84/3.4 + 0.16/(32-bit/14-bit from linear scaling) = 0.31 => speedup = 1/0.31 = 3.15x).	I-Reply	I-4	Reply	497
<sep> <sep> ===Compute throughput as DNN bottleneck	O	O	Reply	497
The DRAM memory bandwidth requirements for DNNs is much lower than its computational requirements [2]. This is due to matrix multiplication, the central DNN computational kernel, requiring roughly N^2 memory operations (i.e. from loop tiling [3]) compared to N^3 arithmetic operations.	B-Reply	B-7	Reply	497
<sep> <sep> ===Customized-precision memory access	O	O	Reply	497
DRAM memory access can be left unchanged when using customized-precision compute units.	B-Reply	B-6	Reply	497
Similar to how GPUs do 32-bit computation efficiently when using a 128- to 512-bit memory bus, a single memory access is distributed to multiple compute units.	I-Reply	I-6	Reply	497
For example, a 128-bit bus provides data to nine 14-bit compute units.	I-Reply	I-6	Reply	497
<sep> <sep> [1] ShiDianNao: Shifting Vision Processing Closer to the Sensor.	O	O	Reply	497
ISCA 2015.	O	O	Reply	497
Zidong Du, et al	O	O	Reply	497
[2] DjiNN and Tonic: DNN as a Service and Its Implications for Future Warehouse Scale Computers.	O	O	Reply	497
ISCA 2015.	O	O	Reply	497
Hauswald, et al	O	O	Reply	497
[3] Optimizing FPGA-based Accelerator Design for Deep Convolutional Neural Networks.	O	O	Reply	497
FPGA 2015.	O	O	Reply	497

The paper provides a first study of customized precision hardware for large convolutional networks, namely alexnet, vgg and googlenet.	O	O	Review	497
It shows that it is possible to achieve larger speed-ups using floating-point precision (up to 7x) when using fewer bits, and better than using fixed-point representations.	O	O	Review	497
<sep> <sep> The paper also explores predicting custom floating-point precision parameters directly from the neural network activations, avoiding exhaustive search, but i could not follow this part.	B-Review	B-1	Review	497
Only the activations of the last layer are evaluated, but on what data ?	I-Review	I-1	Review	497
On all the validation set ?	I-Review	I-1	Review	497
Why would this be faster than computing the classification accuracy ?	I-Review	I-1	Review	497
<sep> <sep> The results should be useful for hardware manufacturers, but with a catch.	B-Review	B-2	Review	497
All popular convolutional networks now use batch normalization, while none of the evaluated ones do.	I-Review	I-2	Review	497
It may well be that the conclusions of this study will be completely different on batch normalization networks, and fixed-point representations are best there, but that remains to be seen.	I-Review	I-2	Review	497
It seems like something worth exploring.	I-Review	I-2	Review	497
<sep> <sep> Overall there is not a great deal of novelty other than being a useful study on numerical precision trade-offs at neural network test time.	B-Review	B-3	Review	497
Training time is also something of interest.	I-Review	I-3	Review	497
There are a lot more researchers trying to train new networks fast than trying to evaluate old ones fast.	I-Review	I-3	Review	497
<sep> <sep> I am also no expert in digital logic design, but my educated guess is that this paper is marginally below the acceptance threshold.	O	O	Review	497
We thank you for your valuable time and comments.	O	O	Reply	497
<sep> <sep> ===Search method clarifications	O	O	Reply	497
Our search model only requires a small subset (evaluation uses 10) of the validation inputs to predict accuracy by leveraging all of the activations in the last layer, rather than observing only the top-1 (or top-5) results.	B-Reply	B-1	Reply	497
Last layer activations require fewer inputs compared to top-1 accuracy, since each DNN input produces many scalar activations rather than a single binary correctness value.	I-Reply	I-1	Reply	497
For example, 10 inputs using top-1 accuracy provides 10 binary values (i.e. each DNN output being either correct or incorrect), while the activations for 10 ImageNet inputs provides 10,000 scalar values (i.e. 10 DNN inputs * 1000 scalar output activations per ImageNet input).	I-Reply	I-1	Reply	497
<sep> <sep> ===Batch normalization	O	O	Reply	497
Batch normalization primarily impacts the training process of DNNs rather than inference, so we expect to arrive at very similar conclusions with or without it.	B-Reply	B-2	Reply	497
Batch normalization during inference applies a fixed linear transformation to each activation, which requires few hardware resources and does not change the shape of the activation distribution.	I-Reply	I-2	Reply	497
<sep> <sep> ===Importance of inference performance	O	O	Reply	497
Reducing the computational requirements of DNN inference is relevant to the machine learning community.	B-Reply	B-3	Reply	497
A number of papers on this topic have been published at venues such as ICLR, ICML, and NIPS[1,2,3,4].	I-Reply	I-3	Reply	497
<sep> [1] Compressing Neural Networks with the Hashing Trick.	O	O	Reply	497
ICML 2015.	O	O	Reply	497
Chen, at al.	O	O	Reply	497
<sep> [2] Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation.	O	O	Reply	497
NIPS 2014.	O	O	Reply	497
Denton, et al	O	O	Reply	497
[3] Learning both Weights and Connections for Efficient Neural Networks.	O	O	Reply	497
NIPS 2015.	O	O	Reply	497
Han, et al	O	O	Reply	497
[4] Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding.	O	O	Reply	497
ICLR 2016.	O	O	Reply	497
Han, et al	O	O	Reply	497

This paper provides an overview of the Deep Voice 3 text-to-speech system.	O	O	Review	497
It describes the system in a fair amount of detail and discusses some trade-offs w.r.t.audio quality and computational constraints.	O	O	Review	497
Some experimental validation of certain architectural choices is also provided.	O	O	Review	497
<sep> <sep> My main concern with this work is that it reads more like a tech report: it describes the workings and design choices behind one particular system in great detail, but often these choices are simply stated as fact and not really motivated, or compared to alternatives.	B-Review	B-1	Review	497
This makes it difficult to tell which of these aspects are crucial to get good performance, and which are just arbitrary choices that happen to work okay.	I-Review	I-1	Review	497
<sep> <sep> As this system was clearly developed with actual deployment in mind (and not purely as an academic pursuit), all of these choices must have been well-deliberated.	B-Review	B-2	Review	497
It is unfortunate that the paper doesn't demonstrate this.	I-Review	I-2	Review	497
I think this makes the work less interesting overall to an ICLR audience.	I-Review	I-2	Review	497
That said, it is perhaps useful to get some insight into what types of models are actually used in practice.	I-Review	I-2	Review	497
<sep> <sep> An exception to this is the comparison of "converters", model components that convert the model's internal representation of speech into waveforms.	B-Review	B-3	Review	497
This comparison is particularly interesting because some of the results are remarkable, i.e. Griffin-Lim spectrogram inversion and the WORLD vocoder achieving very similar MOS scores in some cases (Table 2).	I-Review	I-3	Review	497
I wish there would be more of that kind of thing in the paper.	I-Review	I-3	Review	497
The comparison of attention mechanisms is also useful.	I-Review	I-3	Review	497
<sep> <sep> I'm on the fence as I think it is nice to get some insight into a practical pipeline which benefits from many current trends in deep learning research (autoregressive models, monotonic attention, ...), but I also feel that the paper is a bit meager when it comes to motivating all the architectural aspects.	B-Review	B-12	Review	497
I think the paper is well written so I've tentatively recommended acceptance.	I-Review	I-12	Review	497
<sep> <sep> <sep> Other comments:	O	O	Review	497
<sep> - The separation of the "decoder" and "converter" stage is not entirely clear to me.	B-Review	B-4	Review	497
It seems that the decoder is trained to predict spectrograms autoregressively, but its final layer is then discarded and its hidden representation is then used as input to the converter stage instead?	I-Review	I-4	Review	497
The motivation for doing this is unclear to me, surely it would be better to train everything end-to-end, including the converter?	I-Review	I-4	Review	497
This seems like an unnecessary detour, what's the reasoning behind this?	I-Review	I-4	Review	497
<sep> <sep> - At the bottom of page 2 it is said that "the whole model is trained end-to-end, excluding the vocoder", which I think is an unfortunate turn of phrase.	B-Review	B-5	Review	497
It's either end-to-end, or it isn't.	I-Review	I-5	Review	497
<sep> <sep> - In Section 3.3, the point of mixing of h_k and h_e is unclear to me.	B-Review	B-6	Review	497
Why is this done?	I-Review	I-6	Review	497
<sep> <sep> - The gated linear unit in Figure 2a shows that speaker embedding information is only injected in the linear part.	B-Review	B-7	Review	497
Has this been experimentally validated to work better than simpler mechanisms such as adding conditioning-dependent biases/gains?	I-Review	I-7	Review	497
<sep> <sep> - When the decoder is trained to do autoregressive prediction of spectrograms, is it autoregressive only in time, or also in frequency?	B-Review	B-8	Review	497
I'm guessing it's the former, but this means there is an implicit independence assumption (the intensities in different frequency bins are conditionally independent, given all past timesteps).	I-Review	I-8	Review	497
Has this been taken into consideration?	I-Review	I-8	Review	497
Maybe it doesn't matter because the decoder is never used directly anyway, and this is only a "feature learning" stage of sorts?	I-Review	I-8	Review	497
<sep> <sep> - Why use the L1 loss on spectrograms?	B-Review	B-9	Review	497
<sep> <sep> - The recent work on Parallel WaveNet may allow for speeding up WaveNet when used as a vocoder, this could be worth looking into seeing as inference speed is used as an argument to choose different vocoder strategies (with poorer audio quality as a result).	B-Review	B-10	Review	497
<sep> <sep> - The title heavily emphasizes that this model can do multi-speaker TTS with many (2000) speakers, but that seems to be only a minor aspect that is only discussed briefly in the paper.	B-Review	B-11	Review	497
And it is also something that preceding systems were already capable of (although maybe it hasn't been tested with a dataset of this size before).	I-Review	I-11	Review	497
It might make sense to rethink the title to emphasize some of the more relevant and novel aspects of this work.	I-Review	I-11	Review	497
<sep> <sep> <sep> ----	O	O	Review	497
<sep> Revision: the authors have adequately addressed quite a few instances where I feel motivations / explanations were lacking, so I'm happy to increase my rating from 6 to 7.	O	O	Review	497
I think the proposed title change would also be a good idea.	O	O	Review	497
To incorporate your and other reviewers' suggestions, we have expanded discussions on the motivations behind the design choices in this paper.	B-Reply	B-1	Reply	497
For example:&nbsp;	I-Reply	I-1	Reply	497
1) We have added a new section ("Convolution Blocks for Sequential Processing") to motivate the architecture design choices for the convolution blocks used in our model.&nbsp;	I-Reply	I-1	Reply	497
2) In the "Encoder" section, we have added the motivation behind mixing key vector h_k and embedding h_e.&nbsp;&nbsp;	I-Reply	I-1	Reply	497
3) In the "Decoder" section, we have expanded the explanation of query generation for attention and explain the motivation to use L1 loss.	I-Reply	I-1	Reply	497
<sep> 4) In the "Attention Block" section, we have added more explanations for our attention mechanism choices, attention's role in the overall architecture, the choice of positional encodings, and techniques to minimize attention errors.	I-Reply	I-1	Reply	497
<sep> 5) In the "Converters" section, we have added clarification and justification for the relationship between the decoder hidden state and the converter/vocoder.	I-Reply	I-1	Reply	497
<sep> <sep> We note that due to the required additions, our page limit has exceeded the suggested.	O	O	Reply	497
<sep> <sep> Other comments:	O	O	Reply	497
<sep> - "The separation of the "decoder" and "converter" stage is not entirely clear to me ..."	O	O	Reply	497
* For a complex deep learning model like a TTS system, it can be challenging to train end-to-end in practice - instead, auxiliary/intermediate losses and multi-task learning may be preferred to guide the training of whole system.	B-Reply	B-4	Reply	497
In decoder architecture, the loss for mel-scale spectrogram generation guides training of the attention mechanism, because the parameters are trained with the gradients from&nbsp;mel-scale spectrogram generation besides vocoder parameter generation.	I-Reply	I-4	Reply	497
Our experiments suggest that a mel-scale spectrogram is a compact audio representation with sufficient information content to train a robust attention mechanism.	I-Reply	I-4	Reply	497
Using mel-scale spectrograms yields fewer attention mistakes, compared to other high-dimensional audio representations (e.g., linear spectrogram, or other vocoder parameters).&nbsp;We observe that inputting the last hidden states of the decoder rather than mel-scale spectrograms to the converter network yields slightly higher audio quality.	I-Reply	I-4	Reply	497
We attribute this to the richer information content of the hidden states, as a&nbsp;mel-scale spectrogram is a fixed representation.	I-Reply	I-4	Reply	497
Since WaveNet is conducive to producing high quality audio directly from mel-scale spectrograms, for WaveNet vocoder, we use mel-scale spectrograms as the external conditioners to the WaveNet architecture.	I-Reply	I-4	Reply	497
<sep> <sep> - "At the bottom of page 2 it is said that "the whole model is trained end-to-end, excluding the vocoder" ... "	O	O	Reply	497
* We have removed this phrase.	B-Reply	B-5	Reply	497
<sep> <sep> - "In Section 3.3, the point of mixing of h_k and h_e is unclear to me.	O	O	Reply	497
Why is this done?"	O	O	Reply	497
<sep> * We have added an explanation for this design choice:&nbsp;"The attention value vectors are computed from attention key vectors and text embeddings,, as in&nbsp; (Gehring et al 2017), to jointly consider the local information in and the learned long-term context information in."	B-Reply	B-6	Reply	497
<sep> <sep> &nbsp;- "The gated linear unit in Figure 2a shows that speaker embedding information is only injected in the linear part.	O	O	Reply	497
Has this been validated to work experimentally&nbsp;better ... "	O	O	Reply	497
* We have compared various alternatives to make convolution blocks speaker-dependent, including adding speaker-dependent biases and/or gains.	B-Reply	B-7	Reply	497
The particular choice in the paper has yielded the best results empirically.&nbsp;&nbsp;	I-Reply	I-7	Reply	497
<sep> - "When the decoder is trained to do autoregressive prediction of spectrograms, is it autoregressive only in time, or also in frequency? ... "	O	O	Reply	497
<sep> * The prediction of spectrogram is autoregressive only in time,&nbsp;so there is an implicit conditional independence assumption across frequency bins given all past timesteps.&nbsp;This design choice is important to achieve faster inference, and it yields good enough result&nbsp;as we demonstrated.&nbsp;&nbsp;As you mentioned, converter network plays a more important role in determining the audio quality, and it is non-causal (and hence is not autoregressive).	B-Reply	B-8	Reply	497
<sep> <sep> - ‚ÄúWhy use the L1 loss on spectrograms?‚Äù	O	O	Reply	497
*&nbsp;Prediction of spectrograms is treated as a regression problem.	B-Reply	B-9	Reply	497
We choose L1 loss since it yields the best result empirically.	I-Reply	I-9	Reply	497
Other common regression loss functions such as L2 loss may suffer from outlier spectral features (which may correspond to non-speech noise).	I-Reply	I-9	Reply	497
We have clarified this point in Section 3.5.&nbsp;	I-Reply	I-9	Reply	497
<sep> - "The recent work on Parallel WaveNet .... "	O	O	Reply	497
* Thanks for pointing it out.&nbsp;Parallel WaveNet can be integrated as a vocoder, which may yield better audio quality while still achieving fast inference.	B-Reply	B-10	Reply	497
We think it is an important future direction and leave it to future work.&nbsp;	I-Reply	I-10	Reply	497
<sep> - "... It might make sense to rethink the title to emphasize some of the more relevant and novel aspects of this work."	O	O	Reply	497
<sep> * Thanks for your suggestion.&nbsp;We are considering to change the title to "Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning".	B-Reply	B-11	Reply	497

The paper presents a speech synthesis system based on convolution neural networks.	O	O	Review	497
The proposed approach is an end-to-end characters to spectrogram system, trained on a very large dataset.	O	O	Review	497
The paper also introduces a attention model and can be used with various waveform synthesis methods.	O	O	Review	497
The proposed model is shown to match the state -of-the-art approaches performance in speech naturalness.	O	O	Review	497
The paper is clearly written and easy to follow.	O	O	Review	497
The relation to previous works is detailed and clear.	O	O	Review	497
The contributions of the paper are significants and an important step towards practical and efficient neural TTS system.	O	O	Review	497
The ability to train on a large corpus of speaker 10 times faster than current models is impressive and important for deployment, as is the cost-effective inference and the monotonic attention model.	O	O	Review	497
The experiments on naturalness (Table 2) are convincing and show the viability of the approach.	O	O	Review	497
However, the experiments on multi-speaker synthesis (Table 3) are not very strong.	O	O	Review	497
The proposed model seems to need to use Wavenet as a vocoder to possibly outperform Deep Voice 2, which will slow down the inference time, one of the strong aspect of the proposed model.	O	O	Review	497
Other comments:	O	O	Review	497
* In Section 2, it is mentioned that RNN-based approaches can leads to attention errors, can the authors elaborate more on that aspect ?	O	O	Review	497
It seems important as the proposed approach alleviates these issues, but it is not clear from the paper what these errors are and why they happen.	O	O	Review	497
* In Table 3 there seems to be missing models compared to Table 2, like Tacotron with Wavenet, the authors should explain why in the text.	O	O	Review	497
* The footnote 2 on page 3 looks important enough to be part of the main text.	O	O	Review	497
- "The experiments on naturalness (Table 2) are convincing and show the viability of the approach.	O	O	Reply	497
However, the experiments on multi-speaker synthesis (Table 3) are not very strong ..."	O	O	Reply	497
* Since our submission, we have worked on optimizing the hyperparamet	O	O	Reply	497

This paper discusses a text-to-speech system which is based on a convolutional attentive seq2seq architecture.	O	O	Review	497
It covers experiments on a few datasets, testing the model's ability to handle increasing numbers of speakers.	O	O	Review	497
<sep> <sep> By and large, this is a "system" paper - it mostly describes the successful application of many different existing ideas to an important problem (with some exceptions, e.g. the novel method of enforcing monotonic alignments during inference).	O	O	Review	497
In this type of paper, I typically am most interested in hearing about *why* a particular design choice was made, what alternatives were tried, and how different ideas worked.	O	O	Review	497
This paper is lacking in this regard - I frequently was left looking for more insight into the particular system that was designed.	O	O	Review	497
Beyond that, I think more detailed description of the system would be necessary in order to reimplement it suitably (another important potential takeaway for a "system" paper).	B-Review	B-1	Review	497
Separately, I the thousands-of-speakers results are just not that impressive - a MOS of 2 is not really useable in the real-world.	I-Review	I-1	Review	497
For that reason, I think it's a bit disingenuous to sell this system as "2000-Speaker Neural Text-to-Speech".	I-Review	I-1	Review	497
<sep> <sep> For the above reasons, I'm giving the paper a "marginally above" rating.	O	O	Review	497
If the authors provide improved insight, discussion of system specifics, and experiments, I'd be open to raising my review.	O	O	Review	497
Below, I give some specific questions and suggestions that could be addressed in future drafts.	O	O	Review	497
<sep> <sep> - It might be worth giving a sentence or two defining the TTS problem - the paper is written assuming background knowledge about the problem setting, including different possible input sources, what a vocoder is, etc.	B-Review	B-2	Review	497
The ICLR community at large may not have this domain-specific knowledge.	I-Review	I-2	Review	497
<sep> - Why "softsign" and not tanh?	B-Review	B-3	Review	497
Seems like an unusual choice.	I-Review	I-3	Review	497
<sep> - What do the "c" and "2c" in Figure 2a denote?	B-Review	B-4	Review	497
<sep> - Why scale (h_k + h_e) by \sqrt{0.5} when computing the attention value vectors?	B-Review	B-5	Review	497
<sep> - "An L1 loss is computed using the output spectrograms" I assume you mean the predicted and target spectrograms are compared via an L1 loss.	B-Review	B-6	Review	497
Why L1?	I-Review	I-6	Review	497
<sep> - In Vaswani et al it was shown that a learned positional encoding worked about as well as the sinusoidal position encodings despite being potentially more flexible/less "hand-designed" for machine translation.	B-Review	B-7	Review	497
Did you also try this for TTS?	I-Review	I-7	Review	497
Any insight?	I-Review	I-7	Review	497
<sep> - Some questions about monotonic attention: Did you use the training-time "soft" monotonic attention algorithm from Raffel et al during training and inference, or did you use the "hard" monotonic attention at inference time?	B-Review	B-8	Review	497
IIUC the "soft" algorithm doesn't actually force strict monotonicity.	I-Review	I-8	Review	497
You wrote "monotonic attention results in the model frequently mumbling words", can you provide evidence/examples of this?	I-Review	I-8	Review	497
Why do you think this happens?	I-Review	I-8	Review	497
The monotonic attention approach seems more principled than post-hoc limiting softmax attention to be monotonic, why do you think it didn't work as well?	I-Review	I-8	Review	497
<sep> - I can't find an actual reference to what you mean by a "wavenet vocoder".	B-Review	B-9	Review	497
The original wavenet paper describes an autoregressive model for waveform generation.	I-Review	I-9	Review	497
In order to use it as a vocoder, you'd have to do conditioning in some way.	I-Review	I-9	Review	497
How?	I-Review	I-9	Review	497
What was the structure of the wavenet you used?	I-Review	I-9	Review	497
Why?	I-Review	I-9	Review	497
These details appear to be missing.	I-Review	I-9	Review	497
All you write is the sentence (which seems to end without a period) "In the WaveNet vocoder, we use mel-scale spectrograms from the decoder to condition a Wavenet, which was trained separated".	I-Review	I-9	Review	497
<sep> - Can you provide examples of the mispronunciations etc.	B-Review	B-10	Review	497
which were measured for Table 1?	I-Review	I-10	Review	497
Was the evaluation of each attention mechanism done blindly?	I-Review	I-10	Review	497
<sep> - The 2.07 MOS figure produced for tacotron seems extremely low, and seems to indicate that something went wrong or that insufficient care was taken to report this baseline.	B-Review	B-11	Review	497
How did you adapt tacotron (which as I understand is a single-speaker model) to the multi-speaker setting?	I-Review	I-11	Review	497
<sep> - Table 3 begs the question of whether Deep Voice 3 can outperform Deep Voice 2 when using a wavenet vocoder on VCTK (or improve upon the poor 2.09 MOS score reported).	B-Review	B-12	Review	497
Why wasn't this experiment run?	I-Review	I-12	Review	497
<sep> - The paragraph and appendix about deploying at scale is interesting and impressive, but seems a bit out of place - it probably makes more sense to include this information in a separate "systems" paper.	B-Review	B-13	Review	497
As another reviewer also raised a similar concern, we have paid significant attention to improve the explanations to motivate the model architecture choices in this paper.&nbsp;&nbsp;For example:&nbsp;	B-Reply	B-14	Reply	497
1) We have added a new section ("Convolution Blocks for Sequential Processing") to motivate the architecture design choices for the convolution blocks used in our model.&nbsp;	I-Reply	I-14	Reply	497
2) In the "Encoder" section, we have added the motivation behind mixing key vector h_k and embedding h_e. (	I-Reply	I-14	Reply	497
This is in regards to your question about mixing h_k and h_e.)	I-Reply	I-14	Reply	497
<sep> 3) In the "Decoder" section, we have expanded the explanation of query generation for attention and explain the motivation to use L1 loss.	I-Reply	I-14	Reply	497
<sep> 4) In the "Attention Block" section, we have added more explanations for our attention mechanism choices, attention's role in the overall architecture, the choice of positional encodings, and techniques to minimize attention errors.	I-Reply	I-14	Reply	497
<sep> 5) In the "Converters" section, we have added clarification and justification for the relationship between the decoder hidden state and the converter/vocoder.	I-Reply	I-14	Reply	497
<sep> <sep> &nbsp;We note that due to the required additions by the Reviewers, our page limit has exceeded the suggested.	O	O	Reply	497
<sep> <sep> &nbsp;- "Separately, the thousands-of-speakers results are just not that impressive - a MOS of 2 is not really useable in the real-world ... "	O	O	Reply	497
* Since this submission, we have worked on optimizing the hyperparameters further.	B-Reply	B-1	Reply	497
We were able to improve MOS from 2.09 to 2.37 by increasing the dimensionality of the speaker embedding and to 2.89 with the WORLD vocoder.&nbsp;We have updated our draft to reflect the improvement.	I-Reply	I-1	Reply	497
In addition, it should be noted that LibriSpeech is a dataset for automatic speech recognition (ASR), which is recorded in various environments and often contains noticeable background noise.	I-Reply	I-1	Reply	497
This characteristic is helpful for the robustness of an ASR system, but is harmful for a TTS system.	I-Reply	I-1	Reply	497
In the literature, Yamagishi et al (2010) built TTS systems using several ASR corporas with much fewer speakers, and the highest MOS 2.8 is on WSJ dataset which is "cleaner" than Librispeech.	I-Reply	I-1	Reply	497
We expect a higher MOS score with a "TTS-quality" dataset that is at the scale of LibriSpeech, but it is very expensive to collect.	I-Reply	I-1	Reply	497
Also, we are considering to change the title to "Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning" in the final version.	I-Reply	I-1	Reply	497
<sep> <sep> -&nbsp;‚ÄúIt might be worth giving a sentence or two defining the TTS problem ...&nbsp;‚Äù	O	O	Reply	497
* We have modified the first paragraph to introduce definitions.	B-Reply	B-2	Reply	497
<sep> <sep> &nbsp;- "Why "softsign" and not tanh? "	O	O	Reply	497
<sep> * Softsign is preferred over tanh, because it has does not saturate as easily as nonlinearities based on exponential function and still yields sufficiently large gradients for large inputs.	B-Reply	B-3	Reply	497
We have added a description in Section 3.3.	I-Reply	I-3	Reply	497
<sep> <sep> - "What do the "c" and "2c" in Figure 2a denote?"	O	O	Reply	497
<sep> * "c" denotes the dimensionality of the input.&nbsp;We have added this clarification to the caption of Fig.2a.	B-Reply	B-4	Reply	497
<sep> <sep> - "Why scale (h_k + h_e) by \sqrt{0.5} when computing the attention value vectors?"	O	O	Reply	497
<sep> * The scaling factor \sqrt{0.5} ensures that we preserve the unit variance early in training.	B-Reply	B-5	Reply	497
It is explained in footnote 4.&nbsp;	I-Reply	I-5	Reply	497
<sep> - "An L1 loss is computed using the output spectrograms ... Why L1?"	O	O	Reply	497
<sep> * Prediction of spectrograms is treated as a regression problem.	B-Reply	B-6	Reply	497
We choose L1 loss since it yielded the best results empirically.	I-Reply	I-6	Reply	497
Other common regression loss functions such as L2 loss may suffer from outlier spectral features (which may correspond to non-speech noise).&nbsp;We have clarified this point in Section 3.5.&nbsp;	I-Reply	I-6	Reply	497
<sep> - "In Vaswani et al it was shown that a learned positional encoding ...&nbsp;"	O	O	Reply	497
* We didn't try the learned positional encoding in our system.	B-Reply	B-7	Reply	497
The benefit of adding the positional encoding is significant only at the beginning of training and we do not expect superior audio quality by simply using different positional encodings.	I-Reply	I-7	Reply	497
We have added these additional details in the paper.	I-Reply	I-7	Reply	497

In this paper, authors propose a set of  control experiments in order to get a better understanding of different deep learning heuristics: stochastic gradient with restart (SGDR),  warmup and distillation.	O	O	Review	497
Authors leverage the recently proposed mode connectivity (which fits a simple piecewise linear curve to obtain a low loss path that connect two points in parameter space) and CCA is a way to compute a meaningful correlation of the networks activations.	O	O	Review	497
All the experiments are done using a VGG-16 networks on CIFAR10.	O	O	Review	497
<sep> <sep> For SGDR, authors observe that the solutions found by SGDR or SGD does not appears to be in different basins.	O	O	Review	497
While this contradict previous claim, it goes in the same direction than recent works which  have similar observations for the small batch/large batch case [1]. Authors also identify that warmup tends to avoid large change the top-layers at the beginning of training and that you can achieve similar effect than warmup by freezing the top-layer.	O	O	Review	497
Finally authors show that most of the benefit of distillation happen by impacting the last deep layers of a network.	O	O	Review	497
<sep> While I find all those findings valuable, it is not straightforward to see how they connect to a better understanding of training deep network and how significant they are.	B-Review	B-1	Review	497
In particular,  it is still unclear to me why heuristics such as SGDR is successful in practice or why freezing the top layer of a network improve trainability in a large batch setting?	I-Review	I-1	Review	497
<sep> <sep> Doing control experiments in order to better understand the current practice in deep learning is extremely important, however, I don‚Äôt think that the paper in its current shape is ready for publication.	B-Review	B-2	Review	497
<sep> <sep> [1] Empirical Analysis of the Hessian of Over-Parametrized Neural Networks (Sagun et al 2017).	O	O	Review	497
<sep> <sep> <sep> <sep> Thank you for your review and helpful comments.	O	O	Reply	497
<sep> <sep> Our observations are indeed suggestive of the connected components at the bottom of the landscape as referred to in Sagun et al Thank you for pointing us to that work.	O	O	Reply	497
<sep> <sep> Regarding significance:	O	O	Reply	497
The primary goal of our work was to investigate heuristics carefully, and specifically to understand whether hypotheses aimed at explaining them are founded empirically, and also to reveal new insights about how they work.	B-Reply	B-1	Reply	497
We hope that this is a valuable takeaway for readers in itself to help motivate new techniques and also help answer fundamental questions about loss landscapes and their interaction with training algorithms.	I-Reply	I-1	Reply	497
While it is true that our work is not conclusive in explaining why and how the heuristics work, we believe that the results are significant at clearing misconceptions and shedding light on a difficult problem, and in turn, raising more interesting questions, such as the ones you mentioned.	I-Reply	I-1	Reply	497

Summary:	O	O	Review	497
This paper uses the recently proposed techniques of mode connectivity and CCA to analyze two different popular heuristics in deep learning:	O	O	Review	497
(1) SGDR (stochastic gradient descent with restarts/cosine annealing of learning rate)	O	O	Review	497
(2) Learning rate warmup	O	O	Review	497
(3) Model distillation	O	O	Review	497
<sep> For (1) they visualize 1d and 2d slices of the loss surface either using mode connectivity, or parameter points immediately before restarts to try and understand if the parameters sit in different local minima.	O	O	Review	497
For (2), they study the effect of learning rate warmup using CCA, coming to the conclusion that learning rate warmup helps stabilize the fully connected layers. (	O	O	Review	497
3) They also study model distillation with CCA, finding out that the higher layers are the most similar to the teacher model.	O	O	Review	497
<sep> <sep> Clarity: The paper is clearly written, cites lots of relevant work, and describes the experiments in detail.	O	O	Review	497
<sep> <sep> Originality: This paper seems original, while the techniques used are established, they conduct thorough experiments on phenomena in deep learning that haven't been studied.	O	O	Review	497
<sep> <sep> Comments on Significance and Quality:	O	O	Review	497
I liked parts (2), (3) of the paper most, as it seemed like conclusions from these parts were fairly clear:	O	O	Review	497
<sep> Figures 4, 5 make the effect of warm restarts in the large batch setting on FC layers clear: the restarts help the layers stabilize better.	O	O	Review	497
I really liked the experiment in 4(d), where they tested this hypothesis by freezing the fully connected layers for the duration of the warmup.	O	O	Review	497
It was interesting to see that this had no effect on the remainder of the trajectory.	O	O	Review	497
This seemed to be a good demonstration and investigation of the effect of warm restarts, and I appreciate the tests on different architectures in the supplementary material.	O	O	Review	497
I'd be curious to see if there's some way to further incorporate this into learning rate schedules.	B-Review	B-4	Review	497
<sep> <sep> I also liked Figure 6, exploring Model distillation, which showed that the higher layers of the shallower network were the most affected by the teacher network.	O	O	Review	497
The authors cite related work which suggests only training higher layers, and I'd be curious to see how only training higher layers affects accuracy.	B-Review	B-5	Review	497
<sep> <sep> While I thought the experiments for part (1) SGD with Restarts were thorough, and appreciated Figure 1, which experimentally validated the use of mode connectivity, I felt there was some difficulty in interpreting the results.	B-Review	B-1	Review	497
<sep> <sep> Firstly, in Figure 2, the claim is that SGD with Restarts does possibly bridge local minima as the mode connectivity curves increase between the two convergence points.	B-Review	B-2	Review	497
However, we see in both 2(b) and 2(c) that the linear interpolation between both convergence points does *not* increase in loss.	I-Review	I-2	Review	497
In which case is there any reason to believe that the increase of MC in the middle means that SGDR is climbing a basin?	I-Review	I-2	Review	497
How do we know that the linear combination isn't closer to the path followed by SGDR?	I-Review	I-2	Review	497
<sep> <sep> For additional comparisons, it would be good to have the linear combination plots for Figure 1 also.	B-Review	B-1	Review	497
<sep> <sep> In general, it seems hard to make meaningful conclusions with low dimensional projections of a very high dimensional loss surface.	B-Review	B-6	Review	497
We'd have to know some kind of theoretical property of MC to be able to do so.	I-Review	I-6	Review	497
<sep> <sep> Minor Comments	O	O	Review	497
<sep> I think the figures in this paper could be much clearer.	B-Review	B-3	Review	497
In Figure 2 for example, the legend blocks some of the main areas of interest of the plot.	I-Review	I-3	Review	497
I would recommend cutting some of the raw learning rate figures and making all figures much bigger.	I-Review	I-3	Review	497
<sep> <sep> In figure 4(d), the text describes the process in training steps (200 training steps), but the plot is in epochs -- it would be better if the text and axis were consistent in units.	I-Review	I-3	Review	497
<sep> <sep> Conclusion:	O	O	Review	497
Despite my concerns on the first part of this paper, I think the very thorough experiments, clear presentation and the interesting results on learning rate warmups and model distillation merit its acceptance.	O	O	Review	497
<sep> <sep> <sep> <sep> We thank you for a thorough and supportive review.	O	O	Reply	497
Our responses to the reviews are below -	O	O	Reply	497
<sep> Regarding Fig 1:	O	O	Reply	497
As recommended, we have included the validation accuracy for models on line segment joining the endpoints in figure 1.	B-Reply	B-1	Reply	497
<sep> <sep> Regarding Figure 2 and claims related to SGDR:	O	O	Reply	497
We‚Äôre afraid there has been a misunderstanding here.	B-Reply	B-2	Reply	497
We do not claim, or suggest, that SGDR iterates possibly bridge local minima.	I-Reply	I-2	Reply	497
In fig 2(c) and 2(d) (in original draft), the dot dash curve corresponds to the line segment joining the two iterates and the solid curve represents the MC curve found between the two.	I-Reply	I-2	Reply	497
We see a high loss region on the line segment joining SGDR iterates (dot-dash curves) (2c in original draft), while this ‚Äòbump‚Äô is not observed in the case of iterates from SGD (2d in original draft).	I-Reply	I-2	Reply	497
The MC curves are plotted to indicate the existence of low-loss paths connecting the iterates and highlighting the fact that the SGD iterates ‚Äòjump over the barriers‚Äô (as defined in footnote 3) when there exists a low loss path connecting the two.	I-Reply	I-2	Reply	497
<sep> <sep> Response to minor comments:	O	O	Reply	497
Thank you for pointing out these issues about Fig 2 and Fig 4(d).	B-Reply	B-3	Reply	497
We have made the recommended changes in our updated manuscript.	I-Reply	I-3	Reply	497

This paper empirically explores heuristics commonly used in deep learning: learning rate restarts, warmup and distillation.	O	O	Review	497
The authors utilize two recently proposed tools for neural network analysis: mode connectivity (MC) finding a low loss pathway between two given points in the space of DNN parameters and CCA measuring the correlation of  DNN layer activations.	O	O	Review	497
Conducting a set of experiments and analyzing the results the authors refine the intuition behind the considered heuristics and dynamics of corresponding training procedures.	O	O	Review	497
<sep> <sep> Strengths:	O	O	Review	497
<sep> + The authors conduct experiments ensuring robustness of MC framework.	O	O	Review	497
<sep> + In the chosen settings the experimental methodology of the paper sounds reasonable.	O	O	Review	497
I find the idea of DNN analysis from both perspectives of weight space and activations important.	O	O	Review	497
<sep> + Paper is well-written and organized clearly.	O	O	Review	497
All the used methods and experiments are adequately described.	O	O	Review	497
<sep> + The authors draw connections between obtained results and hypotheses introduced in prior work.	O	O	Review	497
<sep> <sep> Weaknesses:	O	O	Review	497
<sep> - There is a possible flaw in the choice of experimental settings.	B-Review	B-1	Review	497
Authors mention Batch Normalization (BN) among heuristics widely used in deep learning.	I-Review	I-1	Review	497
It is known that properties of both loss surface and activations are different between DNN architectures which include BN layers and those which do not.	I-Review	I-1	Review	497
To emphasize generality of obtained results, it would be beneficial to conduct experiments for both types of DNN architectures as at the moment the majority of the results are presented for VGG architecture which typically does not include BN.	I-Review	I-1	Review	497
Impact of other architecture modifications (e.g. skip connections) might be considered as well.	I-Review	I-1	Review	497
<sep> <sep> - I find the significance of the results unclear.	B-Review	B-2	Review	497
Although the particular insights of the learning procedures are revealed there is not enough attention paid to their value for possible improvements of the procedures and their applications.	I-Review	I-2	Review	497
There is only one idea proposed by the authors based on the experimental results ‚Äì fixing the deeper layers during the warmup phase, but the practical implications of this idea are not discussed.	I-Review	I-2	Review	497
<sep> <sep> Other comments:	O	O	Review	497
<sep> * The scale used in Figure 3 and similar figures in the appendix is not easily comprehensible.	B-Review	B-3	Review	497
I recommend to comment further on the scale or possibly adjust it.	I-Review	I-3	Review	497
<sep> <sep> We thank the reviewer for the feedback.	O	O	Reply	497
<sep> <sep> Our responses to the two weaknesses pointed out in the review:	O	O	Reply	497
<sep> (1) We agree that our observations can gain a lot more generality by covering variants that do and do not have Batch Normalization (BN).	B-Reply	B-1	Reply	497
For the loss landscape analysis performed for SGDR iterates, our current implementation of VGG indeed does not involve Batch Normalization.	I-Reply	I-1	Reply	497
We have added new results in the appendix (Section 8.4 and Fig 13) to cover the case of VGG with BN.	I-Reply	I-1	Reply	497
The results obtained are qualitatively very similar to the ones for without BN.	I-Reply	I-1	Reply	497
<sep> For results related to the FC freezing for large batch training, Section 10 (and Fig 15) in the Appendix includes results for 2 ResNet architectures (containing BN and skip connections).	I-Reply	I-1	Reply	497
<sep> <sep> (2) Regarding practical implication: Thank you for your suggestion.	B-Reply	B-1	Reply	497
We have added a brief discussion to our paper highlighting the possible practical implications of our work, and specifically: new heuristics that could improve training and fundamental research questions that our results motivate.	I-Reply	I-1	Reply	497
We hope one valuable takeaway for readers would be our careful investigation of the heuristics and these new questions that our results open up.	I-Reply	I-1	Reply	497
<sep> <sep> Thank you for pointing out the issue with Fig 3, we have modified its caption to aid the reader‚Äôs understanding.	B-Reply	B-3	Reply	497

<sep> This paper explores two related methods to reduce the number of parameters required (and hence the memory footprint) of neural NLP models that would otherwise use a large word embedding matrix.	O	O	Review	497
Their method, inspired by quantum entanglement, involves computing word embeddings on-the-fly (or by directly computing the output of the "word embedding" with the first linear layer of network).	O	O	Review	497
They demonstrate their method can save an impressive amount of memory and does not exhibit big performance losses on three nlp tasks that they explore.	O	O	Review	497
<sep> <sep> This paper is clearly written (with only a couple of typos) but does not yet reach publication standard.	B-Review	B-9	Review	497
Whilst the empirical performance of their approach is promising from the perspective of saving reducing memory requirements, more experiments are required and more careful comparisons to baselines and other methods in the literature for saving memory/parameters.	I-Review	I-9	Review	497
In general the related work and experimental sections are weak and brief, with only superficial analysis.	I-Review	I-9	Review	497
There is  lack of careful analysis and insight into their results, as well as a careful comparisons to other work in this area.	I-Review	I-9	Review	497
<sep> <sep> The choice of tasks to evaluate on is broad, which is a strength, but is missing simpler tasks that one would expect to see, such as a text classification dataset, or simple bag-of-vectors style models.	B-Review	B-1	Review	497
In addition, the choice of models are somewhat outdated baselines.	B-Review	B-2	Review	497
It seems that transformers would be an ideal setting for their approach, as transformers have rather high dimensional word embedding matrices, but the authors do not run experiments with the now-ubiquitous Transformer.	I-Review	I-2	Review	497
<sep> <sep> The quantum inspiration is largely a distraction, and I think the paper would benefit from this element being scaled back or removed in order to free up space for more experiments.	B-Review	B-10	Review	497
<sep> <sep> The authors acknowledge one key weakness of their approach, that both training and inference time are increased (by 28% or 55% longer for DocQA depending on compression)  but much more work could be done to understand the best way to  mitigate for longer training and inference times.	B-Review	B-3	Review	497
<sep> <sep> The authors argue that reducing the memory footprint of models is vital to address hardware limitations for training and inference for large models like BERT or ROBERTA, but this argument is not particularly strong.	O	O	Review	497
Generally current limitations for training these kinds of models  are the long training times and being able to fit large batches onto our hardware, and the vocabulary matrix is only a constant factor here.	B-Review	B-4	Review	497
And since training time is a bottleneck, the added value of saving memory vs slowing the training speed by 30-50% is debatable.	I-Review	I-4	Review	497
<sep> <sep> Here are some questions for the authors that come to mind when reviewing:	O	O	Review	497
<sep> How does your method compare to other published methods on your benchmarks?	B-Review	B-5	Review	497
<sep> <sep> which choices for r and k lead to the best time/memory/performance tradeoff?	B-Review	B-6	Review	497
how does this compare to other compression methods (on your tasks)	I-Review	I-6	Review	497
<sep> Seq2Seq models usually involve multiplying the the output hidden state with a vocab matrix before softmaxing over all the vocabulary produce word probabilities - did you account for this?	B-Review	B-7	Review	497
Does your method work for the output vocab matrix?	I-Review	I-7	Review	497
<sep> <sep> Did you investigate pre-training word2ket like word2vec or Glove?	B-Review	B-8	Review	497
<sep> <sep> Thank you for your detailed comments!	O	O	Reply	497
We address the main points below:	O	O	Reply	497
<sep> &gt;&gt; The choice of tasks to evaluate on is broad, which is a strength, but is missing simpler tasks that one would expect to see, such as a text classification dataset, or simple bag-of-vectors style models.	O	O	Reply	497
<sep> <sep> Following the suggestion, we trained GloVe using regular embedding and word2ketXS 4/1 for 600K steps on enwiki8 dataset.	B-Reply	B-1	Reply	497
The evaluation loss started at 0.75 and flattened to 0.03 for word2ketXS and 0.01 for regular embedding.	I-Reply	I-1	Reply	497
<sep> <sep> &gt;&gt; authors do not run experiments with the now-ubiquitous Transformer.	O	O	Reply	497
<sep> <sep> Training transformers from scratch is not possible with our current computational budget as it takes more than a month to train using a single V100 GPU.	B-Reply	B-2	Reply	497
We ran an experiment with Bert.base for 2 days using regular and word2ketXS 4/1 embedding.	I-Reply	I-2	Reply	497
The difference at this stage is infinitesimal.	I-Reply	I-2	Reply	497
<sep> <sep> &gt;&gt; much more work could be done to understand the best way to mitigate for longer training and inference times.	O	O	Reply	497
<sep> <sep> From our experiments with pre-training Bert, which is larger model than the ones we used in our experiments, the increase in time dropped to 7%.	B-Reply	B-3	Reply	497
<sep> <sep> &gt;&gt; Generally current limitations for training these kinds of models  are the long training times and being able to fit large batches onto our hardware, and the vocabulary matrix is only a constant factor here.	O	O	Reply	497
<sep> <sep> We have added two paragraphs following the experimental results to discuss the total memory breakdown during training and inference, and clarify where the savings are.	B-Reply	B-4	Reply	497
During inference, there is no need for storing all the activations so embedding and other model‚Äôs parameters are the major bottlenecks.	I-Reply	I-4	Reply	497
During training, one can decrease the memory required for storing activations with a method e.g. `gradient checkpointing` proposed in ‚ÄúTraining deep nets with sublinear memory cost.	I-Reply	I-4	Reply	497
‚Äù by Chen et al 2016 and used recently in ‚ÄúGenerating Long Sequences with Sparse Transformers‚Äù by Child et al 2019.	I-Reply	I-4	Reply	497
Other approaches, such as ‚ÄúALBERT: A Lite BERT for Self-supervised Learning of Language Representations‚Äù by Lan et al use matrix factorization that gives 5 to 30 fold reduction for the base and xxlarge model.	I-Reply	I-4	Reply	497
‚ÄúLow-Memory Neural Network Training: A Technical Report‚Äù by Sohoni reports 8 to 60 fold reduction in the peak memory required to train a model for a DynamicConv Transformer and WideResNet model by combining methods such as (1) imposing sparsity on the model, (2) using low precision, (3) microbatching, and (4) gradient checkpointing.	I-Reply	I-4	Reply	497
<sep> <sep> &gt;&gt; Here are some questions for the authors that come to mind when reviewing:	O	O	Reply	497
<sep> &gt;&gt; How does your method compare to other published methods on your benchmarks?	O	O	Reply	497
<sep> <sep> The obstacle to comparing published methods for word embedding compression empirically with outs is that existing methods have hard limits on the compression rate.	B-Reply	B-5	Reply	497
E.g. bit-reductions techniques can only reduce 32bits to 1bit.	I-Reply	I-5	Reply	497
Other methods also have hard limits on their storage requirement, for example PS-SGNS method cannot use less then |U| + D memory.	I-Reply	I-5	Reply	497
For the  DrQA / SQuAD experiments, we have |U|=118655, D=300, yet our method stores the embedding using just 380 floating numbers, a 380-fold reduction over the theoretical limit of PS-SGNS, with little impact on solution quality.	I-Reply	I-5	Reply	497
We have expanded Related Work section to comment on this issue.	I-Reply	I-5	Reply	497
<sep> <sep> &gt;&gt; which choices for r and k lead to the best time/memory/performance tradeoff?	O	O	Reply	497
how does this compare to other compression methods (on your tasks)	O	O	Reply	497
<sep> The compression rate depends on the tensor product rank and order.	B-Reply	B-6	Reply	497
Increasing the order leads to logarithmic compression, while increasing the rank reduces the compression by a linear rate.	I-Reply	I-6	Reply	497
Increasing order and reducing rank both lead to lower flexibility in what the compressed model can approximate.	I-Reply	I-6	Reply	497
In the Giga experiment, we reported embedding dim of 400 with order of 2 and rank 10.	I-Reply	I-6	Reply	497
We also investigated ranks ranging from 1 to 128.	I-Reply	I-6	Reply	497
Reducing rank below 8 leads to observable drop in accuracy, of about e.g. RG-1 drops from 35.17 to about 34.	I-Reply	I-6	Reply	497
Increasing the rank past 10 does not increase accuracy.	I-Reply	I-6	Reply	497
<sep> <sep> &gt;&gt; Seq2Seq models usually involve multiplying the the output hidden state with a vocab matrix before softmaxing over all the vocabulary produce word probabilities - did you account for this?	O	O	Reply	497
Does your method work for the output vocab matrix?	O	O	Reply	497
<sep> <sep> <sep> No.	B-Reply	B-7	Reply	497
Neither our method nor other methods aim at compressing this matrix.	I-Reply	I-7	Reply	497
We added two paragraphs at the end of experimental results section to clarify this and other memory considerations for training and inference.	I-Reply	I-7	Reply	497
In Transformer, this matrix is shared with the embedding matrix, in principle we can use the same lazy tensor approach to utilize the transposed embeddings matrix without explicitly reconstructing it.	I-Reply	I-7	Reply	497
<sep> <sep> <sep> &gt;&gt; Did you investigate pre-training word2ket like word2vec or Glove?	O	O	Reply	497
<sep> No, we trained all models from random initializations.	B-Reply	B-8	Reply	497
We added a clarification highlighting that to the manuscript.	I-Reply	I-8	Reply	497

<sep> This paper proposes word2ket - a space-efficient form of storing word embeddings through tensor products.	O	O	Review	497
The idea is to factorize each d-dimensional vector into a tensor product of much smaller vectors (either with or without linear operators).	O	O	Review	497
While this results in a time cost for each word lookup, the space savings are enormous and can potentially impact several applications where the vocabulary size is too large to fit into processor memory (CPU or GPU).	O	O	Review	497
The experimental evaluation is done on several tasks like summarization, machine translation and question answering and convincingly demonstrates that one can achieve close to original model performance with very few parameters!	O	O	Review	497
<sep> <sep> This approach would be very useful due to growing model sizes in many areas of NLP (e.g. large pre-trained models) and more broadly, deep learning.	O	O	Review	497
<sep> <sep> Pros:	O	O	Review	497
1.	O	O	Review	497
Novel idea, clear explanation of the method and the tensor factorization scheme.	O	O	Review	497
<sep> 2.	O	O	Review	497
Convincing experiments on a variety of NLP tasks that utilize word embeddings.	O	O	Review	497
<sep> <sep> Cons:	O	O	Review	497
1. (	B-Review	B-1	Review	497
Minor) While this is not the focus of the paper, it would be useful to have at least one experiment with a state-of-the-art model on any of these tasks to further strengthen the results (most of the baseline models used currently seem to be below SOTA).	I-Review	I-1	Review	497
<sep> <sep> <sep> Minor comments:	B-Review	B-2	Review	497
Abstract: stain -&gt; strain	I-Review	I-2	Review	497
Page 2:	I-Review	I-2	Review	497
Thanks for your review and comments!	O	O	Reply	497
<sep> <sep> &gt;&gt; Cons: 1. (	O	O	Reply	497
Minor) While this is not the focus of the paper, it would be useful to have at least one experiment with a state-of-the-art model on any of these tasks to further strengthen the results (most of the baseline models used currently seem to be below SOTA).	O	O	Reply	497
<sep> <sep> Indeed, these models have been surpassed by transformer-based models.	B-Reply	B-1	Reply	497
We explored several models, and ultimately settled on training Bert.base, but it was not possible to advance far into the run given our computational budget.	I-Reply	I-1	Reply	497
On V100 GPU at our disposal, it would take a month to train it.	I-Reply	I-1	Reply	497
After two days of running it using regular embeddings and using word2ketXS 4/1 embedding, there training loss curves were indistinguishable.	I-Reply	I-1	Reply	497
But at that stage, the optimization is still in its early stages, so this is not a conclusive finding.	I-Reply	I-1	Reply	497

The paper presents two methods to learn word embedding matrices that can be stored in much less space compared to traditional d x p embedding matrices, where d is the vocabulary size and p is the embedding size.	O	O	Review	497
Two methods are proposed: the first method estimates a p-dimensional embedding for a word as a sum of r tensor products of order n (tensor product of n q-dimensional embeddings).	O	O	Review	497
This representation takes rnq parameters which can be much less than p, since p = q^n.	O	O	Review	497
The second method factorizes a full d x p embedding matrix jointly as a tensor product of much smaller t x q matrices and can obtain even larger space savings.	O	O	Review	497
Algorithms for efficiently computing full p-dimensional representations are also included.	O	O	Review	497
When only dot products are needed, the p-dimensional representations do not need to be explicitly constructed.	O	O	Review	497
<sep> <sep> In my opinion the terminology from quantum computing and entanglement is an unnecessary complication.	B-Review	B-1	Review	497
It would be better to simply talk about the special parametric form of the embeddings , which allows efficient storage.	I-Review	I-1	Review	497
Tensor product representations have been used for embeddings before (but not with the goal of efficiency) (e.g. Arora et al 2018) <a href="https://openreview.net/pdf?id=B1e5ef-C-" target="_blank" rel="nofollow">https://openreview.net/pdf?id=B1e5ef-C-</a>	B-Review	B-2	Review	497
The paper covers related work briefly and does not compare experimentally to any other work aiming to reduce memory usage for embedding models (e.g. using up-projection from lower-dimensional embeddings, or e.g. this paper: Learning Compact Neural Word Embeddings by Parameter Space Sharing by Suzuki and Nagata.	B-Review	B-3	Review	497
<sep> <sep> The experimental results on summarization, machine translation, and QA show that the methods can obtain comparable results to models using traditional word embeddings while obtaining savings of up to one-thousand fold decrease in space needed for the embeddings.	B-Review	B-4	Review	497
<sep> <sep> The experimental results seem to conflate the issues of the dimensionality of the word embeddings versus that of the higher layers.	B-Review	B-5	Review	497
For example, in the summarization experiments, word2ketXS embeddings corresponding to 8000-dimensional embeddings are compared to a standard model with embeddings of size 256.	I-Review	I-5	Review	497
The LSTM and layers for the word2ketXS model would become quite large but their size is not taken into account.	I-Review	I-5	Review	497
In addition, the activation memory is often the major bottleneck and not the parameter memory.	I-Review	I-5	Review	497
These issues are not discussed or made explicit in the experiments.	I-Review	I-5	Review	497
<sep> <sep> Overall the paper can be a strong contribution if the methods are stated with less quantum computing jargon, the overall parameter size and speed of the different models is specified in the experiments, and more specific connections to related work are made.	B-Review	B-6	Review	497
Ideally, an experimental comparison to a prior method for space-efficient embeddings.	I-Review	I-6	Review	497
<sep> <sep> Question: What is the role of pre-trained Glove embeddings in the word2ket models?	B-Review	B-7	Review	497
Was any pre-training done on unlabeled text?	I-Review	I-7	Review	497
<sep> <sep> <sep> Some typos:	B-Review	B-8	Review	497
<sep> Section 1.1	I-Review	I-8	Review	497
<sep> ‚Äúmatrix, as the cost ..‚Äù  -&gt; ‚Äúmatrix, at the cost‚Äù	I-Review	I-8	Review	497
<sep> Under Eq (2)	I-Review	I-8	Review	497
I think you mean w instead of u	I-Review	I-8	Review	497
<sep> Section 3.2	I-Review	I-8	Review	497
<sep> F_j: R^t -&gt; R^p , do you mean R^q	I-Review	I-8	Review	497
<sep> Thank you for your detailed comments!	O	O	Reply	497
We address the main points below:	O	O	Reply	497
<sep> &gt;&gt; In my opinion the terminology from quantum computing and entanglement is an unnecessary complication.	O	O	Reply	497
It would be better to simply talk about the special parametric form of the embeddings, which allows efficient storage.	O	O	Reply	497
<sep> <sep> We removed some of the quantum computation connections from the introduction, keeping only enough to justify the title.	B-Reply	B-1	Reply	497
<sep> &gt;&gt; Tensor product representations have been used for embeddings before (but not with the goal of efficiency) (e.g. Arora et al 2018) <a href="https://openreview.net/pdf?id=B1e5ef-C-" target="_blank" rel="nofollow">https://openreview.net/pdf?id=B1e5ef-C-</a>	O	O	Reply	497
<sep> We have expanded the ‚Äúrelated work‚Äù section to include:	B-Reply	B-2	Reply	497
In more distantly related work, tensor product spaces have been used in studying document embeddings, by using sketching of a tensor representing-grams in the document \cite{arora2018compressed}.	I-Reply	I-2	Reply	497
<sep> &gt;&gt; The paper covers related work briefly and does not compare experimentally to any other work aiming to reduce memory usage for embedding models (e.g. using up-projection from lower-dimensional embeddings, or e.g. this paper: Learning Compact Neural Word Embeddings by Parameter Space Sharing by Suzuki and Nagata.	O	O	Reply	497
<sep> <sep> We have added a reference to Suzuki and Nagata‚Äôs (N&amp;S) very interesting work.	B-Reply	B-3	Reply	497
We note their experiments show substantial drop in quality on downstream tasks when the space-saving rate increases past 64.	I-Reply	I-3	Reply	497
For a |U| x D embedding, their PS-SGNS method uses |U| B log K + C B K  F bits (N&amp;S, section 3.3), where F is the number of bits (e.g. 32), C B and K are parameters, chosen to meet the assertion C B = D, and log K &gt;=1 .	I-Reply	I-3	Reply	497
Thus, their embeddings use |U| B log K + D K  F,  PS-SGNS method cannot use less then |U| + D memory.	I-Reply	I-3	Reply	497
For the  DrQA / SQuAD experiments, we have |U|=118655, D=300, yet our method stores the embedding using just 380 floating numbers, a 380-fold reduction over the theoretical limit of PS-SGNS, with little impact on solution quality.	I-Reply	I-3	Reply	497
Other existing methods, e.g. Uniform Quantization and K-means Compression  cannot offer more than 32 fold space reduction.	I-Reply	I-3	Reply	497
K-means Compression ‚ÄúCompressing word embeddings‚Äù by Andrews et al also has the same limit. ‚	I-Reply	I-3	Reply	497
ÄúOn the Downstream Performance of Compressed Word Embeddings‚Äù shows that PCA, which also has |U| + D memory, shows a big drop in performance after 4 fold compression.	I-Reply	I-3	Reply	497
On the other hand, the minimum space requirement of our method is only 4 log |U|, if we use 2x2 matrix F_j and tensor of order n=log |U|. This logarithmic dependence on |U| translates to savings that grow higher with higher dictionary sizes.	I-Reply	I-3	Reply	497
<sep> <sep> &gt;&gt; The experimental results seem to conflate the issues of the dimensionality of the word embeddings versus that of the higher layers.	O	O	Reply	497
<sep> <sep> In all experiments, we kept the dimensions of the higher layers constant.	B-Reply	B-4	Reply	497
The LSTM layers used the same 256 hidden size dimensions, but the embedding had a varying size.	I-Reply	I-4	Reply	497
To clarify this, on page 6, we added "we also explored 400, and 8000 for the embedding size  but kept the dimensionality of other layers constant.	I-Reply	I-4	Reply	497
‚Äù	I-Reply	I-4	Reply	497
<sep> &gt;&gt; In addition, the activation memory is often the major bottleneck and not the parameter memory.	O	O	Reply	497
These issues are not discussed or made explicit in the experiments.	O	O	Reply	497
<sep> <sep> We have added two paragraphs following the experimental results to discuss the total memory breakdown during training and inference, and clarify where the savings are.	B-Reply	B-5	Reply	497
During inference, there is no need for storing all the activations so embedding and other model‚Äôs parameters are the major bottlenecks.	I-Reply	I-5	Reply	497
During training, one can decrease the memory required for storing activations with a method e.g. `gradient checkpointing` used recently in ‚ÄúGenerating Long Sequences with Sparse Transformers‚Äù by Child et al 2019.	I-Reply	I-5	Reply	497
<sep> <sep> &gt;&gt;  Ideally, an experimental comparison to a prior method for space-efficient embeddings.	O	O	Reply	497
<sep> <sep> We reduced the quantum part.	B-Reply	B-6	Reply	497
We added classification to the description of the models:	I-Reply	I-6	Reply	497
For the first two tasks, we now have ‚ÄúIn both the encoder and the decoder we used internal layers with dimensionality of 256‚Äù.	I-Reply	I-6	Reply	497
For the third task, we have ‚ÄúWe used the DrQA's model, a 3-layer bidirectional LSTMs with 128 hidden units for both paragraph and question encoding.	I-Reply	I-6	Reply	497
‚Äù.	I-Reply	I-6	Reply	497
In terms of experimental comparison, as noted above, existing methods offer &lt;64-fold embedding reduction, and the main goal of our method is to provide higher reduction rates.	I-Reply	I-6	Reply	497
<sep> <sep> &gt;&gt; Question: What is the role of pre-trained Glove embeddings in the word2ket models?	O	O	Reply	497
Was any pre-training done on unlabeled text?	O	O	Reply	497
<sep> <sep> We did not use any pre-training of the models, and did not use pre-trained embeddings.	B-Reply	B-7	Reply	497
To clarify this, we added ‚ÄúWe trained the model for 40 epochs, starting from random weights and embeddings‚Äù to the experiments descriptions.	I-Reply	I-7	Reply	497
<sep> <sep> &gt;&gt; Section 3.2 F_j: R^t -&gt; R^p , do you mean R^q	O	O	Reply	497
Indeed.	B-Reply	B-8	Reply	497
Apologies for this and other typos.	I-Reply	I-8	Reply	497

One of the main idea of this paper is to replace pooling layers with convolutions of stride 2 and retraining the model.	O	O	Review	442
Authors merge this into a new layer and brand it as a new type of layer.	B-Review	B-1	Review	442
This is very misleading and adding noise to the field.	I-Review	I-1	Review	442
And using strided convolutions rather than pooling is not actually novel (e.g. <a href="https://arxiv.org/abs/1605.02346)."	B-Review	B-2	Review	442
target="_blank" rel="nofollow">https://arxiv.org/abs/1605.02346).</a>	I-Review	I-2	Review	442
While the speed-up obtained are good, the lack of novelty and the rebranding attempt make this paper not a good fit for ICLR.	B-Review	B-3	Review	442
The reviewer missed the key points in our paper.	O	O	Reply	442
There exist clear and significant differences between our work and previous works.	O	O	Reply	442
<sep> <sep> We are not "replacing a pooling layer to a convolution layer of stride 2" which was in fact proposed in another paper "‚ÄúSTRIVING FOR SIMPLICITY: THE ALL CONVOLUTIONAL NET‚Äù.	B-Reply	B-1	Reply	442
Instead, our method merges various types of non-tensor layers (i.e., pooling, LRN etc.)	I-Reply	I-1	Reply	442
and their bottom convolution layer to a new convolution layer (i.e., the "rebirth" layer).	I-Reply	I-1	Reply	442
This is how we achieve significantly improved efficiency and accelerated model execution.	I-Reply	I-1	Reply	442
<sep> We view this process as "rebirth" of a new layer  instead of "a new *type* of layer" as an analogy to help readers' catch up the idea and understand the merit of work.	I-Reply	I-1	Reply	442
<sep> <sep> In addition, from the reference (<a href="https://arxiv.org/abs/1605.02346)," target="_blank" rel="nofollow">https://arxiv.org/abs/1605.02346),</a> we did not find the similar operation as our algorithm which optimizes multiple layers with a new layer.	B-Reply	B-2	Reply	442
As indicted in Section 4 (tasks and datasets section in reference), ‚ÄúFirst, a shallow CNN which consists of six layers each followed by a rectified linear unit [32] and Batch Normalization [33]. The first four layers include max pooling with stride 2, leading to an effective stride of 16,‚Äù  the method in reference relied on traditional network structure without applying the optimization schemes as ours.	I-Reply	I-2	Reply	442
<sep> <sep> <sep> Regarding the novelty, to the best of our knowledge, this is *first* one that leverages merging of different types of layers (including  *non-tensor* layers) for acceleration of CNN models on mobile devices.	B-Reply	B-3	Reply	442
This is also the *best* method (see Table below) reported in accelerating the CNN on mobile devices.	I-Reply	I-3	Reply	442
It has technical novelty, and truly works pretty well in reality.	I-Reply	I-3	Reply	442
<sep> If anyone has questions, we are very happy to do competitions on mobile devices.	O	O	Reply	442
<sep> <sep> Giving all the above considerations, we are very disappointed to see the reviewer viewing our work as "misleading and adding noise to the field. "	O	O	Reply	442

This paper proposes to reduce model size and evaluation time of deep CNN models on mobile devices by converting multiple layers into single layer and then retraining the converted model.	O	O	Review	442
The paper showed that the computation time can be reduced by 3x to 5x with only 0.4% accuracy loss on a specific model.	O	O	Review	442
<sep> <sep> Reducing model sizes and speeding up model evaluation are important in many applications.	O	O	Review	442
I have several concerns:	O	O	Review	442
<sep> 1.	O	O	Review	442
There are many techniques that can reduce model sizes.	B-Review	B-1	Review	442
For example, it has been shown by several groups that using the teacher-student approach, people can achieve the same and sometimes even better accuracy than the teacher (big model) using a much smaller model.	I-Review	I-1	Review	442
However, this paper does not compare any one of them.	I-Review	I-1	Review	442
<sep> 2.	O	O	Review	442
The technique proposed in this paper is limited in its applicability since it's designed specifically for the models discussed in the paper.	B-Review	B-2	Review	442
<sep> 3.	O	O	Review	442
Replacing several layers with single layer is a relatively standard procedure.	B-Review	B-3	Review	442
For example, the mean variance normalization layer and batch normalization layer can all be absorbed without retraining or losing accuracy.	I-Review	I-3	Review	442
<sep> <sep> BTW, the DNN low-rank approximation technique was first proposed in speech recognition.	B-Review	B-4	Review	442
e.g.,	I-Review	I-4	Review	442
<sep> Xue, J., Li, J. and Gong, Y., 2013, August.	O	O	Review	442
Restructuring of deep neural network acoustic models with singular value decomposition.	O	O	Review	442
In INTERSPEECH (pp.2365-2369).	O	O	Review	442
<sep> <sep> (1) There are many techniques that can reduce model sizes.	O	O	Reply	442
For example, it has been shown by several groups that using the teacher-student approach, people can achieve the same and sometimes even better accuracy than the teacher (big model) using a much smaller model.	O	O	Reply	442
However, this paper does not compare any one of them.	O	O	Reply	442
<sep> <sep> Ans: We agree that there are many different kinds of model compression techniques.	B-Reply	B-1	Reply	442
However, these algorithms mainly focus on reducing the model size instead of improving the running speed, especially, the acceleration of the execution time of deep model on mobile devices is not evident.	I-Reply	I-1	Reply	442
We already compared with several state-of-the-art works in the paper.	I-Reply	I-1	Reply	442
As listed in Table 5, in terms of running speed, runtime memory, energy, our approach performs significant better than GoogleNet-Tucker (ICLR'16), &nbsp;Squeezenet (<a href="https://openreview.net/forum?id=S1xh5sYgx)" target="_blank" rel="nofollow">https://openreview.net/forum?id=S1xh5sYgx)</a> and others.&nbsp;The details of comparison are listed as follows:	I-Reply	I-1	Reply	442
<sep> -----------------------|-----DeepRebirth-----|----SqueezeNet--|--Tucker (ICLR'16)*----|--GoogleNet---|	I-Reply	I-1	Reply	442
Acc&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  |<tab>      86.5%<tab>  |<tab>      80.3%<tab> |     <tab>        85.7%          |<tab>        88.9%      |<tab>	I-Reply	I-1	Reply	442
Execution time    |         65.34 ms      |       75.34 ms        |<tab>     342.5 ms        |       424.7 ms    |	I-Reply	I-1	Reply	442
Energy&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  |<tab>        226 mJ      |          288 mJ        |             902 mJ         |          984 mJ    |	I-Reply	I-1	Reply	442
Memory size&nbsp;&nbsp;&nbsp;    |         14.8 MB       |           36.5 MB      |           35.8 MB         |         33.2 MB    |	I-Reply	I-1	Reply	442
Parameter size   |       11.99 MB       |         4.72 MB         |            14.38 MB      |        26.72 MB   |	I-Reply	I-1	Reply	442
*The number is based on our implementation of the algorithm in ICLR'16 paper.	I-Reply	I-1	Reply	442
<sep> <sep> (2) The technique proposed in this paper is limited in its applicability since it's designed specifically for the models discussed in the paper.	O	O	Reply	442
<sep> <sep> Ans: Our proposed approach can be applied to current general deep neural network structures that consist of different layers, e.g., convolution, pooling, LRN, etc.	B-Reply	B-2	Reply	442
The reason why we used GoogleNet, Resnet and Alexnet is due to their popularity, as evident in current model compression work, e.g,  Song Han.	I-Reply	I-2	Reply	442
et al [ICLR‚Äô16],  Yong-Deok Kim et al [ICLR‚Äô16].	I-Reply	I-2	Reply	442
<sep> (3) Replacing several layers with single layer is a relatively standard procedure.	O	O	Reply	442
For example, the mean variance normalization layer and batch normalization layer can all be absorbed without retraining or losing accuracy.	O	O	Reply	442
<sep> <sep> Ans:  As far as we know, only mean variance normalization layer and batch normalization layer can all be absorbed without retraining, however, the operation can be only applied to two-layers and needs specific structure ‚Äì normalization layer right after convolution.	B-Reply	B-3	Reply	442
<sep> <sep> To address these limitations, we proposed a general approach that can be applied to pooling, LRN, batchnorm and convolution, etc.	I-Reply	I-3	Reply	442
<sep> (4) BTW, the DNN low-rank approximation technique was first proposed in speech recognition.	O	O	Reply	442
<sep> <sep> Ans: Thanks for the comment.	B-Reply	B-4	Reply	442
We have already included this reference in revision.	I-Reply	I-4	Reply	442

This paper looks at the idea of fusing multiple layers (typically a convolution and a LRN or pooling layer) into a single convolution via retraining of just that layer, and shows that simpler, faster models can be constructed that way at minimal loss in accuracy.	O	O	Review	442
This idea is fine.	O	O	Review	442
Several issues:	O	O	Review	442
- The paper introduces the concept of a 'Deeprebirth layer', and for a while it seems like it's going to be some new architecture.	B-Review	B-1	Review	442
Mid-way, we discover that 1) it's just a convolution 2) it's actually a different kind of convolution depending on whether one fuses serial or parallel pooling layers.	I-Review	I-1	Review	442
I understand the desire to give a name to the technique, but in this case naming the layer itself, when it's actually multiple things, non of which are new architecturally, confuses the argument a lot.	I-Review	I-1	Review	442
<sep> - There are ways to perform this kind of operator fusion without retraining, and some deep learning framework such as Theano and the upcoming TensorFlow XLA implement them.	B-Review	B-2	Review	442
It would have been nice to have a baseline that implements it, especially since most of the additional energy cost from non-fused operators comes from the extra intermediate memory writes that operator fusion removes.	I-Review	I-2	Review	442
<sep> - Batchnorm can be folded into convolution layers without retraining by scaling the weights.	B-Review	B-3	Review	442
Were they folded into the baseline figures reported in Table 7?	I-Review	I-3	Review	442
<sep> - At the time of writing, the authors have not provided the details that would make this research reproducible, in particular how the depth of the fused layers relates to the depth of the original layers in each of the experiments.	B-Review	B-4	Review	442
<sep> - Retraining: how much time (epochs) does the retraining take?	B-Review	B-5	Review	442
Did you consider using any form of distillation?	I-Review	I-5	Review	442
<sep> Interesting set of experiments.	I-Review	I-5	Review	442
This paper needs a lot of improvements to be suitable for publication.	I-Review	I-5	Review	442
<sep> - Open-sourcing: having the implementation be open-source always enhances the usefulness of such paper.	B-Review	B-6	Review	442
Not a requirement obviously.	I-Review	I-6	Review	442
<sep> <sep> <sep> (1) I understand the desire to give a name to the technique, but in this case naming the layer itself, when it's actually multiple things, non of which are new architecturally, confuses the argument a lot.	O	O	Reply	442
<sep> <sep> Ans: Well, we name our approach as ‚Äúdeep-rebirth‚Äù because in our proposed speed optimization pipeline, we have replaced multiple deep network layers which run much slower compared to the newly generated and faster layer (e.g., convolution layer in our experiment) like a rebirth.	B-Reply	B-1	Reply	442
<sep> <sep> (2) There are ways to perform this kind of operator fusion without retraining, and some deep learning framework such as Theano and the upcoming TensorFlow XLA implement them.	O	O	Reply	442
It would have been nice to have a baseline that implements it, especially since most of the additional energy cost from non-fused operators comes from the extra intermediate memory writes that operator fusion removes.	O	O	Reply	442
<sep> <sep> Ans: As far as we know, the operator fusion without retraining can only be applied to some specific structure, i.e.,  batch normalization or mean normalization after convolution.	B-Reply	B-2	Reply	442
This kind of operator fusion can‚Äôt be applied to other kinds of layers, such as pooling, LRN, etc.	I-Reply	I-2	Reply	442
Our pipeline is much more general.	I-Reply	I-2	Reply	442
<sep> <sep> The deep learning framework such as Theano and XLA performs the operator fusion to reduce the memory.	I-Reply	I-2	Reply	442
However, the execution time of these models may not be accelerated due to the use of same architectures (i.e., performing exactly the same set of floating-point operations).	I-Reply	I-2	Reply	442
If we view them as the baseline, their execution time would be much ‚Äúhigher‚Äù than deep-rebirth.	I-Reply	I-2	Reply	442
In contrast, our method re-trained the rebirth layers and significantly speeds up the execution time.	I-Reply	I-2	Reply	442
<sep> <sep> (3) Batchnorm can be folded into convolution layers without retraining by scaling the weights.	O	O	Reply	442
Were they folded into the baseline figures reported in Table 7?	O	O	Reply	442
<sep> <sep> Ans: We agree that batchnorm can be folded into convolution layer without retraining by scaling the weights.	B-Reply	B-3	Reply	442
The results listed in Table 7 also include other layers‚Äô  optimization, e.g., pooling, not limited to batchnorm.	I-Reply	I-3	Reply	442
<sep> <sep> (4) At the time of writing, the authors have not provided the details that would make this research reproducible, in particular how the depth of the fused layers relates to the depth of the original layers in each of the experiments.	O	O	Reply	442
Open-sourcing: having the implementation be open-source always enhances the usefulness of such paper.	O	O	Reply	442
Not a requirement obviously.	O	O	Reply	442
<sep> <sep> Ans:  We have listed the details in our revision.	B-Reply	B-4	Reply	442
We plan to release the code after final decision.	I-Reply	I-4	Reply	442
Our first step for open-source would be the release of the model architectures (in caffe‚Äôs prototxt format) used in our paper.	I-Reply	I-4	Reply	442
<sep> <sep> (5) Retraining: how much time (epochs) does the retraining take?	O	O	Reply	442
Did you consider using any form of distillation?	O	O	Reply	442
<sep> <sep> Ans: Each step of our optimization pipeline takes around 2 epochs (in section 4.1.1).	B-Reply	B-5	Reply	442
For GoogleNet, it takes 9 steps and 18 epochs.	I-Reply	I-5	Reply	442
We regard this training time (or rebirth time) as a one-time cost and once trained it can be deployed to any mobile devices.	I-Reply	I-5	Reply	442
<sep> <sep> Our ‚Äúrebirth‚Äù method can be considered as a special form of distillation that transfers the knowledge from the cumbersome substructure of multiple layers to the rebirthed accelerated substructure.	I-Reply	I-5	Reply	442
Different from traditional distillation method, our approach adopts layer-wise optimization and maintains the knowledge of the rest layers.	I-Reply	I-5	Reply	442
Also, our method utilizes a softmax at the end of our CNN to optimize classification accuracy.	I-Reply	I-5	Reply	442
<sep> <sep> (6) Interesting set of experiments.	O	O	Reply	442
This paper needs a lot of improvements to be suitable for publication.	O	O	Reply	442
<sep> <sep> Ans: Thanks for your appreciation of our paper.	B-Reply	B-6	Reply	442
We are constantly improving the quality of our paper.	I-Reply	I-6	Reply	442

This paper explores a new approach to optimal transport.	O	O	Review	442
Contributions include a new dual-based algorithm for the fundamental task of computing an optimal transport coupling, the ability to deal with continuous distributions tractably by using a neural net to parameterize the functions which occur in the dual formulation, learning a Monge map parameterized by a neural net allowing extremely tractable mapping of samples from one distribution to another, and a plethora of supporting theoretical results.	O	O	Review	442
The paper presents significant, novel work in a straightforward, clear and engaging way.	O	O	Review	442
It represents an elegant combination of ideas, and a well-rounded combination of theory and experiments.	O	O	Review	442
<sep> <sep> I should mention that I'm not sufficiently familiar with the optimal transport literature to verify the detailed claims about where the proposed dual-based algorithm stands in relation to existing algorithms.	O	O	Review	442
<sep> <sep> Major comments:	O	O	Review	442
<sep> No major flaws.	O	O	Review	442
The introduction is particular well written, as an extremely clear and succinct introduction to optimal transport.	O	O	Review	442
<sep> <sep> Minor comments:	O	O	Review	442
<sep> In the introduction, for VAEs, it's not the case that f(X) matches the target distribution.	B-Review	B-1	Review	442
There are two levels of sampling: of the latent X and of the observed value given the latent.	I-Review	I-1	Review	442
The second step of sampling is ignored in the description of VAEs in the first paragraph.	I-Review	I-1	Review	442
<sep> <sep> In the comparison to previous work, please explicitly mention the EMD algorithm, since it's used in the experiments.	B-Review	B-2	Review	442
<sep> <sep> It would've been nice to see an experimental comparison to the algorithm proposed by Arjovsky et al (2017), since this is mentioned favorably in the introduction.	B-Review	B-3	Review	442
<sep> <sep> In (3), R is not defined.	B-Review	B-15	Review	442
Suggest adding a forward reference to (5).	I-Review	I-15	Review	442
<sep> <sep> In section 3.1, it would be helpful to cite a reference to support the form of dual problem.	B-Review	B-16	Review	442
<sep> <sep> Perhaps the authors have just done a good job of laying the groundwork, but the dual-based approach proposed in section 3.1 seems quite natural.	O	O	Review	442
Is there any reason this sort of approach wasn't used previously, even though this vein of thinking was being explored for example in the semi-dual algorithm?	B-Review	B-4	Review	442
If so, it would interesting to highlight the key obstacles that a naive dual-based approach would encounter and how these are overcome.	I-Review	I-4	Review	442
<sep> <sep> In algorithm 1, it is confusing to use u to mean both the parameters of the neural net and the function represented by the neural net.	B-Review	B-5	Review	442
<sep> <sep> There are many terms in R_e in (5) which appear to have no effect on optimization, such as a(x) and b(y) in the denominator and "- 1".	B-Review	B-6	Review	442
It seems like R_e boils down to just the entropy.	I-Review	I-6	Review	442
<sep> <sep> The definition of F_\epsilon is made unnecessarily confusing by the omission of x and y as arguments.	B-Review	B-12	Review	442
<sep> <sep> It would be great to mention very briefly any helpful intuition as to why F_\epsilon and H_\epsilon have the forms they do.	B-Review	B-13	Review	442
<sep> <sep> In the discussion of Table 1, it would be helpful to spell out the differences between the different Bary proj algorithms, since I would've expected EMD, Sinkhorn and Alg.	B-Review	B-7	Review	442
1 with R_e to all perform similarly.	I-Review	I-7	Review	442
<sep> <sep> In Figure 4 some of the samples are quite non-physical.	B-Review	B-8	Review	442
Is their any helpful intuition about what goes wrong?	I-Review	I-8	Review	442
<sep> <sep> What cost is used for generative modeling on MNIST?	B-Review	B-9	Review	442
<sep> <sep> For generative modeling on MNIST, "784d vector" is less clear than "784-dimensional vector".	B-Review	B-14	Review	442
The fact that the variable d is equal to 768 is not explicitly stated.	I-Review	I-14	Review	442
<sep> <sep> It seems a bit strange to say "The property we gain compared to other generative models is that our generator is a nearly optimal map w.r.t.this cost" as if this was an advantage of the proposed method, since arguably there isn't a really natural cost in the generative modeling case (unlike in the domain adaptation case); the latent variable seems kind of conceptually distinct from observation space.	B-Review	B-10	Review	442
<sep> <sep> Appendix A isn't referred to from the main text as far as I could tell.	B-Review	B-11	Review	442
Just merge it into the main text?	I-Review	I-11	Review	442
<sep> <sep> <sep> <sep> <sep> Dear reviewer,	O	O	Reply	442
<sep> Thank you very much for your positive review and detailed comments.	O	O	Reply	442
Please find below our replies to your comments.	O	O	Reply	442
<sep> <sep> "In the introduction, for VAEs, it's not the case that f(X) matches the target distribution. [...]	O	O	Reply	442
The second step of sampling is ignored in the description of VAEs in the first paragraph."	O	O	Reply	442
<sep> <sep> At training time, there are indeed two neural networks involved in the VAE model, one encoder and one decoder.	B-Reply	B-1	Reply	442
Here, we refer to X as the latent variable, i.e. the distribution obtained by the image of the input data by the encoder.	I-Reply	I-1	Reply	442
We hence refer to f as the decoder network.	I-Reply	I-1	Reply	442
With these notations, we believe that f is learned so that f(X) matches the distribution of the input data.	I-Reply	I-1	Reply	442
<sep> <sep> "In the comparison to previous work, please explicitly mention the EMD algorithm, since it's used in the experiments."	O	O	Reply	442
<sep> <sep> We used a c++ implementation of the network simplex algorithm (<a href="http://liris.cnrs.fr/~nbonneel/FastTransport/)."	B-Reply	B-2	Reply	442
target="_blank" rel="nofollow">http://liris.cnrs.fr/~nbonneel/FastTransport/).</a> We have added this link as a footnote.	I-Reply	I-2	Reply	442
<sep> <sep> "It would've been nice to see an experimental comparison to the algorithm proposed by Arjovsky et al (2017), since this is mentioned favorably in the introduction."	O	O	Reply	442
<sep> <sep> Our algorithm shares indeed similarities with the one proposed by Arjovsky et al (2017): they both use NN parameterizations of the OT dual variables.	B-Reply	B-3	Reply	442
Both our algorithms have the same complexity.	I-Reply	I-3	Reply	442
However, in our case, we compute regularized OT, while Arjovsky et al (2017) unregularized OT.	I-Reply	I-3	Reply	442
Hence, we found it more relevant to compare to Genevay et al (2016) who computed exactly the same objective as us (in the entropy reg.	I-Reply	I-3	Reply	442
case).	I-Reply	I-3	Reply	442
<sep> <sep> "Is there any reason this sort of approach wasn't used previously, even though this vein of thinking was being explored for example in the semi-dual algorithm?"	O	O	Reply	442
<sep> <sep> Let us emphasize that the simplex algorithm is an efficient OT solver for measures supported up to a few thousands samples, and may be suitable in many applications.	B-Reply	B-4	Reply	442
<sep> <sep> It seems that the need to compute OT in large-scale settings is largely driven by the machine-learning community, with the recent idea that the OT objective can be a powerful loss function (Rolet et al (2016), Arjovsky et al (2017)), as well as the OT plans can be used to perform domain adaptation (Courty et al (2016).	I-Reply	I-4	Reply	442
<sep> <sep> Moreover, our dual approach is simple thanks to the convex regularization of the primal OT problem, which was also introduced relatively recently (Cuturi (2013)).	I-Reply	I-4	Reply	442
<sep> <sep> Finally, our approach is not flawless: the use of deep NN makes the problem non-convex (in the semi-discrete and continuous-continuous cases).	I-Reply	I-4	Reply	442
<sep> <sep> "In algorithm 1, it is confusing to use u to mean both the parameters of the neural net and the function represented by the neural net."	O	O	Reply	442
<sep> <sep> We wanted to emphasize that our algorithm is conceptually the same in all settings (discrete-discrete, semi-discrete and continuous-continuous).	B-Reply	B-5	Reply	442
We are thinking of better notations to make it less confusing.	I-Reply	I-5	Reply	442
<sep> <sep> "There are many terms in R_e in (5) which appear to have no effect on optimization, such as a(x) and b(y) in the denominator and "- 1".	O	O	Reply	442
It seems like R_e boils down to just the entropy."	O	O	Reply	442
<sep> <sep> We have removed a and b from the text.	B-Reply	B-6	Reply	442
We can remove the -1 in the entropy regularizer, but 1) it would make the primal-dual relationship less ‚Äòsimple‚Äô and 2) this would not be in line with the work of Genevay et al (2016) or Peyr√© (2016).	I-Reply	I-6	Reply	442
<sep> <sep> "I would've expected EMD, Sinkhorn and Alg.	O	O	Reply	442
1 with R_e to all perform similarly."	O	O	Reply	442
<sep> <sep> We had a typo in the result of the ‚ÄúBar.	B-Reply	B-7	Reply	442
proj.	I-Reply	I-7	Reply	442
Alg.	I-Reply	I-7	Reply	442
1 R_e‚Äù case.	I-Reply	I-7	Reply	442
We have rerun the experiment and it indeed performs similarly as Sinkhorn, as expected.	I-Reply	I-7	Reply	442
We apologize for that.	I-Reply	I-7	Reply	442
<sep> EMD (i.e. non-regularized OT) is not expected to perform as Sinkhorn since the regularization has an effect of the OT plan and hence on the barycentric projection.	I-Reply	I-7	Reply	442
<sep> <sep> "In Figure 4 some of the samples are quite non-physical.	O	O	Reply	442
Is their any helpful intuition about what goes wrong?"	O	O	Reply	442
<sep> <sep> The barycentric projection performs an averaging (w.r.t.	B-Reply	B-8	Reply	442
the squared Euclidean metric which was chosen in that xp) between target samples (weighted according to the optimal plan).	I-Reply	I-8	Reply	442
In some case, this averaging might lead to so these non-physical shapes.	I-Reply	I-8	Reply	442
<sep> <sep> "What cost is used for generative modeling on MNIST?"	O	O	Reply	442
<sep> <sep> We used the squared Euclidean distance.	B-Reply	B-9	Reply	442
<sep> <sep> "It seems a bit strange to say "The property we gain compared to other generative models is that our generator is a nearly optimal map w.r.t.this cost" [...] the latent variable seems kind of conceptually distinct from observation space."	O	O	Reply	442
<sep> <sep> Indeed, most generative models do not need to have an 'optimal' the generator.	B-Reply	B-10	Reply	442
Yet we believe that looking for map which has certain (regularity) properties can be useful for some applications.	I-Reply	I-10	Reply	442
We may consider further work in generative modeling where optimality of the mapping (w.r.t.	I-Reply	I-10	Reply	442
to a given cost) can be important (such as image-to-image translation).	I-Reply	I-10	Reply	442
<sep> <sep> References:	O	O	Reply	442
Peyr√©, Gabriel. "	O	O	Reply	442
Entropic approximation of Wasserstein gradient flows."	O	O	Reply	442
SIAM Journal on Imaging Sciences 8.4 (2015): 2323-2351.	O	O	Reply	442

This paper proposes a new method for estimating optimal transport plans and maps among continuous distributions, or discrete distributions with large support size.	O	O	Review	442
First, the paper proposes a dual algorithm to estimate Kantorovich plans, i.e. a coupling between two input distributions minimizing a given cost function, using dual functions parameterized as neural networks.	O	O	Review	442
Then an algorithm is given to convert a generic plan into a Monge map, a deterministic function from one domain to the other, following the barycenter of the plan.	O	O	Review	442
The algorithms are shown to be consistent, and demonstrated to be more efficient than an existing semi-dual algorithm.	O	O	Review	442
Initial applications to domain adaptation and generative modeling are also shown.	O	O	Review	442
<sep> <sep> These algorithms seem to be an improvement over the current state of the art for this problem setting, although more of a discussion of the relationship to the technique of Genevay et al would be useful: how does your approach compare to the full-dual, continuous case of that paper if you simply replace their ball of RKHS functions with your class of deep networks?	B-Review	B-1	Review	442
<sep> <sep> The consistency properties are nice, though they don't provide much insight into the rate at which epsilon should be decreased with n or similar properties.	B-Review	B-2	Review	442
The proofs are clear, and seem correct on a superficial readthrough; I have not carefully verified them.	I-Review	I-2	Review	442
<sep> <sep> The proofs are mainly limited in that they don't refer in any way to the class of approximating networks or the optimization algorithm, but rather only to the optimal solution.	B-Review	B-3	Review	442
Although of course proving things about the actual outcomes of optimizing a deep network is extremely difficult, it would be helpful to have some kind of understanding of how the class of networks in use affects the solutions.	I-Review	I-3	Review	442
In this way, your guarantees don't say much more than those of Arjovsky et al who must assume that their "critic function" reaches the global optimum: essentially you add a regularization term, and show that as the regularization decreases it still works, but under seemingly the same kind of assumptions as Arjovsky et al's approach which does not add an explicit regularization term at all.	I-Review	I-3	Review	442
Though it makes sense that your regularization might lead to a better estimator, you don't seem to have shown so either in theory or empirically.	I-Review	I-3	Review	442
<sep> <sep> The performance comparison to the algorithm of Genevay et al is somewhat limited: it is only on one particular problem, with three different hyperparameter settings.	B-Review	B-4	Review	442
Also, since Genevay et al propose using SAG for their algorithm, it seems strange to use plain SGD; how would the results compare if you used SAG (or SAGA/etc) for both algorithms?	I-Review	I-4	Review	442
<sep> <sep> In discussing the domain adaptation results, you mention that the L2 regularization "works very well in practice," but don't highlight that although it slightly outperforms entropy regularization in two of the problems, it does substantially worse in the other.	B-Review	B-5	Review	442
Do you have any guesses as to why this might be?	I-Review	I-5	Review	442
<sep> <sep> For generative modeling: you do have guarantees that, *if* your optimization and function parameterization can reach the global optimum, you will obtain the best map relative to the cost function.	B-Review	B-6	Review	442
But it seems that the extent of these guarantees are comparable to those of several other generative models, including WGANs, the Sinkhorn-based models of Genevay et al (2017, <a href="https://arxiv.org/abs/1706.00292/)," target="_blank" rel="nofollow">https://arxiv.org/abs/1706.00292/),</a> or e.g. with a different loss function the MMD-based models of Li, Swersky, and Zemel (ICML 2015) / Dziugaite, Roy, and Ghahramani (UAI 2015).	I-Review	I-6	Review	442
The different setting than the fundamental GAN-like setup of those models is intriguing, but specifying a cost function between the source and the target domains feels exceedingly unnatural compared to specifying a cost function just within one domain as in these other models.	I-Review	I-6	Review	442
<sep> <sep> Minor:	O	O	Review	442
<sep> In (5), what is the purpose of the -1 term in R_e?	B-Review	B-7	Review	442
It seems to just subtract a constant 1 from the regularization term.	I-Review	I-7	Review	442
Dear reviewer,	O	O	Reply	442
<sep> We thank you for your positive review and detailed comments.	O	O	Reply	442
<sep> <sep> "how does your approach compare to the full-dual, continuous case of that paper [..]‚Äù	O	O	Reply	442
<sep> Conceptually there is no difference.	B-Reply	B-1	Reply	442
The main advantage of using NNs lies in the implementation side: using kernel expansions has a O((iteration index)^2) cost per iterations, while using NNs keeps a constant O(batch size) cost.	I-Reply	I-1	Reply	442
<sep> <sep> We have added a paragraph ‚ÄúConvergence rates and computational cost comparison‚Äù.	I-Reply	I-1	Reply	442
<sep> <sep> "The consistency properties are nice, though they don't provide much insight into the rate [..].‚Äù	O	O	Reply	442
<sep> -For a fixed number of samples and the reg.	B-Reply	B-2	Reply	442
decreasing to 0:  Cominetti & Saint Martin (1994) proved an exponential rate for the convergence of the entropy-reg.	I-Reply	I-2	Reply	442
OT plans to a non-regularized OT plan.	I-Reply	I-2	Reply	442
This  asymptotic result does not let infer a regularization value to achieve a given error.	I-Reply	I-2	Reply	442
Building on top of these results would deserve a study in its own right.	I-Reply	I-2	Reply	442
<sep> <sep> -When reg.	B-Reply	B-2	Reply	442
is fixed (or 0), and the number of samples grows to inf.:	I-Reply	I-2	Reply	442
Several works study convergence rates of empirical Wasserstein distances (i.e. the OT objective between empirical measures).	I-Reply	I-2	Reply	442
Boissard (2011), Sriperumbudur et al (2012) (thanks to reviewer 4 for this ref.),	I-Reply	I-2	Reply	442
Boissard & Le Gouic (2014), to name a few.	I-Reply	I-2	Reply	442
However we are not aware of work addressing the same questions for the empirical OT plans (and not just the OT objective).	I-Reply	I-2	Reply	442
We believe this problem is more complicated.	I-Reply	I-2	Reply	442
<sep> <sep> Since our results relate to the convergence of OT plans, we believe they are new and of interest.	B-Reply	B-2	Reply	442
Without them, our discussion in the introduction and experiments would not be theoretically well grounded: we could not justify that the image of a source measure through the learned Monge map approximates well the target measure, at least for some n big and eps small (Corollary 1).	I-Reply	I-2	Reply	442
We understand that convergence rates are more useful and will investigate this in future work.	I-Reply	I-2	Reply	442
<sep> <sep> "The proofs are mainly limited in that they don't refer in any way to the class of approximating networks [...] essentially you add a regularization term, and show that as the regularization decreases it still works, but under seemingly the same kind of assumptions as Arjovsky et al's approach which does not add an explicit regularization term at all. [...]"	O	O	Reply	442
<sep> <sep> In a discrete setting, our Alg.	B-Reply	B-3	Reply	442
1 computes the exact regularized-OT since we are maximizing a concave objective without parameterizing the dual variables.	I-Reply	I-3	Reply	442
<sep> <sep> Whenever the problem involves continuous measure(s), our NN parameterization only gives the exact solution when the latter belongs to this approximating class of NNs (and the global maximum is obtained).	I-Reply	I-3	Reply	442
<sep> <sep> As you wrote, we do believe that this parameterization provides a ‚Äúsmoother‚Äù solution.	I-Reply	I-3	Reply	442
But as we already have some entropic or L2 regularization in the OT problem, we find it complicated to analyze.	I-Reply	I-3	Reply	442
Still, we agree that this is an interesting problem to investigate.	I-Reply	I-3	Reply	442
<sep> Arjovsky et al used indeed the same idea of deep NN  parameterization.	I-Reply	I-3	Reply	442
However, their NN has to Lipschitz, which they enforce by weights clipping.	I-Reply	I-3	Reply	442
This is unclear whether a NN with bounded weights can approximate any Lipschitz function.	I-Reply	I-3	Reply	442
In our case, there is no restriction on the type of NNs.	I-Reply	I-3	Reply	442
<sep> <sep> "The performance comparison to the algorithm of Genevay et al is somewhat limited [...] how would the results compare if you used SAG (or SAGA/etc) for both algorithms?"	O	O	Reply	442
<sep> <sep> We plan to add numerical-speed experiments in the paper soon.	B-Reply	B-4	Reply	442
<sep> <sep> Genevay et al used SAG in the discrete setting (but used SGD in other settings).	I-Reply	I-4	Reply	442
We prefer 1) providing a unified alg.	I-Reply	I-4	Reply	442
regardless of the measures being discrete or continuous, 2) proposing an alg.	I-Reply	I-4	Reply	442
which fits in automatic-differentiation softwares (Tensorflow, Torch etc.),	I-Reply	I-4	Reply	442
which often do not support SAG.	I-Reply	I-4	Reply	442
<sep> <sep> "In discussing the domain adaptation results, you mention that the L2 regularization "works very well in practice," [...]."	O	O	Reply	442
<sep> <sep> We have removed this sentence.	B-Reply	B-5	Reply	442
It is still unclear which regularization works better in practice depending on the problem.	I-Reply	I-5	Reply	442
Our only claim is that the L2 reg.	I-Reply	I-5	Reply	442
is numerically more stable than the entropic one.	I-Reply	I-5	Reply	442
<sep> <sep> "For generative modeling: you do have guarantees that, *if* [...] but specifying a cost function between the source and the target domains feels exceedingly unnatural [‚Ä¶].‚Äù	O	O	Reply	442
<sep> Indeed, most generative models focus on fitting a generator to a target distribution, without optimality criteria.	B-Reply	B-6	Reply	442
Yet we believe that looking for generator which has properties can be useful for some applications.	I-Reply	I-6	Reply	442
We see this experiment as a proof-of-concept that the learned Monge map can be good generator.	I-Reply	I-6	Reply	442
We encourage and will consider future work where optimality of the generator (w.r.t.	I-Reply	I-6	Reply	442
to a cost) is important (such as image-to-image / text-to-text translations).	I-Reply	I-6	Reply	442
<sep> <sep> "In (5), what is the purpose of the -1 term in R_e?	O	O	Reply	442
It seems to just subtract a constant 1 from the regularization term.	O	O	Reply	442
‚Äù	O	O	Reply	442
<sep> You are right.	B-Reply	B-7	Reply	442
It provides a simpler formulation in the primal-dual relationship Eq. (7) (this is also used in Genevay et al (2016), Peyr√© (2016)).	I-Reply	I-7	Reply	442

The paper proves the weak convergence of the regularised OT problem to Kantorovich / Monge optimal transport problems.	O	O	Review	442
<sep> <sep> I like the weak convergence results, but this is just weak convergence.	B-Review	B-1	Review	442
It appears to be an overstatement to claim that the approach "nearly-optimally" transports one distribution to the other (Cf e.g. Conclusion).	I-Review	I-1	Review	442
There is a penalty to pay for choosing a small epsilon -- it seems to be visible from Figure 2.	I-Review	I-1	Review	442
Also, near-optimality would refer to some parameters being chosen in the best possible way.	I-Review	I-1	Review	442
I do not see that from the paper.	I-Review	I-1	Review	442
However, the weak convergence results are good.	I-Review	I-1	Review	442
<sep> <sep> A better result, hinting on how "optimal" this can be, would have been to guarantee that the solution to regularised OT is within f(epsilon) from the optimal one, or from within f(epsilon) from the one with a smaller epsilon (more possibilities exist).	B-Review	B-2	Review	442
This is one of the things experimenters would really care about -- the price to pay for regularisation compared to the unknown unregularized optimum.	I-Review	I-2	Review	442
<sep> <sep> I also like the choice of the two regularisers and wonder whether the authors have tried to make this more general, considering other regularisations ?	B-Review	B-3	Review	442
After all, the L2 one is just an approximation of the entropic one.	I-Review	I-3	Review	442
<sep> <sep> Typoes:	B-Review	B-4	Review	442
<sep> 1- Kanthorovich -> Kantorovich (Intro)	I-Review	I-4	Review	442
2- Cal C <-> C (eq.4)	I-Review	I-4	Review	442
Dear reviewer,	O	O	Reply	442
<sep> We thank you for your positive review and relevant comments.	O	O	Reply	442
<sep> <sep> "I like the weak convergence results, but this is just weak convergence.	O	O	Reply	442
It appears to be an overstatement to claim that the approach "nearly-optimally" transports one distribution to the other (Cf e.g. Conclusion).	O	O	Reply	442
There is a penalty to pay for choosing a small epsilon -- it seems to be visible from Figure 2.	O	O	Reply	442
Also, near-optimality would refer to some parameters being chosen in the best possible way.	O	O	Reply	442
I do not see that from the paper.	O	O	Reply	442
However, the weak convergence results are good."	O	O	Reply	442
<sep> <sep> Theorem 1.	B-Reply	B-1	Reply	442
proves weak convergence of regularized discrete plans.	I-Reply	I-1	Reply	442
This is a natural convergence for random variables (we emphasize that weak convergence is equivalent to the convergence w.r.t.,	I-Reply	I-1	Reply	442
for instance, the Wasserstein distance).	I-Reply	I-1	Reply	442
Regarding the convergence of Monge maps (in Theorem 2), other types of convergence, such as convergence in probability, would be of great interest indeed.	I-Reply	I-1	Reply	442
We may consider this problem in some future work.	I-Reply	I-1	Reply	442
<sep> <sep> Using the term 'nearly-optimality' was indeed vague as we have not defined what ‚Äònearly‚Äô means.	I-Reply	I-1	Reply	442
We have removed this expression from the the paper.	I-Reply	I-1	Reply	442
Otherwise, ‚Äòoptimal‚Äô or ‚Äòoptimality‚Äô refers to a solution of either the Monge problem (1), the OT problem (2), or the regularized OT problem (3).	I-Reply	I-1	Reply	442
<sep> <sep> ‚ÄúA better result, hinting on how "optimal" this can be, would have been to guarantee that the solution to regularised OT is within f(epsilon) from the optimal one, or from within f(epsilon) from the one with a smaller epsilon (more possibilities exist).	O	O	Reply	442
This is one of the things experimenters would really care about -- the price to pay for regularisation compared to the unknown unregularized optimum.	O	O	Reply	442
‚Äù	O	O	Reply	442
<sep> We can indeed consider two cases when to measure how a solution to the regularized OT (ROT) problem is ‚Äòoptimal‚Äô:	B-Reply	B-2	Reply	442
- How close in the solution of ROT to the solution of OT w.r.t.a given norm: in the discrete case, the paper of Cominetti & Saint Martin (1994) proves asymptotic exponential convergence rate for the entropic regularization case.	I-Reply	I-2	Reply	442
We are not aware of similar result for the L2 regularization, which would be of great interest and deserves a study in its own right.	I-Reply	I-2	Reply	442
In the continuous-continuous case, the recent paper from Carlier et al (2017) only provides convergence results of entropy-regularized plans.	I-Reply	I-2	Reply	442
<sep> - How optimal is the OT objective computed with the solution of ROT: in that case various bounds about the ROT objective compared to the OT objective can be used.	I-Reply	I-2	Reply	442
See for example Blondel et al (2017) which provides bounds for both entropic and L2 regularizations.	I-Reply	I-2	Reply	442
<sep> <sep> ‚ÄúI also like the choice of the two regularisers and wonder whether the authors have tried to make this more general, considering other regularisations ?	O	O	Reply	442
After all, the L2 one is just an approximation of the entropic one.	O	O	Reply	442
‚Äù	O	O	Reply	442
<sep> This is indeed be possible.	B-Reply	B-3	Reply	442
To extend our approach seamlessly, it would be sufficient that the regularizer R verifies: convexity, which ensures that the dual is well defined and unconstrained, and decomposability, which provides a dual of the form Eq. (6).	I-Reply	I-3	Reply	442
More details are given in Blondel et al (2017).	I-Reply	I-3	Reply	442
We have added a small discussion about it in the main text of the updated paper, in the paragraph "Regularized OT dual".	I-Reply	I-3	Reply	442
<sep> <sep> ‚ÄúTypoes:	O	O	Reply	442
1- Kanthorovich -> Kantorovich (Intro)	O	O	Reply	442
2- Cal C <-> C (eq.4)‚Äù	O	O	Reply	442
<sep> This has been corrected, thank you.	B-Reply	B-4	Reply	442
<sep> <sep> References not in the paper:	O	O	Reply	442
Carlier, Guillaume, et al "Convergence of entropic schemes for optimal transport and gradient flows."	O	O	Reply	442
SIAM Journal on Mathematical Analysis 49.2 (2017): 1385-1418.	O	O	Reply	442

Quality	O	O	Review	442
The theoretical results presented in the paper appear to be correct.	O	O	Review	442
However, the experimental evaluation is globally limited,  hyperparameter tuning on test which is not fair.	O	O	Review	442
<sep> <sep> Clarity	O	O	Review	442
The paper is mostly clear, even though some parts deserve more discussion/clarification (algorithm, experimental evaluation).	O	O	Review	442
<sep> <sep> Originality	O	O	Review	442
The theoretical results are original, and the SGD approach is a priori original as well.	O	O	Review	442
<sep> <sep> Significance	O	O	Review	442
The relaxed dual formulation and OT/Monge maps convergence results are interesting and can of of interest for researchers in the area, the other aspects of the paper are limited.	O	O	Review	442
<sep> <sep> Pros:	O	O	Review	442
-Theoretical results on the convergence of OT/Monge maps	O	O	Review	442
-Regularized formulation compatible with SGD	O	O	Review	442
Cons	O	O	Review	442
-Experimental evaluation limited	B-Review	B-4	Review	442
-The large scale aspect lacks of thorough analysis	B-Review	B-7	Review	442
-The paper presents 2 contributions but at then end of the day, the development of each of them appears limited	B-Review	B-10	Review	442
<sep> Comments:	O	O	Review	442
<sep> -The weak convergence results are interesting.	B-Review	B-1	Review	442
However, the fact that no convergence rate is given makes the result weak.	I-Review	I-1	Review	442
<sep> In particular, it is possible that the number of examples needed for achieving a given approximation is at least exponential.	I-Review	I-1	Review	442
<sep> This can be coherent with the problem of Domain Adaptation that can be NP-hard even under the co-variate shift assumption (Ben-David&Urner, ALT2012).	B-Review	B-2	Review	442
<sep> Then, I think that the claim of page 6 saying that Domain Adaptation can be performed "nearly optimally" has then to be rephrased.	I-Review	I-2	Review	442
<sep> I think that results show that the approach is theoretically justified but optimality is not here yet.	O	O	Review	442
<sep> <sep> Theorem 1 is only valid for entropy-based regularizations, what is the difficulty for having a similar result with L2 regularization?	B-Review	B-3	Review	442
<sep> <sep> -The experimental evaluation on the running time is limited to one particular problem.	B-Review	B-4	Review	442
If this subject is important, it would have been interesting to compare the approaches on other large scale problems and possibly with other implementations.	I-Review	I-4	Review	442
<sep> It is also surprising that the efficiency the L2-regularized version is not evaluated.	I-Review	I-4	Review	442
<sep> For a paper interesting in large scale aspects, the experimental evaluation is rather weak.	I-Review	I-4	Review	442
<sep> The 2 methods compared in Fig 2 reach the same objective values at convergence, but is there any particular difference in the solutions found?	B-Review	B-5	Review	442
<sep> <sep> -Algorithm 1 is presented without any discussion about complexity, rate of convergence.	B-Review	B-6	Review	442
Could the authors discuss this aspect?	I-Review	I-6	Review	442
<sep> The presentation of this algo is a bit short and could deserve more space (in the supplementary)	I-Review	I-6	Review	442
<sep> -For the DA application, the considered datasets are classic but not really "large scale", anyway this is a minor remark.	O	O	Review	442
<sep> The setup is not completely clear, since the approach is interesting for out of sample data, so I would expect the map to be computed on a small sample of source data, and then all source instances to be projected on target with the learned map.	B-Review	B-7	Review	442
This point is not very clear and we do not know how many source instances are used to compute the mapping - the mapping is incomplete on this point while this is an interesting aspect of the paper: this justifies even more the large scale aspect is the algo need less examples during learning to perform similar or even better classification.	I-Review	I-7	Review	442
<sep> Hyperparameter tuning is another aspect that is not sufficiently precise in the experimental setup: it seems that the parameters are tuned on test (for all methods), which is not fair since target label information will not be available from a practical standpoint.	B-Review	B-8	Review	442
<sep> <sep> The authors claim that they did not want to compete with state of the art DA, but the approach of Perrot et al 2016 seems to a have a similar objective and could be used as a baseline.	B-Review	B-9	Review	442
<sep> <sep> Experiments on generative optimal transport are interesting and probably generate more discussion/perspectives.	O	O	Review	442
<sep> <sep> --	O	O	Review	442
After rebuttal	O	O	Review	442
--	O	O	Review	442
Authors have answered to many of my comments, I think this is an interesting paper, I increase my score.	O	O	Review	442
<sep> <sep> Dear reviewer,	O	O	Reply	442
<sep> We thank you for your positive review and have updated the paper accordingly.	O	O	Reply	442
<sep> <sep> ‚Äú-The weak convergence results are interesting.	O	O	Reply	442
However, the fact that no convergence rate is given makes the result weak. [‚	O	O	Reply	442
Ä¶] approximation is at least exponential.	O	O	Reply	442
‚Äù	O	O	Reply	442
<sep> We thank Reviewer4 for the clarification and reference.	B-Reply	B-1	Reply	442
Indeed, we expect that the number of samples to achieve a given error on the OT plans grows exponentially with the dimension since it was proven in the case of the OT objective (Boissard (2011), Sriperumbudur et al (2012), Boissard & Le Gouic (2014)), and we expect the behavior is at least as ‚Äòbad‚Äô for the convergence of OT plans.	I-Reply	I-1	Reply	442
An interesting line of research, mentioned in conclusion of Weed and Bach (2017) is to investigate whether regularization helps improve these rates.	I-Reply	I-1	Reply	442
<sep> <sep> Regarding the convergence rates of empirical OT plans, we believe this is an interesting but complex topic which deserves a study in its own right.	I-Reply	I-1	Reply	442
To our knowledge, there are works proving convergence rates of the empirical OT objective (see ref.	I-Reply	I-1	Reply	442
above), but none about convergence rates of OT plans.	I-Reply	I-1	Reply	442
<sep> <sep> ‚Äú[...]DA can be performed "nearly optimally" has then to be rephrased.	O	O	Reply	442
‚Äù	O	O	Reply	442
<sep> We agree and have rephrased accordingly.	B-Reply	B-2	Reply	442
<sep> <sep> ‚ÄúTheorem 1[...], what is the difficulty for having a similar result with L2 regularization?‚Äù	O	O	Reply	442
<sep> Our proofs rely partly on asymptotic convergence rates of entropy-reg linear programs established by Cominetti & Saint Martin (1994).	B-Reply	B-3	Reply	442
To our knowledge, no extension has been obtained for L2-reg linear programs, which prevents us from adapting our proofs.	I-Reply	I-3	Reply	442
Extending these results to the L2 case would be indeed of great interest.	I-Reply	I-3	Reply	442
<sep> <sep> ‚Äú-The experimental evaluation on the running time is limited [‚Ä¶]. It is also surprising that the efficiency the L2-regularized version is not evaluated. [‚	O	O	Reply	442
Ä¶], the experimental evaluation is rather weak.	O	O	Reply	442
‚Äù	O	O	Reply	442
<sep> No algorithm for computing the L2-reg OT in large-scale or continuous settings have been proposed.	B-Reply	B-4	Reply	442
Hence, we do not know other algorithms to compare with.	I-Reply	I-4	Reply	442
<sep> <sep> We mention that our experiments are large-scale considering the OT problem.	I-Reply	I-4	Reply	442
For ex.,	I-Reply	I-4	Reply	442
Genevay et al (2016) considered measures supported on 20k samples, while  measures in our numerical-speed xp have 250k samples.	I-Reply	I-4	Reply	442
However, we agree that more numerical-speed xps would make our proposed Alg.	I-Reply	I-4	Reply	442
1 more convincing and will add experiments.	I-Reply	I-4	Reply	442
<sep> ‚ÄúThe 2 methods compared in Fig 2 [...], is there any particular difference in the solutions found?‚Äù	O	O	Reply	442
<sep> We performed speed-comparison experiments in the discrete setting, where the dual objective is strictly concave with a unique solution.	B-Reply	B-5	Reply	442
The semi-dual objective is also strictly concave, and the dual variable solution of the semi-dual is the same as the first dual variable of the dual problem.	I-Reply	I-5	Reply	442
<sep> <sep> ‚Äú-Algorithm 1 is presented without any discussion about complexity, rate of convergence.	O	O	Reply	442
‚Äù	O	O	Reply	442
<sep> We agree and have added a paragraph ‚ÄúConvergence rates and computational cost comparison‚Äù.	B-Reply	B-6	Reply	442
<sep> <sep> ‚ÄúThe setup is not completely clear, since the approach is interesting for out of sample data, so I would expect the map to be computed on a small sample of source data, and then all source instances to be projected on target with the learned map. [‚	O	O	Reply	442
Ä¶] needs less examples during learning to perform similar or even better classification.	O	O	Reply	442
‚Äù	O	O	Reply	442
<sep> One of our contribution is indeed to allow out-of-sample prediction which avoids learning again a full transport map if one dataset is augmented.	B-Reply	B-7	Reply	442
But learning a Monge map is a very difficult problem and one should use all the available data, which is now possible thanks to our proposed stochastic algorithms.	I-Reply	I-7	Reply	442
The fact that Perrot et al (2016) used at most 1000 samples was due to the numerical complexity of the mapping estimation alg.	I-Reply	I-7	Reply	442
<sep> <sep> ‚ÄúHyperparameter tuning is another aspect that is not sufficiently precise in the experimental setup: it seems that the parameters are tuned on test [‚Ä¶].‚Äù	O	O	Reply	442
<sep> The parameter validation tuned on test is indeed unrealistic because we have indeed not access to target samples labels in practice.	B-Reply	B-8	Reply	442
Still we believe it is reasonable and fair since it allows all methods to work at their best, without relying on approximate validation that might benefit one method over another.	I-Reply	I-8	Reply	442
Note that unsupervised DA validation is still an open problem: some authors perform as we did; or do validation using labels; others do more realistic but less stable techniques such as circular validation.	I-Reply	I-8	Reply	442
<sep> <sep> ‚ÄúThe authors claim that they did not want to compete with state of the art DA, but the approach of Perrot et al 2016 seems to a have a similar objective and could be used as a baseline.	O	O	Reply	442
‚Äù	O	O	Reply	442
<sep> We cannot compare fairly to Perrot et al (2016) &nbsp;since they used a very small number of sample to estimate a map.	B-Reply	B-9	Reply	442
But this would be a good baseline to show the importance of learning with a many samples.	I-Reply	I-9	Reply	442
The method will be added to the xps very soon.	I-Reply	I-9	Reply	442
<sep> <sep> Reference not in the paper:	O	O	Reply	442
-Weed, Jonathan, and Francis Bach. "	B-Reply	B-10	Reply	442
Sharp asymptotic and finite-sample rates of convergence of empirical measures in Wasserstein distance."	I-Reply	I-10	Reply	442
arXiv	I-Reply	I-10	Reply	442

Neural process (NP) is a recent probablistic method for modeling distributions of functions.	O	O	Review	442
The authors claim that one substantial weakness of NP is the tendency of under-fitting.	O	O	Review	442
The authors give a hypoethesize: the under-fitting behaviour of NP is because the mean-aggregation step in the encoder acts as a bottleneck, as a result, it is difficult for the decoder to learn the relevant information for a give target prediction.	O	O	Review	442
This paper proposes to resolve this issue by adding an attention mechanism to the deterministic path.	O	O	Review	442
The experimental results show that the proposed method converge faster and give better results on various tasks.	O	O	Review	442
<sep> <sep> One major concern about the paper is the lack of analysis of the true cause of under-fitting in NP.	B-Review	B-1	Review	442
The authors give the hypoethesize about the potential cause of the under-fitting issue and proposes to resolve it with attention, however, without theoretical or empirical analyses, it is hard to understand the true cause of the under-fitting issue.	I-Review	I-1	Review	442
Although the proposed method give better performance, it is not clear whether the better performance is due to the added complexity to the model (the attention mechanism) or truely resolving the under-fitting issue.	I-Review	I-1	Review	442
Some analyses along this line can make the paper clearer and more convincing.	I-Review	I-1	Review	442
<sep> <sep> A lot of technical details are missing in the paper, which makes the method not reproducible.	B-Review	B-2	Review	442
Please add more details about the proposed attention mechanism and how they are implemented into NP.	I-Review	I-2	Review	442
<sep> <sep> In the GP literature, there are also methods tackling meta-learning or multi-task learning or few shot learning.	B-Review	B-3	Review	442
These works are known as multi-output / multi-tasks Gaussian processes.	I-Review	I-3	Review	442
A few works on this topic are listed:	I-Review	I-3	Review	442
* Z Dai, MA √Ålvarez, ND Lawrence, Efficient Modeling of Latent Information in Supervised Learning using Gaussian Processes, NIPS 2017	I-Review	I-3	Review	442
* MA Alvarez, L Rosasco, ND Lawrence, Kernels for vector-valued functions: A review, Foundations and Trends¬Æ in Machine Learning 2012	I-Review	I-3	Review	442
* EV Bonilla, KM Chai, C Williams, Multi-task Gaussian process prediction, NIPS 2007	I-Review	I-3	Review	442
<sep> For the 1D regression experiments (Figure 1left, Figure 3right), it is not clear which fitting is better.	B-Review	B-4	Review	442
It largely depends on the prior of kerel parameters.	I-Review	I-4	Review	442
As the data points are generated from a GP, plotting the Gaussian process fit with the ground truth parameters can show what a ground truth fitting would look like.	I-Review	I-4	Review	442
<sep> <sep> The Bayesian optimization experiment is very nice and gives some good insights about the quality of the uncertainty of prediction.	B-Review	B-5	Review	442
Maybe consider it to include it in the main text.	I-Review	I-5	Review	442
We would like to thank you for your constructive criticism of the paper.	O	O	Reply	442
Here are our responses:	O	O	Reply	442
<sep> ‚ÄúThe authors give the hypoethesize about the potential cause of the under-fitting issue and proposes to resolve it with attention‚Ä¶. Although the proposed method give better performance, it is not clear whether the better performance is due to the added complexity to the model (the attention mechanism) or truely resolving the under-fitting issue‚Äù	O	O	Reply	442
<sep> Our reasoning that the mean-aggregation acts as a bottleneck is as follows.	B-Reply	B-1	Reply	442
In NPs, the aggregated representations r_C and s_C needs to have information about the particular function (the realisation of the stochastic process) not only at the context x-values but for all x-values in the domain for the predictions to generalise well to unseen targets.	I-Reply	I-1	Reply	442
When we compute these aggregated representations simply by taking the mean of representations of each context pair, it will be difficult for the resulting representation to model the entire function, and may require a large representation dimensionality.	I-Reply	I-1	Reply	442
On the other hand, cross-attention allows the aggregated representation r* to be specific to the target x-value x*, so that it suffices for the representation r* to only be informative about the prediction at x* instead of all x-values in the domain.	I-Reply	I-1	Reply	442
We claim that this inductive bias allows the ANP to resolve the undefitting issue, not just because of the added model capacity (i.e. more parameters) that attention introduces.	I-Reply	I-1	Reply	442
As evidence for this, on the left of Figure 3 we show quantitative results for differing sizes of the bottleneck in NPs, ranging from d=128 to 1024.	I-Reply	I-1	Reply	442
The figure shows that raising d (i.e. increasing model capacity) does help achieve better reconstructions, but there seems to be a limit in how much the reconstructions can improve, hence showing that naively adding capacity to the model is insufficient in addressing the underfitting behaviour.	I-Reply	I-1	Reply	442
We show that multihead (and dot-product) attention with d=128 gives a much faster decrease in the reconstructions than NPs with any value of d, both against iteration and wall-clock time.	I-Reply	I-1	Reply	442
We would also like to point out that the number of parameters in the NP model for bottleneck size d is approximately 10d^2 (ignoring smaller order terms), whereas for multihead it is 15d^2 (so cross-attention introduces 5d^2 extra parameters).	I-Reply	I-1	Reply	442
So the number of parameters of NP with d=1024 is much higher than that of multihead with d=128, yet we can get noticeably better performance with multihead attention.	I-Reply	I-1	Reply	442
Hence the improvement in performance is mostly due to the attention mechanism rather than the increase in model complexity (i.e. number of parameters).	I-Reply	I-1	Reply	442
<sep> <sep> <sep> ‚ÄúA lot of technical details are missing in the paper, which makes the method not reproducible.	O	O	Reply	442
‚Äù	O	O	Reply	442
<sep> In addition to the experimental and model architecture details in Appendix A, we have included Figure 8 detailing the precise architecture for the different models.	B-Reply	B-2	Reply	442
We believe this is sufficient to reproduce the method, but if you think anything is missing please do let us know and we revise the experimental details accordingly.	I-Reply	I-2	Reply	442
<sep> <sep> <sep> ‚ÄúIn the GP literature, there are also methods tackling meta-learning or multi-task learning or few shot learning.	O	O	Reply	442
‚Äù	O	O	Reply	442
<sep> Thank you for pointing out these references.	B-Reply	B-3	Reply	442
We agree that these are relevant work and have added them to the related work section of the paper.	I-Reply	I-3	Reply	442
<sep> <sep> <sep> ‚ÄúFor the 1D regression experiments (Figure 1left, Figure 3right), it is not clear which fitting is better.	O	O	Reply	442
It largely depends on the prior of kerel parameters.	O	O	Reply	442
As the data points are generated from a GP, plotting the Gaussian process fit with the ground truth parameters can show what a ground truth fitting would look like.	O	O	Reply	442
‚Äù	O	O	Reply	442
<sep> In the revised version of the paper, we have included Figure 9 showing the predictive mean and variance of the oracle GP from which the contexts were drawn for comparison in Appendix C. Note that the data was generated from a GP with small observation noise (sigma_n = 0.02), so we do want the predictive mean to pass through the contexts with predictive variance small near the context points and large away from them.	B-Reply	B-4	Reply	442
It is clear that the Multihead ANP is much closer to the ground truth than the NP with very accurate predictive mean, despite there being evidence of underestimating the variance away from the contexts - one possible explanation for this is that variational inference usually leads to underestimates of predictive variance.	I-Reply	I-4	Reply	442

This paper is a joy to review, as it is clearly written and has a crisp idea that the authors try to motivate consistently.	O	O	Review	442
<sep> It extends the framework of neural processes and conditional neural processes by an incremental seeming idea: self attention on the conditioning set and cross attention.	O	O	Review	442
What this means in practice is that the model is able to learn a more detailed and structured 'kernel' between query and past data which allows it to identify and model conditional structure better.	O	O	Review	442
<sep> <sep> The authors try three main prongs of such attention mechanisms with the multi-head attention appearing to be the most successful one in the experiments.	O	O	Review	442
<sep> <sep> Regarding experiments, the authors show a 1d function gitting example and various conditional image generation ones, similar to the original examples in the paper.	O	O	Review	442
While I find the function fitting exampole quite unconvin cing, it arguably also contains less interesting structure for the model to pick up.	O	O	Review	442
<sep> In the image generation examples both he quantitative and the qualitative illustrations appear to indicate that a very rich conditioning apparatus (stacked multi head attention) manages to give the model more detailed generative abilities.	O	O	Review	442
<sep> While introducing all this machinery seems a bit over-engineered at times, the results do show a benefit.	O	O	Review	442
<sep> <sep> Overall I find the exposition of the effects of the attention mechanism very well executed and the paper clearly positioned and written.	O	O	Review	442
My main complaint would be the incremental nature of the work, as the contributions here are not as significant advances as some preceding ideas that have gone into this work, but still steadily improve on the vision of NP and appear to be necessary steps to push the model forward giving this work validity on its own.	B-Review	B-1	Review	442
<sep> The authors discuss a similar mechanism for generation, which while more involved would be a very exciting change from the current framework.	B-Review	B-2	Review	442
I would have enjoyed seeing more of that in this paper to discuss input and output attention jointly.	I-Review	I-2	Review	442
<sep> <sep> <sep> <sep> We would like to thank you for your positive review and thoughtful comments.	O	O	Reply	442
Here are our responses:	O	O	Reply	442
<sep> ‚ÄúMy main complaint would be the incremental nature of the work ‚Ä¶ but still steadily improve on the vision of NP and appear to be necessary steps to push the model forward giving this work validity on its own.	O	O	Reply	442
‚Äù	O	O	Reply	442
<sep> Regarding the nature of the work, we show that attention addresses underfitting, which is a fundamental drawback of NPs, so this simple change makes a large difference.	B-Reply	B-1	Reply	442
We show empirically that attention leads to large improvements in training time, expressiveness of the model, and solves the underfitting issue so that ANPs can be used reliably for tasks such as mapping images from one resolution to another.	I-Reply	I-1	Reply	442
Hence as you pointed out, we believe that ANPs are a notable improvement to NPs and is valid work in its own right.	I-Reply	I-1	Reply	442
<sep> <sep> <sep> ‚ÄúThe authors discuss a similar mechanism for generation, which while more involved would be a very exciting change from the current framework.	O	O	Reply	442
‚Äù	O	O	Reply	442
<sep> We gladly agree that the incorporation of self-attention in the decoder is an interesting direction for future research.	B-Reply	B-2	Reply	442
We are currently investigating this avenue as future work.	I-Reply	I-2	Reply	442

Summary:	O	O	Review	442
The authors extend neural processes by incorporating two types of attention processes: self-attention for enriching the features of the context points and cross-attention for producing a query-specific representation.	O	O	Review	442
By replacing MLPs and mean pooling with these attention processes, the authors resolve the underfitting problem of NPs.	O	O	Review	442
The experimental results show that ANPs converge better and faster than NPs.	O	O	Review	442
<sep> <sep> Overall, I had fun to read the paper and have not much to complain.	O	O	Review	442
Below are some comments and questions.	O	O	Review	442
<sep> <sep> 1.	O	O	Review	442
It is intuitive and reasonable that the cross-attention process makes ANPs fit with smaller predictive uncertainty for those regions with many context points.	B-Review	B-1	Review	442
This is well illustrated in the qualitative results in the experiment section.	I-Review	I-1	Review	442
<sep> <sep> 2.	O	O	Review	442
I would like to see an ablation study with the two separate techniques (self- and cross-attention processes) on NPs since the two techniques aim to improve different aspects of NPs.	B-Review	B-2	Review	442
More specifically, I wonder the results of just adding cross-attention with the vanilla MLPs for feature encoding and just replacing the MLPs with self-attention modules while keeping using mean pooling.	I-Review	I-2	Review	442
<sep> <sep> 3.	O	O	Review	442
While the dot product improves the performance significantly, the gain of Laplace is much lower.	B-Review	B-3	Review	442
Also, qualitatively it fails to overcome the underfitting problem.	I-Review	I-3	Review	442
Do you have any intuition about why performs worse than other models?	I-Review	I-3	Review	442
<sep> <sep> 4.	O	O	Review	442
Do you have any specific application in mind?	B-Review	B-4	Review	442
I just wonder some example tasks where contexts are given as inputs.	I-Review	I-4	Review	442
We would like to thank you for your thoughtful review with constructive criticism.	O	O	Reply	442
Here are our responses to your suggestions and questions.	O	O	Reply	442
<sep> <sep> ‚ÄúI would like to see an ablation study with the two separate techniques (self- and cross-attention processes) on NPs‚Äù	O	O	Reply	442
<sep> Regarding the ablation study for using just cross-attention, all the ANP results for 1D GP regression use cross-attention but not self-attention (i.e. have MLP encodings of each context pair).	B-Reply	B-2	Reply	442
Hence the improvements here show the contribution of cross-attention only.	I-Reply	I-2	Reply	442
Figure 4b also shows quantitative results for the CelebA image regression with only cross-attention, denoted Multihead ANP in the legend.	I-Reply	I-2	Reply	442
The counterpart results for MNIST can be found in Figure 13b of Appendix E of the revised version of the paper.	I-Reply	I-2	Reply	442
Qualitative comparisons of the NP, Multihead ANP and Stacked Multihead ANP can be found in Figures 14 and 15.	I-Reply	I-2	Reply	442
It would indeed be helpful to show results for the case when we just have self-attention in the encoder without any cross-attention.	I-Reply	I-2	Reply	442
We are currently running these experiments and will include the results in the next version of the paper.	I-Reply	I-2	Reply	442
<sep> <sep> <sep> ‚ÄúWhile the dot product improves the performance significantly, the gain of Laplace is much lower‚Ä¶ Do you have any intuition about why performs worse than other models?‚Äù	O	O	Reply	442
<sep> Laplace attention is parameter-free (so keys and queries are just x-values) whereas for dot-product attention, the keys and queries are parameterised representations of the x-values (output of learned MLP that takes x-values as inputs).	B-Reply	B-3	Reply	442
So the dot-product similarities are computed in a learned representation space, whereas for Laplace the similarities are computed based on L1 distance in the x-space.	I-Reply	I-3	Reply	442
Hence it is expected that dot-product attention will be able to fit the contexts better than Laplace.	I-Reply	I-3	Reply	442
We have made this clear in the revised version of the paper.	I-Reply	I-3	Reply	442
<sep> <sep> <sep> ‚ÄúDo you have any specific application in mind?‚Äù	O	O	Reply	442
<sep> Bayesian Optimisation (BO) is one notable application of (A)NPs since the predictive mean and uncertainty can be used for finding the minimum of a test function drawn from a stochastic process whose realisations can be used to train the (A)NP (toy experiment results shown in Appendix C, referred to in the last paragraph of the section on 1D experiments in main text).	B-Reply	B-4	Reply	442
The image data experiments also show promise for applying ANPs to arbitrary pixel inpainting, bottom half prediction and mapping images between arbitrary resolutions.	I-Reply	I-4	Reply	442

This paper considers an architecture change to the transformer in which they swap the feedforward subcomponent of the standard transformer with an "attention only" variant that includes persistent "memory" vectors.	O	O	Review	442
The model is evaluated against a suite of baselines on the tasks of character- and word-level language modeling.	O	O	Review	442
Combining this "all attention" approach with adaptive span yields results about equivalent to the SOTA, in some cases with fewer parameters than existing models.	O	O	Review	442
The authors do a nice job of presenting ablation results.	O	O	Review	442
A key finding here, for example, is that the a model stripped of both persistent vectors and the feedforward sublayer performs poorly.	O	O	Review	442
<sep> <sep> Overall, I'm on the fence regarding this submission.	O	O	Review	442
This is solid work, and the idea of exploiting persistent representations in the transformer seems promising.	O	O	Review	442
But the architecture change here is relatively minor, and the gains seem somewhat minor (the exception may be in Table 2 which shows equivalent performance with half the parameters to previous SOTA, but then no other model is in the range of O(100m) parameters, so hard to know what's going on here).	B-Review	B-1	Review	442
<sep> <sep> One thing I would have liked is more motivation.	B-Review	B-2	Review	442
If equivalence with fewer parameters is the main aim, then the model seems to fair reasonably well but the results are not really compelling.	I-Review	I-2	Review	442
If, on the other hand, the authors are primarily interested in exploiting persistence, then I think this could have been investigated a bit more exhaustively, and perhaps the focus need not be on necessarily replacing the feedforward subcomponent (although that is one reasonable strategy).	I-Review	I-2	Review	442
I do not see a huge inherent advantage to removing the feedforward layer, and it seems like there are alternative strategies --- at least equally as good --- to reduce parameters.	I-Review	I-2	Review	442
<sep> <sep> A question for the authors: did you consider a vanilla Transformer with persistent memory vectors added?	B-Review	B-3	Review	442
This would be something like adding a constant dummy input (independent of the example) that would be passed forward and arbitrarily transformed.	I-Review	I-3	Review	442
I guess the meta-point here is that it doesn't seem to me that the persistent representations and the feedforward sublayer are necessarily mutually exclusive.	I-Review	I-3	Review	442
<sep> <sep> As a minor comment, I think Eq 13 is redundant since it literally repeats Eq.4 save for swapping in for.	B-Review	B-4	Review	442
Thank you for the constructive and insightful review.	O	O	Reply	442
Find below our responses to your questions:	O	O	Reply	442
<sep> - ‚Äúno other model is in the range of O(100m) parameters‚Äù:	O	O	Reply	442
- This is true.	B-Reply	B-1	Reply	442
So we added a ‚ÄúTransformer + adaptive-span‚Äù baseline with a similar number of parameters as our model.	I-Reply	I-1	Reply	442
It matched the performance of our model, confirming that our simplification has not degraded the performance.	I-Reply	I-1	Reply	442
However, we would like to point out that we have a similar sized baseline in Table 3, which our model outperformed by a large margin (in appendix B, we also added baselines of a similar size using our implementation to separate out the improvements that could have brought by some of the training details).	I-Reply	I-1	Reply	442
<sep> <sep> - ‚ÄúI would have liked is more motivation‚Äù	O	O	Reply	442
- We agree that our motivation might not have been conveyed clearly enough in the manuscript, so we tried to make it clearer in the updated version.	B-Reply	B-2	Reply	442
Our motivation was to simplify the Transformer architecture without degrading its performance.	I-Reply	I-2	Reply	442
We hope that this simplification will lead to new insights and better analysis of the model.	I-Reply	I-2	Reply	442
But the smaller number of parameters in the word-level LM task is a concrete outcome that, by itself, could justify our approach.	I-Reply	I-2	Reply	442
<sep> <sep> - ‚Äúadding a constant dummy input (independent of the example) that would be passed forward and arbitrarily transformed‚Äù:	O	O	Reply	442
- This is definitely an interesting idea to explore.	B-Reply	B-3	Reply	442
However, it is quite different and orthogonal to our approach because 1) they are transformed at every layer and 2) have learnable parameters only at the embedding layer.	I-Reply	I-3	Reply	442
Because of 2, such a model will require a very large number of dummy inputs to have a comparable number of parameters.	I-Reply	I-3	Reply	442
Because of 1, it would be very slow to train because the dummy inputs have to be re-transformed at every step, thus significantly reducing the parallelism of Transformer models.	I-Reply	I-3	Reply	442

This paper proposes a simple modification to the ubiquitous Transformer model.	O	O	Review	442
Noticing that the feed-forward layer of a Transformer layer looks a bit like an attention over "persistent" memory vectors, the authors propose to explicitly incorporate this notion directly into the self-attention layer.	O	O	Review	442
This involves concatenating the contextual representations with global, learned memory vectors, which are attended over.	O	O	Review	442
<sep> <sep> The model is tested on widedly-utilized character/word-level language modeling benchmarks, where it is found to outperform, or be on par with, existing models while using fewer number of parameters.	O	O	Review	442
<sep> <sep> Insofar as architectural advancements can translate to general improvements across multiple NLP tasks, this paper could be seen as important.	O	O	Review	442
However, I am not sure that in 2019, demonstrating arguably-marginal perplexity improvements on standard datasets is enough.	B-Review	B-1	Review	442
I would love to see if this type of layer can result in better conditional generation models (e.g. translation, summarization), or can train GPT2/BERT/XLNet-style models whose representations better transfer to other tasks.	I-Review	I-1	Review	442
<sep> <sep> I had some further questions/comments:	O	O	Review	442
<sep> - I found the motivation of the persistent memory vector as replacing the FF-layer somewhat tenuous.	B-Review	B-2	Review	442
Eq(5) is definitely different from Eq(9)!	I-Review	I-2	Review	442
In my opinion this work can be better motivated/presented as just a standalone modification to the Transformer layer.	I-Review	I-2	Review	442
<sep> <sep> - While it is impressive that the proposed approach performs better (or on par with, in the case of character-level language modeling) than the previous state-of-the-art models which are larger, to me it is not immediately clear if the benefit is coming from the proposed modifications, or something else (e.g. some of the things mentioned in 4.3).	B-Review	B-3	Review	442
I understand most of this is taking from prior work, but as we all know, in deep models various architectural/hyperparameter modifications can interact in unexpected ways.	I-Review	I-3	Review	442
Therefore, at a minimum, I would like to see the performance of a comparable model with the same exact setting, except for the persistent attention layer (i.e. N = 0 but using the feedforward sublayers). (	I-Review	I-3	Review	442
If I understand the work correctly, this baseline should have comparable number of parameters?)	I-Review	I-3	Review	442
<sep> <sep> - The ablation studies are good but it would be good to see them on the word-level task as well.	B-Review	B-4	Review	442
<sep> <sep> - What is the performance of the FF-attn baseline with the same depth? (	B-Review	B-5	Review	442
I understand the number of parameters would be  larger, but does this model perform as well as the Dai et al 2019 work?)	I-Review	I-5	Review	442
<sep> <sep> - What if you combine this with the FF sublayer as well?	B-Review	B-6	Review	442
<sep> <sep> - Have you tried qualitatively analyzing the attention distributions?	B-Review	B-7	Review	442
What are some examples in which the persistent memory vectors are attended to most?	I-Review	I-7	Review	442
What are some examples in which the attention distribution for this model differs considerly versus regular self-attention layers?	I-Review	I-7	Review	442
<sep> <sep> [EDIT after author rebuttal]	O	O	Review	442
Thank you very much for the rebuttal.	O	O	Review	442
I have updated my score to reflect the latest iteration of the paper.	O	O	Review	442
Thank you for taking time to review our paper and the useful suggestions.	O	O	Reply	442
However, we have to respectfully disagree with the reasoning behind the rejection.	B-Reply	B-1	Reply	442
We agree that having experiments like GPT2/BERT/XLNet-style would make our paper stronger, but this shouldn‚Äôt be a reason for rejection.	I-Reply	I-1	Reply	442
Training such large-scale experiments often take lot of efforts and resources that goes beyond the scope of this paper, and also unlikely to add any more insights to our approach.	I-Reply	I-1	Reply	442
<sep> <sep> The goal of the paper is not to push the state-of-the-art regardless of model size and complexity, but it‚Äôs rather about simplifying the current architecture while maintaining its performance.	I-Reply	I-1	Reply	442
We chose language modeling tasks because it‚Äôs at the core of all those tasks, and rich in baselines of various architectures.	I-Reply	I-1	Reply	442
However, we agree with the point about missing a same-sized baseline, so we added it in the updated version.	I-Reply	I-1	Reply	442
Our model still outperforms this baseline as well as the similar-sized TransformerXL baseline.	I-Reply	I-1	Reply	442
<sep> <sep> Here are our answers to your questions:	O	O	Reply	442
- ‚ÄúEq(5) is definitely different from Eq(9)!‚Äù	O	O	Reply	442
- Yes, they are not exactly the same.	B-Reply	B-2	Reply	442
We added section 4.1 to help readers better understand the intuition behind our method, and how we come up with the idea.	I-Reply	I-2	Reply	442
We modified the introduction to make our motivation more clearer.	I-Reply	I-2	Reply	442
<sep> <sep> - ‚Äúin deep models various architectural/hyperparameter modifications can interact in unexpected ways.	O	O	Reply	442
Therefore, at a minimum, I would like to see the performance of a comparable model with the same exact setting‚Äù	O	O	Reply	442
- This is a great point and we agree that training details can affect the model performance.	B-Reply	B-3	Reply	442
Therefore, as suggested, we added a comparable baseline Transformer trained with our code using exactly the same setting as our model in the appendix B. Although the training diverged in near the end (deep transformer models are known to be unstable during training), we can clearly see its performance is worse than our model.	I-Reply	I-3	Reply	442
<sep> <sep> - ‚ÄúWhat is the performance of the FF-attn baseline with the same depth?‚Äù	O	O	Reply	442
- Comparing the depth of two different architectures is a little problematic.	B-Reply	B-5	Reply	442
A transformer layer actually consists of two sublayers, so its depth could be viewed as 2.	I-Reply	I-5	Reply	442
In that case we added a baseline with 44 sublayers in the appendix B as mentioned above.	I-Reply	I-5	Reply	442
If the depth is the number of transformer layers, then a same-depth baseline would have 36 layers, or 72 sublayers.	I-Reply	I-5	Reply	442
This means it has twice as many nonlinear layers as our model.	I-Reply	I-5	Reply	442
Training a such deep transformer model is known to be very unstable.	I-Reply	I-5	Reply	442
We did try to train it, but the training diverged after 157k updates as shown in the appendix B. We tried to make it more stable by reducing the gradient clipping without success.	I-Reply	I-5	Reply	442
<sep> <sep> - ‚ÄúWhat if you combine this with the FF sublayer as well?‚Äù	O	O	Reply	442
- Combining FF sublayer is an interesting idea that might improve the performance, but as mentioned above, the point of the paper was to simplify the architecture using a single attention mechanism, rather than pushing the limits of the SOTA.	B-Reply	B-6	Reply	442
<sep> <sep> - ‚ÄúHave you tried qualitatively analyzing the attention distributions?‚Äù	O	O	Reply	442
- This is a great question.	B-Reply	B-7	Reply	442
We have tried looking at persistent memory attention qualitatively, but it‚Äôs challenging to find any meaningful persistent vector because there are more than half a million of them.	I-Reply	I-7	Reply	442
Plus, unlike context vectors, they lack any temporal structure or direct connections to input tokens.	I-Reply	I-7	Reply	442
However, we have included sample attention maps in the appendix A, where we observed several different types of patterns.	I-Reply	I-7	Reply	442
The attention over persistent vectors is definitely different from the one over context vectors.	I-Reply	I-7	Reply	442
First they look very random, because they don‚Äôt have any structure.	I-Reply	I-7	Reply	442
Also, we observed that sometimes few persistent vectors would dominate the attention, which could be a focus of a follow-up work.	I-Reply	I-7	Reply	442
<sep> <sep> - ‚ÄúThe ablation studies are good but it would be good to see them on the word-level task as well‚Äù	O	O	Reply	442
- Yes, it would be better to have all the ablation studies on all the datasets.	B-Reply	B-4	Reply	442
However, considering that even training a single word-level model takes a significant amount of resources, we decided to only perform the ablation study on a single dataset.	I-Reply	I-4	Reply	442

This paper proposes an instance-wise feature selection method, which chooses relevant features for each individual sample.	O	O	Review	171
The basic idea is to minimize the KL divergence between the distribution p(Y|X) and p(Y|X^{(s)}).	O	O	Review	171
The authors consider the classification problem and construct three frameworks: 1) a selector network to calculate the selection probability of each feature; 2) a baseline network for classification on all features; 3) a predictor network for classification on selected features.	O	O	Review	171
The goal is to minimize the difference between the baseline loss and predictor loss.	O	O	Review	171
<sep> <sep> The motivation of the paper is clear and the presentation is easy to follow.	O	O	Review	171
However, I have some questions on the model and experiments:	O	O	Review	171
<sep> 1.	O	O	Review	171
How is Eq. (5) formulated?	B-Review	B-1	Review	171
As the selector network does not impact the baseline network, an intuition regarding Eq. (5) is to maximize the predictor loss, which seems not reasonable.	I-Review	I-1	Review	171
It seems more appropriate to use an absolute value of the difference in Eq. (5).	I-Review	I-1	Review	171
Some explanation for the formulation of Eq. (5) would be helpful.	I-Review	I-1	Review	171
<sep> <sep> 2.	B-Review	B-2	Review	171
The model introduces an extra hyper-parameter,, to adjust the sparsity of selected features.	I-Review	I-2	Review	171
I was curious how sensitive is the performance w.r.t.this hyper-parameter.	I-Review	I-2	Review	171
How is determined in the experiments?	I-Review	I-2	Review	171
<sep> <sep> 3.	O	O	Review	171
After the selector network is constructed, how are the features selected on testing data?	B-Review	B-3	Review	171
Is the selection conducted by sampling from the Bernoulli distribution as in training or by directly cutting off the features with lower probabilities?	I-Review	I-3	Review	171
<sep> <sep> Thank you for the insightful comments.	O	O	Reply	171
<sep> <sep> A1: Equation (5) is the difference between the cross-entropies of the predictor and baseline networks.	B-Reply	B-1	Reply	171
The first term (-sum_y log f_i^\phi (x^(s), s)) is the cross-entropy of the predictor network and the second term (-sum y log f_i^\gamma (x)) is the cross-entropy of the baseline network.	I-Reply	I-1	Reply	171
The loss in equation (5) is defined as the ‚Äúfirst term ‚Äì second term‚Äù.	I-Reply	I-1	Reply	171
The selector network is trained to minimize this, not maximize it.	I-Reply	I-1	Reply	171
Note that the baseline network is introduced to reduce the variance of this quantity, and not as a term that the selector network can change (this is a standard technique used in the actor-critic literature).	I-Reply	I-1	Reply	171
<sep> <sep> Also note that if the baseline network term (the second term) in equation (5) is removed, then we simply end up with the predictor loss defined in the ‚ÄúPredictor Network‚Äù section (l_1).	I-Reply	I-1	Reply	171
<sep> <sep> If instead we were to use absolute value, then when the baseline network loss is larger than the predictor network loss, the method would actually be trying to maximise the predictor network loss (which we do not want).	I-Reply	I-1	Reply	171
<sep> <sep> It is important to note that we are not trying to minimize the difference between the predictor and baseline losses - we are using the baseline to reduce the variance of the overall loss and we are simply trying to minimize the predictor loss.	I-Reply	I-1	Reply	171
<sep> <sep> A2: As can be seen in page 13 (subsection ‚ÄúDetails of INVASE‚Äù), we explain that ‚ÄúWe use cross-validation to select lambda among {0.1,0.3,0.5,1,2,5,10}‚Äù.	B-Reply	B-2	Reply	171
We select the lambda which maximizes the predictor accuracy in terms of AUROC.	I-Reply	I-2	Reply	171
We will clarify this in the revised manuscript.	I-Reply	I-2	Reply	171
Below, we give the results for various values of lambda in the Syn4, Syn5, and Syn6 settings.	I-Reply	I-2	Reply	171
More detailed results will be added to the revised manuscript.	I-Reply	I-2	Reply	171
<sep> --------------------------------------------------------------------------------------------------------------------------------------------------	I-Reply	I-2	Reply	171
Datasets             |                   Syn4                   |                   Syn5                   |                   Syn6                   |	I-Reply	I-2	Reply	171
--------------------------------------------------------------------------------------------------------------------------------------------------	I-Reply	I-2	Reply	171
Lambda / Metrics (%)  |         TPR        |      FDR        |         TPR        |      FDR       |         TPR        |      FDR        |	I-Reply	I-2	Reply	171
--------------------------------------------------------------------------------------------------------------------------------------------------	I-Reply	I-2	Reply	171
0.1                      |       98.0         |      94.3        |         90.0        |      93.4      |         99.2        |        92.3     |	I-Reply	I-2	Reply	171
0.3                      |       93.7         |      87.9        |         84.2        |      88.9      |         96.9        |        86.7     |	I-Reply	I-2	Reply	171
0.5                      |       99.0         |      43.1        |         88.3        |      50.6      |         99.6        |        31.7     |	I-Reply	I-2	Reply	171
1                       |       66.3         |      40.5        |         73.2        |      23.7      |         90.5        |        15.4     |	I-Reply	I-2	Reply	171
2                       |         0.0         |       0.0         |         25.4        |       4.1       |         67.1         |         3.6      |	I-Reply	I-2	Reply	171
5                       |         0.0         |       0.0         |          7.5         |       2.7       |          7.6          |         2.5      |	I-Reply	I-2	Reply	171
10                      |         0.0         |       0.0         |          0.0         |       0.0       |          0.0          |         0.0      |	I-Reply	I-2	Reply	171
--------------------------------------------------------------------------------------------------------------------------------------------------	O	O	Reply	171
<sep> A3: As can be seen in the GitHub code (anonymously published on <a href="https://github.com/iclr2018invase/INVASE)," target="_blank" rel="nofollow">https://github.com/iclr2018invase/INVASE),</a> on testing data, we select the features whose selection probabilities are larger than 0.5. (	B-Reply	B-3	Reply	171
see line 225 in INVASE-.py and line 274 in INVASE.py) We will clarify this in the revised manuscript.	I-Reply	I-3	Reply	171

This paper proposes a new instance-wise feature selection method, INVASE.	O	O	Review	171
It is closely related to the prior work L2X (Learning to Explain).	O	O	Review	171
There are three differences compared to L2X. The most important difference is about how to backpropagate through subset sampling to select features.	O	O	Review	171
L2X use the Gumbel-softmax trick and this paper uses actor-critic models.	O	O	Review	171
<sep> <sep> The paper is written well.	O	O	Review	171
It is easy to follow the paper.	O	O	Review	171
The contribution of this paper is that it provides a new way,  compared to L2X, to backpropagate through subset sampling in order to select features.	O	O	Review	171
The authors compare INVASE with L2X and several other approaches on synthetic data and show outperforming results.	O	O	Review	171
In the real-world experiments, the authors do not compare INVASE with other approaches.	O	O	Review	171
<sep> <sep> Regarding experiments, instance-wise feature selection is often applied on computer vision or natural language process applications, where global feature selection is not enough.	O	O	Review	171
This paper lacks experiments on CV or NLP applications.	O	O	Review	171
For the MAGGIC dataset, I expect to see subgroup patterns.	B-Review	B-5	Review	171
The patterns that authors show in Figure 2 are very different for all randomly selected 20 patients.	I-Review	I-5	Review	171
The authors do not explain why it is preferred to see very different feature patterns for all patients instead of subgroup patterns.	I-Review	I-5	Review	171
<sep> <sep> I have questions about other two differences from L2X, pointed by the authors.	O	O	Review	171
First, the selector function outputs a probability for selecting each feature \hat{S}^\theta(x).	B-Review	B-1	Review	171
In the paper of L2X, it also produces a weight vector w_\theta(x) as described in section 3.4.	I-Review	I-1	Review	171
I think the \hat{S}^\theta(x) has similar meaning as w_\theta(x) in L2X. In the synthetic data experiment, the authors fix the number of selected features for L2X so that it forces to overselect or underselect features in the example of Syn4.	I-Review	I-1	Review	171
Did the author try to relax this constraint for L2X and use w_\theta(x) in L2X to select features as using \hat{S}^\theta(x) in INVASE?	I-Review	I-1	Review	171
<sep> <sep> Second, I agree with the authors that L2X is inspired by maximizing mutual information between Y and X_S and INVASE is inspired by minimizing KL divergence between Y|X and Y|X_S. Both intuitions lead to similar objective functions that INVASE has an extra term \log p(y|x) and \lambda ||S(x)||. INVASE is able to add a l_0 penalty on S(x) since it uses the actor-critic models.	B-Review	B-2	Review	171
For the \log p(y|x) term, as the author mentioned, it helps to reduce the variance in actor-critic models.	I-Review	I-2	Review	171
This \log p(y|x) term is a constant in the optimization of S(x).	I-Review	I-2	Review	171
In Algorithm 1, 12, the updates of \gamma does not depend on other parameters related to the predictor network and selector network.	I-Review	I-2	Review	171
Could the authors first train a baseline network and use it as a fixed function in Algorithm 1?	I-Review	I-2	Review	171
I don't understand the meaning of updates for \gamma iteratively with other parameters since it does not depend on the learning of other parameters.	I-Review	I-2	Review	171
Does this constant term \log p(y|x) have other benefits besides reducing variance in actor-critic models?	I-Review	I-2	Review	171
<sep> <sep> I have another minor question about scaling.	B-Review	B-3	Review	171
How does the scaling of X affect the feature importance learned by INVASE?	I-Review	I-3	Review	171
<sep> <sep> Note: I have another concern about the experiments.	B-Review	B-4	Review	171
Previous instance-wise variable selection methods are often tested on CV or NLP applications, could the authors present those experiments as previous works?	I-Review	I-4	Review	171
Thank you for the insightful comments.	O	O	Reply	171
<sep> <sep> A1: We performed extensive experiments in the synthetic setting on all methods (we both reproduced and extended the settings from L2X).	B-Reply	B-1	Reply	171
In addition to this, results for semi-synthetic data (where the underlying features are from real data but the label is generated synthetically) can be found in the Appendix on page 16.	I-Reply	I-1	Reply	171
It is necessary to perform experiments on synthetic data if we wish to be able to compare the TPR and FDR of the different methods since we require knowledge of the ground truth relevant features.	I-Reply	I-1	Reply	171
<sep> <sep> For the real-world results, our focus was on qualitative results (believing we had already demonstrated the methods efficacy in the synthetic - and in the appendix the semi-synthetic - settings).	I-Reply	I-1	Reply	171
We will move the semi-synthetic results to the main body of the paper to make clear that we have demonstrated the performance in this setting.	I-Reply	I-1	Reply	171
<sep> <sep> For the real-data experiment in which we report prediction performance, we have extended our results to include the other approaches.	I-Reply	I-1	Reply	171
We use the same predictive model as the INVASE predictor network (to allow a fair comparison) but use only the selected features of each approach.	I-Reply	I-1	Reply	171
As can be seen in the below table (for the PLCO dataset), INVASE does significantly outperform the other approaches.	I-Reply	I-1	Reply	171
Detailed results will be added to the revised manuscript.	I-Reply	I-1	Reply	171
<sep> <sep> ----------------------------------------------------------------------------------------------------	I-Reply	I-1	Reply	171
Labels           |                  5-year                 |                  10-year                |	I-Reply	I-1	Reply	171
Metrics         |      AUROC     |    AUPRC    |      AUROC     |     AUPRC    |	I-Reply	I-1	Reply	171
----------------------------------------------------------------------------------------------------	I-Reply	I-1	Reply	171
INVASE           |     0.637         |     0.329      |       0.673        |       0.506    |	I-Reply	I-1	Reply	171
L2X               |     0.558         |     0.170      |       0.583        |       0.365    |	I-Reply	I-1	Reply	171
LIME             |     0.597         |     0.183      |       0.601        |       0.374    |	I-Reply	I-1	Reply	171
Shapley          |     0.614         |     0.194      |       0.615        |       0.381    |	I-Reply	I-1	Reply	171
Knockoff        |     0.619         |     0.230      |       0.658        |       0.475    |	I-Reply	I-1	Reply	171
Tree             |     0.632         |     0.269      |       0.655        |       0.469    |	I-Reply	I-1	Reply	171
SCFS             |     0.632         |     0.231      |       0.632        |       0.444    |	I-Reply	I-1	Reply	171
LASSO          |     0.623         |     0.218      |       0.656        |       0.467    |	I-Reply	I-1	Reply	171
----------------------------------------------------------------------------------------------------	O	O	Reply	171
<sep> A2: Our method can definitely be applied to CV or NLP, though in the paper we focus on what we believe to be an equally important application where global feature selection is not enough, i.e. medicine.	B-Reply	B-4	Reply	171
<sep> We will provide qualitative results in the Appendix of the revised manuscript using the Kaggle Dog vs Cat dataset (<a href="https://www.kaggle.com/c/dogs-vs-cats)."	I-Reply	I-4	Reply	171
target="_blank" rel="nofollow">https://www.kaggle.com/c/dogs-vs-cats).</a>	I-Reply	I-4	Reply	171
<sep> A3: The results shown in figure 2 for the MAGGIC dataset are entirely qualitative.	B-Reply	B-5	Reply	171
We are not suggesting that the patterns shown are preferred (or expected) but rather showing that when we use INVASE to discover features for MAGGIC, we find that the patterns are different (though, if you look at, for example, patients 9, 10 and 11 we see a similar pattern for all 3).	I-Reply	I-5	Reply	171
To us, this simply reinforces the fact that instance-wise feature selection is necessary - if MAGGIC did indeed only contain subgroup patterns then we would expect INVASE to pick these out (as it does in the synthetic and semi-synthetic experiments where, for example in Syn4, Syn5 and Syn6, there are two distinct subgroups).	I-Reply	I-5	Reply	171

In the paper, the authors proposed a new algorithm for instance-wise feature selection.	O	O	Review	171
In the proposed algorithm, we prepare three DNNs, which are predictor network, baseline network, and selector network.	O	O	Review	171
The predictor network and the baseline networks are trained so that it fits the data well, where the predictor network uses only selected features sampled from the selector network.	O	O	Review	171
The selector network is trained to minimize the KL-divergence between the predictor network and the baseline network.	O	O	Review	171
In this way, one can train the selector network that select different feature sets for each of given instances.	O	O	Review	171
<sep> <sep> I think the idea is quite simple: the use of three DNNs and the proposed loss functions seem to be reasonable.	O	O	Review	171
The experimental results also look promising.	O	O	Review	171
<sep> <sep> I have a concern on the scheduling of training.	B-Review	B-1	Review	171
Too fast training of the predictor network can lead to the subotpimal selection network.	I-Review	I-1	Review	171
I have checked the implementations in github, and found that all the networks used Adam with the same learning rates.	I-Review	I-1	Review	171
Is there any issue of training instability?	I-Review	I-1	Review	171
And, if so, how we can confirm that good selector network has trained?	I-Review	I-1	Review	171
<sep> <sep> My another concern is on the implementations in github.	B-Review	B-2	Review	171
The repository originally had INVASE.py.	I-Review	I-2	Review	171
In the middle of the reviewing period, I found that INVASE+.py has added.	I-Review	I-2	Review	171
I am not sure which implementations is used for this manuscript.	I-Review	I-2	Review	171
It seems that INVASE.py contains only two networks, while INVASE+.py contains three networks.	I-Review	I-2	Review	171
I therefore think the latter is the implementation used for this manuscript.	I-Review	I-2	Review	171
If this is the case, what INVASE.py is for?	I-Review	I-2	Review	171
<sep> I am also not sure if it is appropriate to "communicate" through external repositories during the reviewing period.	I-Review	I-2	Review	171
Thank you for the insightful comments.	O	O	Reply	171
<sep> <sep> A1: It is not true that fast training of the predictor network can lead to a suboptimal selector network.	B-Reply	B-1	Reply	171
Even when the predictor network is fully trained after each selector network update, the selector network can converge optimally.	I-Reply	I-1	Reply	171
However, because the input distribution of the predictor network changes with each update of the selector network, the predictor network will have to update after each selector update.	I-Reply	I-1	Reply	171
It is therefore not possible for the predictor network to converge until after the selector network has converged.	I-Reply	I-1	Reply	171
Therefore, there are no stability issues caused by using the same learning rates for each network.	I-Reply	I-1	Reply	171
<sep> <sep> A2: INVASE+.py is the code corresponding to the implementation found in this paper.	B-Reply	B-2	Reply	171
INVASE.py corresponds to the same implementation but without the baseline (i.e. just the selector and predictor networks).	I-Reply	I-2	Reply	171
In practice we found both to perform similarly, but the derivation of INVASE+ is a little more natural, and as such we used it for the paper.	I-Reply	I-2	Reply	171
<sep> <sep> We have since changed the names in the repository to INVASE and INVASE- (so that now INVASE is indeed the implemented method and INVASE- is the method without the baseline).	I-Reply	I-2	Reply	171
We hope this alleviates the confusion.	I-Reply	I-2	Reply	171

This paper proposes a novel approach to deal with the computational problems of self-attention without introducing independence assumptions.	O	O	Review	171
The proposed approach is simple, easy to understand, and easy to implement.	O	O	Review	171
<sep> <sep> However, evaluation for this paper is severely lacking.	B-Review	B-1	Review	171
As it is, there is not enough information provided to adequately assess the proposed method's strengths in practice.	I-Review	I-1	Review	171
The following should be added:	I-Review	I-1	Review	171
<sep> Evaluation on a variety of different tasks, such as image segmentation, temporally consistent object detection, object tracking, etc.	I-Review	I-1	Review	171
Why are the evaluations limited to generative modeling?	I-Review	I-1	Review	171
To prove the generality of the method (as claimed), it needs to be applied to various tasks.	I-Review	I-1	Review	171
<sep> Runtime (in inference) comparisons for each of the datasets and for each of the baselines.	I-Review	I-1	Review	171
Additionally, a theoretical analysis for runtime in terms of the size of the input should be given (the column in Table 1 should have runtimes for each method clearly specified, and this should be done for each dataset and baseline)	I-Review	I-1	Review	171
Ablation study.	B-Review	B-2	Review	171
What is the baseline architecture used without axial attention?	I-Review	I-2	Review	171
There is only comparison to previous work which may have used a different architecture.	I-Review	I-2	Review	171
<sep> <sep> If these concerns are thoroughly addressed, I would be happy to increase my score.	O	O	Review	171
Thank you for your comments.	O	O	Reply	171
We would like to point outright that the intended scope and focus of the paper is exclusively generative models of images with an extension to videos.	B-Reply	B-1	Reply	171
Some aspects of the paper make this clear:	B-Reply	B-1	Reply	171
- The title centrally includes "multidimensional transformers" that are only generative models indeed with an encoder part and a decoder part (like the original transformer for language).	I-Reply	I-1	Reply	171
<sep> - Our main contribution is the Axial Transformer architecture itself, i.e. how to easily apply (masked) axial attention to multi-dimensional transformers by using a number of additional features: reordering of RGB channels, shifting operation for the rows, shallow and hence faster strict autoregressive decoder, no need for custom kernels.	B-Reply	B-1	Reply	171
<sep> - The thorough and exclusive comparison with previous image modelling attention-based architectures.	B-Reply	B-1	Reply	171
<sep> <sep> However, we also realize now that some sentences in the paper may hint at axial attention as a stand-alone operation to be used beyond generative modelling.	B-Reply	B-2	Reply	171
Showing this is beyond the scope of our paper and we are working to make this clear and rephrase the relevant passages and subsections.	I-Reply	I-2	Reply	171

This paper claims to propose a new approach to solve the computational problems of self-attention.	B-Review	B-1	Review	171
However, the paper mainly focuses on adapting Transformer for image generation, which has far less applications.	I-Review	I-1	Review	171
The whole paper needs to be rewritten to make their target and contribution clearer.	I-Review	I-1	Review	171
<sep> <sep> 1.	B-Review	B-2	Review	171
The authors overclaim that they provide a new approach for accelerating self-attention.	I-Review	I-2	Review	171
However, they only adapted Transformer for image generation.	I-Review	I-2	Review	171
In fact, Transformer does not equal to self-attention.	I-Review	I-2	Review	171
Currently, two directional self-attention like Bert has much wider applications compared with Transformer like sequential self-attention.	I-Review	I-2	Review	171
<sep> <sep> 2.	O	O	Review	171
For a paper claim to improve self-attention, they should show its effectiveness on a broad range of tasks, with comprehensive experimental evaluation.	B-Review	B-3	Review	171
However, authors mainly reported the image generation on several datasets.	I-Review	I-3	Review	171
<sep> <sep> Overall, the authors need to rewrite the paper.	O	O	Review	171
They should either show more applications with the proposed self-attention approach or treat it as a new approach for image generation.	O	O	Review	171
Thank you for remarks.	O	O	Reply	171
Since one of your major objections is at its core the same objection as that by reviewer #1, please see comment above.	O	O	Reply	171
We want to treat our paper as a new architecture for image (and video) generation and we are making this clear in the text.	O	O	Reply	171

It is known that the standard self-attention method is computationally expensive and cost a significantly large amount of storage when the number of points to be attended is large.	O	O	Review	171
<sep> <sep> This paper attempts to solve this problem and proposed the Axial Attention method.	O	O	Review	171
It is claimed to be able to save an O(N^(d-1)/d) factor of resources over standard self-attention.	O	O	Review	171
<sep> <sep> The proposed method looks novel to me, but some of the related works are missing and the experiment session is insufficient.	O	O	Review	171
<sep> <sep> 1)  The author should at least include the following works which also aim to reduce the cost of self-attention.	B-Review	B-1	Review	171
Since the author did not mention these works which also focus on solving the same problem, It is hard for me to judge if the proposed method is better than existing works.	I-Review	I-1	Review	171
<sep> [a] CCNet: Criss-Cross Attention for Semantic Segmentation	I-Review	I-1	Review	171
[b] A^2-Nets: Double Attention Networks	I-Review	I-1	Review	171
<sep> 2) self-attention has shown its effectiveness on a broad range of computer vision tasks, including image generation, detection, segmentation, and classification.	B-Review	B-2	Review	171
I do not get why the proposed method is only benchmarked for generative models.	I-Review	I-2	Review	171
Is it because the proposed method cannot be adopted on other popular CV tasks, such as detection, segmentation, and classification?	I-Review	I-2	Review	171
Extra experiments should be included if the proposed method is not only designed for generative models.	I-Review	I-2	Review	171
<sep> <sep> 3) The ablation study is missing.	B-Review	B-3	Review	171
The author directly compared its own method with other existing methods that are implemented and trained with different hyperparameters.	I-Review	I-3	Review	171
It is hard to know which indeed benefits the accuracy gain and how significant is the proposed method.	I-Review	I-3	Review	171
<sep> <sep> 4) In table 2 and 3, I do not see a clear advantage of the proposed method over the SOTA methods.	B-Review	B-4	Review	171
Thanks for your remarks.	O	O	Reply	171
Some of your major points (2 and to some extent 1) concern the scope of the notions that we introduce, specifically axial attention.	B-Reply	B-2	Reply	171
Please note that the intended scope is only axial attention within multidimensional transformers, that is within generative modelling of multidimensional data such as images and videos.	I-Reply	I-2	Reply	171
We are aiming at making this very clear in the paper.	I-Reply	I-2	Reply	171
Please see our related remarks to the other reviewers.	O	O	Reply	171

Summary:	O	O	Review	171
The authors present a PyTorch based framework for performing second-order	O	O	Review	171
reverse mode autodiff for meta-learning.	O	O	Review	171
<sep> <sep> First, the authors present a formalization of a general prototypical	O	O	Review	171
meta-learning setting.	O	O	Review	171
<sep> They then provide an algorithm that solves this problem via gradient based	O	O	Review	171
optimization.	O	O	Review	171
<sep> Finally, perhaps the main contribution is a specific PyTorch implementation	O	O	Review	171
of said algorithm.	O	O	Review	171
<sep> <sep> The type of meta-learning setting the authors consider is one where a gradient	O	O	Review	171
based inner loop optimizer finds by performing a finite number of steps.	O	O	Review	171
<sep> The inner loop optimizer is parameterized through that consists of	O	O	Review	171
two parts and.	O	O	Review	171
<sep> The parameters are somehow part of the loss used for	O	O	Review	171
training in the inner loop.	O	O	Review	171
Example: Regularization paramter.	O	O	Review	171
<sep> The parameters do not occur in the loss but in the	O	O	Review	171
optimizer step.	O	O	Review	171
Example: Learning rate.	O	O	Review	171
<sep> <sep> Example of an inner loop step:	O	O	Review	171
where are the parameters of a neural network, is the training loss, is the regularizer, is the learning rate, is the regularization parameter.	O	O	Review	171
<sep> In this example we would have.	O	O	Review	171
<sep> <sep> The authos assume, the output of the inner loop after steps to	O	O	Review	171
be differentiable wrt.	O	O	Review	171
<sep> Furthermore, the meta-learning loss is assumed to be differentiable wrt	O	O	Review	171
so that a gradient of the meta-learning loss wrt to can be computed.	O	O	Review	171
<sep> The authors also assume the meta-learning loss to be sufficient smooth in	O	O	Review	171
such that a gradient based optimization can even be used for meta learning to	O	O	Review	171
a local optimum.	O	O	Review	171
<sep> <sep> The authors explicitly write down the reverse mode auto differentiation of	O	O	Review	171
the inner loop and show how to, in that way, compute the gradient of the	O	O	Review	171
meta-learning loss wrt to.	O	O	Review	171
<sep> <sep> The reverse (adjoint) mode auto differentiation of the above example inner loop step	O	O	Review	171
is the following step (iterated over in reverse down from to:	O	O	Review	171
where accumulates the gradient of wrt and accumulates the gradient of wrt.	O	O	Review	171
<sep> <sep> The authors give some implementation details specific to some frameworks necessary	O	O	Review	171
for implementing such "gradient of an inner loop".	O	O	Review	171
<sep> <sep> The authors present experiments where they show how to meta-learn learning rates	O	O	Review	171
with their framework.	O	O	Review	171
<sep> They also how their framework can be used to quickly implement a MAML type	O	O	Review	171
meta-learning optimizer ablation study comparing various combinations of	O	O	Review	171
architecture, optimizer and inner loop steps etc..	O	O	Review	171
<sep> Recommendation:	O	O	Review	171
I propose to reject the paper.	O	O	Review	171
<sep> In my eyes the only contribution is the implementation of a meta-learner in	B-Review	B-11	Review	171
PyTorch based on well known methods.	I-Review	I-11	Review	171
<sep> The provided unifying formalization is theoretically inaccurate (see below)	I-Review	I-11	Review	171
and to me come across as merely a motivation for their framework	I-Review	I-11	Review	171
(but no value added compared to existing literature).	I-Review	I-11	Review	171
<sep> There is no new insight provided on the software engineering level either as	I-Review	I-11	Review	171
far as I can see.	I-Review	I-11	Review	171
<sep> <sep> Detailed comments:	O	O	Review	171
- Page 1: ...provides tooling for analysing the provable requirements...	B-Review	B-1	Review	171
<tab>seems like a complicated way of saying something that could be said simple	I-Review	I-1	Review	171
<sep> - Page 2: Without loss of generality, ...	B-Review	B-2	Review	171
<tab>You are assuming a parametric model.	I-Review	I-2	Review	171
Not sure what generality this phrase	I-Review	I-2	Review	171
<tab>refers to.	I-Review	I-2	Review	171
<sep> <sep> - Page 2: A formalization as	B-Review	B-3	Review	171
<tab>is inaccurate in the sense that it does not acknowledge the existing of	I-Review	I-3	Review	171
<tab>multiple optima.	I-Review	I-3	Review	171
<sep> <tab>I would recommend not to use the operator here, since for	I-Review	I-3	Review	171
<tab>something like a neural network would for example either return a global	I-Review	I-3	Review	171
<tab>optimum (which no optimizer used in practice finds, and is not ment here)	I-Review	I-3	Review	171
<tab>or would take on a set value with multiple local minima for example.	I-Review	I-3	Review	171
<sep> <sep> <tab>In the same context, the authors should mention the issues about uniqueness	I-Review	I-3	Review	171
<tab>of optima (we are not even really finding optima when training neural networks),	I-Review	I-3	Review	171
<tab>implicit functions / implicit differentiation	I-Review	I-3	Review	171
<sep> <tab>In the context of using stochastic optimizers one should also at least	I-Review	I-3	Review	171
<tab>mention something about the differentiability of outputs of such optimizers	I-Review	I-3	Review	171
<tab>and how they potentially depend on randomness of mini-batches	I-Review	I-3	Review	171
<tab>(what if different randomness is used with the same or a perturbed	I-Review	I-3	Review	171
<tab>hyper parameter?)	I-Review	I-3	Review	171
<sep> <sep> - Page 3: You mention the potential statefulness of the optimizer.	B-Review	B-4	Review	171
<sep> <tab>Why not explicitly carry it in the math notation?	I-Review	I-4	Review	171
<sep> <tab>Probably things would get cluttered but saying it should be covered within	I-Review	I-4	Review	171
does not seem reasonable to me.	I-Review	I-4	Review	171
<sep> <sep> - Page 3: While this may seem like a fairly trivial formalization...	B-Review	B-5	Review	171
<tab>Yes, but also nesting this in an outer loop is fairly trivial in the sense	I-Review	I-5	Review	171
<tab>that it is a well known approach.	I-Review	I-5	Review	171
<sep> <sep> - Page 4: there exist continuous hyperparam...	B-Review	B-6	Review	171
<tab>If they are not continuous then they should not even occur in this	I-Review	I-6	Review	171
<tab>formalization so saying there exist... does not make much sense to me here	I-Review	I-6	Review	171
<sep> implies that is	I-Review	I-6	Review	171
<tab>a set from notation although we are treating it as a vector everywhere else	I-Review	I-6	Review	171
<sep> - Page 4: All of section 2.4 seems somewhat trivial to me, but I guess that is	B-Review	B-7	Review	171
<tab>highly subjective.	I-Review	I-7	Review	171
<sep> <sep> - Page 5: in the definition of stop operator perhaps use	B-Review	B-8	Review	171
<sep> - Page 5: Perhaps explicitly mention how your approach differs from a reverse	B-Review	B-9	Review	171
<tab>mode differentiation of training or if it does not differ, say this.	I-Review	I-9	Review	171
<sep> <sep> - Page 14: When talking about _S_GD (instead of just GD) perhaps mention	B-Review	B-10	Review	171
<tab>something about non-existence of mini-batch randomness / being deterministic	I-Review	I-10	Review	171
<sep> Dear Reviewer,	O	O	Reply	171
<sep> We have made modifications to the manuscript based on our discussion.	O	O	Reply	171
For your convenience, please find, below, a log of the changes made that pertain to our discussion.	O	O	Reply	171
Please note that the paper has still been kept under the page limit as a result of these changes.	O	O	Reply	171
<sep> <sep> Replaced ‚ÄúThe proposed formalism provides tooling for analysing the provable requirements of the meta-optimization process, and allows for describing the process in general terms.	O	O	Reply	171
‚Äù with ‚ÄúThe proposed formalism allows us to describe the meta-optimization process in general terms and analyse its requirements.	B-Reply	B-1	Reply	171
‚Äù as discussed.	I-Reply	I-1	Reply	171
<sep> <sep> Removed ‚Äúwithout loss of generality‚Äù where it would cause confusion,	O	O	Reply	171
Replaced ‚Äúestimate‚Äù with ‚Äúapproximate‚Äù to avoid confusion, as discussed.	B-Reply	B-2	Reply	171
<sep> <sep> Left a footnote for requirement 2 to clarify the applicability of the requirement to stochastic optimizers.	I-Reply	I-2	Reply	171
<sep> <sep> Added a clarification about the relation between the Gimli update algorithm and reverse-mode differentiation as the end of section 2.	I-Reply	I-2	Reply	171
<sep> <sep> Thanks again for your excellent suggestions.	O	O	Reply	171

This work presented a general formulation of a wide class of existing meta-learning approaches, and proved the requirements that must be satisfied for such approaches to be possible.	O	O	Review	171
<sep> <sep> Half of the work is focused on describing the unnamedlib library, which extends PyTorch to enable the easy	O	O	Review	171
and natural implementation of such meta-learning approaches.	O	O	Review	171
<sep> <sep> The early sections are interesting, especially section 2, which gives some great insights to the existing inner loop pattern in meta-learning.	B-Review	B-1	Review	171
However, from section 3, the paper has turned to examples and related works, where I was hoping the author would give more detailed analysis of the pattern.	I-Review	I-1	Review	171
My concern is the authors have spent too much space on the unnamedlib library.	I-Review	I-1	Review	171
So <a href="http://www.jmlr.org/mloss/" target="_blank" rel="nofollow">http://www.jmlr.org/mloss/</a> might be a more suitable place for publication.	I-Review	I-1	Review	171
Dear Reviewer,	O	O	Reply	171
<sep> We have made modifications to the manuscript based on our discussion.	O	O	Reply	171
For your convenience, please find, below, a log of the changes made that pertain to our discussion.	O	O	Reply	171
Please note that the paper has still been kept under the page limit as a result of these changes.	O	O	Reply	171
<sep> <sep> We‚Äôve updated the manuscript to add specific examples of how select existing approaches fit the Gimli formalism in Section 3.	B-Reply	B-1	Reply	171
Thank you for your suggestion.	I-Reply	I-1	Reply	171

The authors propose the general formulation of recent meta-learning methods and propose a good library to use.	O	O	Review	171
<sep> <sep> Pros:	O	O	Review	171
1.	O	O	Review	171
The general formulation of recent meta-learning methods is reasonable.	O	O	Review	171
<sep> 2.	O	O	Review	171
The proposed library is easy to use.	O	O	Review	171
<sep> <sep> Cons:	O	O	Review	171
<sep> The paper lacks technical novelty.	B-Review	B-1	Review	171
I understand the goal of this paper is to build a library.	I-Review	I-1	Review	171
However, the paper only describes a general formulation for recent meta-learning methods (e.g., MAML) and implement the formulation.	I-Review	I-1	Review	171
It is better to clarify and some key engineering challenges and do the corresponding experiments.	I-Review	I-1	Review	171
<sep> <sep> In addition, in the experiment parts, the authors only compare the results with MAML++.	B-Review	B-2	Review	171
It will be more convincing if the authors can analyze other popular meta-learning methods (e.g.. Prototypical network [1], meta-LSTM [2]).	I-Review	I-2	Review	171
<sep> <sep> Another suggestion is that the authors can give some examples to connect current meta-learning models with the proposed general formulation.	B-Review	B-3	Review	171
For example, the meaning of \phi_i^opt, \phi_i^loss in MAML, Prototype, Reptile, etc.	I-Review	I-3	Review	171
<sep> <sep> It is better to explain the meaning of different colors in Figure 3.	B-Review	B-4	Review	171
<sep> <sep> [1] Snell, Jake, Kevin Swersky, and Richard Zemel. "	O	O	Review	171
Prototypical networks for few-shot learning."	O	O	Review	171
Advances in Neural Information Processing Systems.	O	O	Review	171
2017.	O	O	Review	171
<sep> [2] Ravi, Sachin, and Hugo Larochelle. "	O	O	Review	171
Optimization as a model for few-shot learning."	O	O	Review	171
ICLR (2016).	O	O	Review	171
<sep> <sep> <sep> <sep> Decision after rebuttal: I have read the authors' responses.	O	O	Review	171
Like review 2, I also think the "generalization" is overclaimed, it only provides a general formulation.	O	O	Review	171
Thus, I finally decide to keep my score.	O	O	Review	171
Dear Reviewer,	O	O	Reply	171
<sep> We have made modifications to the manuscript based on our discussion.	O	O	Reply	171
For your convenience, please find, below, a log of the changes made that pertain to our discussion.	O	O	Reply	171
Please note that the paper has still been kept under the page limit as a result of these changes.	O	O	Reply	171
<sep> <sep> We‚Äôve updated the manuscript to add specific examples of how select existing approaches fit the Gimli formalism in Section 3.	B-Reply	B-3	Reply	171
Thank you for your suggestion.	I-Reply	I-3	Reply	171
<sep> <sep> We have clarified the purpose of the different colours in the figures at the end of the appendix.	B-Reply	B-4	Reply	171
<sep> <sep> Thanks again for your excellent suggestions.	O	O	Reply	171

The paper considers Grassmannian SGD to optimize the skip gram negative sampling (SGNS) objective for learning better word embeddings.	B-Review	B-1	Review	552
It is not clear why the proposed optimization approach has any advantage over the existing vanilla SGD-based approach - neither approach comes with theoretical guarantees - the empirical comparisons show marginal improvements.	I-Review	I-1	Review	552
Furthermore, the key idea here - that of projector splitting algorithm - has been applied on numerous occasions to machine learning problems - see references by Vandereycken on matrix completion and by Sepulchre on matrix factorization.	I-Review	I-1	Review	552
<sep> <sep> The computational cost of the two approaches is not carefully discussed.	B-Review	B-2	Review	552
For instance, how expensive is the SVD in (7)?	I-Review	I-2	Review	552
One can always perform an efficient low-rank update to the SVD - therefore, a rank one update requires O(nd) operations.	I-Review	I-2	Review	552
What is the computational cost of each iteration of the proposed approach?	I-Review	I-2	Review	552
<sep> <sep> <sep> Thank you for your reply!	O	O	Reply	552
<sep> <sep> We think that the contribution of our paper is not only in the new application of the existing Riemannian optimization technique but also in the clear reformulation of the word embedding learning problem (see previous comments for details).	B-Reply	B-1	Reply	552
<sep> <sep> Speaking of the computational complexity, you are right ‚Äî the complexity of our algorithm is not perfect and the algorithm can not be applied to large-scale datasets with millions of unique tokens in the training corpus.	B-Reply	B-2	Reply	552
We are going to improve the efficiency of the algorithm in our future work.	I-Reply	I-2	Reply	552

This paper presents a principled optimization method for SGNS (word2vec).	O	O	Review	552
While the proposed method is elegant from a theoretical perspective, I am not sure what the tangible benefits of this approach are.	O	O	Review	552
For example, does using Riemannian optimization allow the model to converge faster than the alternatives?	O	O	Review	552
The evaluation doesn't show a dramatic advantage to RO-SGNS; the 1% difference on the word similarity benchmarks is within the range of hyperparameter effects (see "Improving Distributional Similarity with Lessons Learned from Word Embeddings", (Levy et al 2015)).	O	O	Review	552
The theoretical connection to Riemannian optimization is nice though, and it might be useful for understanding related methods in the future.	O	O	Review	552
Thank you for your reply!	O	O	Reply	552
I have commented it in the answer to your other message.	O	O	Reply	552

This submission is difficult to review, since it leaves the reader in suspense as to what the specific contributions it makes are.	O	O	Review	151
<sep> <sep> The authors model the circuity involved in C. elegans mechanosensory habituation.	O	O	Review	151
However, they don't appear to provide many specifics of their model, rather almost all the space is taken with background information.	B-Review	B-1	Review	151
The key findings do not appear to be novel (neurons can have state that is modified by history of the neuron's experience), and are assumptions of their model (based on known experimental results), so it is unclear that they are significant new contributions (given the paucity of details about their specific approach, it is difficult to judge).	I-Review	I-1	Review	151
<sep> <sep> Reasons to accept:	O	O	Review	151
- The authors promise that their approach may give rise to new "bio-inspired learning algorithms."	O	O	Review	151
<sep> - They provide a good background regarding C elegans and habituation.	O	O	Review	151
<sep> <sep> Reasons to reject:	O	O	Review	151
- Submission is unclear about their model or specific contributions.	B-Review	B-1	Review	151
<sep> - Although the authors make a reference to this work leading to "better learning algorithms," no specifics are provided.	B-Review	B-2	Review	151
This paper doesn't appear to have much connection with representation learning and may be more suited for a different venue.	I-Review	I-2	Review	151
<sep> - Abstract advertises insights that give rise to "new bio-inspired learning algorithms" but doesn't appear to provide any general insights into learning.	B-Review	B-3	Review	151
<sep> <sep> Minor issue: there are a number of grammatical errors.	O	O	Review	151
Thank you very much for your comments and review.	O	O	Reply	151
<sep> <sep> I would like to add some key comments in defense of our work:	O	O	Reply	151
<sep> - I will highlight the key contributions of our work and stress on the fact that our presentation well-suits the ICLR venue:	O	O	Reply	151
<sep> -<tab>We provided a clear-compact overview on the mechanisms of the non-associative learning within the nervous system of the C. elegans.	B-Reply	B-1	Reply	151
Within the first part of the paper, we built up several insights towards understanding the mechanism of learning by provided key notes on the structure and dynamics of the nervous system during the learning process.	I-Reply	I-1	Reply	151
<sep> <sep> -<tab>We have constructed a detailed mathematical simulation platform for our analyses and tried to draw a general overview on the principles we found by using our simulator, in such a compact report.	B-Reply	B-1	Reply	151
However, as the reviewer is fully aware, explaining the details of a neuronal model and synaptic connectivity models is extremely difficult in such a compact version.	I-Reply	I-1	Reply	151
We therefore, structured our work to be understandable for a larger audience who are not much familiar with the field.	I-Reply	I-1	Reply	151
We also planned to include the details of the equations and analyses, within the poster-session at the ICLR workshop in order to establish a clear picture on our novel work, interactively.	I-Reply	I-1	Reply	151
<sep> <sep> -<tab>The first Key finding states the novel fact that an additional layer of input neurons can be placed in a network and their properties and state can depend on the structure of the input features and data.	B-Reply	B-1	Reply	151
The second key finding states that synapses can have states and that can significantly changes the behavior of the entire network.	I-Reply	I-1	Reply	151
We have precisely followed the effects of the gene modifications on the global behavior of the worm in several biological experiments and correspondingly added suitable dynamics variables in the model (which were noted within the text).	I-Reply	I-1	Reply	151
Figures illustrates a small example of such experiments and comparison.	I-Reply	I-1	Reply	151
<sep> <sep> -<tab>Within the paper, we stated that our findings may lead to new learning algorithms.	B-Reply	B-2	Reply	151
This is explained in the text within the concepts introduced in the first part of the paper as well as the key findings.	I-Reply	I-2	Reply	151
The reader can potentially get inspired to include our findings in the existing learning algorithms and correspondingly improve the quality of the learning.	I-Reply	I-2	Reply	151
This is of course on the priority-list of our future works.	I-Reply	I-2	Reply	151
<sep> <sep> -<tab>The workshop track of ICLR this year ‚Äúwill focus and favor&nbsp;late-breaking developments and very novel ideas.	B-Reply	B-3	Reply	151
‚Äù I believe that designing a simulation platform with which one can easily turn attractive behavioural features such as learning various representations, to mathematical equations and useful conclusions, can be extremely interesting for the well-regarded ICLR Audience.	I-Reply	I-3	Reply	151
<sep> <sep> Furthermore, our extended abstract tries to introduce a novel principle on modelling the sources of learning in the brain of C. elegans considerably compact.	B-Reply	B-3	Reply	151
The topic can easily get sophisticated to comprehend for the majority of the ICLR audience without providing proper background information.	I-Reply	I-3	Reply	151
We therefore attempted to provide a high-level background description on the topic, while including novel findings even within the introductory part.	I-Reply	I-3	Reply	151
examples include:	I-Reply	I-3	Reply	151
<sep> "Sensory (input) neurons within the network are subjected to a mediation during the non- associative training process (repeated tap stimulation) (Kindt et al 2007). "	I-Reply	I-3	Reply	151
<sep> This indicates that one can set a layer of input-neurons which their threshold of activation is tunable depending on the type of the input features to be learned.	I-Reply	I-3	Reply	151
<sep> <sep> ‚ÄúWithin a neural circuit, only some of the interneurons are proposed to be the substrate of memory (Sugi et al 2014).‚Äù	I-Reply	I-3	Reply	151
This implies that only some neurons within the nervous system can have states and some of them are stateless.	I-Reply	I-3	Reply	151
That makes the process of learning faster and more efficient.	I-Reply	I-3	Reply	151
Like other biological sources of optimal networks such as beta cell hubs in islet functional architecture [1], C. elegans‚Äô brain network consists of hubs (neurons with states) which are actively involved in learning.	I-Reply	I-3	Reply	151
<sep> <sep> <sep> I would like to sincerely ask the reviewer to reevaluate our short paper, given our recent comments.	I-Reply	I-3	Reply	151
<sep> <sep> Thank you very much for your consideration.	O	O	Reply	151
<sep> <sep> References:	O	O	Reply	151
<sep> [1] Johnston, Natalie R., et al "Beta cell hubs dictate pancreatic islet responses to glucose.	O	O	Reply	151
"&nbsp;Cell Metabolism&nbsp;24.3 (2016): 389-401.	O	O	Reply	151

It is nice to see some discussion of the biological underpinning of learning, and C.elegans is indeed a great model system.	O	O	Review	151
It is also very tempting to hear about modeling genetic mechanisms and I was really intrigued by the abstract.	B-Review	B-1	Review	151
Unfortunately, the basic think that of explaining the way S(t) depends on the experiments is completely omitted.	B-Review	B-2	Review	151
It is clear if the synaptic current are modified by a variable that the resulting behaviour of the postsynaptic neuron can be modified, but not showing this model instead of the well known conductance model itself is disappointing.	I-Review	I-2	Review	151
Thank you for your review and comments.	O	O	Reply	151
<sep> <sep> I would like to add some comments:	O	O	Reply	151
<sep> -<tab>Reviewer is fully aware of the fact that explaining the details of the equations used for synaptic connectivity and neural dynamics, requires way more that 3 single-column pages.	B-Reply	B-2	Reply	151
Authors attempted to provide a compact clear picture over the idea of sources of biological learning and simultaneously pointed out several notes and findings which can build up well-founded understanding for readers with any areas of expertise.	I-Reply	I-2	Reply	151
<sep> <sep> -<tab>Authors intentionally structured the paper to make it possible for the ICLR readers which are mostly computer scientists, get connected to the overall picture of the non-associative learning mechanism in C. elegans, within the extended abstract, and provide the details of the equations in the poster and discuss it interactively during the workshop.	B-Reply	B-2	Reply	151
<sep> <sep> -<tab>We believe that the reviewer is totally right about including the equations.	B-Reply	B-1	Reply	151
Accordingly, I mention some of them here and would demand the reviewer‚Äôs opinion about how to integrate them inside the text with their proper explanation?	I-Reply	I-1	Reply	151
<sep> <sep> We have mentioned within the text of the abstract where we can modify in the neuron model in order to create the effect of gene modifications in a sensory neuron habituation.	I-Reply	I-1	Reply	151
examples include:	I-Reply	I-1	Reply	151
<sep> 1)<tab>Conductance of K-Channel decreases over time, due to the gene functions described in [1]. We then proposed to have the following expression for the maximum conductance of the potassium channel, G_K:	I-Reply	I-1	Reply	151
<sep> G_K, is set to a dynamic variable expressed as follows:	I-Reply	I-1	Reply	151
G_K = 10 exp(-0.02*t) +3,	I-Reply	I-1	Reply	151
where parameters are determined empirically.	I-Reply	I-1	Reply	151
<sep> <sep> We also hypothesised that the calcium pump plays a key-role in the suppression of the calcium level in the sensory neuron.	I-Reply	I-1	Reply	151
For the Calcium pump, its maximum conductance has been set to a dynamic variable in a sigmoid-like function:	I-Reply	I-1	Reply	151
G_pump = 10 / (exp(-0.01(t+200)) + 1)	I-Reply	I-1	Reply	151
<sep> Furthermore, We hypothesised that an inactivation-calcium gate should play a role in the learning mechanism.	I-Reply	I-1	Reply	151
<sep> Therefore, we design an inactivation gate, h, as follows:	I-Reply	I-1	Reply	151
<sep> dh/dt = (h_inf ‚Äì h) / tau_h,	I-Reply	I-1	Reply	151
where h_inf = 1 / 1 + H * exp((v-v_half)/k_h),	I-Reply	I-1	Reply	151
where the h_inf is the steady state value of the inactivation gate, with gate rate parameters H, v_half and k_h.	I-Reply	I-1	Reply	151
<sep> v_half = -45 mV, H = 1/, tau_h = 2 s, k_h =1  1/mV.	I-Reply	I-1	Reply	151
Figure 1C in the paper is generated by including all the three dynamics described above, within the model of the neuron.	I-Reply	I-1	Reply	151
<sep> <sep> 2)<tab>We have also mentioned that considering S(t) and G_max of a synapse and their modifications, result in similar habituation and dishabituation behavior on a postsynaptic cell observed in the experimental results:	I-Reply	I-1	Reply	151
The overall synaptic current: I_syn = G_max G(V_pre) S(t) (E_Syn ‚Äì V_Post)	I-Reply	I-1	Reply	151
Where G(V_pre) = m(t)	I-Reply	I-1	Reply	151
And dm/dt = (m_inf ‚Äì m) / tau_m	I-Reply	I-1	Reply	151
And m_inf = 1/(exp((V_shift ‚Äì V_pre)/V_range) +1)	I-Reply	I-1	Reply	151
And S(t) = n(t).	I-Reply	I-1	Reply	151
s(t)	I-Reply	I-1	Reply	151
And dn/dt = (n_inf ‚Äì n).	I-Reply	I-1	Reply	151
k_n ‚Äì n.k_r ‚Äì n. m(t)	I-Reply	I-1	Reply	151
<sep> n(t) describes the amount of available neurotransmitter vesicles.	I-Reply	I-1	Reply	151
With each firing of the neuron, n ¬∑ m vesicles are removed.	I-Reply	I-1	Reply	151
Vesicles are refilled from a reserve pool with a rate k_n and move to the reserve-pool with a rate k_r.	I-Reply	I-1	Reply	151
This type of model is described in [2]. With the right choice of parameters (Below), this leads to a decrease in the postsynaptic signal after a series of pulses.	I-Reply	I-1	Reply	151
Without stimulation, the signal strength recovers over time.	I-Reply	I-1	Reply	151
<sep> s(t) is modelled in the following and provides the probability of the neurotransmitters arriving at the postsynaptic receptors [3]:	I-Reply	I-1	Reply	151
ds/dt = -s/tau_F + h	I-Reply	I-1	Reply	151
dh/dt = -h/tau_R ‚Äì h0 .	I-Reply	I-1	Reply	151
delta(t-t0)	I-Reply	I-1	Reply	151
where t0 is the time of the beginning of neurotransmitter release.	I-Reply	I-1	Reply	151
<sep> ‚Ä¢<tab>Parameters of m(t): tau_m = 5 ms, V_range = 4 mV, V_shift = -30 mV.	I-Reply	I-1	Reply	151
‚Ä¢<tab>Parameters of S(t): n_inf = 10000, k_r = 0.01 1/ms and k_n = 0.08 1/ms, tau_R = 2.5 ms, tau_F = 5ms, h0 = 10, t0 = recorded at V_pre > 59mV,	I-Reply	I-1	Reply	151
<sep> This is part of the analyses we have conducted fully quantitative.	I-Reply	I-1	Reply	151
We kept the paper in a high-level description for the readability.	I-Reply	I-1	Reply	151
Accordingly, we targeted to include all these mathematical descriptions within the poster we provide there at the workshop.	I-Reply	I-1	Reply	151
<sep> I would sincerely ask the reviewer to reevaluate our work, given our recent comments.	I-Reply	I-1	Reply	151
<sep> Thank you very much for your kind consideration.	I-Reply	I-1	Reply	151
<sep> <sep> <sep> References	O	O	Reply	151
<sep> [1] Shi-Qing Cai, Yi Wang, Ki Ho Park, Xin Tong, Zui Pan, and Federico Sesti.	O	O	Reply	151
Auto-phosphorylation of a voltage-gated k+ channel controls non-associative learning.	O	O	Reply	151
The EMBO journal, 28(11):1601‚Äì1611, 2009.	O	O	Reply	151
<sep> [2] David Sterratt, Bruce Graham, Andrew Gillies, and David Willshaw.	O	O	Reply	151
Principles of computational modelling in neuroscience.	O	O	Reply	151
Cambridge University Press, 2011.	O	O	Reply	151
<sep> [3] Erik De Schutter.	O	O	Reply	151
Computational modeling methods for neuroscientists.	O	O	Reply	151
The MIT Press, 2009.	O	O	Reply	151

The new network architecture proposed in the paper is novel.	O	O	Review	151
The experiment results show this architecture compares favorable with MalConv on a data set collected by the authors.	O	O	Review	151
It is good to know that learned features also help to improve accuracy.	O	O	Review	151
Several questions:	O	O	Review	151
1) Are the malicious and benign examples balanced?	B-Review	B-1	Review	151
<sep> 2) Is the good performance due to its deeper structure comparing with MalConv?	B-Review	B-2	Review	151
How long is training time?	I-Review	I-2	Review	151
<sep> 3) Why does SELU help here?	B-Review	B-3	Review	151
<sep> <sep> <sep> 1) Yes, clean and malicious examples are roughly balanced in the dataset	B-Reply	B-1	Reply	151
2) We have not experimented extensively with the depth but we were not able to improve upon the shallow MalConv, so we assume that depth helps.	B-Reply	B-2	Reply	151
Training time is between 2-3 days on the full dataset.	I-Reply	I-2	Reply	151
<sep> 3) After recent repeated multiple experiments with sole ReLU activations in all layers, we found no measurable difference.	B-Reply	B-3	Reply	151
We apologize for a hurried conclusion in our abstract based upon a single run (each run is simply too expensive for us).	I-Reply	I-3	Reply	151

This paper proposes to use a convolutional neural network, taking program binaries as inputs, to detect malware.	O	O	Review	151
The results are on par with a network that takes in hand-crafted features, and the hidden layers are shown to be complementary to the hand-crafted features.	O	O	Review	151
<sep> <sep> The paper is well written and easy to follow.	O	O	Review	151
The descriptions of the experiments are complete.	O	O	Review	151
One minor thing missing is the learning rate of the Adam optimizer.	O	O	Review	151
<sep> <sep> I have a more fundamental question about the task.	B-Review	B-1	Review	151
How much does the model learn to identify parts of the problematic source code?	I-Review	I-1	Review	151
How much does the model learn to identify signs unrelated to the source code, such as things in the header?	I-Review	I-1	Review	151
I assume that in many cases you can judge whether a piece of binary is malware just by looking at the cosmetics of the program, but these features might not generalize well in the long run.	I-Review	I-1	Review	151
I assume it would be much more useful to identify certain sequence of instructions and memory addresses based on cpu architectures.	I-Review	I-1	Review	151
It would be great to analyze the CNN to see what it is paying attention to.	I-Review	I-1	Review	151
<sep> <sep> The other fundamental question about the task is obfuscation.	B-Review	B-2	Review	151
On the one hand, in theory there is no universal tool to overcome obfuscation (with the standard crypto assumptions).	I-Review	I-2	Review	151
On the other hand, it's probably easy to detect trivial obfuscation, because the resulting program binaries would look significantly different from regular program binaries.	I-Review	I-2	Review	151
How often are binaries obfuscated in general?	I-Review	I-2	Review	151
How do these affect the model's performance?	I-Review	I-2	Review	151
What are the characteristics of regular program binaries?	I-Review	I-2	Review	151
<sep> <sep> Programs as data are more stringent than natural images and words.	B-Review	B-3	Review	151
The CNNs might require a lot of effort just learning the common idioms of programming, such as control flows, loops, from the binaries.	I-Review	I-3	Review	151
I think the CNNs might benefit from these high-level constructs/templates when identifying malwares.	I-Review	I-3	Review	151
Since CNNs or deep models in general are strong at coping with noise, it might be useful to look at how they behave on mutated malware.	I-Review	I-3	Review	151
1) According to the latest experiments with Guided Backpropagation combined with Grad-CAM, we saw no "explanation" based on a machine code (however, the number of manually inspected samples and the time spent have been very limited so far).	B-Reply	B-1	Reply	151
In this aspect the automatic convolutional features might be very similar to the traditional hand-engineered features which cover mainly the "envelope" of the executable	I-Reply	I-1	Reply	151
<sep> 2) We do think that obfuscation can be overcome in theory, emulation/sandboxing being one (relatively) universal tool.	B-Reply	B-2	Reply	151
However we do not expect the convnet to do the job.	I-Reply	I-2	Reply	151
Because of the type "explanations" we have observed so far, we think that the performance may not be hurt significantly by including obfuscated files (indeed we use fairly simple/imperfect detection of obfuscation and our dataset certainly contains a large portion of obfuscated files already).	I-Reply	I-2	Reply	151
Tests on the whole collection will be hopefully ready soon.	I-Reply	I-2	Reply	151
<sep> Obfuscation is quite common for the current malware but majority can be reversed by manually crafted "unpackers", that is another option.	I-Reply	I-2	Reply	151
<sep> <sep> 3) We believe that we can force the deep nets to focus on the code itself is by inputting emulation/sandboxing output instead of the file.	B-Reply	B-3	Reply	151
That is definitely one of the major directions for further research.	I-Reply	I-3	Reply	151

This paper extended the flow-based generative model for stochastic video prediction.	O	O	Review	151
The proposed model takes an advantage of the flow-based models which provide exact latent-variable inference, exact log-likelihood evaluation, and efficiency.	O	O	Review	151
The paper used the autoregressive model and the multi-scale Glow architecture.	O	O	Review	151
The experiments on the stochastic movement dataset (synthetic) and the BAIR Robot push dataset show the performance improvement against other state-of-the-art stochastic video generation models (SV2P and SAVP-VAE).	O	O	Review	151
<sep> <sep> The main contribution in this paper is the use of flow-based models for video prediction, and it is the first work in this direction.	O	O	Review	151
The major idea sounds and the paper is clearly written.	O	O	Review	151
<sep> <sep> Below is my concerns and the feedback.	O	O	Review	151
<sep> <sep> It looks like the low-temperature sampling is important to achieve the better scores for prediction.	B-Review	B-1	Review	151
Can the low-temperature sampling trick be applied for SV2P and SAVP-VAE as well?	I-Review	I-1	Review	151
If then, how is the performance difference compare to the proposed model?	I-Review	I-1	Review	151
<sep> <sep> The authors reported the best possible values of PSNR, SSIM and VGG perceptual metrics by choosing the video closest to the ground-truth.	B-Review	B-2	Review	151
However, I believe this evaluation does not present the benefit of the stochastic models.	I-Review	I-2	Review	151
The better comparison I believe is to report the median/mean with the range between best and worst values.	I-Review	I-2	Review	151
<sep> <sep> The BAIR robot push dataset is with a pretty limited setting: a small robot and/or object motion between frames and a small variation of the background between videos.	B-Review	B-3	Review	151
It would be interesting to see more dynamic scenarios such as driving or human motion scenes.	I-Review	I-3	Review	151
We thank for your reviews.	O	O	Reply	151
Please find attached our response.	O	O	Reply	151
<sep> <sep> Low temperature Sampling	O	O	Reply	151
--------------------------------------	O	O	Reply	151
As suggested, in the updated version of the paper, we included experiments in which we applied low-temperature sampling to the latent gaussian priors of SV2P and SAVP-VAE.	B-Reply	B-1	Reply	151
We report our results in Section D (Effect of Temperature on SAVP-VAE and SV2P ) of the appendix in the revision.	I-Reply	I-1	Reply	151
We empirically find that decreasing temperature from 1.0 to 0.0 monotonically decreases the performance of the VAE models.	I-Reply	I-1	Reply	151
<sep> <sep> Our insight is that the VideoFlow model gains by low-temperature sampling (upto a certain temperature) due to the following reason.	I-Reply	I-1	Reply	151
By decreasing the temperature of the flow model, we trade-off between a performance gain by noise removal from the background and a performance hit due to reduced stochasticity of the robot arm.	I-Reply	I-1	Reply	151
<sep> <sep> On the other hand, the VAE models have a clear but slightly blurry background throughout from T=1.0 to T=0.0.	I-Reply	I-1	Reply	151
Reducing T in this case, solely reduces the stochasticity of the arm motion thus hurting performance.	I-Reply	I-1	Reply	151
<sep> <sep> Reporting best vs mean	O	O	Reply	151
---------------------------------	O	O	Reply	151
In the updated version paper, we added a summary of our response below to the sub-section "Accuracy of the best sample" in Section 5.2 to make this clear.	B-Reply	B-2	Reply	151
<sep> <sep> The BAIR dataset is highly stochastic and the number of plausible futures are high.	I-Reply	I-2	Reply	151
Each generated video can be super realistic, can represent a plausible future in theory but can be far from the single ground truth video perceptually.	I-Reply	I-2	Reply	151
The best values according to the PSNR, SSIM and VGG metrics from a finite number of samples is a proxy to help us understand if the ground truth can lie in the set of possible futures as per the model.	I-Reply	I-2	Reply	151
<sep> <sep> Consider a hypothetical scenario where there are eight plausible but completely diverse future frames, such that the pairwise perceptual similarity between the frames ~= 0.0.	I-Reply	I-2	Reply	151
Let us also consider the perfect model that is capable of generating each of these future frames accurately.	I-Reply	I-2	Reply	151
<sep> <sep> If we, compute the similarity of each sample with the ground truth video, and average this across multiple samples, we would get a similarity of ~ 12.5%.	I-Reply	I-2	Reply	151
The ‚Äúmean‚Äù in this case is not a useful statistic and the ‚Äúbest‚Äù quantifies the performance of the stochastic model better.	I-Reply	I-2	Reply	151
This metric should be also used in combination with the Amazon MTurk results in Figure 3 and Section 5.2 to assess if the generated videos are realistic.	I-Reply	I-2	Reply	151
<sep> <sep> BAIR Robot dataset	O	O	Reply	151
----------------------------	O	O	Reply	151
In regard to our choice of the BAIR dataset for comparisons, it is a standard evaluation benchmark used in the stochastic video prediction literature. [	B-Reply	B-3	Reply	151
Babazeidah et al 2018, Lee et al 2018, Unterthiner et al 2018, Denton &amp; Fergus 2018, Weissenborn et al 2019]. We believe the BAIR robot dataset is challenging due to its stochasticity i.e. there are multiple possible futures for the robot arm in the absence of supervision via actions as well as unknown physical properties of the objects.	I-Reply	I-3	Reply	151
A network unable to model the stochasticity (e.g. a deterministic network) would blur the arm out in all possible directions.	I-Reply	I-3	Reply	151
We agree that including experiments on larger and high resolution datasets would indeed be even more interesting to explore in future.	I-Reply	I-3	Reply	151

The paper "VideoFlow: A Conditional Flow-Based Model for Stochastic Video " proposes a new model for video prediction from a starting sequence of conditionning frames.	O	O	Review	151
It is based on a state-space model that encodes successive frames in a continuous hierarchical state, with contraints on trajectories of the codes in this state.	O	O	Review	151
<sep> <sep> I like the invertible NN framework the model relies on.	O	O	Review	151
It allows to avoid variational autoencoding of frames via invertible deterministic transforms.	O	O	Review	151
Learning the dynamics of the video is therefore easier, since there is no need of any stochastic inference process.	O	O	Review	151
However, is there no risk of high latent vacancy in the representation space?	B-Review	B-5	Review	151
Uncertainty of stochastic inference usually helps filling the space by considering larger areas of codes than deterministic process.	I-Review	I-5	Review	151
Also, since at each step, the next code is conditionned by the whole past sequence of codes, besides the increasing complexity induced, I am wondering if such a model is able to efficiently encode the dynamics and the stochasticity of the video.	I-Review	I-5	Review	151
In fact, a given z_t does not encode any dynamics nor uncertainty at that point, only the image (it cannot since it is fully determined via the invertible function from the image).	I-Review	I-5	Review	151
Imagine that at a given point, two very different scenarios can follow, with very different following frames.	I-Review	I-5	Review	151
In that case, how could the next state could encode these two different futures with a simple gaussian in the space ?	I-Review	I-5	Review	151
Also,  it would be useful to compare the model with a version where the invertible frame encoder and the sequential model would be learned separately, to better understand what the model really does during training.	B-Review	B-3	Review	151
A study of the impact of the hierarchy depth would also be useful.	B-Review	B-4	Review	151
<sep> Also, an additional real-world dataset would be useful for really assessing the performance of the model, since BAIR is known to be fully random and the past does not highly impact the future.	B-Review	B-2	Review	151
A possible dataset would be KTH.	I-Review	I-2	Review	151
Other baselines could also be considered, notably the famous approach from  [Denton et al 2017].	I-Review	I-2	Review	151
<sep> At last, the clarity of some parts could be improved.	B-Review	B-1	Review	151
Notably the description of the sequential model in the space, whih is succintly given in the appendix.	I-Review	I-1	Review	151
<sep> <sep> We thank you for your reviews.	O	O	Reply	151
Please find attached our response.	O	O	Reply	151
<sep> <sep> Q: Clarity can be improved:	O	O	Reply	151
<sep> We added the following changes to our revision.	O	O	Reply	151
<sep> 1.	B-Reply	B-1	Reply	151
We added network diagrams of the 3-D residual network used to model temporal dependencies (Figure 8) in the appendix, to assist the description of the sequential model in the appendix (Section B).	I-Reply	I-1	Reply	151
<sep> 2.	O	O	Reply	151
We added Section 4.1, where we briefly explain the multi-scale architecture before moving on to the autoregressive latent dynamics model.	B-Reply	B-1	Reply	151
We describe the invertible transformations used in the multi-scale architecture and how the per-frame latent variables per level (scale) are inferred.	I-Reply	I-1	Reply	151
<sep> 3.	O	O	Reply	151
We added the second last paragraph under Section 4.2 that describes how the invertible multi-scale architecture and the autoregressive latent dynamics model contribute to different parts of the training objective.	B-Reply	B-1	Reply	151
<sep> <sep> Q: Additional baseline and dataset	O	O	Reply	151
<sep> As requested, we added results from SVG-LP [Denton &amp; Fergus 2018], another strong baseline to Figure 4 and Figure 3.	B-Reply	B-2	Reply	151
VideoFlow either outperforms or is comparable to SVG-LP on all metrics in the paper.	I-Reply	I-2	Reply	151
We also added results from CDNA [Finn et al 2016], a strong deterministic baseline to our results in Figure 4.	I-Reply	I-2	Reply	151
<sep> <sep> In regard to our choice of the BAIR dataset for comparisons, it is a standard evaluation benchmark used in the stochastic video prediction literature.	I-Reply	I-2	Reply	151
We believe the BAIR robot dataset is challenging due to its stochasticity i.e. there are multiple possible futures for the robot arm in the absence of supervision via actions as well as unknown physical properties of the objects.	I-Reply	I-2	Reply	151
We agree that including experiments on larger and high resolution datasets would indeed be even more interesting to explore in future	I-Reply	I-2	Reply	151
<sep> Q: Learning the invertible encoder and sequential model separately	O	O	Reply	151
<sep> We did attempt training the invertible encoder and sequential model separately in our initial experiments.	B-Reply	B-3	Reply	151
We compared:	I-Reply	I-3	Reply	151
1.	I-Reply	I-3	Reply	151
Training the sequential model and the invertible flow encoder jointly. (	I-Reply	I-3	Reply	151
our current version)	I-Reply	I-3	Reply	151
2.	I-Reply	I-3	Reply	151
Two stage training process:	I-Reply	I-3	Reply	151
Stage a): Pretraining the invertible flow encoder to model individual frames that provides stable latent representations.	I-Reply	I-3	Reply	151
<sep> Stage b): (Training the sequential model + Fine-tuning the flow encoder) on video.	I-Reply	I-3	Reply	151
<sep> <sep> We found out that after pre-training the invertible flow encoder (i.e 2a), (2b) does indeed converge faster as compared to 1.	I-Reply	I-3	Reply	151
<sep> But the total compute time of 2 (2a + 2b), was similar to (1).	I-Reply	I-3	Reply	151
In addition this training scheme added increased complexity to our model, so we disbanded this after our initial efforts.	I-Reply	I-3	Reply	151
<sep> <sep> Q: Impact of hierarchy depth	O	O	Reply	151
<sep> With a flow level of 1, our generated samples were able to capture the global structure of the robotic arm (for eg, a red blob).	B-Reply	B-4	Reply	151
This is similar to Fig 9 in [Kingma &amp; Dhariwal, 2018], where a flow model with a lower number of levels of hierarchy captures global structure.	I-Reply	I-4	Reply	151
We also show qualitatively in [1] and Section 5.3, that the latents at lower levels encode background objects as smaller scales while higher levels encode larger objects, such as the robotic arm.	I-Reply	I-4	Reply	151
<sep> <sep> Q: .... The next code is conditioned by the whole past sequence of codes, besides the increasing complexity induced.....	O	O	Reply	151
<sep> For computational efficiency, we limit the history of the codes that we condition on to a window of 3 frames.	B-Reply	B-5	Reply	151
We report this in Section 5.2 and the first paragraphs of Section 5.4.	I-Reply	I-5	Reply	151
We empirically find that this sufficient to infer the dynamics of the dataset.	I-Reply	I-5	Reply	151
This works quite well, but we do see that this Markovian assumption does have artifacts in the case of occlusions and obstructions that we report in Section 5.4 (Longer predictions)	I-Reply	I-5	Reply	151

This paper presents a stochastic model based on Glow for conditional video generation.	O	O	Review	151
The major novelty of this work is to introduce the flow-based models to video modeling and learn the video dynamics via the dependencies of the latent variables.	O	O	Review	151
The general idea is reasonable and the proposed model is technically correct, but I have the following concerns mainly about the originality and the experiments.	O	O	Review	151
<sep> **Above all, most of the text in Section 3 is very similar (or exactly the same) to the text of the Glow paper (the background section).**	O	O	Review	151
<sep> <sep> ‚Äî Significance and originality ‚Äî	O	O	Review	151
a.1) In Section 1, the authors discussed some possible application scenarios of video prediction models, e.g. learning from unlabeled data and being used for downstream tasks.	B-Review	B-4	Review	151
However, all models mentioned here, including [Mathieu et al 2016] and [Finn et al 2016], are deterministic models.	I-Review	I-4	Review	151
Thus, in what way can the stochastic model proposed in this paper be used in real applications?	I-Review	I-4	Review	151
<sep> <sep> a.2) VideoFlow can be viewed as an extension of the Glow model.	B-Review	B-5	Review	151
There are two problems.	I-Review	I-5	Review	151
First, the originality is limited.	I-Review	I-5	Review	151
I don‚Äôt think modeling the temporal dependencies of the latent variables with a convolutional network is a significant contribution to the conditional flow-based methods.	I-Review	I-5	Review	151
Second, this paper is not self-contained.	I-Review	I-5	Review	151
After reading Section 4.2, I have to check the previous literature to find the objective function, the network details, or the training procedure.	I-Review	I-5	Review	151
<sep> <sep> ‚Äî Experiments ‚Äî	O	O	Review	151
b.1) Throughout the experiments, the VideoFlow model is mainly compared with two stochastic video prediction models that were probably proposed by the same research group.	B-Review	B-1	Review	151
If it is possible, the authors might include other stochastic models such as the SVG-LP [Denton &amp; Fergus 2018], and at least one deterministic model such as the E3D-LSTM [Wang et al 2019] as well.	I-Review	I-1	Review	151
<sep> [Wang et al 2019] E3D-LSTM: A Model for Video Prediction and Beyond.	I-Review	I-1	Review	151
<sep> <sep> b.2) The evaluation metric bits-per-pixel was not directly optimized by the previous video generation/prediction models.	B-Review	B-2	Review	151
Thus, the comparisons in Table 2 might be unfair.	I-Review	I-2	Review	151
<sep> <sep> b.3) Since training the Glow model requires a huge computational cost, how is the training efficiency of the VideoFlow model compared with other stochastic video generation models?	B-Review	B-3	Review	151
<sep> <sep> ‚Äî Other ‚Äî	O	O	Review	151
c.1) In Section 4, it is not clear what the temporal border effect means?	B-Review	B-6	Review	151
<sep> <sep> AFTER REBUTTAL:	O	O	Review	151
Though the overall novelty is still not fully convincing, this paper may shed some insights into video generation by introducing flow-based models to this topic.	B-Review	B-7	Review	151
I have increased my score from 3 to 6.	O	O	Review	151
We thank you for your reviews.	O	O	Reply	151
We believe we have addressed your concern about the writing in the revision.	O	O	Reply	151
Please find attached our detailed response below.	O	O	Reply	151
<sep> <sep> Experiments	O	O	Reply	151
-----------------	O	O	Reply	151
b1) SVG-LP: As requested, we added results from SVG-LP [Denton &amp; Fergus 2018], another strong baseline to Figure 4 and Figure 3 in our revision.	B-Reply	B-1	Reply	151
VideoFlow either outperforms or is competent with SVG-LP on all the metrics used in the paper.	I-Reply	I-1	Reply	151
<sep> <sep> Deterministic baseline: We evaluated two deterministic baselines CDNA [Finn et al, 2016] and EPVA [Wichers et al, 2017] on the BAIR Robot pushing dataset.	I-Reply	I-1	Reply	151
The samples from the CDNA model were qualitatively better as compared to the samples from the EPVA model.	I-Reply	I-1	Reply	151
So, we added results from [Finn et al, 2016] on multiple metrics to Figure 4 of our revision.	I-Reply	I-1	Reply	151
<sep> <sep> b2) We believe we made a good-faith effort; We estimated the best-possible beta for the video-VAE‚Äôs post training.	B-Reply	B-2	Reply	151
We also employed importance sampling using 100 samples from the posterior which gives a much tighter bound on the bits-per-pixel.	I-Reply	I-2	Reply	151
Our goal was to measure how the VAE models perform out-of-the-box on a density estimation task.	I-Reply	I-2	Reply	151
In other words, in addition to being better / competent with the VAE approaches, our model also has the additional advantage of good likelihood numbers.	I-Reply	I-2	Reply	151
<sep> <sep> b3) Our VideoFlow model reported in the paper has 45M parameters as compared to SVG-LP that has around 23M parameters.	B-Reply	B-3	Reply	151
But, we performed the following experiments to make a convincing case.	I-Reply	I-3	Reply	151
<sep> <sep> * We trained a smaller version of our model (VideoFlow small) with 12M parameters.	I-Reply	I-3	Reply	151
We report our results in Section I of the appendix (VideoFlow: low parameter regime) in the revision.	I-Reply	I-3	Reply	151
We are slightly better than SVG-LP on VGG perceptual metrics despite being 2x smaller.	I-Reply	I-3	Reply	151
We lose ~0.2 bpp as compared to VideoFlow large but our samples are still largely coherent. [	I-Reply	I-3	Reply	151
2,3]	I-Reply	I-3	Reply	151
<sep> * For VideoFlow small and VideoFlow large, we reported our results after 5 days and 2 weeks (600K steps) on 8 GPU‚Äôs respectively.	B-Reply	B-3	Reply	151
But we gain very little (around 0.04-0.05 bpp) between training our model for 200K and 600K steps.	I-Reply	I-3	Reply	151
We attached our bits-per-pixel on the validation set as a function of training steps over here which validates this claim [1]. We were able to generate high quality samples within 150-200K steps.	I-Reply	I-3	Reply	151
We expect our results should be comparable or slightly worse if at all, when evaluated on a checkpoint at 200K steps.	I-Reply	I-3	Reply	151
In comparison, the video-VAE models were trained between 2-3 days on 1 GPU.	I-Reply	I-3	Reply	151
<sep> <sep> In future, we could leverage improvements in normalizing flows to further close this gap.	I-Reply	I-3	Reply	151
<sep> <sep> Significance	O	O	Reply	151
----------------	O	O	Reply	151
a.1) Good examples are [Hafner et al 2018] and [Kaiser at al 2018] where they report higher scores in numerous planning and reinforcement learning tasks by utilizing stochastic video prediction models.	B-Reply	B-4	Reply	151
Also, [Nair et al 2018], leverage a stochastic video prediction model for self-supervision.	I-Reply	I-4	Reply	151
<sep> <sep> In short, a deterministic model cannot accurately model settings where there are multiple possible outcomes, (most real-life settings) and is obliged to predict a statistic of all the possible outcomes.	I-Reply	I-4	Reply	151
<sep> <sep> Other	O	O	Reply	151
--------	O	O	Reply	151
We replaced this with ‚Äúwithout introducing such artifacts‚Äù in our latest version.	B-Reply	B-6	Reply	151
<sep> <sep> <sep> [1] <a href="https://ibb.co/NNrwfGm" target="_blank" rel="nofollow">https://ibb.co/NNrwfGm</a>	O	O	Reply	151
[2] <a href="https://gifyu.com/image/v9Rp" target="_blank" rel="nofollow">https://gifyu.com/image/v9Rp</a>	O	O	Reply	151
[3]  <a href="https://gifyu.com/image/v9RT" target="_blank" rel="nofollow">https://gifyu.com/image/v9RT</a>	O	O	Reply	151

The paper presents an approach to learning shared neural representations of temporal abstractions in hierarchical RL, based on actor-critic methods.	O	O	Review	397
The approach is illustrated in two tasks: gridworld with objects and a simplified Minecraft problem).	O	O	Review	397
The idea of providing symbolic descriptions of tasks and learning corresponding "implementations" is potentially interesting and the empirical results are promising.	B-Review	B-1	Review	397
However, there are two main drawbacks of the current incarnation of this work.	I-Review	I-1	Review	397
First, the ideas presented in the paper have all been explored in other work (symbolic specifications, actor-critic, shared representations).	I-Review	I-1	Review	397
While related work is discussed, it is not really clear what is new here, and what is the main contribution of this work besides providing a new implementation of existing ideas in the context of deep learning.	I-Review	I-1	Review	397
The main contribution if the work needs to be clearly spelled out.	B-Review	B-2	Review	397
Secondly, the approach presented relies crucially on curriculum learning (this is quite clear from the experiments).	I-Review	I-2	Review	397
While the authors argue that specifying tasks in simplified language is easy, designing a curriculum may in fact be pretty complicated, depending on the task at hand.	I-Review	I-2	Review	397
The examples provided are fairly small, and there is no hint of how curriculum can be designed for larger problems.	I-Review	I-2	Review	397
Because the approach is sensitive to the curriculum, this limits the potential utility of the work.	I-Review	I-2	Review	397
It is also unclear if there is a way to provide supervision automatically, instead of doing it based on prior domain knowledge.	I-Review	I-2	Review	397
<sep> More minor comments:	O	O	Review	397
- The experiments are not described in enough detail in the paper.	B-Review	B-3	Review	397
It's great to provide github code, but one needs to explain in the paper why certain choices were made in the task setup (were these optimized?	I-Review	I-3	Review	397
What's this the first thing that worked?)	I-Review	I-3	Review	397
Even with the code, the experiments as described are not reproducible	I-Review	I-3	Review	397
- The description of the approach is pretty tangled with the specific algorithmic choices.	B-Review	B-4	Review	397
Can the authors step back and think more generally of how this approach can be formalized?	I-Review	I-4	Review	397
I think this would help relate it to the prior work more clearly as well.	I-Review	I-4	Review	397
NOVELTY	O	O	Reply	397
<sep> As described in the related work section, our approach indeed shares a number of similarities in existing work on learning hierarchical policy representations.	B-Reply	B-1	Reply	397
Structurally the model is quite similar to the Option--Critic approach of Bacon & Precup; this is not intended to be a contribution of the paper.	I-Reply	I-1	Reply	397
What we claim to be novel are (1) the training condition (using discrete high-level policy representations without an explicit grounding or feature abstraction hierarchy) and (2) the objective (using the small amount of extra structure in the training data to decouple actors from critics across multiple tasks).	I-Reply	I-1	Reply	397
You mention that symbolic specifications have been explored in other work---as discussed in our earlier comment, we've done our best to describe the differences with nearest neighbors, but are not aware of any previous approaches that learn with as little high-level supervision as we use here.	I-Reply	I-1	Reply	397
Again, if you can let us know exactly what you have in mind we would greatly appreciate it!	I-Reply	I-1	Reply	397
<sep> <sep> CURRICULA	O	O	Reply	397
<sep> The general curriculum learning approach (Algorithm 2) can construct a sampling distribution for any collection of tasks: it relies only on the sketch length and the current empirical performance of the model, both of which can be computed without any task-specific engineering.	B-Reply	B-2	Reply	397
The collections of tasks in this paper were in fact designed to give rise to particularly challenging curricula (no length-1 tasks, various subpolicies that appear only as constituents of very long tasks, etc.)	I-Reply	I-2	Reply	397
and demonstrate robustness to decisions about task selection and curriculum design.	I-Reply	I-2	Reply	397
<sep> <sep> TASKS	O	O	Reply	397
<sep> We did most of our development on a restricted subset (only length-2 and length-3 sketches) of crafting domain tasks.	B-Reply	B-2	Reply	397
Generalization to longer crafting tasks, as well as generalization to the maze domain, worked out of the box without any modifications to the initial task design or tuning of hyperparameters.	I-Reply	I-2	Reply	397
As some evidence that the task design process is indeed reproducible, we are happy to point to follow-up work by Rob Fergus's group, who have already succeeded in reimplementing our tasks and evaluation for a different model architecture (<a href="https://uclmr.github.io/nampi/talk_slides/rob-nampi.pdf)."	I-Reply	I-2	Reply	397
target="_blank" rel="nofollow">https://uclmr.github.io/nampi/talk_slides/rob-nampi.pdf).</a>	I-Reply	I-2	Reply	397

This paper studies the problem of abstract hierarchical multiagent RL with policy sketches, high level descriptions of abstract actions.	O	O	Review	397
The work is related to much previous work in hierarchical RL, and adds some new elements by using neural implementations of prior work on hierarchical learning and skill representations.	O	O	Review	397
<sep> <sep> Sketches are sequences of high level symbolic labels drawn from some fixed vocabulary, which initially are devoid of any meaning.	O	O	Review	397
Eventually the sketches get mapped into real policies and enable policy transfer and temporal abstraction.	O	O	Review	397
Learning occurs through a variant of the standard actor critic architecture.	O	O	Review	397
<sep> <sep> Experiments are provided through a standard game like domain (maze, minecraft etc.).	O	O	Review	397
<sep> <sep> The paper as written suffers from two problems.	O	O	Review	397
One, the idea of policy sketches is nice, but not sufficiently fleshed out to have any real impact.	B-Review	B-1	Review	397
It would have been useful to see this spelled out in the context of abstract SMDP models to see what they bring to the table.	I-Review	I-1	Review	397
What one gets here is some specialized invocation of this idea in the context of the specific approach proposed here.	I-Review	I-1	Review	397
Second, the experiments are not thorough enough in terms of comparing with all the related work.	B-Review	B-2	Review	397
For example, Ghavamzadeh et al explored the use of MAXQ like abstractions in the context of mulitagent RL.	I-Review	I-2	Review	397
It would be great to get a more detailed comparison to MAXQ based multiagent RL approaches, where the value function is explicitly decomposed.	I-Review	I-2	Review	397
We have done our best to discuss relationships and provide comparisons with existing work on hierarchical policy learning, and would be happy to do so in more detail if told exactly what in the extremely large family of techniques for policy abstraction we should compare to.	B-Reply	B-1	Reply	397
We remain somewhat puzzled by references to multiagent RL.	B-Reply	B-2	Reply	397

The paper proposes a new RL architecture that aims at learning policies from sketches i.e sequence of high-level operations to execute for solving a particular task.	O	O	Review	397
The model relies on a hierarchical structure where the sub-policy is chosen depending on the current operation to execute in the sketch .	O	O	Review	397
The learning algorithm is based on an extension of the actor-critic model for that particular case, and also involves curriculum learning techniques when the task to solve is hard.	O	O	Review	397
Experimental results are provided on different learning problems and compared to baseline methods.	O	O	Review	397
<sep> <sep> The paper is well-written and very easy to follow.	B-Review	B-1	Review	397
I am not really convinced by the impact of such a paper since the problem solved here can be seen as an option-learning problem with a richer supervision (i.e the sequence of option is given).	I-Review	I-1	Review	397
It thus corresponds to an easier problem with a limited impact.	B-Review	B-2	Review	397
Moreover, I do not really understand to which concrete application this setting corresponds.	I-Review	I-2	Review	397
For example, learning from natural langage instructions is clearly more relevant.	I-Review	I-2	Review	397
So since the model proposed in this article is not a major contribution and shares many common ideas with existing hierarchical reinforcement learning methods,  the paper lacks a strong motivation and/or concrete application.	I-Review	I-2	Review	397
So, the paper only has a marginal interest for the RL community	I-Review	I-2	Review	397
<sep> @pros:	O	O	Review	397
* Original problem with well design experiments	O	O	Review	397
* Simple adaptation of the actor-critic method to the problem of learning sub policies	O	O	Review	397
<sep> <sep> @cons:	O	O	Review	397
* Very simple task that can be seen as a simplification of more complex problems like options discovery, hierarchical RL or learning from instructions	B-Review	B-1	Review	397
* No strong underlying applications that could help to 'reinforce' the interest of the approach	B-Review	B-2	Review	397
<sep> <sep> TRAINING CONDITION	O	O	Reply	397
<sep> We could have done a better job of making this clearer: The reviewer is correct that there is not a natural source of sketch-like training annotations (as there is for e.g. natural language instructions).	B-Reply	B-1	Reply	397
Our claim is that these sketches are nonetheless extremely easy to produce, contain very few bits of information, but nevertheless result in dramatic improvements in training performance.	I-Reply	I-1	Reply	397
The extra annotation we use here literally fits in a 10-line text file.	I-Reply	I-1	Reply	397
We thus think it is reasonable for system designers to take a few minutes to write such a file, and then use a training objective that can efficiently exploit the information contained in it.	I-Reply	I-1	Reply	397
<sep> <sep> NATURAL LANGUAGE	O	O	Reply	397
<sep> We also want to emphasize that the learning problem considered here is very different from the one normally encountered in natural language processing.	B-Reply	B-2	Reply	397
There, the learned model is a policy that conditions on both environment states and text to determine next actions; this policy is completely useless in the absence of instructions.	I-Reply	I-2	Reply	397
By contrast, our approach induces a collection of options that can later be employed in sketch- or language-free hierarchical RL sections (as shown in the final experiment in our paper), making the approach much more general.	I-Reply	I-2	Reply	397
We are not aware of any work that uses natural instructions to induce policy fragments that can be executed even when those instructions are not present.	I-Reply	I-2	Reply	397
We believe the current work is the first step in that direction.	I-Reply	I-2	Reply	397

The paper introduces a novel way of learning Hamiltonian dynamics with a generative network.	O	O	Review	397
The Hamiltonian generative network (HGN) learns the dynamics directly from data by embedding observations in a latent space, which is then transformed into a phase space describing the system's initial (abstract) position and momentum.	O	O	Review	397
Using a second network, the Hamiltonian network, the position and momentum are reduced to a scalar, interpreted as the Hamiltonian of the system, which can then be used to do rollouts in the phase space using techniques known from, e.g., Hamiltonian Monte Carlo sampling.	O	O	Review	397
Finally, a decoder network can use the system's phase space location at any rollout step to generate images of the system.	O	O	Review	397
The HGN can further be modified, leading to a flow-based model, the Neural Hamiltonian Flow (NHF).	O	O	Review	397
<sep> The authors evaluate the HGN on four simulated physical systems, showing substantial improvements over the competing Hamiltonian Neural Network (HNN).	O	O	Review	397
Lastly, the NHF is shown to be able to model complex densities, which can further be interpreted in terms of the kinetic and potential energy.	O	O	Review	397
<sep> <sep> This paper is a rare treasure.	O	O	Review	397
It tackles a well-motivated problem and introduces a, to my knowledge, completely new framework for embedding Hamiltonian dynamics in a generative model.	O	O	Review	397
This is hugely inspiring!	O	O	Review	397
The paper is a joy to read and includes very informative figures providing a high-level understanding of the proposed models.	O	O	Review	397
Accept is a no-brainer.	O	O	Review	397
<sep> <sep> That being said, I have a few questions and suggestions for improvements.	O	O	Review	397
My biggest complaint is the evaluation of the NHF model.	B-Review	B-1	Review	397
I would have liked to see a comparison to a state-of-the-art flow-based model in terms of density modelling.	I-Review	I-1	Review	397
The authors state that the NHF offers more expressiveness and computational benefits over standard flow-based models, but this is never shown.	I-Review	I-1	Review	397
While I am willing to believe the claim, it is not intuitive to me, and I would have liked to see experimental verification of it.	I-Review	I-1	Review	397
<sep> <sep> Figure 6 needs a bit of love.	B-Review	B-2	Review	397
It is quite challenging to read.	I-Review	I-2	Review	397
Larger font sizes, conversion to vector format, and more distinguishable colours will help a lot.	I-Review	I-2	Review	397
<sep> Additionally, I think it would be helpful to have the derivation of the ELBO in Eq. (4) written out, e.g. in the supplementary material.	B-Review	B-3	Review	397
<sep> <sep> Additional questions:	O	O	Review	397
- In the experimental section, I am not sure what is meant by the deterministic version of HGN.	B-Review	B-4	Review	397
Which part if the model is deterministic?	I-Review	I-4	Review	397
<sep> - On p 6, it is mentioned that the Euler integrator results in an increased variance of the learnt Hamiltonian and that this can be seen in Fig.6.	B-Review	B-2	Review	397
How exactly is this seen in the figure?	I-Review	I-2	Review	397
<sep> - How many epochs were HNN and HGN trained for to produce table 1?	B-Review	B-5	Review	397
How do the convergence rates look, and how long time did they take to train?	I-Review	I-5	Review	397
<sep> <sep> Minor comments:	B-Review	B-6	Review	397
- p 5: Reference to "Salimans et al" is missing the year.	I-Review	I-6	Review	397
<sep> - p 6: There is a hanging ')' after "as shown in Fig.6)."	I-Review	I-6	Review	397
<sep> - p 6: "reversed it time" -&gt; "reversed in time"	I-Review	I-6	Review	397
- In the reference for Glow, "Durk P Kingma" should be "Diederik P. Kingma".	I-Review	I-6	Review	397
<sep> <sep> <sep> Dear Reviewer, thank you for your thoughtful comments and feedback.	O	O	Reply	397
<sep> <sep> [Flows evaluations]: In the paper we do not explicitly claim that the NHF model in necessarily more expressive than other normalizing flows - this by itself is a very difficult comparison to do and it is likely that it is data dependent as well.	B-Reply	B-1	Reply	397
The key point is that our results suggest that it is at least on par with other flow-based models while providing some computational benefits.	I-Reply	I-1	Reply	397
These benefits, as discussed at the end of section 3.3 are that since the NHF is volume preserving by design we do not need to calculate the standard log determinant of the likelihood, because it is 0.	I-Reply	I-1	Reply	397
Additionally, similar to Neural ODEs (and RevNets for instance), you do not need to store the forward pass to compute gradients as the model can be directly inverted.	I-Reply	I-1	Reply	397
Finally, we can even use simple symplectic integrators, like the leapfrog integrator, when the Hamiltonian is separable, and this defines a valid volume preserving transformation even in the discrete case (e.g. not only in the limit dt-&gt;0).	I-Reply	I-1	Reply	397
We are running extra experiments to produce a quantitative comparison between NHF and some of the existing alternatives, which we will include in the paper as soon as the results are ready.	I-Reply	I-1	Reply	397
<sep> <sep> [Figure 6]: We have updated Fig.6 to improve readability by increasing the resolution of the plots and by splitting the comparisons between HGN, HNN, and the different versions of HGN into separate plots.	B-Reply	B-2	Reply	397
We have also moved the numbers indicating the variance of the learnt Hamiltonian over a single trajectory into Tbl.	I-Reply	I-2	Reply	397
2.	I-Reply	I-2	Reply	397
<sep> <sep> [Derivation of ELBO in Eq.4 (which is now Eq.6 in the new manuscript) at the end of the Appendix.	O	O	Reply	397
4]: We have provided a more detailed proof of Eq.	B-Reply	B-3	Reply	397
Hopefully, this clears up any confusion about the result.	I-Reply	I-3	Reply	397
<sep> <sep> [Deterministic HGN]: The deterministic version of HGN is equivalent to an autoencoder, where we remove the sampling step from the posterior q(z|x_0...x_T).	B-Reply	B-4	Reply	397
We have added this clarification to the text.	I-Reply	I-4	Reply	397
<sep> <sep> [Number of epochs and convergence curves]: We trained both models for 15000 iterations, with batch size of 16 for HGN, and 64 for the HNN.	B-Reply	B-5	Reply	397
This means that HGN trained for around 5 epochs and HNN trained for around 19.	I-Reply	I-5	Reply	397
This took around 16 hours to run.	I-Reply	I-5	Reply	397
We have included this information as well as the convergence curves for the four datasets in the Supplementary Materials.	I-Reply	I-5	Reply	397
<sep> <sep> We have also addressed your minor comments and fixed the typos.	B-Reply	B-6	Reply	397

Summary: The authors present a method for learning Hamiltonian functions that govern a dynamical directly from observational data.	O	O	Review	397
The basic approach uses three networks: 1) an inference network (I'm not clear why this is not just called an encoder), that maps past observations to a latent p,q space in a VAE-like fashion; 2) a Hamiltonian network that governs the time-evolution of the system over this latent state; and 3) a decoder network that outputs the observation from the latent state.	O	O	Review	397
In addition to introducing this basic formalism, the	O	O	Review	397
<sep> Comments: I have mixed opinions on this paper, though am leaning slightly toward acceptance.	O	O	Review	397
The overall notion of learning a Hamiltonian network directly is a great one, though really this is due to the Hamiltonian Neural Networks paper of Greydanus et al 2019.	B-Review	B-1	Review	397
Although the focus in that work is on applying learned Hamiltonian networks directly to physics-based data, they also have an encoder-decoder network just using a classical autoencoder instead of a VAE.	I-Review	I-1	Review	397
So my first impression is that the benefits of the proposed HGN over HNNs in Figure 6 is really just an artific of this replacement.	I-Review	I-1	Review	397
<sep> <sep> Perhaps because the authors also felt this was a marginal contribution, the paper's ultimate value may prove to be in the consideration of such networks for the purposes of normalizing flow models.	B-Review	B-2	Review	397
This portion seemed a little bit underdeveloped in the paper, to be honest, but overall the idea of parameterizing a normalizing flow with a Hamiltonian dynamical system seems like a good one (e.g., allowing for easier large-timestep inference).	I-Review	I-2	Review	397
But on the flipside, it does seem like the presentation here is rather brief, i.e., just defining the ELBO without much context or detail, etc.	I-Review	I-2	Review	397
<sep> <sep> Thus, while I'm very much on the fence on this paper, I think the marginal improvement over HNNs via a better encoder/decoder model, plus the realization that these methods are a good fit for normalizing flow models, altogether put the paper slightly above bar for me.	O	O	Review	397
Dear Reviewer, thank you for your thoughtful comments and feedback.	O	O	Reply	397
<sep> <sep> You are right that our work is closely related to the Hamiltonian Neural Network (HNN) model by Greydanus et al, 2019.	B-Reply	B-1	Reply	397
We would like to note that our work was done concurrently to the work by Greydanus and colleagues.	I-Reply	I-1	Reply	397
We would also like to clarify the differences between our Hamiltonian Generative Network (HGN) and HNN.	I-Reply	I-1	Reply	397
We apologize if this was not made clear in the original manuscript.	I-Reply	I-1	Reply	397
<sep> <sep> The most obvious difference is that HGN is a generative model and uses the VAE framework rather than a deterministic autoencoder to infer the phase space from pixels.	I-Reply	I-1	Reply	397
However, this difference does not account for our improved results, as even the deterministic version of our model greatly outperforms the HNN (see Table 1 in the original manuscript).	I-Reply	I-1	Reply	397
The key difference between the two methods is that our proposed HGN learns the Hamiltonian function directly, rather than learning its derivatives.	I-Reply	I-1	Reply	397
This is a very important distinction.	I-Reply	I-1	Reply	397
Because the HNN model learns the derivatives of the Hamiltonian, it requires access to the time derivatives dH/dp and dH/dq of the system, which means that the model is trained in an essentially supervised manner.	I-Reply	I-1	Reply	397
When there is no access to the true derivatives of the Hamiltonian for supervision, one has to resort to finite differences, which can be quite inaccurate.	I-Reply	I-1	Reply	397
On the other hand, our HGN model learns the energy function directly from data and does not require such supervision.	I-Reply	I-1	Reply	397
HNN also requires a priori knowledge of the dimensionality of the phase space and a separable Hamiltonian, while our model requires no a priori knowledge and does not depend on a separability assumption.	I-Reply	I-1	Reply	397
Finally, given that our model is generative, it can be sampled to generate novel rollouts, which HNN cannot.	I-Reply	I-1	Reply	397
Taking all of these factors together, our model is able to model all of the visual datasets considered in our paper well, while HNN struggles to learn anything beyond an average pixel reconstruction (see see Tbl.	I-Reply	I-1	Reply	397
1 and Figs.	I-Reply	I-1	Reply	397
6-7 in the original manuscript).	I-Reply	I-1	Reply	397
<sep> <sep> In terms of the Hamiltonian flows part of the paper, we have provided a more detailed proof of the ELBO in Eq.4 (which is now Eq.6 in the new manuscript) at the end of the Appendix.	B-Reply	B-2	Reply	397
We are also running extra experiments to produce a quantitative comparison between NHF and some of the existing alternatives, which we will include in the paper as soon as the results are ready.	I-Reply	I-2	Reply	397

The paper proposes two ideas: 1) Hamiltonian Generative Networks (HGN) and 2) Neural Hamiltonian Flow (NHF).	O	O	Review	397
<sep> <sep> Hamiltonian Generative Networks are generative models of high-dimensional timeseries which use hamiltonian differential equations to evolve latent variables (~position and ~momentum vectors) through time (using any differentiable integration scheme).	O	O	Review	397
Given the ~position vector a decoder network generate predictions.	O	O	Review	397
The initial latent variables are inferred using a VAE style inference network that takes a sequence of images as the input.	O	O	Review	397
The decoder, inference network and crucially the hamiltonian energy function is learned by minimizing a VAE style ELBO on observed sequences.	O	O	Review	397
The model induces a strong hamiltonian physics prior and is quite elegant all in all.	O	O	Review	397
The model is evaluated on 4 simulated physics tasks, and beats the only baseline the Hamiltonian Neural Network (HNN).	O	O	Review	397
<sep> <sep> Neural Hamiltonian Flow notes that hamiltonian dynamics are invertible and volume preserving, which is the properties you need for neural flow models.	O	O	Review	397
As such it propose to use a series of hamiltonian update steps with multiple learned energy functions as a flexible density estimator.	O	O	Review	397
The resulting density estimator is subjectively evaluated on three 2d toy density estimation tasks.	O	O	Review	397
<sep> <sep> I propose a weak accept as I think the paper is interesting and well written, but could be much better.	O	O	Review	397
The paper explains how both HGN and NHF work, but not much more.	O	O	Review	397
The HGN is only compared to a single other method (the closely related HNN), on four toy benchmarks.	B-Review	B-1	Review	397
The NHF is barely evaluated, and not compared to anything.	I-Review	I-1	Review	397
<sep> <sep> Does the authors actually care about modelling physics and think their method is superior at this?	B-Review	B-2	Review	397
If so, they should compare and contrast to some of the many, many papers on modelling physics, e.g. [1,2,3,4] and references herein.	I-Review	I-2	Review	397
If not, what do they care about?	I-Review	I-2	Review	397
Where do they think this model can be useful?	I-Review	I-2	Review	397
Why should anyone use this model over some of the many, many other models one could use?	I-Review	I-2	Review	397
<sep> <sep> Similarly for the NHF, if I only read this paper I have no idea whether it's better than any of the other flow based models.	B-Review	B-3	Review	397
Is it faster (to sample?	I-Review	I-3	Review	397
to eval likelihood?)	I-Review	I-3	Review	397
is it a better estimator?	I-Review	I-3	Review	397
Why should I use it?	I-Review	I-3	Review	397
<sep> <sep> I think the paper would benefit from being split into two papers, each thoroughly examining one idea.	B-Review	B-4	Review	397
<sep> <sep> A few questions and minor comments	O	O	Review	397
<sep> - While the hamiltonian dynamics expect position and momentum vectors, the neural network is free to use those however it sees fit.	B-Review	B-5	Review	397
Actually, if I understand correctly, the position vector must also encode the color of the objects for the 2 and 3 body problem.	I-Review	I-5	Review	397
Is that correct?	I-Review	I-5	Review	397
It would be interesting if you could examine how predictive the q and p vectors were of the true position and momentum vectors.	I-Review	I-5	Review	397
<sep> - Successful experiments with n-body problems with n randomly sampled during training and unseen n used in testing would be very powerful in showing generalization.	B-Review	B-6	Review	397
I'm afraid that the current setup doesn't generalize well.	I-Review	I-6	Review	397
<sep> - I'm surprised that the generated images start showing artifacts after some time, e.g. pendulum sample 4 and 6 in <a href="https://docs.google.com/presentation/d/e/2PACX-1vRD2FnKgymgR2lU8lE6-XM8Cz-UWLTI6n_Uht3v6Gu4hIyMHmOcNL5D-0eG6Z4WHDAWS4qFosU-lxXP/pub?start=false&amp;loop=false&amp;delayms=3000&amp;slide=id.g61bbdf339d_0_426."	B-Review	B-7	Review	397
target="_blank" rel="nofollow">https://docs.google.com/presentation/d/e/2PACX-1vRD2FnKgymgR2lU8lE6-XM8Cz-UWLTI6n_Uht3v6Gu4hIyMHmOcNL5D-0eG6Z4WHDAWS4qFosU-lxXP/pub?start=false&amp;loop=false&amp;delayms=3000&amp;slide=id.g61bbdf339d_0_426.</a> How can those appear if the hamiltonian dynamics preserve energy?	I-Review	I-7	Review	397
<sep> - Equation 3 is given as self evident.	B-Review	B-8	Review	397
It's not clear to me why 1) det(I+dt*A) = 1+dt*Tr(A)+O(dt^2).	I-Review	I-8	Review	397
Can the authors give a reference?	I-Review	I-8	Review	397
Also, doesn't the O(dt^2) term accumulate over multiple timesteps or longer rollouts?	I-Review	I-8	Review	397
if so, how can the multiple steps proposed be said to be volume preserving?	I-Review	I-8	Review	397
<sep> <sep> [1] - Battaglia, Peter, et al "Interaction networks for learning about objects, relations and physics."	O	O	Review	397
Advances in neural information processing systems.	O	O	Review	397
2016.	O	O	Review	397
<sep> [2] - de Avila Belbute-Peres, Filipe, et al "End-to-end differentiable physics for learning and control."	O	O	Review	397
Advances in Neural Information Processing Systems.	O	O	Review	397
2018.	O	O	Review	397
<sep> [3] - Santoro, Adam, et al "A simple neural network module for relational reasoning."	O	O	Review	397
Advances in neural information processing systems.	O	O	Review	397
2017.	O	O	Review	397
<sep> [4] - Fraccaro, Marco, et al "A disentangled recognition and nonlinear dynamics model for unsupervised learning."	O	O	Review	397
Advances in Neural Information Processing Systems.	O	O	Review	397
2017.	O	O	Review	397
Dear Reviewer, thank you for your thoughtful comments and feedback.	O	O	Reply	397
<sep> <sep> [Why is Hamiltonian flow more efficient]: The benefits of the NHF over standard flows, as discussed at the end of section 3.3, are that since the NHF is volume preserving by design we do not need to calculate the standard log determinant of the likelihood, because it is 0.	B-Reply	B-3	Reply	397
Additionally, similar to Neural ODEs (and RevNets for instance) you do not need to store the forward pass for computing gradients as the model can be directly inverted.	I-Reply	I-3	Reply	397
Finally, we can even use simple symplectic integrators, like the leapfrog integrator, when the Hamiltonian is separable, and this defines a valid volume preserving transformation even in the discrete case (e.g. not only in the limit dt-&gt;0).	I-Reply	I-3	Reply	397
We are also running extra experiments to produce a quantitative comparison between NHF and some of the existing alternatives.	I-Reply	I-3	Reply	397
We will include these results in the paper as soon as they are ready.	I-Reply	I-3	Reply	397
<sep> <sep> [Relevance of the model in the context of past work]: Thank you for raising this point and for providing these references.	B-Reply	B-2	Reply	397
As described in the introduction to our submission, the main goal of our paper is to introduce the Hamiltonian formalism to contemporary machine learning, since it plays a central role in physics, the theory and tools around it have a long history of development and use, and it has properties that many machine learning systems may benefit from, like time reversibility, smooth interpolation in time and conservation of state properties.	I-Reply	I-2	Reply	397
Given that this is a relatively new line of work, we start by modelling image sequences with well understood underlying physical dynamics that allow us to evaluate our approach easily.	I-Reply	I-2	Reply	397
The  aim of this work is not primarily image sequence modelling.	I-Reply	I-2	Reply	397
This is the reason why we do not compare to the large body of literature that uses neural networks to model image sequences, and instead only focus on the most relevant work with the same motivation as us, the Greydanus et al (2019) paper.	I-Reply	I-2	Reply	397
<sep> <sep> That said, the references you raise are certainly very interesting, despite not being directly comparable to our present work.	I-Reply	I-2	Reply	397
Of these four papers, de Avila Belbute-Peres et al [2] is the closest in flavour to our work, as it proposes a model that works from images and that models dynamics. [	I-Reply	I-2	Reply	397
2] uses an autoencoder to map images to a latent variable that can be stepped forward in time using a learned physics model.	I-Reply	I-2	Reply	397
As such, this model is similar in both design philosophy and architecture to the pixel version of HNN (Greydanus et al, 2019), which, however, is a more direct baseline and which our model consistently outperforms.	I-Reply	I-2	Reply	397
Moreover, the model in [2] is trained in a supervised or semi-supervised regime, which makes it difficult to baseline against our model, which is unsupervised.	I-Reply	I-2	Reply	397
We agree that this paper provides important context for understanding our contribution, and we have added it to the revised manuscript.	I-Reply	I-2	Reply	397
<sep> <sep> While Fraccaro et al [4] models image dynamics, it does not focus on modeling systems with unknown Hamiltonian dynamics.	I-Reply	I-2	Reply	397
The other two papers are less directly relevant: Battaglia et al [1] operates directly from state and leverages domain-specific knowledge about objects, and as such is not directly comparable to our work, which uses images as input and does not use knowledge about the number or structure of objects in the scene.	I-Reply	I-2	Reply	397
Santoro et al [3] is a model of relational reasoning, and is not designed to model physical system dynamics.	I-Reply	I-2	Reply	397
The experiments on physical system included probe the model's ability to extract relational information (e.g. classifying the connectivity structure of a set of moving balls), not to model dynamics.	I-Reply	I-2	Reply	397

Based on recent progress in unbiased MCMC sampling the paper proposes an unbiased contrastive divergence (UCD) algorithm for training energy based models.	O	O	Review	372
Specifically they developed an unbiased version of the gibbs sampling contrastive divergence algorithm for training restricted Boltzman machines.	O	O	Review	372
The authors demonstrate their method on a toy dataset, simulated data, as well as a reduced version (only the zero digits) of the MNIST dataset and compare the results with the standard Contrastive divergence and Persistent Contrastive Divergence methods.	O	O	Review	372
<sep> <sep> Score:	O	O	Review	372
I find the line of work on unbiased estimators important and the (although i‚Äôm not an expert) the theory in the paper seems sound.	O	O	Review	372
Further the paper is well written and relatively easy to follow.	O	O	Review	372
However I do not find the experimental section completely comprehensive and some of the results seem to achieve worse performance than what is reported in the litterature for both the proposed method and baselines (see detailed questions below).	O	O	Review	372
Overall I currently score the paper as a weak reject although I can be convinced to bump the score depending on the author feedback.	O	O	Review	372
<sep> <sep> Detailed Questions:	O	O	Review	372
Experimental Results:	O	O	Review	372
Q1) In [Tieleman2008] log-likelihood values for the full MNIST dataset using a) a small model (25 hidden units) where the likelihood is computed exactly and b) an bigger model (500 hidden units) where the likelihood is approximated.	B-Review	B-1	Review	372
On the full MNIST dataset they train using PCD, CD-1, CD-10 and report approximately Log-Likelihoods of -130 and -85 for the small and large models respectively.	I-Review	I-1	Review	372
My questions are:	I-Review	I-1	Review	372
Q1.1) In figure 4 you report approximate log-likelihood values on MNIST (only digits zero) of -150 for the different samplers using an RBM with100 hidden units.	I-Review	I-1	Review	372
That seems to be lower performance than the models in [Tieleman2008] while training on a presumably easier dataset?	I-Review	I-1	Review	372
<sep> <sep> Q1.2) In figure 4.	B-Review	B-2	Review	372
Can you comment a bit on the variance of your method which seems to be higher, Is there a Bias/Variance trade-off between UCD and e.g PCD?	I-Review	I-2	Review	372
<sep> <sep> Q1.3) [Tieleman2008] Reports training times of 1 to 9 Hours for training in on the full MNIST dataset in 2008 and [Hinton 2006] trained large RBMs in 2006.	B-Review	B-3	Review	372
Why is that setting then computationally time-consuming today in your setup - Is there some difference in the setup that I'm missing?	I-Review	I-3	Review	372
<sep> <sep> Q1.4) I highly value enlightening small scale experiments and do understand that computational resources are not available everywhere however I think it would benefit the paper greatly if the proposed method is demonstrated on some reasonably sized dataset (at the very least one of full MNIST, Fashion MNIST, FreyFaces).	B-Review	B-4	Review	372
<sep> <sep> Q1.5) In Figure 2 you show some interesting figures for the average stopping time and number of rejected samples on the BAS toy dataset.	B-Review	B-5	Review	372
How does these results look on a real dataset like the MNIST zero digit data?	I-Review	I-5	Review	372
<sep> <sep> [Tieleman 2008], Training Restricted Boltzmann Machines using Approximations to the Likelihood Gradient,	O	O	Review	372
[Hinton 2006] Reducing the Dimensionality of Data with Neural Networks	O	O	Review	372
<sep> Thanks for the constructive comments on numerical experiments, and we have adopted the suggestion to compute on a large data set (the full Fashion-MNIST) with a large model (1000 hidden units).	B-Reply	B-4	Reply	372
We have also included many other discussions such as the variance of UCD and the computational cost.	B-Reply	B-2	Reply	372
The detailed responses are as follows.	I-Reply	I-2	Reply	372
<sep> <sep> &gt;&gt;&gt; Q1) In [Tieleman2008] log-likelihood values for the full MNIST dataset using a) a small model (25 hidden units) where the likelihood is computed exactly and b) an bigger model (500 hidden units) where the likelihood is approximated.	O	O	Reply	372
On the full MNIST dataset they train using PCD, CD-1, CD-10 and report approximately Log-Likelihoods of -130 and -85 for the small and large models respectively.	O	O	Reply	372
My questions are:	O	O	Reply	372
&gt;&gt;&gt; Q1.1) In figure 4 you report approximate log-likelihood values on MNIST (only digits zero) of -150 for the different samplers using an RBM with100 hidden units.	O	O	Reply	372
That seems to be lower performance than the models in [Tieleman2008] while training on a presumably easier dataset?	O	O	Reply	372
<sep> <sep> In general the likelihood values are not comparable with different data sets.	B-Reply	B-1	Reply	372
In the updated version we have trained a much larger model (1000 hidden units) with the full Fashion-MNIST data.	I-Reply	I-1	Reply	372
We hope the new experiment is more convincing.	I-Reply	I-1	Reply	372
<sep> <sep> &gt;&gt;&gt; Q1.2) In figure 4.	O	O	Reply	372
Can you comment a bit on the variance of your method which seems to be higher, Is there a Bias/Variance trade-off between UCD and e.g PCD?	O	O	Reply	372
<sep> <sep> Yes, in the updated version we discuss the variance of UCD in Appendix C.	B-Reply	B-2	Reply	372
<sep> &gt;&gt;&gt; Q1.3) [Tieleman2008] Reports training times of 1 to 9 Hours for training in on the full MNIST dataset in 2008 and [Hinton 2006] trained large RBMs in 2006.	O	O	Reply	372
Why is that setting then computationally time-consuming today in your setup - Is there some difference in the setup that I'm missing?	O	O	Reply	372
<sep> <sep> What we meant about "time-consuming" is the following: we found that the MNIST data set was quite "benign", or "robust", in the sense that even biased algorithms such as CD can train a reasonably good model.	B-Reply	B-3	Reply	372
Therefore, it may take a very long time to actually observe the divergence of CD (recall that even in the small BAS data, it takes thousands of iterations).	I-Reply	I-3	Reply	372
But on the Fashion-MNIST data that we use in the updated manuscript, it is easy to see the differences of CD, PCD, and UCD, even with a small number of iterations.	I-Reply	I-3	Reply	372
<sep> <sep> &gt;&gt;&gt; Q1.4) I highly value enlightening small scale experiments and do understand that computational resources are not available everywhere however I think it would benefit the paper greatly if the proposed method is demonstrated on some reasonably sized dataset (at the very least one of full MNIST, Fashion MNIST, FreyFaces).	O	O	Reply	372
<sep> <sep> Thanks for the recommendation.	B-Reply	B-4	Reply	372
We have updated our experiment based on the full Fashion-MNIST data.	I-Reply	I-4	Reply	372
<sep> <sep> &gt;&gt;&gt; Q1.5) In Figure 2 you show some interesting figures for the average stopping time and number of rejected samples on the BAS toy dataset.	O	O	Reply	372
How does these results look on a real dataset like the MNIST zero digit data?	O	O	Reply	372
<sep> <sep> In fact we have included such results in Appendix B. In the new manuscript the plot for Fashion-MNIST is in Figure 11.	B-Reply	B-5	Reply	372

The paper introduces an efficient, unbiased contrastive divergence-like algorithm for training energy-based generative models on the example of Restricted Boltzmann Machine.	O	O	Review	372
<sep> The proposed algorithm is built upon a very interesting work on unbiased finite-step MCMC approximations by Jacob et al, 2017.	O	O	Review	372
<sep> Despite the actual theory being published some time ago, the submitted paper popularises these ideas in the machine learning community and contains optimised variants of the existing algorithms for training of RBMs.	O	O	Review	372
<sep> <sep> The paper is mostly written well and does a good job of introducing unbiased MCMC estimators.	O	O	Review	372
<sep> Authors evaluate their method on rather toyish datasets (by modern standards), however, their empirical analysis is thorough.	O	O	Review	372
The improvement upon the standard CD and persistent CD is clear.	O	O	Review	372
<sep> It also appears that the algorithm actually does not require too many steps and generally does not introduce a lot of computational overhead.	O	O	Review	372
<sep> The only question I have is why CD has only been tried with k=1 steps?	B-Review	B-1	Review	372
<sep> I would be interested in its performance for different number of steps including the dynamically chosen number provided by the empirical \tau in UCD for a given iteration.	I-Review	I-1	Review	372
<sep> Even though I do not expect a significant improvement to be obtained, this would separate the effect of the number of steps chosen ‚Äúright‚Äù from unbiasedness of the gradient estimator.	B-Review	B-2	Review	372
<sep> Other baselines, including those mentioned in the related work, could also make the comparison more complete.	B-Review	B-3	Review	372
<sep> <sep> I would also suggest including <a href="https://arxiv.org/abs/1905.04062," target="_blank" rel="nofollow">https://arxiv.org/abs/1905.04062,</a> as it seems to be relevant in the spirit.	B-Review	B-4	Review	372
Thanks for the suggestions.	O	O	Reply	372
We have added more comparisons in the new version.	B-Reply	B-3	Reply	372
<sep> <sep> &gt;&gt;&gt; The only question I have is why CD has only been tried with k=1 steps?	O	O	Reply	372
<sep> I would be interested in its performance for different number of steps including the dynamically chosen number provided by the empirical \tau in UCD for a given iteration.	O	O	Reply	372
<sep> Even though I do not expect a significant improvement to be obtained, this would separate the effect of the number of steps chosen ‚Äúright‚Äù from unbiasedness of the gradient estimator.	B-Reply	B-1	Reply	372
<sep> Other baselines, including those mentioned in the related work, could also make the comparison more complete.	I-Reply	I-1	Reply	372
<sep> <sep> We have significantly improved the numerical experiments with larger models, and have included CD-k algorithms with larger k in Appendix B.	I-Reply	I-1	Reply	372
<sep> &gt;&gt;&gt; I would also suggest including <a href="https://arxiv.org/abs/1905.04062," target="_blank" rel="nofollow">https://arxiv.org/abs/1905.04062,</a> as it seems to be relevant in the spirit.	O	O	Reply	372
<sep> <sep> We have added this article to our reference.	B-Reply	B-4	Reply	372

The paper proposes an algorithmic improvement that significantly simplifies training of energy-based models, such as the Restricted Boltzmann Machine.	O	O	Review	372
The key issue in training such models is computing the gradient of the log partition function, which can be framed as computing the expected value of f(x) = dE(x; theta) / d theta over the model distribution p(x).	O	O	Review	372
The canonical algorithm for this problem is Contrastive Divergence which approximates x ~ p(x) with k steps of Gibbs sampling, resulting in biased gradients.	O	O	Review	372
In this paper, the authors apply the recently introduced unbiased MCMC framework of Jacob et al to completely remove the bias.	O	O	Review	372
The key idea is to (1) rewrite the expectation as a limit of a telescopic sum: E f(x_0) + \sum_t E f(x_t) - E f(x_{t-1}); (2) run two coupled MCMC chains, one for the ‚Äúpositive‚Äù part of the telescopic sum and one for the ‚Äúnegative‚Äù part until they converge.	O	O	Review	372
After convergence, all remaining terms of the sum are zero and we can stop iterating.	O	O	Review	372
However, the number of time steps until convergence is now random.	O	O	Review	372
<sep> <sep> Other contributions of the paper are:	O	O	Review	372
1.	O	O	Review	372
Proof that Bernoulli RBMs and other models satisfying certain conditions have finite expected number of steps and finite variance of the unbiased gradient estimator.	O	O	Review	372
<sep> 2.	O	O	Review	372
A shared random variables method for the coupled Gibbs chains that should result in faster convergence of the chains.	O	O	Review	372
<sep> 3.	O	O	Review	372
Verification of the proposed method on two synthetic datasets and a subset of MNIST, demonstrating more stable training compared to contrastive divergence and persistent contrastive divergence.	O	O	Review	372
<sep> <sep> I am very excited about this paper and strongly support its acceptance, since the proposed method should revitalize research in energy-based models.	O	O	Review	372
While I find the experiments to be somewhat lacking, this is sufficiently offset by the theoretical contributions of the paper.	O	O	Review	372
<sep> <sep> Pros	O	O	Review	372
1.	O	O	Review	372
The paper reads well and introduces all the necessary preliminaries to understand the method.	O	O	Review	372
This is important, since I expect many readers to be unfamiliar with the technique.	O	O	Review	372
<sep> 2.	O	O	Review	372
The proposed method solves an important problem which, as far as I understand, has been the roadblock in large-scale training of RBMs and related models.	O	O	Review	372
It is also elegant and fairly straightforward to implement.	O	O	Review	372
<sep> 3.	O	O	Review	372
The proof of finite computation time and variance is very nice to have.	O	O	Review	372
This is because in some cases removing the bias leads to infinite variance, e.g. a parallel submission on SUMO (<a href="https://openreview.net/forum?id=SylkYeHtwr)."	O	O	Review	372
target="_blank" rel="nofollow">https://openreview.net/forum?id=SylkYeHtwr).</a>	O	O	Review	372
<sep> Cons	O	O	Review	372
1.	O	O	Review	372
I don‚Äôt think Corollary 1 (convergence of gradient descent to the global optimum) is true for RBMs, as stated on Page 6.	B-Review	B-1	Review	372
This is because the log-likelihood of RBM, or indeed any latent-variable model with permutation-invariant latents, is non-convex.	I-Review	I-1	Review	372
I would suggest removing this corollary and simplifying Algorithm 2 to be regular SGD, as used in the experiments.	I-Review	I-1	Review	372
<sep> 2.	O	O	Review	372
There is no experimental comparison of Algorithm 1 (the general version) and Algorithm 3 (the specialized RBM version).	B-Review	B-2	Review	372
It seems intuitive that the specialized version should have lower computation time, but this must be confirmed.	I-Review	I-2	Review	372
<sep> 3.	O	O	Review	372
The experimental section may be significantly improved.	O	O	Review	372
<sep> * It is unclear what value of k (number of initial Gibbs steps) from Algorithm 2 is used.	B-Review	B-3	Review	372
<sep> * The experiments on just the ‚Äú0‚Äù digits of MNIST seem a bit simplistic for the year 2019.	B-Review	B-4	Review	372
It is also not clear what binarization protocol is used.	I-Review	I-4	Review	372
<sep> * It would be very helpful to provide estimates of the gradient (not log-likelihood) variance of each method to better understand the trade-off between the bias and the variance.	B-Review	B-5	Review	372
<sep> * I would also like to see the wall-clock time comparison of the methods.	B-Review	B-6	Review	372
<sep> <sep> Minor comments	O	O	Review	372
* Page 1.	B-Review	B-7	Review	372
Of this kind -&gt; of this class.	I-Review	I-7	Review	372
The data distribution p_v (v; theta) -&gt; The model distribution	I-Review	I-7	Review	372
* Page 2.	B-Review	B-8	Review	372
Property -&gt; properties.	I-Review	I-8	Review	372
CD-\tau -- I don‚Äôt think you can correctly refer to your method in this way, since it has at least double the computation time of CD for the same number of iterations.	I-Review	I-8	Review	372
<sep> * Page 3.	B-Review	B-9	Review	372
Provides -&gt; provide.	I-Review	I-9	Review	372
Likelihood gradient -&gt; log-likelihood gradient	I-Review	I-9	Review	372
* Algorithm 1 is an infinite loop with no break clause.	B-Review	B-10	Review	372
It would be good to add a break statement after line 5.	I-Review	I-10	Review	372
This would also simplify the discussion of the method.	I-Review	I-10	Review	372
<sep> * Page 7.	B-Review	B-11	Review	372
I wouldn‚Äôt call the fact that CD doesn‚Äôt converge on the BAS dataset remarkable, given that it‚Äôs been reported by Fischer &amp; Igel 2014.	I-Review	I-11	Review	372
<sep> * Page 9.	B-Review	B-12	Review	372
The last paragraph stating that the proposed method is not a replacement for CD is confusing.	I-Review	I-12	Review	372
Can you add a short experiment to demonstrate that this combination makes sense?	I-Review	I-12	Review	372
Thanks for the helpful comments and corrections.	O	O	Reply	372
We have included many new numerical results in the updated manuscript, and below are our line-to-line responses.	O	O	Reply	372
<sep> <sep> &gt;&gt;&gt; 1.	O	O	Reply	372
I don‚Äôt think Corollary 1 (convergence of gradient descent to the global optimum) is true for RBMs, as stated on Page 6.	O	O	Reply	372
This is because the log-likelihood of RBM, or indeed any latent-variable model with permutation-invariant latents, is non-convex.	O	O	Reply	372
I would suggest removing this corollary and simplifying Algorithm 2 to be regular SGD, as used in the experiments.	O	O	Reply	372
<sep> <sep> For Theorem 1 and Algorithm 2 we do not assume a specific model for, and Corollary 1 is mainly used to demonstrate a typical convergence result for SGD.	B-Reply	B-1	Reply	372
Indeed it does not apply to RBM as the objective function is not convex, so on top of page 6 we have mentioned that there are other versions of the theorem, for different types of objective functions.	I-Reply	I-1	Reply	372
We have made this clearer in the updated manuscript.	I-Reply	I-1	Reply	372
<sep> <sep> &gt;&gt;&gt; 2.	O	O	Reply	372
There is no experimental comparison of Algorithm 1 (the general version) and Algorithm 3 (the specialized RBM version).	O	O	Reply	372
It seems intuitive that the specialized version should have lower computation time, but this must be confirmed.	O	O	Reply	372
<sep> <sep> Thanks for pointing out.	B-Reply	B-2	Reply	372
We have added this comparison in Appendix A.2.	I-Reply	I-2	Reply	372
<sep> <sep> &gt;&gt;&gt; 3.	O	O	Reply	372
The experimental section may be significantly improved.	O	O	Reply	372
<sep> &gt;&gt;&gt; * It is unclear what value of k (number of initial Gibbs steps) from Algorithm 2 is used.	O	O	Reply	372
<sep> <sep> In all our experiments we set k=1.	B-Reply	B-3	Reply	372
We have added this point to the text.	I-Reply	I-3	Reply	372
<sep> <sep> &gt;&gt;&gt; * The experiments on just the ‚Äú0‚Äù digits of MNIST seem a bit simplistic for the year 2019.	O	O	Reply	372
It is also not clear what binarization protocol is used.	O	O	Reply	372
<sep> <sep> We have significantly increased the size of the experiment: a full Fashion-MNIST data set with n=1000 hidden units.	B-Reply	B-4	Reply	372
We treat data values as probabilities and globally binarize all the data points by sampling from Bernoulli distributions.	I-Reply	I-4	Reply	372
The binarized data are then passed to the models.	I-Reply	I-4	Reply	372
<sep> <sep> &gt;&gt;&gt; * It would be very helpful to provide estimates of the gradient (not log-likelihood) variance of each method to better understand the trade-off between the bias and the variance.	O	O	Reply	372
<sep> <sep> We have included such an analysis in Appendix C.	B-Reply	B-5	Reply	372
<sep> &gt;&gt;&gt; * I would also like to see the wall-clock time comparison of the methods.	O	O	Reply	372
<sep> <sep> We have included the timing comparisons in Appendix B.	B-Reply	B-6	Reply	372
<sep> &gt;&gt;&gt; Minor comments	O	O	Reply	372
&gt;&gt;&gt; * Page 1.	O	O	Reply	372
Of this kind -&gt; of this class.	O	O	Reply	372
The data distribution p_v (v; theta) -&gt; The model distribution	O	O	Reply	372
<sep> Corrected.	B-Reply	B-9	Reply	372
<sep> <sep> &gt;&gt;&gt; * Page 2.	O	O	Reply	372
Property -&gt; properties.	O	O	Reply	372
CD-\tau -- I don‚Äôt think you can correctly refer to your method in this way, since it has at least double the computation time of CD for the same number of iterations.	O	O	Reply	372
<sep> <sep> We have removed this notation and changed the wording.	B-Reply	B-8	Reply	372
<sep> <sep> &gt;&gt;&gt; * Page 3.	O	O	Reply	372
Provides -&gt; provide.	O	O	Reply	372
Likelihood gradient -&gt; log-likelihood gradient	O	O	Reply	372
<sep> Corrected.	O	O	Reply	372
<sep> <sep> &gt;&gt;&gt; * Algorithm 1 is an infinite loop with no break clause.	O	O	Reply	372
It would be good to add a break statement after line 5.	O	O	Reply	372
This would also simplify the discussion of the method.	O	O	Reply	372
<sep> <sep> We have added a maximum stopping time to Algorithm 1.	B-Reply	B-10	Reply	372
<sep> <sep> &gt;&gt;&gt; * Page 7.	O	O	Reply	372
I wouldn‚Äôt call the fact that CD doesn‚Äôt converge on the BAS dataset remarkable, given that it‚Äôs been reported by Fischer &amp; Igel 2014.	O	O	Reply	372
<sep> <sep> Fixed and rewritten.	B-Reply	B-11	Reply	372
<sep> <sep> &gt;&gt;&gt; * Page 9.	O	O	Reply	372
The last paragraph stating that the proposed method is not a replacement for CD is confusing.	O	O	Reply	372
Can you add a short experiment to demonstrate that this combination makes sense?	O	O	Reply	372
<sep> <sep> Yes, we have added an example in Appendix B.2 and Figure 9.	B-Reply	B-12	Reply	372

